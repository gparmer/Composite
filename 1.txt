
/home/hcwang/composite/transfer/unit_fpu_test.o:     file format elf32-i386


Disassembly of section .text:

00000000 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
       0:	55                   	push   %ebp
       1:	89 e5                	mov    %esp,%ebp
       3:	57                   	push   %edi
       4:	56                   	push   %esi
       5:	53                   	push   %ebx
       6:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
       9:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
      10:	8b 45 08             	mov    0x8(%ebp),%eax
      13:	83 c0 01             	add    $0x1,%eax
      16:	c1 e0 10             	shl    $0x10,%eax
      19:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
      1c:	8b 45 0c             	mov    0xc(%ebp),%eax
      1f:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
      22:	8b 45 08             	mov    0x8(%ebp),%eax
      25:	8b 4d 10             	mov    0x10(%ebp),%ecx
      28:	8b 75 14             	mov    0x14(%ebp),%esi
      2b:	8b 7d 18             	mov    0x18(%ebp),%edi
      2e:	8b 55 1c             	mov    0x1c(%ebp),%edx
      31:	89 cb                	mov    %ecx,%ebx
      33:	55                   	push   %ebp
      34:	89 e5                	mov    %esp,%ebp
      36:	b9 48 00 00 00       	mov    $0x48,%ecx
      3b:	0f 34                	sysenter 
      3d:	8d 76 00             	lea    0x0(%esi),%esi
      40:	eb 0d                	jmp    4f <call_cap_asm+0x4f>
      42:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
      48:	b9 00 00 00 00       	mov    $0x0,%ecx
      4d:	eb 05                	jmp    54 <call_cap_asm+0x54>
      4f:	b9 01 00 00 00       	mov    $0x1,%ecx
      54:	5d                   	pop    %ebp
      55:	89 ca                	mov    %ecx,%edx
      57:	89 45 ec             	mov    %eax,-0x14(%ebp)
      5a:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
      5d:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
      60:	83 c4 10             	add    $0x10,%esp
      63:	5b                   	pop    %ebx
      64:	5e                   	pop    %esi
      65:	5f                   	pop    %edi
      66:	5d                   	pop    %ebp
      67:	c3                   	ret    

00000068 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
      68:	55                   	push   %ebp
      69:	89 e5                	mov    %esp,%ebp
      6b:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
      6e:	8b 45 18             	mov    0x18(%ebp),%eax
      71:	89 44 24 14          	mov    %eax,0x14(%esp)
      75:	8b 45 14             	mov    0x14(%ebp),%eax
      78:	89 44 24 10          	mov    %eax,0x10(%esp)
      7c:	8b 45 10             	mov    0x10(%ebp),%eax
      7f:	89 44 24 0c          	mov    %eax,0xc(%esp)
      83:	8b 45 0c             	mov    0xc(%ebp),%eax
      86:	89 44 24 08          	mov    %eax,0x8(%esp)
      8a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
      91:	00 
      92:	8b 45 08             	mov    0x8(%ebp),%eax
      95:	89 04 24             	mov    %eax,(%esp)
      98:	e8 63 ff ff ff       	call   0 <call_cap_asm>
}
      9d:	c9                   	leave  
      9e:	c3                   	ret    

0000009f <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
      9f:	55                   	push   %ebp
      a0:	89 e5                	mov    %esp,%ebp
      a2:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
      a5:	8b 45 08             	mov    0x8(%ebp),%eax
      a8:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
      af:	00 
      b0:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
      b7:	00 
      b8:	8b 55 0c             	mov    0xc(%ebp),%edx
      bb:	89 54 24 08          	mov    %edx,0x8(%esp)
      bf:	89 44 24 04          	mov    %eax,0x4(%esp)
      c3:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
      ca:	e8 99 ff ff ff       	call   68 <call_cap>
}
      cf:	c9                   	leave  
      d0:	c3                   	ret    

000000d1 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
      d1:	55                   	push   %ebp
      d2:	89 e5                	mov    %esp,%ebp
      d4:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
      d7:	89 e0                	mov    %esp,%eax
      d9:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
      dc:	8b 45 fc             	mov    -0x4(%ebp),%eax
      df:	25 00 f0 ff ff       	and    $0xfffff000,%eax
      e4:	89 c2                	mov    %eax,%edx
      e6:	8b 45 08             	mov    0x8(%ebp),%eax
      e9:	c1 e0 02             	shl    $0x2,%eax
      ec:	29 c2                	sub    %eax,%edx
      ee:	89 d0                	mov    %edx,%eax
      f0:	05 00 10 00 00       	add    $0x1000,%eax
      f5:	8b 00                	mov    (%eax),%eax
}
      f7:	c9                   	leave  
      f8:	c3                   	ret    

000000f9 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
      f9:	55                   	push   %ebp
      fa:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
      fc:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
     101:	5d                   	pop    %ebp
     102:	c3                   	ret    

00000103 <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
     103:	55                   	push   %ebp
     104:	89 e5                	mov    %esp,%ebp
     106:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
     109:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
     110:	e8 bc ff ff ff       	call   d1 <get_stk_data>
}
     115:	c9                   	leave  
     116:	c3                   	ret    

00000117 <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
     117:	55                   	push   %ebp
     118:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
     11a:	e8 e4 ff ff ff       	call   103 <cos_get_thd_id>
}
     11f:	5d                   	pop    %ebp
     120:	c3                   	ret    

00000121 <cos_spd_id>:
		goto label;      \
	} while (0)

static inline long
cos_spd_id(void)
{
     121:	55                   	push   %ebp
     122:	89 e5                	mov    %esp,%ebp
	return cos_comp_info.cos_this_spd_id;
     124:	a1 40 00 00 00       	mov    0x40,%eax
}
     129:	5d                   	pop    %ebp
     12a:	c3                   	ret    

0000012b <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
     12b:	55                   	push   %ebp
     12c:	89 e5                	mov    %esp,%ebp
     12e:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
     131:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
     138:	eb 20                	jmp    15a <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
     13a:	8b 45 f4             	mov    -0xc(%ebp),%eax
     13d:	83 c0 01             	add    $0x1,%eax
     140:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
     147:	8b 45 08             	mov    0x8(%ebp),%eax
     14a:	01 d0                	add    %edx,%eax
     14c:	8b 00                	mov    (%eax),%eax
     14e:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
     151:	8b 45 f0             	mov    -0x10(%ebp),%eax
     154:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
     156:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
     15a:	8b 45 08             	mov    0x8(%ebp),%eax
     15d:	8b 00                	mov    (%eax),%eax
     15f:	3b 45 f4             	cmp    -0xc(%ebp),%eax
     162:	7f d6                	jg     13a <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
     164:	c9                   	leave  
     165:	c3                   	ret    

00000166 <constructors_execute>:

static void
constructors_execute(void)
{
     166:	55                   	push   %ebp
     167:	89 e5                	mov    %esp,%ebp
     169:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
     16c:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
     173:	e8 b3 ff ff ff       	call   12b <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
     178:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
     17f:	e8 a7 ff ff ff       	call   12b <section_fnptrs_execute>
}
     184:	c9                   	leave  
     185:	c3                   	ret    

00000186 <destructors_execute>:
static void
destructors_execute(void)
{
     186:	55                   	push   %ebp
     187:	89 e5                	mov    %esp,%ebp
     189:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
     18c:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
     193:	e8 93 ff ff ff       	call   12b <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
     198:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
     19f:	e8 87 ff ff ff       	call   12b <section_fnptrs_execute>
}
     1a4:	c9                   	leave  
     1a5:	c3                   	ret    

000001a6 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
     1a6:	55                   	push   %ebp
     1a7:	89 e5                	mov    %esp,%ebp
     1a9:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
     1ac:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
     1b3:	e8 73 ff ff ff       	call   12b <section_fnptrs_execute>
}
     1b8:	c9                   	leave  
     1b9:	c3                   	ret    

000001ba <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
     1ba:	55                   	push   %ebp
     1bb:	89 e5                	mov    %esp,%ebp
     1bd:	83 ec 08             	sub    $0x8,%esp
     1c0:	8b 55 08             	mov    0x8(%ebp),%edx
     1c3:	8b 45 0c             	mov    0xc(%ebp),%eax
     1c6:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
     1ca:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
     1cd:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
     1d1:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
     1d5:	ee                   	out    %al,(%dx)
}
     1d6:	c9                   	leave  
     1d7:	c3                   	ret    

000001d8 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
     1d8:	55                   	push   %ebp
     1d9:	89 e5                	mov    %esp,%ebp
     1db:	83 ec 14             	sub    $0x14,%esp
     1de:	8b 45 08             	mov    0x8(%ebp),%eax
     1e1:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
     1e5:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
     1e9:	89 c2                	mov    %eax,%edx
     1eb:	ec                   	in     (%dx),%al
     1ec:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
     1ef:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
     1f3:	c9                   	leave  
     1f4:	c3                   	ret    

000001f5 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
     1f5:	55                   	push   %ebp
     1f6:	89 e5                	mov    %esp,%ebp
     1f8:	83 ec 0c             	sub    $0xc,%esp
     1fb:	8b 45 08             	mov    0x8(%ebp),%eax
     1fe:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
     201:	90                   	nop
     202:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
     209:	e8 ca ff ff ff       	call   1d8 <inb>
     20e:	0f b6 c0             	movzbl %al,%eax
     211:	83 e0 20             	and    $0x20,%eax
     214:	85 c0                	test   %eax,%eax
     216:	74 ea                	je     202 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
     218:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     21c:	0f b6 c0             	movzbl %al,%eax
     21f:	89 44 24 04          	mov    %eax,0x4(%esp)
     223:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
     22a:	e8 8b ff ff ff       	call   1ba <outb>
}
     22f:	c9                   	leave  
     230:	c3                   	ret    

00000231 <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
     231:	55                   	push   %ebp
     232:	89 e5                	mov    %esp,%ebp
     234:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
     237:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
     23e:	eb 1a                	jmp    25a <cos_serial_putb+0x29>
     240:	8b 45 fc             	mov    -0x4(%ebp),%eax
     243:	8b 55 08             	mov    0x8(%ebp),%edx
     246:	01 d0                	add    %edx,%eax
     248:	0f b6 00             	movzbl (%eax),%eax
     24b:	0f be c0             	movsbl %al,%eax
     24e:	89 04 24             	mov    %eax,(%esp)
     251:	e8 9f ff ff ff       	call   1f5 <cos_serial_putc>
     256:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
     25a:	8b 45 fc             	mov    -0x4(%ebp),%eax
     25d:	3b 45 0c             	cmp    0xc(%ebp),%eax
     260:	72 de                	jb     240 <cos_serial_putb+0xf>
}
     262:	c9                   	leave  
     263:	c3                   	ret    

00000264 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
     264:	55                   	push   %ebp
     265:	89 e5                	mov    %esp,%ebp
     267:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
     26a:	8b 45 0c             	mov    0xc(%ebp),%eax
     26d:	89 44 24 04          	mov    %eax,0x4(%esp)
     271:	8b 45 08             	mov    0x8(%ebp),%eax
     274:	89 04 24             	mov    %eax,(%esp)
     277:	e8 b5 ff ff ff       	call   231 <cos_serial_putb>
}
     27c:	c9                   	leave  
     27d:	c3                   	ret    

0000027e <prints>:

static int
prints(char *s)
{
     27e:	55                   	push   %ebp
     27f:	89 e5                	mov    %esp,%ebp
     281:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
     284:	8b 45 08             	mov    0x8(%ebp),%eax
     287:	89 04 24             	mov    %eax,(%esp)
     28a:	e8 fc ff ff ff       	call   28b <prints+0xd>
     28f:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
     292:	8b 45 f4             	mov    -0xc(%ebp),%eax
     295:	89 44 24 04          	mov    %eax,0x4(%esp)
     299:	8b 45 08             	mov    0x8(%ebp),%eax
     29c:	89 04 24             	mov    %eax,(%esp)
     29f:	e8 fb fd ff ff       	call   9f <cos_print>

	return len;
     2a4:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
     2a7:	c9                   	leave  
     2a8:	c3                   	ret    

000002a9 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
     2a9:	55                   	push   %ebp
     2aa:	89 e5                	mov    %esp,%ebp
     2ac:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
     2b2:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
     2b9:	8d 45 0c             	lea    0xc(%ebp),%eax
     2bc:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
     2c2:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
     2c8:	89 44 24 0c          	mov    %eax,0xc(%esp)
     2cc:	8b 45 08             	mov    0x8(%ebp),%eax
     2cf:	89 44 24 08          	mov    %eax,0x8(%esp)
     2d3:	8b 45 f4             	mov    -0xc(%ebp),%eax
     2d6:	89 44 24 04          	mov    %eax,0x4(%esp)
     2da:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
     2e0:	89 04 24             	mov    %eax,(%esp)
     2e3:	e8 fc ff ff ff       	call   2e4 <printc+0x3b>
     2e8:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
     2eb:	8b 45 f0             	mov    -0x10(%ebp),%eax
     2ee:	89 44 24 04          	mov    %eax,0x4(%esp)
     2f2:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
     2f8:	89 04 24             	mov    %eax,(%esp)
     2fb:	e8 64 ff ff ff       	call   264 <cos_llprint>

	return ret;
     300:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
     303:	c9                   	leave  
     304:	c3                   	ret    

00000305 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
     305:	55                   	push   %ebp
     306:	89 e5                	mov    %esp,%ebp
	while (1)
		;
     308:	eb fe                	jmp    308 <__cos_noret+0x3>

0000030a <ps_cas>:
 * 0 on failure due to contention (*target != old)
 * 1 otherwise (*target == old -> *target = updated)
 */
static inline int
ps_cas(unsigned long *target, unsigned long old, unsigned long updated)
{
     30a:	55                   	push   %ebp
     30b:	89 e5                	mov    %esp,%ebp
     30d:	53                   	push   %ebx
     30e:	83 ec 10             	sub    $0x10,%esp
        char z;
        __asm__ __volatile__("lock " PS_CAS_STR
     311:	8b 55 08             	mov    0x8(%ebp),%edx
     314:	8b 4d 10             	mov    0x10(%ebp),%ecx
     317:	8b 45 0c             	mov    0xc(%ebp),%eax
     31a:	8b 5d 08             	mov    0x8(%ebp),%ebx
     31d:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
     321:	0f 94 c0             	sete   %al
     324:	88 45 fb             	mov    %al,-0x5(%ebp)
                             : "+m" (*target), "=a" (z)
                             : "q"  (updated), "a"  (old)
                             : "memory", "cc");
        return (int)z;
     327:	0f be 45 fb          	movsbl -0x5(%ebp),%eax
}
     32b:	83 c4 10             	add    $0x10,%esp
     32e:	5b                   	pop    %ebx
     32f:	5d                   	pop    %ebp
     330:	c3                   	ret    

00000331 <ps_faa>:

static inline long
ps_faa(unsigned long *target, long inc)
{
     331:	55                   	push   %ebp
     332:	89 e5                	mov    %esp,%ebp
        __asm__ __volatile__("lock " PS_FAA_STR
     334:	8b 55 08             	mov    0x8(%ebp),%edx
     337:	8b 4d 08             	mov    0x8(%ebp),%ecx
     33a:	8b 45 0c             	mov    0xc(%ebp),%eax
     33d:	f0 0f c1 02          	lock xadd %eax,(%edx)
     341:	89 45 0c             	mov    %eax,0xc(%ebp)
                             : "+m" (*target), "+q" (inc)
                             : : "memory", "cc");
        return inc;
     344:	8b 45 0c             	mov    0xc(%ebp),%eax
}
     347:	5d                   	pop    %ebp
     348:	c3                   	ret    

00000349 <ps_tsc>:
ps_lock_init(struct ps_lock *l)
{ l->o = 0; }

static inline ps_tsc_t
ps_tsc(void)
{
     349:	55                   	push   %ebp
     34a:	89 e5                	mov    %esp,%ebp
     34c:	57                   	push   %edi
     34d:	56                   	push   %esi
     34e:	53                   	push   %ebx
     34f:	83 ec 1c             	sub    $0x1c,%esp
	unsigned long a, d, c;

	__asm__ __volatile__("rdtsc" : "=a" (a), "=d" (d), "=c" (c) : : );
     352:	0f 31                	rdtsc  
     354:	89 45 ec             	mov    %eax,-0x14(%ebp)
     357:	89 55 e8             	mov    %edx,-0x18(%ebp)
     35a:	89 4d e4             	mov    %ecx,-0x1c(%ebp)

	return ((u64_t)d << 32) | (u64_t)a;
     35d:	8b 45 e8             	mov    -0x18(%ebp),%eax
     360:	ba 00 00 00 00       	mov    $0x0,%edx
     365:	89 c2                	mov    %eax,%edx
     367:	b8 00 00 00 00       	mov    $0x0,%eax
     36c:	89 c1                	mov    %eax,%ecx
     36e:	89 d3                	mov    %edx,%ebx
     370:	8b 45 ec             	mov    -0x14(%ebp),%eax
     373:	ba 00 00 00 00       	mov    $0x0,%edx
     378:	89 45 d8             	mov    %eax,-0x28(%ebp)
     37b:	89 55 dc             	mov    %edx,-0x24(%ebp)
     37e:	89 c8                	mov    %ecx,%eax
     380:	0b 45 d8             	or     -0x28(%ebp),%eax
     383:	89 c6                	mov    %eax,%esi
     385:	89 d8                	mov    %ebx,%eax
     387:	0b 45 dc             	or     -0x24(%ebp),%eax
     38a:	89 c7                	mov    %eax,%edi
     38c:	89 f0                	mov    %esi,%eax
     38e:	89 fa                	mov    %edi,%edx
}
     390:	83 c4 1c             	add    $0x1c,%esp
     393:	5b                   	pop    %ebx
     394:	5e                   	pop    %esi
     395:	5f                   	pop    %edi
     396:	5d                   	pop    %ebp
     397:	c3                   	ret    

00000398 <cos_aepthd_fn>:
	struct cos_aep_info sched_aep[NUM_CPU];
};

static void
cos_aepthd_fn(void *data)
{
     398:	55                   	push   %ebp
     399:	89 e5                	mov    %esp,%ebp
     39b:	83 ec 28             	sub    $0x28,%esp
	struct cos_aep_info *aep_info = (struct cos_aep_info *)data;
     39e:	8b 45 08             	mov    0x8(%ebp),%eax
     3a1:	89 45 f4             	mov    %eax,-0xc(%ebp)
	cos_aepthd_fn_t      aep_fn   = aep_info->fn;
     3a4:	8b 45 f4             	mov    -0xc(%ebp),%eax
     3a7:	8b 40 10             	mov    0x10(%eax),%eax
     3aa:	89 45 f0             	mov    %eax,-0x10(%ebp)
	void *               fn_data  = aep_info->data;
     3ad:	8b 45 f4             	mov    -0xc(%ebp),%eax
     3b0:	8b 40 14             	mov    0x14(%eax),%eax
     3b3:	89 45 ec             	mov    %eax,-0x14(%ebp)

	(aep_fn)(aep_info->rcv, fn_data);
     3b6:	8b 45 f4             	mov    -0xc(%ebp),%eax
     3b9:	8b 40 0c             	mov    0xc(%eax),%eax
     3bc:	8b 55 ec             	mov    -0x14(%ebp),%edx
     3bf:	89 54 24 04          	mov    %edx,0x4(%esp)
     3c3:	89 04 24             	mov    %eax,(%esp)
     3c6:	8b 45 f0             	mov    -0x10(%ebp),%eax
     3c9:	ff d0                	call   *%eax

	/* TODO: handling destruction */
	assert(0);
     3cb:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
     3d2:	e8 a7 fe ff ff       	call   27e <prints>
     3d7:	a1 00 00 00 00       	mov    0x0,%eax
     3dc:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
     3e2:	e8 1e ff ff ff       	call   305 <__cos_noret>

000003e7 <sched_param_pack>:
};
typedef u32_t sched_param_t;

static inline sched_param_t
sched_param_pack(sched_param_type_t type, unsigned int value)
{
     3e7:	55                   	push   %ebp
     3e8:	89 e5                	mov    %esp,%ebp
     3ea:	83 ec 10             	sub    $0x10,%esp
	return ((union sched_param_union){.c = {.type = type, .value = value}}).v;
     3ed:	8b 45 08             	mov    0x8(%ebp),%eax
     3f0:	88 45 fc             	mov    %al,-0x4(%ebp)
     3f3:	8b 45 0c             	mov    0xc(%ebp),%eax
     3f6:	25 ff ff ff 00       	and    $0xffffff,%eax
     3fb:	c1 e0 08             	shl    $0x8,%eax
     3fe:	89 c2                	mov    %eax,%edx
     400:	8b 45 fc             	mov    -0x4(%ebp),%eax
     403:	0f b6 c0             	movzbl %al,%eax
     406:	09 d0                	or     %edx,%eax
     408:	89 45 fc             	mov    %eax,-0x4(%ebp)
     40b:	8b 45 fc             	mov    -0x4(%ebp),%eax
}
     40e:	c9                   	leave  
     40f:	c3                   	ret    

00000410 <ps_list_ll_empty>:
ps_list_head_init(struct ps_list_head *lh)
{ ps_list_ll_init(&lh->l); }

static inline int
ps_list_ll_empty(struct ps_list *l)
{ return l->n == l; }
     410:	55                   	push   %ebp
     411:	89 e5                	mov    %esp,%ebp
     413:	8b 45 08             	mov    0x8(%ebp),%eax
     416:	8b 00                	mov    (%eax),%eax
     418:	3b 45 08             	cmp    0x8(%ebp),%eax
     41b:	0f 94 c0             	sete   %al
     41e:	0f b6 c0             	movzbl %al,%eax
     421:	5d                   	pop    %ebp
     422:	c3                   	ret    

00000423 <ps_list_ll_add>:
ps_list_head_empty(struct ps_list_head *lh)
{ return ps_list_ll_empty(&lh->l); }

static inline void
ps_list_ll_add(struct ps_list *l, struct ps_list *new)
{
     423:	55                   	push   %ebp
     424:	89 e5                	mov    %esp,%ebp
	new->n    = l->n;
     426:	8b 45 08             	mov    0x8(%ebp),%eax
     429:	8b 10                	mov    (%eax),%edx
     42b:	8b 45 0c             	mov    0xc(%ebp),%eax
     42e:	89 10                	mov    %edx,(%eax)
	new->p    = l;
     430:	8b 45 0c             	mov    0xc(%ebp),%eax
     433:	8b 55 08             	mov    0x8(%ebp),%edx
     436:	89 50 04             	mov    %edx,0x4(%eax)
	l->n      = new;
     439:	8b 45 08             	mov    0x8(%ebp),%eax
     43c:	8b 55 0c             	mov    0xc(%ebp),%edx
     43f:	89 10                	mov    %edx,(%eax)
	new->n->p = new;
     441:	8b 45 0c             	mov    0xc(%ebp),%eax
     444:	8b 00                	mov    (%eax),%eax
     446:	8b 55 0c             	mov    0xc(%ebp),%edx
     449:	89 50 04             	mov    %edx,0x4(%eax)
}
     44c:	5d                   	pop    %ebp
     44d:	c3                   	ret    

0000044e <ps_list_ll_rem>:

static inline void
ps_list_ll_rem(struct ps_list *l)
{
     44e:	55                   	push   %ebp
     44f:	89 e5                	mov    %esp,%ebp
	l->n->p = l->p;
     451:	8b 45 08             	mov    0x8(%ebp),%eax
     454:	8b 00                	mov    (%eax),%eax
     456:	8b 55 08             	mov    0x8(%ebp),%edx
     459:	8b 52 04             	mov    0x4(%edx),%edx
     45c:	89 50 04             	mov    %edx,0x4(%eax)
	l->p->n = l->n;
     45f:	8b 45 08             	mov    0x8(%ebp),%eax
     462:	8b 40 04             	mov    0x4(%eax),%eax
     465:	8b 55 08             	mov    0x8(%ebp),%edx
     468:	8b 12                	mov    (%edx),%edx
     46a:	89 10                	mov    %edx,(%eax)
	l->p = l->n = l;
     46c:	8b 45 08             	mov    0x8(%ebp),%eax
     46f:	8b 55 08             	mov    0x8(%ebp),%edx
     472:	89 10                	mov    %edx,(%eax)
     474:	8b 45 08             	mov    0x8(%ebp),%eax
     477:	8b 10                	mov    (%eax),%edx
     479:	8b 45 08             	mov    0x8(%ebp),%eax
     47c:	89 50 04             	mov    %edx,0x4(%eax)
}
     47f:	5d                   	pop    %ebp
     480:	c3                   	ret    

00000481 <__slab_freelist_rem>:
static inline void __ps_slab_freelist_check(struct ps_slab_freelist *fl) { (void)fl; }
#endif /* PS_SLAB_DEBUG */

static void
__slab_freelist_rem(struct ps_slab_freelist *fl, struct ps_slab *s)
{
     481:	55                   	push   %ebp
     482:	89 e5                	mov    %esp,%ebp
     484:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
     487:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
     48b:	0f 94 c0             	sete   %al
     48e:	0f b6 c0             	movzbl %al,%eax
     491:	85 c0                	test   %eax,%eax
     493:	75 0e                	jne    4a3 <__slab_freelist_rem+0x22>
     495:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
     499:	0f 94 c0             	sete   %al
     49c:	0f b6 c0             	movzbl %al,%eax
     49f:	85 c0                	test   %eax,%eax
     4a1:	74 1c                	je     4bf <__slab_freelist_rem+0x3e>
     4a3:	c7 04 24 64 00 00 00 	movl   $0x64,(%esp)
     4aa:	e8 cf fd ff ff       	call   27e <prints>
     4af:	a1 00 00 00 00       	mov    0x0,%eax
     4b4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
     4ba:	e8 46 fe ff ff       	call   305 <__cos_noret>
	if (fl->list == s) {
     4bf:	8b 45 08             	mov    0x8(%ebp),%eax
     4c2:	8b 00                	mov    (%eax),%eax
     4c4:	3b 45 0c             	cmp    0xc(%ebp),%eax
     4c7:	75 2b                	jne    4f4 <__slab_freelist_rem+0x73>
		if (ps_list_singleton(s, list)) fl->list = NULL;
     4c9:	8b 45 0c             	mov    0xc(%ebp),%eax
     4cc:	83 c0 44             	add    $0x44,%eax
     4cf:	89 04 24             	mov    %eax,(%esp)
     4d2:	e8 39 ff ff ff       	call   410 <ps_list_ll_empty>
     4d7:	85 c0                	test   %eax,%eax
     4d9:	74 0b                	je     4e6 <__slab_freelist_rem+0x65>
     4db:	8b 45 08             	mov    0x8(%ebp),%eax
     4de:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
     4e4:	eb 0e                	jmp    4f4 <__slab_freelist_rem+0x73>
		else                            fl->list = ps_list_next(s, list);
     4e6:	8b 45 0c             	mov    0xc(%ebp),%eax
     4e9:	8b 40 44             	mov    0x44(%eax),%eax
     4ec:	8d 50 bc             	lea    -0x44(%eax),%edx
     4ef:	8b 45 08             	mov    0x8(%ebp),%eax
     4f2:	89 10                	mov    %edx,(%eax)
	}
	ps_list_rem(s, list);
     4f4:	8b 45 0c             	mov    0xc(%ebp),%eax
     4f7:	83 c0 44             	add    $0x44,%eax
     4fa:	89 04 24             	mov    %eax,(%esp)
     4fd:	e8 4c ff ff ff       	call   44e <ps_list_ll_rem>
}
     502:	c9                   	leave  
     503:	c3                   	ret    

00000504 <__slab_freelist_add>:

static void
__slab_freelist_add(struct ps_slab_freelist *fl, struct ps_slab *s)
{
     504:	55                   	push   %ebp
     505:	89 e5                	mov    %esp,%ebp
     507:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
     50a:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
     50e:	0f 94 c0             	sete   %al
     511:	0f b6 c0             	movzbl %al,%eax
     514:	85 c0                	test   %eax,%eax
     516:	75 0e                	jne    526 <__slab_freelist_add+0x22>
     518:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
     51c:	0f 94 c0             	sete   %al
     51f:	0f b6 c0             	movzbl %al,%eax
     522:	85 c0                	test   %eax,%eax
     524:	74 1c                	je     542 <__slab_freelist_add+0x3e>
     526:	c7 04 24 bc 00 00 00 	movl   $0xbc,(%esp)
     52d:	e8 4c fd ff ff       	call   27e <prints>
     532:	a1 00 00 00 00       	mov    0x0,%eax
     537:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
     53d:	e8 c3 fd ff ff       	call   305 <__cos_noret>
	assert(ps_list_singleton(s, list));
     542:	8b 45 0c             	mov    0xc(%ebp),%eax
     545:	83 c0 44             	add    $0x44,%eax
     548:	89 04 24             	mov    %eax,(%esp)
     54b:	e8 c0 fe ff ff       	call   410 <ps_list_ll_empty>
     550:	85 c0                	test   %eax,%eax
     552:	0f 94 c0             	sete   %al
     555:	0f b6 c0             	movzbl %al,%eax
     558:	85 c0                	test   %eax,%eax
     55a:	74 1c                	je     578 <__slab_freelist_add+0x74>
     55c:	c7 04 24 14 01 00 00 	movl   $0x114,(%esp)
     563:	e8 16 fd ff ff       	call   27e <prints>
     568:	a1 00 00 00 00       	mov    0x0,%eax
     56d:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
     573:	e8 8d fd ff ff       	call   305 <__cos_noret>
	assert(s != fl->list);
     578:	8b 45 08             	mov    0x8(%ebp),%eax
     57b:	8b 00                	mov    (%eax),%eax
     57d:	3b 45 0c             	cmp    0xc(%ebp),%eax
     580:	0f 94 c0             	sete   %al
     583:	0f b6 c0             	movzbl %al,%eax
     586:	85 c0                	test   %eax,%eax
     588:	74 1c                	je     5a6 <__slab_freelist_add+0xa2>
     58a:	c7 04 24 6c 01 00 00 	movl   $0x16c,(%esp)
     591:	e8 e8 fc ff ff       	call   27e <prints>
     596:	a1 00 00 00 00       	mov    0x0,%eax
     59b:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
     5a1:	e8 5f fd ff ff       	call   305 <__cos_noret>
	if (fl->list) ps_list_add(fl->list, s, list);
     5a6:	8b 45 08             	mov    0x8(%ebp),%eax
     5a9:	8b 00                	mov    (%eax),%eax
     5ab:	85 c0                	test   %eax,%eax
     5ad:	74 1a                	je     5c9 <__slab_freelist_add+0xc5>
     5af:	8b 45 0c             	mov    0xc(%ebp),%eax
     5b2:	8d 50 44             	lea    0x44(%eax),%edx
     5b5:	8b 45 08             	mov    0x8(%ebp),%eax
     5b8:	8b 00                	mov    (%eax),%eax
     5ba:	83 c0 44             	add    $0x44,%eax
     5bd:	89 54 24 04          	mov    %edx,0x4(%esp)
     5c1:	89 04 24             	mov    %eax,(%esp)
     5c4:	e8 5a fe ff ff       	call   423 <ps_list_ll_add>
	fl->list = s;
     5c9:	8b 45 08             	mov    0x8(%ebp),%eax
     5cc:	8b 55 0c             	mov    0xc(%ebp),%edx
     5cf:	89 10                	mov    %edx,(%eax)
	/* TODO: sort based on emptiness...just use N bins */
}
     5d1:	c9                   	leave  
     5d2:	c3                   	ret    

000005d3 <ck_cc_ffs>:
 */
#ifndef CK_MD_CC_BUILTIN_DISABLE
#define CK_F_CC_FFS
CK_CC_INLINE static int
ck_cc_ffs(unsigned int x)
{
     5d3:	55                   	push   %ebp
     5d4:	89 e5                	mov    %esp,%ebp

	return __builtin_ffsl(x);
     5d6:	8b 45 08             	mov    0x8(%ebp),%eax
     5d9:	ba ff ff ff ff       	mov    $0xffffffff,%edx
     5de:	0f bc c0             	bsf    %eax,%eax
     5e1:	0f 44 c2             	cmove  %edx,%eax
     5e4:	83 c0 01             	add    $0x1,%eax
}
     5e7:	5d                   	pop    %ebp
     5e8:	c3                   	ret    

000005e9 <ck_cc_ffsl>:

#define CK_F_CC_FFSL
CK_CC_INLINE static int
ck_cc_ffsl(unsigned long x)
{
     5e9:	55                   	push   %ebp
     5ea:	89 e5                	mov    %esp,%ebp
     5ec:	83 ec 18             	sub    $0x18,%esp

	return __builtin_ffsll(x);
     5ef:	8b 45 08             	mov    0x8(%ebp),%eax
     5f2:	ba 00 00 00 00       	mov    $0x0,%edx
     5f7:	89 04 24             	mov    %eax,(%esp)
     5fa:	89 54 24 04          	mov    %edx,0x4(%esp)
     5fe:	e8 fc ff ff ff       	call   5ff <ck_cc_ffsl+0x16>
}
     603:	c9                   	leave  
     604:	c3                   	ret    

00000605 <ck_cc_ctz>:

#define CK_F_CC_CTZ
CK_CC_INLINE static int
ck_cc_ctz(unsigned int x)
{
     605:	55                   	push   %ebp
     606:	89 e5                	mov    %esp,%ebp

	return __builtin_ctz(x);
     608:	f3 0f bc 45 08       	tzcnt  0x8(%ebp),%eax
}
     60d:	5d                   	pop    %ebp
     60e:	c3                   	ret    

0000060f <ck_cc_popcount>:

#define CK_F_CC_POPCOUNT
CK_CC_INLINE static int
ck_cc_popcount(unsigned int x)
{
     60f:	55                   	push   %ebp
     610:	89 e5                	mov    %esp,%ebp
     612:	83 ec 18             	sub    $0x18,%esp

	return __builtin_popcount(x);
     615:	8b 45 08             	mov    0x8(%ebp),%eax
     618:	89 04 24             	mov    %eax,(%esp)
     61b:	e8 fc ff ff ff       	call   61c <ck_cc_popcount+0xd>
}
     620:	c9                   	leave  
     621:	c3                   	ret    

00000622 <ck_cc_ffsll>:
CK_F_CC_FFS_G(ffsl, unsigned long)
#endif /* CK_F_CC_FFSL */

#ifndef CK_F_CC_FFSLL
#define CK_F_CC_FFSLL
CK_F_CC_FFS_G(ffsll, unsigned long long)
     622:	55                   	push   %ebp
     623:	89 e5                	mov    %esp,%ebp
     625:	53                   	push   %ebx
     626:	83 ec 1c             	sub    $0x1c,%esp
     629:	8b 4d 08             	mov    0x8(%ebp),%ecx
     62c:	89 4d e0             	mov    %ecx,-0x20(%ebp)
     62f:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     632:	89 4d e4             	mov    %ecx,-0x1c(%ebp)
     635:	8b 4d e0             	mov    -0x20(%ebp),%ecx
     638:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
     63b:	09 d9                	or     %ebx,%ecx
     63d:	85 c9                	test   %ecx,%ecx
     63f:	75 07                	jne    648 <ck_cc_ffsll+0x26>
     641:	b8 00 00 00 00       	mov    $0x0,%eax
     646:	eb 3a                	jmp    682 <ck_cc_ffsll+0x60>
     648:	c7 45 f4 01 00 00 00 	movl   $0x1,-0xc(%ebp)
     64f:	eb 16                	jmp    667 <ck_cc_ffsll+0x45>
     651:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
     655:	8b 4d e0             	mov    -0x20(%ebp),%ecx
     658:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
     65b:	0f ac d9 01          	shrd   $0x1,%ebx,%ecx
     65f:	d1 eb                	shr    %ebx
     661:	89 4d e0             	mov    %ecx,-0x20(%ebp)
     664:	89 5d e4             	mov    %ebx,-0x1c(%ebp)
     667:	8b 4d e0             	mov    -0x20(%ebp),%ecx
     66a:	83 e1 01             	and    $0x1,%ecx
     66d:	89 c8                	mov    %ecx,%eax
     66f:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
     672:	83 e1 00             	and    $0x0,%ecx
     675:	89 ca                	mov    %ecx,%edx
     677:	89 d1                	mov    %edx,%ecx
     679:	09 c1                	or     %eax,%ecx
     67b:	85 c9                	test   %ecx,%ecx
     67d:	74 d2                	je     651 <ck_cc_ffsll+0x2f>
     67f:	8b 45 f4             	mov    -0xc(%ebp),%eax
     682:	83 c4 1c             	add    $0x1c,%esp
     685:	5b                   	pop    %ebx
     686:	5d                   	pop    %ebp
     687:	c3                   	ret    

00000688 <ck_pr_stall>:
 * Prevent speculative execution in busy-wait loops (P4 <=) or "predefined
 * delay".
 */
CK_CC_INLINE static void
ck_pr_stall(void)
{
     688:	55                   	push   %ebp
     689:	89 e5                	mov    %esp,%ebp
	__asm__ __volatile__("pause" ::: "memory");
     68b:	f3 90                	pause  
	return;
     68d:	90                   	nop
}
     68e:	5d                   	pop    %ebp
     68f:	c3                   	ret    

00000690 <ck_pr_fence_strict_atomic>:
#define CK_MD_X86_SFENCE "sfence"
#define CK_MD_X86_LFENCE "lfence"
#define CK_MD_X86_MFENCE "mfence"
#endif /* !CK_MD_SSE_DISABLE */

CK_PR_FENCE(atomic, "")
     690:	55                   	push   %ebp
     691:	89 e5                	mov    %esp,%ebp
     693:	90                   	nop
     694:	5d                   	pop    %ebp
     695:	c3                   	ret    

00000696 <ck_pr_fence_strict_atomic_store>:
CK_PR_FENCE(atomic_store, "")
     696:	55                   	push   %ebp
     697:	89 e5                	mov    %esp,%ebp
     699:	90                   	nop
     69a:	5d                   	pop    %ebp
     69b:	c3                   	ret    

0000069c <ck_pr_fence_strict_atomic_load>:
CK_PR_FENCE(atomic_load, "")
     69c:	55                   	push   %ebp
     69d:	89 e5                	mov    %esp,%ebp
     69f:	90                   	nop
     6a0:	5d                   	pop    %ebp
     6a1:	c3                   	ret    

000006a2 <ck_pr_fence_strict_store_atomic>:
CK_PR_FENCE(store_atomic, "")
     6a2:	55                   	push   %ebp
     6a3:	89 e5                	mov    %esp,%ebp
     6a5:	90                   	nop
     6a6:	5d                   	pop    %ebp
     6a7:	c3                   	ret    

000006a8 <ck_pr_fence_strict_load_atomic>:
CK_PR_FENCE(load_atomic, "")
     6a8:	55                   	push   %ebp
     6a9:	89 e5                	mov    %esp,%ebp
     6ab:	90                   	nop
     6ac:	5d                   	pop    %ebp
     6ad:	c3                   	ret    

000006ae <ck_pr_fence_strict_load>:
CK_PR_FENCE(load, CK_MD_X86_LFENCE)
     6ae:	55                   	push   %ebp
     6af:	89 e5                	mov    %esp,%ebp
     6b1:	0f ae e8             	lfence 
     6b4:	90                   	nop
     6b5:	5d                   	pop    %ebp
     6b6:	c3                   	ret    

000006b7 <ck_pr_fence_strict_load_store>:
CK_PR_FENCE(load_store, CK_MD_X86_MFENCE)
     6b7:	55                   	push   %ebp
     6b8:	89 e5                	mov    %esp,%ebp
     6ba:	0f ae f0             	mfence 
     6bd:	90                   	nop
     6be:	5d                   	pop    %ebp
     6bf:	c3                   	ret    

000006c0 <ck_pr_fence_strict_store>:
CK_PR_FENCE(store, CK_MD_X86_SFENCE)
     6c0:	55                   	push   %ebp
     6c1:	89 e5                	mov    %esp,%ebp
     6c3:	0f ae f8             	sfence 
     6c6:	90                   	nop
     6c7:	5d                   	pop    %ebp
     6c8:	c3                   	ret    

000006c9 <ck_pr_fence_strict_store_load>:
CK_PR_FENCE(store_load, CK_MD_X86_MFENCE)
     6c9:	55                   	push   %ebp
     6ca:	89 e5                	mov    %esp,%ebp
     6cc:	0f ae f0             	mfence 
     6cf:	90                   	nop
     6d0:	5d                   	pop    %ebp
     6d1:	c3                   	ret    

000006d2 <ck_pr_fence_strict_memory>:
CK_PR_FENCE(memory, CK_MD_X86_MFENCE)
     6d2:	55                   	push   %ebp
     6d3:	89 e5                	mov    %esp,%ebp
     6d5:	0f ae f0             	mfence 
     6d8:	90                   	nop
     6d9:	5d                   	pop    %ebp
     6da:	c3                   	ret    

000006db <ck_pr_fence_strict_release>:
CK_PR_FENCE(release, CK_MD_X86_MFENCE)
     6db:	55                   	push   %ebp
     6dc:	89 e5                	mov    %esp,%ebp
     6de:	0f ae f0             	mfence 
     6e1:	90                   	nop
     6e2:	5d                   	pop    %ebp
     6e3:	c3                   	ret    

000006e4 <ck_pr_fence_strict_acquire>:
CK_PR_FENCE(acquire, CK_MD_X86_MFENCE)
     6e4:	55                   	push   %ebp
     6e5:	89 e5                	mov    %esp,%ebp
     6e7:	0f ae f0             	mfence 
     6ea:	90                   	nop
     6eb:	5d                   	pop    %ebp
     6ec:	c3                   	ret    

000006ed <ck_pr_fence_strict_acqrel>:
CK_PR_FENCE(acqrel, CK_MD_X86_MFENCE)
     6ed:	55                   	push   %ebp
     6ee:	89 e5                	mov    %esp,%ebp
     6f0:	0f ae f0             	mfence 
     6f3:	90                   	nop
     6f4:	5d                   	pop    %ebp
     6f5:	c3                   	ret    

000006f6 <ck_pr_fence_strict_lock>:
CK_PR_FENCE(lock, CK_MD_X86_MFENCE)
     6f6:	55                   	push   %ebp
     6f7:	89 e5                	mov    %esp,%ebp
     6f9:	0f ae f0             	mfence 
     6fc:	90                   	nop
     6fd:	5d                   	pop    %ebp
     6fe:	c3                   	ret    

000006ff <ck_pr_fence_strict_unlock>:
CK_PR_FENCE(unlock, CK_MD_X86_MFENCE)
     6ff:	55                   	push   %ebp
     700:	89 e5                	mov    %esp,%ebp
     702:	0f ae f0             	mfence 
     705:	90                   	nop
     706:	5d                   	pop    %ebp
     707:	c3                   	ret    

00000708 <ck_pr_fas_ptr>:
					:			\
					: "memory");		\
		return v;					\
	}

CK_PR_FAS(ptr, void, void *, char, "xchgl")
     708:	55                   	push   %ebp
     709:	89 e5                	mov    %esp,%ebp
     70b:	8b 55 08             	mov    0x8(%ebp),%edx
     70e:	8b 4d 08             	mov    0x8(%ebp),%ecx
     711:	8b 45 0c             	mov    0xc(%ebp),%eax
     714:	87 02                	xchg   %eax,(%edx)
     716:	89 45 0c             	mov    %eax,0xc(%ebp)
     719:	8b 45 0c             	mov    0xc(%ebp),%eax
     71c:	5d                   	pop    %ebp
     71d:	c3                   	ret    

0000071e <ck_pr_fas_char>:

#define CK_PR_FAS_S(S, T, I) CK_PR_FAS(S, T, T, T, I)

CK_PR_FAS_S(char, char, "xchgb")
     71e:	55                   	push   %ebp
     71f:	89 e5                	mov    %esp,%ebp
     721:	83 ec 04             	sub    $0x4,%esp
     724:	8b 45 0c             	mov    0xc(%ebp),%eax
     727:	88 45 fc             	mov    %al,-0x4(%ebp)
     72a:	8b 55 08             	mov    0x8(%ebp),%edx
     72d:	8b 4d 08             	mov    0x8(%ebp),%ecx
     730:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     734:	86 02                	xchg   %al,(%edx)
     736:	88 45 fc             	mov    %al,-0x4(%ebp)
     739:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     73d:	c9                   	leave  
     73e:	c3                   	ret    

0000073f <ck_pr_fas_uint>:
CK_PR_FAS_S(uint, unsigned int, "xchgl")
     73f:	55                   	push   %ebp
     740:	89 e5                	mov    %esp,%ebp
     742:	8b 55 08             	mov    0x8(%ebp),%edx
     745:	8b 4d 08             	mov    0x8(%ebp),%ecx
     748:	8b 45 0c             	mov    0xc(%ebp),%eax
     74b:	87 02                	xchg   %eax,(%edx)
     74d:	89 45 0c             	mov    %eax,0xc(%ebp)
     750:	8b 45 0c             	mov    0xc(%ebp),%eax
     753:	5d                   	pop    %ebp
     754:	c3                   	ret    

00000755 <ck_pr_fas_int>:
CK_PR_FAS_S(int, int, "xchgl")
     755:	55                   	push   %ebp
     756:	89 e5                	mov    %esp,%ebp
     758:	8b 55 08             	mov    0x8(%ebp),%edx
     75b:	8b 4d 08             	mov    0x8(%ebp),%ecx
     75e:	8b 45 0c             	mov    0xc(%ebp),%eax
     761:	87 02                	xchg   %eax,(%edx)
     763:	89 45 0c             	mov    %eax,0xc(%ebp)
     766:	8b 45 0c             	mov    0xc(%ebp),%eax
     769:	5d                   	pop    %ebp
     76a:	c3                   	ret    

0000076b <ck_pr_fas_32>:
CK_PR_FAS_S(32, uint32_t, "xchgl")
     76b:	55                   	push   %ebp
     76c:	89 e5                	mov    %esp,%ebp
     76e:	8b 55 08             	mov    0x8(%ebp),%edx
     771:	8b 4d 08             	mov    0x8(%ebp),%ecx
     774:	8b 45 0c             	mov    0xc(%ebp),%eax
     777:	87 02                	xchg   %eax,(%edx)
     779:	89 45 0c             	mov    %eax,0xc(%ebp)
     77c:	8b 45 0c             	mov    0xc(%ebp),%eax
     77f:	5d                   	pop    %ebp
     780:	c3                   	ret    

00000781 <ck_pr_fas_16>:
CK_PR_FAS_S(16, uint16_t, "xchgw")
     781:	55                   	push   %ebp
     782:	89 e5                	mov    %esp,%ebp
     784:	83 ec 04             	sub    $0x4,%esp
     787:	8b 45 0c             	mov    0xc(%ebp),%eax
     78a:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     78e:	8b 55 08             	mov    0x8(%ebp),%edx
     791:	8b 4d 08             	mov    0x8(%ebp),%ecx
     794:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
     798:	66 87 02             	xchg   %ax,(%edx)
     79b:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     79f:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
     7a3:	c9                   	leave  
     7a4:	c3                   	ret    

000007a5 <ck_pr_fas_8>:
CK_PR_FAS_S(8,  uint8_t,  "xchgb")
     7a5:	55                   	push   %ebp
     7a6:	89 e5                	mov    %esp,%ebp
     7a8:	83 ec 04             	sub    $0x4,%esp
     7ab:	8b 45 0c             	mov    0xc(%ebp),%eax
     7ae:	88 45 fc             	mov    %al,-0x4(%ebp)
     7b1:	8b 55 08             	mov    0x8(%ebp),%edx
     7b4:	8b 4d 08             	mov    0x8(%ebp),%ecx
     7b7:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     7bb:	86 02                	xchg   %al,(%edx)
     7bd:	88 45 fc             	mov    %al,-0x4(%ebp)
     7c0:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     7c4:	c9                   	leave  
     7c5:	c3                   	ret    

000007c6 <ck_pr_md_load_ptr>:
					: "m"  (*(const C *)target)	\
					: "memory");			\
		return (r);						\
	}

CK_PR_LOAD(ptr, void, void *, char, "movl")
     7c6:	55                   	push   %ebp
     7c7:	89 e5                	mov    %esp,%ebp
     7c9:	83 ec 10             	sub    $0x10,%esp
     7cc:	8b 45 08             	mov    0x8(%ebp),%eax
     7cf:	8b 00                	mov    (%eax),%eax
     7d1:	89 45 fc             	mov    %eax,-0x4(%ebp)
     7d4:	8b 45 fc             	mov    -0x4(%ebp),%eax
     7d7:	c9                   	leave  
     7d8:	c3                   	ret    

000007d9 <ck_pr_md_load_char>:

#define CK_PR_LOAD_S(S, T, I) CK_PR_LOAD(S, T, T, T, I)

CK_PR_LOAD_S(char, char, "movb")
     7d9:	55                   	push   %ebp
     7da:	89 e5                	mov    %esp,%ebp
     7dc:	83 ec 10             	sub    $0x10,%esp
     7df:	8b 45 08             	mov    0x8(%ebp),%eax
     7e2:	8a 00                	mov    (%eax),%al
     7e4:	88 45 ff             	mov    %al,-0x1(%ebp)
     7e7:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
     7eb:	c9                   	leave  
     7ec:	c3                   	ret    

000007ed <ck_pr_md_load_uint>:
CK_PR_LOAD_S(uint, unsigned int, "movl")
     7ed:	55                   	push   %ebp
     7ee:	89 e5                	mov    %esp,%ebp
     7f0:	83 ec 10             	sub    $0x10,%esp
     7f3:	8b 45 08             	mov    0x8(%ebp),%eax
     7f6:	8b 00                	mov    (%eax),%eax
     7f8:	89 45 fc             	mov    %eax,-0x4(%ebp)
     7fb:	8b 45 fc             	mov    -0x4(%ebp),%eax
     7fe:	c9                   	leave  
     7ff:	c3                   	ret    

00000800 <ck_pr_md_load_int>:
CK_PR_LOAD_S(int, int, "movl")
     800:	55                   	push   %ebp
     801:	89 e5                	mov    %esp,%ebp
     803:	83 ec 10             	sub    $0x10,%esp
     806:	8b 45 08             	mov    0x8(%ebp),%eax
     809:	8b 00                	mov    (%eax),%eax
     80b:	89 45 fc             	mov    %eax,-0x4(%ebp)
     80e:	8b 45 fc             	mov    -0x4(%ebp),%eax
     811:	c9                   	leave  
     812:	c3                   	ret    

00000813 <ck_pr_md_load_32>:
CK_PR_LOAD_S(32, uint32_t, "movl")
     813:	55                   	push   %ebp
     814:	89 e5                	mov    %esp,%ebp
     816:	83 ec 10             	sub    $0x10,%esp
     819:	8b 45 08             	mov    0x8(%ebp),%eax
     81c:	8b 00                	mov    (%eax),%eax
     81e:	89 45 fc             	mov    %eax,-0x4(%ebp)
     821:	8b 45 fc             	mov    -0x4(%ebp),%eax
     824:	c9                   	leave  
     825:	c3                   	ret    

00000826 <ck_pr_md_load_16>:
CK_PR_LOAD_S(16, uint16_t, "movw")
     826:	55                   	push   %ebp
     827:	89 e5                	mov    %esp,%ebp
     829:	83 ec 10             	sub    $0x10,%esp
     82c:	8b 45 08             	mov    0x8(%ebp),%eax
     82f:	66 8b 00             	mov    (%eax),%ax
     832:	66 89 45 fe          	mov    %ax,-0x2(%ebp)
     836:	0f b7 45 fe          	movzwl -0x2(%ebp),%eax
     83a:	c9                   	leave  
     83b:	c3                   	ret    

0000083c <ck_pr_md_load_8>:
CK_PR_LOAD_S(8,  uint8_t,  "movb")
     83c:	55                   	push   %ebp
     83d:	89 e5                	mov    %esp,%ebp
     83f:	83 ec 10             	sub    $0x10,%esp
     842:	8b 45 08             	mov    0x8(%ebp),%eax
     845:	8a 00                	mov    (%eax),%al
     847:	88 45 ff             	mov    %al,-0x1(%ebp)
     84a:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
     84e:	c9                   	leave  
     84f:	c3                   	ret    

00000850 <ck_pr_md_store_ptr>:
					: CK_CC_IMM "q" (v)	\
					: "memory");		\
		return;						\
	}

CK_PR_STORE(ptr, void, const void *, char, "movl")
     850:	55                   	push   %ebp
     851:	89 e5                	mov    %esp,%ebp
     853:	8b 45 08             	mov    0x8(%ebp),%eax
     856:	8b 55 0c             	mov    0xc(%ebp),%edx
     859:	89 10                	mov    %edx,(%eax)
     85b:	90                   	nop
     85c:	5d                   	pop    %ebp
     85d:	c3                   	ret    

0000085e <ck_pr_md_store_char>:

#define CK_PR_STORE_S(S, T, I) CK_PR_STORE(S, T, T, T, I)

CK_PR_STORE_S(char, char, "movb")
     85e:	55                   	push   %ebp
     85f:	89 e5                	mov    %esp,%ebp
     861:	83 ec 04             	sub    $0x4,%esp
     864:	8b 45 0c             	mov    0xc(%ebp),%eax
     867:	88 45 fc             	mov    %al,-0x4(%ebp)
     86a:	8b 45 08             	mov    0x8(%ebp),%eax
     86d:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     871:	88 10                	mov    %dl,(%eax)
     873:	90                   	nop
     874:	c9                   	leave  
     875:	c3                   	ret    

00000876 <ck_pr_md_store_uint>:
CK_PR_STORE_S(uint, unsigned int, "movl")
     876:	55                   	push   %ebp
     877:	89 e5                	mov    %esp,%ebp
     879:	8b 45 08             	mov    0x8(%ebp),%eax
     87c:	8b 55 0c             	mov    0xc(%ebp),%edx
     87f:	89 10                	mov    %edx,(%eax)
     881:	90                   	nop
     882:	5d                   	pop    %ebp
     883:	c3                   	ret    

00000884 <ck_pr_md_store_int>:
CK_PR_STORE_S(int, int, "movl")
     884:	55                   	push   %ebp
     885:	89 e5                	mov    %esp,%ebp
     887:	8b 45 08             	mov    0x8(%ebp),%eax
     88a:	8b 55 0c             	mov    0xc(%ebp),%edx
     88d:	89 10                	mov    %edx,(%eax)
     88f:	90                   	nop
     890:	5d                   	pop    %ebp
     891:	c3                   	ret    

00000892 <ck_pr_md_store_32>:
CK_PR_STORE_S(32, uint32_t, "movl")
     892:	55                   	push   %ebp
     893:	89 e5                	mov    %esp,%ebp
     895:	8b 45 08             	mov    0x8(%ebp),%eax
     898:	8b 55 0c             	mov    0xc(%ebp),%edx
     89b:	89 10                	mov    %edx,(%eax)
     89d:	90                   	nop
     89e:	5d                   	pop    %ebp
     89f:	c3                   	ret    

000008a0 <ck_pr_md_store_16>:
CK_PR_STORE_S(16, uint16_t, "movw")
     8a0:	55                   	push   %ebp
     8a1:	89 e5                	mov    %esp,%ebp
     8a3:	83 ec 04             	sub    $0x4,%esp
     8a6:	8b 45 0c             	mov    0xc(%ebp),%eax
     8a9:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     8ad:	8b 45 08             	mov    0x8(%ebp),%eax
     8b0:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
     8b4:	66 89 10             	mov    %dx,(%eax)
     8b7:	90                   	nop
     8b8:	c9                   	leave  
     8b9:	c3                   	ret    

000008ba <ck_pr_md_store_8>:
CK_PR_STORE_S(8,  uint8_t, "movb")
     8ba:	55                   	push   %ebp
     8bb:	89 e5                	mov    %esp,%ebp
     8bd:	83 ec 04             	sub    $0x4,%esp
     8c0:	8b 45 0c             	mov    0xc(%ebp),%eax
     8c3:	88 45 fc             	mov    %al,-0x4(%ebp)
     8c6:	8b 45 08             	mov    0x8(%ebp),%eax
     8c9:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     8cd:	88 10                	mov    %dl,(%eax)
     8cf:	90                   	nop
     8d0:	c9                   	leave  
     8d1:	c3                   	ret    

000008d2 <ck_pr_faa_ptr>:
					:				\
					: "memory", "cc");		\
		return (d);						\
	}

CK_PR_FAA(ptr, void, uintptr_t, char, "xaddl")
     8d2:	55                   	push   %ebp
     8d3:	89 e5                	mov    %esp,%ebp
     8d5:	8b 55 08             	mov    0x8(%ebp),%edx
     8d8:	8b 4d 08             	mov    0x8(%ebp),%ecx
     8db:	8b 45 0c             	mov    0xc(%ebp),%eax
     8de:	f0 0f c1 02          	lock xadd %eax,(%edx)
     8e2:	89 45 0c             	mov    %eax,0xc(%ebp)
     8e5:	8b 45 0c             	mov    0xc(%ebp),%eax
     8e8:	5d                   	pop    %ebp
     8e9:	c3                   	ret    

000008ea <ck_pr_faa_char>:

#define CK_PR_FAA_S(S, T, I) CK_PR_FAA(S, T, T, T, I)

CK_PR_FAA_S(char, char, "xaddb")
     8ea:	55                   	push   %ebp
     8eb:	89 e5                	mov    %esp,%ebp
     8ed:	83 ec 04             	sub    $0x4,%esp
     8f0:	8b 45 0c             	mov    0xc(%ebp),%eax
     8f3:	88 45 fc             	mov    %al,-0x4(%ebp)
     8f6:	8b 55 08             	mov    0x8(%ebp),%edx
     8f9:	8b 4d 08             	mov    0x8(%ebp),%ecx
     8fc:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     900:	f0 0f c0 02          	lock xadd %al,(%edx)
     904:	88 45 fc             	mov    %al,-0x4(%ebp)
     907:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     90b:	c9                   	leave  
     90c:	c3                   	ret    

0000090d <ck_pr_faa_uint>:
CK_PR_FAA_S(uint, unsigned int, "xaddl")
     90d:	55                   	push   %ebp
     90e:	89 e5                	mov    %esp,%ebp
     910:	8b 55 08             	mov    0x8(%ebp),%edx
     913:	8b 4d 08             	mov    0x8(%ebp),%ecx
     916:	8b 45 0c             	mov    0xc(%ebp),%eax
     919:	f0 0f c1 02          	lock xadd %eax,(%edx)
     91d:	89 45 0c             	mov    %eax,0xc(%ebp)
     920:	8b 45 0c             	mov    0xc(%ebp),%eax
     923:	5d                   	pop    %ebp
     924:	c3                   	ret    

00000925 <ck_pr_faa_int>:
CK_PR_FAA_S(int, int, "xaddl")
     925:	55                   	push   %ebp
     926:	89 e5                	mov    %esp,%ebp
     928:	8b 55 08             	mov    0x8(%ebp),%edx
     92b:	8b 4d 08             	mov    0x8(%ebp),%ecx
     92e:	8b 45 0c             	mov    0xc(%ebp),%eax
     931:	f0 0f c1 02          	lock xadd %eax,(%edx)
     935:	89 45 0c             	mov    %eax,0xc(%ebp)
     938:	8b 45 0c             	mov    0xc(%ebp),%eax
     93b:	5d                   	pop    %ebp
     93c:	c3                   	ret    

0000093d <ck_pr_faa_32>:
CK_PR_FAA_S(32, uint32_t, "xaddl")
     93d:	55                   	push   %ebp
     93e:	89 e5                	mov    %esp,%ebp
     940:	8b 55 08             	mov    0x8(%ebp),%edx
     943:	8b 4d 08             	mov    0x8(%ebp),%ecx
     946:	8b 45 0c             	mov    0xc(%ebp),%eax
     949:	f0 0f c1 02          	lock xadd %eax,(%edx)
     94d:	89 45 0c             	mov    %eax,0xc(%ebp)
     950:	8b 45 0c             	mov    0xc(%ebp),%eax
     953:	5d                   	pop    %ebp
     954:	c3                   	ret    

00000955 <ck_pr_faa_16>:
CK_PR_FAA_S(16, uint16_t, "xaddw")
     955:	55                   	push   %ebp
     956:	89 e5                	mov    %esp,%ebp
     958:	83 ec 04             	sub    $0x4,%esp
     95b:	8b 45 0c             	mov    0xc(%ebp),%eax
     95e:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     962:	8b 55 08             	mov    0x8(%ebp),%edx
     965:	8b 4d 08             	mov    0x8(%ebp),%ecx
     968:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
     96c:	66 f0 0f c1 02       	lock xadd %ax,(%edx)
     971:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     975:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
     979:	c9                   	leave  
     97a:	c3                   	ret    

0000097b <ck_pr_faa_8>:
CK_PR_FAA_S(8,  uint8_t,  "xaddb")
     97b:	55                   	push   %ebp
     97c:	89 e5                	mov    %esp,%ebp
     97e:	83 ec 04             	sub    $0x4,%esp
     981:	8b 45 0c             	mov    0xc(%ebp),%eax
     984:	88 45 fc             	mov    %al,-0x4(%ebp)
     987:	8b 55 08             	mov    0x8(%ebp),%edx
     98a:	8b 4d 08             	mov    0x8(%ebp),%ecx
     98d:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     991:	f0 0f c0 02          	lock xadd %al,(%edx)
     995:	88 45 fc             	mov    %al,-0x4(%ebp)
     998:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
     99c:	c9                   	leave  
     99d:	c3                   	ret    

0000099e <ck_pr_inc_ptr>:
	CK_PR_UNARY_S(K, uint, unsigned int, #K "l")	\
	CK_PR_UNARY_S(K, 32, uint32_t, #K "l")		\
	CK_PR_UNARY_S(K, 16, uint16_t, #K "w")		\
	CK_PR_UNARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(inc)
     99e:	55                   	push   %ebp
     99f:	89 e5                	mov    %esp,%ebp
     9a1:	8b 45 08             	mov    0x8(%ebp),%eax
     9a4:	8b 55 08             	mov    0x8(%ebp),%edx
     9a7:	f0 ff 00             	lock incl (%eax)
     9aa:	90                   	nop
     9ab:	5d                   	pop    %ebp
     9ac:	c3                   	ret    

000009ad <ck_pr_inc_ptr_zero>:
     9ad:	55                   	push   %ebp
     9ae:	89 e5                	mov    %esp,%ebp
     9b0:	8b 45 08             	mov    0x8(%ebp),%eax
     9b3:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     9b6:	8b 55 08             	mov    0x8(%ebp),%edx
     9b9:	f0 ff 00             	lock incl (%eax)
     9bc:	0f 94 01             	sete   (%ecx)
     9bf:	90                   	nop
     9c0:	5d                   	pop    %ebp
     9c1:	c3                   	ret    

000009c2 <ck_pr_inc_char>:
     9c2:	55                   	push   %ebp
     9c3:	89 e5                	mov    %esp,%ebp
     9c5:	8b 45 08             	mov    0x8(%ebp),%eax
     9c8:	8b 55 08             	mov    0x8(%ebp),%edx
     9cb:	f0 fe 00             	lock incb (%eax)
     9ce:	90                   	nop
     9cf:	5d                   	pop    %ebp
     9d0:	c3                   	ret    

000009d1 <ck_pr_inc_char_zero>:
     9d1:	55                   	push   %ebp
     9d2:	89 e5                	mov    %esp,%ebp
     9d4:	8b 45 08             	mov    0x8(%ebp),%eax
     9d7:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     9da:	8b 55 08             	mov    0x8(%ebp),%edx
     9dd:	f0 fe 00             	lock incb (%eax)
     9e0:	0f 94 01             	sete   (%ecx)
     9e3:	90                   	nop
     9e4:	5d                   	pop    %ebp
     9e5:	c3                   	ret    

000009e6 <ck_pr_inc_int>:
     9e6:	55                   	push   %ebp
     9e7:	89 e5                	mov    %esp,%ebp
     9e9:	8b 45 08             	mov    0x8(%ebp),%eax
     9ec:	8b 55 08             	mov    0x8(%ebp),%edx
     9ef:	f0 ff 00             	lock incl (%eax)
     9f2:	90                   	nop
     9f3:	5d                   	pop    %ebp
     9f4:	c3                   	ret    

000009f5 <ck_pr_inc_int_zero>:
     9f5:	55                   	push   %ebp
     9f6:	89 e5                	mov    %esp,%ebp
     9f8:	8b 45 08             	mov    0x8(%ebp),%eax
     9fb:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     9fe:	8b 55 08             	mov    0x8(%ebp),%edx
     a01:	f0 ff 00             	lock incl (%eax)
     a04:	0f 94 01             	sete   (%ecx)
     a07:	90                   	nop
     a08:	5d                   	pop    %ebp
     a09:	c3                   	ret    

00000a0a <ck_pr_inc_uint>:
     a0a:	55                   	push   %ebp
     a0b:	89 e5                	mov    %esp,%ebp
     a0d:	8b 45 08             	mov    0x8(%ebp),%eax
     a10:	8b 55 08             	mov    0x8(%ebp),%edx
     a13:	f0 ff 00             	lock incl (%eax)
     a16:	90                   	nop
     a17:	5d                   	pop    %ebp
     a18:	c3                   	ret    

00000a19 <ck_pr_inc_uint_zero>:
     a19:	55                   	push   %ebp
     a1a:	89 e5                	mov    %esp,%ebp
     a1c:	8b 45 08             	mov    0x8(%ebp),%eax
     a1f:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     a22:	8b 55 08             	mov    0x8(%ebp),%edx
     a25:	f0 ff 00             	lock incl (%eax)
     a28:	0f 94 01             	sete   (%ecx)
     a2b:	90                   	nop
     a2c:	5d                   	pop    %ebp
     a2d:	c3                   	ret    

00000a2e <ck_pr_inc_32>:
     a2e:	55                   	push   %ebp
     a2f:	89 e5                	mov    %esp,%ebp
     a31:	8b 45 08             	mov    0x8(%ebp),%eax
     a34:	8b 55 08             	mov    0x8(%ebp),%edx
     a37:	f0 ff 00             	lock incl (%eax)
     a3a:	90                   	nop
     a3b:	5d                   	pop    %ebp
     a3c:	c3                   	ret    

00000a3d <ck_pr_inc_32_zero>:
     a3d:	55                   	push   %ebp
     a3e:	89 e5                	mov    %esp,%ebp
     a40:	8b 45 08             	mov    0x8(%ebp),%eax
     a43:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     a46:	8b 55 08             	mov    0x8(%ebp),%edx
     a49:	f0 ff 00             	lock incl (%eax)
     a4c:	0f 94 01             	sete   (%ecx)
     a4f:	90                   	nop
     a50:	5d                   	pop    %ebp
     a51:	c3                   	ret    

00000a52 <ck_pr_inc_16>:
     a52:	55                   	push   %ebp
     a53:	89 e5                	mov    %esp,%ebp
     a55:	8b 45 08             	mov    0x8(%ebp),%eax
     a58:	8b 55 08             	mov    0x8(%ebp),%edx
     a5b:	66 f0 ff 00          	lock incw (%eax)
     a5f:	90                   	nop
     a60:	5d                   	pop    %ebp
     a61:	c3                   	ret    

00000a62 <ck_pr_inc_16_zero>:
     a62:	55                   	push   %ebp
     a63:	89 e5                	mov    %esp,%ebp
     a65:	8b 45 08             	mov    0x8(%ebp),%eax
     a68:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     a6b:	8b 55 08             	mov    0x8(%ebp),%edx
     a6e:	66 f0 ff 00          	lock incw (%eax)
     a72:	0f 94 01             	sete   (%ecx)
     a75:	90                   	nop
     a76:	5d                   	pop    %ebp
     a77:	c3                   	ret    

00000a78 <ck_pr_inc_8>:
     a78:	55                   	push   %ebp
     a79:	89 e5                	mov    %esp,%ebp
     a7b:	8b 45 08             	mov    0x8(%ebp),%eax
     a7e:	8b 55 08             	mov    0x8(%ebp),%edx
     a81:	f0 fe 00             	lock incb (%eax)
     a84:	90                   	nop
     a85:	5d                   	pop    %ebp
     a86:	c3                   	ret    

00000a87 <ck_pr_inc_8_zero>:
     a87:	55                   	push   %ebp
     a88:	89 e5                	mov    %esp,%ebp
     a8a:	8b 45 08             	mov    0x8(%ebp),%eax
     a8d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     a90:	8b 55 08             	mov    0x8(%ebp),%edx
     a93:	f0 fe 00             	lock incb (%eax)
     a96:	0f 94 01             	sete   (%ecx)
     a99:	90                   	nop
     a9a:	5d                   	pop    %ebp
     a9b:	c3                   	ret    

00000a9c <ck_pr_dec_ptr>:
CK_PR_GENERATE(dec)
     a9c:	55                   	push   %ebp
     a9d:	89 e5                	mov    %esp,%ebp
     a9f:	8b 45 08             	mov    0x8(%ebp),%eax
     aa2:	8b 55 08             	mov    0x8(%ebp),%edx
     aa5:	f0 ff 08             	lock decl (%eax)
     aa8:	90                   	nop
     aa9:	5d                   	pop    %ebp
     aaa:	c3                   	ret    

00000aab <ck_pr_dec_ptr_zero>:
     aab:	55                   	push   %ebp
     aac:	89 e5                	mov    %esp,%ebp
     aae:	8b 45 08             	mov    0x8(%ebp),%eax
     ab1:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     ab4:	8b 55 08             	mov    0x8(%ebp),%edx
     ab7:	f0 ff 08             	lock decl (%eax)
     aba:	0f 94 01             	sete   (%ecx)
     abd:	90                   	nop
     abe:	5d                   	pop    %ebp
     abf:	c3                   	ret    

00000ac0 <ck_pr_dec_char>:
     ac0:	55                   	push   %ebp
     ac1:	89 e5                	mov    %esp,%ebp
     ac3:	8b 45 08             	mov    0x8(%ebp),%eax
     ac6:	8b 55 08             	mov    0x8(%ebp),%edx
     ac9:	f0 fe 08             	lock decb (%eax)
     acc:	90                   	nop
     acd:	5d                   	pop    %ebp
     ace:	c3                   	ret    

00000acf <ck_pr_dec_char_zero>:
     acf:	55                   	push   %ebp
     ad0:	89 e5                	mov    %esp,%ebp
     ad2:	8b 45 08             	mov    0x8(%ebp),%eax
     ad5:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     ad8:	8b 55 08             	mov    0x8(%ebp),%edx
     adb:	f0 fe 08             	lock decb (%eax)
     ade:	0f 94 01             	sete   (%ecx)
     ae1:	90                   	nop
     ae2:	5d                   	pop    %ebp
     ae3:	c3                   	ret    

00000ae4 <ck_pr_dec_int>:
     ae4:	55                   	push   %ebp
     ae5:	89 e5                	mov    %esp,%ebp
     ae7:	8b 45 08             	mov    0x8(%ebp),%eax
     aea:	8b 55 08             	mov    0x8(%ebp),%edx
     aed:	f0 ff 08             	lock decl (%eax)
     af0:	90                   	nop
     af1:	5d                   	pop    %ebp
     af2:	c3                   	ret    

00000af3 <ck_pr_dec_int_zero>:
     af3:	55                   	push   %ebp
     af4:	89 e5                	mov    %esp,%ebp
     af6:	8b 45 08             	mov    0x8(%ebp),%eax
     af9:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     afc:	8b 55 08             	mov    0x8(%ebp),%edx
     aff:	f0 ff 08             	lock decl (%eax)
     b02:	0f 94 01             	sete   (%ecx)
     b05:	90                   	nop
     b06:	5d                   	pop    %ebp
     b07:	c3                   	ret    

00000b08 <ck_pr_dec_uint>:
     b08:	55                   	push   %ebp
     b09:	89 e5                	mov    %esp,%ebp
     b0b:	8b 45 08             	mov    0x8(%ebp),%eax
     b0e:	8b 55 08             	mov    0x8(%ebp),%edx
     b11:	f0 ff 08             	lock decl (%eax)
     b14:	90                   	nop
     b15:	5d                   	pop    %ebp
     b16:	c3                   	ret    

00000b17 <ck_pr_dec_uint_zero>:
     b17:	55                   	push   %ebp
     b18:	89 e5                	mov    %esp,%ebp
     b1a:	8b 45 08             	mov    0x8(%ebp),%eax
     b1d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     b20:	8b 55 08             	mov    0x8(%ebp),%edx
     b23:	f0 ff 08             	lock decl (%eax)
     b26:	0f 94 01             	sete   (%ecx)
     b29:	90                   	nop
     b2a:	5d                   	pop    %ebp
     b2b:	c3                   	ret    

00000b2c <ck_pr_dec_32>:
     b2c:	55                   	push   %ebp
     b2d:	89 e5                	mov    %esp,%ebp
     b2f:	8b 45 08             	mov    0x8(%ebp),%eax
     b32:	8b 55 08             	mov    0x8(%ebp),%edx
     b35:	f0 ff 08             	lock decl (%eax)
     b38:	90                   	nop
     b39:	5d                   	pop    %ebp
     b3a:	c3                   	ret    

00000b3b <ck_pr_dec_32_zero>:
     b3b:	55                   	push   %ebp
     b3c:	89 e5                	mov    %esp,%ebp
     b3e:	8b 45 08             	mov    0x8(%ebp),%eax
     b41:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     b44:	8b 55 08             	mov    0x8(%ebp),%edx
     b47:	f0 ff 08             	lock decl (%eax)
     b4a:	0f 94 01             	sete   (%ecx)
     b4d:	90                   	nop
     b4e:	5d                   	pop    %ebp
     b4f:	c3                   	ret    

00000b50 <ck_pr_dec_16>:
     b50:	55                   	push   %ebp
     b51:	89 e5                	mov    %esp,%ebp
     b53:	8b 45 08             	mov    0x8(%ebp),%eax
     b56:	8b 55 08             	mov    0x8(%ebp),%edx
     b59:	66 f0 ff 08          	lock decw (%eax)
     b5d:	90                   	nop
     b5e:	5d                   	pop    %ebp
     b5f:	c3                   	ret    

00000b60 <ck_pr_dec_16_zero>:
     b60:	55                   	push   %ebp
     b61:	89 e5                	mov    %esp,%ebp
     b63:	8b 45 08             	mov    0x8(%ebp),%eax
     b66:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     b69:	8b 55 08             	mov    0x8(%ebp),%edx
     b6c:	66 f0 ff 08          	lock decw (%eax)
     b70:	0f 94 01             	sete   (%ecx)
     b73:	90                   	nop
     b74:	5d                   	pop    %ebp
     b75:	c3                   	ret    

00000b76 <ck_pr_dec_8>:
     b76:	55                   	push   %ebp
     b77:	89 e5                	mov    %esp,%ebp
     b79:	8b 45 08             	mov    0x8(%ebp),%eax
     b7c:	8b 55 08             	mov    0x8(%ebp),%edx
     b7f:	f0 fe 08             	lock decb (%eax)
     b82:	90                   	nop
     b83:	5d                   	pop    %ebp
     b84:	c3                   	ret    

00000b85 <ck_pr_dec_8_zero>:
     b85:	55                   	push   %ebp
     b86:	89 e5                	mov    %esp,%ebp
     b88:	8b 45 08             	mov    0x8(%ebp),%eax
     b8b:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     b8e:	8b 55 08             	mov    0x8(%ebp),%edx
     b91:	f0 fe 08             	lock decb (%eax)
     b94:	0f 94 01             	sete   (%ecx)
     b97:	90                   	nop
     b98:	5d                   	pop    %ebp
     b99:	c3                   	ret    

00000b9a <ck_pr_neg_ptr>:
CK_PR_GENERATE(neg)
     b9a:	55                   	push   %ebp
     b9b:	89 e5                	mov    %esp,%ebp
     b9d:	8b 45 08             	mov    0x8(%ebp),%eax
     ba0:	8b 55 08             	mov    0x8(%ebp),%edx
     ba3:	f0 f7 18             	lock negl (%eax)
     ba6:	90                   	nop
     ba7:	5d                   	pop    %ebp
     ba8:	c3                   	ret    

00000ba9 <ck_pr_neg_ptr_zero>:
     ba9:	55                   	push   %ebp
     baa:	89 e5                	mov    %esp,%ebp
     bac:	8b 45 08             	mov    0x8(%ebp),%eax
     baf:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     bb2:	8b 55 08             	mov    0x8(%ebp),%edx
     bb5:	f0 f7 18             	lock negl (%eax)
     bb8:	0f 94 01             	sete   (%ecx)
     bbb:	90                   	nop
     bbc:	5d                   	pop    %ebp
     bbd:	c3                   	ret    

00000bbe <ck_pr_neg_char>:
     bbe:	55                   	push   %ebp
     bbf:	89 e5                	mov    %esp,%ebp
     bc1:	8b 45 08             	mov    0x8(%ebp),%eax
     bc4:	8b 55 08             	mov    0x8(%ebp),%edx
     bc7:	f0 f6 18             	lock negb (%eax)
     bca:	90                   	nop
     bcb:	5d                   	pop    %ebp
     bcc:	c3                   	ret    

00000bcd <ck_pr_neg_char_zero>:
     bcd:	55                   	push   %ebp
     bce:	89 e5                	mov    %esp,%ebp
     bd0:	8b 45 08             	mov    0x8(%ebp),%eax
     bd3:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     bd6:	8b 55 08             	mov    0x8(%ebp),%edx
     bd9:	f0 f6 18             	lock negb (%eax)
     bdc:	0f 94 01             	sete   (%ecx)
     bdf:	90                   	nop
     be0:	5d                   	pop    %ebp
     be1:	c3                   	ret    

00000be2 <ck_pr_neg_int>:
     be2:	55                   	push   %ebp
     be3:	89 e5                	mov    %esp,%ebp
     be5:	8b 45 08             	mov    0x8(%ebp),%eax
     be8:	8b 55 08             	mov    0x8(%ebp),%edx
     beb:	f0 f7 18             	lock negl (%eax)
     bee:	90                   	nop
     bef:	5d                   	pop    %ebp
     bf0:	c3                   	ret    

00000bf1 <ck_pr_neg_int_zero>:
     bf1:	55                   	push   %ebp
     bf2:	89 e5                	mov    %esp,%ebp
     bf4:	8b 45 08             	mov    0x8(%ebp),%eax
     bf7:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     bfa:	8b 55 08             	mov    0x8(%ebp),%edx
     bfd:	f0 f7 18             	lock negl (%eax)
     c00:	0f 94 01             	sete   (%ecx)
     c03:	90                   	nop
     c04:	5d                   	pop    %ebp
     c05:	c3                   	ret    

00000c06 <ck_pr_neg_uint>:
     c06:	55                   	push   %ebp
     c07:	89 e5                	mov    %esp,%ebp
     c09:	8b 45 08             	mov    0x8(%ebp),%eax
     c0c:	8b 55 08             	mov    0x8(%ebp),%edx
     c0f:	f0 f7 18             	lock negl (%eax)
     c12:	90                   	nop
     c13:	5d                   	pop    %ebp
     c14:	c3                   	ret    

00000c15 <ck_pr_neg_uint_zero>:
     c15:	55                   	push   %ebp
     c16:	89 e5                	mov    %esp,%ebp
     c18:	8b 45 08             	mov    0x8(%ebp),%eax
     c1b:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     c1e:	8b 55 08             	mov    0x8(%ebp),%edx
     c21:	f0 f7 18             	lock negl (%eax)
     c24:	0f 94 01             	sete   (%ecx)
     c27:	90                   	nop
     c28:	5d                   	pop    %ebp
     c29:	c3                   	ret    

00000c2a <ck_pr_neg_32>:
     c2a:	55                   	push   %ebp
     c2b:	89 e5                	mov    %esp,%ebp
     c2d:	8b 45 08             	mov    0x8(%ebp),%eax
     c30:	8b 55 08             	mov    0x8(%ebp),%edx
     c33:	f0 f7 18             	lock negl (%eax)
     c36:	90                   	nop
     c37:	5d                   	pop    %ebp
     c38:	c3                   	ret    

00000c39 <ck_pr_neg_32_zero>:
     c39:	55                   	push   %ebp
     c3a:	89 e5                	mov    %esp,%ebp
     c3c:	8b 45 08             	mov    0x8(%ebp),%eax
     c3f:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     c42:	8b 55 08             	mov    0x8(%ebp),%edx
     c45:	f0 f7 18             	lock negl (%eax)
     c48:	0f 94 01             	sete   (%ecx)
     c4b:	90                   	nop
     c4c:	5d                   	pop    %ebp
     c4d:	c3                   	ret    

00000c4e <ck_pr_neg_16>:
     c4e:	55                   	push   %ebp
     c4f:	89 e5                	mov    %esp,%ebp
     c51:	8b 45 08             	mov    0x8(%ebp),%eax
     c54:	8b 55 08             	mov    0x8(%ebp),%edx
     c57:	66 f0 f7 18          	lock negw (%eax)
     c5b:	90                   	nop
     c5c:	5d                   	pop    %ebp
     c5d:	c3                   	ret    

00000c5e <ck_pr_neg_16_zero>:
     c5e:	55                   	push   %ebp
     c5f:	89 e5                	mov    %esp,%ebp
     c61:	8b 45 08             	mov    0x8(%ebp),%eax
     c64:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     c67:	8b 55 08             	mov    0x8(%ebp),%edx
     c6a:	66 f0 f7 18          	lock negw (%eax)
     c6e:	0f 94 01             	sete   (%ecx)
     c71:	90                   	nop
     c72:	5d                   	pop    %ebp
     c73:	c3                   	ret    

00000c74 <ck_pr_neg_8>:
     c74:	55                   	push   %ebp
     c75:	89 e5                	mov    %esp,%ebp
     c77:	8b 45 08             	mov    0x8(%ebp),%eax
     c7a:	8b 55 08             	mov    0x8(%ebp),%edx
     c7d:	f0 f6 18             	lock negb (%eax)
     c80:	90                   	nop
     c81:	5d                   	pop    %ebp
     c82:	c3                   	ret    

00000c83 <ck_pr_neg_8_zero>:
     c83:	55                   	push   %ebp
     c84:	89 e5                	mov    %esp,%ebp
     c86:	8b 45 08             	mov    0x8(%ebp),%eax
     c89:	8b 4d 0c             	mov    0xc(%ebp),%ecx
     c8c:	8b 55 08             	mov    0x8(%ebp),%edx
     c8f:	f0 f6 18             	lock negb (%eax)
     c92:	0f 94 01             	sete   (%ecx)
     c95:	90                   	nop
     c96:	5d                   	pop    %ebp
     c97:	c3                   	ret    

00000c98 <ck_pr_not_ptr>:

/* not does not affect condition flags. */
#undef CK_PR_UNARY_V
#define CK_PR_UNARY_V(a, b, c, d, e)
CK_PR_GENERATE(not)
     c98:	55                   	push   %ebp
     c99:	89 e5                	mov    %esp,%ebp
     c9b:	8b 45 08             	mov    0x8(%ebp),%eax
     c9e:	8b 55 08             	mov    0x8(%ebp),%edx
     ca1:	f0 f7 10             	lock notl (%eax)
     ca4:	90                   	nop
     ca5:	5d                   	pop    %ebp
     ca6:	c3                   	ret    

00000ca7 <ck_pr_not_char>:
     ca7:	55                   	push   %ebp
     ca8:	89 e5                	mov    %esp,%ebp
     caa:	8b 45 08             	mov    0x8(%ebp),%eax
     cad:	8b 55 08             	mov    0x8(%ebp),%edx
     cb0:	f0 f6 10             	lock notb (%eax)
     cb3:	90                   	nop
     cb4:	5d                   	pop    %ebp
     cb5:	c3                   	ret    

00000cb6 <ck_pr_not_int>:
     cb6:	55                   	push   %ebp
     cb7:	89 e5                	mov    %esp,%ebp
     cb9:	8b 45 08             	mov    0x8(%ebp),%eax
     cbc:	8b 55 08             	mov    0x8(%ebp),%edx
     cbf:	f0 f7 10             	lock notl (%eax)
     cc2:	90                   	nop
     cc3:	5d                   	pop    %ebp
     cc4:	c3                   	ret    

00000cc5 <ck_pr_not_uint>:
     cc5:	55                   	push   %ebp
     cc6:	89 e5                	mov    %esp,%ebp
     cc8:	8b 45 08             	mov    0x8(%ebp),%eax
     ccb:	8b 55 08             	mov    0x8(%ebp),%edx
     cce:	f0 f7 10             	lock notl (%eax)
     cd1:	90                   	nop
     cd2:	5d                   	pop    %ebp
     cd3:	c3                   	ret    

00000cd4 <ck_pr_not_32>:
     cd4:	55                   	push   %ebp
     cd5:	89 e5                	mov    %esp,%ebp
     cd7:	8b 45 08             	mov    0x8(%ebp),%eax
     cda:	8b 55 08             	mov    0x8(%ebp),%edx
     cdd:	f0 f7 10             	lock notl (%eax)
     ce0:	90                   	nop
     ce1:	5d                   	pop    %ebp
     ce2:	c3                   	ret    

00000ce3 <ck_pr_not_16>:
     ce3:	55                   	push   %ebp
     ce4:	89 e5                	mov    %esp,%ebp
     ce6:	8b 45 08             	mov    0x8(%ebp),%eax
     ce9:	8b 55 08             	mov    0x8(%ebp),%edx
     cec:	66 f0 f7 10          	lock notw (%eax)
     cf0:	90                   	nop
     cf1:	5d                   	pop    %ebp
     cf2:	c3                   	ret    

00000cf3 <ck_pr_not_8>:
     cf3:	55                   	push   %ebp
     cf4:	89 e5                	mov    %esp,%ebp
     cf6:	8b 45 08             	mov    0x8(%ebp),%eax
     cf9:	8b 55 08             	mov    0x8(%ebp),%edx
     cfc:	f0 f6 10             	lock notb (%eax)
     cff:	90                   	nop
     d00:	5d                   	pop    %ebp
     d01:	c3                   	ret    

00000d02 <ck_pr_add_ptr>:
	CK_PR_BINARY_S(K, uint, unsigned int, #K "l")		\
	CK_PR_BINARY_S(K, 32, uint32_t, #K "l")			\
	CK_PR_BINARY_S(K, 16, uint16_t, #K "w")			\
	CK_PR_BINARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(add)
     d02:	55                   	push   %ebp
     d03:	89 e5                	mov    %esp,%ebp
     d05:	8b 45 08             	mov    0x8(%ebp),%eax
     d08:	8b 55 0c             	mov    0xc(%ebp),%edx
     d0b:	8b 4d 08             	mov    0x8(%ebp),%ecx
     d0e:	f0 01 10             	lock add %edx,(%eax)
     d11:	90                   	nop
     d12:	5d                   	pop    %ebp
     d13:	c3                   	ret    

00000d14 <ck_pr_add_char>:
     d14:	55                   	push   %ebp
     d15:	89 e5                	mov    %esp,%ebp
     d17:	83 ec 04             	sub    $0x4,%esp
     d1a:	8b 45 0c             	mov    0xc(%ebp),%eax
     d1d:	88 45 fc             	mov    %al,-0x4(%ebp)
     d20:	8b 45 08             	mov    0x8(%ebp),%eax
     d23:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     d27:	8b 4d 08             	mov    0x8(%ebp),%ecx
     d2a:	f0 00 10             	lock add %dl,(%eax)
     d2d:	90                   	nop
     d2e:	c9                   	leave  
     d2f:	c3                   	ret    

00000d30 <ck_pr_add_int>:
     d30:	55                   	push   %ebp
     d31:	89 e5                	mov    %esp,%ebp
     d33:	8b 45 08             	mov    0x8(%ebp),%eax
     d36:	8b 55 0c             	mov    0xc(%ebp),%edx
     d39:	8b 4d 08             	mov    0x8(%ebp),%ecx
     d3c:	f0 01 10             	lock add %edx,(%eax)
     d3f:	90                   	nop
     d40:	5d                   	pop    %ebp
     d41:	c3                   	ret    

00000d42 <ck_pr_add_uint>:
     d42:	55                   	push   %ebp
     d43:	89 e5                	mov    %esp,%ebp
     d45:	8b 45 08             	mov    0x8(%ebp),%eax
     d48:	8b 55 0c             	mov    0xc(%ebp),%edx
     d4b:	8b 4d 08             	mov    0x8(%ebp),%ecx
     d4e:	f0 01 10             	lock add %edx,(%eax)
     d51:	90                   	nop
     d52:	5d                   	pop    %ebp
     d53:	c3                   	ret    

00000d54 <ck_pr_add_32>:
     d54:	55                   	push   %ebp
     d55:	89 e5                	mov    %esp,%ebp
     d57:	8b 45 08             	mov    0x8(%ebp),%eax
     d5a:	8b 55 0c             	mov    0xc(%ebp),%edx
     d5d:	8b 4d 08             	mov    0x8(%ebp),%ecx
     d60:	f0 01 10             	lock add %edx,(%eax)
     d63:	90                   	nop
     d64:	5d                   	pop    %ebp
     d65:	c3                   	ret    

00000d66 <ck_pr_add_16>:
     d66:	55                   	push   %ebp
     d67:	89 e5                	mov    %esp,%ebp
     d69:	83 ec 04             	sub    $0x4,%esp
     d6c:	8b 45 0c             	mov    0xc(%ebp),%eax
     d6f:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     d73:	8b 45 08             	mov    0x8(%ebp),%eax
     d76:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
     d7a:	8b 4d 08             	mov    0x8(%ebp),%ecx
     d7d:	66 f0 01 10          	lock add %dx,(%eax)
     d81:	90                   	nop
     d82:	c9                   	leave  
     d83:	c3                   	ret    

00000d84 <ck_pr_add_8>:
     d84:	55                   	push   %ebp
     d85:	89 e5                	mov    %esp,%ebp
     d87:	83 ec 04             	sub    $0x4,%esp
     d8a:	8b 45 0c             	mov    0xc(%ebp),%eax
     d8d:	88 45 fc             	mov    %al,-0x4(%ebp)
     d90:	8b 45 08             	mov    0x8(%ebp),%eax
     d93:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     d97:	8b 4d 08             	mov    0x8(%ebp),%ecx
     d9a:	f0 00 10             	lock add %dl,(%eax)
     d9d:	90                   	nop
     d9e:	c9                   	leave  
     d9f:	c3                   	ret    

00000da0 <ck_pr_sub_ptr>:
CK_PR_GENERATE(sub)
     da0:	55                   	push   %ebp
     da1:	89 e5                	mov    %esp,%ebp
     da3:	8b 45 08             	mov    0x8(%ebp),%eax
     da6:	8b 55 0c             	mov    0xc(%ebp),%edx
     da9:	8b 4d 08             	mov    0x8(%ebp),%ecx
     dac:	f0 29 10             	lock sub %edx,(%eax)
     daf:	90                   	nop
     db0:	5d                   	pop    %ebp
     db1:	c3                   	ret    

00000db2 <ck_pr_sub_char>:
     db2:	55                   	push   %ebp
     db3:	89 e5                	mov    %esp,%ebp
     db5:	83 ec 04             	sub    $0x4,%esp
     db8:	8b 45 0c             	mov    0xc(%ebp),%eax
     dbb:	88 45 fc             	mov    %al,-0x4(%ebp)
     dbe:	8b 45 08             	mov    0x8(%ebp),%eax
     dc1:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     dc5:	8b 4d 08             	mov    0x8(%ebp),%ecx
     dc8:	f0 28 10             	lock sub %dl,(%eax)
     dcb:	90                   	nop
     dcc:	c9                   	leave  
     dcd:	c3                   	ret    

00000dce <ck_pr_sub_int>:
     dce:	55                   	push   %ebp
     dcf:	89 e5                	mov    %esp,%ebp
     dd1:	8b 45 08             	mov    0x8(%ebp),%eax
     dd4:	8b 55 0c             	mov    0xc(%ebp),%edx
     dd7:	8b 4d 08             	mov    0x8(%ebp),%ecx
     dda:	f0 29 10             	lock sub %edx,(%eax)
     ddd:	90                   	nop
     dde:	5d                   	pop    %ebp
     ddf:	c3                   	ret    

00000de0 <ck_pr_sub_uint>:
     de0:	55                   	push   %ebp
     de1:	89 e5                	mov    %esp,%ebp
     de3:	8b 45 08             	mov    0x8(%ebp),%eax
     de6:	8b 55 0c             	mov    0xc(%ebp),%edx
     de9:	8b 4d 08             	mov    0x8(%ebp),%ecx
     dec:	f0 29 10             	lock sub %edx,(%eax)
     def:	90                   	nop
     df0:	5d                   	pop    %ebp
     df1:	c3                   	ret    

00000df2 <ck_pr_sub_32>:
     df2:	55                   	push   %ebp
     df3:	89 e5                	mov    %esp,%ebp
     df5:	8b 45 08             	mov    0x8(%ebp),%eax
     df8:	8b 55 0c             	mov    0xc(%ebp),%edx
     dfb:	8b 4d 08             	mov    0x8(%ebp),%ecx
     dfe:	f0 29 10             	lock sub %edx,(%eax)
     e01:	90                   	nop
     e02:	5d                   	pop    %ebp
     e03:	c3                   	ret    

00000e04 <ck_pr_sub_16>:
     e04:	55                   	push   %ebp
     e05:	89 e5                	mov    %esp,%ebp
     e07:	83 ec 04             	sub    $0x4,%esp
     e0a:	8b 45 0c             	mov    0xc(%ebp),%eax
     e0d:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     e11:	8b 45 08             	mov    0x8(%ebp),%eax
     e14:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
     e18:	8b 4d 08             	mov    0x8(%ebp),%ecx
     e1b:	66 f0 29 10          	lock sub %dx,(%eax)
     e1f:	90                   	nop
     e20:	c9                   	leave  
     e21:	c3                   	ret    

00000e22 <ck_pr_sub_8>:
     e22:	55                   	push   %ebp
     e23:	89 e5                	mov    %esp,%ebp
     e25:	83 ec 04             	sub    $0x4,%esp
     e28:	8b 45 0c             	mov    0xc(%ebp),%eax
     e2b:	88 45 fc             	mov    %al,-0x4(%ebp)
     e2e:	8b 45 08             	mov    0x8(%ebp),%eax
     e31:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     e35:	8b 4d 08             	mov    0x8(%ebp),%ecx
     e38:	f0 28 10             	lock sub %dl,(%eax)
     e3b:	90                   	nop
     e3c:	c9                   	leave  
     e3d:	c3                   	ret    

00000e3e <ck_pr_and_ptr>:
CK_PR_GENERATE(and)
     e3e:	55                   	push   %ebp
     e3f:	89 e5                	mov    %esp,%ebp
     e41:	8b 45 08             	mov    0x8(%ebp),%eax
     e44:	8b 55 0c             	mov    0xc(%ebp),%edx
     e47:	8b 4d 08             	mov    0x8(%ebp),%ecx
     e4a:	f0 21 10             	lock and %edx,(%eax)
     e4d:	90                   	nop
     e4e:	5d                   	pop    %ebp
     e4f:	c3                   	ret    

00000e50 <ck_pr_and_char>:
     e50:	55                   	push   %ebp
     e51:	89 e5                	mov    %esp,%ebp
     e53:	83 ec 04             	sub    $0x4,%esp
     e56:	8b 45 0c             	mov    0xc(%ebp),%eax
     e59:	88 45 fc             	mov    %al,-0x4(%ebp)
     e5c:	8b 45 08             	mov    0x8(%ebp),%eax
     e5f:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     e63:	8b 4d 08             	mov    0x8(%ebp),%ecx
     e66:	f0 20 10             	lock and %dl,(%eax)
     e69:	90                   	nop
     e6a:	c9                   	leave  
     e6b:	c3                   	ret    

00000e6c <ck_pr_and_int>:
     e6c:	55                   	push   %ebp
     e6d:	89 e5                	mov    %esp,%ebp
     e6f:	8b 45 08             	mov    0x8(%ebp),%eax
     e72:	8b 55 0c             	mov    0xc(%ebp),%edx
     e75:	8b 4d 08             	mov    0x8(%ebp),%ecx
     e78:	f0 21 10             	lock and %edx,(%eax)
     e7b:	90                   	nop
     e7c:	5d                   	pop    %ebp
     e7d:	c3                   	ret    

00000e7e <ck_pr_and_uint>:
     e7e:	55                   	push   %ebp
     e7f:	89 e5                	mov    %esp,%ebp
     e81:	8b 45 08             	mov    0x8(%ebp),%eax
     e84:	8b 55 0c             	mov    0xc(%ebp),%edx
     e87:	8b 4d 08             	mov    0x8(%ebp),%ecx
     e8a:	f0 21 10             	lock and %edx,(%eax)
     e8d:	90                   	nop
     e8e:	5d                   	pop    %ebp
     e8f:	c3                   	ret    

00000e90 <ck_pr_and_32>:
     e90:	55                   	push   %ebp
     e91:	89 e5                	mov    %esp,%ebp
     e93:	8b 45 08             	mov    0x8(%ebp),%eax
     e96:	8b 55 0c             	mov    0xc(%ebp),%edx
     e99:	8b 4d 08             	mov    0x8(%ebp),%ecx
     e9c:	f0 21 10             	lock and %edx,(%eax)
     e9f:	90                   	nop
     ea0:	5d                   	pop    %ebp
     ea1:	c3                   	ret    

00000ea2 <ck_pr_and_16>:
     ea2:	55                   	push   %ebp
     ea3:	89 e5                	mov    %esp,%ebp
     ea5:	83 ec 04             	sub    $0x4,%esp
     ea8:	8b 45 0c             	mov    0xc(%ebp),%eax
     eab:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     eaf:	8b 45 08             	mov    0x8(%ebp),%eax
     eb2:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
     eb6:	8b 4d 08             	mov    0x8(%ebp),%ecx
     eb9:	66 f0 21 10          	lock and %dx,(%eax)
     ebd:	90                   	nop
     ebe:	c9                   	leave  
     ebf:	c3                   	ret    

00000ec0 <ck_pr_and_8>:
     ec0:	55                   	push   %ebp
     ec1:	89 e5                	mov    %esp,%ebp
     ec3:	83 ec 04             	sub    $0x4,%esp
     ec6:	8b 45 0c             	mov    0xc(%ebp),%eax
     ec9:	88 45 fc             	mov    %al,-0x4(%ebp)
     ecc:	8b 45 08             	mov    0x8(%ebp),%eax
     ecf:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     ed3:	8b 4d 08             	mov    0x8(%ebp),%ecx
     ed6:	f0 20 10             	lock and %dl,(%eax)
     ed9:	90                   	nop
     eda:	c9                   	leave  
     edb:	c3                   	ret    

00000edc <ck_pr_or_ptr>:
CK_PR_GENERATE(or)
     edc:	55                   	push   %ebp
     edd:	89 e5                	mov    %esp,%ebp
     edf:	8b 45 08             	mov    0x8(%ebp),%eax
     ee2:	8b 55 0c             	mov    0xc(%ebp),%edx
     ee5:	8b 4d 08             	mov    0x8(%ebp),%ecx
     ee8:	f0 09 10             	lock or %edx,(%eax)
     eeb:	90                   	nop
     eec:	5d                   	pop    %ebp
     eed:	c3                   	ret    

00000eee <ck_pr_or_char>:
     eee:	55                   	push   %ebp
     eef:	89 e5                	mov    %esp,%ebp
     ef1:	83 ec 04             	sub    $0x4,%esp
     ef4:	8b 45 0c             	mov    0xc(%ebp),%eax
     ef7:	88 45 fc             	mov    %al,-0x4(%ebp)
     efa:	8b 45 08             	mov    0x8(%ebp),%eax
     efd:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     f01:	8b 4d 08             	mov    0x8(%ebp),%ecx
     f04:	f0 08 10             	lock or %dl,(%eax)
     f07:	90                   	nop
     f08:	c9                   	leave  
     f09:	c3                   	ret    

00000f0a <ck_pr_or_int>:
     f0a:	55                   	push   %ebp
     f0b:	89 e5                	mov    %esp,%ebp
     f0d:	8b 45 08             	mov    0x8(%ebp),%eax
     f10:	8b 55 0c             	mov    0xc(%ebp),%edx
     f13:	8b 4d 08             	mov    0x8(%ebp),%ecx
     f16:	f0 09 10             	lock or %edx,(%eax)
     f19:	90                   	nop
     f1a:	5d                   	pop    %ebp
     f1b:	c3                   	ret    

00000f1c <ck_pr_or_uint>:
     f1c:	55                   	push   %ebp
     f1d:	89 e5                	mov    %esp,%ebp
     f1f:	8b 45 08             	mov    0x8(%ebp),%eax
     f22:	8b 55 0c             	mov    0xc(%ebp),%edx
     f25:	8b 4d 08             	mov    0x8(%ebp),%ecx
     f28:	f0 09 10             	lock or %edx,(%eax)
     f2b:	90                   	nop
     f2c:	5d                   	pop    %ebp
     f2d:	c3                   	ret    

00000f2e <ck_pr_or_32>:
     f2e:	55                   	push   %ebp
     f2f:	89 e5                	mov    %esp,%ebp
     f31:	8b 45 08             	mov    0x8(%ebp),%eax
     f34:	8b 55 0c             	mov    0xc(%ebp),%edx
     f37:	8b 4d 08             	mov    0x8(%ebp),%ecx
     f3a:	f0 09 10             	lock or %edx,(%eax)
     f3d:	90                   	nop
     f3e:	5d                   	pop    %ebp
     f3f:	c3                   	ret    

00000f40 <ck_pr_or_16>:
     f40:	55                   	push   %ebp
     f41:	89 e5                	mov    %esp,%ebp
     f43:	83 ec 04             	sub    $0x4,%esp
     f46:	8b 45 0c             	mov    0xc(%ebp),%eax
     f49:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     f4d:	8b 45 08             	mov    0x8(%ebp),%eax
     f50:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
     f54:	8b 4d 08             	mov    0x8(%ebp),%ecx
     f57:	66 f0 09 10          	lock or %dx,(%eax)
     f5b:	90                   	nop
     f5c:	c9                   	leave  
     f5d:	c3                   	ret    

00000f5e <ck_pr_or_8>:
     f5e:	55                   	push   %ebp
     f5f:	89 e5                	mov    %esp,%ebp
     f61:	83 ec 04             	sub    $0x4,%esp
     f64:	8b 45 0c             	mov    0xc(%ebp),%eax
     f67:	88 45 fc             	mov    %al,-0x4(%ebp)
     f6a:	8b 45 08             	mov    0x8(%ebp),%eax
     f6d:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     f71:	8b 4d 08             	mov    0x8(%ebp),%ecx
     f74:	f0 08 10             	lock or %dl,(%eax)
     f77:	90                   	nop
     f78:	c9                   	leave  
     f79:	c3                   	ret    

00000f7a <ck_pr_xor_ptr>:
CK_PR_GENERATE(xor)
     f7a:	55                   	push   %ebp
     f7b:	89 e5                	mov    %esp,%ebp
     f7d:	8b 45 08             	mov    0x8(%ebp),%eax
     f80:	8b 55 0c             	mov    0xc(%ebp),%edx
     f83:	8b 4d 08             	mov    0x8(%ebp),%ecx
     f86:	f0 31 10             	lock xor %edx,(%eax)
     f89:	90                   	nop
     f8a:	5d                   	pop    %ebp
     f8b:	c3                   	ret    

00000f8c <ck_pr_xor_char>:
     f8c:	55                   	push   %ebp
     f8d:	89 e5                	mov    %esp,%ebp
     f8f:	83 ec 04             	sub    $0x4,%esp
     f92:	8b 45 0c             	mov    0xc(%ebp),%eax
     f95:	88 45 fc             	mov    %al,-0x4(%ebp)
     f98:	8b 45 08             	mov    0x8(%ebp),%eax
     f9b:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
     f9f:	8b 4d 08             	mov    0x8(%ebp),%ecx
     fa2:	f0 30 10             	lock xor %dl,(%eax)
     fa5:	90                   	nop
     fa6:	c9                   	leave  
     fa7:	c3                   	ret    

00000fa8 <ck_pr_xor_int>:
     fa8:	55                   	push   %ebp
     fa9:	89 e5                	mov    %esp,%ebp
     fab:	8b 45 08             	mov    0x8(%ebp),%eax
     fae:	8b 55 0c             	mov    0xc(%ebp),%edx
     fb1:	8b 4d 08             	mov    0x8(%ebp),%ecx
     fb4:	f0 31 10             	lock xor %edx,(%eax)
     fb7:	90                   	nop
     fb8:	5d                   	pop    %ebp
     fb9:	c3                   	ret    

00000fba <ck_pr_xor_uint>:
     fba:	55                   	push   %ebp
     fbb:	89 e5                	mov    %esp,%ebp
     fbd:	8b 45 08             	mov    0x8(%ebp),%eax
     fc0:	8b 55 0c             	mov    0xc(%ebp),%edx
     fc3:	8b 4d 08             	mov    0x8(%ebp),%ecx
     fc6:	f0 31 10             	lock xor %edx,(%eax)
     fc9:	90                   	nop
     fca:	5d                   	pop    %ebp
     fcb:	c3                   	ret    

00000fcc <ck_pr_xor_32>:
     fcc:	55                   	push   %ebp
     fcd:	89 e5                	mov    %esp,%ebp
     fcf:	8b 45 08             	mov    0x8(%ebp),%eax
     fd2:	8b 55 0c             	mov    0xc(%ebp),%edx
     fd5:	8b 4d 08             	mov    0x8(%ebp),%ecx
     fd8:	f0 31 10             	lock xor %edx,(%eax)
     fdb:	90                   	nop
     fdc:	5d                   	pop    %ebp
     fdd:	c3                   	ret    

00000fde <ck_pr_xor_16>:
     fde:	55                   	push   %ebp
     fdf:	89 e5                	mov    %esp,%ebp
     fe1:	83 ec 04             	sub    $0x4,%esp
     fe4:	8b 45 0c             	mov    0xc(%ebp),%eax
     fe7:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
     feb:	8b 45 08             	mov    0x8(%ebp),%eax
     fee:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
     ff2:	8b 4d 08             	mov    0x8(%ebp),%ecx
     ff5:	66 f0 31 10          	lock xor %dx,(%eax)
     ff9:	90                   	nop
     ffa:	c9                   	leave  
     ffb:	c3                   	ret    

00000ffc <ck_pr_xor_8>:
     ffc:	55                   	push   %ebp
     ffd:	89 e5                	mov    %esp,%ebp
     fff:	83 ec 04             	sub    $0x4,%esp
    1002:	8b 45 0c             	mov    0xc(%ebp),%eax
    1005:	88 45 fc             	mov    %al,-0x4(%ebp)
    1008:	8b 45 08             	mov    0x8(%ebp),%eax
    100b:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    100f:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1012:	f0 30 10             	lock xor %dl,(%eax)
    1015:	90                   	nop
    1016:	c9                   	leave  
    1017:	c3                   	ret    

00001018 <ck_pr_cas_ptr>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return z;							\
	}

CK_PR_CAS(ptr, void, void *, char, "cmpxchgl")
    1018:	55                   	push   %ebp
    1019:	89 e5                	mov    %esp,%ebp
    101b:	53                   	push   %ebx
    101c:	83 ec 10             	sub    $0x10,%esp
    101f:	8b 55 08             	mov    0x8(%ebp),%edx
    1022:	8b 4d 10             	mov    0x10(%ebp),%ecx
    1025:	8b 45 0c             	mov    0xc(%ebp),%eax
    1028:	8b 5d 08             	mov    0x8(%ebp),%ebx
    102b:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    102f:	0f 94 c0             	sete   %al
    1032:	88 45 fb             	mov    %al,-0x5(%ebp)
    1035:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    1039:	83 c4 10             	add    $0x10,%esp
    103c:	5b                   	pop    %ebx
    103d:	5d                   	pop    %ebp
    103e:	c3                   	ret    

0000103f <ck_pr_cas_char>:

#define CK_PR_CAS_S(S, T, I) CK_PR_CAS(S, T, T, T, I)

CK_PR_CAS_S(char, char, "cmpxchgb")
    103f:	55                   	push   %ebp
    1040:	89 e5                	mov    %esp,%ebp
    1042:	53                   	push   %ebx
    1043:	83 ec 18             	sub    $0x18,%esp
    1046:	8b 55 0c             	mov    0xc(%ebp),%edx
    1049:	8b 45 10             	mov    0x10(%ebp),%eax
    104c:	88 55 e8             	mov    %dl,-0x18(%ebp)
    104f:	88 45 e4             	mov    %al,-0x1c(%ebp)
    1052:	8b 55 08             	mov    0x8(%ebp),%edx
    1055:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
    1059:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
    105d:	8b 5d 08             	mov    0x8(%ebp),%ebx
    1060:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
    1064:	0f 94 c0             	sete   %al
    1067:	88 45 fb             	mov    %al,-0x5(%ebp)
    106a:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    106e:	83 c4 18             	add    $0x18,%esp
    1071:	5b                   	pop    %ebx
    1072:	5d                   	pop    %ebp
    1073:	c3                   	ret    

00001074 <ck_pr_cas_int>:
CK_PR_CAS_S(int, int, "cmpxchgl")
    1074:	55                   	push   %ebp
    1075:	89 e5                	mov    %esp,%ebp
    1077:	53                   	push   %ebx
    1078:	83 ec 10             	sub    $0x10,%esp
    107b:	8b 55 08             	mov    0x8(%ebp),%edx
    107e:	8b 4d 10             	mov    0x10(%ebp),%ecx
    1081:	8b 45 0c             	mov    0xc(%ebp),%eax
    1084:	8b 5d 08             	mov    0x8(%ebp),%ebx
    1087:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    108b:	0f 94 c0             	sete   %al
    108e:	88 45 fb             	mov    %al,-0x5(%ebp)
    1091:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    1095:	83 c4 10             	add    $0x10,%esp
    1098:	5b                   	pop    %ebx
    1099:	5d                   	pop    %ebp
    109a:	c3                   	ret    

0000109b <ck_pr_cas_uint>:
CK_PR_CAS_S(uint, unsigned int, "cmpxchgl")
    109b:	55                   	push   %ebp
    109c:	89 e5                	mov    %esp,%ebp
    109e:	53                   	push   %ebx
    109f:	83 ec 10             	sub    $0x10,%esp
    10a2:	8b 55 08             	mov    0x8(%ebp),%edx
    10a5:	8b 4d 10             	mov    0x10(%ebp),%ecx
    10a8:	8b 45 0c             	mov    0xc(%ebp),%eax
    10ab:	8b 5d 08             	mov    0x8(%ebp),%ebx
    10ae:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    10b2:	0f 94 c0             	sete   %al
    10b5:	88 45 fb             	mov    %al,-0x5(%ebp)
    10b8:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    10bc:	83 c4 10             	add    $0x10,%esp
    10bf:	5b                   	pop    %ebx
    10c0:	5d                   	pop    %ebp
    10c1:	c3                   	ret    

000010c2 <ck_pr_cas_32>:
CK_PR_CAS_S(32, uint32_t, "cmpxchgl")
    10c2:	55                   	push   %ebp
    10c3:	89 e5                	mov    %esp,%ebp
    10c5:	53                   	push   %ebx
    10c6:	83 ec 10             	sub    $0x10,%esp
    10c9:	8b 55 08             	mov    0x8(%ebp),%edx
    10cc:	8b 4d 10             	mov    0x10(%ebp),%ecx
    10cf:	8b 45 0c             	mov    0xc(%ebp),%eax
    10d2:	8b 5d 08             	mov    0x8(%ebp),%ebx
    10d5:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    10d9:	0f 94 c0             	sete   %al
    10dc:	88 45 fb             	mov    %al,-0x5(%ebp)
    10df:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    10e3:	83 c4 10             	add    $0x10,%esp
    10e6:	5b                   	pop    %ebx
    10e7:	5d                   	pop    %ebp
    10e8:	c3                   	ret    

000010e9 <ck_pr_cas_16>:
CK_PR_CAS_S(16, uint16_t, "cmpxchgw")
    10e9:	55                   	push   %ebp
    10ea:	89 e5                	mov    %esp,%ebp
    10ec:	53                   	push   %ebx
    10ed:	83 ec 18             	sub    $0x18,%esp
    10f0:	8b 55 0c             	mov    0xc(%ebp),%edx
    10f3:	8b 45 10             	mov    0x10(%ebp),%eax
    10f6:	66 89 55 e8          	mov    %dx,-0x18(%ebp)
    10fa:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
    10fe:	8b 55 08             	mov    0x8(%ebp),%edx
    1101:	0f b7 4d e4          	movzwl -0x1c(%ebp),%ecx
    1105:	0f b7 45 e8          	movzwl -0x18(%ebp),%eax
    1109:	8b 5d 08             	mov    0x8(%ebp),%ebx
    110c:	66 f0 0f b1 0a       	lock cmpxchg %cx,(%edx)
    1111:	0f 94 c0             	sete   %al
    1114:	88 45 fb             	mov    %al,-0x5(%ebp)
    1117:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    111b:	83 c4 18             	add    $0x18,%esp
    111e:	5b                   	pop    %ebx
    111f:	5d                   	pop    %ebp
    1120:	c3                   	ret    

00001121 <ck_pr_cas_8>:
CK_PR_CAS_S(8,  uint8_t,  "cmpxchgb")
    1121:	55                   	push   %ebp
    1122:	89 e5                	mov    %esp,%ebp
    1124:	53                   	push   %ebx
    1125:	83 ec 18             	sub    $0x18,%esp
    1128:	8b 55 0c             	mov    0xc(%ebp),%edx
    112b:	8b 45 10             	mov    0x10(%ebp),%eax
    112e:	88 55 e8             	mov    %dl,-0x18(%ebp)
    1131:	88 45 e4             	mov    %al,-0x1c(%ebp)
    1134:	8b 55 08             	mov    0x8(%ebp),%edx
    1137:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
    113b:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
    113f:	8b 5d 08             	mov    0x8(%ebp),%ebx
    1142:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
    1146:	0f 94 c0             	sete   %al
    1149:	88 45 fb             	mov    %al,-0x5(%ebp)
    114c:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    1150:	83 c4 18             	add    $0x18,%esp
    1153:	5b                   	pop    %ebx
    1154:	5d                   	pop    %ebp
    1155:	c3                   	ret    

00001156 <ck_pr_cas_ptr_value>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return (bool)z;							\
	}

CK_PR_CAS_O(ptr, void, void *, char, "l", "eax")
    1156:	55                   	push   %ebp
    1157:	89 e5                	mov    %esp,%ebp
    1159:	56                   	push   %esi
    115a:	53                   	push   %ebx
    115b:	83 ec 10             	sub    $0x10,%esp
    115e:	8b 5d 08             	mov    0x8(%ebp),%ebx
    1161:	8b 75 14             	mov    0x14(%ebp),%esi
    1164:	8b 55 10             	mov    0x10(%ebp),%edx
    1167:	8b 45 0c             	mov    0xc(%ebp),%eax
    116a:	8b 4d 08             	mov    0x8(%ebp),%ecx
    116d:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
    1171:	89 06                	mov    %eax,(%esi)
    1173:	0f 94 c0             	sete   %al
    1176:	88 45 f7             	mov    %al,-0x9(%ebp)
    1179:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    117d:	83 c4 10             	add    $0x10,%esp
    1180:	5b                   	pop    %ebx
    1181:	5e                   	pop    %esi
    1182:	5d                   	pop    %ebp
    1183:	c3                   	ret    

00001184 <ck_pr_cas_char_value>:

#define CK_PR_CAS_O_S(S, T, I, R)	\
	CK_PR_CAS_O(S, T, T, T, I, R)

CK_PR_CAS_O_S(char, char, "b", "al")
    1184:	55                   	push   %ebp
    1185:	89 e5                	mov    %esp,%ebp
    1187:	56                   	push   %esi
    1188:	53                   	push   %ebx
    1189:	83 ec 18             	sub    $0x18,%esp
    118c:	8b 55 0c             	mov    0xc(%ebp),%edx
    118f:	8b 45 10             	mov    0x10(%ebp),%eax
    1192:	88 55 e4             	mov    %dl,-0x1c(%ebp)
    1195:	88 45 e0             	mov    %al,-0x20(%ebp)
    1198:	8b 5d 08             	mov    0x8(%ebp),%ebx
    119b:	8b 75 14             	mov    0x14(%ebp),%esi
    119e:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
    11a2:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
    11a6:	8b 4d 08             	mov    0x8(%ebp),%ecx
    11a9:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
    11ad:	88 06                	mov    %al,(%esi)
    11af:	0f 94 c0             	sete   %al
    11b2:	88 45 f7             	mov    %al,-0x9(%ebp)
    11b5:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    11b9:	83 c4 18             	add    $0x18,%esp
    11bc:	5b                   	pop    %ebx
    11bd:	5e                   	pop    %esi
    11be:	5d                   	pop    %ebp
    11bf:	c3                   	ret    

000011c0 <ck_pr_cas_int_value>:
CK_PR_CAS_O_S(int, int, "l", "eax")
    11c0:	55                   	push   %ebp
    11c1:	89 e5                	mov    %esp,%ebp
    11c3:	56                   	push   %esi
    11c4:	53                   	push   %ebx
    11c5:	83 ec 10             	sub    $0x10,%esp
    11c8:	8b 5d 08             	mov    0x8(%ebp),%ebx
    11cb:	8b 75 14             	mov    0x14(%ebp),%esi
    11ce:	8b 55 10             	mov    0x10(%ebp),%edx
    11d1:	8b 45 0c             	mov    0xc(%ebp),%eax
    11d4:	8b 4d 08             	mov    0x8(%ebp),%ecx
    11d7:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
    11db:	89 06                	mov    %eax,(%esi)
    11dd:	0f 94 c0             	sete   %al
    11e0:	88 45 f7             	mov    %al,-0x9(%ebp)
    11e3:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    11e7:	83 c4 10             	add    $0x10,%esp
    11ea:	5b                   	pop    %ebx
    11eb:	5e                   	pop    %esi
    11ec:	5d                   	pop    %ebp
    11ed:	c3                   	ret    

000011ee <ck_pr_cas_uint_value>:
CK_PR_CAS_O_S(uint, unsigned int, "l", "eax")
    11ee:	55                   	push   %ebp
    11ef:	89 e5                	mov    %esp,%ebp
    11f1:	56                   	push   %esi
    11f2:	53                   	push   %ebx
    11f3:	83 ec 10             	sub    $0x10,%esp
    11f6:	8b 5d 08             	mov    0x8(%ebp),%ebx
    11f9:	8b 75 14             	mov    0x14(%ebp),%esi
    11fc:	8b 55 10             	mov    0x10(%ebp),%edx
    11ff:	8b 45 0c             	mov    0xc(%ebp),%eax
    1202:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1205:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
    1209:	89 06                	mov    %eax,(%esi)
    120b:	0f 94 c0             	sete   %al
    120e:	88 45 f7             	mov    %al,-0x9(%ebp)
    1211:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    1215:	83 c4 10             	add    $0x10,%esp
    1218:	5b                   	pop    %ebx
    1219:	5e                   	pop    %esi
    121a:	5d                   	pop    %ebp
    121b:	c3                   	ret    

0000121c <ck_pr_cas_32_value>:
CK_PR_CAS_O_S(32, uint32_t, "l", "eax")
    121c:	55                   	push   %ebp
    121d:	89 e5                	mov    %esp,%ebp
    121f:	56                   	push   %esi
    1220:	53                   	push   %ebx
    1221:	83 ec 10             	sub    $0x10,%esp
    1224:	8b 5d 08             	mov    0x8(%ebp),%ebx
    1227:	8b 75 14             	mov    0x14(%ebp),%esi
    122a:	8b 55 10             	mov    0x10(%ebp),%edx
    122d:	8b 45 0c             	mov    0xc(%ebp),%eax
    1230:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1233:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
    1237:	89 06                	mov    %eax,(%esi)
    1239:	0f 94 c0             	sete   %al
    123c:	88 45 f7             	mov    %al,-0x9(%ebp)
    123f:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    1243:	83 c4 10             	add    $0x10,%esp
    1246:	5b                   	pop    %ebx
    1247:	5e                   	pop    %esi
    1248:	5d                   	pop    %ebp
    1249:	c3                   	ret    

0000124a <ck_pr_cas_16_value>:
CK_PR_CAS_O_S(16, uint16_t, "w", "ax")
    124a:	55                   	push   %ebp
    124b:	89 e5                	mov    %esp,%ebp
    124d:	56                   	push   %esi
    124e:	53                   	push   %ebx
    124f:	83 ec 18             	sub    $0x18,%esp
    1252:	8b 55 0c             	mov    0xc(%ebp),%edx
    1255:	8b 45 10             	mov    0x10(%ebp),%eax
    1258:	66 89 55 e4          	mov    %dx,-0x1c(%ebp)
    125c:	66 89 45 e0          	mov    %ax,-0x20(%ebp)
    1260:	8b 5d 08             	mov    0x8(%ebp),%ebx
    1263:	8b 75 14             	mov    0x14(%ebp),%esi
    1266:	0f b7 55 e0          	movzwl -0x20(%ebp),%edx
    126a:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
    126e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1271:	66 f0 0f b1 13       	lock cmpxchg %dx,(%ebx)
    1276:	66 89 06             	mov    %ax,(%esi)
    1279:	0f 94 c0             	sete   %al
    127c:	88 45 f7             	mov    %al,-0x9(%ebp)
    127f:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    1283:	83 c4 18             	add    $0x18,%esp
    1286:	5b                   	pop    %ebx
    1287:	5e                   	pop    %esi
    1288:	5d                   	pop    %ebp
    1289:	c3                   	ret    

0000128a <ck_pr_cas_8_value>:
CK_PR_CAS_O_S(8,  uint8_t,  "b", "al")
    128a:	55                   	push   %ebp
    128b:	89 e5                	mov    %esp,%ebp
    128d:	56                   	push   %esi
    128e:	53                   	push   %ebx
    128f:	83 ec 18             	sub    $0x18,%esp
    1292:	8b 55 0c             	mov    0xc(%ebp),%edx
    1295:	8b 45 10             	mov    0x10(%ebp),%eax
    1298:	88 55 e4             	mov    %dl,-0x1c(%ebp)
    129b:	88 45 e0             	mov    %al,-0x20(%ebp)
    129e:	8b 5d 08             	mov    0x8(%ebp),%ebx
    12a1:	8b 75 14             	mov    0x14(%ebp),%esi
    12a4:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
    12a8:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
    12ac:	8b 4d 08             	mov    0x8(%ebp),%ecx
    12af:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
    12b3:	88 06                	mov    %al,(%esi)
    12b5:	0f 94 c0             	sete   %al
    12b8:	88 45 f7             	mov    %al,-0x9(%ebp)
    12bb:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    12bf:	83 c4 18             	add    $0x18,%esp
    12c2:	5b                   	pop    %ebx
    12c3:	5e                   	pop    %esi
    12c4:	5d                   	pop    %ebp
    12c5:	c3                   	ret    

000012c6 <ck_pr_btc_ptr>:
	CK_PR_BT_S(K, uint, unsigned int, #K "l %2, %0")	\
	CK_PR_BT_S(K, int, int, #K "l %2, %0")			\
	CK_PR_BT_S(K, 32, uint32_t, #K "l %2, %0")		\
	CK_PR_BT_S(K, 16, uint16_t, #K "w %w2, %0")

CK_PR_GENERATE(btc)
    12c6:	55                   	push   %ebp
    12c7:	89 e5                	mov    %esp,%ebp
    12c9:	83 ec 10             	sub    $0x10,%esp
    12cc:	8b 55 08             	mov    0x8(%ebp),%edx
    12cf:	8b 45 0c             	mov    0xc(%ebp),%eax
    12d2:	8b 4d 08             	mov    0x8(%ebp),%ecx
    12d5:	f0 0f bb 02          	lock btc %eax,(%edx)
    12d9:	0f 92 c0             	setb   %al
    12dc:	88 45 ff             	mov    %al,-0x1(%ebp)
    12df:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    12e3:	c9                   	leave  
    12e4:	c3                   	ret    

000012e5 <ck_pr_btc_uint>:
    12e5:	55                   	push   %ebp
    12e6:	89 e5                	mov    %esp,%ebp
    12e8:	83 ec 10             	sub    $0x10,%esp
    12eb:	8b 55 08             	mov    0x8(%ebp),%edx
    12ee:	8b 45 0c             	mov    0xc(%ebp),%eax
    12f1:	8b 4d 08             	mov    0x8(%ebp),%ecx
    12f4:	f0 0f bb 02          	lock btc %eax,(%edx)
    12f8:	0f 92 c0             	setb   %al
    12fb:	88 45 ff             	mov    %al,-0x1(%ebp)
    12fe:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    1302:	c9                   	leave  
    1303:	c3                   	ret    

00001304 <ck_pr_btc_int>:
    1304:	55                   	push   %ebp
    1305:	89 e5                	mov    %esp,%ebp
    1307:	83 ec 10             	sub    $0x10,%esp
    130a:	8b 45 0c             	mov    0xc(%ebp),%eax
    130d:	8b 55 08             	mov    0x8(%ebp),%edx
    1310:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1313:	f0 0f bb 02          	lock btc %eax,(%edx)
    1317:	0f 92 c0             	setb   %al
    131a:	88 45 ff             	mov    %al,-0x1(%ebp)
    131d:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    1321:	c9                   	leave  
    1322:	c3                   	ret    

00001323 <ck_pr_btc_32>:
    1323:	55                   	push   %ebp
    1324:	89 e5                	mov    %esp,%ebp
    1326:	83 ec 10             	sub    $0x10,%esp
    1329:	8b 55 08             	mov    0x8(%ebp),%edx
    132c:	8b 45 0c             	mov    0xc(%ebp),%eax
    132f:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1332:	f0 0f bb 02          	lock btc %eax,(%edx)
    1336:	0f 92 c0             	setb   %al
    1339:	88 45 ff             	mov    %al,-0x1(%ebp)
    133c:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    1340:	c9                   	leave  
    1341:	c3                   	ret    

00001342 <ck_pr_btc_16>:
    1342:	55                   	push   %ebp
    1343:	89 e5                	mov    %esp,%ebp
    1345:	83 ec 10             	sub    $0x10,%esp
    1348:	8b 45 0c             	mov    0xc(%ebp),%eax
    134b:	8b 55 08             	mov    0x8(%ebp),%edx
    134e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1351:	66 f0 0f bb 02       	lock btc %ax,(%edx)
    1356:	0f 92 c0             	setb   %al
    1359:	88 45 ff             	mov    %al,-0x1(%ebp)
    135c:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    1360:	c9                   	leave  
    1361:	c3                   	ret    

00001362 <ck_pr_bts_ptr>:
CK_PR_GENERATE(bts)
    1362:	55                   	push   %ebp
    1363:	89 e5                	mov    %esp,%ebp
    1365:	83 ec 10             	sub    $0x10,%esp
    1368:	8b 55 08             	mov    0x8(%ebp),%edx
    136b:	8b 45 0c             	mov    0xc(%ebp),%eax
    136e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1371:	f0 0f ab 02          	lock bts %eax,(%edx)
    1375:	0f 92 c0             	setb   %al
    1378:	88 45 ff             	mov    %al,-0x1(%ebp)
    137b:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    137f:	c9                   	leave  
    1380:	c3                   	ret    

00001381 <ck_pr_bts_uint>:
    1381:	55                   	push   %ebp
    1382:	89 e5                	mov    %esp,%ebp
    1384:	83 ec 10             	sub    $0x10,%esp
    1387:	8b 55 08             	mov    0x8(%ebp),%edx
    138a:	8b 45 0c             	mov    0xc(%ebp),%eax
    138d:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1390:	f0 0f ab 02          	lock bts %eax,(%edx)
    1394:	0f 92 c0             	setb   %al
    1397:	88 45 ff             	mov    %al,-0x1(%ebp)
    139a:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    139e:	c9                   	leave  
    139f:	c3                   	ret    

000013a0 <ck_pr_bts_int>:
    13a0:	55                   	push   %ebp
    13a1:	89 e5                	mov    %esp,%ebp
    13a3:	83 ec 10             	sub    $0x10,%esp
    13a6:	8b 45 0c             	mov    0xc(%ebp),%eax
    13a9:	8b 55 08             	mov    0x8(%ebp),%edx
    13ac:	8b 4d 08             	mov    0x8(%ebp),%ecx
    13af:	f0 0f ab 02          	lock bts %eax,(%edx)
    13b3:	0f 92 c0             	setb   %al
    13b6:	88 45 ff             	mov    %al,-0x1(%ebp)
    13b9:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    13bd:	c9                   	leave  
    13be:	c3                   	ret    

000013bf <ck_pr_bts_32>:
    13bf:	55                   	push   %ebp
    13c0:	89 e5                	mov    %esp,%ebp
    13c2:	83 ec 10             	sub    $0x10,%esp
    13c5:	8b 55 08             	mov    0x8(%ebp),%edx
    13c8:	8b 45 0c             	mov    0xc(%ebp),%eax
    13cb:	8b 4d 08             	mov    0x8(%ebp),%ecx
    13ce:	f0 0f ab 02          	lock bts %eax,(%edx)
    13d2:	0f 92 c0             	setb   %al
    13d5:	88 45 ff             	mov    %al,-0x1(%ebp)
    13d8:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    13dc:	c9                   	leave  
    13dd:	c3                   	ret    

000013de <ck_pr_bts_16>:
    13de:	55                   	push   %ebp
    13df:	89 e5                	mov    %esp,%ebp
    13e1:	83 ec 10             	sub    $0x10,%esp
    13e4:	8b 45 0c             	mov    0xc(%ebp),%eax
    13e7:	8b 55 08             	mov    0x8(%ebp),%edx
    13ea:	8b 4d 08             	mov    0x8(%ebp),%ecx
    13ed:	66 f0 0f ab 02       	lock bts %ax,(%edx)
    13f2:	0f 92 c0             	setb   %al
    13f5:	88 45 ff             	mov    %al,-0x1(%ebp)
    13f8:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    13fc:	c9                   	leave  
    13fd:	c3                   	ret    

000013fe <ck_pr_btr_ptr>:
CK_PR_GENERATE(btr)
    13fe:	55                   	push   %ebp
    13ff:	89 e5                	mov    %esp,%ebp
    1401:	83 ec 10             	sub    $0x10,%esp
    1404:	8b 55 08             	mov    0x8(%ebp),%edx
    1407:	8b 45 0c             	mov    0xc(%ebp),%eax
    140a:	8b 4d 08             	mov    0x8(%ebp),%ecx
    140d:	f0 0f b3 02          	lock btr %eax,(%edx)
    1411:	0f 92 c0             	setb   %al
    1414:	88 45 ff             	mov    %al,-0x1(%ebp)
    1417:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    141b:	c9                   	leave  
    141c:	c3                   	ret    

0000141d <ck_pr_btr_uint>:
    141d:	55                   	push   %ebp
    141e:	89 e5                	mov    %esp,%ebp
    1420:	83 ec 10             	sub    $0x10,%esp
    1423:	8b 55 08             	mov    0x8(%ebp),%edx
    1426:	8b 45 0c             	mov    0xc(%ebp),%eax
    1429:	8b 4d 08             	mov    0x8(%ebp),%ecx
    142c:	f0 0f b3 02          	lock btr %eax,(%edx)
    1430:	0f 92 c0             	setb   %al
    1433:	88 45 ff             	mov    %al,-0x1(%ebp)
    1436:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    143a:	c9                   	leave  
    143b:	c3                   	ret    

0000143c <ck_pr_btr_int>:
    143c:	55                   	push   %ebp
    143d:	89 e5                	mov    %esp,%ebp
    143f:	83 ec 10             	sub    $0x10,%esp
    1442:	8b 45 0c             	mov    0xc(%ebp),%eax
    1445:	8b 55 08             	mov    0x8(%ebp),%edx
    1448:	8b 4d 08             	mov    0x8(%ebp),%ecx
    144b:	f0 0f b3 02          	lock btr %eax,(%edx)
    144f:	0f 92 c0             	setb   %al
    1452:	88 45 ff             	mov    %al,-0x1(%ebp)
    1455:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    1459:	c9                   	leave  
    145a:	c3                   	ret    

0000145b <ck_pr_btr_32>:
    145b:	55                   	push   %ebp
    145c:	89 e5                	mov    %esp,%ebp
    145e:	83 ec 10             	sub    $0x10,%esp
    1461:	8b 55 08             	mov    0x8(%ebp),%edx
    1464:	8b 45 0c             	mov    0xc(%ebp),%eax
    1467:	8b 4d 08             	mov    0x8(%ebp),%ecx
    146a:	f0 0f b3 02          	lock btr %eax,(%edx)
    146e:	0f 92 c0             	setb   %al
    1471:	88 45 ff             	mov    %al,-0x1(%ebp)
    1474:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    1478:	c9                   	leave  
    1479:	c3                   	ret    

0000147a <ck_pr_btr_16>:
    147a:	55                   	push   %ebp
    147b:	89 e5                	mov    %esp,%ebp
    147d:	83 ec 10             	sub    $0x10,%esp
    1480:	8b 45 0c             	mov    0xc(%ebp),%eax
    1483:	8b 55 08             	mov    0x8(%ebp),%edx
    1486:	8b 4d 08             	mov    0x8(%ebp),%ecx
    1489:	66 f0 0f b3 02       	lock btr %ax,(%edx)
    148e:	0f 92 c0             	setb   %al
    1491:	88 45 ff             	mov    %al,-0x1(%ebp)
    1494:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    1498:	c9                   	leave  
    1499:	c3                   	ret    

0000149a <ck_pr_barrier>:

#include <ck_cc.h>

CK_CC_INLINE static void
ck_pr_barrier(void)
{
    149a:	55                   	push   %ebp
    149b:	89 e5                	mov    %esp,%ebp

	__asm__ __volatile__("" ::: "memory");
	return;
    149d:	90                   	nop
}
    149e:	5d                   	pop    %ebp
    149f:	c3                   	ret    

000014a0 <ck_pr_fence_load_depends>:

/*
 * None of the currently supported platforms allow for data-dependent
 * load ordering.
 */
CK_PR_FENCE_NOOP(load_depends)
    14a0:	55                   	push   %ebp
    14a1:	89 e5                	mov    %esp,%ebp
    14a3:	e8 f2 ff ff ff       	call   149a <ck_pr_barrier>
    14a8:	90                   	nop
    14a9:	5d                   	pop    %ebp
    14aa:	c3                   	ret    

000014ab <ck_pr_fence_atomic>:
#elif defined(CK_MD_TSO)
/*
 * Only loads are re-ordered and only with respect to
 * prior stores. Atomic operations are serializing.
 */
CK_PR_FENCE_NOOP(atomic)
    14ab:	55                   	push   %ebp
    14ac:	89 e5                	mov    %esp,%ebp
    14ae:	e8 e7 ff ff ff       	call   149a <ck_pr_barrier>
    14b3:	90                   	nop
    14b4:	5d                   	pop    %ebp
    14b5:	c3                   	ret    

000014b6 <ck_pr_fence_atomic_load>:
CK_PR_FENCE_NOOP(atomic_load)
    14b6:	55                   	push   %ebp
    14b7:	89 e5                	mov    %esp,%ebp
    14b9:	e8 dc ff ff ff       	call   149a <ck_pr_barrier>
    14be:	90                   	nop
    14bf:	5d                   	pop    %ebp
    14c0:	c3                   	ret    

000014c1 <ck_pr_fence_atomic_store>:
CK_PR_FENCE_NOOP(atomic_store)
    14c1:	55                   	push   %ebp
    14c2:	89 e5                	mov    %esp,%ebp
    14c4:	e8 d1 ff ff ff       	call   149a <ck_pr_barrier>
    14c9:	90                   	nop
    14ca:	5d                   	pop    %ebp
    14cb:	c3                   	ret    

000014cc <ck_pr_fence_store_atomic>:
CK_PR_FENCE_NOOP(store_atomic)
    14cc:	55                   	push   %ebp
    14cd:	89 e5                	mov    %esp,%ebp
    14cf:	e8 c6 ff ff ff       	call   149a <ck_pr_barrier>
    14d4:	90                   	nop
    14d5:	5d                   	pop    %ebp
    14d6:	c3                   	ret    

000014d7 <ck_pr_fence_load_atomic>:
CK_PR_FENCE_NOOP(load_atomic)
    14d7:	55                   	push   %ebp
    14d8:	89 e5                	mov    %esp,%ebp
    14da:	e8 bb ff ff ff       	call   149a <ck_pr_barrier>
    14df:	90                   	nop
    14e0:	5d                   	pop    %ebp
    14e1:	c3                   	ret    

000014e2 <ck_pr_fence_load_store>:
CK_PR_FENCE_NOOP(load_store)
    14e2:	55                   	push   %ebp
    14e3:	89 e5                	mov    %esp,%ebp
    14e5:	e8 b0 ff ff ff       	call   149a <ck_pr_barrier>
    14ea:	90                   	nop
    14eb:	5d                   	pop    %ebp
    14ec:	c3                   	ret    

000014ed <ck_pr_fence_store_load>:
CK_PR_FENCE_EMIT(store_load)
    14ed:	55                   	push   %ebp
    14ee:	89 e5                	mov    %esp,%ebp
    14f0:	e8 d4 f1 ff ff       	call   6c9 <ck_pr_fence_strict_store_load>
    14f5:	90                   	nop
    14f6:	5d                   	pop    %ebp
    14f7:	c3                   	ret    

000014f8 <ck_pr_fence_load>:
CK_PR_FENCE_NOOP(load)
    14f8:	55                   	push   %ebp
    14f9:	89 e5                	mov    %esp,%ebp
    14fb:	e8 9a ff ff ff       	call   149a <ck_pr_barrier>
    1500:	90                   	nop
    1501:	5d                   	pop    %ebp
    1502:	c3                   	ret    

00001503 <ck_pr_fence_store>:
CK_PR_FENCE_NOOP(store)
    1503:	55                   	push   %ebp
    1504:	89 e5                	mov    %esp,%ebp
    1506:	e8 8f ff ff ff       	call   149a <ck_pr_barrier>
    150b:	90                   	nop
    150c:	5d                   	pop    %ebp
    150d:	c3                   	ret    

0000150e <ck_pr_fence_memory>:
CK_PR_FENCE_EMIT(memory)
    150e:	55                   	push   %ebp
    150f:	89 e5                	mov    %esp,%ebp
    1511:	e8 bc f1 ff ff       	call   6d2 <ck_pr_fence_strict_memory>
    1516:	90                   	nop
    1517:	5d                   	pop    %ebp
    1518:	c3                   	ret    

00001519 <ck_pr_fence_acquire>:
CK_PR_FENCE_NOOP(acquire)
    1519:	55                   	push   %ebp
    151a:	89 e5                	mov    %esp,%ebp
    151c:	e8 79 ff ff ff       	call   149a <ck_pr_barrier>
    1521:	90                   	nop
    1522:	5d                   	pop    %ebp
    1523:	c3                   	ret    

00001524 <ck_pr_fence_release>:
CK_PR_FENCE_NOOP(release)
    1524:	55                   	push   %ebp
    1525:	89 e5                	mov    %esp,%ebp
    1527:	e8 6e ff ff ff       	call   149a <ck_pr_barrier>
    152c:	90                   	nop
    152d:	5d                   	pop    %ebp
    152e:	c3                   	ret    

0000152f <ck_pr_fence_acqrel>:
CK_PR_FENCE_NOOP(acqrel)
    152f:	55                   	push   %ebp
    1530:	89 e5                	mov    %esp,%ebp
    1532:	e8 63 ff ff ff       	call   149a <ck_pr_barrier>
    1537:	90                   	nop
    1538:	5d                   	pop    %ebp
    1539:	c3                   	ret    

0000153a <ck_pr_fence_lock>:
CK_PR_FENCE_NOOP(lock)
    153a:	55                   	push   %ebp
    153b:	89 e5                	mov    %esp,%ebp
    153d:	e8 58 ff ff ff       	call   149a <ck_pr_barrier>
    1542:	90                   	nop
    1543:	5d                   	pop    %ebp
    1544:	c3                   	ret    

00001545 <ck_pr_fence_unlock>:
CK_PR_FENCE_NOOP(unlock)
    1545:	55                   	push   %ebp
    1546:	89 e5                	mov    %esp,%ebp
    1548:	e8 4d ff ff ff       	call   149a <ck_pr_barrier>
    154d:	90                   	nop
    154e:	5d                   	pop    %ebp
    154f:	c3                   	ret    

00001550 <ck_pr_rfo>:

#ifndef CK_F_PR_RFO
#define CK_F_PR_RFO
CK_CC_INLINE static void
ck_pr_rfo(const void *m)
{
    1550:	55                   	push   %ebp
    1551:	89 e5                	mov    %esp,%ebp

	(void)m;
	return;
    1553:	90                   	nop
}
    1554:	5d                   	pop    %ebp
    1555:	c3                   	ret    

00001556 <ck_ring_size>:
};
typedef struct ck_ring_buffer ck_ring_buffer_t;

CK_CC_INLINE static unsigned int
ck_ring_size(const struct ck_ring *ring)
{
    1556:	55                   	push   %ebp
    1557:	89 e5                	mov    %esp,%ebp
    1559:	83 ec 14             	sub    $0x14,%esp
	unsigned int c, p;

	c = ck_pr_load_uint(&ring->c_head);
    155c:	8b 45 08             	mov    0x8(%ebp),%eax
    155f:	89 04 24             	mov    %eax,(%esp)
    1562:	e8 86 f2 ff ff       	call   7ed <ck_pr_md_load_uint>
    1567:	89 45 fc             	mov    %eax,-0x4(%ebp)
	p = ck_pr_load_uint(&ring->p_tail);
    156a:	8b 45 08             	mov    0x8(%ebp),%eax
    156d:	83 c0 40             	add    $0x40,%eax
    1570:	89 04 24             	mov    %eax,(%esp)
    1573:	e8 75 f2 ff ff       	call   7ed <ck_pr_md_load_uint>
    1578:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return (p - c) & ring->mask;
    157b:	8b 45 fc             	mov    -0x4(%ebp),%eax
    157e:	8b 55 f8             	mov    -0x8(%ebp),%edx
    1581:	29 c2                	sub    %eax,%edx
    1583:	8b 45 08             	mov    0x8(%ebp),%eax
    1586:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    158c:	21 d0                	and    %edx,%eax
}
    158e:	c9                   	leave  
    158f:	c3                   	ret    

00001590 <ck_ring_capacity>:

CK_CC_INLINE static unsigned int
ck_ring_capacity(const struct ck_ring *ring)
{
    1590:	55                   	push   %ebp
    1591:	89 e5                	mov    %esp,%ebp
	return ring->size;
    1593:	8b 45 08             	mov    0x8(%ebp),%eax
    1596:	8b 80 80 00 00 00    	mov    0x80(%eax),%eax
}
    159c:	5d                   	pop    %ebp
    159d:	c3                   	ret    

0000159e <ck_ring_init>:

CK_CC_INLINE static void
ck_ring_init(struct ck_ring *ring, unsigned int size)
{
    159e:	55                   	push   %ebp
    159f:	89 e5                	mov    %esp,%ebp

	ring->size = size;
    15a1:	8b 45 08             	mov    0x8(%ebp),%eax
    15a4:	8b 55 0c             	mov    0xc(%ebp),%edx
    15a7:	89 90 80 00 00 00    	mov    %edx,0x80(%eax)
	ring->mask = size - 1;
    15ad:	8b 45 0c             	mov    0xc(%ebp),%eax
    15b0:	8d 50 ff             	lea    -0x1(%eax),%edx
    15b3:	8b 45 08             	mov    0x8(%ebp),%eax
    15b6:	89 90 84 00 00 00    	mov    %edx,0x84(%eax)
	ring->p_tail = 0;
    15bc:	8b 45 08             	mov    0x8(%ebp),%eax
    15bf:	c7 40 40 00 00 00 00 	movl   $0x0,0x40(%eax)
	ring->p_head = 0;
    15c6:	8b 45 08             	mov    0x8(%ebp),%eax
    15c9:	c7 40 44 00 00 00 00 	movl   $0x0,0x44(%eax)
	ring->c_head = 0;
    15d0:	8b 45 08             	mov    0x8(%ebp),%eax
    15d3:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
	return;
    15d9:	90                   	nop
}
    15da:	5d                   	pop    %ebp
    15db:	c3                   	ret    

000015dc <ck_ring_enqueue_spsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
    15dc:	55                   	push   %ebp
    15dd:	89 e5                	mov    %esp,%ebp
    15df:	83 ec 58             	sub    $0x58,%esp
    15e2:	8b 45 08             	mov    0x8(%ebp),%eax
    15e5:	89 45 f4             	mov    %eax,-0xc(%ebp)
    15e8:	8b 45 0c             	mov    0xc(%ebp),%eax
    15eb:	89 45 f0             	mov    %eax,-0x10(%ebp)
    15ee:	8d 45 10             	lea    0x10(%ebp),%eax
    15f1:	89 45 ec             	mov    %eax,-0x14(%ebp)
    15f4:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    15fb:	8b 45 14             	mov    0x14(%ebp),%eax
    15fe:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    1601:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1604:	89 45 e0             	mov    %eax,-0x20(%ebp)
    1607:	8b 45 f0             	mov    -0x10(%ebp),%eax
    160a:	89 45 dc             	mov    %eax,-0x24(%ebp)
    160d:	8b 45 ec             	mov    -0x14(%ebp),%eax
    1610:	89 45 d8             	mov    %eax,-0x28(%ebp)
    1613:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1616:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    1619:	8d 45 b8             	lea    -0x48(%ebp),%eax
    161c:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    161f:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1622:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    1628:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    162b:	8b 45 e0             	mov    -0x20(%ebp),%eax
    162e:	89 04 24             	mov    %eax,(%esp)
    1631:	e8 b7 f1 ff ff       	call   7ed <ck_pr_md_load_uint>
    1636:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    1639:	8b 45 e0             	mov    -0x20(%ebp),%eax
    163c:	8b 40 40             	mov    0x40(%eax),%eax
    163f:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    1642:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    1645:	83 c0 01             	add    $0x1,%eax
    1648:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    164b:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    164f:	74 14                	je     1665 <ck_ring_enqueue_spsc_size+0x89>
		*size = (producer - consumer) & mask;
    1651:	8b 45 c8             	mov    -0x38(%ebp),%eax
    1654:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    1657:	29 c2                	sub    %eax,%edx
    1659:	89 d0                	mov    %edx,%eax
    165b:	23 45 cc             	and    -0x34(%ebp),%eax
    165e:	89 c2                	mov    %eax,%edx
    1660:	8b 45 d0             	mov    -0x30(%ebp),%eax
    1663:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    1665:	8b 45 c0             	mov    -0x40(%ebp),%eax
    1668:	8b 55 c8             	mov    -0x38(%ebp),%edx
    166b:	31 d0                	xor    %edx,%eax
    166d:	23 45 cc             	and    -0x34(%ebp),%eax
    1670:	85 c0                	test   %eax,%eax
    1672:	0f 94 c0             	sete   %al
    1675:	0f b6 c0             	movzbl %al,%eax
    1678:	85 c0                	test   %eax,%eax
    167a:	74 07                	je     1683 <ck_ring_enqueue_spsc_size+0xa7>
		return false;
    167c:	b8 00 00 00 00       	mov    $0x0,%eax
    1681:	eb 47                	jmp    16ca <ck_ring_enqueue_spsc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    1683:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    1686:	8b 55 cc             	mov    -0x34(%ebp),%edx
    1689:	21 d0                	and    %edx,%eax
    168b:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    168f:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    1692:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    1695:	89 44 24 08          	mov    %eax,0x8(%esp)
    1699:	8b 45 d8             	mov    -0x28(%ebp),%eax
    169c:	89 44 24 04          	mov    %eax,0x4(%esp)
    16a0:	8b 45 dc             	mov    -0x24(%ebp),%eax
    16a3:	89 04 24             	mov    %eax,(%esp)
    16a6:	e8 fc ff ff ff       	call   16a7 <ck_ring_enqueue_spsc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    16ab:	e8 53 fe ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    16b0:	8b 45 e0             	mov    -0x20(%ebp),%eax
    16b3:	8d 50 40             	lea    0x40(%eax),%edx
    16b6:	8b 45 c0             	mov    -0x40(%ebp),%eax
    16b9:	89 44 24 04          	mov    %eax,0x4(%esp)
    16bd:	89 14 24             	mov    %edx,(%esp)
    16c0:	e8 b1 f1 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    16c5:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    16ca:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    16cd:	8b 55 b8             	mov    -0x48(%ebp),%edx
    16d0:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    16d3:	89 10                	mov    %edx,(%eax)
	return r;
    16d5:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
    16d9:	c9                   	leave  
    16da:	c3                   	ret    

000016db <ck_ring_enqueue_spsc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
    16db:	55                   	push   %ebp
    16dc:	89 e5                	mov    %esp,%ebp
    16de:	83 ec 48             	sub    $0x48,%esp
    16e1:	8b 45 08             	mov    0x8(%ebp),%eax
    16e4:	89 45 f4             	mov    %eax,-0xc(%ebp)
    16e7:	8b 45 0c             	mov    0xc(%ebp),%eax
    16ea:	89 45 f0             	mov    %eax,-0x10(%ebp)
    16ed:	8d 45 10             	lea    0x10(%ebp),%eax
    16f0:	89 45 ec             	mov    %eax,-0x14(%ebp)
    16f3:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    16fa:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    1701:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1704:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    170a:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    170d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1710:	89 04 24             	mov    %eax,(%esp)
    1713:	e8 d5 f0 ff ff       	call   7ed <ck_pr_md_load_uint>
    1718:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    171b:	8b 45 f4             	mov    -0xc(%ebp),%eax
    171e:	8b 40 40             	mov    0x40(%eax),%eax
    1721:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    1724:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1727:	83 c0 01             	add    $0x1,%eax
    172a:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    172d:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    1731:	74 14                	je     1747 <ck_ring_enqueue_spsc+0x6c>
		*size = (producer - consumer) & mask;
    1733:	8b 45 dc             	mov    -0x24(%ebp),%eax
    1736:	8b 55 d8             	mov    -0x28(%ebp),%edx
    1739:	29 c2                	sub    %eax,%edx
    173b:	89 d0                	mov    %edx,%eax
    173d:	23 45 e0             	and    -0x20(%ebp),%eax
    1740:	89 c2                	mov    %eax,%edx
    1742:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    1745:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    1747:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    174a:	8b 55 dc             	mov    -0x24(%ebp),%edx
    174d:	31 d0                	xor    %edx,%eax
    174f:	23 45 e0             	and    -0x20(%ebp),%eax
    1752:	85 c0                	test   %eax,%eax
    1754:	0f 94 c0             	sete   %al
    1757:	0f b6 c0             	movzbl %al,%eax
    175a:	85 c0                	test   %eax,%eax
    175c:	74 07                	je     1765 <ck_ring_enqueue_spsc+0x8a>
		return false;
    175e:	b8 00 00 00 00       	mov    $0x0,%eax
    1763:	eb 47                	jmp    17ac <ck_ring_enqueue_spsc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    1765:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1768:	8b 55 e0             	mov    -0x20(%ebp),%edx
    176b:	21 d0                	and    %edx,%eax
    176d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    1771:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    1774:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1777:	89 44 24 08          	mov    %eax,0x8(%esp)
    177b:	8b 45 ec             	mov    -0x14(%ebp),%eax
    177e:	89 44 24 04          	mov    %eax,0x4(%esp)
    1782:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1785:	89 04 24             	mov    %eax,(%esp)
    1788:	e8 fc ff ff ff       	call   1789 <ck_ring_enqueue_spsc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    178d:	e8 71 fd ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    1792:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1795:	8d 50 40             	lea    0x40(%eax),%edx
    1798:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    179b:	89 44 24 04          	mov    %eax,0x4(%esp)
    179f:	89 14 24             	mov    %edx,(%esp)
    17a2:	e8 cf f0 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    17a7:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer,
	    &entry, sizeof(entry), NULL);
}
    17ac:	c9                   	leave  
    17ad:	c3                   	ret    

000017ae <ck_ring_dequeue_spsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    17ae:	55                   	push   %ebp
    17af:	89 e5                	mov    %esp,%ebp
    17b1:	83 ec 38             	sub    $0x38,%esp
    17b4:	8b 45 08             	mov    0x8(%ebp),%eax
    17b7:	89 45 f4             	mov    %eax,-0xc(%ebp)
    17ba:	8b 45 0c             	mov    0xc(%ebp),%eax
    17bd:	89 45 f0             	mov    %eax,-0x10(%ebp)
    17c0:	8b 45 10             	mov    0x10(%ebp),%eax
    17c3:	89 45 ec             	mov    %eax,-0x14(%ebp)
    17c6:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    17cd:	8b 45 f4             	mov    -0xc(%ebp),%eax
    17d0:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    17d6:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    17d9:	8b 45 f4             	mov    -0xc(%ebp),%eax
    17dc:	8b 00                	mov    (%eax),%eax
    17de:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    17e1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    17e4:	83 c0 40             	add    $0x40,%eax
    17e7:	89 04 24             	mov    %eax,(%esp)
    17ea:	e8 fe ef ff ff       	call   7ed <ck_pr_md_load_uint>
    17ef:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    17f2:	8b 45 e0             	mov    -0x20(%ebp),%eax
    17f5:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    17f8:	0f 94 c0             	sete   %al
    17fb:	0f b6 c0             	movzbl %al,%eax
    17fe:	85 c0                	test   %eax,%eax
    1800:	74 07                	je     1809 <ck_ring_dequeue_spsc+0x5b>
		return false;
    1802:	b8 00 00 00 00       	mov    $0x0,%eax
    1807:	eb 4c                	jmp    1855 <ck_ring_dequeue_spsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    1809:	e8 ea fc ff ff       	call   14f8 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    180e:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1811:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    1814:	21 d0                	and    %edx,%eax
    1816:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    181a:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    181d:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1820:	89 44 24 08          	mov    %eax,0x8(%esp)
    1824:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1827:	89 44 24 04          	mov    %eax,0x4(%esp)
    182b:	8b 45 ec             	mov    -0x14(%ebp),%eax
    182e:	89 04 24             	mov    %eax,(%esp)
    1831:	e8 fc ff ff ff       	call   1832 <ck_ring_dequeue_spsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    1836:	e8 c8 fc ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    183b:	8b 45 e0             	mov    -0x20(%ebp),%eax
    183e:	8d 50 01             	lea    0x1(%eax),%edx
    1841:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1844:	89 54 24 04          	mov    %edx,0x4(%esp)
    1848:	89 04 24             	mov    %eax,(%esp)
    184b:	e8 26 f0 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    1850:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer,
	    (void **)data, sizeof(void *));
}
    1855:	c9                   	leave  
    1856:	c3                   	ret    

00001857 <ck_ring_enqueue_mpmc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
    1857:	55                   	push   %ebp
    1858:	89 e5                	mov    %esp,%ebp
    185a:	83 ec 48             	sub    $0x48,%esp
    185d:	8b 45 08             	mov    0x8(%ebp),%eax
    1860:	89 45 f4             	mov    %eax,-0xc(%ebp)
    1863:	8b 45 0c             	mov    0xc(%ebp),%eax
    1866:	89 45 f0             	mov    %eax,-0x10(%ebp)
    1869:	8d 45 10             	lea    0x10(%ebp),%eax
    186c:	89 45 ec             	mov    %eax,-0x14(%ebp)
    186f:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    1876:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    187d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1880:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    1886:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    1889:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    188d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1890:	83 c0 44             	add    $0x44,%eax
    1893:	89 04 24             	mov    %eax,(%esp)
    1896:	e8 52 ef ff ff       	call   7ed <ck_pr_md_load_uint>
    189b:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    189e:	e8 55 fc ff ff       	call   14f8 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    18a3:	8b 45 f4             	mov    -0xc(%ebp),%eax
    18a6:	89 04 24             	mov    %eax,(%esp)
    18a9:	e8 3f ef ff ff       	call   7ed <ck_pr_md_load_uint>
    18ae:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    18b1:	8b 45 cc             	mov    -0x34(%ebp),%eax
    18b4:	83 c0 01             	add    $0x1,%eax
    18b7:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    18ba:	8b 45 cc             	mov    -0x34(%ebp),%eax
    18bd:	2b 45 d8             	sub    -0x28(%ebp),%eax
    18c0:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    18c3:	0f 97 c0             	seta   %al
    18c6:	0f b6 c0             	movzbl %al,%eax
    18c9:	85 c0                	test   %eax,%eax
    18cb:	74 29                	je     18f6 <ck_ring_enqueue_mpmc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    18cd:	8b 45 cc             	mov    -0x34(%ebp),%eax
    18d0:	8b 55 f4             	mov    -0xc(%ebp),%edx
    18d3:	8d 4a 44             	lea    0x44(%edx),%ecx
    18d6:	8d 55 cc             	lea    -0x34(%ebp),%edx
    18d9:	89 54 24 0c          	mov    %edx,0xc(%esp)
    18dd:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    18e0:	89 54 24 08          	mov    %edx,0x8(%esp)
    18e4:	89 44 24 04          	mov    %eax,0x4(%esp)
    18e8:	89 0c 24             	mov    %ecx,(%esp)
    18eb:	e8 fe f8 ff ff       	call   11ee <ck_pr_cas_uint_value>
    18f0:	84 c0                	test   %al,%al
    18f2:	75 31                	jne    1925 <ck_ring_enqueue_mpmc+0xce>
    18f4:	eb a8                	jmp    189e <ck_ring_enqueue_mpmc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    18f6:	e8 fd fb ff ff       	call   14f8 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    18fb:	8b 45 f4             	mov    -0xc(%ebp),%eax
    18fe:	83 c0 44             	add    $0x44,%eax
    1901:	89 04 24             	mov    %eax,(%esp)
    1904:	e8 e4 ee ff ff       	call   7ed <ck_pr_md_load_uint>
    1909:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    190c:	8b 45 cc             	mov    -0x34(%ebp),%eax
    190f:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    1912:	75 06                	jne    191a <ck_ring_enqueue_mpmc+0xc3>
				r = false;
    1914:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    1918:	eb 67                	jmp    1981 <ck_ring_enqueue_mpmc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    191a:	8b 45 d0             	mov    -0x30(%ebp),%eax
    191d:	89 45 cc             	mov    %eax,-0x34(%ebp)
    1920:	e9 79 ff ff ff       	jmp    189e <ck_ring_enqueue_mpmc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    1925:	8b 45 cc             	mov    -0x34(%ebp),%eax
    1928:	23 45 e0             	and    -0x20(%ebp),%eax
    192b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    192f:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    1932:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1935:	89 44 24 08          	mov    %eax,0x8(%esp)
    1939:	8b 45 ec             	mov    -0x14(%ebp),%eax
    193c:	89 44 24 04          	mov    %eax,0x4(%esp)
    1940:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1943:	89 04 24             	mov    %eax,(%esp)
    1946:	e8 fc ff ff ff       	call   1947 <ck_ring_enqueue_mpmc+0xf0>
    194b:	eb 05                	jmp    1952 <ck_ring_enqueue_mpmc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    194d:	e8 36 ed ff ff       	call   688 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    1952:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1955:	83 c0 40             	add    $0x40,%eax
    1958:	89 04 24             	mov    %eax,(%esp)
    195b:	e8 8d ee ff ff       	call   7ed <ck_pr_md_load_uint>
    1960:	8b 55 cc             	mov    -0x34(%ebp),%edx
    1963:	39 d0                	cmp    %edx,%eax
    1965:	75 e6                	jne    194d <ck_ring_enqueue_mpmc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    1967:	e8 97 fb ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    196c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    196f:	8d 50 40             	lea    0x40(%eax),%edx
    1972:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    1975:	89 44 24 04          	mov    %eax,0x4(%esp)
    1979:	89 14 24             	mov    %edx,(%esp)
    197c:	e8 f5 ee ff ff       	call   876 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    1981:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    1985:	74 10                	je     1997 <ck_ring_enqueue_mpmc+0x140>
		*size = (producer - consumer) & mask;
    1987:	8b 45 cc             	mov    -0x34(%ebp),%eax
    198a:	2b 45 d8             	sub    -0x28(%ebp),%eax
    198d:	23 45 e0             	and    -0x20(%ebp),%eax
    1990:	89 c2                	mov    %eax,%edx
    1992:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    1995:	89 10                	mov    %edx,(%eax)

	return r;
    1997:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
    199b:	c9                   	leave  
    199c:	c3                   	ret    

0000199d <ck_ring_enqueue_mpmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
    199d:	55                   	push   %ebp
    199e:	89 e5                	mov    %esp,%ebp
    19a0:	83 ec 68             	sub    $0x68,%esp
    19a3:	8b 45 08             	mov    0x8(%ebp),%eax
    19a6:	89 45 f4             	mov    %eax,-0xc(%ebp)
    19a9:	8b 45 0c             	mov    0xc(%ebp),%eax
    19ac:	89 45 f0             	mov    %eax,-0x10(%ebp)
    19af:	8d 45 10             	lea    0x10(%ebp),%eax
    19b2:	89 45 ec             	mov    %eax,-0x14(%ebp)
    19b5:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    19bc:	8b 45 14             	mov    0x14(%ebp),%eax
    19bf:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    19c2:	8b 45 f4             	mov    -0xc(%ebp),%eax
    19c5:	89 45 e0             	mov    %eax,-0x20(%ebp)
    19c8:	8b 45 f0             	mov    -0x10(%ebp),%eax
    19cb:	89 45 dc             	mov    %eax,-0x24(%ebp)
    19ce:	8b 45 ec             	mov    -0x14(%ebp),%eax
    19d1:	89 45 d8             	mov    %eax,-0x28(%ebp)
    19d4:	8b 45 e8             	mov    -0x18(%ebp),%eax
    19d7:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    19da:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    19dd:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    19e0:	8b 45 e0             	mov    -0x20(%ebp),%eax
    19e3:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    19e9:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    19ec:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    19f0:	8b 45 e0             	mov    -0x20(%ebp),%eax
    19f3:	83 c0 44             	add    $0x44,%eax
    19f6:	89 04 24             	mov    %eax,(%esp)
    19f9:	e8 ef ed ff ff       	call   7ed <ck_pr_md_load_uint>
    19fe:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    1a01:	e8 f2 fa ff ff       	call   14f8 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    1a06:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1a09:	89 04 24             	mov    %eax,(%esp)
    1a0c:	e8 dc ed ff ff       	call   7ed <ck_pr_md_load_uint>
    1a11:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    1a14:	8b 45 b0             	mov    -0x50(%ebp),%eax
    1a17:	83 c0 01             	add    $0x1,%eax
    1a1a:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    1a1d:	8b 45 b0             	mov    -0x50(%ebp),%eax
    1a20:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    1a23:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    1a26:	0f 97 c0             	seta   %al
    1a29:	0f b6 c0             	movzbl %al,%eax
    1a2c:	85 c0                	test   %eax,%eax
    1a2e:	74 29                	je     1a59 <ck_ring_enqueue_mpmc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    1a30:	8b 45 b0             	mov    -0x50(%ebp),%eax
    1a33:	8b 55 e0             	mov    -0x20(%ebp),%edx
    1a36:	8d 4a 44             	lea    0x44(%edx),%ecx
    1a39:	8d 55 b0             	lea    -0x50(%ebp),%edx
    1a3c:	89 54 24 0c          	mov    %edx,0xc(%esp)
    1a40:	8b 55 c0             	mov    -0x40(%ebp),%edx
    1a43:	89 54 24 08          	mov    %edx,0x8(%esp)
    1a47:	89 44 24 04          	mov    %eax,0x4(%esp)
    1a4b:	89 0c 24             	mov    %ecx,(%esp)
    1a4e:	e8 9b f7 ff ff       	call   11ee <ck_pr_cas_uint_value>
    1a53:	84 c0                	test   %al,%al
    1a55:	75 31                	jne    1a88 <ck_ring_enqueue_mpmc_size+0xeb>
    1a57:	eb a8                	jmp    1a01 <ck_ring_enqueue_mpmc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    1a59:	e8 9a fa ff ff       	call   14f8 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    1a5e:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1a61:	83 c0 44             	add    $0x44,%eax
    1a64:	89 04 24             	mov    %eax,(%esp)
    1a67:	e8 81 ed ff ff       	call   7ed <ck_pr_md_load_uint>
    1a6c:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    1a6f:	8b 45 b0             	mov    -0x50(%ebp),%eax
    1a72:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    1a75:	75 06                	jne    1a7d <ck_ring_enqueue_mpmc_size+0xe0>
				r = false;
    1a77:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    1a7b:	eb 67                	jmp    1ae4 <ck_ring_enqueue_mpmc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    1a7d:	8b 45 bc             	mov    -0x44(%ebp),%eax
    1a80:	89 45 b0             	mov    %eax,-0x50(%ebp)
    1a83:	e9 79 ff ff ff       	jmp    1a01 <ck_ring_enqueue_mpmc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    1a88:	8b 45 b0             	mov    -0x50(%ebp),%eax
    1a8b:	23 45 cc             	and    -0x34(%ebp),%eax
    1a8e:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    1a92:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    1a95:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    1a98:	89 44 24 08          	mov    %eax,0x8(%esp)
    1a9c:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1a9f:	89 44 24 04          	mov    %eax,0x4(%esp)
    1aa3:	8b 45 dc             	mov    -0x24(%ebp),%eax
    1aa6:	89 04 24             	mov    %eax,(%esp)
    1aa9:	e8 fc ff ff ff       	call   1aaa <ck_ring_enqueue_mpmc_size+0x10d>
    1aae:	eb 05                	jmp    1ab5 <ck_ring_enqueue_mpmc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    1ab0:	e8 d3 eb ff ff       	call   688 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    1ab5:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1ab8:	83 c0 40             	add    $0x40,%eax
    1abb:	89 04 24             	mov    %eax,(%esp)
    1abe:	e8 2a ed ff ff       	call   7ed <ck_pr_md_load_uint>
    1ac3:	8b 55 b0             	mov    -0x50(%ebp),%edx
    1ac6:	39 d0                	cmp    %edx,%eax
    1ac8:	75 e6                	jne    1ab0 <ck_ring_enqueue_mpmc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    1aca:	e8 34 fa ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    1acf:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1ad2:	8d 50 40             	lea    0x40(%eax),%edx
    1ad5:	8b 45 c0             	mov    -0x40(%ebp),%eax
    1ad8:	89 44 24 04          	mov    %eax,0x4(%esp)
    1adc:	89 14 24             	mov    %edx,(%esp)
    1adf:	e8 92 ed ff ff       	call   876 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    1ae4:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    1ae8:	74 10                	je     1afa <ck_ring_enqueue_mpmc_size+0x15d>
		*size = (producer - consumer) & mask;
    1aea:	8b 45 b0             	mov    -0x50(%ebp),%eax
    1aed:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    1af0:	23 45 cc             	and    -0x34(%ebp),%eax
    1af3:	89 c2                	mov    %eax,%edx
    1af5:	8b 45 d0             	mov    -0x30(%ebp),%eax
    1af8:	89 10                	mov    %edx,(%eax)

	return r;
    1afa:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    1afe:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    1b01:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    1b04:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    1b07:	89 10                	mov    %edx,(%eax)
	return r;
    1b09:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
    1b0d:	c9                   	leave  
    1b0e:	c3                   	ret    

00001b0f <ck_ring_trydequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    1b0f:	55                   	push   %ebp
    1b10:	89 e5                	mov    %esp,%ebp
    1b12:	83 ec 38             	sub    $0x38,%esp
    1b15:	8b 45 08             	mov    0x8(%ebp),%eax
    1b18:	89 45 f4             	mov    %eax,-0xc(%ebp)
    1b1b:	8b 45 0c             	mov    0xc(%ebp),%eax
    1b1e:	89 45 f0             	mov    %eax,-0x10(%ebp)
    1b21:	8b 45 10             	mov    0x10(%ebp),%eax
    1b24:	89 45 ec             	mov    %eax,-0x14(%ebp)
    1b27:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    1b2e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1b31:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    1b37:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    1b3a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1b3d:	89 04 24             	mov    %eax,(%esp)
    1b40:	e8 a8 ec ff ff       	call   7ed <ck_pr_md_load_uint>
    1b45:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    1b48:	e8 ab f9 ff ff       	call   14f8 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    1b4d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1b50:	83 c0 40             	add    $0x40,%eax
    1b53:	89 04 24             	mov    %eax,(%esp)
    1b56:	e8 92 ec ff ff       	call   7ed <ck_pr_md_load_uint>
    1b5b:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    1b5e:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1b61:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    1b64:	0f 94 c0             	sete   %al
    1b67:	0f b6 c0             	movzbl %al,%eax
    1b6a:	85 c0                	test   %eax,%eax
    1b6c:	74 07                	je     1b75 <ck_ring_trydequeue_mpmc+0x66>
		return false;
    1b6e:	b8 00 00 00 00       	mov    $0x0,%eax
    1b73:	eb 4e                	jmp    1bc3 <ck_ring_trydequeue_mpmc+0xb4>

	ck_pr_fence_load();
    1b75:	e8 7e f9 ff ff       	call   14f8 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    1b7a:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1b7d:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    1b80:	21 d0                	and    %edx,%eax
    1b82:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    1b86:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    1b89:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1b8c:	89 44 24 08          	mov    %eax,0x8(%esp)
    1b90:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1b93:	89 44 24 04          	mov    %eax,0x4(%esp)
    1b97:	8b 45 ec             	mov    -0x14(%ebp),%eax
    1b9a:	89 04 24             	mov    %eax,(%esp)
    1b9d:	e8 fc ff ff ff       	call   1b9e <ck_ring_trydequeue_mpmc+0x8f>

	ck_pr_fence_store_atomic();
    1ba2:	e8 25 f9 ff ff       	call   14cc <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    1ba7:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1baa:	8d 50 01             	lea    0x1(%eax),%edx
    1bad:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1bb0:	89 54 24 08          	mov    %edx,0x8(%esp)
    1bb4:	8b 55 e0             	mov    -0x20(%ebp),%edx
    1bb7:	89 54 24 04          	mov    %edx,0x4(%esp)
    1bbb:	89 04 24             	mov    %eax,(%esp)
    1bbe:	e8 d8 f4 ff ff       	call   109b <ck_pr_cas_uint>
    void *data)
{

	return _ck_ring_trydequeue_mc(ring,
	    buffer, (void **)data, sizeof(void *));
}
    1bc3:	c9                   	leave  
    1bc4:	c3                   	ret    

00001bc5 <ck_ring_dequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    1bc5:	55                   	push   %ebp
    1bc6:	89 e5                	mov    %esp,%ebp
    1bc8:	53                   	push   %ebx
    1bc9:	83 ec 34             	sub    $0x34,%esp
    1bcc:	8b 45 08             	mov    0x8(%ebp),%eax
    1bcf:	89 45 f4             	mov    %eax,-0xc(%ebp)
    1bd2:	8b 45 0c             	mov    0xc(%ebp),%eax
    1bd5:	89 45 f0             	mov    %eax,-0x10(%ebp)
    1bd8:	8b 45 10             	mov    0x10(%ebp),%eax
    1bdb:	89 45 ec             	mov    %eax,-0x14(%ebp)
    1bde:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    1be5:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1be8:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    1bee:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    1bf1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1bf4:	89 04 24             	mov    %eax,(%esp)
    1bf7:	e8 f1 eb ff ff       	call   7ed <ck_pr_md_load_uint>
    1bfc:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    1bff:	e8 f4 f8 ff ff       	call   14f8 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    1c04:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1c07:	83 c0 40             	add    $0x40,%eax
    1c0a:	89 04 24             	mov    %eax,(%esp)
    1c0d:	e8 db eb ff ff       	call   7ed <ck_pr_md_load_uint>
    1c12:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    1c15:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1c18:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    1c1b:	0f 94 c0             	sete   %al
    1c1e:	0f b6 c0             	movzbl %al,%eax
    1c21:	85 c0                	test   %eax,%eax
    1c23:	74 07                	je     1c2c <ck_ring_dequeue_mpmc+0x67>
			return false;
    1c25:	b8 00 00 00 00       	mov    $0x0,%eax
    1c2a:	eb 6a                	jmp    1c96 <ck_ring_dequeue_mpmc+0xd1>

		ck_pr_fence_load();
    1c2c:	e8 c7 f8 ff ff       	call   14f8 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    1c31:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1c34:	23 45 e4             	and    -0x1c(%ebp),%eax
    1c37:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    1c3b:	89 c2                	mov    %eax,%edx
    1c3d:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1c40:	01 d0                	add    %edx,%eax
    1c42:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    1c45:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1c48:	89 44 24 08          	mov    %eax,0x8(%esp)
    1c4c:	8b 45 dc             	mov    -0x24(%ebp),%eax
    1c4f:	89 44 24 04          	mov    %eax,0x4(%esp)
    1c53:	8b 45 ec             	mov    -0x14(%ebp),%eax
    1c56:	89 04 24             	mov    %eax,(%esp)
    1c59:	e8 fc ff ff ff       	call   1c5a <ck_ring_dequeue_mpmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    1c5e:	e8 69 f8 ff ff       	call   14cc <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    1c63:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1c66:	8d 58 01             	lea    0x1(%eax),%ebx
    1c69:	8b 55 d8             	mov    -0x28(%ebp),%edx
    1c6c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1c6f:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    1c72:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    1c76:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    1c7a:	89 54 24 04          	mov    %edx,0x4(%esp)
    1c7e:	89 04 24             	mov    %eax,(%esp)
    1c81:	e8 68 f5 ff ff       	call   11ee <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    1c86:	83 f0 01             	xor    $0x1,%eax
    1c89:	84 c0                	test   %al,%al
    1c8b:	0f 85 6e ff ff ff    	jne    1bff <ck_ring_dequeue_mpmc+0x3a>

	return true;
    1c91:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data,
	    sizeof(void *));
}
    1c96:	83 c4 34             	add    $0x34,%esp
    1c99:	5b                   	pop    %ebx
    1c9a:	5d                   	pop    %ebp
    1c9b:	c3                   	ret    

00001c9c <ck_ring_enqueue_spmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
    1c9c:	55                   	push   %ebp
    1c9d:	89 e5                	mov    %esp,%ebp
    1c9f:	83 ec 58             	sub    $0x58,%esp
    1ca2:	8b 45 08             	mov    0x8(%ebp),%eax
    1ca5:	89 45 f4             	mov    %eax,-0xc(%ebp)
    1ca8:	8b 45 0c             	mov    0xc(%ebp),%eax
    1cab:	89 45 f0             	mov    %eax,-0x10(%ebp)
    1cae:	8d 45 10             	lea    0x10(%ebp),%eax
    1cb1:	89 45 ec             	mov    %eax,-0x14(%ebp)
    1cb4:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    1cbb:	8b 45 14             	mov    0x14(%ebp),%eax
    1cbe:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    1cc1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1cc4:	89 45 e0             	mov    %eax,-0x20(%ebp)
    1cc7:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1cca:	89 45 dc             	mov    %eax,-0x24(%ebp)
    1ccd:	8b 45 ec             	mov    -0x14(%ebp),%eax
    1cd0:	89 45 d8             	mov    %eax,-0x28(%ebp)
    1cd3:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1cd6:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    1cd9:	8d 45 b8             	lea    -0x48(%ebp),%eax
    1cdc:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    1cdf:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1ce2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    1ce8:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    1ceb:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1cee:	89 04 24             	mov    %eax,(%esp)
    1cf1:	e8 f7 ea ff ff       	call   7ed <ck_pr_md_load_uint>
    1cf6:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    1cf9:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1cfc:	8b 40 40             	mov    0x40(%eax),%eax
    1cff:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    1d02:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    1d05:	83 c0 01             	add    $0x1,%eax
    1d08:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    1d0b:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    1d0f:	74 14                	je     1d25 <ck_ring_enqueue_spmc_size+0x89>
		*size = (producer - consumer) & mask;
    1d11:	8b 45 c8             	mov    -0x38(%ebp),%eax
    1d14:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    1d17:	29 c2                	sub    %eax,%edx
    1d19:	89 d0                	mov    %edx,%eax
    1d1b:	23 45 cc             	and    -0x34(%ebp),%eax
    1d1e:	89 c2                	mov    %eax,%edx
    1d20:	8b 45 d0             	mov    -0x30(%ebp),%eax
    1d23:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    1d25:	8b 45 c0             	mov    -0x40(%ebp),%eax
    1d28:	8b 55 c8             	mov    -0x38(%ebp),%edx
    1d2b:	31 d0                	xor    %edx,%eax
    1d2d:	23 45 cc             	and    -0x34(%ebp),%eax
    1d30:	85 c0                	test   %eax,%eax
    1d32:	0f 94 c0             	sete   %al
    1d35:	0f b6 c0             	movzbl %al,%eax
    1d38:	85 c0                	test   %eax,%eax
    1d3a:	74 07                	je     1d43 <ck_ring_enqueue_spmc_size+0xa7>
		return false;
    1d3c:	b8 00 00 00 00       	mov    $0x0,%eax
    1d41:	eb 47                	jmp    1d8a <ck_ring_enqueue_spmc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    1d43:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    1d46:	8b 55 cc             	mov    -0x34(%ebp),%edx
    1d49:	21 d0                	and    %edx,%eax
    1d4b:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    1d4f:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    1d52:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    1d55:	89 44 24 08          	mov    %eax,0x8(%esp)
    1d59:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1d5c:	89 44 24 04          	mov    %eax,0x4(%esp)
    1d60:	8b 45 dc             	mov    -0x24(%ebp),%eax
    1d63:	89 04 24             	mov    %eax,(%esp)
    1d66:	e8 fc ff ff ff       	call   1d67 <ck_ring_enqueue_spmc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    1d6b:	e8 93 f7 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    1d70:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1d73:	8d 50 40             	lea    0x40(%eax),%edx
    1d76:	8b 45 c0             	mov    -0x40(%ebp),%eax
    1d79:	89 44 24 04          	mov    %eax,0x4(%esp)
    1d7d:	89 14 24             	mov    %edx,(%esp)
    1d80:	e8 f1 ea ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    1d85:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    1d8a:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    1d8d:	8b 55 b8             	mov    -0x48(%ebp),%edx
    1d90:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    1d93:	89 10                	mov    %edx,(%eax)
	return r;
    1d95:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
    1d99:	c9                   	leave  
    1d9a:	c3                   	ret    

00001d9b <ck_ring_enqueue_spmc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
    1d9b:	55                   	push   %ebp
    1d9c:	89 e5                	mov    %esp,%ebp
    1d9e:	83 ec 48             	sub    $0x48,%esp
    1da1:	8b 45 08             	mov    0x8(%ebp),%eax
    1da4:	89 45 f4             	mov    %eax,-0xc(%ebp)
    1da7:	8b 45 0c             	mov    0xc(%ebp),%eax
    1daa:	89 45 f0             	mov    %eax,-0x10(%ebp)
    1dad:	8d 45 10             	lea    0x10(%ebp),%eax
    1db0:	89 45 ec             	mov    %eax,-0x14(%ebp)
    1db3:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    1dba:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    1dc1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1dc4:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    1dca:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    1dcd:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1dd0:	89 04 24             	mov    %eax,(%esp)
    1dd3:	e8 15 ea ff ff       	call   7ed <ck_pr_md_load_uint>
    1dd8:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    1ddb:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1dde:	8b 40 40             	mov    0x40(%eax),%eax
    1de1:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    1de4:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1de7:	83 c0 01             	add    $0x1,%eax
    1dea:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    1ded:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    1df1:	74 14                	je     1e07 <ck_ring_enqueue_spmc+0x6c>
		*size = (producer - consumer) & mask;
    1df3:	8b 45 dc             	mov    -0x24(%ebp),%eax
    1df6:	8b 55 d8             	mov    -0x28(%ebp),%edx
    1df9:	29 c2                	sub    %eax,%edx
    1dfb:	89 d0                	mov    %edx,%eax
    1dfd:	23 45 e0             	and    -0x20(%ebp),%eax
    1e00:	89 c2                	mov    %eax,%edx
    1e02:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    1e05:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    1e07:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    1e0a:	8b 55 dc             	mov    -0x24(%ebp),%edx
    1e0d:	31 d0                	xor    %edx,%eax
    1e0f:	23 45 e0             	and    -0x20(%ebp),%eax
    1e12:	85 c0                	test   %eax,%eax
    1e14:	0f 94 c0             	sete   %al
    1e17:	0f b6 c0             	movzbl %al,%eax
    1e1a:	85 c0                	test   %eax,%eax
    1e1c:	74 07                	je     1e25 <ck_ring_enqueue_spmc+0x8a>
		return false;
    1e1e:	b8 00 00 00 00       	mov    $0x0,%eax
    1e23:	eb 47                	jmp    1e6c <ck_ring_enqueue_spmc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    1e25:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1e28:	8b 55 e0             	mov    -0x20(%ebp),%edx
    1e2b:	21 d0                	and    %edx,%eax
    1e2d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    1e31:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    1e34:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1e37:	89 44 24 08          	mov    %eax,0x8(%esp)
    1e3b:	8b 45 ec             	mov    -0x14(%ebp),%eax
    1e3e:	89 44 24 04          	mov    %eax,0x4(%esp)
    1e42:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1e45:	89 04 24             	mov    %eax,(%esp)
    1e48:	e8 fc ff ff ff       	call   1e49 <ck_ring_enqueue_spmc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    1e4d:	e8 b1 f6 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    1e52:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1e55:	8d 50 40             	lea    0x40(%eax),%edx
    1e58:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    1e5b:	89 44 24 04          	mov    %eax,0x4(%esp)
    1e5f:	89 14 24             	mov    %edx,(%esp)
    1e62:	e8 0f ea ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    1e67:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
    1e6c:	c9                   	leave  
    1e6d:	c3                   	ret    

00001e6e <ck_ring_trydequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    1e6e:	55                   	push   %ebp
    1e6f:	89 e5                	mov    %esp,%ebp
    1e71:	83 ec 38             	sub    $0x38,%esp
    1e74:	8b 45 08             	mov    0x8(%ebp),%eax
    1e77:	89 45 f4             	mov    %eax,-0xc(%ebp)
    1e7a:	8b 45 0c             	mov    0xc(%ebp),%eax
    1e7d:	89 45 f0             	mov    %eax,-0x10(%ebp)
    1e80:	8b 45 10             	mov    0x10(%ebp),%eax
    1e83:	89 45 ec             	mov    %eax,-0x14(%ebp)
    1e86:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    1e8d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1e90:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    1e96:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    1e99:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1e9c:	89 04 24             	mov    %eax,(%esp)
    1e9f:	e8 49 e9 ff ff       	call   7ed <ck_pr_md_load_uint>
    1ea4:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    1ea7:	e8 4c f6 ff ff       	call   14f8 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    1eac:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1eaf:	83 c0 40             	add    $0x40,%eax
    1eb2:	89 04 24             	mov    %eax,(%esp)
    1eb5:	e8 33 e9 ff ff       	call   7ed <ck_pr_md_load_uint>
    1eba:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    1ebd:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1ec0:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    1ec3:	0f 94 c0             	sete   %al
    1ec6:	0f b6 c0             	movzbl %al,%eax
    1ec9:	85 c0                	test   %eax,%eax
    1ecb:	74 07                	je     1ed4 <ck_ring_trydequeue_spmc+0x66>
		return false;
    1ecd:	b8 00 00 00 00       	mov    $0x0,%eax
    1ed2:	eb 4e                	jmp    1f22 <ck_ring_trydequeue_spmc+0xb4>

	ck_pr_fence_load();
    1ed4:	e8 1f f6 ff ff       	call   14f8 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    1ed9:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1edc:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    1edf:	21 d0                	and    %edx,%eax
    1ee1:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    1ee5:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    1ee8:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1eeb:	89 44 24 08          	mov    %eax,0x8(%esp)
    1eef:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1ef2:	89 44 24 04          	mov    %eax,0x4(%esp)
    1ef6:	8b 45 ec             	mov    -0x14(%ebp),%eax
    1ef9:	89 04 24             	mov    %eax,(%esp)
    1efc:	e8 fc ff ff ff       	call   1efd <ck_ring_trydequeue_spmc+0x8f>

	ck_pr_fence_store_atomic();
    1f01:	e8 c6 f5 ff ff       	call   14cc <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    1f06:	8b 45 e0             	mov    -0x20(%ebp),%eax
    1f09:	8d 50 01             	lea    0x1(%eax),%edx
    1f0c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1f0f:	89 54 24 08          	mov    %edx,0x8(%esp)
    1f13:	8b 55 e0             	mov    -0x20(%ebp),%edx
    1f16:	89 54 24 04          	mov    %edx,0x4(%esp)
    1f1a:	89 04 24             	mov    %eax,(%esp)
    1f1d:	e8 79 f1 ff ff       	call   109b <ck_pr_cas_uint>
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_trydequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
    1f22:	c9                   	leave  
    1f23:	c3                   	ret    

00001f24 <ck_ring_dequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    1f24:	55                   	push   %ebp
    1f25:	89 e5                	mov    %esp,%ebp
    1f27:	53                   	push   %ebx
    1f28:	83 ec 34             	sub    $0x34,%esp
    1f2b:	8b 45 08             	mov    0x8(%ebp),%eax
    1f2e:	89 45 f4             	mov    %eax,-0xc(%ebp)
    1f31:	8b 45 0c             	mov    0xc(%ebp),%eax
    1f34:	89 45 f0             	mov    %eax,-0x10(%ebp)
    1f37:	8b 45 10             	mov    0x10(%ebp),%eax
    1f3a:	89 45 ec             	mov    %eax,-0x14(%ebp)
    1f3d:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    1f44:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1f47:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    1f4d:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    1f50:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1f53:	89 04 24             	mov    %eax,(%esp)
    1f56:	e8 92 e8 ff ff       	call   7ed <ck_pr_md_load_uint>
    1f5b:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    1f5e:	e8 95 f5 ff ff       	call   14f8 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    1f63:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1f66:	83 c0 40             	add    $0x40,%eax
    1f69:	89 04 24             	mov    %eax,(%esp)
    1f6c:	e8 7c e8 ff ff       	call   7ed <ck_pr_md_load_uint>
    1f71:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    1f74:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1f77:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    1f7a:	0f 94 c0             	sete   %al
    1f7d:	0f b6 c0             	movzbl %al,%eax
    1f80:	85 c0                	test   %eax,%eax
    1f82:	74 07                	je     1f8b <ck_ring_dequeue_spmc+0x67>
			return false;
    1f84:	b8 00 00 00 00       	mov    $0x0,%eax
    1f89:	eb 6a                	jmp    1ff5 <ck_ring_dequeue_spmc+0xd1>

		ck_pr_fence_load();
    1f8b:	e8 68 f5 ff ff       	call   14f8 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    1f90:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1f93:	23 45 e4             	and    -0x1c(%ebp),%eax
    1f96:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    1f9a:	89 c2                	mov    %eax,%edx
    1f9c:	8b 45 f0             	mov    -0x10(%ebp),%eax
    1f9f:	01 d0                	add    %edx,%eax
    1fa1:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    1fa4:	8b 45 e8             	mov    -0x18(%ebp),%eax
    1fa7:	89 44 24 08          	mov    %eax,0x8(%esp)
    1fab:	8b 45 dc             	mov    -0x24(%ebp),%eax
    1fae:	89 44 24 04          	mov    %eax,0x4(%esp)
    1fb2:	8b 45 ec             	mov    -0x14(%ebp),%eax
    1fb5:	89 04 24             	mov    %eax,(%esp)
    1fb8:	e8 fc ff ff ff       	call   1fb9 <ck_ring_dequeue_spmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    1fbd:	e8 0a f5 ff ff       	call   14cc <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    1fc2:	8b 45 d8             	mov    -0x28(%ebp),%eax
    1fc5:	8d 58 01             	lea    0x1(%eax),%ebx
    1fc8:	8b 55 d8             	mov    -0x28(%ebp),%edx
    1fcb:	8b 45 f4             	mov    -0xc(%ebp),%eax
    1fce:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    1fd1:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    1fd5:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    1fd9:	89 54 24 04          	mov    %edx,0x4(%esp)
    1fdd:	89 04 24             	mov    %eax,(%esp)
    1fe0:	e8 09 f2 ff ff       	call   11ee <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    1fe5:	83 f0 01             	xor    $0x1,%eax
    1fe8:	84 c0                	test   %al,%al
    1fea:	0f 85 6e ff ff ff    	jne    1f5e <ck_ring_dequeue_spmc+0x3a>

	return true;
    1ff0:	b8 01 00 00 00       	mov    $0x1,%eax
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
    1ff5:	83 c4 34             	add    $0x34,%esp
    1ff8:	5b                   	pop    %ebx
    1ff9:	5d                   	pop    %ebp
    1ffa:	c3                   	ret    

00001ffb <ck_ring_enqueue_mpsc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
    1ffb:	55                   	push   %ebp
    1ffc:	89 e5                	mov    %esp,%ebp
    1ffe:	83 ec 48             	sub    $0x48,%esp
    2001:	8b 45 08             	mov    0x8(%ebp),%eax
    2004:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2007:	8b 45 0c             	mov    0xc(%ebp),%eax
    200a:	89 45 f0             	mov    %eax,-0x10(%ebp)
    200d:	8d 45 10             	lea    0x10(%ebp),%eax
    2010:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2013:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    201a:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    2021:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2024:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    202a:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    202d:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    2031:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2034:	83 c0 44             	add    $0x44,%eax
    2037:	89 04 24             	mov    %eax,(%esp)
    203a:	e8 ae e7 ff ff       	call   7ed <ck_pr_md_load_uint>
    203f:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    2042:	e8 b1 f4 ff ff       	call   14f8 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    2047:	8b 45 f4             	mov    -0xc(%ebp),%eax
    204a:	89 04 24             	mov    %eax,(%esp)
    204d:	e8 9b e7 ff ff       	call   7ed <ck_pr_md_load_uint>
    2052:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    2055:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2058:	83 c0 01             	add    $0x1,%eax
    205b:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    205e:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2061:	2b 45 d8             	sub    -0x28(%ebp),%eax
    2064:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    2067:	0f 97 c0             	seta   %al
    206a:	0f b6 c0             	movzbl %al,%eax
    206d:	85 c0                	test   %eax,%eax
    206f:	74 29                	je     209a <ck_ring_enqueue_mpsc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    2071:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2074:	8b 55 f4             	mov    -0xc(%ebp),%edx
    2077:	8d 4a 44             	lea    0x44(%edx),%ecx
    207a:	8d 55 cc             	lea    -0x34(%ebp),%edx
    207d:	89 54 24 0c          	mov    %edx,0xc(%esp)
    2081:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    2084:	89 54 24 08          	mov    %edx,0x8(%esp)
    2088:	89 44 24 04          	mov    %eax,0x4(%esp)
    208c:	89 0c 24             	mov    %ecx,(%esp)
    208f:	e8 5a f1 ff ff       	call   11ee <ck_pr_cas_uint_value>
    2094:	84 c0                	test   %al,%al
    2096:	75 31                	jne    20c9 <ck_ring_enqueue_mpsc+0xce>
    2098:	eb a8                	jmp    2042 <ck_ring_enqueue_mpsc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    209a:	e8 59 f4 ff ff       	call   14f8 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    209f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    20a2:	83 c0 44             	add    $0x44,%eax
    20a5:	89 04 24             	mov    %eax,(%esp)
    20a8:	e8 40 e7 ff ff       	call   7ed <ck_pr_md_load_uint>
    20ad:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    20b0:	8b 45 cc             	mov    -0x34(%ebp),%eax
    20b3:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    20b6:	75 06                	jne    20be <ck_ring_enqueue_mpsc+0xc3>
				r = false;
    20b8:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    20bc:	eb 67                	jmp    2125 <ck_ring_enqueue_mpsc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    20be:	8b 45 d0             	mov    -0x30(%ebp),%eax
    20c1:	89 45 cc             	mov    %eax,-0x34(%ebp)
    20c4:	e9 79 ff ff ff       	jmp    2042 <ck_ring_enqueue_mpsc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    20c9:	8b 45 cc             	mov    -0x34(%ebp),%eax
    20cc:	23 45 e0             	and    -0x20(%ebp),%eax
    20cf:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    20d3:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    20d6:	8b 45 e8             	mov    -0x18(%ebp),%eax
    20d9:	89 44 24 08          	mov    %eax,0x8(%esp)
    20dd:	8b 45 ec             	mov    -0x14(%ebp),%eax
    20e0:	89 44 24 04          	mov    %eax,0x4(%esp)
    20e4:	8b 45 f0             	mov    -0x10(%ebp),%eax
    20e7:	89 04 24             	mov    %eax,(%esp)
    20ea:	e8 fc ff ff ff       	call   20eb <ck_ring_enqueue_mpsc+0xf0>
    20ef:	eb 05                	jmp    20f6 <ck_ring_enqueue_mpsc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    20f1:	e8 92 e5 ff ff       	call   688 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    20f6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    20f9:	83 c0 40             	add    $0x40,%eax
    20fc:	89 04 24             	mov    %eax,(%esp)
    20ff:	e8 e9 e6 ff ff       	call   7ed <ck_pr_md_load_uint>
    2104:	8b 55 cc             	mov    -0x34(%ebp),%edx
    2107:	39 d0                	cmp    %edx,%eax
    2109:	75 e6                	jne    20f1 <ck_ring_enqueue_mpsc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    210b:	e8 f3 f3 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    2110:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2113:	8d 50 40             	lea    0x40(%eax),%edx
    2116:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2119:	89 44 24 04          	mov    %eax,0x4(%esp)
    211d:	89 14 24             	mov    %edx,(%esp)
    2120:	e8 51 e7 ff ff       	call   876 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    2125:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    2129:	74 10                	je     213b <ck_ring_enqueue_mpsc+0x140>
		*size = (producer - consumer) & mask;
    212b:	8b 45 cc             	mov    -0x34(%ebp),%eax
    212e:	2b 45 d8             	sub    -0x28(%ebp),%eax
    2131:	23 45 e0             	and    -0x20(%ebp),%eax
    2134:	89 c2                	mov    %eax,%edx
    2136:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    2139:	89 10                	mov    %edx,(%eax)

	return r;
    213b:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
    213f:	c9                   	leave  
    2140:	c3                   	ret    

00002141 <ck_ring_enqueue_mpsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
    2141:	55                   	push   %ebp
    2142:	89 e5                	mov    %esp,%ebp
    2144:	83 ec 68             	sub    $0x68,%esp
    2147:	8b 45 08             	mov    0x8(%ebp),%eax
    214a:	89 45 f4             	mov    %eax,-0xc(%ebp)
    214d:	8b 45 0c             	mov    0xc(%ebp),%eax
    2150:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2153:	8d 45 10             	lea    0x10(%ebp),%eax
    2156:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2159:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    2160:	8b 45 14             	mov    0x14(%ebp),%eax
    2163:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    2166:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2169:	89 45 e0             	mov    %eax,-0x20(%ebp)
    216c:	8b 45 f0             	mov    -0x10(%ebp),%eax
    216f:	89 45 dc             	mov    %eax,-0x24(%ebp)
    2172:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2175:	89 45 d8             	mov    %eax,-0x28(%ebp)
    2178:	8b 45 e8             	mov    -0x18(%ebp),%eax
    217b:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    217e:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    2181:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    2184:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2187:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    218d:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    2190:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    2194:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2197:	83 c0 44             	add    $0x44,%eax
    219a:	89 04 24             	mov    %eax,(%esp)
    219d:	e8 4b e6 ff ff       	call   7ed <ck_pr_md_load_uint>
    21a2:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    21a5:	e8 4e f3 ff ff       	call   14f8 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    21aa:	8b 45 e0             	mov    -0x20(%ebp),%eax
    21ad:	89 04 24             	mov    %eax,(%esp)
    21b0:	e8 38 e6 ff ff       	call   7ed <ck_pr_md_load_uint>
    21b5:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    21b8:	8b 45 b0             	mov    -0x50(%ebp),%eax
    21bb:	83 c0 01             	add    $0x1,%eax
    21be:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    21c1:	8b 45 b0             	mov    -0x50(%ebp),%eax
    21c4:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    21c7:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    21ca:	0f 97 c0             	seta   %al
    21cd:	0f b6 c0             	movzbl %al,%eax
    21d0:	85 c0                	test   %eax,%eax
    21d2:	74 29                	je     21fd <ck_ring_enqueue_mpsc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    21d4:	8b 45 b0             	mov    -0x50(%ebp),%eax
    21d7:	8b 55 e0             	mov    -0x20(%ebp),%edx
    21da:	8d 4a 44             	lea    0x44(%edx),%ecx
    21dd:	8d 55 b0             	lea    -0x50(%ebp),%edx
    21e0:	89 54 24 0c          	mov    %edx,0xc(%esp)
    21e4:	8b 55 c0             	mov    -0x40(%ebp),%edx
    21e7:	89 54 24 08          	mov    %edx,0x8(%esp)
    21eb:	89 44 24 04          	mov    %eax,0x4(%esp)
    21ef:	89 0c 24             	mov    %ecx,(%esp)
    21f2:	e8 f7 ef ff ff       	call   11ee <ck_pr_cas_uint_value>
    21f7:	84 c0                	test   %al,%al
    21f9:	75 31                	jne    222c <ck_ring_enqueue_mpsc_size+0xeb>
    21fb:	eb a8                	jmp    21a5 <ck_ring_enqueue_mpsc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    21fd:	e8 f6 f2 ff ff       	call   14f8 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    2202:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2205:	83 c0 44             	add    $0x44,%eax
    2208:	89 04 24             	mov    %eax,(%esp)
    220b:	e8 dd e5 ff ff       	call   7ed <ck_pr_md_load_uint>
    2210:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    2213:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2216:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    2219:	75 06                	jne    2221 <ck_ring_enqueue_mpsc_size+0xe0>
				r = false;
    221b:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    221f:	eb 67                	jmp    2288 <ck_ring_enqueue_mpsc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    2221:	8b 45 bc             	mov    -0x44(%ebp),%eax
    2224:	89 45 b0             	mov    %eax,-0x50(%ebp)
    2227:	e9 79 ff ff ff       	jmp    21a5 <ck_ring_enqueue_mpsc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    222c:	8b 45 b0             	mov    -0x50(%ebp),%eax
    222f:	23 45 cc             	and    -0x34(%ebp),%eax
    2232:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    2236:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    2239:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    223c:	89 44 24 08          	mov    %eax,0x8(%esp)
    2240:	8b 45 d8             	mov    -0x28(%ebp),%eax
    2243:	89 44 24 04          	mov    %eax,0x4(%esp)
    2247:	8b 45 dc             	mov    -0x24(%ebp),%eax
    224a:	89 04 24             	mov    %eax,(%esp)
    224d:	e8 fc ff ff ff       	call   224e <ck_ring_enqueue_mpsc_size+0x10d>
    2252:	eb 05                	jmp    2259 <ck_ring_enqueue_mpsc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    2254:	e8 2f e4 ff ff       	call   688 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    2259:	8b 45 e0             	mov    -0x20(%ebp),%eax
    225c:	83 c0 40             	add    $0x40,%eax
    225f:	89 04 24             	mov    %eax,(%esp)
    2262:	e8 86 e5 ff ff       	call   7ed <ck_pr_md_load_uint>
    2267:	8b 55 b0             	mov    -0x50(%ebp),%edx
    226a:	39 d0                	cmp    %edx,%eax
    226c:	75 e6                	jne    2254 <ck_ring_enqueue_mpsc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    226e:	e8 90 f2 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    2273:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2276:	8d 50 40             	lea    0x40(%eax),%edx
    2279:	8b 45 c0             	mov    -0x40(%ebp),%eax
    227c:	89 44 24 04          	mov    %eax,0x4(%esp)
    2280:	89 14 24             	mov    %edx,(%esp)
    2283:	e8 ee e5 ff ff       	call   876 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    2288:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    228c:	74 10                	je     229e <ck_ring_enqueue_mpsc_size+0x15d>
		*size = (producer - consumer) & mask;
    228e:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2291:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    2294:	23 45 cc             	and    -0x34(%ebp),%eax
    2297:	89 c2                	mov    %eax,%edx
    2299:	8b 45 d0             	mov    -0x30(%ebp),%eax
    229c:	89 10                	mov    %edx,(%eax)

	return r;
    229e:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    22a2:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    22a5:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    22a8:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    22ab:	89 10                	mov    %edx,(%eax)
	return r;
    22ad:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
    22b1:	c9                   	leave  
    22b2:	c3                   	ret    

000022b3 <ck_ring_dequeue_mpsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    22b3:	55                   	push   %ebp
    22b4:	89 e5                	mov    %esp,%ebp
    22b6:	83 ec 38             	sub    $0x38,%esp
    22b9:	8b 45 08             	mov    0x8(%ebp),%eax
    22bc:	89 45 f4             	mov    %eax,-0xc(%ebp)
    22bf:	8b 45 0c             	mov    0xc(%ebp),%eax
    22c2:	89 45 f0             	mov    %eax,-0x10(%ebp)
    22c5:	8b 45 10             	mov    0x10(%ebp),%eax
    22c8:	89 45 ec             	mov    %eax,-0x14(%ebp)
    22cb:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    22d2:	8b 45 f4             	mov    -0xc(%ebp),%eax
    22d5:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    22db:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    22de:	8b 45 f4             	mov    -0xc(%ebp),%eax
    22e1:	8b 00                	mov    (%eax),%eax
    22e3:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    22e6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    22e9:	83 c0 40             	add    $0x40,%eax
    22ec:	89 04 24             	mov    %eax,(%esp)
    22ef:	e8 f9 e4 ff ff       	call   7ed <ck_pr_md_load_uint>
    22f4:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    22f7:	8b 45 e0             	mov    -0x20(%ebp),%eax
    22fa:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    22fd:	0f 94 c0             	sete   %al
    2300:	0f b6 c0             	movzbl %al,%eax
    2303:	85 c0                	test   %eax,%eax
    2305:	74 07                	je     230e <ck_ring_dequeue_mpsc+0x5b>
		return false;
    2307:	b8 00 00 00 00       	mov    $0x0,%eax
    230c:	eb 4c                	jmp    235a <ck_ring_dequeue_mpsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    230e:	e8 e5 f1 ff ff       	call   14f8 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    2313:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2316:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    2319:	21 d0                	and    %edx,%eax
    231b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    231f:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    2322:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2325:	89 44 24 08          	mov    %eax,0x8(%esp)
    2329:	8b 45 f0             	mov    -0x10(%ebp),%eax
    232c:	89 44 24 04          	mov    %eax,0x4(%esp)
    2330:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2333:	89 04 24             	mov    %eax,(%esp)
    2336:	e8 fc ff ff ff       	call   2337 <ck_ring_dequeue_mpsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    233b:	e8 c3 f1 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    2340:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2343:	8d 50 01             	lea    0x1(%eax),%edx
    2346:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2349:	89 54 24 04          	mov    %edx,0x4(%esp)
    234d:	89 04 24             	mov    %eax,(%esp)
    2350:	e8 21 e5 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    2355:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer, (void **)data,
	    sizeof(void *));
}
    235a:	c9                   	leave  
    235b:	c3                   	ret    

0000235c <ck_ring_enqueue_spsc_size_xcpu>:
			struct cos_defcompinfo *dci, *sched;
		} sl_xcpu_req_initaep_alloc;
	};
};

CK_RING_PROTOTYPE(xcpu, sl_xcpu_request);
    235c:	55                   	push   %ebp
    235d:	89 e5                	mov    %esp,%ebp
    235f:	83 ec 58             	sub    $0x58,%esp
    2362:	8b 45 08             	mov    0x8(%ebp),%eax
    2365:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2368:	8b 45 0c             	mov    0xc(%ebp),%eax
    236b:	89 45 f0             	mov    %eax,-0x10(%ebp)
    236e:	8b 45 10             	mov    0x10(%ebp),%eax
    2371:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2374:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    237b:	8b 45 14             	mov    0x14(%ebp),%eax
    237e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    2381:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2384:	89 45 e0             	mov    %eax,-0x20(%ebp)
    2387:	8b 45 f0             	mov    -0x10(%ebp),%eax
    238a:	89 45 dc             	mov    %eax,-0x24(%ebp)
    238d:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2390:	89 45 d8             	mov    %eax,-0x28(%ebp)
    2393:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2396:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    2399:	8d 45 b8             	lea    -0x48(%ebp),%eax
    239c:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    239f:	8b 45 e0             	mov    -0x20(%ebp),%eax
    23a2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    23a8:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    23ab:	8b 45 e0             	mov    -0x20(%ebp),%eax
    23ae:	89 04 24             	mov    %eax,(%esp)
    23b1:	e8 37 e4 ff ff       	call   7ed <ck_pr_md_load_uint>
    23b6:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    23b9:	8b 45 e0             	mov    -0x20(%ebp),%eax
    23bc:	8b 40 40             	mov    0x40(%eax),%eax
    23bf:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    23c2:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    23c5:	83 c0 01             	add    $0x1,%eax
    23c8:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    23cb:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    23cf:	74 14                	je     23e5 <ck_ring_enqueue_spsc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
    23d1:	8b 45 c8             	mov    -0x38(%ebp),%eax
    23d4:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    23d7:	29 c2                	sub    %eax,%edx
    23d9:	89 d0                	mov    %edx,%eax
    23db:	23 45 cc             	and    -0x34(%ebp),%eax
    23de:	89 c2                	mov    %eax,%edx
    23e0:	8b 45 d0             	mov    -0x30(%ebp),%eax
    23e3:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    23e5:	8b 45 c0             	mov    -0x40(%ebp),%eax
    23e8:	8b 55 c8             	mov    -0x38(%ebp),%edx
    23eb:	31 d0                	xor    %edx,%eax
    23ed:	23 45 cc             	and    -0x34(%ebp),%eax
    23f0:	85 c0                	test   %eax,%eax
    23f2:	0f 94 c0             	sete   %al
    23f5:	0f b6 c0             	movzbl %al,%eax
    23f8:	85 c0                	test   %eax,%eax
    23fa:	74 07                	je     2403 <ck_ring_enqueue_spsc_size_xcpu+0xa7>
		return false;
    23fc:	b8 00 00 00 00       	mov    $0x0,%eax
    2401:	eb 47                	jmp    244a <ck_ring_enqueue_spsc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    2403:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    2406:	8b 55 cc             	mov    -0x34(%ebp),%edx
    2409:	21 d0                	and    %edx,%eax
    240b:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    240f:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    2412:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2415:	89 44 24 08          	mov    %eax,0x8(%esp)
    2419:	8b 45 d8             	mov    -0x28(%ebp),%eax
    241c:	89 44 24 04          	mov    %eax,0x4(%esp)
    2420:	8b 45 dc             	mov    -0x24(%ebp),%eax
    2423:	89 04 24             	mov    %eax,(%esp)
    2426:	e8 fc ff ff ff       	call   2427 <ck_ring_enqueue_spsc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    242b:	e8 d3 f0 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    2430:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2433:	8d 50 40             	lea    0x40(%eax),%edx
    2436:	8b 45 c0             	mov    -0x40(%ebp),%eax
    2439:	89 44 24 04          	mov    %eax,0x4(%esp)
    243d:	89 14 24             	mov    %edx,(%esp)
    2440:	e8 31 e4 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    2445:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    244a:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    244d:	8b 55 b8             	mov    -0x48(%ebp),%edx
    2450:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    2453:	89 10                	mov    %edx,(%eax)
	return r;
    2455:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    2459:	c9                   	leave  
    245a:	c3                   	ret    

0000245b <ck_ring_enqueue_spsc_xcpu>:
    245b:	55                   	push   %ebp
    245c:	89 e5                	mov    %esp,%ebp
    245e:	83 ec 48             	sub    $0x48,%esp
    2461:	8b 45 08             	mov    0x8(%ebp),%eax
    2464:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2467:	8b 45 0c             	mov    0xc(%ebp),%eax
    246a:	89 45 f0             	mov    %eax,-0x10(%ebp)
    246d:	8b 45 10             	mov    0x10(%ebp),%eax
    2470:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2473:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    247a:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    2481:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2484:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    248a:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    248d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2490:	89 04 24             	mov    %eax,(%esp)
    2493:	e8 55 e3 ff ff       	call   7ed <ck_pr_md_load_uint>
    2498:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    249b:	8b 45 f4             	mov    -0xc(%ebp),%eax
    249e:	8b 40 40             	mov    0x40(%eax),%eax
    24a1:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    24a4:	8b 45 d8             	mov    -0x28(%ebp),%eax
    24a7:	83 c0 01             	add    $0x1,%eax
    24aa:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    24ad:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    24b1:	74 14                	je     24c7 <ck_ring_enqueue_spsc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
    24b3:	8b 45 dc             	mov    -0x24(%ebp),%eax
    24b6:	8b 55 d8             	mov    -0x28(%ebp),%edx
    24b9:	29 c2                	sub    %eax,%edx
    24bb:	89 d0                	mov    %edx,%eax
    24bd:	23 45 e0             	and    -0x20(%ebp),%eax
    24c0:	89 c2                	mov    %eax,%edx
    24c2:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    24c5:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    24c7:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    24ca:	8b 55 dc             	mov    -0x24(%ebp),%edx
    24cd:	31 d0                	xor    %edx,%eax
    24cf:	23 45 e0             	and    -0x20(%ebp),%eax
    24d2:	85 c0                	test   %eax,%eax
    24d4:	0f 94 c0             	sete   %al
    24d7:	0f b6 c0             	movzbl %al,%eax
    24da:	85 c0                	test   %eax,%eax
    24dc:	74 07                	je     24e5 <ck_ring_enqueue_spsc_xcpu+0x8a>
		return false;
    24de:	b8 00 00 00 00       	mov    $0x0,%eax
    24e3:	eb 47                	jmp    252c <ck_ring_enqueue_spsc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    24e5:	8b 45 d8             	mov    -0x28(%ebp),%eax
    24e8:	8b 55 e0             	mov    -0x20(%ebp),%edx
    24eb:	21 d0                	and    %edx,%eax
    24ed:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    24f1:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    24f4:	8b 45 e8             	mov    -0x18(%ebp),%eax
    24f7:	89 44 24 08          	mov    %eax,0x8(%esp)
    24fb:	8b 45 ec             	mov    -0x14(%ebp),%eax
    24fe:	89 44 24 04          	mov    %eax,0x4(%esp)
    2502:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2505:	89 04 24             	mov    %eax,(%esp)
    2508:	e8 fc ff ff ff       	call   2509 <ck_ring_enqueue_spsc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    250d:	e8 f1 ef ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    2512:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2515:	8d 50 40             	lea    0x40(%eax),%edx
    2518:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    251b:	89 44 24 04          	mov    %eax,0x4(%esp)
    251f:	89 14 24             	mov    %edx,(%esp)
    2522:	e8 4f e3 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    2527:	b8 01 00 00 00       	mov    $0x1,%eax
    252c:	c9                   	leave  
    252d:	c3                   	ret    

0000252e <ck_ring_dequeue_spsc_xcpu>:
    252e:	55                   	push   %ebp
    252f:	89 e5                	mov    %esp,%ebp
    2531:	83 ec 38             	sub    $0x38,%esp
    2534:	8b 45 08             	mov    0x8(%ebp),%eax
    2537:	89 45 f4             	mov    %eax,-0xc(%ebp)
    253a:	8b 45 0c             	mov    0xc(%ebp),%eax
    253d:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2540:	8b 45 10             	mov    0x10(%ebp),%eax
    2543:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2546:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    254d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2550:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2556:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    2559:	8b 45 f4             	mov    -0xc(%ebp),%eax
    255c:	8b 00                	mov    (%eax),%eax
    255e:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    2561:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2564:	83 c0 40             	add    $0x40,%eax
    2567:	89 04 24             	mov    %eax,(%esp)
    256a:	e8 7e e2 ff ff       	call   7ed <ck_pr_md_load_uint>
    256f:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    2572:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2575:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    2578:	0f 94 c0             	sete   %al
    257b:	0f b6 c0             	movzbl %al,%eax
    257e:	85 c0                	test   %eax,%eax
    2580:	74 07                	je     2589 <ck_ring_dequeue_spsc_xcpu+0x5b>
		return false;
    2582:	b8 00 00 00 00       	mov    $0x0,%eax
    2587:	eb 4c                	jmp    25d5 <ck_ring_dequeue_spsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    2589:	e8 6a ef ff ff       	call   14f8 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    258e:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2591:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    2594:	21 d0                	and    %edx,%eax
    2596:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    259a:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    259d:	8b 45 e8             	mov    -0x18(%ebp),%eax
    25a0:	89 44 24 08          	mov    %eax,0x8(%esp)
    25a4:	8b 45 f0             	mov    -0x10(%ebp),%eax
    25a7:	89 44 24 04          	mov    %eax,0x4(%esp)
    25ab:	8b 45 ec             	mov    -0x14(%ebp),%eax
    25ae:	89 04 24             	mov    %eax,(%esp)
    25b1:	e8 fc ff ff ff       	call   25b2 <ck_ring_dequeue_spsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    25b6:	e8 48 ef ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    25bb:	8b 45 e0             	mov    -0x20(%ebp),%eax
    25be:	8d 50 01             	lea    0x1(%eax),%edx
    25c1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    25c4:	89 54 24 04          	mov    %edx,0x4(%esp)
    25c8:	89 04 24             	mov    %eax,(%esp)
    25cb:	e8 a6 e2 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    25d0:	b8 01 00 00 00       	mov    $0x1,%eax
    25d5:	c9                   	leave  
    25d6:	c3                   	ret    

000025d7 <ck_ring_enqueue_spmc_size_xcpu>:
    25d7:	55                   	push   %ebp
    25d8:	89 e5                	mov    %esp,%ebp
    25da:	83 ec 58             	sub    $0x58,%esp
    25dd:	8b 45 08             	mov    0x8(%ebp),%eax
    25e0:	89 45 f4             	mov    %eax,-0xc(%ebp)
    25e3:	8b 45 0c             	mov    0xc(%ebp),%eax
    25e6:	89 45 f0             	mov    %eax,-0x10(%ebp)
    25e9:	8b 45 10             	mov    0x10(%ebp),%eax
    25ec:	89 45 ec             	mov    %eax,-0x14(%ebp)
    25ef:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    25f6:	8b 45 14             	mov    0x14(%ebp),%eax
    25f9:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    25fc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    25ff:	89 45 e0             	mov    %eax,-0x20(%ebp)
    2602:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2605:	89 45 dc             	mov    %eax,-0x24(%ebp)
    2608:	8b 45 ec             	mov    -0x14(%ebp),%eax
    260b:	89 45 d8             	mov    %eax,-0x28(%ebp)
    260e:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2611:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    2614:	8d 45 b8             	lea    -0x48(%ebp),%eax
    2617:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    261a:	8b 45 e0             	mov    -0x20(%ebp),%eax
    261d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2623:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    2626:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2629:	89 04 24             	mov    %eax,(%esp)
    262c:	e8 bc e1 ff ff       	call   7ed <ck_pr_md_load_uint>
    2631:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    2634:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2637:	8b 40 40             	mov    0x40(%eax),%eax
    263a:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    263d:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    2640:	83 c0 01             	add    $0x1,%eax
    2643:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    2646:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    264a:	74 14                	je     2660 <ck_ring_enqueue_spmc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
    264c:	8b 45 c8             	mov    -0x38(%ebp),%eax
    264f:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    2652:	29 c2                	sub    %eax,%edx
    2654:	89 d0                	mov    %edx,%eax
    2656:	23 45 cc             	and    -0x34(%ebp),%eax
    2659:	89 c2                	mov    %eax,%edx
    265b:	8b 45 d0             	mov    -0x30(%ebp),%eax
    265e:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    2660:	8b 45 c0             	mov    -0x40(%ebp),%eax
    2663:	8b 55 c8             	mov    -0x38(%ebp),%edx
    2666:	31 d0                	xor    %edx,%eax
    2668:	23 45 cc             	and    -0x34(%ebp),%eax
    266b:	85 c0                	test   %eax,%eax
    266d:	0f 94 c0             	sete   %al
    2670:	0f b6 c0             	movzbl %al,%eax
    2673:	85 c0                	test   %eax,%eax
    2675:	74 07                	je     267e <ck_ring_enqueue_spmc_size_xcpu+0xa7>
		return false;
    2677:	b8 00 00 00 00       	mov    $0x0,%eax
    267c:	eb 47                	jmp    26c5 <ck_ring_enqueue_spmc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    267e:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    2681:	8b 55 cc             	mov    -0x34(%ebp),%edx
    2684:	21 d0                	and    %edx,%eax
    2686:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    268a:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    268d:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2690:	89 44 24 08          	mov    %eax,0x8(%esp)
    2694:	8b 45 d8             	mov    -0x28(%ebp),%eax
    2697:	89 44 24 04          	mov    %eax,0x4(%esp)
    269b:	8b 45 dc             	mov    -0x24(%ebp),%eax
    269e:	89 04 24             	mov    %eax,(%esp)
    26a1:	e8 fc ff ff ff       	call   26a2 <ck_ring_enqueue_spmc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    26a6:	e8 58 ee ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    26ab:	8b 45 e0             	mov    -0x20(%ebp),%eax
    26ae:	8d 50 40             	lea    0x40(%eax),%edx
    26b1:	8b 45 c0             	mov    -0x40(%ebp),%eax
    26b4:	89 44 24 04          	mov    %eax,0x4(%esp)
    26b8:	89 14 24             	mov    %edx,(%esp)
    26bb:	e8 b6 e1 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    26c0:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    26c5:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    26c8:	8b 55 b8             	mov    -0x48(%ebp),%edx
    26cb:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    26ce:	89 10                	mov    %edx,(%eax)
	return r;
    26d0:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    26d4:	c9                   	leave  
    26d5:	c3                   	ret    

000026d6 <ck_ring_enqueue_spmc_xcpu>:
    26d6:	55                   	push   %ebp
    26d7:	89 e5                	mov    %esp,%ebp
    26d9:	83 ec 48             	sub    $0x48,%esp
    26dc:	8b 45 08             	mov    0x8(%ebp),%eax
    26df:	89 45 f4             	mov    %eax,-0xc(%ebp)
    26e2:	8b 45 0c             	mov    0xc(%ebp),%eax
    26e5:	89 45 f0             	mov    %eax,-0x10(%ebp)
    26e8:	8b 45 10             	mov    0x10(%ebp),%eax
    26eb:	89 45 ec             	mov    %eax,-0x14(%ebp)
    26ee:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    26f5:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    26fc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    26ff:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2705:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    2708:	8b 45 f4             	mov    -0xc(%ebp),%eax
    270b:	89 04 24             	mov    %eax,(%esp)
    270e:	e8 da e0 ff ff       	call   7ed <ck_pr_md_load_uint>
    2713:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    2716:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2719:	8b 40 40             	mov    0x40(%eax),%eax
    271c:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    271f:	8b 45 d8             	mov    -0x28(%ebp),%eax
    2722:	83 c0 01             	add    $0x1,%eax
    2725:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    2728:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    272c:	74 14                	je     2742 <ck_ring_enqueue_spmc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
    272e:	8b 45 dc             	mov    -0x24(%ebp),%eax
    2731:	8b 55 d8             	mov    -0x28(%ebp),%edx
    2734:	29 c2                	sub    %eax,%edx
    2736:	89 d0                	mov    %edx,%eax
    2738:	23 45 e0             	and    -0x20(%ebp),%eax
    273b:	89 c2                	mov    %eax,%edx
    273d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    2740:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    2742:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2745:	8b 55 dc             	mov    -0x24(%ebp),%edx
    2748:	31 d0                	xor    %edx,%eax
    274a:	23 45 e0             	and    -0x20(%ebp),%eax
    274d:	85 c0                	test   %eax,%eax
    274f:	0f 94 c0             	sete   %al
    2752:	0f b6 c0             	movzbl %al,%eax
    2755:	85 c0                	test   %eax,%eax
    2757:	74 07                	je     2760 <ck_ring_enqueue_spmc_xcpu+0x8a>
		return false;
    2759:	b8 00 00 00 00       	mov    $0x0,%eax
    275e:	eb 47                	jmp    27a7 <ck_ring_enqueue_spmc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    2760:	8b 45 d8             	mov    -0x28(%ebp),%eax
    2763:	8b 55 e0             	mov    -0x20(%ebp),%edx
    2766:	21 d0                	and    %edx,%eax
    2768:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    276c:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    276f:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2772:	89 44 24 08          	mov    %eax,0x8(%esp)
    2776:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2779:	89 44 24 04          	mov    %eax,0x4(%esp)
    277d:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2780:	89 04 24             	mov    %eax,(%esp)
    2783:	e8 fc ff ff ff       	call   2784 <ck_ring_enqueue_spmc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    2788:	e8 76 ed ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    278d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2790:	8d 50 40             	lea    0x40(%eax),%edx
    2793:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2796:	89 44 24 04          	mov    %eax,0x4(%esp)
    279a:	89 14 24             	mov    %edx,(%esp)
    279d:	e8 d4 e0 ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    27a2:	b8 01 00 00 00       	mov    $0x1,%eax
    27a7:	c9                   	leave  
    27a8:	c3                   	ret    

000027a9 <ck_ring_trydequeue_spmc_xcpu>:
    27a9:	55                   	push   %ebp
    27aa:	89 e5                	mov    %esp,%ebp
    27ac:	83 ec 38             	sub    $0x38,%esp
    27af:	8b 45 08             	mov    0x8(%ebp),%eax
    27b2:	89 45 f4             	mov    %eax,-0xc(%ebp)
    27b5:	8b 45 0c             	mov    0xc(%ebp),%eax
    27b8:	89 45 f0             	mov    %eax,-0x10(%ebp)
    27bb:	8b 45 10             	mov    0x10(%ebp),%eax
    27be:	89 45 ec             	mov    %eax,-0x14(%ebp)
    27c1:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    27c8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    27cb:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    27d1:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    27d4:	8b 45 f4             	mov    -0xc(%ebp),%eax
    27d7:	89 04 24             	mov    %eax,(%esp)
    27da:	e8 0e e0 ff ff       	call   7ed <ck_pr_md_load_uint>
    27df:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    27e2:	e8 11 ed ff ff       	call   14f8 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    27e7:	8b 45 f4             	mov    -0xc(%ebp),%eax
    27ea:	83 c0 40             	add    $0x40,%eax
    27ed:	89 04 24             	mov    %eax,(%esp)
    27f0:	e8 f8 df ff ff       	call   7ed <ck_pr_md_load_uint>
    27f5:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    27f8:	8b 45 e0             	mov    -0x20(%ebp),%eax
    27fb:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    27fe:	0f 94 c0             	sete   %al
    2801:	0f b6 c0             	movzbl %al,%eax
    2804:	85 c0                	test   %eax,%eax
    2806:	74 07                	je     280f <ck_ring_trydequeue_spmc_xcpu+0x66>
		return false;
    2808:	b8 00 00 00 00       	mov    $0x0,%eax
    280d:	eb 4e                	jmp    285d <ck_ring_trydequeue_spmc_xcpu+0xb4>

	ck_pr_fence_load();
    280f:	e8 e4 ec ff ff       	call   14f8 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    2814:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2817:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    281a:	21 d0                	and    %edx,%eax
    281c:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    2820:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    2823:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2826:	89 44 24 08          	mov    %eax,0x8(%esp)
    282a:	8b 45 f0             	mov    -0x10(%ebp),%eax
    282d:	89 44 24 04          	mov    %eax,0x4(%esp)
    2831:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2834:	89 04 24             	mov    %eax,(%esp)
    2837:	e8 fc ff ff ff       	call   2838 <ck_ring_trydequeue_spmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
    283c:	e8 8b ec ff ff       	call   14cc <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    2841:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2844:	8d 50 01             	lea    0x1(%eax),%edx
    2847:	8b 45 f4             	mov    -0xc(%ebp),%eax
    284a:	89 54 24 08          	mov    %edx,0x8(%esp)
    284e:	8b 55 e0             	mov    -0x20(%ebp),%edx
    2851:	89 54 24 04          	mov    %edx,0x4(%esp)
    2855:	89 04 24             	mov    %eax,(%esp)
    2858:	e8 3e e8 ff ff       	call   109b <ck_pr_cas_uint>
    285d:	c9                   	leave  
    285e:	c3                   	ret    

0000285f <ck_ring_dequeue_spmc_xcpu>:
    285f:	55                   	push   %ebp
    2860:	89 e5                	mov    %esp,%ebp
    2862:	53                   	push   %ebx
    2863:	83 ec 34             	sub    $0x34,%esp
    2866:	8b 45 08             	mov    0x8(%ebp),%eax
    2869:	89 45 f4             	mov    %eax,-0xc(%ebp)
    286c:	8b 45 0c             	mov    0xc(%ebp),%eax
    286f:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2872:	8b 45 10             	mov    0x10(%ebp),%eax
    2875:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2878:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    287f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2882:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2888:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    288b:	8b 45 f4             	mov    -0xc(%ebp),%eax
    288e:	89 04 24             	mov    %eax,(%esp)
    2891:	e8 57 df ff ff       	call   7ed <ck_pr_md_load_uint>
    2896:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    2899:	e8 5a ec ff ff       	call   14f8 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    289e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    28a1:	83 c0 40             	add    $0x40,%eax
    28a4:	89 04 24             	mov    %eax,(%esp)
    28a7:	e8 41 df ff ff       	call   7ed <ck_pr_md_load_uint>
    28ac:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    28af:	8b 45 d8             	mov    -0x28(%ebp),%eax
    28b2:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    28b5:	0f 94 c0             	sete   %al
    28b8:	0f b6 c0             	movzbl %al,%eax
    28bb:	85 c0                	test   %eax,%eax
    28bd:	74 07                	je     28c6 <ck_ring_dequeue_spmc_xcpu+0x67>
			return false;
    28bf:	b8 00 00 00 00       	mov    $0x0,%eax
    28c4:	eb 6a                	jmp    2930 <ck_ring_dequeue_spmc_xcpu+0xd1>

		ck_pr_fence_load();
    28c6:	e8 2d ec ff ff       	call   14f8 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    28cb:	8b 45 d8             	mov    -0x28(%ebp),%eax
    28ce:	23 45 e4             	and    -0x1c(%ebp),%eax
    28d1:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    28d5:	89 c2                	mov    %eax,%edx
    28d7:	8b 45 f0             	mov    -0x10(%ebp),%eax
    28da:	01 d0                	add    %edx,%eax
    28dc:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    28df:	8b 45 e8             	mov    -0x18(%ebp),%eax
    28e2:	89 44 24 08          	mov    %eax,0x8(%esp)
    28e6:	8b 45 dc             	mov    -0x24(%ebp),%eax
    28e9:	89 44 24 04          	mov    %eax,0x4(%esp)
    28ed:	8b 45 ec             	mov    -0x14(%ebp),%eax
    28f0:	89 04 24             	mov    %eax,(%esp)
    28f3:	e8 fc ff ff ff       	call   28f4 <ck_ring_dequeue_spmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    28f8:	e8 cf eb ff ff       	call   14cc <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    28fd:	8b 45 d8             	mov    -0x28(%ebp),%eax
    2900:	8d 58 01             	lea    0x1(%eax),%ebx
    2903:	8b 55 d8             	mov    -0x28(%ebp),%edx
    2906:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2909:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    290c:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    2910:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    2914:	89 54 24 04          	mov    %edx,0x4(%esp)
    2918:	89 04 24             	mov    %eax,(%esp)
    291b:	e8 ce e8 ff ff       	call   11ee <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    2920:	83 f0 01             	xor    $0x1,%eax
    2923:	84 c0                	test   %al,%al
    2925:	0f 85 6e ff ff ff    	jne    2899 <ck_ring_dequeue_spmc_xcpu+0x3a>

	return true;
    292b:	b8 01 00 00 00       	mov    $0x1,%eax
    2930:	83 c4 34             	add    $0x34,%esp
    2933:	5b                   	pop    %ebx
    2934:	5d                   	pop    %ebp
    2935:	c3                   	ret    

00002936 <ck_ring_enqueue_mpsc_xcpu>:
    2936:	55                   	push   %ebp
    2937:	89 e5                	mov    %esp,%ebp
    2939:	83 ec 48             	sub    $0x48,%esp
    293c:	8b 45 08             	mov    0x8(%ebp),%eax
    293f:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2942:	8b 45 0c             	mov    0xc(%ebp),%eax
    2945:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2948:	8b 45 10             	mov    0x10(%ebp),%eax
    294b:	89 45 ec             	mov    %eax,-0x14(%ebp)
    294e:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    2955:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    295c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    295f:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2965:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    2968:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    296c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    296f:	83 c0 44             	add    $0x44,%eax
    2972:	89 04 24             	mov    %eax,(%esp)
    2975:	e8 73 de ff ff       	call   7ed <ck_pr_md_load_uint>
    297a:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    297d:	e8 76 eb ff ff       	call   14f8 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    2982:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2985:	89 04 24             	mov    %eax,(%esp)
    2988:	e8 60 de ff ff       	call   7ed <ck_pr_md_load_uint>
    298d:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    2990:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2993:	83 c0 01             	add    $0x1,%eax
    2996:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    2999:	8b 45 cc             	mov    -0x34(%ebp),%eax
    299c:	2b 45 d8             	sub    -0x28(%ebp),%eax
    299f:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    29a2:	0f 97 c0             	seta   %al
    29a5:	0f b6 c0             	movzbl %al,%eax
    29a8:	85 c0                	test   %eax,%eax
    29aa:	74 29                	je     29d5 <ck_ring_enqueue_mpsc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    29ac:	8b 45 cc             	mov    -0x34(%ebp),%eax
    29af:	8b 55 f4             	mov    -0xc(%ebp),%edx
    29b2:	8d 4a 44             	lea    0x44(%edx),%ecx
    29b5:	8d 55 cc             	lea    -0x34(%ebp),%edx
    29b8:	89 54 24 0c          	mov    %edx,0xc(%esp)
    29bc:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    29bf:	89 54 24 08          	mov    %edx,0x8(%esp)
    29c3:	89 44 24 04          	mov    %eax,0x4(%esp)
    29c7:	89 0c 24             	mov    %ecx,(%esp)
    29ca:	e8 1f e8 ff ff       	call   11ee <ck_pr_cas_uint_value>
    29cf:	84 c0                	test   %al,%al
    29d1:	75 31                	jne    2a04 <ck_ring_enqueue_mpsc_xcpu+0xce>
    29d3:	eb a8                	jmp    297d <ck_ring_enqueue_mpsc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    29d5:	e8 1e eb ff ff       	call   14f8 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    29da:	8b 45 f4             	mov    -0xc(%ebp),%eax
    29dd:	83 c0 44             	add    $0x44,%eax
    29e0:	89 04 24             	mov    %eax,(%esp)
    29e3:	e8 05 de ff ff       	call   7ed <ck_pr_md_load_uint>
    29e8:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    29eb:	8b 45 cc             	mov    -0x34(%ebp),%eax
    29ee:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    29f1:	75 06                	jne    29f9 <ck_ring_enqueue_mpsc_xcpu+0xc3>
				r = false;
    29f3:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    29f7:	eb 67                	jmp    2a60 <ck_ring_enqueue_mpsc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    29f9:	8b 45 d0             	mov    -0x30(%ebp),%eax
    29fc:	89 45 cc             	mov    %eax,-0x34(%ebp)
    29ff:	e9 79 ff ff ff       	jmp    297d <ck_ring_enqueue_mpsc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    2a04:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2a07:	23 45 e0             	and    -0x20(%ebp),%eax
    2a0a:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    2a0e:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    2a11:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2a14:	89 44 24 08          	mov    %eax,0x8(%esp)
    2a18:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2a1b:	89 44 24 04          	mov    %eax,0x4(%esp)
    2a1f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2a22:	89 04 24             	mov    %eax,(%esp)
    2a25:	e8 fc ff ff ff       	call   2a26 <ck_ring_enqueue_mpsc_xcpu+0xf0>
    2a2a:	eb 05                	jmp    2a31 <ck_ring_enqueue_mpsc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    2a2c:	e8 57 dc ff ff       	call   688 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    2a31:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2a34:	83 c0 40             	add    $0x40,%eax
    2a37:	89 04 24             	mov    %eax,(%esp)
    2a3a:	e8 ae dd ff ff       	call   7ed <ck_pr_md_load_uint>
    2a3f:	8b 55 cc             	mov    -0x34(%ebp),%edx
    2a42:	39 d0                	cmp    %edx,%eax
    2a44:	75 e6                	jne    2a2c <ck_ring_enqueue_mpsc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    2a46:	e8 b8 ea ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    2a4b:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2a4e:	8d 50 40             	lea    0x40(%eax),%edx
    2a51:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2a54:	89 44 24 04          	mov    %eax,0x4(%esp)
    2a58:	89 14 24             	mov    %edx,(%esp)
    2a5b:	e8 16 de ff ff       	call   876 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    2a60:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    2a64:	74 10                	je     2a76 <ck_ring_enqueue_mpsc_xcpu+0x140>
		*size = (producer - consumer) & mask;
    2a66:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2a69:	2b 45 d8             	sub    -0x28(%ebp),%eax
    2a6c:	23 45 e0             	and    -0x20(%ebp),%eax
    2a6f:	89 c2                	mov    %eax,%edx
    2a71:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    2a74:	89 10                	mov    %edx,(%eax)

	return r;
    2a76:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    2a7a:	c9                   	leave  
    2a7b:	c3                   	ret    

00002a7c <ck_ring_enqueue_mpsc_size_xcpu>:
    2a7c:	55                   	push   %ebp
    2a7d:	89 e5                	mov    %esp,%ebp
    2a7f:	83 ec 68             	sub    $0x68,%esp
    2a82:	8b 45 08             	mov    0x8(%ebp),%eax
    2a85:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2a88:	8b 45 0c             	mov    0xc(%ebp),%eax
    2a8b:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2a8e:	8b 45 10             	mov    0x10(%ebp),%eax
    2a91:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2a94:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    2a9b:	8b 45 14             	mov    0x14(%ebp),%eax
    2a9e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    2aa1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2aa4:	89 45 e0             	mov    %eax,-0x20(%ebp)
    2aa7:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2aaa:	89 45 dc             	mov    %eax,-0x24(%ebp)
    2aad:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2ab0:	89 45 d8             	mov    %eax,-0x28(%ebp)
    2ab3:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2ab6:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    2ab9:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    2abc:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    2abf:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2ac2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2ac8:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    2acb:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    2acf:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2ad2:	83 c0 44             	add    $0x44,%eax
    2ad5:	89 04 24             	mov    %eax,(%esp)
    2ad8:	e8 10 dd ff ff       	call   7ed <ck_pr_md_load_uint>
    2add:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    2ae0:	e8 13 ea ff ff       	call   14f8 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    2ae5:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2ae8:	89 04 24             	mov    %eax,(%esp)
    2aeb:	e8 fd dc ff ff       	call   7ed <ck_pr_md_load_uint>
    2af0:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    2af3:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2af6:	83 c0 01             	add    $0x1,%eax
    2af9:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    2afc:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2aff:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    2b02:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    2b05:	0f 97 c0             	seta   %al
    2b08:	0f b6 c0             	movzbl %al,%eax
    2b0b:	85 c0                	test   %eax,%eax
    2b0d:	74 29                	je     2b38 <ck_ring_enqueue_mpsc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    2b0f:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2b12:	8b 55 e0             	mov    -0x20(%ebp),%edx
    2b15:	8d 4a 44             	lea    0x44(%edx),%ecx
    2b18:	8d 55 b0             	lea    -0x50(%ebp),%edx
    2b1b:	89 54 24 0c          	mov    %edx,0xc(%esp)
    2b1f:	8b 55 c0             	mov    -0x40(%ebp),%edx
    2b22:	89 54 24 08          	mov    %edx,0x8(%esp)
    2b26:	89 44 24 04          	mov    %eax,0x4(%esp)
    2b2a:	89 0c 24             	mov    %ecx,(%esp)
    2b2d:	e8 bc e6 ff ff       	call   11ee <ck_pr_cas_uint_value>
    2b32:	84 c0                	test   %al,%al
    2b34:	75 31                	jne    2b67 <ck_ring_enqueue_mpsc_size_xcpu+0xeb>
    2b36:	eb a8                	jmp    2ae0 <ck_ring_enqueue_mpsc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    2b38:	e8 bb e9 ff ff       	call   14f8 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    2b3d:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2b40:	83 c0 44             	add    $0x44,%eax
    2b43:	89 04 24             	mov    %eax,(%esp)
    2b46:	e8 a2 dc ff ff       	call   7ed <ck_pr_md_load_uint>
    2b4b:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    2b4e:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2b51:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    2b54:	75 06                	jne    2b5c <ck_ring_enqueue_mpsc_size_xcpu+0xe0>
				r = false;
    2b56:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    2b5a:	eb 67                	jmp    2bc3 <ck_ring_enqueue_mpsc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    2b5c:	8b 45 bc             	mov    -0x44(%ebp),%eax
    2b5f:	89 45 b0             	mov    %eax,-0x50(%ebp)
    2b62:	e9 79 ff ff ff       	jmp    2ae0 <ck_ring_enqueue_mpsc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    2b67:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2b6a:	23 45 cc             	and    -0x34(%ebp),%eax
    2b6d:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    2b71:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    2b74:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2b77:	89 44 24 08          	mov    %eax,0x8(%esp)
    2b7b:	8b 45 d8             	mov    -0x28(%ebp),%eax
    2b7e:	89 44 24 04          	mov    %eax,0x4(%esp)
    2b82:	8b 45 dc             	mov    -0x24(%ebp),%eax
    2b85:	89 04 24             	mov    %eax,(%esp)
    2b88:	e8 fc ff ff ff       	call   2b89 <ck_ring_enqueue_mpsc_size_xcpu+0x10d>
    2b8d:	eb 05                	jmp    2b94 <ck_ring_enqueue_mpsc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    2b8f:	e8 f4 da ff ff       	call   688 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    2b94:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2b97:	83 c0 40             	add    $0x40,%eax
    2b9a:	89 04 24             	mov    %eax,(%esp)
    2b9d:	e8 4b dc ff ff       	call   7ed <ck_pr_md_load_uint>
    2ba2:	8b 55 b0             	mov    -0x50(%ebp),%edx
    2ba5:	39 d0                	cmp    %edx,%eax
    2ba7:	75 e6                	jne    2b8f <ck_ring_enqueue_mpsc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    2ba9:	e8 55 e9 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    2bae:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2bb1:	8d 50 40             	lea    0x40(%eax),%edx
    2bb4:	8b 45 c0             	mov    -0x40(%ebp),%eax
    2bb7:	89 44 24 04          	mov    %eax,0x4(%esp)
    2bbb:	89 14 24             	mov    %edx,(%esp)
    2bbe:	e8 b3 dc ff ff       	call   876 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    2bc3:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    2bc7:	74 10                	je     2bd9 <ck_ring_enqueue_mpsc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
    2bc9:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2bcc:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    2bcf:	23 45 cc             	and    -0x34(%ebp),%eax
    2bd2:	89 c2                	mov    %eax,%edx
    2bd4:	8b 45 d0             	mov    -0x30(%ebp),%eax
    2bd7:	89 10                	mov    %edx,(%eax)

	return r;
    2bd9:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    2bdd:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    2be0:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    2be3:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    2be6:	89 10                	mov    %edx,(%eax)
	return r;
    2be8:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    2bec:	c9                   	leave  
    2bed:	c3                   	ret    

00002bee <ck_ring_dequeue_mpsc_xcpu>:
    2bee:	55                   	push   %ebp
    2bef:	89 e5                	mov    %esp,%ebp
    2bf1:	83 ec 38             	sub    $0x38,%esp
    2bf4:	8b 45 08             	mov    0x8(%ebp),%eax
    2bf7:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2bfa:	8b 45 0c             	mov    0xc(%ebp),%eax
    2bfd:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2c00:	8b 45 10             	mov    0x10(%ebp),%eax
    2c03:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2c06:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    2c0d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2c10:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2c16:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    2c19:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2c1c:	8b 00                	mov    (%eax),%eax
    2c1e:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    2c21:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2c24:	83 c0 40             	add    $0x40,%eax
    2c27:	89 04 24             	mov    %eax,(%esp)
    2c2a:	e8 be db ff ff       	call   7ed <ck_pr_md_load_uint>
    2c2f:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    2c32:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2c35:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    2c38:	0f 94 c0             	sete   %al
    2c3b:	0f b6 c0             	movzbl %al,%eax
    2c3e:	85 c0                	test   %eax,%eax
    2c40:	74 07                	je     2c49 <ck_ring_dequeue_mpsc_xcpu+0x5b>
		return false;
    2c42:	b8 00 00 00 00       	mov    $0x0,%eax
    2c47:	eb 4c                	jmp    2c95 <ck_ring_dequeue_mpsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    2c49:	e8 aa e8 ff ff       	call   14f8 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    2c4e:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2c51:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    2c54:	21 d0                	and    %edx,%eax
    2c56:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    2c5a:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    2c5d:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2c60:	89 44 24 08          	mov    %eax,0x8(%esp)
    2c64:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2c67:	89 44 24 04          	mov    %eax,0x4(%esp)
    2c6b:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2c6e:	89 04 24             	mov    %eax,(%esp)
    2c71:	e8 fc ff ff ff       	call   2c72 <ck_ring_dequeue_mpsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    2c76:	e8 88 e8 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    2c7b:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2c7e:	8d 50 01             	lea    0x1(%eax),%edx
    2c81:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2c84:	89 54 24 04          	mov    %edx,0x4(%esp)
    2c88:	89 04 24             	mov    %eax,(%esp)
    2c8b:	e8 e6 db ff ff       	call   876 <ck_pr_md_store_uint>
	return true;
    2c90:	b8 01 00 00 00       	mov    $0x1,%eax
    2c95:	c9                   	leave  
    2c96:	c3                   	ret    

00002c97 <ck_ring_enqueue_mpmc_size_xcpu>:
    2c97:	55                   	push   %ebp
    2c98:	89 e5                	mov    %esp,%ebp
    2c9a:	83 ec 68             	sub    $0x68,%esp
    2c9d:	8b 45 08             	mov    0x8(%ebp),%eax
    2ca0:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2ca3:	8b 45 0c             	mov    0xc(%ebp),%eax
    2ca6:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2ca9:	8b 45 10             	mov    0x10(%ebp),%eax
    2cac:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2caf:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    2cb6:	8b 45 14             	mov    0x14(%ebp),%eax
    2cb9:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    2cbc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2cbf:	89 45 e0             	mov    %eax,-0x20(%ebp)
    2cc2:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2cc5:	89 45 dc             	mov    %eax,-0x24(%ebp)
    2cc8:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2ccb:	89 45 d8             	mov    %eax,-0x28(%ebp)
    2cce:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2cd1:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    2cd4:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    2cd7:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    2cda:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2cdd:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2ce3:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    2ce6:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    2cea:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2ced:	83 c0 44             	add    $0x44,%eax
    2cf0:	89 04 24             	mov    %eax,(%esp)
    2cf3:	e8 f5 da ff ff       	call   7ed <ck_pr_md_load_uint>
    2cf8:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    2cfb:	e8 f8 e7 ff ff       	call   14f8 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    2d00:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2d03:	89 04 24             	mov    %eax,(%esp)
    2d06:	e8 e2 da ff ff       	call   7ed <ck_pr_md_load_uint>
    2d0b:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    2d0e:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2d11:	83 c0 01             	add    $0x1,%eax
    2d14:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    2d17:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2d1a:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    2d1d:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    2d20:	0f 97 c0             	seta   %al
    2d23:	0f b6 c0             	movzbl %al,%eax
    2d26:	85 c0                	test   %eax,%eax
    2d28:	74 29                	je     2d53 <ck_ring_enqueue_mpmc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    2d2a:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2d2d:	8b 55 e0             	mov    -0x20(%ebp),%edx
    2d30:	8d 4a 44             	lea    0x44(%edx),%ecx
    2d33:	8d 55 b0             	lea    -0x50(%ebp),%edx
    2d36:	89 54 24 0c          	mov    %edx,0xc(%esp)
    2d3a:	8b 55 c0             	mov    -0x40(%ebp),%edx
    2d3d:	89 54 24 08          	mov    %edx,0x8(%esp)
    2d41:	89 44 24 04          	mov    %eax,0x4(%esp)
    2d45:	89 0c 24             	mov    %ecx,(%esp)
    2d48:	e8 a1 e4 ff ff       	call   11ee <ck_pr_cas_uint_value>
    2d4d:	84 c0                	test   %al,%al
    2d4f:	75 31                	jne    2d82 <ck_ring_enqueue_mpmc_size_xcpu+0xeb>
    2d51:	eb a8                	jmp    2cfb <ck_ring_enqueue_mpmc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    2d53:	e8 a0 e7 ff ff       	call   14f8 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    2d58:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2d5b:	83 c0 44             	add    $0x44,%eax
    2d5e:	89 04 24             	mov    %eax,(%esp)
    2d61:	e8 87 da ff ff       	call   7ed <ck_pr_md_load_uint>
    2d66:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    2d69:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2d6c:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    2d6f:	75 06                	jne    2d77 <ck_ring_enqueue_mpmc_size_xcpu+0xe0>
				r = false;
    2d71:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    2d75:	eb 67                	jmp    2dde <ck_ring_enqueue_mpmc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    2d77:	8b 45 bc             	mov    -0x44(%ebp),%eax
    2d7a:	89 45 b0             	mov    %eax,-0x50(%ebp)
    2d7d:	e9 79 ff ff ff       	jmp    2cfb <ck_ring_enqueue_mpmc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    2d82:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2d85:	23 45 cc             	and    -0x34(%ebp),%eax
    2d88:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    2d8c:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    2d8f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2d92:	89 44 24 08          	mov    %eax,0x8(%esp)
    2d96:	8b 45 d8             	mov    -0x28(%ebp),%eax
    2d99:	89 44 24 04          	mov    %eax,0x4(%esp)
    2d9d:	8b 45 dc             	mov    -0x24(%ebp),%eax
    2da0:	89 04 24             	mov    %eax,(%esp)
    2da3:	e8 fc ff ff ff       	call   2da4 <ck_ring_enqueue_mpmc_size_xcpu+0x10d>
    2da8:	eb 05                	jmp    2daf <ck_ring_enqueue_mpmc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    2daa:	e8 d9 d8 ff ff       	call   688 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    2daf:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2db2:	83 c0 40             	add    $0x40,%eax
    2db5:	89 04 24             	mov    %eax,(%esp)
    2db8:	e8 30 da ff ff       	call   7ed <ck_pr_md_load_uint>
    2dbd:	8b 55 b0             	mov    -0x50(%ebp),%edx
    2dc0:	39 d0                	cmp    %edx,%eax
    2dc2:	75 e6                	jne    2daa <ck_ring_enqueue_mpmc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    2dc4:	e8 3a e7 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    2dc9:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2dcc:	8d 50 40             	lea    0x40(%eax),%edx
    2dcf:	8b 45 c0             	mov    -0x40(%ebp),%eax
    2dd2:	89 44 24 04          	mov    %eax,0x4(%esp)
    2dd6:	89 14 24             	mov    %edx,(%esp)
    2dd9:	e8 98 da ff ff       	call   876 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    2dde:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    2de2:	74 10                	je     2df4 <ck_ring_enqueue_mpmc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
    2de4:	8b 45 b0             	mov    -0x50(%ebp),%eax
    2de7:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    2dea:	23 45 cc             	and    -0x34(%ebp),%eax
    2ded:	89 c2                	mov    %eax,%edx
    2def:	8b 45 d0             	mov    -0x30(%ebp),%eax
    2df2:	89 10                	mov    %edx,(%eax)

	return r;
    2df4:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    2df8:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    2dfb:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    2dfe:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    2e01:	89 10                	mov    %edx,(%eax)
	return r;
    2e03:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    2e07:	c9                   	leave  
    2e08:	c3                   	ret    

00002e09 <ck_ring_enqueue_mpmc_xcpu>:
    2e09:	55                   	push   %ebp
    2e0a:	89 e5                	mov    %esp,%ebp
    2e0c:	83 ec 48             	sub    $0x48,%esp
    2e0f:	8b 45 08             	mov    0x8(%ebp),%eax
    2e12:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2e15:	8b 45 0c             	mov    0xc(%ebp),%eax
    2e18:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2e1b:	8b 45 10             	mov    0x10(%ebp),%eax
    2e1e:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2e21:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    2e28:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    2e2f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2e32:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2e38:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    2e3b:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    2e3f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2e42:	83 c0 44             	add    $0x44,%eax
    2e45:	89 04 24             	mov    %eax,(%esp)
    2e48:	e8 a0 d9 ff ff       	call   7ed <ck_pr_md_load_uint>
    2e4d:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    2e50:	e8 a3 e6 ff ff       	call   14f8 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    2e55:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2e58:	89 04 24             	mov    %eax,(%esp)
    2e5b:	e8 8d d9 ff ff       	call   7ed <ck_pr_md_load_uint>
    2e60:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    2e63:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2e66:	83 c0 01             	add    $0x1,%eax
    2e69:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    2e6c:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2e6f:	2b 45 d8             	sub    -0x28(%ebp),%eax
    2e72:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    2e75:	0f 97 c0             	seta   %al
    2e78:	0f b6 c0             	movzbl %al,%eax
    2e7b:	85 c0                	test   %eax,%eax
    2e7d:	74 29                	je     2ea8 <ck_ring_enqueue_mpmc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    2e7f:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2e82:	8b 55 f4             	mov    -0xc(%ebp),%edx
    2e85:	8d 4a 44             	lea    0x44(%edx),%ecx
    2e88:	8d 55 cc             	lea    -0x34(%ebp),%edx
    2e8b:	89 54 24 0c          	mov    %edx,0xc(%esp)
    2e8f:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    2e92:	89 54 24 08          	mov    %edx,0x8(%esp)
    2e96:	89 44 24 04          	mov    %eax,0x4(%esp)
    2e9a:	89 0c 24             	mov    %ecx,(%esp)
    2e9d:	e8 4c e3 ff ff       	call   11ee <ck_pr_cas_uint_value>
    2ea2:	84 c0                	test   %al,%al
    2ea4:	75 31                	jne    2ed7 <ck_ring_enqueue_mpmc_xcpu+0xce>
    2ea6:	eb a8                	jmp    2e50 <ck_ring_enqueue_mpmc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    2ea8:	e8 4b e6 ff ff       	call   14f8 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    2ead:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2eb0:	83 c0 44             	add    $0x44,%eax
    2eb3:	89 04 24             	mov    %eax,(%esp)
    2eb6:	e8 32 d9 ff ff       	call   7ed <ck_pr_md_load_uint>
    2ebb:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    2ebe:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2ec1:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    2ec4:	75 06                	jne    2ecc <ck_ring_enqueue_mpmc_xcpu+0xc3>
				r = false;
    2ec6:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    2eca:	eb 67                	jmp    2f33 <ck_ring_enqueue_mpmc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    2ecc:	8b 45 d0             	mov    -0x30(%ebp),%eax
    2ecf:	89 45 cc             	mov    %eax,-0x34(%ebp)
    2ed2:	e9 79 ff ff ff       	jmp    2e50 <ck_ring_enqueue_mpmc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    2ed7:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2eda:	23 45 e0             	and    -0x20(%ebp),%eax
    2edd:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    2ee1:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    2ee4:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2ee7:	89 44 24 08          	mov    %eax,0x8(%esp)
    2eeb:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2eee:	89 44 24 04          	mov    %eax,0x4(%esp)
    2ef2:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2ef5:	89 04 24             	mov    %eax,(%esp)
    2ef8:	e8 fc ff ff ff       	call   2ef9 <ck_ring_enqueue_mpmc_xcpu+0xf0>
    2efd:	eb 05                	jmp    2f04 <ck_ring_enqueue_mpmc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    2eff:	e8 84 d7 ff ff       	call   688 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    2f04:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2f07:	83 c0 40             	add    $0x40,%eax
    2f0a:	89 04 24             	mov    %eax,(%esp)
    2f0d:	e8 db d8 ff ff       	call   7ed <ck_pr_md_load_uint>
    2f12:	8b 55 cc             	mov    -0x34(%ebp),%edx
    2f15:	39 d0                	cmp    %edx,%eax
    2f17:	75 e6                	jne    2eff <ck_ring_enqueue_mpmc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    2f19:	e8 e5 e5 ff ff       	call   1503 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    2f1e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2f21:	8d 50 40             	lea    0x40(%eax),%edx
    2f24:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    2f27:	89 44 24 04          	mov    %eax,0x4(%esp)
    2f2b:	89 14 24             	mov    %edx,(%esp)
    2f2e:	e8 43 d9 ff ff       	call   876 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    2f33:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    2f37:	74 10                	je     2f49 <ck_ring_enqueue_mpmc_xcpu+0x140>
		*size = (producer - consumer) & mask;
    2f39:	8b 45 cc             	mov    -0x34(%ebp),%eax
    2f3c:	2b 45 d8             	sub    -0x28(%ebp),%eax
    2f3f:	23 45 e0             	and    -0x20(%ebp),%eax
    2f42:	89 c2                	mov    %eax,%edx
    2f44:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    2f47:	89 10                	mov    %edx,(%eax)

	return r;
    2f49:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    2f4d:	c9                   	leave  
    2f4e:	c3                   	ret    

00002f4f <ck_ring_trydequeue_mpmc_xcpu>:
    2f4f:	55                   	push   %ebp
    2f50:	89 e5                	mov    %esp,%ebp
    2f52:	83 ec 38             	sub    $0x38,%esp
    2f55:	8b 45 08             	mov    0x8(%ebp),%eax
    2f58:	89 45 f4             	mov    %eax,-0xc(%ebp)
    2f5b:	8b 45 0c             	mov    0xc(%ebp),%eax
    2f5e:	89 45 f0             	mov    %eax,-0x10(%ebp)
    2f61:	8b 45 10             	mov    0x10(%ebp),%eax
    2f64:	89 45 ec             	mov    %eax,-0x14(%ebp)
    2f67:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    2f6e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2f71:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    2f77:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    2f7a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2f7d:	89 04 24             	mov    %eax,(%esp)
    2f80:	e8 68 d8 ff ff       	call   7ed <ck_pr_md_load_uint>
    2f85:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    2f88:	e8 6b e5 ff ff       	call   14f8 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    2f8d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2f90:	83 c0 40             	add    $0x40,%eax
    2f93:	89 04 24             	mov    %eax,(%esp)
    2f96:	e8 52 d8 ff ff       	call   7ed <ck_pr_md_load_uint>
    2f9b:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    2f9e:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2fa1:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    2fa4:	0f 94 c0             	sete   %al
    2fa7:	0f b6 c0             	movzbl %al,%eax
    2faa:	85 c0                	test   %eax,%eax
    2fac:	74 07                	je     2fb5 <ck_ring_trydequeue_mpmc_xcpu+0x66>
		return false;
    2fae:	b8 00 00 00 00       	mov    $0x0,%eax
    2fb3:	eb 4e                	jmp    3003 <ck_ring_trydequeue_mpmc_xcpu+0xb4>

	ck_pr_fence_load();
    2fb5:	e8 3e e5 ff ff       	call   14f8 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    2fba:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2fbd:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    2fc0:	21 d0                	and    %edx,%eax
    2fc2:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    2fc6:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    2fc9:	8b 45 e8             	mov    -0x18(%ebp),%eax
    2fcc:	89 44 24 08          	mov    %eax,0x8(%esp)
    2fd0:	8b 45 f0             	mov    -0x10(%ebp),%eax
    2fd3:	89 44 24 04          	mov    %eax,0x4(%esp)
    2fd7:	8b 45 ec             	mov    -0x14(%ebp),%eax
    2fda:	89 04 24             	mov    %eax,(%esp)
    2fdd:	e8 fc ff ff ff       	call   2fde <ck_ring_trydequeue_mpmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
    2fe2:	e8 e5 e4 ff ff       	call   14cc <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    2fe7:	8b 45 e0             	mov    -0x20(%ebp),%eax
    2fea:	8d 50 01             	lea    0x1(%eax),%edx
    2fed:	8b 45 f4             	mov    -0xc(%ebp),%eax
    2ff0:	89 54 24 08          	mov    %edx,0x8(%esp)
    2ff4:	8b 55 e0             	mov    -0x20(%ebp),%edx
    2ff7:	89 54 24 04          	mov    %edx,0x4(%esp)
    2ffb:	89 04 24             	mov    %eax,(%esp)
    2ffe:	e8 98 e0 ff ff       	call   109b <ck_pr_cas_uint>
    3003:	c9                   	leave  
    3004:	c3                   	ret    

00003005 <ck_ring_dequeue_mpmc_xcpu>:
    3005:	55                   	push   %ebp
    3006:	89 e5                	mov    %esp,%ebp
    3008:	53                   	push   %ebx
    3009:	83 ec 34             	sub    $0x34,%esp
    300c:	8b 45 08             	mov    0x8(%ebp),%eax
    300f:	89 45 f4             	mov    %eax,-0xc(%ebp)
    3012:	8b 45 0c             	mov    0xc(%ebp),%eax
    3015:	89 45 f0             	mov    %eax,-0x10(%ebp)
    3018:	8b 45 10             	mov    0x10(%ebp),%eax
    301b:	89 45 ec             	mov    %eax,-0x14(%ebp)
    301e:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    3025:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3028:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    302e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    3031:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3034:	89 04 24             	mov    %eax,(%esp)
    3037:	e8 b1 d7 ff ff       	call   7ed <ck_pr_md_load_uint>
    303c:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    303f:	e8 b4 e4 ff ff       	call   14f8 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    3044:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3047:	83 c0 40             	add    $0x40,%eax
    304a:	89 04 24             	mov    %eax,(%esp)
    304d:	e8 9b d7 ff ff       	call   7ed <ck_pr_md_load_uint>
    3052:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    3055:	8b 45 d8             	mov    -0x28(%ebp),%eax
    3058:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    305b:	0f 94 c0             	sete   %al
    305e:	0f b6 c0             	movzbl %al,%eax
    3061:	85 c0                	test   %eax,%eax
    3063:	74 07                	je     306c <ck_ring_dequeue_mpmc_xcpu+0x67>
			return false;
    3065:	b8 00 00 00 00       	mov    $0x0,%eax
    306a:	eb 6a                	jmp    30d6 <ck_ring_dequeue_mpmc_xcpu+0xd1>

		ck_pr_fence_load();
    306c:	e8 87 e4 ff ff       	call   14f8 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    3071:	8b 45 d8             	mov    -0x28(%ebp),%eax
    3074:	23 45 e4             	and    -0x1c(%ebp),%eax
    3077:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    307b:	89 c2                	mov    %eax,%edx
    307d:	8b 45 f0             	mov    -0x10(%ebp),%eax
    3080:	01 d0                	add    %edx,%eax
    3082:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    3085:	8b 45 e8             	mov    -0x18(%ebp),%eax
    3088:	89 44 24 08          	mov    %eax,0x8(%esp)
    308c:	8b 45 dc             	mov    -0x24(%ebp),%eax
    308f:	89 44 24 04          	mov    %eax,0x4(%esp)
    3093:	8b 45 ec             	mov    -0x14(%ebp),%eax
    3096:	89 04 24             	mov    %eax,(%esp)
    3099:	e8 fc ff ff ff       	call   309a <ck_ring_dequeue_mpmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    309e:	e8 29 e4 ff ff       	call   14cc <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    30a3:	8b 45 d8             	mov    -0x28(%ebp),%eax
    30a6:	8d 58 01             	lea    0x1(%eax),%ebx
    30a9:	8b 55 d8             	mov    -0x28(%ebp),%edx
    30ac:	8b 45 f4             	mov    -0xc(%ebp),%eax
    30af:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    30b2:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    30b6:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    30ba:	89 54 24 04          	mov    %edx,0x4(%esp)
    30be:	89 04 24             	mov    %eax,(%esp)
    30c1:	e8 28 e1 ff ff       	call   11ee <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    30c6:	83 f0 01             	xor    $0x1,%eax
    30c9:	84 c0                	test   %al,%al
    30cb:	0f 85 6e ff ff ff    	jne    303f <ck_ring_dequeue_mpmc_xcpu+0x3a>

	return true;
    30d1:	b8 01 00 00 00       	mov    $0x1,%eax
    30d6:	83 c4 34             	add    $0x34,%esp
    30d9:	5b                   	pop    %ebx
    30da:	5d                   	pop    %ebp
    30db:	c3                   	ret    

000030dc <sl__globals_cpu>:

extern struct sl_global_cpu sl_global_cpu_data[];

static inline struct sl_global_cpu *
sl__globals_cpu(void)
{
    30dc:	55                   	push   %ebp
    30dd:	89 e5                	mov    %esp,%ebp
	return &(sl_global_cpu_data[cos_cpuid()]);
    30df:	e8 15 d0 ff ff       	call   f9 <cos_cpuid>
    30e4:	c1 e0 03             	shl    $0x3,%eax
    30e7:	8d 14 c5 00 00 00 00 	lea    0x0(,%eax,8),%edx
    30ee:	29 c2                	sub    %eax,%edx
    30f0:	8d 82 00 00 00 00    	lea    0x0(%edx),%eax
}
    30f6:	5d                   	pop    %ebp
    30f7:	c3                   	ret    

000030f8 <sl_usec2cyc>:
	return cyc / sl__globals_cpu()->cyc_per_usec;
}

static inline cycles_t
sl_usec2cyc(microsec_t usec)
{
    30f8:	55                   	push   %ebp
    30f9:	89 e5                	mov    %esp,%ebp
    30fb:	53                   	push   %ebx
    30fc:	83 ec 0c             	sub    $0xc,%esp
    30ff:	8b 45 08             	mov    0x8(%ebp),%eax
    3102:	89 45 f0             	mov    %eax,-0x10(%ebp)
    3105:	8b 45 0c             	mov    0xc(%ebp),%eax
    3108:	89 45 f4             	mov    %eax,-0xc(%ebp)
	return usec * sl__globals_cpu()->cyc_per_usec;
    310b:	e8 cc ff ff ff       	call   30dc <sl__globals_cpu>
    3110:	8b 40 18             	mov    0x18(%eax),%eax
    3113:	99                   	cltd   
    3114:	8b 4d f0             	mov    -0x10(%ebp),%ecx
    3117:	89 cb                	mov    %ecx,%ebx
    3119:	0f af da             	imul   %edx,%ebx
    311c:	8b 4d f4             	mov    -0xc(%ebp),%ecx
    311f:	0f af c8             	imul   %eax,%ecx
    3122:	01 d9                	add    %ebx,%ecx
    3124:	f7 65 f0             	mull   -0x10(%ebp)
    3127:	01 d1                	add    %edx,%ecx
    3129:	89 ca                	mov    %ecx,%edx
}
    312b:	83 c4 0c             	add    $0xc,%esp
    312e:	5b                   	pop    %ebx
    312f:	5d                   	pop    %ebp
    3130:	c3                   	ret    

00003131 <sl_now>:

static inline cycles_t
sl_now(void)
{
    3131:	55                   	push   %ebp
    3132:	89 e5                	mov    %esp,%ebp
	return ps_tsc();
    3134:	e8 10 d2 ff ff       	call   349 <ps_tsc>
}
    3139:	5d                   	pop    %ebp
    313a:	c3                   	ret    

0000313b <reg_thd_fn>:
static int thd2_fpu[NUM_CPU] = { 0 };
static int thd3_fpu[NUM_CPU] = { 0 };
static int thd4_reg[NUM_CPU] = { 0 };
static void
reg_thd_fn()
{
    313b:	55                   	push   %ebp
    313c:	89 e5                	mov    %esp,%ebp
    313e:	56                   	push   %esi
    313f:	53                   	push   %ebx
    3140:	83 ec 10             	sub    $0x10,%esp
	thd1_reg[cos_cpuid()] = 1;
    3143:	e8 b1 cf ff ff       	call   f9 <cos_cpuid>
    3148:	c7 04 85 04 00 00 00 	movl   $0x1,0x4(,%eax,4)
    314f:	01 00 00 00 
	while (1) PRINTC("in thd reg1\n");
    3153:	e8 c9 cf ff ff       	call   121 <cos_spd_id>
    3158:	89 c3                	mov    %eax,%ebx
    315a:	e8 b8 cf ff ff       	call   117 <cos_thdid>
    315f:	0f b7 f0             	movzwl %ax,%esi
    3162:	e8 92 cf ff ff       	call   f9 <cos_cpuid>
    3167:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    316b:	89 74 24 08          	mov    %esi,0x8(%esp)
    316f:	89 44 24 04          	mov    %eax,0x4(%esp)
    3173:	c7 04 24 c4 01 00 00 	movl   $0x1c4,(%esp)
    317a:	e8 2a d1 ff ff       	call   2a9 <printc>
    317f:	eb d2                	jmp    3153 <reg_thd_fn+0x18>

00003181 <reg2_thd_fn>:
}
static void
reg2_thd_fn()
{
    3181:	55                   	push   %ebp
    3182:	89 e5                	mov    %esp,%ebp
    3184:	56                   	push   %esi
    3185:	53                   	push   %ebx
    3186:	83 ec 30             	sub    $0x30,%esp
	thd4_reg[cos_cpuid()] = 1;
    3189:	e8 6b cf ff ff       	call   f9 <cos_cpuid>
    318e:	c7 04 85 10 00 00 00 	movl   $0x1,0x10(,%eax,4)
    3195:	01 00 00 00 
	float m = 1.0;
    3199:	a1 28 03 00 00       	mov    0x328,%eax
    319e:	89 45 f4             	mov    %eax,-0xc(%ebp)
	int   i = 1;
    31a1:	c7 45 f0 01 00 00 00 	movl   $0x1,-0x10(%ebp)
	while (i < 100) {
    31a8:	eb 30                	jmp    31da <reg2_thd_fn+0x59>
		PRINTC("in thd reg2\n");
    31aa:	e8 72 cf ff ff       	call   121 <cos_spd_id>
    31af:	89 c3                	mov    %eax,%ebx
    31b1:	e8 61 cf ff ff       	call   117 <cos_thdid>
    31b6:	0f b7 f0             	movzwl %ax,%esi
    31b9:	e8 3b cf ff ff       	call   f9 <cos_cpuid>
    31be:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    31c2:	89 74 24 08          	mov    %esi,0x8(%esp)
    31c6:	89 44 24 04          	mov    %eax,0x4(%esp)
    31ca:	c7 04 24 de 01 00 00 	movl   $0x1de,(%esp)
    31d1:	e8 d3 d0 ff ff       	call   2a9 <printc>
		i++;
    31d6:	83 45 f0 01          	addl   $0x1,-0x10(%ebp)
reg2_thd_fn()
{
	thd4_reg[cos_cpuid()] = 1;
	float m = 1.0;
	int   i = 1;
	while (i < 100) {
    31da:	83 7d f0 63          	cmpl   $0x63,-0x10(%ebp)
    31de:	7e ca                	jle    31aa <reg2_thd_fn+0x29>
		PRINTC("in thd reg2\n");
		i++;
	}
	while (m < 200) {
    31e0:	eb 43                	jmp    3225 <reg2_thd_fn+0xa4>
		m += 1.0;
    31e2:	d9 45 f4             	flds   -0xc(%ebp)
    31e5:	d9 e8                	fld1   
    31e7:	de c1                	faddp  %st,%st(1)
    31e9:	d9 5d f4             	fstps  -0xc(%ebp)
		PRINTC("in thd reg2 %f\n", m);
    31ec:	d9 45 f4             	flds   -0xc(%ebp)
    31ef:	dd 5d e0             	fstpl  -0x20(%ebp)
    31f2:	e8 2a cf ff ff       	call   121 <cos_spd_id>
    31f7:	89 c3                	mov    %eax,%ebx
    31f9:	e8 19 cf ff ff       	call   117 <cos_thdid>
    31fe:	0f b7 f0             	movzwl %ax,%esi
    3201:	e8 f3 ce ff ff       	call   f9 <cos_cpuid>
    3206:	dd 45 e0             	fldl   -0x20(%ebp)
    3209:	dd 5c 24 10          	fstpl  0x10(%esp)
    320d:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    3211:	89 74 24 08          	mov    %esi,0x8(%esp)
    3215:	89 44 24 04          	mov    %eax,0x4(%esp)
    3219:	c7 04 24 f8 01 00 00 	movl   $0x1f8,(%esp)
    3220:	e8 84 d0 ff ff       	call   2a9 <printc>
	int   i = 1;
	while (i < 100) {
		PRINTC("in thd reg2\n");
		i++;
	}
	while (m < 200) {
    3225:	d9 05 2c 03 00 00    	flds   0x32c
    322b:	d9 45 f4             	flds   -0xc(%ebp)
    322e:	d9 c9                	fxch   %st(1)
    3230:	df e9                	fucomip %st(1),%st
    3232:	dd d8                	fstp   %st(0)
    3234:	77 ac                	ja     31e2 <reg2_thd_fn+0x61>
		m += 1.0;
		PRINTC("in thd reg2 %f\n", m);
	}
}
    3236:	83 c4 30             	add    $0x30,%esp
    3239:	5b                   	pop    %ebx
    323a:	5e                   	pop    %esi
    323b:	5d                   	pop    %ebp
    323c:	c3                   	ret    

0000323d <pi_thd_fn>:
static void
pi_thd_fn()
{
    323d:	55                   	push   %ebp
    323e:	89 e5                	mov    %esp,%ebp
    3240:	56                   	push   %esi
    3241:	53                   	push   %ebx
    3242:	83 ec 40             	sub    $0x40,%esp
	thd2_fpu[cos_cpuid()] = 1;
    3245:	e8 af ce ff ff       	call   f9 <cos_cpuid>
    324a:	c7 04 85 08 00 00 00 	movl   $0x1,0x8(,%eax,4)
    3251:	01 00 00 00 
	float    PI = 3.0;
    3255:	a1 30 03 00 00       	mov    0x330,%eax
    325a:	89 45 f4             	mov    %eax,-0xc(%ebp)
	int      flag = 1, i;
    325d:	c7 45 f0 01 00 00 00 	movl   $0x1,-0x10(%ebp)
	for (i = 2; i < 20; i += 2) {	
    3264:	c7 45 ec 02 00 00 00 	movl   $0x2,-0x14(%ebp)
    326b:	e9 97 00 00 00       	jmp    3307 <pi_thd_fn+0xca>
		if (flag) {
    3270:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    3274:	74 2b                	je     32a1 <pi_thd_fn+0x64>
			PI += (4.0 / (i * (i + 1) * (i + 2)));
    3276:	d9 45 f4             	flds   -0xc(%ebp)
    3279:	8b 45 ec             	mov    -0x14(%ebp),%eax
    327c:	83 c0 01             	add    $0x1,%eax
    327f:	0f af 45 ec          	imul   -0x14(%ebp),%eax
    3283:	8b 55 ec             	mov    -0x14(%ebp),%edx
    3286:	83 c2 02             	add    $0x2,%edx
    3289:	0f af c2             	imul   %edx,%eax
    328c:	89 45 e0             	mov    %eax,-0x20(%ebp)
    328f:	db 45 e0             	fildl  -0x20(%ebp)
    3292:	dd 05 38 03 00 00    	fldl   0x338
    3298:	de f1                	fdivp  %st,%st(1)
    329a:	de c1                	faddp  %st,%st(1)
    329c:	d9 5d f4             	fstps  -0xc(%ebp)
    329f:	eb 29                	jmp    32ca <pi_thd_fn+0x8d>
		} else {
			PI -= (4.0 / (i * (i + 1) * (i + 2)));
    32a1:	d9 45 f4             	flds   -0xc(%ebp)
    32a4:	8b 45 ec             	mov    -0x14(%ebp),%eax
    32a7:	83 c0 01             	add    $0x1,%eax
    32aa:	0f af 45 ec          	imul   -0x14(%ebp),%eax
    32ae:	8b 55 ec             	mov    -0x14(%ebp),%edx
    32b1:	83 c2 02             	add    $0x2,%edx
    32b4:	0f af c2             	imul   %edx,%eax
    32b7:	89 45 e0             	mov    %eax,-0x20(%ebp)
    32ba:	db 45 e0             	fildl  -0x20(%ebp)
    32bd:	dd 05 38 03 00 00    	fldl   0x338
    32c3:	de f1                	fdivp  %st,%st(1)
    32c5:	de e9                	fsubrp %st,%st(1)
    32c7:	d9 5d f4             	fstps  -0xc(%ebp)
		}
		flag = !flag;
    32ca:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    32ce:	0f 94 c0             	sete   %al
    32d1:	0f b6 c0             	movzbl %al,%eax
    32d4:	89 45 f0             	mov    %eax,-0x10(%ebp)
		PRINTC("in thd pi\n");
    32d7:	e8 45 ce ff ff       	call   121 <cos_spd_id>
    32dc:	89 c3                	mov    %eax,%ebx
    32de:	e8 34 ce ff ff       	call   117 <cos_thdid>
    32e3:	0f b7 f0             	movzwl %ax,%esi
    32e6:	e8 0e ce ff ff       	call   f9 <cos_cpuid>
    32eb:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    32ef:	89 74 24 08          	mov    %esi,0x8(%esp)
    32f3:	89 44 24 04          	mov    %eax,0x4(%esp)
    32f7:	c7 04 24 15 02 00 00 	movl   $0x215,(%esp)
    32fe:	e8 a6 cf ff ff       	call   2a9 <printc>
pi_thd_fn()
{
	thd2_fpu[cos_cpuid()] = 1;
	float    PI = 3.0;
	int      flag = 1, i;
	for (i = 2; i < 20; i += 2) {	
    3303:	83 45 ec 02          	addl   $0x2,-0x14(%ebp)
    3307:	83 7d ec 13          	cmpl   $0x13,-0x14(%ebp)
    330b:	0f 8e 5f ff ff ff    	jle    3270 <pi_thd_fn+0x33>
			PI -= (4.0 / (i * (i + 1) * (i + 2)));
		}
		flag = !flag;
		PRINTC("in thd pi\n");
	}
        PRINTC("\tpi = %f: \t\t\tFinish calculate Pi\n", PI);
    3311:	d9 45 f4             	flds   -0xc(%ebp)
    3314:	dd 5d d8             	fstpl  -0x28(%ebp)
    3317:	e8 05 ce ff ff       	call   121 <cos_spd_id>
    331c:	89 c3                	mov    %eax,%ebx
    331e:	e8 f4 cd ff ff       	call   117 <cos_thdid>
    3323:	0f b7 f0             	movzwl %ax,%esi
    3326:	e8 ce cd ff ff       	call   f9 <cos_cpuid>
    332b:	dd 45 d8             	fldl   -0x28(%ebp)
    332e:	dd 5c 24 10          	fstpl  0x10(%esp)
    3332:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    3336:	89 74 24 08          	mov    %esi,0x8(%esp)
    333a:	89 44 24 04          	mov    %eax,0x4(%esp)
    333e:	c7 04 24 30 02 00 00 	movl   $0x230,(%esp)
    3345:	e8 5f cf ff ff       	call   2a9 <printc>
	return;
    334a:	90                   	nop
}
    334b:	83 c4 40             	add    $0x40,%esp
    334e:	5b                   	pop    %ebx
    334f:	5e                   	pop    %esi
    3350:	5d                   	pop    %ebp
    3351:	c3                   	ret    

00003352 <euler_thd_fn>:

static void
euler_thd_fn()
{
    3352:	55                   	push   %ebp
    3353:	89 e5                	mov    %esp,%ebp
    3355:	56                   	push   %esi
    3356:	53                   	push   %ebx
    3357:	83 ec 40             	sub    $0x40,%esp
	thd3_fpu[cos_cpuid()] = 1;
    335a:	e8 9a cd ff ff       	call   f9 <cos_cpuid>
    335f:	c7 04 85 0c 00 00 00 	movl   $0x1,0xc(,%eax,4)
    3366:	01 00 00 00 
	float    E = 1.0;
    336a:	a1 28 03 00 00       	mov    0x328,%eax
    336f:	89 45 f4             	mov    %eax,-0xc(%ebp)
	int   	 i, fact = 1;
    3372:	c7 45 ec 01 00 00 00 	movl   $0x1,-0x14(%ebp)
	for (i = 1; i < 20; i++) {	
    3379:	c7 45 f0 01 00 00 00 	movl   $0x1,-0x10(%ebp)
    3380:	eb 49                	jmp    33cb <euler_thd_fn+0x79>
		fact *= i;
    3382:	8b 45 ec             	mov    -0x14(%ebp),%eax
    3385:	0f af 45 f0          	imul   -0x10(%ebp),%eax
    3389:	89 45 ec             	mov    %eax,-0x14(%ebp)
		E += (1.0 / fact);
    338c:	d9 45 f4             	flds   -0xc(%ebp)
    338f:	db 45 ec             	fildl  -0x14(%ebp)
    3392:	d9 e8                	fld1   
    3394:	de f1                	fdivp  %st,%st(1)
    3396:	de c1                	faddp  %st,%st(1)
    3398:	d9 5d f4             	fstps  -0xc(%ebp)
		PRINTC("in thd euler\n");	
    339b:	e8 81 cd ff ff       	call   121 <cos_spd_id>
    33a0:	89 c3                	mov    %eax,%ebx
    33a2:	e8 70 cd ff ff       	call   117 <cos_thdid>
    33a7:	0f b7 f0             	movzwl %ax,%esi
    33aa:	e8 4a cd ff ff       	call   f9 <cos_cpuid>
    33af:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    33b3:	89 74 24 08          	mov    %esi,0x8(%esp)
    33b7:	89 44 24 04          	mov    %eax,0x4(%esp)
    33bb:	c7 04 24 5f 02 00 00 	movl   $0x25f,(%esp)
    33c2:	e8 e2 ce ff ff       	call   2a9 <printc>
euler_thd_fn()
{
	thd3_fpu[cos_cpuid()] = 1;
	float    E = 1.0;
	int   	 i, fact = 1;
	for (i = 1; i < 20; i++) {	
    33c7:	83 45 f0 01          	addl   $0x1,-0x10(%ebp)
    33cb:	83 7d f0 13          	cmpl   $0x13,-0x10(%ebp)
    33cf:	7e b1                	jle    3382 <euler_thd_fn+0x30>
		fact *= i;
		E += (1.0 / fact);
		PRINTC("in thd euler\n");	
	}
        PRINTC("\te = %f: \t\t\tFinish calculate E\n", E);
    33d1:	d9 45 f4             	flds   -0xc(%ebp)
    33d4:	dd 5d d8             	fstpl  -0x28(%ebp)
    33d7:	e8 45 cd ff ff       	call   121 <cos_spd_id>
    33dc:	89 c3                	mov    %eax,%ebx
    33de:	e8 34 cd ff ff       	call   117 <cos_thdid>
    33e3:	0f b7 f0             	movzwl %ax,%esi
    33e6:	e8 0e cd ff ff       	call   f9 <cos_cpuid>
    33eb:	dd 45 d8             	fldl   -0x28(%ebp)
    33ee:	dd 5c 24 10          	fstpl  0x10(%esp)
    33f2:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    33f6:	89 74 24 08          	mov    %esi,0x8(%esp)
    33fa:	89 44 24 04          	mov    %eax,0x4(%esp)
    33fe:	c7 04 24 7c 02 00 00 	movl   $0x27c,(%esp)
    3405:	e8 9f ce ff ff       	call   2a9 <printc>
	return;
    340a:	90                   	nop
}
    340b:	83 c4 40             	add    $0x40,%esp
    340e:	5b                   	pop    %ebx
    340f:	5e                   	pop    %esi
    3410:	5d                   	pop    %ebp
    3411:	c3                   	ret    

00003412 <allocator_thread_fn>:
static void
allocator_thread_fn()
{
    3412:	55                   	push   %ebp
    3413:	89 e5                	mov    %esp,%ebp
    3415:	56                   	push   %esi
    3416:	53                   	push   %ebx
    3417:	83 ec 20             	sub    $0x20,%esp
	struct sl_thd *thd1, *thd2, *thd3;
	cycles_t wakeup;

	thd1 = sl_thd_alloc(reg_thd_fn, NULL);
    341a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    3421:	00 
    3422:	c7 04 24 3b 31 00 00 	movl   $0x313b,(%esp)
    3429:	e8 fc ff ff ff       	call   342a <allocator_thread_fn+0x18>
    342e:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_thd_param_set(thd1, sched_param_pack(SCHEDP_PRIO, FIXED_PRIORITY));
    3431:	c7 44 24 04 0a 00 00 	movl   $0xa,0x4(%esp)
    3438:	00 
    3439:	c7 04 24 01 00 00 00 	movl   $0x1,(%esp)
    3440:	e8 a2 cf ff ff       	call   3e7 <sched_param_pack>
    3445:	89 44 24 04          	mov    %eax,0x4(%esp)
    3449:	8b 45 f4             	mov    -0xc(%ebp),%eax
    344c:	89 04 24             	mov    %eax,(%esp)
    344f:	e8 fc ff ff ff       	call   3450 <allocator_thread_fn+0x3e>

	thd2 = sl_thd_alloc(reg2_thd_fn, NULL);
    3454:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    345b:	00 
    345c:	c7 04 24 81 31 00 00 	movl   $0x3181,(%esp)
    3463:	e8 fc ff ff ff       	call   3464 <allocator_thread_fn+0x52>
    3468:	89 45 f0             	mov    %eax,-0x10(%ebp)
	sl_thd_param_set(thd2, sched_param_pack(SCHEDP_PRIO, FIXED_PRIORITY));
    346b:	c7 44 24 04 0a 00 00 	movl   $0xa,0x4(%esp)
    3472:	00 
    3473:	c7 04 24 01 00 00 00 	movl   $0x1,(%esp)
    347a:	e8 68 cf ff ff       	call   3e7 <sched_param_pack>
    347f:	89 44 24 04          	mov    %eax,0x4(%esp)
    3483:	8b 45 f0             	mov    -0x10(%ebp),%eax
    3486:	89 04 24             	mov    %eax,(%esp)
    3489:	e8 fc ff ff ff       	call   348a <allocator_thread_fn+0x78>

	//thd3 = sl_thd_alloc(euler_thd_fn, NULL);
	//sl_thd_param_set(thd3, sched_param_pack(SCHEDP_PRIO, FIXED_PRIORITY));

	wakeup = sl_now() + sl_usec2cyc(1000 * 1000);
    348e:	e8 9e fc ff ff       	call   3131 <sl_now>
    3493:	89 c3                	mov    %eax,%ebx
    3495:	89 d6                	mov    %edx,%esi
    3497:	c7 04 24 40 42 0f 00 	movl   $0xf4240,(%esp)
    349e:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    34a5:	00 
    34a6:	e8 4d fc ff ff       	call   30f8 <sl_usec2cyc>
    34ab:	01 d8                	add    %ebx,%eax
    34ad:	11 f2                	adc    %esi,%edx
    34af:	89 45 e8             	mov    %eax,-0x18(%ebp)
    34b2:	89 55 ec             	mov    %edx,-0x14(%ebp)
	sl_thd_block_timeout(0, wakeup);
    34b5:	8b 45 e8             	mov    -0x18(%ebp),%eax
    34b8:	8b 55 ec             	mov    -0x14(%ebp),%edx
    34bb:	89 44 24 04          	mov    %eax,0x4(%esp)
    34bf:	89 54 24 08          	mov    %edx,0x8(%esp)
    34c3:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    34ca:	e8 fc ff ff ff       	call   34cb <allocator_thread_fn+0xb9>

	sl_thd_free(thd1);
    34cf:	8b 45 f4             	mov    -0xc(%ebp),%eax
    34d2:	89 04 24             	mov    %eax,(%esp)
    34d5:	e8 fc ff ff ff       	call   34d6 <allocator_thread_fn+0xc4>
	sl_thd_free(thd2);
    34da:	8b 45 f0             	mov    -0x10(%ebp),%eax
    34dd:	89 04 24             	mov    %eax,(%esp)
    34e0:	e8 fc ff ff ff       	call   34e1 <allocator_thread_fn+0xcf>
	//sl_thd_free(thd3);

	sl_thd_exit();
    34e5:	e8 fc ff ff ff       	call   34e6 <allocator_thread_fn+0xd4>
}
    34ea:	83 c4 20             	add    $0x20,%esp
    34ed:	5b                   	pop    %ebx
    34ee:	5e                   	pop    %esi
    34ef:	5d                   	pop    %ebp
    34f0:	c3                   	ret    

000034f1 <test_swapping>:

static void
test_swapping(void)
{
    34f1:	55                   	push   %ebp
    34f2:	89 e5                	mov    %esp,%ebp
    34f4:	56                   	push   %esi
    34f5:	53                   	push   %ebx
    34f6:	83 ec 20             	sub    $0x20,%esp
	struct sl_thd *allocator_thread;
	cycles_t wakeup;

	allocator_thread = sl_thd_alloc(allocator_thread_fn, NULL);
    34f9:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    3500:	00 
    3501:	c7 04 24 12 34 00 00 	movl   $0x3412,(%esp)
    3508:	e8 fc ff ff ff       	call   3509 <test_swapping+0x18>
    350d:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_thd_param_set(allocator_thread, sched_param_pack(SCHEDP_PRIO, FIXED_PRIORITY));
    3510:	c7 44 24 04 0a 00 00 	movl   $0xa,0x4(%esp)
    3517:	00 
    3518:	c7 04 24 01 00 00 00 	movl   $0x1,(%esp)
    351f:	e8 c3 ce ff ff       	call   3e7 <sched_param_pack>
    3524:	89 44 24 04          	mov    %eax,0x4(%esp)
    3528:	8b 45 f4             	mov    -0xc(%ebp),%eax
    352b:	89 04 24             	mov    %eax,(%esp)
    352e:	e8 fc ff ff ff       	call   352f <test_swapping+0x3e>

	wakeup = sl_now() + sl_usec2cyc(100 * 1000);
    3533:	e8 f9 fb ff ff       	call   3131 <sl_now>
    3538:	89 c3                	mov    %eax,%ebx
    353a:	89 d6                	mov    %edx,%esi
    353c:	c7 04 24 a0 86 01 00 	movl   $0x186a0,(%esp)
    3543:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    354a:	00 
    354b:	e8 a8 fb ff ff       	call   30f8 <sl_usec2cyc>
    3550:	01 d8                	add    %ebx,%eax
    3552:	11 f2                	adc    %esi,%edx
    3554:	89 45 e8             	mov    %eax,-0x18(%ebp)
    3557:	89 55 ec             	mov    %edx,-0x14(%ebp)
	sl_thd_block_timeout(0, wakeup);
    355a:	8b 45 e8             	mov    -0x18(%ebp),%eax
    355d:	8b 55 ec             	mov    -0x14(%ebp),%edx
    3560:	89 44 24 04          	mov    %eax,0x4(%esp)
    3564:	89 54 24 08          	mov    %edx,0x8(%esp)
    3568:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    356f:	e8 fc ff ff ff       	call   3570 <test_swapping+0x7f>
}
    3574:	83 c4 20             	add    $0x20,%esp
    3577:	5b                   	pop    %ebx
    3578:	5e                   	pop    %esi
    3579:	5d                   	pop    %ebp
    357a:	c3                   	ret    

0000357b <run_tests>:


static void
run_tests()
{
    357b:	55                   	push   %ebp
    357c:	89 e5                	mov    %esp,%ebp
    357e:	57                   	push   %edi
    357f:	56                   	push   %esi
    3580:	53                   	push   %ebx
    3581:	83 ec 2c             	sub    $0x2c,%esp
	test_swapping();
    3584:	e8 68 ff ff ff       	call   34f1 <test_swapping>
	PRINTC("%s: Swap back and forth!\n", (thd1_reg[cos_cpuid()] && thd2_fpu[cos_cpuid()]) ? "SUCCESS" : "FAILURE");
    3589:	e8 6b cb ff ff       	call   f9 <cos_cpuid>
    358e:	8b 04 85 04 00 00 00 	mov    0x4(,%eax,4),%eax
    3595:	85 c0                	test   %eax,%eax
    3597:	74 17                	je     35b0 <run_tests+0x35>
    3599:	e8 5b cb ff ff       	call   f9 <cos_cpuid>
    359e:	8b 04 85 08 00 00 00 	mov    0x8(,%eax,4),%eax
    35a5:	85 c0                	test   %eax,%eax
    35a7:	74 07                	je     35b0 <run_tests+0x35>
    35a9:	bb a9 02 00 00       	mov    $0x2a9,%ebx
    35ae:	eb 05                	jmp    35b5 <run_tests+0x3a>
    35b0:	bb b1 02 00 00       	mov    $0x2b1,%ebx
    35b5:	e8 67 cb ff ff       	call   121 <cos_spd_id>
    35ba:	89 c6                	mov    %eax,%esi
    35bc:	e8 56 cb ff ff       	call   117 <cos_thdid>
    35c1:	0f b7 f8             	movzwl %ax,%edi
    35c4:	e8 30 cb ff ff       	call   f9 <cos_cpuid>
    35c9:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    35cd:	89 74 24 0c          	mov    %esi,0xc(%esp)
    35d1:	89 7c 24 08          	mov    %edi,0x8(%esp)
    35d5:	89 44 24 04          	mov    %eax,0x4(%esp)
    35d9:	c7 04 24 bc 02 00 00 	movl   $0x2bc,(%esp)
    35e0:	e8 c4 cc ff ff       	call   2a9 <printc>
	PRINTC("Unit-test done!\n");
    35e5:	e8 37 cb ff ff       	call   121 <cos_spd_id>
    35ea:	89 c3                	mov    %eax,%ebx
    35ec:	e8 26 cb ff ff       	call   117 <cos_thdid>
    35f1:	0f b7 f0             	movzwl %ax,%esi
    35f4:	e8 00 cb ff ff       	call   f9 <cos_cpuid>
    35f9:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    35fd:	89 74 24 08          	mov    %esi,0x8(%esp)
    3601:	89 44 24 04          	mov    %eax,0x4(%esp)
    3605:	c7 04 24 e3 02 00 00 	movl   $0x2e3,(%esp)
    360c:	e8 98 cc ff ff       	call   2a9 <printc>
	sl_thd_exit();
    3611:	e8 fc ff ff ff       	call   3612 <run_tests+0x97>
}
    3616:	83 c4 2c             	add    $0x2c,%esp
    3619:	5b                   	pop    %ebx
    361a:	5e                   	pop    %esi
    361b:	5f                   	pop    %edi
    361c:	5d                   	pop    %ebp
    361d:	c3                   	ret    

0000361e <cos_init>:

void
cos_init(void)
{
    361e:	55                   	push   %ebp
    361f:	89 e5                	mov    %esp,%ebp
    3621:	56                   	push   %esi
    3622:	53                   	push   %ebx
    3623:	83 ec 20             	sub    $0x20,%esp
	int i;
	static unsigned long first = NUM_CPU + 1, init_done[NUM_CPU] = { 0 };
	struct sl_thd *testing_thread;
	struct cos_defcompinfo *defci = cos_defcompinfo_curr_get();
    3626:	e8 fc ff ff ff       	call   3627 <cos_init+0x9>
    362b:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_compinfo    *ci    = cos_compinfo_get(defci);
    362e:	8b 45 f0             	mov    -0x10(%ebp),%eax
    3631:	89 04 24             	mov    %eax,(%esp)
    3634:	e8 fc ff ff ff       	call   3635 <cos_init+0x17>
    3639:	89 45 ec             	mov    %eax,-0x14(%ebp)

	PRINTC("Unit-test for the fpu\n");
    363c:	e8 e0 ca ff ff       	call   121 <cos_spd_id>
    3641:	89 c3                	mov    %eax,%ebx
    3643:	e8 cf ca ff ff       	call   117 <cos_thdid>
    3648:	0f b7 f0             	movzwl %ax,%esi
    364b:	e8 a9 ca ff ff       	call   f9 <cos_cpuid>
    3650:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    3654:	89 74 24 08          	mov    %esi,0x8(%esp)
    3658:	89 44 24 04          	mov    %eax,0x4(%esp)
    365c:	c7 04 24 04 03 00 00 	movl   $0x304,(%esp)
    3663:	e8 41 cc ff ff       	call   2a9 <printc>

	if (ps_cas(&first, NUM_CPU + 1, cos_cpuid())) {
    3668:	e8 8c ca ff ff       	call   f9 <cos_cpuid>
    366d:	89 44 24 08          	mov    %eax,0x8(%esp)
    3671:	c7 44 24 04 02 00 00 	movl   $0x2,0x4(%esp)
    3678:	00 
    3679:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    3680:	e8 85 cc ff ff       	call   30a <ps_cas>
    3685:	85 c0                	test   %eax,%eax
    3687:	74 2d                	je     36b6 <cos_init+0x98>
		cos_meminfo_init(&(ci->mi), BOOT_MEM_KM_BASE, COS_MEM_KERN_PA_SZ, BOOT_CAPTBL_SELF_UNTYPED_PT);
    3689:	8b 45 ec             	mov    -0x14(%ebp),%eax
    368c:	83 c0 2c             	add    $0x2c,%eax
    368f:	c7 44 24 0c 0e 00 00 	movl   $0xe,0xc(%esp)
    3696:	00 
    3697:	c7 44 24 08 00 00 00 	movl   $0x1c000000,0x8(%esp)
    369e:	1c 
    369f:	c7 44 24 04 00 00 40 	movl   $0x400000,0x4(%esp)
    36a6:	00 
    36a7:	89 04 24             	mov    %eax,(%esp)
    36aa:	e8 fc ff ff ff       	call   36ab <cos_init+0x8d>
		cos_defcompinfo_init();
    36af:	e8 fc ff ff ff       	call   36b0 <cos_init+0x92>
    36b4:	eb 19                	jmp    36cf <cos_init+0xb1>
	} else {
		while (!ps_load(&init_done[first])) ;
    36b6:	90                   	nop
    36b7:	a1 00 00 00 00       	mov    0x0,%eax
    36bc:	c1 e0 02             	shl    $0x2,%eax
    36bf:	05 14 00 00 00       	add    $0x14,%eax
    36c4:	8b 00                	mov    (%eax),%eax
    36c6:	85 c0                	test   %eax,%eax
    36c8:	74 ed                	je     36b7 <cos_init+0x99>

		cos_defcompinfo_sched_init();
    36ca:	e8 fc ff ff ff       	call   36cb <cos_init+0xad>
	}
	ps_faa(&init_done[cos_cpuid()], 1);
    36cf:	e8 25 ca ff ff       	call   f9 <cos_cpuid>
    36d4:	c1 e0 02             	shl    $0x2,%eax
    36d7:	05 14 00 00 00       	add    $0x14,%eax
    36dc:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    36e3:	00 
    36e4:	89 04 24             	mov    %eax,(%esp)
    36e7:	e8 45 cc ff ff       	call   331 <ps_faa>
	for (i = 0; i < NUM_CPU; i++) {
    36ec:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    36f3:	eb 16                	jmp    370b <cos_init+0xed>
		while (!ps_load(&init_done[i])) ;
    36f5:	90                   	nop
    36f6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    36f9:	c1 e0 02             	shl    $0x2,%eax
    36fc:	05 14 00 00 00       	add    $0x14,%eax
    3701:	8b 00                	mov    (%eax),%eax
    3703:	85 c0                	test   %eax,%eax
    3705:	74 ef                	je     36f6 <cos_init+0xd8>
		while (!ps_load(&init_done[first])) ;

		cos_defcompinfo_sched_init();
	}
	ps_faa(&init_done[cos_cpuid()], 1);
	for (i = 0; i < NUM_CPU; i++) {
    3707:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    370b:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    370f:	7e e4                	jle    36f5 <cos_init+0xd7>
		while (!ps_load(&init_done[i])) ;
	}

	sl_init(SL_MIN_PERIOD_US);
    3711:	c7 04 24 e8 03 00 00 	movl   $0x3e8,(%esp)
    3718:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    371f:	00 
    3720:	e8 fc ff ff ff       	call   3721 <cos_init+0x103>

	testing_thread = sl_thd_alloc(run_tests, NULL);
    3725:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    372c:	00 
    372d:	c7 04 24 7b 35 00 00 	movl   $0x357b,(%esp)
    3734:	e8 fc ff ff ff       	call   3735 <cos_init+0x117>
    3739:	89 45 e8             	mov    %eax,-0x18(%ebp)
	sl_thd_param_set(testing_thread, sched_param_pack(SCHEDP_PRIO, FIXED_PRIORITY));
    373c:	c7 44 24 04 0a 00 00 	movl   $0xa,0x4(%esp)
    3743:	00 
    3744:	c7 04 24 01 00 00 00 	movl   $0x1,(%esp)
    374b:	e8 97 cc ff ff       	call   3e7 <sched_param_pack>
    3750:	89 44 24 04          	mov    %eax,0x4(%esp)
    3754:	8b 45 e8             	mov    -0x18(%ebp),%eax
    3757:	89 04 24             	mov    %eax,(%esp)
    375a:	e8 fc ff ff ff       	call   375b <cos_init+0x13d>

	sl_sched_loop();
    375f:	e8 fc ff ff ff       	call   3760 <cos_init+0x142>
    3764:	66 90                	xchg   %ax,%ax
    3766:	66 90                	xchg   %ax,%ax
    3768:	66 90                	xchg   %ax,%ax
    376a:	66 90                	xchg   %ax,%ax
    376c:	66 90                	xchg   %ax,%ax
    376e:	66 90                	xchg   %ax,%ax

00003770 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
    3770:	55                   	push   %ebp
    3771:	89 e5                	mov    %esp,%ebp
    3773:	57                   	push   %edi
    3774:	56                   	push   %esi
    3775:	53                   	push   %ebx
    3776:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    3779:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    3780:	8b 45 08             	mov    0x8(%ebp),%eax
    3783:	83 c0 01             	add    $0x1,%eax
    3786:	c1 e0 10             	shl    $0x10,%eax
    3789:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    378c:	8b 45 0c             	mov    0xc(%ebp),%eax
    378f:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    3792:	8b 45 08             	mov    0x8(%ebp),%eax
    3795:	8b 4d 10             	mov    0x10(%ebp),%ecx
    3798:	8b 75 14             	mov    0x14(%ebp),%esi
    379b:	8b 7d 18             	mov    0x18(%ebp),%edi
    379e:	8b 55 1c             	mov    0x1c(%ebp),%edx
    37a1:	89 cb                	mov    %ecx,%ebx
    37a3:	55                   	push   %ebp
    37a4:	89 e5                	mov    %esp,%ebp
    37a6:	b9 b8 37 00 00       	mov    $0x37b8,%ecx
    37ab:	0f 34                	sysenter 
    37ad:	8d 76 00             	lea    0x0(%esi),%esi
    37b0:	eb 0d                	jmp    37bf <call_cap_asm+0x4f>
    37b2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    37b8:	b9 00 00 00 00       	mov    $0x0,%ecx
    37bd:	eb 05                	jmp    37c4 <call_cap_asm+0x54>
    37bf:	b9 01 00 00 00       	mov    $0x1,%ecx
    37c4:	5d                   	pop    %ebp
    37c5:	89 ca                	mov    %ecx,%edx
    37c7:	89 45 ec             	mov    %eax,-0x14(%ebp)
    37ca:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    37cd:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    37d0:	83 c4 10             	add    $0x10,%esp
    37d3:	5b                   	pop    %ebx
    37d4:	5e                   	pop    %esi
    37d5:	5f                   	pop    %edi
    37d6:	5d                   	pop    %ebp
    37d7:	c3                   	ret    

000037d8 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
    37d8:	55                   	push   %ebp
    37d9:	89 e5                	mov    %esp,%ebp
    37db:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
    37de:	8b 45 18             	mov    0x18(%ebp),%eax
    37e1:	89 44 24 14          	mov    %eax,0x14(%esp)
    37e5:	8b 45 14             	mov    0x14(%ebp),%eax
    37e8:	89 44 24 10          	mov    %eax,0x10(%esp)
    37ec:	8b 45 10             	mov    0x10(%ebp),%eax
    37ef:	89 44 24 0c          	mov    %eax,0xc(%esp)
    37f3:	8b 45 0c             	mov    0xc(%ebp),%eax
    37f6:	89 44 24 08          	mov    %eax,0x8(%esp)
    37fa:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    3801:	00 
    3802:	8b 45 08             	mov    0x8(%ebp),%eax
    3805:	89 04 24             	mov    %eax,(%esp)
    3808:	e8 63 ff ff ff       	call   3770 <call_cap_asm>
}
    380d:	c9                   	leave  
    380e:	c3                   	ret    

0000380f <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
    380f:	55                   	push   %ebp
    3810:	89 e5                	mov    %esp,%ebp
    3812:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
    3815:	8b 45 08             	mov    0x8(%ebp),%eax
    3818:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    381f:	00 
    3820:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    3827:	00 
    3828:	8b 55 0c             	mov    0xc(%ebp),%edx
    382b:	89 54 24 08          	mov    %edx,0x8(%esp)
    382f:	89 44 24 04          	mov    %eax,0x4(%esp)
    3833:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    383a:	e8 99 ff ff ff       	call   37d8 <call_cap>
}
    383f:	c9                   	leave  
    3840:	c3                   	ret    

00003841 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
    3841:	55                   	push   %ebp
    3842:	89 e5                	mov    %esp,%ebp
    3844:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
    3847:	89 e0                	mov    %esp,%eax
    3849:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
    384c:	8b 45 fc             	mov    -0x4(%ebp),%eax
    384f:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    3854:	89 c2                	mov    %eax,%edx
    3856:	8b 45 08             	mov    0x8(%ebp),%eax
    3859:	c1 e0 02             	shl    $0x2,%eax
    385c:	29 c2                	sub    %eax,%edx
    385e:	89 d0                	mov    %edx,%eax
    3860:	05 00 10 00 00       	add    $0x1000,%eax
    3865:	8b 00                	mov    (%eax),%eax
}
    3867:	c9                   	leave  
    3868:	c3                   	ret    

00003869 <cos_get_thd_id>:
	return get_stk_data(CPUID_OFFSET);
}

static inline unsigned short int
cos_get_thd_id(void)
{
    3869:	55                   	push   %ebp
    386a:	89 e5                	mov    %esp,%ebp
    386c:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
    386f:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    3876:	e8 c6 ff ff ff       	call   3841 <get_stk_data>
}
    387b:	c9                   	leave  
    387c:	c3                   	ret    

0000387d <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
    387d:	55                   	push   %ebp
    387e:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
    3880:	e8 e4 ff ff ff       	call   3869 <cos_get_thd_id>
}
    3885:	5d                   	pop    %ebp
    3886:	c3                   	ret    

00003887 <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
    3887:	55                   	push   %ebp
    3888:	89 e5                	mov    %esp,%ebp
    388a:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
    388d:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    3894:	eb 20                	jmp    38b6 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
    3896:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3899:	83 c0 01             	add    $0x1,%eax
    389c:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    38a3:	8b 45 08             	mov    0x8(%ebp),%eax
    38a6:	01 d0                	add    %edx,%eax
    38a8:	8b 00                	mov    (%eax),%eax
    38aa:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
    38ad:	8b 45 f0             	mov    -0x10(%ebp),%eax
    38b0:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
    38b2:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    38b6:	8b 45 08             	mov    0x8(%ebp),%eax
    38b9:	8b 00                	mov    (%eax),%eax
    38bb:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    38be:	7f d6                	jg     3896 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
    38c0:	c9                   	leave  
    38c1:	c3                   	ret    

000038c2 <constructors_execute>:

static void
constructors_execute(void)
{
    38c2:	55                   	push   %ebp
    38c3:	89 e5                	mov    %esp,%ebp
    38c5:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
    38c8:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    38cf:	e8 b3 ff ff ff       	call   3887 <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
    38d4:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    38db:	e8 a7 ff ff ff       	call   3887 <section_fnptrs_execute>
}
    38e0:	c9                   	leave  
    38e1:	c3                   	ret    

000038e2 <destructors_execute>:
static void
destructors_execute(void)
{
    38e2:	55                   	push   %ebp
    38e3:	89 e5                	mov    %esp,%ebp
    38e5:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
    38e8:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    38ef:	e8 93 ff ff ff       	call   3887 <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
    38f4:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    38fb:	e8 87 ff ff ff       	call   3887 <section_fnptrs_execute>
}
    3900:	c9                   	leave  
    3901:	c3                   	ret    

00003902 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
    3902:	55                   	push   %ebp
    3903:	89 e5                	mov    %esp,%ebp
    3905:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
    3908:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    390f:	e8 73 ff ff ff       	call   3887 <section_fnptrs_execute>
}
    3914:	c9                   	leave  
    3915:	c3                   	ret    

00003916 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
    3916:	55                   	push   %ebp
    3917:	89 e5                	mov    %esp,%ebp
    3919:	83 ec 08             	sub    $0x8,%esp
    391c:	8b 55 08             	mov    0x8(%ebp),%edx
    391f:	8b 45 0c             	mov    0xc(%ebp),%eax
    3922:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
    3926:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
    3929:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    392d:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
    3931:	ee                   	out    %al,(%dx)
}
    3932:	c9                   	leave  
    3933:	c3                   	ret    

00003934 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
    3934:	55                   	push   %ebp
    3935:	89 e5                	mov    %esp,%ebp
    3937:	83 ec 14             	sub    $0x14,%esp
    393a:	8b 45 08             	mov    0x8(%ebp),%eax
    393d:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
    3941:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
    3945:	89 c2                	mov    %eax,%edx
    3947:	ec                   	in     (%dx),%al
    3948:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
    394b:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
    394f:	c9                   	leave  
    3950:	c3                   	ret    

00003951 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
    3951:	55                   	push   %ebp
    3952:	89 e5                	mov    %esp,%ebp
    3954:	83 ec 0c             	sub    $0xc,%esp
    3957:	8b 45 08             	mov    0x8(%ebp),%eax
    395a:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
    395d:	90                   	nop
    395e:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
    3965:	e8 ca ff ff ff       	call   3934 <inb>
    396a:	0f b6 c0             	movzbl %al,%eax
    396d:	83 e0 20             	and    $0x20,%eax
    3970:	85 c0                	test   %eax,%eax
    3972:	74 ea                	je     395e <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
    3974:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    3978:	0f b6 c0             	movzbl %al,%eax
    397b:	89 44 24 04          	mov    %eax,0x4(%esp)
    397f:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
    3986:	e8 8b ff ff ff       	call   3916 <outb>
}
    398b:	c9                   	leave  
    398c:	c3                   	ret    

0000398d <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
    398d:	55                   	push   %ebp
    398e:	89 e5                	mov    %esp,%ebp
    3990:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
    3993:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
    399a:	eb 1a                	jmp    39b6 <cos_serial_putb+0x29>
    399c:	8b 45 fc             	mov    -0x4(%ebp),%eax
    399f:	8b 55 08             	mov    0x8(%ebp),%edx
    39a2:	01 d0                	add    %edx,%eax
    39a4:	0f b6 00             	movzbl (%eax),%eax
    39a7:	0f be c0             	movsbl %al,%eax
    39aa:	89 04 24             	mov    %eax,(%esp)
    39ad:	e8 9f ff ff ff       	call   3951 <cos_serial_putc>
    39b2:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
    39b6:	8b 45 fc             	mov    -0x4(%ebp),%eax
    39b9:	3b 45 0c             	cmp    0xc(%ebp),%eax
    39bc:	72 de                	jb     399c <cos_serial_putb+0xf>
}
    39be:	c9                   	leave  
    39bf:	c3                   	ret    

000039c0 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
    39c0:	55                   	push   %ebp
    39c1:	89 e5                	mov    %esp,%ebp
    39c3:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
    39c6:	8b 45 0c             	mov    0xc(%ebp),%eax
    39c9:	89 44 24 04          	mov    %eax,0x4(%esp)
    39cd:	8b 45 08             	mov    0x8(%ebp),%eax
    39d0:	89 04 24             	mov    %eax,(%esp)
    39d3:	e8 b5 ff ff ff       	call   398d <cos_serial_putb>
}
    39d8:	c9                   	leave  
    39d9:	c3                   	ret    

000039da <prints>:

static int
prints(char *s)
{
    39da:	55                   	push   %ebp
    39db:	89 e5                	mov    %esp,%ebp
    39dd:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
    39e0:	8b 45 08             	mov    0x8(%ebp),%eax
    39e3:	89 04 24             	mov    %eax,(%esp)
    39e6:	e8 fc ff ff ff       	call   39e7 <prints+0xd>
    39eb:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
    39ee:	8b 45 f4             	mov    -0xc(%ebp),%eax
    39f1:	89 44 24 04          	mov    %eax,0x4(%esp)
    39f5:	8b 45 08             	mov    0x8(%ebp),%eax
    39f8:	89 04 24             	mov    %eax,(%esp)
    39fb:	e8 0f fe ff ff       	call   380f <cos_print>

	return len;
    3a00:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    3a03:	c9                   	leave  
    3a04:	c3                   	ret    

00003a05 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
    3a05:	55                   	push   %ebp
    3a06:	89 e5                	mov    %esp,%ebp
    3a08:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
    3a0e:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
    3a15:	8d 45 0c             	lea    0xc(%ebp),%eax
    3a18:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
    3a1e:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
    3a24:	89 44 24 0c          	mov    %eax,0xc(%esp)
    3a28:	8b 45 08             	mov    0x8(%ebp),%eax
    3a2b:	89 44 24 08          	mov    %eax,0x8(%esp)
    3a2f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3a32:	89 44 24 04          	mov    %eax,0x4(%esp)
    3a36:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    3a3c:	89 04 24             	mov    %eax,(%esp)
    3a3f:	e8 fc ff ff ff       	call   3a40 <printc+0x3b>
    3a44:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
    3a47:	8b 45 f0             	mov    -0x10(%ebp),%eax
    3a4a:	89 44 24 04          	mov    %eax,0x4(%esp)
    3a4e:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    3a54:	89 04 24             	mov    %eax,(%esp)
    3a57:	e8 64 ff ff ff       	call   39c0 <cos_llprint>

	return ret;
    3a5c:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    3a5f:	c9                   	leave  
    3a60:	c3                   	ret    

00003a61 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
    3a61:	55                   	push   %ebp
    3a62:	89 e5                	mov    %esp,%ebp
	while (1)
		;
    3a64:	eb fe                	jmp    3a64 <__cos_noret+0x3>

00003a66 <SS_ipc_client_fault>:
#endif

/* Return zero from SS_ipc_client_fault to cause CSTUB_INVOKE to retry */
__attribute__((weak, regparm(1))) int
SS_ipc_client_fault(cos_flt_off flt)
{
    3a66:	55                   	push   %ebp
    3a67:	89 e5                	mov    %esp,%ebp
    3a69:	83 ec 28             	sub    $0x28,%esp
    3a6c:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	int error_out = 0;
    3a6f:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	switch (flt) {
    3a76:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    3a79:	85 c0                	test   %eax,%eax
    3a7b:	75 09                	jne    3a86 <SS_ipc_client_fault+0x20>
	case COS_FLT_PGFLT:
		error_out = -EFAULT;
    3a7d:	c7 45 f4 f2 ff ff ff 	movl   $0xfffffff2,-0xc(%ebp)
		break;
    3a84:	eb 1c                	jmp    3aa2 <SS_ipc_client_fault+0x3c>
	default:
		/* Any other fault is bad */
		assert(0);
    3a86:	c7 04 24 40 03 00 00 	movl   $0x340,(%esp)
    3a8d:	e8 48 ff ff ff       	call   39da <prints>
    3a92:	a1 18 00 00 00       	mov    0x18,%eax
    3a97:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    3a9d:	e8 bf ff ff ff       	call   3a61 <__cos_noret>
	}

	return error_out;
    3aa2:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    3aa5:	c9                   	leave  
    3aa6:	c3                   	ret    

00003aa7 <SS_ipc_client_marshal_args>:

__attribute__((regparm(1))) int
SS_ipc_client_marshal_args(struct usr_inv_cap *uc, long p0, long p1, long p2, long p3)
{
    3aa7:	55                   	push   %ebp
    3aa8:	89 e5                	mov    %esp,%ebp
    3aaa:	56                   	push   %esi
    3aab:	53                   	push   %ebx
    3aac:	83 ec 20             	sub    $0x20,%esp
    3aaf:	89 45 f4             	mov    %eax,-0xc(%ebp)
	return cos_sinv(uc->cap_no, p0, p1, p2, p3);
    3ab2:	8b 75 14             	mov    0x14(%ebp),%esi
    3ab5:	8b 5d 10             	mov    0x10(%ebp),%ebx
    3ab8:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    3abb:	8b 55 08             	mov    0x8(%ebp),%edx
    3abe:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3ac1:	8b 40 0c             	mov    0xc(%eax),%eax
    3ac4:	89 74 24 10          	mov    %esi,0x10(%esp)
    3ac8:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    3acc:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    3ad0:	89 54 24 04          	mov    %edx,0x4(%esp)
    3ad4:	89 04 24             	mov    %eax,(%esp)
    3ad7:	e8 fc ff ff ff       	call   3ad8 <SS_ipc_client_marshal_args+0x31>
}
    3adc:	83 c4 20             	add    $0x20,%esp
    3adf:	5b                   	pop    %ebx
    3ae0:	5e                   	pop    %esi
    3ae1:	5d                   	pop    %ebp
    3ae2:	c3                   	ret    

00003ae3 <SS_ipc_client_marshal_args_rets>:

__attribute__((regparm(1))) int
SS_ipc_client_marshal_args_rets(struct usr_inv_cap *uc, long *r2, long *r3, long p0, long p1, long p2, long p3)
{
    3ae3:	55                   	push   %ebp
    3ae4:	89 e5                	mov    %esp,%ebp
    3ae6:	57                   	push   %edi
    3ae7:	56                   	push   %esi
    3ae8:	53                   	push   %ebx
    3ae9:	83 ec 2c             	sub    $0x2c,%esp
    3aec:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	return cos_sinv_rets(uc->cap_no, p0, p1, p2, p3, (word_t *)r2, (word_t *)r3);
    3aef:	8b 75 1c             	mov    0x1c(%ebp),%esi
    3af2:	8b 5d 18             	mov    0x18(%ebp),%ebx
    3af5:	8b 4d 14             	mov    0x14(%ebp),%ecx
    3af8:	8b 55 10             	mov    0x10(%ebp),%edx
    3afb:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    3afe:	8b 40 0c             	mov    0xc(%eax),%eax
    3b01:	8b 7d 0c             	mov    0xc(%ebp),%edi
    3b04:	89 7c 24 18          	mov    %edi,0x18(%esp)
    3b08:	8b 7d 08             	mov    0x8(%ebp),%edi
    3b0b:	89 7c 24 14          	mov    %edi,0x14(%esp)
    3b0f:	89 74 24 10          	mov    %esi,0x10(%esp)
    3b13:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    3b17:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    3b1b:	89 54 24 04          	mov    %edx,0x4(%esp)
    3b1f:	89 04 24             	mov    %eax,(%esp)
    3b22:	e8 fc ff ff ff       	call   3b23 <SS_ipc_client_marshal_args_rets+0x40>
}
    3b27:	83 c4 2c             	add    $0x2c,%esp
    3b2a:	5b                   	pop    %ebx
    3b2b:	5e                   	pop    %esi
    3b2c:	5f                   	pop    %edi
    3b2d:	5d                   	pop    %ebp
    3b2e:	c3                   	ret    
    3b2f:	90                   	nop

00003b30 <cos_upcall_entry>:
    3b30:	bc 00 00 00 00       	mov    $0x0,%esp
    3b35:	89 c2                	mov    %eax,%edx
    3b37:	25 ff ff 00 00       	and    $0xffff,%eax
    3b3c:	c1 e0 0c             	shl    $0xc,%eax
    3b3f:	01 c4                	add    %eax,%esp
    3b41:	c1 e8 0c             	shr    $0xc,%eax
    3b44:	c1 ea 10             	shr    $0x10,%edx
    3b47:	52                   	push   %edx
    3b48:	50                   	push   %eax
    3b49:	6a 00                	push   $0x0
    3b4b:	6a 00                	push   $0x0
    3b4d:	89 64 24 f8          	mov    %esp,-0x8(%esp)
    3b51:	6a 00                	push   $0x0
    3b53:	89 64 24 f8          	mov    %esp,-0x8(%esp)
    3b57:	83 ec 08             	sub    $0x8,%esp
    3b5a:	56                   	push   %esi
    3b5b:	57                   	push   %edi
    3b5c:	53                   	push   %ebx
    3b5d:	31 ed                	xor    %ebp,%ebp
    3b5f:	51                   	push   %ecx
    3b60:	e8 fc ff ff ff       	call   3b61 <cos_upcall_entry+0x31>
    3b65:	83 c4 18             	add    $0x18,%esp
    3b68:	5e                   	pop    %esi
    3b69:	5f                   	pop    %edi
    3b6a:	89 c1                	mov    %eax,%ecx
    3b6c:	b8 00 00 01 00       	mov    $0x10000,%eax
    3b71:	0f 34                	sysenter 
    3b73:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    3b79:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

00003b80 <cos_atomic_cmpxchg>:
    3b80:	89 c2                	mov    %eax,%edx
    3b82:	3b 03                	cmp    (%ebx),%eax
    3b84:	0f 85 fc ff ff ff    	jne    3b86 <cos_atomic_cmpxchg+0x6>
    3b8a:	89 ca                	mov    %ecx,%edx
    3b8c:	89 0b                	mov    %ecx,(%ebx)

00003b8e <cos_atomic_cmpxchg_end>:
    3b8e:	c3                   	ret    

00003b8f <cos_atomic_user1>:
    3b8f:	b8 00 00 00 00       	mov    $0x0,%eax
    3b94:	8b 00                	mov    (%eax),%eax
    3b96:	66 90                	xchg   %ax,%ax
    3b98:	66 90                	xchg   %ax,%ax
    3b9a:	66 90                	xchg   %ax,%ax
    3b9c:	66 90                	xchg   %ax,%ax
    3b9e:	66 90                	xchg   %ax,%ax

00003ba0 <cos_ainv_entry>:
    3ba0:	53                   	push   %ebx
    3ba1:	56                   	push   %esi
    3ba2:	57                   	push   %edi
    3ba3:	52                   	push   %edx
    3ba4:	55                   	push   %ebp
    3ba5:	89 e3                	mov    %esp,%ebx
    3ba7:	83 c3 18             	add    $0x18,%ebx
    3baa:	53                   	push   %ebx
    3bab:	50                   	push   %eax
    3bac:	e8 fc ff ff ff       	call   3bad <cos_ainv_entry+0xd>
    3bb1:	83 c4 08             	add    $0x8,%esp
    3bb4:	83 f8 00             	cmp    $0x0,%eax
    3bb7:	74 19                	je     3bd2 <ainv_ret>
    3bb9:	8b 5c 24 18          	mov    0x18(%esp),%ebx
    3bbd:	8b 74 24 1c          	mov    0x1c(%esp),%esi
    3bc1:	8b 7c 24 20          	mov    0x20(%esp),%edi
    3bc5:	8b 54 24 24          	mov    0x24(%esp),%edx
    3bc9:	89 e5                	mov    %esp,%ebp
    3bcb:	b9 d2 3b 00 00       	mov    $0x3bd2,%ecx
    3bd0:	0f 34                	sysenter 

00003bd2 <ainv_ret>:
    3bd2:	5d                   	pop    %ebp
    3bd3:	5a                   	pop    %edx
    3bd4:	5f                   	pop    %edi
    3bd5:	5e                   	pop    %esi
    3bd6:	5b                   	pop    %ebx
    3bd7:	c3                   	ret    

00003bd8 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
    3bd8:	55                   	push   %ebp
    3bd9:	89 e5                	mov    %esp,%ebp
    3bdb:	57                   	push   %edi
    3bdc:	56                   	push   %esi
    3bdd:	53                   	push   %ebx
    3bde:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    3be1:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    3be8:	8b 45 08             	mov    0x8(%ebp),%eax
    3beb:	83 c0 01             	add    $0x1,%eax
    3bee:	c1 e0 10             	shl    $0x10,%eax
    3bf1:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    3bf4:	8b 45 0c             	mov    0xc(%ebp),%eax
    3bf7:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    3bfa:	8b 45 08             	mov    0x8(%ebp),%eax
    3bfd:	8b 4d 10             	mov    0x10(%ebp),%ecx
    3c00:	8b 75 14             	mov    0x14(%ebp),%esi
    3c03:	8b 7d 18             	mov    0x18(%ebp),%edi
    3c06:	8b 55 1c             	mov    0x1c(%ebp),%edx
    3c09:	89 cb                	mov    %ecx,%ebx
    3c0b:	55                   	push   %ebp
    3c0c:	89 e5                	mov    %esp,%ebp
    3c0e:	b9 20 3c 00 00       	mov    $0x3c20,%ecx
    3c13:	0f 34                	sysenter 
    3c15:	8d 76 00             	lea    0x0(%esi),%esi
    3c18:	eb 0d                	jmp    3c27 <call_cap_asm+0x4f>
    3c1a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    3c20:	b9 00 00 00 00       	mov    $0x0,%ecx
    3c25:	eb 05                	jmp    3c2c <call_cap_asm+0x54>
    3c27:	b9 01 00 00 00       	mov    $0x1,%ecx
    3c2c:	5d                   	pop    %ebp
    3c2d:	89 ca                	mov    %ecx,%edx
    3c2f:	89 45 ec             	mov    %eax,-0x14(%ebp)
    3c32:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    3c35:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    3c38:	83 c4 10             	add    $0x10,%esp
    3c3b:	5b                   	pop    %ebx
    3c3c:	5e                   	pop    %esi
    3c3d:	5f                   	pop    %edi
    3c3e:	5d                   	pop    %ebp
    3c3f:	c3                   	ret    

00003c40 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
    3c40:	55                   	push   %ebp
    3c41:	89 e5                	mov    %esp,%ebp
    3c43:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
    3c46:	8b 45 18             	mov    0x18(%ebp),%eax
    3c49:	89 44 24 14          	mov    %eax,0x14(%esp)
    3c4d:	8b 45 14             	mov    0x14(%ebp),%eax
    3c50:	89 44 24 10          	mov    %eax,0x10(%esp)
    3c54:	8b 45 10             	mov    0x10(%ebp),%eax
    3c57:	89 44 24 0c          	mov    %eax,0xc(%esp)
    3c5b:	8b 45 0c             	mov    0xc(%ebp),%eax
    3c5e:	89 44 24 08          	mov    %eax,0x8(%esp)
    3c62:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    3c69:	00 
    3c6a:	8b 45 08             	mov    0x8(%ebp),%eax
    3c6d:	89 04 24             	mov    %eax,(%esp)
    3c70:	e8 63 ff ff ff       	call   3bd8 <call_cap_asm>
}
    3c75:	c9                   	leave  
    3c76:	c3                   	ret    

00003c77 <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
    3c77:	55                   	push   %ebp
    3c78:	89 e5                	mov    %esp,%ebp
    3c7a:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
    3c7d:	8b 45 08             	mov    0x8(%ebp),%eax
    3c80:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    3c87:	00 
    3c88:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    3c8f:	00 
    3c90:	8b 55 0c             	mov    0xc(%ebp),%edx
    3c93:	89 54 24 08          	mov    %edx,0x8(%esp)
    3c97:	89 44 24 04          	mov    %eax,0x4(%esp)
    3c9b:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    3ca2:	e8 99 ff ff ff       	call   3c40 <call_cap>
}
    3ca7:	c9                   	leave  
    3ca8:	c3                   	ret    

00003ca9 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
    3ca9:	55                   	push   %ebp
    3caa:	89 e5                	mov    %esp,%ebp
    3cac:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
    3caf:	89 e0                	mov    %esp,%eax
    3cb1:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
    3cb4:	8b 45 fc             	mov    -0x4(%ebp),%eax
    3cb7:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    3cbc:	89 c2                	mov    %eax,%edx
    3cbe:	8b 45 08             	mov    0x8(%ebp),%eax
    3cc1:	c1 e0 02             	shl    $0x2,%eax
    3cc4:	29 c2                	sub    %eax,%edx
    3cc6:	89 d0                	mov    %edx,%eax
    3cc8:	05 00 10 00 00       	add    $0x1000,%eax
    3ccd:	8b 00                	mov    (%eax),%eax
}
    3ccf:	c9                   	leave  
    3cd0:	c3                   	ret    

00003cd1 <cos_get_thd_id>:
	return get_stk_data(CPUID_OFFSET);
}

static inline unsigned short int
cos_get_thd_id(void)
{
    3cd1:	55                   	push   %ebp
    3cd2:	89 e5                	mov    %esp,%ebp
    3cd4:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
    3cd7:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    3cde:	e8 c6 ff ff ff       	call   3ca9 <get_stk_data>
}
    3ce3:	c9                   	leave  
    3ce4:	c3                   	ret    

00003ce5 <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
    3ce5:	55                   	push   %ebp
    3ce6:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
    3ce8:	e8 e4 ff ff ff       	call   3cd1 <cos_get_thd_id>
}
    3ced:	5d                   	pop    %ebp
    3cee:	c3                   	ret    

00003cef <cos_spd_id>:
		goto label;      \
	} while (0)

static inline long
cos_spd_id(void)
{
    3cef:	55                   	push   %ebp
    3cf0:	89 e5                	mov    %esp,%ebp
	return cos_comp_info.cos_this_spd_id;
    3cf2:	a1 40 00 00 00       	mov    0x40,%eax
}
    3cf7:	5d                   	pop    %ebp
    3cf8:	c3                   	ret    

00003cf9 <cos_get_heap_ptr>:

static inline void *
cos_get_heap_ptr(void)
{
    3cf9:	55                   	push   %ebp
    3cfa:	89 e5                	mov    %esp,%ebp
	return (void *)cos_comp_info.cos_heap_ptr;
    3cfc:	a1 54 00 00 00       	mov    0x54,%eax
}
    3d01:	5d                   	pop    %ebp
    3d02:	c3                   	ret    

00003d03 <cos_cmpxchg>:

#define COS_EXTERN_FN(fn) __cos_extern_##fn

static inline long
cos_cmpxchg(volatile void *memory, long anticipated, long result)
{
    3d03:	55                   	push   %ebp
    3d04:	89 e5                	mov    %esp,%ebp
    3d06:	53                   	push   %ebx
    3d07:	83 ec 10             	sub    $0x10,%esp
	long ret;

	__asm__ __volatile__("call cos_atomic_cmpxchg"
    3d0a:	8b 45 0c             	mov    0xc(%ebp),%eax
    3d0d:	8b 55 08             	mov    0x8(%ebp),%edx
    3d10:	8b 4d 10             	mov    0x10(%ebp),%ecx
    3d13:	89 d3                	mov    %edx,%ebx
    3d15:	e8 fc ff ff ff       	call   3d16 <cos_cmpxchg+0x13>
    3d1a:	89 d0                	mov    %edx,%eax
    3d1c:	89 45 f8             	mov    %eax,-0x8(%ebp)
	                     : "=d"(ret)
	                     : "a"(anticipated), "b"(memory), "c"(result)
	                     : "cc", "memory");

	return ret;
    3d1f:	8b 45 f8             	mov    -0x8(%ebp),%eax
}
    3d22:	83 c4 10             	add    $0x10,%esp
    3d25:	5b                   	pop    %ebx
    3d26:	5d                   	pop    %ebp
    3d27:	c3                   	ret    

00003d28 <cos_set_heap_ptr_conditional>:
extern void  cos_release_vas_page(void *p);

/* only if the heap pointer is pre_addr, set it to post_addr */
static inline void
cos_set_heap_ptr_conditional(void *pre_addr, void *post_addr)
{
    3d28:	55                   	push   %ebp
    3d29:	89 e5                	mov    %esp,%ebp
    3d2b:	83 ec 0c             	sub    $0xc,%esp
	cos_cmpxchg(&cos_comp_info.cos_heap_ptr, (long)pre_addr, (long)post_addr);
    3d2e:	8b 55 0c             	mov    0xc(%ebp),%edx
    3d31:	8b 45 08             	mov    0x8(%ebp),%eax
    3d34:	89 54 24 08          	mov    %edx,0x8(%esp)
    3d38:	89 44 24 04          	mov    %eax,0x4(%esp)
    3d3c:	c7 04 24 54 00 00 00 	movl   $0x54,(%esp)
    3d43:	e8 bb ff ff ff       	call   3d03 <cos_cmpxchg>
}
    3d48:	c9                   	leave  
    3d49:	c3                   	ret    

00003d4a <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
    3d4a:	55                   	push   %ebp
    3d4b:	89 e5                	mov    %esp,%ebp
    3d4d:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
    3d50:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    3d57:	eb 20                	jmp    3d79 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
    3d59:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3d5c:	83 c0 01             	add    $0x1,%eax
    3d5f:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    3d66:	8b 45 08             	mov    0x8(%ebp),%eax
    3d69:	01 d0                	add    %edx,%eax
    3d6b:	8b 00                	mov    (%eax),%eax
    3d6d:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
    3d70:	8b 45 f0             	mov    -0x10(%ebp),%eax
    3d73:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
    3d75:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    3d79:	8b 45 08             	mov    0x8(%ebp),%eax
    3d7c:	8b 00                	mov    (%eax),%eax
    3d7e:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    3d81:	7f d6                	jg     3d59 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
    3d83:	c9                   	leave  
    3d84:	c3                   	ret    

00003d85 <constructors_execute>:

static void
constructors_execute(void)
{
    3d85:	55                   	push   %ebp
    3d86:	89 e5                	mov    %esp,%ebp
    3d88:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
    3d8b:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    3d92:	e8 b3 ff ff ff       	call   3d4a <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
    3d97:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    3d9e:	e8 a7 ff ff ff       	call   3d4a <section_fnptrs_execute>
}
    3da3:	c9                   	leave  
    3da4:	c3                   	ret    

00003da5 <destructors_execute>:
static void
destructors_execute(void)
{
    3da5:	55                   	push   %ebp
    3da6:	89 e5                	mov    %esp,%ebp
    3da8:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
    3dab:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    3db2:	e8 93 ff ff ff       	call   3d4a <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
    3db7:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    3dbe:	e8 87 ff ff ff       	call   3d4a <section_fnptrs_execute>
}
    3dc3:	c9                   	leave  
    3dc4:	c3                   	ret    

00003dc5 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
    3dc5:	55                   	push   %ebp
    3dc6:	89 e5                	mov    %esp,%ebp
    3dc8:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
    3dcb:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    3dd2:	e8 73 ff ff ff       	call   3d4a <section_fnptrs_execute>
}
    3dd7:	c9                   	leave  
    3dd8:	c3                   	ret    

00003dd9 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
    3dd9:	55                   	push   %ebp
    3dda:	89 e5                	mov    %esp,%ebp
    3ddc:	83 ec 08             	sub    $0x8,%esp
    3ddf:	8b 55 08             	mov    0x8(%ebp),%edx
    3de2:	8b 45 0c             	mov    0xc(%ebp),%eax
    3de5:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
    3de9:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
    3dec:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    3df0:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
    3df4:	ee                   	out    %al,(%dx)
}
    3df5:	c9                   	leave  
    3df6:	c3                   	ret    

00003df7 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
    3df7:	55                   	push   %ebp
    3df8:	89 e5                	mov    %esp,%ebp
    3dfa:	83 ec 14             	sub    $0x14,%esp
    3dfd:	8b 45 08             	mov    0x8(%ebp),%eax
    3e00:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
    3e04:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
    3e08:	89 c2                	mov    %eax,%edx
    3e0a:	ec                   	in     (%dx),%al
    3e0b:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
    3e0e:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
    3e12:	c9                   	leave  
    3e13:	c3                   	ret    

00003e14 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
    3e14:	55                   	push   %ebp
    3e15:	89 e5                	mov    %esp,%ebp
    3e17:	83 ec 0c             	sub    $0xc,%esp
    3e1a:	8b 45 08             	mov    0x8(%ebp),%eax
    3e1d:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
    3e20:	90                   	nop
    3e21:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
    3e28:	e8 ca ff ff ff       	call   3df7 <inb>
    3e2d:	0f b6 c0             	movzbl %al,%eax
    3e30:	83 e0 20             	and    $0x20,%eax
    3e33:	85 c0                	test   %eax,%eax
    3e35:	74 ea                	je     3e21 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
    3e37:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    3e3b:	0f b6 c0             	movzbl %al,%eax
    3e3e:	89 44 24 04          	mov    %eax,0x4(%esp)
    3e42:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
    3e49:	e8 8b ff ff ff       	call   3dd9 <outb>
}
    3e4e:	c9                   	leave  
    3e4f:	c3                   	ret    

00003e50 <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
    3e50:	55                   	push   %ebp
    3e51:	89 e5                	mov    %esp,%ebp
    3e53:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
    3e56:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
    3e5d:	eb 1a                	jmp    3e79 <cos_serial_putb+0x29>
    3e5f:	8b 45 fc             	mov    -0x4(%ebp),%eax
    3e62:	8b 55 08             	mov    0x8(%ebp),%edx
    3e65:	01 d0                	add    %edx,%eax
    3e67:	0f b6 00             	movzbl (%eax),%eax
    3e6a:	0f be c0             	movsbl %al,%eax
    3e6d:	89 04 24             	mov    %eax,(%esp)
    3e70:	e8 9f ff ff ff       	call   3e14 <cos_serial_putc>
    3e75:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
    3e79:	8b 45 fc             	mov    -0x4(%ebp),%eax
    3e7c:	3b 45 0c             	cmp    0xc(%ebp),%eax
    3e7f:	72 de                	jb     3e5f <cos_serial_putb+0xf>
}
    3e81:	c9                   	leave  
    3e82:	c3                   	ret    

00003e83 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
    3e83:	55                   	push   %ebp
    3e84:	89 e5                	mov    %esp,%ebp
    3e86:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
    3e89:	8b 45 0c             	mov    0xc(%ebp),%eax
    3e8c:	89 44 24 04          	mov    %eax,0x4(%esp)
    3e90:	8b 45 08             	mov    0x8(%ebp),%eax
    3e93:	89 04 24             	mov    %eax,(%esp)
    3e96:	e8 b5 ff ff ff       	call   3e50 <cos_serial_putb>
}
    3e9b:	c9                   	leave  
    3e9c:	c3                   	ret    

00003e9d <prints>:

static int
prints(char *s)
{
    3e9d:	55                   	push   %ebp
    3e9e:	89 e5                	mov    %esp,%ebp
    3ea0:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
    3ea3:	8b 45 08             	mov    0x8(%ebp),%eax
    3ea6:	89 04 24             	mov    %eax,(%esp)
    3ea9:	e8 fc ff ff ff       	call   3eaa <prints+0xd>
    3eae:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
    3eb1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3eb4:	89 44 24 04          	mov    %eax,0x4(%esp)
    3eb8:	8b 45 08             	mov    0x8(%ebp),%eax
    3ebb:	89 04 24             	mov    %eax,(%esp)
    3ebe:	e8 b4 fd ff ff       	call   3c77 <cos_print>

	return len;
    3ec3:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    3ec6:	c9                   	leave  
    3ec7:	c3                   	ret    

00003ec8 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
    3ec8:	55                   	push   %ebp
    3ec9:	89 e5                	mov    %esp,%ebp
    3ecb:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
    3ed1:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
    3ed8:	8d 45 0c             	lea    0xc(%ebp),%eax
    3edb:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
    3ee1:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
    3ee7:	89 44 24 0c          	mov    %eax,0xc(%esp)
    3eeb:	8b 45 08             	mov    0x8(%ebp),%eax
    3eee:	89 44 24 08          	mov    %eax,0x8(%esp)
    3ef2:	8b 45 f4             	mov    -0xc(%ebp),%eax
    3ef5:	89 44 24 04          	mov    %eax,0x4(%esp)
    3ef9:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    3eff:	89 04 24             	mov    %eax,(%esp)
    3f02:	e8 fc ff ff ff       	call   3f03 <printc+0x3b>
    3f07:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
    3f0a:	8b 45 f0             	mov    -0x10(%ebp),%eax
    3f0d:	89 44 24 04          	mov    %eax,0x4(%esp)
    3f11:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    3f17:	89 04 24             	mov    %eax,(%esp)
    3f1a:	e8 64 ff ff ff       	call   3e83 <cos_llprint>

	return ret;
    3f1f:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    3f22:	c9                   	leave  
    3f23:	c3                   	ret    

00003f24 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
    3f24:	55                   	push   %ebp
    3f25:	89 e5                	mov    %esp,%ebp
	while (1)
		;
    3f27:	eb fe                	jmp    3f27 <__cos_noret+0x3>

00003f29 <ps_list_ll_empty>:
ps_list_head_init(struct ps_list_head *lh)
{ ps_list_ll_init(&lh->l); }

static inline int
ps_list_ll_empty(struct ps_list *l)
{ return l->n == l; }
    3f29:	55                   	push   %ebp
    3f2a:	89 e5                	mov    %esp,%ebp
    3f2c:	8b 45 08             	mov    0x8(%ebp),%eax
    3f2f:	8b 00                	mov    (%eax),%eax
    3f31:	3b 45 08             	cmp    0x8(%ebp),%eax
    3f34:	0f 94 c0             	sete   %al
    3f37:	0f b6 c0             	movzbl %al,%eax
    3f3a:	5d                   	pop    %ebp
    3f3b:	c3                   	ret    

00003f3c <ps_list_ll_add>:
ps_list_head_empty(struct ps_list_head *lh)
{ return ps_list_ll_empty(&lh->l); }

static inline void
ps_list_ll_add(struct ps_list *l, struct ps_list *new)
{
    3f3c:	55                   	push   %ebp
    3f3d:	89 e5                	mov    %esp,%ebp
	new->n    = l->n;
    3f3f:	8b 45 08             	mov    0x8(%ebp),%eax
    3f42:	8b 10                	mov    (%eax),%edx
    3f44:	8b 45 0c             	mov    0xc(%ebp),%eax
    3f47:	89 10                	mov    %edx,(%eax)
	new->p    = l;
    3f49:	8b 45 0c             	mov    0xc(%ebp),%eax
    3f4c:	8b 55 08             	mov    0x8(%ebp),%edx
    3f4f:	89 50 04             	mov    %edx,0x4(%eax)
	l->n      = new;
    3f52:	8b 45 08             	mov    0x8(%ebp),%eax
    3f55:	8b 55 0c             	mov    0xc(%ebp),%edx
    3f58:	89 10                	mov    %edx,(%eax)
	new->n->p = new;
    3f5a:	8b 45 0c             	mov    0xc(%ebp),%eax
    3f5d:	8b 00                	mov    (%eax),%eax
    3f5f:	8b 55 0c             	mov    0xc(%ebp),%edx
    3f62:	89 50 04             	mov    %edx,0x4(%eax)
}
    3f65:	5d                   	pop    %ebp
    3f66:	c3                   	ret    

00003f67 <ps_list_ll_rem>:

static inline void
ps_list_ll_rem(struct ps_list *l)
{
    3f67:	55                   	push   %ebp
    3f68:	89 e5                	mov    %esp,%ebp
	l->n->p = l->p;
    3f6a:	8b 45 08             	mov    0x8(%ebp),%eax
    3f6d:	8b 00                	mov    (%eax),%eax
    3f6f:	8b 55 08             	mov    0x8(%ebp),%edx
    3f72:	8b 52 04             	mov    0x4(%edx),%edx
    3f75:	89 50 04             	mov    %edx,0x4(%eax)
	l->p->n = l->n;
    3f78:	8b 45 08             	mov    0x8(%ebp),%eax
    3f7b:	8b 40 04             	mov    0x4(%eax),%eax
    3f7e:	8b 55 08             	mov    0x8(%ebp),%edx
    3f81:	8b 12                	mov    (%edx),%edx
    3f83:	89 10                	mov    %edx,(%eax)
	l->p = l->n = l;
    3f85:	8b 45 08             	mov    0x8(%ebp),%eax
    3f88:	8b 55 08             	mov    0x8(%ebp),%edx
    3f8b:	89 10                	mov    %edx,(%eax)
    3f8d:	8b 45 08             	mov    0x8(%ebp),%eax
    3f90:	8b 10                	mov    (%eax),%edx
    3f92:	8b 45 08             	mov    0x8(%ebp),%eax
    3f95:	89 50 04             	mov    %edx,0x4(%eax)
}
    3f98:	5d                   	pop    %ebp
    3f99:	c3                   	ret    

00003f9a <__slab_freelist_rem>:
static inline void __ps_slab_freelist_check(struct ps_slab_freelist *fl) { (void)fl; }
#endif /* PS_SLAB_DEBUG */

static void
__slab_freelist_rem(struct ps_slab_freelist *fl, struct ps_slab *s)
{
    3f9a:	55                   	push   %ebp
    3f9b:	89 e5                	mov    %esp,%ebp
    3f9d:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
    3fa0:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    3fa4:	0f 94 c0             	sete   %al
    3fa7:	0f b6 c0             	movzbl %al,%eax
    3faa:	85 c0                	test   %eax,%eax
    3fac:	75 0e                	jne    3fbc <__slab_freelist_rem+0x22>
    3fae:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    3fb2:	0f 94 c0             	sete   %al
    3fb5:	0f b6 c0             	movzbl %al,%eax
    3fb8:	85 c0                	test   %eax,%eax
    3fba:	74 1c                	je     3fd8 <__slab_freelist_rem+0x3e>
    3fbc:	c7 04 24 68 03 00 00 	movl   $0x368,(%esp)
    3fc3:	e8 d5 fe ff ff       	call   3e9d <prints>
    3fc8:	a1 30 00 00 00       	mov    0x30,%eax
    3fcd:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    3fd3:	e8 4c ff ff ff       	call   3f24 <__cos_noret>
	if (fl->list == s) {
    3fd8:	8b 45 08             	mov    0x8(%ebp),%eax
    3fdb:	8b 00                	mov    (%eax),%eax
    3fdd:	3b 45 0c             	cmp    0xc(%ebp),%eax
    3fe0:	75 2b                	jne    400d <__slab_freelist_rem+0x73>
		if (ps_list_singleton(s, list)) fl->list = NULL;
    3fe2:	8b 45 0c             	mov    0xc(%ebp),%eax
    3fe5:	83 c0 44             	add    $0x44,%eax
    3fe8:	89 04 24             	mov    %eax,(%esp)
    3feb:	e8 39 ff ff ff       	call   3f29 <ps_list_ll_empty>
    3ff0:	85 c0                	test   %eax,%eax
    3ff2:	74 0b                	je     3fff <__slab_freelist_rem+0x65>
    3ff4:	8b 45 08             	mov    0x8(%ebp),%eax
    3ff7:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    3ffd:	eb 0e                	jmp    400d <__slab_freelist_rem+0x73>
		else                            fl->list = ps_list_next(s, list);
    3fff:	8b 45 0c             	mov    0xc(%ebp),%eax
    4002:	8b 40 44             	mov    0x44(%eax),%eax
    4005:	8d 50 bc             	lea    -0x44(%eax),%edx
    4008:	8b 45 08             	mov    0x8(%ebp),%eax
    400b:	89 10                	mov    %edx,(%eax)
	}
	ps_list_rem(s, list);
    400d:	8b 45 0c             	mov    0xc(%ebp),%eax
    4010:	83 c0 44             	add    $0x44,%eax
    4013:	89 04 24             	mov    %eax,(%esp)
    4016:	e8 4c ff ff ff       	call   3f67 <ps_list_ll_rem>
}
    401b:	c9                   	leave  
    401c:	c3                   	ret    

0000401d <__slab_freelist_add>:

static void
__slab_freelist_add(struct ps_slab_freelist *fl, struct ps_slab *s)
{
    401d:	55                   	push   %ebp
    401e:	89 e5                	mov    %esp,%ebp
    4020:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
    4023:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    4027:	0f 94 c0             	sete   %al
    402a:	0f b6 c0             	movzbl %al,%eax
    402d:	85 c0                	test   %eax,%eax
    402f:	75 0e                	jne    403f <__slab_freelist_add+0x22>
    4031:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    4035:	0f 94 c0             	sete   %al
    4038:	0f b6 c0             	movzbl %al,%eax
    403b:	85 c0                	test   %eax,%eax
    403d:	74 1c                	je     405b <__slab_freelist_add+0x3e>
    403f:	c7 04 24 c0 03 00 00 	movl   $0x3c0,(%esp)
    4046:	e8 52 fe ff ff       	call   3e9d <prints>
    404b:	a1 30 00 00 00       	mov    0x30,%eax
    4050:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4056:	e8 c9 fe ff ff       	call   3f24 <__cos_noret>
	assert(ps_list_singleton(s, list));
    405b:	8b 45 0c             	mov    0xc(%ebp),%eax
    405e:	83 c0 44             	add    $0x44,%eax
    4061:	89 04 24             	mov    %eax,(%esp)
    4064:	e8 c0 fe ff ff       	call   3f29 <ps_list_ll_empty>
    4069:	85 c0                	test   %eax,%eax
    406b:	0f 94 c0             	sete   %al
    406e:	0f b6 c0             	movzbl %al,%eax
    4071:	85 c0                	test   %eax,%eax
    4073:	74 1c                	je     4091 <__slab_freelist_add+0x74>
    4075:	c7 04 24 18 04 00 00 	movl   $0x418,(%esp)
    407c:	e8 1c fe ff ff       	call   3e9d <prints>
    4081:	a1 30 00 00 00       	mov    0x30,%eax
    4086:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    408c:	e8 93 fe ff ff       	call   3f24 <__cos_noret>
	assert(s != fl->list);
    4091:	8b 45 08             	mov    0x8(%ebp),%eax
    4094:	8b 00                	mov    (%eax),%eax
    4096:	3b 45 0c             	cmp    0xc(%ebp),%eax
    4099:	0f 94 c0             	sete   %al
    409c:	0f b6 c0             	movzbl %al,%eax
    409f:	85 c0                	test   %eax,%eax
    40a1:	74 1c                	je     40bf <__slab_freelist_add+0xa2>
    40a3:	c7 04 24 70 04 00 00 	movl   $0x470,(%esp)
    40aa:	e8 ee fd ff ff       	call   3e9d <prints>
    40af:	a1 30 00 00 00       	mov    0x30,%eax
    40b4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    40ba:	e8 65 fe ff ff       	call   3f24 <__cos_noret>
	if (fl->list) ps_list_add(fl->list, s, list);
    40bf:	8b 45 08             	mov    0x8(%ebp),%eax
    40c2:	8b 00                	mov    (%eax),%eax
    40c4:	85 c0                	test   %eax,%eax
    40c6:	74 1a                	je     40e2 <__slab_freelist_add+0xc5>
    40c8:	8b 45 0c             	mov    0xc(%ebp),%eax
    40cb:	8d 50 44             	lea    0x44(%eax),%edx
    40ce:	8b 45 08             	mov    0x8(%ebp),%eax
    40d1:	8b 00                	mov    (%eax),%eax
    40d3:	83 c0 44             	add    $0x44,%eax
    40d6:	89 54 24 04          	mov    %edx,0x4(%esp)
    40da:	89 04 24             	mov    %eax,(%esp)
    40dd:	e8 5a fe ff ff       	call   3f3c <ps_list_ll_add>
	fl->list = s;
    40e2:	8b 45 08             	mov    0x8(%ebp),%eax
    40e5:	8b 55 0c             	mov    0xc(%ebp),%edx
    40e8:	89 10                	mov    %edx,(%eax)
	/* TODO: sort based on emptiness...just use N bins */
}
    40ea:	c9                   	leave  
    40eb:	c3                   	ret    

000040ec <main>:

CWEAKSYMB int cos_sched_notifications;

CWEAKSYMB int
main(void)
{
    40ec:	55                   	push   %ebp
    40ed:	89 e5                	mov    %esp,%ebp
	return 0;
    40ef:	b8 00 00 00 00       	mov    $0x0,%eax
}
    40f4:	5d                   	pop    %ebp
    40f5:	c3                   	ret    

CWEAKSYMB void
cos_init(void *arg)
{
    40f6:	55                   	push   %ebp
    40f7:	89 e5                	mov    %esp,%ebp
    40f9:	83 ec 08             	sub    $0x8,%esp
	main();
    40fc:	e8 fc ff ff ff       	call   40fd <main+0x11>
}
    4101:	c9                   	leave  
    4102:	c3                   	ret    

00004103 <pre_syscall_default_setup>:

/* Intended to be implement by libraries */
CWEAKSYMB void
pre_syscall_default_setup()
{
    4103:	55                   	push   %ebp
    4104:	89 e5                	mov    %esp,%ebp
}
    4106:	5d                   	pop    %ebp
    4107:	c3                   	ret    

00004108 <pre_syscall_setup>:

/* Intended to be overriden by components */
CWEAKSYMB void
pre_syscall_setup()
{
    4108:	55                   	push   %ebp
    4109:	89 e5                	mov    %esp,%ebp
    410b:	83 ec 08             	sub    $0x8,%esp
	pre_syscall_default_setup();
    410e:	e8 fc ff ff ff       	call   410f <pre_syscall_setup+0x7>
}
    4113:	c9                   	leave  
    4114:	c3                   	ret    

00004115 <syscall_emulation_setup>:

CWEAKSYMB void
syscall_emulation_setup()
{
    4115:	55                   	push   %ebp
    4116:	89 e5                	mov    %esp,%ebp
}
    4118:	5d                   	pop    %ebp
    4119:	c3                   	ret    

0000411a <cos_syscall_handler>:

CWEAKSYMB long
cos_syscall_handler(int syscall_num, long a, long b, long c, long d, long e, long f, long g)
{
    411a:	55                   	push   %ebp
    411b:	89 e5                	mov    %esp,%ebp
    411d:	83 ec 18             	sub    $0x18,%esp
	printc("Default syscall handler callled (syscall: %d), faulting!", syscall_num);
    4120:	8b 45 08             	mov    0x8(%ebp),%eax
    4123:	89 44 24 04          	mov    %eax,0x4(%esp)
    4127:	c7 04 24 c8 04 00 00 	movl   $0x4c8,(%esp)
    412e:	e8 95 fd ff ff       	call   3ec8 <printc>
	assert(0);
    4133:	c7 04 24 04 05 00 00 	movl   $0x504,(%esp)
    413a:	e8 5e fd ff ff       	call   3e9d <prints>
    413f:	a1 30 00 00 00       	mov    0x30,%eax
    4144:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    414a:	e8 d5 fd ff ff       	call   3f24 <__cos_noret>

0000414f <__cos_syscall>:
	return 0;
}

__attribute__((regparm(1))) long
__cos_syscall(int syscall_num, long a, long b, long c, long d, long e, long f, long g)
{
    414f:	55                   	push   %ebp
    4150:	89 e5                	mov    %esp,%ebp
    4152:	83 ec 38             	sub    $0x38,%esp
    4155:	89 45 f4             	mov    %eax,-0xc(%ebp)
	return cos_syscall_handler(syscall_num, a, b, c, d, e, f, g);
    4158:	8b 45 20             	mov    0x20(%ebp),%eax
    415b:	89 44 24 1c          	mov    %eax,0x1c(%esp)
    415f:	8b 45 1c             	mov    0x1c(%ebp),%eax
    4162:	89 44 24 18          	mov    %eax,0x18(%esp)
    4166:	8b 45 18             	mov    0x18(%ebp),%eax
    4169:	89 44 24 14          	mov    %eax,0x14(%esp)
    416d:	8b 45 14             	mov    0x14(%ebp),%eax
    4170:	89 44 24 10          	mov    %eax,0x10(%esp)
    4174:	8b 45 10             	mov    0x10(%ebp),%eax
    4177:	89 44 24 0c          	mov    %eax,0xc(%esp)
    417b:	8b 45 0c             	mov    0xc(%ebp),%eax
    417e:	89 44 24 08          	mov    %eax,0x8(%esp)
    4182:	8b 45 08             	mov    0x8(%ebp),%eax
    4185:	89 44 24 04          	mov    %eax,0x4(%esp)
    4189:	8b 45 f4             	mov    -0xc(%ebp),%eax
    418c:	89 04 24             	mov    %eax,(%esp)
    418f:	e8 fc ff ff ff       	call   4190 <__cos_syscall+0x41>
}
    4194:	c9                   	leave  
    4195:	c3                   	ret    

00004196 <libc_initialization_handler>:

CWEAKSYMB void
libc_initialization_handler()
{
    4196:	55                   	push   %ebp
    4197:	89 e5                	mov    %esp,%ebp
}
    4199:	5d                   	pop    %ebp
    419a:	c3                   	ret    

0000419b <libc_init>:
/* TODO: Make this a weak symbol (currently doing so makes this fail) */
void __init_libc(char **envp, char *pn);

void
libc_init()
{
    419b:	55                   	push   %ebp
    419c:	89 e5                	mov    %esp,%ebp
    419e:	83 ec 28             	sub    $0x28,%esp
                               (char *)1000, /* Effective group id */
                               (char *)AT_SECURE,
                               (char *)0, /* Whether the program is being run under sudo */
                               NULL
	};
	char *program_name = "composite component";
    41a1:	c7 45 f4 32 05 00 00 	movl   $0x532,-0xc(%ebp)
	__init_libc(envp, program_name);
    41a8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    41ab:	89 44 24 04          	mov    %eax,0x4(%esp)
    41af:	c7 04 24 40 00 00 00 	movl   $0x40,(%esp)
    41b6:	e8 fc ff ff ff       	call   41b7 <libc_init+0x1c>
}
    41bb:	c9                   	leave  
    41bc:	c3                   	ret    

000041bd <cos_upcall_exec>:

CWEAKSYMB void
cos_upcall_exec(void *arg)
{
    41bd:	55                   	push   %ebp
    41be:	89 e5                	mov    %esp,%ebp
}
    41c0:	5d                   	pop    %ebp
    41c1:	c3                   	ret    

000041c2 <cos_async_inv>:

CWEAKSYMB int
cos_async_inv(struct usr_inv_cap *ucap, int *params)
{
    41c2:	55                   	push   %ebp
    41c3:	89 e5                	mov    %esp,%ebp
	return 0;
    41c5:	b8 00 00 00 00       	mov    $0x0,%eax
}
    41ca:	5d                   	pop    %ebp
    41cb:	c3                   	ret    

000041cc <cos_thd_entry_static>:

CWEAKSYMB int
cos_thd_entry_static(u32_t idx)
{
    41cc:	55                   	push   %ebp
    41cd:	89 e5                	mov    %esp,%ebp
    41cf:	83 ec 18             	sub    $0x18,%esp
	assert(0);
    41d2:	c7 04 24 48 05 00 00 	movl   $0x548,(%esp)
    41d9:	e8 bf fc ff ff       	call   3e9d <prints>
    41de:	a1 30 00 00 00       	mov    0x30,%eax
    41e3:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    41e9:	e8 36 fd ff ff       	call   3f24 <__cos_noret>

000041ee <cos_print_level_set>:
cos_print_level_t cos_print_level   = PRINT_ERROR;
int               cos_print_lvl_str = 0;

CWEAKSYMB void
cos_print_level_set(cos_print_level_t lvl, int print_str)
{
    41ee:	55                   	push   %ebp
    41ef:	89 e5                	mov    %esp,%ebp
	cos_print_level   = lvl;
    41f1:	8b 45 08             	mov    0x8(%ebp),%eax
    41f4:	a3 00 00 00 00       	mov    %eax,0x0
	cos_print_lvl_str = print_str;
    41f9:	8b 45 0c             	mov    0xc(%ebp),%eax
    41fc:	a3 00 00 00 00       	mov    %eax,0x0
}
    4201:	5d                   	pop    %ebp
    4202:	c3                   	ret    

00004203 <cos_thd_entry_exec>:
 */
struct __thd_init_data __thd_init_data[COS_THD_INIT_REGION_SIZE] CACHE_ALIGNED;

static void
cos_thd_entry_exec(u32_t idx)
{
    4203:	55                   	push   %ebp
    4204:	89 e5                	mov    %esp,%ebp
    4206:	83 ec 28             	sub    $0x28,%esp
	void (*fn)(void *);
	void *data;

	fn   = __thd_init_data[idx].fn;
    4209:	8b 45 08             	mov    0x8(%ebp),%eax
    420c:	8b 04 c5 00 00 00 00 	mov    0x0(,%eax,8),%eax
    4213:	89 45 f4             	mov    %eax,-0xc(%ebp)
	data = __thd_init_data[idx].data;
    4216:	8b 45 08             	mov    0x8(%ebp),%eax
    4219:	8b 04 c5 04 00 00 00 	mov    0x4(,%eax,8),%eax
    4220:	89 45 f0             	mov    %eax,-0x10(%ebp)
	/* and release the entry... might need a barrier here. */
	__thd_init_data[idx].data = NULL;
    4223:	8b 45 08             	mov    0x8(%ebp),%eax
    4226:	c7 04 c5 04 00 00 00 	movl   $0x0,0x4(,%eax,8)
    422d:	00 00 00 00 
	__thd_init_data[idx].fn   = NULL;
    4231:	8b 45 08             	mov    0x8(%ebp),%eax
    4234:	c7 04 c5 00 00 00 00 	movl   $0x0,0x0(,%eax,8)
    423b:	00 00 00 00 

	(fn)(data);
    423f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    4242:	89 04 24             	mov    %eax,(%esp)
    4245:	8b 45 f4             	mov    -0xc(%ebp),%eax
    4248:	ff d0                	call   *%eax
}
    424a:	c9                   	leave  
    424b:	c3                   	ret    

0000424c <cos_upcall_fn>:

CWEAKSYMB void
cos_upcall_fn(upcall_type_t t, void *arg1, void *arg2, void *arg3)
{
    424c:	55                   	push   %ebp
    424d:	89 e5                	mov    %esp,%ebp
    424f:	83 ec 28             	sub    $0x28,%esp
	static int first = 1;

	if (first) {
    4252:	a1 88 00 00 00       	mov    0x88,%eax
    4257:	85 c0                	test   %eax,%eax
    4259:	74 32                	je     428d <cos_upcall_fn+0x41>
		first = 0;
    425b:	c7 05 88 00 00 00 00 	movl   $0x0,0x88
    4262:	00 00 00 
		cos_print_level_set(PRINT_DEBUG, 1);
    4265:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    426c:	00 
    426d:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    4274:	e8 fc ff ff ff       	call   4275 <cos_upcall_fn+0x29>
		/* The syscall enumlator might need something to be setup before it can work */
		pre_syscall_setup();
    4279:	e8 fc ff ff ff       	call   427a <cos_upcall_fn+0x2e>
		/* libc needs syscall emulation to work */
		syscall_emulation_setup();
    427e:	e8 fc ff ff ff       	call   427f <cos_upcall_fn+0x33>
		/* With all that setup, we can invoke the libc_initialization_handler */
		libc_initialization_handler();
    4283:	e8 fc ff ff ff       	call   4284 <cos_upcall_fn+0x38>

		constructors_execute();
    4288:	e8 f8 fa ff ff       	call   3d85 <constructors_execute>

	/*
	 * if it's the first component.. wait for timer calibration
	 * NOTE: for "fork"ing components and not updating "spdid"s, this call will just fail and should be fine.
	 */
	if (cos_spd_id() == 0) {
    428d:	e8 5d fa ff ff       	call   3cef <cos_spd_id>
    4292:	85 c0                	test   %eax,%eax
    4294:	75 0c                	jne    42a2 <cos_upcall_fn+0x56>
		cos_hw_cycles_per_usec(BOOT_CAPTBL_SELF_INITHW_BASE);
    4296:	c7 04 24 18 00 00 00 	movl   $0x18,(%esp)
    429d:	e8 fc ff ff ff       	call   429e <cos_upcall_fn+0x52>
	}

	switch (t) {
    42a2:	8b 45 08             	mov    0x8(%ebp),%eax
    42a5:	85 c0                	test   %eax,%eax
    42a7:	75 47                	jne    42f0 <cos_upcall_fn+0xa4>
		{
			/* A new thread is created in this comp. */

			/* arg1 is the thread init data. 0 means
			 * bootstrap. */
			if (arg1 == 0) {
    42a9:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    42ad:	75 0e                	jne    42bd <cos_upcall_fn+0x71>
				cos_init(NULL);
    42af:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    42b6:	e8 fc ff ff ff       	call   42b7 <cos_upcall_fn+0x6b>
    42bb:	eb 31                	jmp    42ee <cos_upcall_fn+0xa2>
			} else {
				u32_t idx = (int)arg1 - 1;
    42bd:	8b 45 0c             	mov    0xc(%ebp),%eax
    42c0:	83 e8 01             	sub    $0x1,%eax
    42c3:	89 45 f4             	mov    %eax,-0xc(%ebp)
				if (idx >= COS_THD_INIT_REGION_SIZE) {
    42c6:	81 7d f4 ff 00 00 00 	cmpl   $0xff,-0xc(%ebp)
    42cd:	76 12                	jbe    42e1 <cos_upcall_fn+0x95>
					/* This means static defined entry */
					cos_thd_entry_static(idx - COS_THD_INIT_REGION_SIZE);
    42cf:	8b 45 f4             	mov    -0xc(%ebp),%eax
    42d2:	2d 00 01 00 00       	sub    $0x100,%eax
    42d7:	89 04 24             	mov    %eax,(%esp)
    42da:	e8 fc ff ff ff       	call   42db <cos_upcall_fn+0x8f>
    42df:	eb 0d                	jmp    42ee <cos_upcall_fn+0xa2>
				} else {
					/* Execute dynamic allocated entry. */
					cos_thd_entry_exec(idx);
    42e1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    42e4:	89 04 24             	mov    %eax,(%esp)
    42e7:	e8 17 ff ff ff       	call   4203 <cos_thd_entry_exec>
				}
			}
			return;
    42ec:	eb 1e                	jmp    430c <cos_upcall_fn+0xc0>
    42ee:	eb 1c                	jmp    430c <cos_upcall_fn+0xc0>
		}
	default:
		/* fault! */
		assert(0);
    42f0:	c7 04 24 88 05 00 00 	movl   $0x588,(%esp)
    42f7:	e8 a1 fb ff ff       	call   3e9d <prints>
    42fc:	a1 30 00 00 00       	mov    0x30,%eax
    4301:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4307:	e8 18 fc ff ff       	call   3f24 <__cos_noret>
		return;
	}
	return;
}
    430c:	c9                   	leave  
    430d:	c3                   	ret    

0000430e <cos_get_vas_page>:

CWEAKSYMB void *
cos_get_vas_page(void)
{
    430e:	55                   	push   %ebp
    430f:	89 e5                	mov    %esp,%ebp
    4311:	83 ec 1c             	sub    $0x1c,%esp
	char *h;
	long  r;
	do {
		h = cos_get_heap_ptr();
    4314:	e8 e0 f9 ff ff       	call   3cf9 <cos_get_heap_ptr>
    4319:	89 45 fc             	mov    %eax,-0x4(%ebp)
		r = (long)h + PAGE_SIZE;
    431c:	8b 45 fc             	mov    -0x4(%ebp),%eax
    431f:	05 00 10 00 00       	add    $0x1000,%eax
    4324:	89 45 f8             	mov    %eax,-0x8(%ebp)
	} while (cos_cmpxchg(&cos_comp_info.cos_heap_ptr, (long)h, r) != r);
    4327:	8b 45 fc             	mov    -0x4(%ebp),%eax
    432a:	8b 55 f8             	mov    -0x8(%ebp),%edx
    432d:	89 54 24 08          	mov    %edx,0x8(%esp)
    4331:	89 44 24 04          	mov    %eax,0x4(%esp)
    4335:	c7 04 24 54 00 00 00 	movl   $0x54,(%esp)
    433c:	e8 c2 f9 ff ff       	call   3d03 <cos_cmpxchg>
    4341:	3b 45 f8             	cmp    -0x8(%ebp),%eax
    4344:	75 ce                	jne    4314 <cos_get_vas_page+0x6>
	return h;
    4346:	8b 45 fc             	mov    -0x4(%ebp),%eax
}
    4349:	c9                   	leave  
    434a:	c3                   	ret    

0000434b <cos_release_vas_page>:

CWEAKSYMB void
cos_release_vas_page(void *p)
{
    434b:	55                   	push   %ebp
    434c:	89 e5                	mov    %esp,%ebp
    434e:	83 ec 08             	sub    $0x8,%esp
	cos_set_heap_ptr_conditional(p + PAGE_SIZE, p);
    4351:	8b 45 08             	mov    0x8(%ebp),%eax
    4354:	8d 90 00 10 00 00    	lea    0x1000(%eax),%edx
    435a:	8b 45 08             	mov    0x8(%ebp),%eax
    435d:	89 44 24 04          	mov    %eax,0x4(%esp)
    4361:	89 14 24             	mov    %edx,(%esp)
    4364:	e8 bf f9 ff ff       	call   3d28 <cos_set_heap_ptr_conditional>
}
    4369:	c9                   	leave  
    436a:	c3                   	ret    
    436b:	66 90                	xchg   %ax,%ax
    436d:	66 90                	xchg   %ax,%ax
    436f:	90                   	nop

00004370 <__captbl_cap2sz>:
#define CAPTBL_EXPAND_SZ 128

/* a function instead of a struct to enable inlining + constant prop */
static inline cap_sz_t
__captbl_cap2sz(cap_t c)
{
    4370:	55                   	push   %ebp
    4371:	89 e5                	mov    %esp,%ebp
	/* TODO: optimize for invocation and return */
	switch (c) {
    4373:	83 7d 08 0d          	cmpl   $0xd,0x8(%ebp)
    4377:	77 24                	ja     439d <__captbl_cap2sz+0x2d>
    4379:	8b 45 08             	mov    0x8(%ebp),%eax
    437c:	c1 e0 02             	shl    $0x2,%eax
    437f:	05 10 06 00 00       	add    $0x610,%eax
    4384:	8b 00                	mov    (%eax),%eax
    4386:	ff e0                	jmp    *%eax
	case CAP_SRET:
	case CAP_THD:
	case CAP_TCAP:
		return CAP_SZ_16B;
    4388:	b8 00 00 00 00       	mov    $0x0,%eax
    438d:	eb 13                	jmp    43a2 <__captbl_cap2sz+0x32>
	case CAP_CAPTBL:
	case CAP_PGTBL:
	case CAP_HW: /* TODO: 256bits = 32B * 8b */
		return CAP_SZ_32B;
    438f:	b8 01 00 00 00       	mov    $0x1,%eax
    4394:	eb 0c                	jmp    43a2 <__captbl_cap2sz+0x32>
	case CAP_SINV:
	case CAP_COMP:
	case CAP_ASND:
	case CAP_ARCV:
		return CAP_SZ_64B;
    4396:	b8 02 00 00 00       	mov    $0x2,%eax
    439b:	eb 05                	jmp    43a2 <__captbl_cap2sz+0x32>
	default:
		return CAP_SZ_ERR;
    439d:	b8 03 00 00 00       	mov    $0x3,%eax
	}
}
    43a2:	5d                   	pop    %ebp
    43a3:	c3                   	ret    

000043a4 <captbl_idsize>:

static inline unsigned long
captbl_idsize(cap_t c)
{
    43a4:	55                   	push   %ebp
    43a5:	89 e5                	mov    %esp,%ebp
    43a7:	83 ec 04             	sub    $0x4,%esp
	return 1 << __captbl_cap2sz(c);
    43aa:	8b 45 08             	mov    0x8(%ebp),%eax
    43ad:	89 04 24             	mov    %eax,(%esp)
    43b0:	e8 bb ff ff ff       	call   4370 <__captbl_cap2sz>
    43b5:	ba 01 00 00 00       	mov    $0x1,%edx
    43ba:	89 c1                	mov    %eax,%ecx
    43bc:	d3 e2                	shl    %cl,%edx
    43be:	89 d0                	mov    %edx,%eax
}
    43c0:	c9                   	leave  
    43c1:	c3                   	ret    

000043c2 <cos_cas>:
 * 0 on failure due to contention (*target != old)
 * 1 otherwise (*target == old -> *target = updated)
 */
static inline int
cos_cas(unsigned long *target, unsigned long old, unsigned long updated)
{
    43c2:	55                   	push   %ebp
    43c3:	89 e5                	mov    %esp,%ebp
    43c5:	53                   	push   %ebx
    43c6:	83 ec 10             	sub    $0x10,%esp
	char z;
	__asm__ __volatile__("lock cmpxchgl %2, %0; setz %1"
    43c9:	8b 55 08             	mov    0x8(%ebp),%edx
    43cc:	8b 4d 10             	mov    0x10(%ebp),%ecx
    43cf:	8b 45 0c             	mov    0xc(%ebp),%eax
    43d2:	8b 5d 08             	mov    0x8(%ebp),%ebx
    43d5:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    43d9:	0f 94 c0             	sete   %al
    43dc:	88 45 fb             	mov    %al,-0x5(%ebp)
	                     : "+m"(*target), "=a"(z)
	                     : "q"(updated), "a"(old)
	                     : "memory", "cc");
	return (int)z;
    43df:	0f be 45 fb          	movsbl -0x5(%ebp),%eax
}
    43e3:	83 c4 10             	add    $0x10,%esp
    43e6:	5b                   	pop    %ebx
    43e7:	5d                   	pop    %ebp
    43e8:	c3                   	ret    

000043e9 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
    43e9:	55                   	push   %ebp
    43ea:	89 e5                	mov    %esp,%ebp
    43ec:	57                   	push   %edi
    43ed:	56                   	push   %esi
    43ee:	53                   	push   %ebx
    43ef:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    43f2:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    43f9:	8b 45 08             	mov    0x8(%ebp),%eax
    43fc:	83 c0 01             	add    $0x1,%eax
    43ff:	c1 e0 10             	shl    $0x10,%eax
    4402:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    4405:	8b 45 0c             	mov    0xc(%ebp),%eax
    4408:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    440b:	8b 45 08             	mov    0x8(%ebp),%eax
    440e:	8b 4d 10             	mov    0x10(%ebp),%ecx
    4411:	8b 75 14             	mov    0x14(%ebp),%esi
    4414:	8b 7d 18             	mov    0x18(%ebp),%edi
    4417:	8b 55 1c             	mov    0x1c(%ebp),%edx
    441a:	89 cb                	mov    %ecx,%ebx
    441c:	55                   	push   %ebp
    441d:	89 e5                	mov    %esp,%ebp
    441f:	b9 30 44 00 00       	mov    $0x4430,%ecx
    4424:	0f 34                	sysenter 
    4426:	66 90                	xchg   %ax,%ax
    4428:	eb 0d                	jmp    4437 <call_cap_asm+0x4e>
    442a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    4430:	b9 00 00 00 00       	mov    $0x0,%ecx
    4435:	eb 05                	jmp    443c <call_cap_asm+0x53>
    4437:	b9 01 00 00 00       	mov    $0x1,%ecx
    443c:	5d                   	pop    %ebp
    443d:	89 ca                	mov    %ecx,%edx
    443f:	89 45 ec             	mov    %eax,-0x14(%ebp)
    4442:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    4445:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    4448:	83 c4 10             	add    $0x10,%esp
    444b:	5b                   	pop    %ebx
    444c:	5e                   	pop    %esi
    444d:	5f                   	pop    %edi
    444e:	5d                   	pop    %ebp
    444f:	c3                   	ret    

00004450 <call_cap_retvals_asm>:

static inline int
call_cap_retvals_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4,
			 unsigned long *r1, unsigned long *r2, unsigned long *r3)
{
    4450:	55                   	push   %ebp
    4451:	89 e5                	mov    %esp,%ebp
    4453:	57                   	push   %edi
    4454:	56                   	push   %esi
    4455:	53                   	push   %ebx
    4456:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    4459:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    4460:	8b 45 08             	mov    0x8(%ebp),%eax
    4463:	83 c0 01             	add    $0x1,%eax
    4466:	c1 e0 10             	shl    $0x10,%eax
    4469:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    446c:	8b 45 0c             	mov    0xc(%ebp),%eax
    446f:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    4472:	8b 45 08             	mov    0x8(%ebp),%eax
    4475:	8b 4d 10             	mov    0x10(%ebp),%ecx
    4478:	8b 75 14             	mov    0x14(%ebp),%esi
    447b:	8b 7d 18             	mov    0x18(%ebp),%edi
    447e:	8b 55 1c             	mov    0x1c(%ebp),%edx
    4481:	89 cb                	mov    %ecx,%ebx
    4483:	55                   	push   %ebp
    4484:	89 e5                	mov    %esp,%ebp
    4486:	b9 98 44 00 00       	mov    $0x4498,%ecx
    448b:	0f 34                	sysenter 
    448d:	8d 76 00             	lea    0x0(%esi),%esi
    4490:	eb 0d                	jmp    449f <call_cap_retvals_asm+0x4f>
    4492:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    4498:	b9 00 00 00 00       	mov    $0x0,%ecx
    449d:	eb 05                	jmp    44a4 <call_cap_retvals_asm+0x54>
    449f:	b9 01 00 00 00       	mov    $0x1,%ecx
    44a4:	5d                   	pop    %ebp
    44a5:	89 da                	mov    %ebx,%edx
    44a7:	89 45 ec             	mov    %eax,-0x14(%ebp)
    44aa:	89 4d f0             	mov    %ecx,-0x10(%ebp)
    44ad:	8b 45 20             	mov    0x20(%ebp),%eax
    44b0:	89 30                	mov    %esi,(%eax)
    44b2:	8b 45 24             	mov    0x24(%ebp),%eax
    44b5:	89 38                	mov    %edi,(%eax)
    44b7:	8b 45 28             	mov    0x28(%ebp),%eax
    44ba:	89 10                	mov    %edx,(%eax)
	                     "popl %%ebp\n\t"		\
	                     : "=a"(ret), "=c"(fault), "=S"(*r1), "=D"(*r2), "=b" (*r3)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    44bc:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    44bf:	83 c4 10             	add    $0x10,%esp
    44c2:	5b                   	pop    %ebx
    44c3:	5e                   	pop    %esi
    44c4:	5f                   	pop    %edi
    44c5:	5d                   	pop    %ebp
    44c6:	c3                   	ret    

000044c7 <call_cap_2retvals_asm>:

static inline int
call_cap_2retvals_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4,
			 unsigned long *r1, unsigned long *r2)
{
    44c7:	55                   	push   %ebp
    44c8:	89 e5                	mov    %esp,%ebp
    44ca:	57                   	push   %edi
    44cb:	56                   	push   %esi
    44cc:	53                   	push   %ebx
    44cd:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    44d0:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    44d7:	8b 45 08             	mov    0x8(%ebp),%eax
    44da:	83 c0 01             	add    $0x1,%eax
    44dd:	c1 e0 10             	shl    $0x10,%eax
    44e0:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    44e3:	8b 45 0c             	mov    0xc(%ebp),%eax
    44e6:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    44e9:	8b 45 08             	mov    0x8(%ebp),%eax
    44ec:	8b 4d 10             	mov    0x10(%ebp),%ecx
    44ef:	8b 75 14             	mov    0x14(%ebp),%esi
    44f2:	8b 7d 18             	mov    0x18(%ebp),%edi
    44f5:	8b 55 1c             	mov    0x1c(%ebp),%edx
    44f8:	89 cb                	mov    %ecx,%ebx
    44fa:	55                   	push   %ebp
    44fb:	89 e5                	mov    %esp,%ebp
    44fd:	b9 10 45 00 00       	mov    $0x4510,%ecx
    4502:	0f 34                	sysenter 
    4504:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
    4508:	eb 0d                	jmp    4517 <call_cap_2retvals_asm+0x50>
    450a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    4510:	b9 00 00 00 00       	mov    $0x0,%ecx
    4515:	eb 05                	jmp    451c <call_cap_2retvals_asm+0x55>
    4517:	b9 01 00 00 00       	mov    $0x1,%ecx
    451c:	5d                   	pop    %ebp
    451d:	89 fa                	mov    %edi,%edx
    451f:	89 f3                	mov    %esi,%ebx
    4521:	89 45 ec             	mov    %eax,-0x14(%ebp)
    4524:	89 4d f0             	mov    %ecx,-0x10(%ebp)
    4527:	8b 45 20             	mov    0x20(%ebp),%eax
    452a:	89 18                	mov    %ebx,(%eax)
    452c:	8b 45 24             	mov    0x24(%ebp),%eax
    452f:	89 10                	mov    %edx,(%eax)
	                     "popl %%ebp\n\t"		\
	                     : "=a"(ret), "=c"(fault), "=S"(*r1), "=D"(*r2)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    4531:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    4534:	83 c4 10             	add    $0x10,%esp
    4537:	5b                   	pop    %ebx
    4538:	5e                   	pop    %esi
    4539:	5f                   	pop    %edi
    453a:	5d                   	pop    %ebp
    453b:	c3                   	ret    

0000453c <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
    453c:	55                   	push   %ebp
    453d:	89 e5                	mov    %esp,%ebp
    453f:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
    4542:	8b 45 18             	mov    0x18(%ebp),%eax
    4545:	89 44 24 14          	mov    %eax,0x14(%esp)
    4549:	8b 45 14             	mov    0x14(%ebp),%eax
    454c:	89 44 24 10          	mov    %eax,0x10(%esp)
    4550:	8b 45 10             	mov    0x10(%ebp),%eax
    4553:	89 44 24 0c          	mov    %eax,0xc(%esp)
    4557:	8b 45 0c             	mov    0xc(%ebp),%eax
    455a:	89 44 24 08          	mov    %eax,0x8(%esp)
    455e:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    4565:	00 
    4566:	8b 45 08             	mov    0x8(%ebp),%eax
    4569:	89 04 24             	mov    %eax,(%esp)
    456c:	e8 78 fe ff ff       	call   43e9 <call_cap_asm>
}
    4571:	c9                   	leave  
    4572:	c3                   	ret    

00004573 <call_cap_op>:

static inline int
call_cap_op(u32_t cap_no, u32_t op_code, int arg1, int arg2, int arg3, int arg4)
{
    4573:	55                   	push   %ebp
    4574:	89 e5                	mov    %esp,%ebp
    4576:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
    4579:	8b 45 1c             	mov    0x1c(%ebp),%eax
    457c:	89 44 24 14          	mov    %eax,0x14(%esp)
    4580:	8b 45 18             	mov    0x18(%ebp),%eax
    4583:	89 44 24 10          	mov    %eax,0x10(%esp)
    4587:	8b 45 14             	mov    0x14(%ebp),%eax
    458a:	89 44 24 0c          	mov    %eax,0xc(%esp)
    458e:	8b 45 10             	mov    0x10(%ebp),%eax
    4591:	89 44 24 08          	mov    %eax,0x8(%esp)
    4595:	8b 45 0c             	mov    0xc(%ebp),%eax
    4598:	89 44 24 04          	mov    %eax,0x4(%esp)
    459c:	8b 45 08             	mov    0x8(%ebp),%eax
    459f:	89 04 24             	mov    %eax,(%esp)
    45a2:	e8 42 fe ff ff       	call   43e9 <call_cap_asm>
}
    45a7:	c9                   	leave  
    45a8:	c3                   	ret    

000045a9 <cos_print>:

static void
cos_print(char *s, int len)
{
    45a9:	55                   	push   %ebp
    45aa:	89 e5                	mov    %esp,%ebp
    45ac:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
    45af:	8b 45 08             	mov    0x8(%ebp),%eax
    45b2:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    45b9:	00 
    45ba:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    45c1:	00 
    45c2:	8b 55 0c             	mov    0xc(%ebp),%edx
    45c5:	89 54 24 08          	mov    %edx,0x8(%esp)
    45c9:	89 44 24 04          	mov    %eax,0x4(%esp)
    45cd:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    45d4:	e8 63 ff ff ff       	call   453c <call_cap>
}
    45d9:	c9                   	leave  
    45da:	c3                   	ret    

000045db <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
    45db:	55                   	push   %ebp
    45dc:	89 e5                	mov    %esp,%ebp
    45de:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
    45e1:	89 e0                	mov    %esp,%eax
    45e3:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
    45e6:	8b 45 fc             	mov    -0x4(%ebp),%eax
    45e9:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    45ee:	89 c2                	mov    %eax,%edx
    45f0:	8b 45 08             	mov    0x8(%ebp),%eax
    45f3:	c1 e0 02             	shl    $0x2,%eax
    45f6:	29 c2                	sub    %eax,%edx
    45f8:	89 d0                	mov    %edx,%eax
    45fa:	05 00 10 00 00       	add    $0x1000,%eax
    45ff:	8b 00                	mov    (%eax),%eax
}
    4601:	c9                   	leave  
    4602:	c3                   	ret    

00004603 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
    4603:	55                   	push   %ebp
    4604:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
    4606:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
    460b:	5d                   	pop    %ebp
    460c:	c3                   	ret    

0000460d <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
    460d:	55                   	push   %ebp
    460e:	89 e5                	mov    %esp,%ebp
    4610:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
    4613:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    461a:	e8 bc ff ff ff       	call   45db <get_stk_data>
}
    461f:	c9                   	leave  
    4620:	c3                   	ret    

00004621 <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
    4621:	55                   	push   %ebp
    4622:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
    4624:	e8 e4 ff ff ff       	call   460d <cos_get_thd_id>
}
    4629:	5d                   	pop    %ebp
    462a:	c3                   	ret    

0000462b <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
    462b:	55                   	push   %ebp
    462c:	89 e5                	mov    %esp,%ebp
    462e:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
    4631:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    4638:	eb 20                	jmp    465a <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
    463a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    463d:	83 c0 01             	add    $0x1,%eax
    4640:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    4647:	8b 45 08             	mov    0x8(%ebp),%eax
    464a:	01 d0                	add    %edx,%eax
    464c:	8b 00                	mov    (%eax),%eax
    464e:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
    4651:	8b 45 f0             	mov    -0x10(%ebp),%eax
    4654:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
    4656:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    465a:	8b 45 08             	mov    0x8(%ebp),%eax
    465d:	8b 00                	mov    (%eax),%eax
    465f:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    4662:	7f d6                	jg     463a <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
    4664:	c9                   	leave  
    4665:	c3                   	ret    

00004666 <constructors_execute>:

static void
constructors_execute(void)
{
    4666:	55                   	push   %ebp
    4667:	89 e5                	mov    %esp,%ebp
    4669:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
    466c:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    4673:	e8 b3 ff ff ff       	call   462b <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
    4678:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    467f:	e8 a7 ff ff ff       	call   462b <section_fnptrs_execute>
}
    4684:	c9                   	leave  
    4685:	c3                   	ret    

00004686 <destructors_execute>:
static void
destructors_execute(void)
{
    4686:	55                   	push   %ebp
    4687:	89 e5                	mov    %esp,%ebp
    4689:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
    468c:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    4693:	e8 93 ff ff ff       	call   462b <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
    4698:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    469f:	e8 87 ff ff ff       	call   462b <section_fnptrs_execute>
}
    46a4:	c9                   	leave  
    46a5:	c3                   	ret    

000046a6 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
    46a6:	55                   	push   %ebp
    46a7:	89 e5                	mov    %esp,%ebp
    46a9:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
    46ac:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    46b3:	e8 73 ff ff ff       	call   462b <section_fnptrs_execute>
}
    46b8:	c9                   	leave  
    46b9:	c3                   	ret    

000046ba <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
    46ba:	55                   	push   %ebp
    46bb:	89 e5                	mov    %esp,%ebp
    46bd:	83 ec 08             	sub    $0x8,%esp
    46c0:	8b 55 08             	mov    0x8(%ebp),%edx
    46c3:	8b 45 0c             	mov    0xc(%ebp),%eax
    46c6:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
    46ca:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
    46cd:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    46d1:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
    46d5:	ee                   	out    %al,(%dx)
}
    46d6:	c9                   	leave  
    46d7:	c3                   	ret    

000046d8 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
    46d8:	55                   	push   %ebp
    46d9:	89 e5                	mov    %esp,%ebp
    46db:	83 ec 14             	sub    $0x14,%esp
    46de:	8b 45 08             	mov    0x8(%ebp),%eax
    46e1:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
    46e5:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
    46e9:	89 c2                	mov    %eax,%edx
    46eb:	ec                   	in     (%dx),%al
    46ec:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
    46ef:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
    46f3:	c9                   	leave  
    46f4:	c3                   	ret    

000046f5 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
    46f5:	55                   	push   %ebp
    46f6:	89 e5                	mov    %esp,%ebp
    46f8:	83 ec 0c             	sub    $0xc,%esp
    46fb:	8b 45 08             	mov    0x8(%ebp),%eax
    46fe:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
    4701:	90                   	nop
    4702:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
    4709:	e8 ca ff ff ff       	call   46d8 <inb>
    470e:	0f b6 c0             	movzbl %al,%eax
    4711:	83 e0 20             	and    $0x20,%eax
    4714:	85 c0                	test   %eax,%eax
    4716:	74 ea                	je     4702 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
    4718:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    471c:	0f b6 c0             	movzbl %al,%eax
    471f:	89 44 24 04          	mov    %eax,0x4(%esp)
    4723:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
    472a:	e8 8b ff ff ff       	call   46ba <outb>
}
    472f:	c9                   	leave  
    4730:	c3                   	ret    

00004731 <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
    4731:	55                   	push   %ebp
    4732:	89 e5                	mov    %esp,%ebp
    4734:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
    4737:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
    473e:	eb 1a                	jmp    475a <cos_serial_putb+0x29>
    4740:	8b 45 fc             	mov    -0x4(%ebp),%eax
    4743:	8b 55 08             	mov    0x8(%ebp),%edx
    4746:	01 d0                	add    %edx,%eax
    4748:	0f b6 00             	movzbl (%eax),%eax
    474b:	0f be c0             	movsbl %al,%eax
    474e:	89 04 24             	mov    %eax,(%esp)
    4751:	e8 9f ff ff ff       	call   46f5 <cos_serial_putc>
    4756:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
    475a:	8b 45 fc             	mov    -0x4(%ebp),%eax
    475d:	3b 45 0c             	cmp    0xc(%ebp),%eax
    4760:	72 de                	jb     4740 <cos_serial_putb+0xf>
}
    4762:	c9                   	leave  
    4763:	c3                   	ret    

00004764 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
    4764:	55                   	push   %ebp
    4765:	89 e5                	mov    %esp,%ebp
    4767:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
    476a:	8b 45 0c             	mov    0xc(%ebp),%eax
    476d:	89 44 24 04          	mov    %eax,0x4(%esp)
    4771:	8b 45 08             	mov    0x8(%ebp),%eax
    4774:	89 04 24             	mov    %eax,(%esp)
    4777:	e8 b5 ff ff ff       	call   4731 <cos_serial_putb>
}
    477c:	c9                   	leave  
    477d:	c3                   	ret    

0000477e <prints>:

static int
prints(char *s)
{
    477e:	55                   	push   %ebp
    477f:	89 e5                	mov    %esp,%ebp
    4781:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
    4784:	8b 45 08             	mov    0x8(%ebp),%eax
    4787:	89 04 24             	mov    %eax,(%esp)
    478a:	e8 fc ff ff ff       	call   478b <prints+0xd>
    478f:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
    4792:	8b 45 f4             	mov    -0xc(%ebp),%eax
    4795:	89 44 24 04          	mov    %eax,0x4(%esp)
    4799:	8b 45 08             	mov    0x8(%ebp),%eax
    479c:	89 04 24             	mov    %eax,(%esp)
    479f:	e8 05 fe ff ff       	call   45a9 <cos_print>

	return len;
    47a4:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    47a7:	c9                   	leave  
    47a8:	c3                   	ret    

000047a9 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
    47a9:	55                   	push   %ebp
    47aa:	89 e5                	mov    %esp,%ebp
    47ac:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
    47b2:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
    47b9:	8d 45 0c             	lea    0xc(%ebp),%eax
    47bc:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
    47c2:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
    47c8:	89 44 24 0c          	mov    %eax,0xc(%esp)
    47cc:	8b 45 08             	mov    0x8(%ebp),%eax
    47cf:	89 44 24 08          	mov    %eax,0x8(%esp)
    47d3:	8b 45 f4             	mov    -0xc(%ebp),%eax
    47d6:	89 44 24 04          	mov    %eax,0x4(%esp)
    47da:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    47e0:	89 04 24             	mov    %eax,(%esp)
    47e3:	e8 fc ff ff ff       	call   47e4 <printc+0x3b>
    47e8:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
    47eb:	8b 45 f0             	mov    -0x10(%ebp),%eax
    47ee:	89 44 24 04          	mov    %eax,0x4(%esp)
    47f2:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    47f8:	89 04 24             	mov    %eax,(%esp)
    47fb:	e8 64 ff ff ff       	call   4764 <cos_llprint>

	return ret;
    4800:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    4803:	c9                   	leave  
    4804:	c3                   	ret    

00004805 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
    4805:	55                   	push   %ebp
    4806:	89 e5                	mov    %esp,%ebp
	while (1)
		;
    4808:	eb fe                	jmp    4808 <__cos_noret+0x3>

0000480a <ps_cas>:
 * 0 on failure due to contention (*target != old)
 * 1 otherwise (*target == old -> *target = updated)
 */
static inline int
ps_cas(unsigned long *target, unsigned long old, unsigned long updated)
{
    480a:	55                   	push   %ebp
    480b:	89 e5                	mov    %esp,%ebp
    480d:	53                   	push   %ebx
    480e:	83 ec 10             	sub    $0x10,%esp
        char z;
        __asm__ __volatile__("lock " PS_CAS_STR
    4811:	8b 55 08             	mov    0x8(%ebp),%edx
    4814:	8b 4d 10             	mov    0x10(%ebp),%ecx
    4817:	8b 45 0c             	mov    0xc(%ebp),%eax
    481a:	8b 5d 08             	mov    0x8(%ebp),%ebx
    481d:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    4821:	0f 94 c0             	sete   %al
    4824:	88 45 fb             	mov    %al,-0x5(%ebp)
                             : "+m" (*target), "=a" (z)
                             : "q"  (updated), "a"  (old)
                             : "memory", "cc");
        return (int)z;
    4827:	0f be 45 fb          	movsbl -0x5(%ebp),%eax
}
    482b:	83 c4 10             	add    $0x10,%esp
    482e:	5b                   	pop    %ebx
    482f:	5d                   	pop    %ebp
    4830:	c3                   	ret    

00004831 <ps_faa>:

static inline long
ps_faa(unsigned long *target, long inc)
{
    4831:	55                   	push   %ebp
    4832:	89 e5                	mov    %esp,%ebp
        __asm__ __volatile__("lock " PS_FAA_STR
    4834:	8b 55 08             	mov    0x8(%ebp),%edx
    4837:	8b 4d 08             	mov    0x8(%ebp),%ecx
    483a:	8b 45 0c             	mov    0xc(%ebp),%eax
    483d:	f0 0f c1 02          	lock xadd %eax,(%edx)
    4841:	89 45 0c             	mov    %eax,0xc(%ebp)
                             : "+m" (*target), "+q" (inc)
                             : : "memory", "cc");
        return inc;
    4844:	8b 45 0c             	mov    0xc(%ebp),%eax
}
    4847:	5d                   	pop    %ebp
    4848:	c3                   	ret    

00004849 <ps_lock_take>:
	unsigned long o;
};

static inline void
ps_lock_take(struct ps_lock *l)
{ while (!ps_cas(&l->o, 0, 1)) ; }
    4849:	55                   	push   %ebp
    484a:	89 e5                	mov    %esp,%ebp
    484c:	83 ec 0c             	sub    $0xc,%esp
    484f:	90                   	nop
    4850:	8b 45 08             	mov    0x8(%ebp),%eax
    4853:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
    485a:	00 
    485b:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    4862:	00 
    4863:	89 04 24             	mov    %eax,(%esp)
    4866:	e8 9f ff ff ff       	call   480a <ps_cas>
    486b:	85 c0                	test   %eax,%eax
    486d:	74 e1                	je     4850 <ps_lock_take+0x7>
    486f:	c9                   	leave  
    4870:	c3                   	ret    

00004871 <ps_lock_release>:

static inline void
ps_lock_release(struct ps_lock *l)
{ l->o = 0; }
    4871:	55                   	push   %ebp
    4872:	89 e5                	mov    %esp,%ebp
    4874:	8b 45 08             	mov    0x8(%ebp),%eax
    4877:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    487d:	5d                   	pop    %ebp
    487e:	c3                   	ret    

0000487f <ps_lock_init>:

static inline void
ps_lock_init(struct ps_lock *l)
{ l->o = 0; }
    487f:	55                   	push   %ebp
    4880:	89 e5                	mov    %esp,%ebp
    4882:	8b 45 08             	mov    0x8(%ebp),%eax
    4885:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    488b:	5d                   	pop    %ebp
    488c:	c3                   	ret    

0000488d <cos_meminfo_init>:
#define printd(...)
#endif

void
cos_meminfo_init(struct cos_meminfo *mi, vaddr_t untyped_ptr, unsigned long untyped_sz, pgtblcap_t pgtbl_cap)
{
    488d:	55                   	push   %ebp
    488e:	89 e5                	mov    %esp,%ebp
	mi->untyped_ptr = mi->umem_ptr = mi->kmem_ptr = mi->umem_frontier = mi->kmem_frontier = untyped_ptr;
    4890:	8b 45 08             	mov    0x8(%ebp),%eax
    4893:	8b 55 0c             	mov    0xc(%ebp),%edx
    4896:	89 50 14             	mov    %edx,0x14(%eax)
    4899:	8b 45 08             	mov    0x8(%ebp),%eax
    489c:	8b 50 14             	mov    0x14(%eax),%edx
    489f:	8b 45 08             	mov    0x8(%ebp),%eax
    48a2:	89 50 10             	mov    %edx,0x10(%eax)
    48a5:	8b 45 08             	mov    0x8(%ebp),%eax
    48a8:	8b 50 10             	mov    0x10(%eax),%edx
    48ab:	8b 45 08             	mov    0x8(%ebp),%eax
    48ae:	89 50 08             	mov    %edx,0x8(%eax)
    48b1:	8b 45 08             	mov    0x8(%ebp),%eax
    48b4:	8b 50 08             	mov    0x8(%eax),%edx
    48b7:	8b 45 08             	mov    0x8(%ebp),%eax
    48ba:	89 50 04             	mov    %edx,0x4(%eax)
    48bd:	8b 45 08             	mov    0x8(%ebp),%eax
    48c0:	8b 50 04             	mov    0x4(%eax),%edx
    48c3:	8b 45 08             	mov    0x8(%ebp),%eax
    48c6:	89 10                	mov    %edx,(%eax)
	mi->untyped_frontier = untyped_ptr + untyped_sz;
    48c8:	8b 45 10             	mov    0x10(%ebp),%eax
    48cb:	8b 55 0c             	mov    0xc(%ebp),%edx
    48ce:	01 c2                	add    %eax,%edx
    48d0:	8b 45 08             	mov    0x8(%ebp),%eax
    48d3:	89 50 0c             	mov    %edx,0xc(%eax)
	mi->pgtbl_cap        = pgtbl_cap;
    48d6:	8b 45 08             	mov    0x8(%ebp),%eax
    48d9:	8b 55 14             	mov    0x14(%ebp),%edx
    48dc:	89 50 18             	mov    %edx,0x18(%eax)
}
    48df:	5d                   	pop    %ebp
    48e0:	c3                   	ret    

000048e1 <__compinfo_metacap>:

static inline struct cos_compinfo *
__compinfo_metacap(struct cos_compinfo *ci)
{
    48e1:	55                   	push   %ebp
    48e2:	89 e5                	mov    %esp,%ebp
	return ci->memsrc;
    48e4:	8b 45 08             	mov    0x8(%ebp),%eax
    48e7:	8b 40 28             	mov    0x28(%eax),%eax
}
    48ea:	5d                   	pop    %ebp
    48eb:	c3                   	ret    

000048ec <cos_vasfrontier_init>:

static inline void
cos_vasfrontier_init(struct cos_compinfo *ci, vaddr_t heap_ptr)
{
    48ec:	55                   	push   %ebp
    48ed:	89 e5                	mov    %esp,%ebp
    48ef:	83 ec 18             	sub    $0x18,%esp
	ci->vas_frontier = heap_ptr;
    48f2:	8b 45 08             	mov    0x8(%ebp),%eax
    48f5:	8b 55 0c             	mov    0xc(%ebp),%edx
    48f8:	89 50 20             	mov    %edx,0x20(%eax)
	/*
	 * The first allocation should trigger PTE allocation, unless
	 * it is in the middle of a PGD, in which case we assume one
	 * is already allocated.
	 */
	ci->vasrange_frontier = round_up_to_pgd_page(heap_ptr);
    48fb:	8b 45 0c             	mov    0xc(%ebp),%eax
    48fe:	05 ff ff 3f 00       	add    $0x3fffff,%eax
    4903:	25 00 00 c0 ff       	and    $0xffc00000,%eax
    4908:	89 c2                	mov    %eax,%edx
    490a:	8b 45 08             	mov    0x8(%ebp),%eax
    490d:	89 50 24             	mov    %edx,0x24(%eax)
	assert(ci->vasrange_frontier == round_up_to_pgd_page(ci->vasrange_frontier));
    4910:	8b 45 08             	mov    0x8(%ebp),%eax
    4913:	8b 50 24             	mov    0x24(%eax),%edx
    4916:	8b 45 08             	mov    0x8(%ebp),%eax
    4919:	8b 40 24             	mov    0x24(%eax),%eax
    491c:	05 ff ff 3f 00       	add    $0x3fffff,%eax
    4921:	25 00 00 c0 ff       	and    $0xffc00000,%eax
    4926:	39 c2                	cmp    %eax,%edx
    4928:	0f 95 c0             	setne  %al
    492b:	0f b6 c0             	movzbl %al,%eax
    492e:	85 c0                	test   %eax,%eax
    4930:	74 1c                	je     494e <cos_vasfrontier_init+0x62>
    4932:	c7 04 24 48 06 00 00 	movl   $0x648,(%esp)
    4939:	e8 40 fe ff ff       	call   477e <prints>
    493e:	a1 40 00 00 00       	mov    0x40,%eax
    4943:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4949:	e8 b7 fe ff ff       	call   4805 <__cos_noret>
}
    494e:	c9                   	leave  
    494f:	c3                   	ret    

00004950 <cos_capfrontier_init>:

static inline void
cos_capfrontier_init(struct cos_compinfo *ci, capid_t cap_frontier)
{
    4950:	55                   	push   %ebp
    4951:	89 e5                	mov    %esp,%ebp
    4953:	83 ec 28             	sub    $0x28,%esp
	int i;

	assert(round_up_to_pow2(cap_frontier, CAPMAX_ENTRY_SZ) == cap_frontier);
    4956:	8b 45 0c             	mov    0xc(%ebp),%eax
    4959:	83 c0 03             	add    $0x3,%eax
    495c:	83 e0 fc             	and    $0xfffffffc,%eax
    495f:	3b 45 0c             	cmp    0xc(%ebp),%eax
    4962:	0f 95 c0             	setne  %al
    4965:	0f b6 c0             	movzbl %al,%eax
    4968:	85 c0                	test   %eax,%eax
    496a:	74 1c                	je     4988 <cos_capfrontier_init+0x38>
    496c:	c7 04 24 78 06 00 00 	movl   $0x678,(%esp)
    4973:	e8 06 fe ff ff       	call   477e <prints>
    4978:	a1 40 00 00 00       	mov    0x40,%eax
    497d:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4983:	e8 7d fe ff ff       	call   4805 <__cos_noret>
	ci->cap_frontier = cap_frontier;
    4988:	8b 45 08             	mov    0x8(%ebp),%eax
    498b:	8b 55 0c             	mov    0xc(%ebp),%edx
    498e:	89 50 0c             	mov    %edx,0xc(%eax)

	/*
	 * captbls are initialized populated with a single
	 * second-level node.
	 */
	if (cap_frontier < CAPTBL_EXPAND_SZ) {
    4991:	83 7d 0c 7f          	cmpl   $0x7f,0xc(%ebp)
    4995:	77 13                	ja     49aa <cos_capfrontier_init+0x5a>
		ci->caprange_frontier = round_up_to_pow2(cap_frontier, CAPTBL_EXPAND_SZ);
    4997:	8b 45 0c             	mov    0xc(%ebp),%eax
    499a:	83 c0 7f             	add    $0x7f,%eax
    499d:	83 e0 80             	and    $0xffffff80,%eax
    49a0:	89 c2                	mov    %eax,%edx
    49a2:	8b 45 08             	mov    0x8(%ebp),%eax
    49a5:	89 50 10             	mov    %edx,0x10(%eax)
    49a8:	eb 13                	jmp    49bd <cos_capfrontier_init+0x6d>
	} else {
		/* caprange_frontier should be rounded up to CAPTBL_EXPAND_SZ * 2 */
		ci->caprange_frontier = round_up_to_pow2(cap_frontier + CAPTBL_EXPAND_SZ, CAPTBL_EXPAND_SZ * 2) - CAPTBL_EXPAND_SZ;
    49aa:	8b 45 0c             	mov    0xc(%ebp),%eax
    49ad:	05 7f 01 00 00       	add    $0x17f,%eax
    49b2:	b0 00                	mov    $0x0,%al
    49b4:	8d 50 80             	lea    -0x80(%eax),%edx
    49b7:	8b 45 08             	mov    0x8(%ebp),%eax
    49ba:	89 50 10             	mov    %edx,0x10(%eax)
	}
	ci->cap64_frontier = cap_frontier;
    49bd:	8b 45 08             	mov    0x8(%ebp),%eax
    49c0:	8b 55 0c             	mov    0xc(%ebp),%edx
    49c3:	89 50 1c             	mov    %edx,0x1c(%eax)

	for (i = 0; i < NUM_CPU; i++) {
    49c6:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    49cd:	eb 2e                	jmp    49fd <cos_capfrontier_init+0xad>
		ci->cap16_frontier[i] = ci->cap32_frontier[i] = cap_frontier;
    49cf:	8b 45 08             	mov    0x8(%ebp),%eax
    49d2:	8b 55 f4             	mov    -0xc(%ebp),%edx
    49d5:	8d 4a 04             	lea    0x4(%edx),%ecx
    49d8:	8b 55 0c             	mov    0xc(%ebp),%edx
    49db:	89 54 88 08          	mov    %edx,0x8(%eax,%ecx,4)
    49df:	8b 45 08             	mov    0x8(%ebp),%eax
    49e2:	8b 55 f4             	mov    -0xc(%ebp),%edx
    49e5:	83 c2 04             	add    $0x4,%edx
    49e8:	8b 54 90 08          	mov    0x8(%eax,%edx,4),%edx
    49ec:	8b 45 08             	mov    0x8(%ebp),%eax
    49ef:	8b 4d f4             	mov    -0xc(%ebp),%ecx
    49f2:	83 c1 04             	add    $0x4,%ecx
    49f5:	89 54 88 04          	mov    %edx,0x4(%eax,%ecx,4)
		/* caprange_frontier should be rounded up to CAPTBL_EXPAND_SZ * 2 */
		ci->caprange_frontier = round_up_to_pow2(cap_frontier + CAPTBL_EXPAND_SZ, CAPTBL_EXPAND_SZ * 2) - CAPTBL_EXPAND_SZ;
	}
	ci->cap64_frontier = cap_frontier;

	for (i = 0; i < NUM_CPU; i++) {
    49f9:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    49fd:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    4a01:	7e cc                	jle    49cf <cos_capfrontier_init+0x7f>
		ci->cap16_frontier[i] = ci->cap32_frontier[i] = cap_frontier;
	}
}
    4a03:	c9                   	leave  
    4a04:	c3                   	ret    

00004a05 <cos_compinfo_init>:

void
cos_compinfo_init(struct cos_compinfo *ci, pgtblcap_t pgtbl_cap, captblcap_t captbl_cap, compcap_t comp_cap,
                  vaddr_t heap_ptr, capid_t cap_frontier, struct cos_compinfo *ci_resources)
{
    4a05:	55                   	push   %ebp
    4a06:	89 e5                	mov    %esp,%ebp
    4a08:	83 ec 18             	sub    $0x18,%esp
	assert(ci && ci_resources);
    4a0b:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    4a0f:	0f 94 c0             	sete   %al
    4a12:	0f b6 c0             	movzbl %al,%eax
    4a15:	85 c0                	test   %eax,%eax
    4a17:	75 0e                	jne    4a27 <cos_compinfo_init+0x22>
    4a19:	83 7d 20 00          	cmpl   $0x0,0x20(%ebp)
    4a1d:	0f 94 c0             	sete   %al
    4a20:	0f b6 c0             	movzbl %al,%eax
    4a23:	85 c0                	test   %eax,%eax
    4a25:	74 1c                	je     4a43 <cos_compinfo_init+0x3e>
    4a27:	c7 04 24 a8 06 00 00 	movl   $0x6a8,(%esp)
    4a2e:	e8 4b fd ff ff       	call   477e <prints>
    4a33:	a1 40 00 00 00       	mov    0x40,%eax
    4a38:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4a3e:	e8 c2 fd ff ff       	call   4805 <__cos_noret>
	assert(cap_frontier % CAPMAX_ENTRY_SZ == 0);
    4a43:	8b 45 1c             	mov    0x1c(%ebp),%eax
    4a46:	83 e0 03             	and    $0x3,%eax
    4a49:	85 c0                	test   %eax,%eax
    4a4b:	0f 95 c0             	setne  %al
    4a4e:	0f b6 c0             	movzbl %al,%eax
    4a51:	85 c0                	test   %eax,%eax
    4a53:	74 1c                	je     4a71 <cos_compinfo_init+0x6c>
    4a55:	c7 04 24 d8 06 00 00 	movl   $0x6d8,(%esp)
    4a5c:	e8 1d fd ff ff       	call   477e <prints>
    4a61:	a1 40 00 00 00       	mov    0x40,%eax
    4a66:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4a6c:	e8 94 fd ff ff       	call   4805 <__cos_noret>

	ci->memsrc = ci_resources;
    4a71:	8b 45 08             	mov    0x8(%ebp),%eax
    4a74:	8b 55 20             	mov    0x20(%ebp),%edx
    4a77:	89 50 28             	mov    %edx,0x28(%eax)
	assert(ci_resources->memsrc == ci_resources); /* prevent infinite data-structs */
    4a7a:	8b 45 20             	mov    0x20(%ebp),%eax
    4a7d:	8b 40 28             	mov    0x28(%eax),%eax
    4a80:	3b 45 20             	cmp    0x20(%ebp),%eax
    4a83:	0f 95 c0             	setne  %al
    4a86:	0f b6 c0             	movzbl %al,%eax
    4a89:	85 c0                	test   %eax,%eax
    4a8b:	74 1c                	je     4aa9 <cos_compinfo_init+0xa4>
    4a8d:	c7 04 24 08 07 00 00 	movl   $0x708,(%esp)
    4a94:	e8 e5 fc ff ff       	call   477e <prints>
    4a99:	a1 40 00 00 00       	mov    0x40,%eax
    4a9e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4aa4:	e8 5c fd ff ff       	call   4805 <__cos_noret>

	ci->pgtbl_cap    = pgtbl_cap;
    4aa9:	8b 45 08             	mov    0x8(%ebp),%eax
    4aac:	8b 55 0c             	mov    0xc(%ebp),%edx
    4aaf:	89 10                	mov    %edx,(%eax)
	ci->captbl_cap   = captbl_cap;
    4ab1:	8b 45 08             	mov    0x8(%ebp),%eax
    4ab4:	8b 55 10             	mov    0x10(%ebp),%edx
    4ab7:	89 50 04             	mov    %edx,0x4(%eax)
	ci->comp_cap     = comp_cap;
    4aba:	8b 45 08             	mov    0x8(%ebp),%eax
    4abd:	8b 55 14             	mov    0x14(%ebp),%edx
    4ac0:	89 50 08             	mov    %edx,0x8(%eax)

	cos_vasfrontier_init(ci, heap_ptr);
    4ac3:	8b 45 18             	mov    0x18(%ebp),%eax
    4ac6:	89 44 24 04          	mov    %eax,0x4(%esp)
    4aca:	8b 45 08             	mov    0x8(%ebp),%eax
    4acd:	89 04 24             	mov    %eax,(%esp)
    4ad0:	e8 17 fe ff ff       	call   48ec <cos_vasfrontier_init>
	cos_capfrontier_init(ci, cap_frontier);
    4ad5:	8b 45 1c             	mov    0x1c(%ebp),%eax
    4ad8:	89 44 24 04          	mov    %eax,0x4(%esp)
    4adc:	8b 45 08             	mov    0x8(%ebp),%eax
    4adf:	89 04 24             	mov    %eax,(%esp)
    4ae2:	e8 69 fe ff ff       	call   4950 <cos_capfrontier_init>

	ps_lock_init(&ci->cap_lock);
    4ae7:	8b 45 08             	mov    0x8(%ebp),%eax
    4aea:	83 c0 48             	add    $0x48,%eax
    4aed:	89 04 24             	mov    %eax,(%esp)
    4af0:	e8 8a fd ff ff       	call   487f <ps_lock_init>
	ps_lock_init(&ci->mem_lock);
    4af5:	8b 45 08             	mov    0x8(%ebp),%eax
    4af8:	83 c0 4c             	add    $0x4c,%eax
    4afb:	89 04 24             	mov    %eax,(%esp)
    4afe:	e8 7c fd ff ff       	call   487f <ps_lock_init>
	ps_lock_init(&ci->va_lock);
    4b03:	8b 45 08             	mov    0x8(%ebp),%eax
    4b06:	83 c0 50             	add    $0x50,%eax
    4b09:	89 04 24             	mov    %eax,(%esp)
    4b0c:	e8 6e fd ff ff       	call   487f <ps_lock_init>
}
    4b11:	c9                   	leave  
    4b12:	c3                   	ret    

00004b13 <__mem_bump_alloc>:

/**************** [Memory Capability Allocation Functions] ***************/

static vaddr_t
__mem_bump_alloc(struct cos_compinfo *__ci, int km, int retype)
{
    4b13:	55                   	push   %ebp
    4b14:	89 e5                	mov    %esp,%ebp
    4b16:	83 ec 48             	sub    $0x48,%esp
	vaddr_t              ret = 0;
    4b19:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct cos_compinfo *ci;
	vaddr_t *            ptr, *frontier;

	printd("__mem_bump_alloc\n");

	assert(__ci);
    4b20:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    4b24:	0f 94 c0             	sete   %al
    4b27:	0f b6 c0             	movzbl %al,%eax
    4b2a:	85 c0                	test   %eax,%eax
    4b2c:	74 1c                	je     4b4a <__mem_bump_alloc+0x37>
    4b2e:	c7 04 24 38 07 00 00 	movl   $0x738,(%esp)
    4b35:	e8 44 fc ff ff       	call   477e <prints>
    4b3a:	a1 40 00 00 00       	mov    0x40,%eax
    4b3f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4b45:	e8 bb fc ff ff       	call   4805 <__cos_noret>
	ci = __compinfo_metacap(__ci);
    4b4a:	8b 45 08             	mov    0x8(%ebp),%eax
    4b4d:	89 04 24             	mov    %eax,(%esp)
    4b50:	e8 8c fd ff ff       	call   48e1 <__compinfo_metacap>
    4b55:	89 45 e8             	mov    %eax,-0x18(%ebp)
	assert(ci && ci == __compinfo_metacap(__ci));
    4b58:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
    4b5c:	0f 94 c0             	sete   %al
    4b5f:	0f b6 c0             	movzbl %al,%eax
    4b62:	85 c0                	test   %eax,%eax
    4b64:	75 18                	jne    4b7e <__mem_bump_alloc+0x6b>
    4b66:	8b 45 08             	mov    0x8(%ebp),%eax
    4b69:	89 04 24             	mov    %eax,(%esp)
    4b6c:	e8 70 fd ff ff       	call   48e1 <__compinfo_metacap>
    4b71:	3b 45 e8             	cmp    -0x18(%ebp),%eax
    4b74:	0f 95 c0             	setne  %al
    4b77:	0f b6 c0             	movzbl %al,%eax
    4b7a:	85 c0                	test   %eax,%eax
    4b7c:	74 1c                	je     4b9a <__mem_bump_alloc+0x87>
    4b7e:	c7 04 24 68 07 00 00 	movl   $0x768,(%esp)
    4b85:	e8 f4 fb ff ff       	call   477e <prints>
    4b8a:	a1 40 00 00 00       	mov    0x40,%eax
    4b8f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4b95:	e8 6b fc ff ff       	call   4805 <__cos_noret>

	ps_lock_take(&ci->mem_lock);
    4b9a:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4b9d:	83 c0 4c             	add    $0x4c,%eax
    4ba0:	89 04 24             	mov    %eax,(%esp)
    4ba3:	e8 a1 fc ff ff       	call   4849 <ps_lock_take>

	if (km) {
    4ba8:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    4bac:	74 14                	je     4bc2 <__mem_bump_alloc+0xaf>
		ptr      = &ci->mi.kmem_ptr;
    4bae:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4bb1:	83 c0 34             	add    $0x34,%eax
    4bb4:	89 45 f0             	mov    %eax,-0x10(%ebp)
		frontier = &ci->mi.kmem_frontier;
    4bb7:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4bba:	83 c0 40             	add    $0x40,%eax
    4bbd:	89 45 ec             	mov    %eax,-0x14(%ebp)
    4bc0:	eb 12                	jmp    4bd4 <__mem_bump_alloc+0xc1>
	} else {
		ptr      = &ci->mi.umem_ptr;
    4bc2:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4bc5:	83 c0 30             	add    $0x30,%eax
    4bc8:	89 45 f0             	mov    %eax,-0x10(%ebp)
		frontier = &ci->mi.umem_frontier;
    4bcb:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4bce:	83 c0 3c             	add    $0x3c,%eax
    4bd1:	89 45 ec             	mov    %eax,-0x14(%ebp)
	}

	ret = ps_faa(ptr, PAGE_SIZE);
    4bd4:	c7 44 24 04 00 10 00 	movl   $0x1000,0x4(%esp)
    4bdb:	00 
    4bdc:	8b 45 f0             	mov    -0x10(%ebp),%eax
    4bdf:	89 04 24             	mov    %eax,(%esp)
    4be2:	e8 4a fc ff ff       	call   4831 <ps_faa>
    4be7:	89 45 f4             	mov    %eax,-0xc(%ebp)

	if (ret >= *frontier || *frontier - ret > RETYPE_MEM_SIZE) {
    4bea:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4bed:	8b 00                	mov    (%eax),%eax
    4bef:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    4bf2:	76 0f                	jbe    4c03 <__mem_bump_alloc+0xf0>
    4bf4:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4bf7:	8b 00                	mov    (%eax),%eax
    4bf9:	2b 45 f4             	sub    -0xc(%ebp),%eax
    4bfc:	3d 00 10 00 00       	cmp    $0x1000,%eax
    4c01:	76 7e                	jbe    4c81 <__mem_bump_alloc+0x16e>
		vaddr_t ptr_tmp = *ptr, front_tmp = *frontier;
    4c03:	8b 45 f0             	mov    -0x10(%ebp),%eax
    4c06:	8b 00                	mov    (%eax),%eax
    4c08:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    4c0b:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4c0e:	8b 00                	mov    (%eax),%eax
    4c10:	89 45 e0             	mov    %eax,-0x20(%ebp)

		/* TODO: expand frontier if introspection says there is more memory */
		if (ci->mi.untyped_ptr == ci->mi.untyped_frontier) goto error;
    4c13:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4c16:	8b 50 2c             	mov    0x2c(%eax),%edx
    4c19:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4c1c:	8b 40 38             	mov    0x38(%eax),%eax
    4c1f:	39 c2                	cmp    %eax,%edx
    4c21:	75 05                	jne    4c28 <__mem_bump_alloc+0x115>
    4c23:	e9 cd 00 00 00       	jmp    4cf5 <__mem_bump_alloc+0x1e2>
		/* this is the overall frontier, so we know we can use this value... */
		ret = ps_faa(&ci->mi.untyped_ptr, RETYPE_MEM_SIZE);
    4c28:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4c2b:	83 c0 2c             	add    $0x2c,%eax
    4c2e:	c7 44 24 04 00 10 00 	movl   $0x1000,0x4(%esp)
    4c35:	00 
    4c36:	89 04 24             	mov    %eax,(%esp)
    4c39:	e8 f3 fb ff ff       	call   4831 <ps_faa>
    4c3e:	89 45 f4             	mov    %eax,-0xc(%ebp)
		/* failure here means that someone else already advanced the frontier/ptr */
		if (ps_cas(ptr, ptr_tmp, ret + PAGE_SIZE)) {
    4c41:	8b 45 f4             	mov    -0xc(%ebp),%eax
    4c44:	05 00 10 00 00       	add    $0x1000,%eax
    4c49:	89 44 24 08          	mov    %eax,0x8(%esp)
    4c4d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    4c50:	89 44 24 04          	mov    %eax,0x4(%esp)
    4c54:	8b 45 f0             	mov    -0x10(%ebp),%eax
    4c57:	89 04 24             	mov    %eax,(%esp)
    4c5a:	e8 ab fb ff ff       	call   480a <ps_cas>
    4c5f:	85 c0                	test   %eax,%eax
    4c61:	74 1e                	je     4c81 <__mem_bump_alloc+0x16e>
			ps_cas(frontier, front_tmp, ret + RETYPE_MEM_SIZE);
    4c63:	8b 45 f4             	mov    -0xc(%ebp),%eax
    4c66:	05 00 10 00 00       	add    $0x1000,%eax
    4c6b:	89 44 24 08          	mov    %eax,0x8(%esp)
    4c6f:	8b 45 e0             	mov    -0x20(%ebp),%eax
    4c72:	89 44 24 04          	mov    %eax,0x4(%esp)
    4c76:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4c79:	89 04 24             	mov    %eax,(%esp)
    4c7c:	e8 89 fb ff ff       	call   480a <ps_cas>
		}
	}

	if (retype && (ret % RETYPE_MEM_SIZE == 0)) {
    4c81:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    4c85:	74 5b                	je     4ce2 <__mem_bump_alloc+0x1cf>
    4c87:	8b 45 f4             	mov    -0xc(%ebp),%eax
    4c8a:	25 ff 0f 00 00       	and    $0xfff,%eax
    4c8f:	85 c0                	test   %eax,%eax
    4c91:	75 4f                	jne    4ce2 <__mem_bump_alloc+0x1cf>
		/* are we dealing with a kernel memory allocation? */
		syscall_op_t op = km ? CAPTBL_OP_MEM_RETYPE2KERN : CAPTBL_OP_MEM_RETYPE2USER;
    4c93:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    4c97:	74 07                	je     4ca0 <__mem_bump_alloc+0x18d>
    4c99:	b8 13 00 00 00       	mov    $0x13,%eax
    4c9e:	eb 05                	jmp    4ca5 <__mem_bump_alloc+0x192>
    4ca0:	b8 12 00 00 00       	mov    $0x12,%eax
    4ca5:	89 45 dc             	mov    %eax,-0x24(%ebp)
		if (call_cap_op(ci->mi.pgtbl_cap, op, ret, 0, 0, 0)) goto error;
    4ca8:	8b 55 f4             	mov    -0xc(%ebp),%edx
    4cab:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4cae:	8b 40 44             	mov    0x44(%eax),%eax
    4cb1:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    4cb8:	00 
    4cb9:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    4cc0:	00 
    4cc1:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    4cc8:	00 
    4cc9:	89 54 24 08          	mov    %edx,0x8(%esp)
    4ccd:	8b 55 dc             	mov    -0x24(%ebp),%edx
    4cd0:	89 54 24 04          	mov    %edx,0x4(%esp)
    4cd4:	89 04 24             	mov    %eax,(%esp)
    4cd7:	e8 97 f8 ff ff       	call   4573 <call_cap_op>
    4cdc:	85 c0                	test   %eax,%eax
    4cde:	74 02                	je     4ce2 <__mem_bump_alloc+0x1cf>
    4ce0:	eb 13                	jmp    4cf5 <__mem_bump_alloc+0x1e2>
	}

	ps_lock_release(&ci->mem_lock);
    4ce2:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4ce5:	83 c0 4c             	add    $0x4c,%eax
    4ce8:	89 04 24             	mov    %eax,(%esp)
    4ceb:	e8 81 fb ff ff       	call   4871 <ps_lock_release>

	return ret;
    4cf0:	8b 45 f4             	mov    -0xc(%ebp),%eax
    4cf3:	eb 13                	jmp    4d08 <__mem_bump_alloc+0x1f5>
error:
	ps_lock_release(&ci->mem_lock);
    4cf5:	8b 45 e8             	mov    -0x18(%ebp),%eax
    4cf8:	83 c0 4c             	add    $0x4c,%eax
    4cfb:	89 04 24             	mov    %eax,(%esp)
    4cfe:	e8 6e fb ff ff       	call   4871 <ps_lock_release>

	return 0;
    4d03:	b8 00 00 00 00       	mov    $0x0,%eax
}
    4d08:	c9                   	leave  
    4d09:	c3                   	ret    

00004d0a <__kmem_bump_alloc>:

static vaddr_t
__kmem_bump_alloc(struct cos_compinfo *ci)
{
    4d0a:	55                   	push   %ebp
    4d0b:	89 e5                	mov    %esp,%ebp
    4d0d:	83 ec 18             	sub    $0x18,%esp
	printd("__kmem_bump_alloc\n");
	return __mem_bump_alloc(ci, 1, 1);
    4d10:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
    4d17:	00 
    4d18:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    4d1f:	00 
    4d20:	8b 45 08             	mov    0x8(%ebp),%eax
    4d23:	89 04 24             	mov    %eax,(%esp)
    4d26:	e8 e8 fd ff ff       	call   4b13 <__mem_bump_alloc>
}
    4d2b:	c9                   	leave  
    4d2c:	c3                   	ret    

00004d2d <__umem_bump_alloc>:

/* this should back-up to using untyped memory... */
static vaddr_t
__umem_bump_alloc(struct cos_compinfo *ci)
{
    4d2d:	55                   	push   %ebp
    4d2e:	89 e5                	mov    %esp,%ebp
    4d30:	83 ec 18             	sub    $0x18,%esp
	printd("__umem_bump_alloc\n");
	return __mem_bump_alloc(ci, 0, 1);
    4d33:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
    4d3a:	00 
    4d3b:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    4d42:	00 
    4d43:	8b 45 08             	mov    0x8(%ebp),%eax
    4d46:	89 04 24             	mov    %eax,(%esp)
    4d49:	e8 c5 fd ff ff       	call   4b13 <__mem_bump_alloc>
}
    4d4e:	c9                   	leave  
    4d4f:	c3                   	ret    

00004d50 <__untyped_bump_alloc>:

static vaddr_t
__untyped_bump_alloc(struct cos_compinfo *ci)
{
    4d50:	55                   	push   %ebp
    4d51:	89 e5                	mov    %esp,%ebp
    4d53:	83 ec 18             	sub    $0x18,%esp
	printd("__umem_bump_alloc\n");
	return __mem_bump_alloc(ci, 1, 0);
    4d56:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    4d5d:	00 
    4d5e:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    4d65:	00 
    4d66:	8b 45 08             	mov    0x8(%ebp),%eax
    4d69:	89 04 24             	mov    %eax,(%esp)
    4d6c:	e8 a2 fd ff ff       	call   4b13 <__mem_bump_alloc>
}
    4d71:	c9                   	leave  
    4d72:	c3                   	ret    

00004d73 <__capid_captbl_check_expand>:

static capid_t __capid_bump_alloc(struct cos_compinfo *ci, cap_t cap);

static int
__capid_captbl_check_expand(struct cos_compinfo *ci)
{
    4d73:	55                   	push   %ebp
    4d74:	89 e5                	mov    %esp,%ebp
    4d76:	53                   	push   %ebx
    4d77:	83 ec 44             	sub    $0x44,%esp
	/* the compinfo that tracks/allocates resources */
	struct cos_compinfo *meta = __compinfo_metacap(ci);
    4d7a:	8b 45 08             	mov    0x8(%ebp),%eax
    4d7d:	89 04 24             	mov    %eax,(%esp)
    4d80:	e8 5c fb ff ff       	call   48e1 <__compinfo_metacap>
    4d85:	89 45 ec             	mov    %eax,-0x14(%ebp)
	/* do we manage our own resources, or does a separate meta? */
	int     self_resources = (meta == ci);
    4d88:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4d8b:	3b 45 08             	cmp    0x8(%ebp),%eax
    4d8e:	0f 94 c0             	sete   %al
    4d91:	0f b6 c0             	movzbl %al,%eax
    4d94:	89 45 e8             	mov    %eax,-0x18(%ebp)
	capid_t captblcap;
	capid_t captblid_add;
	vaddr_t kmem;

	/* ensure that we have bounded structure, and bounded recursion */
	assert(__compinfo_metacap(meta) == meta);
    4d97:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4d9a:	89 04 24             	mov    %eax,(%esp)
    4d9d:	e8 3f fb ff ff       	call   48e1 <__compinfo_metacap>
    4da2:	3b 45 ec             	cmp    -0x14(%ebp),%eax
    4da5:	0f 95 c0             	setne  %al
    4da8:	0f b6 c0             	movzbl %al,%eax
    4dab:	85 c0                	test   %eax,%eax
    4dad:	74 1c                	je     4dcb <__capid_captbl_check_expand+0x58>
    4daf:	c7 04 24 98 07 00 00 	movl   $0x798,(%esp)
    4db6:	e8 c3 f9 ff ff       	call   477e <prints>
    4dbb:	a1 40 00 00 00       	mov    0x40,%eax
    4dc0:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4dc6:	e8 3a fa ff ff       	call   4805 <__cos_noret>
	 * capability for the next internal node.  This will waste the
	 * rest of the entry (internal fragmentation WRT the captbl
	 * capability).  Oh well.
	 */

	if (self_resources)
    4dcb:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
    4dcf:	74 10                	je     4de1 <__capid_captbl_check_expand+0x6e>
		frontier = ps_load(&ci->caprange_frontier) - CAPMAX_ENTRY_SZ;
    4dd1:	8b 45 08             	mov    0x8(%ebp),%eax
    4dd4:	83 c0 10             	add    $0x10,%eax
    4dd7:	8b 00                	mov    (%eax),%eax
    4dd9:	83 e8 04             	sub    $0x4,%eax
    4ddc:	89 45 f4             	mov    %eax,-0xc(%ebp)
    4ddf:	eb 09                	jmp    4dea <__capid_captbl_check_expand+0x77>
	else
		frontier = ps_load(&ci->caprange_frontier);
    4de1:	8b 45 08             	mov    0x8(%ebp),%eax
    4de4:	8b 40 10             	mov    0x10(%eax),%eax
    4de7:	89 45 f4             	mov    %eax,-0xc(%ebp)
	assert(ci->cap_frontier <= frontier);
    4dea:	8b 45 08             	mov    0x8(%ebp),%eax
    4ded:	8b 40 0c             	mov    0xc(%eax),%eax
    4df0:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    4df3:	0f 97 c0             	seta   %al
    4df6:	0f b6 c0             	movzbl %al,%eax
    4df9:	85 c0                	test   %eax,%eax
    4dfb:	74 1c                	je     4e19 <__capid_captbl_check_expand+0xa6>
    4dfd:	c7 04 24 c8 07 00 00 	movl   $0x7c8,(%esp)
    4e04:	e8 75 f9 ff ff       	call   477e <prints>
    4e09:	a1 40 00 00 00       	mov    0x40,%eax
    4e0e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4e14:	e8 ec f9 ff ff       	call   4805 <__cos_noret>

	/* Common case: */
	if (likely(ci->cap_frontier != frontier)) return 0;
    4e19:	8b 45 08             	mov    0x8(%ebp),%eax
    4e1c:	8b 40 0c             	mov    0xc(%eax),%eax
    4e1f:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    4e22:	0f 95 c0             	setne  %al
    4e25:	0f b6 c0             	movzbl %al,%eax
    4e28:	85 c0                	test   %eax,%eax
    4e2a:	74 0a                	je     4e36 <__capid_captbl_check_expand+0xc3>
    4e2c:	b8 00 00 00 00       	mov    $0x0,%eax
    4e31:	e9 ac 01 00 00       	jmp    4fe2 <__capid_captbl_check_expand+0x26f>

	kmem = __kmem_bump_alloc(ci);
    4e36:	8b 45 08             	mov    0x8(%ebp),%eax
    4e39:	89 04 24             	mov    %eax,(%esp)
    4e3c:	e8 c9 fe ff ff       	call   4d0a <__kmem_bump_alloc>
    4e41:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	assert(kmem); /* FIXME: should have a failure semantics for capids */
    4e44:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    4e48:	0f 94 c0             	sete   %al
    4e4b:	0f b6 c0             	movzbl %al,%eax
    4e4e:	85 c0                	test   %eax,%eax
    4e50:	74 1c                	je     4e6e <__capid_captbl_check_expand+0xfb>
    4e52:	c7 04 24 f8 07 00 00 	movl   $0x7f8,(%esp)
    4e59:	e8 20 f9 ff ff       	call   477e <prints>
    4e5e:	a1 40 00 00 00       	mov    0x40,%eax
    4e63:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4e69:	e8 97 f9 ff ff       	call   4805 <__cos_noret>

	if (self_resources) {
    4e6e:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
    4e72:	74 08                	je     4e7c <__capid_captbl_check_expand+0x109>
		captblcap = frontier;
    4e74:	8b 45 f4             	mov    -0xc(%ebp),%eax
    4e77:	89 45 f0             	mov    %eax,-0x10(%ebp)
    4e7a:	eb 40                	jmp    4ebc <__capid_captbl_check_expand+0x149>
	} else {
		/* Recursive call: can recur maximum 2 times. */
		captblcap = __capid_bump_alloc(meta, CAP_CAPTBL);
    4e7c:	c7 44 24 04 07 00 00 	movl   $0x7,0x4(%esp)
    4e83:	00 
    4e84:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4e87:	89 04 24             	mov    %eax,(%esp)
    4e8a:	e8 fd 01 00 00       	call   508c <__capid_bump_alloc>
    4e8f:	89 45 f0             	mov    %eax,-0x10(%ebp)
		assert(captblcap);
    4e92:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    4e96:	0f 94 c0             	sete   %al
    4e99:	0f b6 c0             	movzbl %al,%eax
    4e9c:	85 c0                	test   %eax,%eax
    4e9e:	74 1c                	je     4ebc <__capid_captbl_check_expand+0x149>
    4ea0:	c7 04 24 28 08 00 00 	movl   $0x828,(%esp)
    4ea7:	e8 d2 f8 ff ff       	call   477e <prints>
    4eac:	a1 40 00 00 00       	mov    0x40,%eax
    4eb1:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4eb7:	e8 49 f9 ff ff       	call   4805 <__cos_noret>
	}
	captblid_add = ps_load(&ci->caprange_frontier);
    4ebc:	8b 45 08             	mov    0x8(%ebp),%eax
    4ebf:	8b 40 10             	mov    0x10(%eax),%eax
    4ec2:	89 45 e0             	mov    %eax,-0x20(%ebp)
	assert(captblid_add % CAPTBL_EXPAND_SZ == 0);
    4ec5:	8b 45 e0             	mov    -0x20(%ebp),%eax
    4ec8:	83 e0 7f             	and    $0x7f,%eax
    4ecb:	85 c0                	test   %eax,%eax
    4ecd:	0f 95 c0             	setne  %al
    4ed0:	0f b6 c0             	movzbl %al,%eax
    4ed3:	85 c0                	test   %eax,%eax
    4ed5:	74 1c                	je     4ef3 <__capid_captbl_check_expand+0x180>
    4ed7:	c7 04 24 58 08 00 00 	movl   $0x858,(%esp)
    4ede:	e8 9b f8 ff ff       	call   477e <prints>
    4ee3:	a1 40 00 00 00       	mov    0x40,%eax
    4ee8:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4eee:	e8 12 f9 ff ff       	call   4805 <__cos_noret>

	printd("__capid_captbl_check_expand->pre-captblactivate (%d)\n", CAPTBL_OP_CAPTBLACTIVATE);
	/* captbl internal node allocated with the resource provider's captbls */
	if (call_cap_op(meta->captbl_cap, CAPTBL_OP_CAPTBLACTIVATE, captblcap, meta->mi.pgtbl_cap, kmem, 1)) {
    4ef3:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
    4ef6:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4ef9:	8b 40 44             	mov    0x44(%eax),%eax
    4efc:	89 c1                	mov    %eax,%ecx
    4efe:	8b 55 f0             	mov    -0x10(%ebp),%edx
    4f01:	8b 45 ec             	mov    -0x14(%ebp),%eax
    4f04:	8b 40 04             	mov    0x4(%eax),%eax
    4f07:	c7 44 24 14 01 00 00 	movl   $0x1,0x14(%esp)
    4f0e:	00 
    4f0f:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    4f13:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    4f17:	89 54 24 08          	mov    %edx,0x8(%esp)
    4f1b:	c7 44 24 04 17 00 00 	movl   $0x17,0x4(%esp)
    4f22:	00 
    4f23:	89 04 24             	mov    %eax,(%esp)
    4f26:	e8 48 f6 ff ff       	call   4573 <call_cap_op>
    4f2b:	85 c0                	test   %eax,%eax
    4f2d:	74 1c                	je     4f4b <__capid_captbl_check_expand+0x1d8>
		assert(0); /* race condition? */
    4f2f:	c7 04 24 88 08 00 00 	movl   $0x888,(%esp)
    4f36:	e8 43 f8 ff ff       	call   477e <prints>
    4f3b:	a1 40 00 00 00       	mov    0x40,%eax
    4f40:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4f46:	e8 ba f8 ff ff       	call   4805 <__cos_noret>
	 * meta->captbl_cap refers to _our_ captbl, thus
	 * captblcap's use in the following.
	 */

	/* Construct captbl */
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_CONS, captblcap, captblid_add, 0, 0)) {
    4f4b:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    4f4e:	8b 55 f0             	mov    -0x10(%ebp),%edx
    4f51:	8b 45 08             	mov    0x8(%ebp),%eax
    4f54:	8b 40 04             	mov    0x4(%eax),%eax
    4f57:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    4f5e:	00 
    4f5f:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    4f66:	00 
    4f67:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    4f6b:	89 54 24 08          	mov    %edx,0x8(%esp)
    4f6f:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    4f76:	00 
    4f77:	89 04 24             	mov    %eax,(%esp)
    4f7a:	e8 f4 f5 ff ff       	call   4573 <call_cap_op>
    4f7f:	85 c0                	test   %eax,%eax
    4f81:	74 1c                	je     4f9f <__capid_captbl_check_expand+0x22c>
		assert(0); /* race? */
    4f83:	c7 04 24 b8 08 00 00 	movl   $0x8b8,(%esp)
    4f8a:	e8 ef f7 ff ff       	call   477e <prints>
    4f8f:	a1 40 00 00 00       	mov    0x40,%eax
    4f94:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    4f9a:	e8 66 f8 ff ff       	call   4805 <__cos_noret>
		return -1;
	}

	/* Success!  Advance the frontiers. */
	frontier       = ps_load(&ci->cap_frontier);
    4f9f:	8b 45 08             	mov    0x8(%ebp),%eax
    4fa2:	8b 40 0c             	mov    0xc(%eax),%eax
    4fa5:	89 45 f4             	mov    %eax,-0xc(%ebp)
	range_frontier = ps_faa(&ci->caprange_frontier, CAPTBL_EXPAND_SZ * 2);
    4fa8:	8b 45 08             	mov    0x8(%ebp),%eax
    4fab:	83 c0 10             	add    $0x10,%eax
    4fae:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
    4fb5:	00 
    4fb6:	89 04 24             	mov    %eax,(%esp)
    4fb9:	e8 73 f8 ff ff       	call   4831 <ps_faa>
    4fbe:	89 45 dc             	mov    %eax,-0x24(%ebp)
	ps_cas(&ci->cap_frontier, frontier, range_frontier);
    4fc1:	8b 45 08             	mov    0x8(%ebp),%eax
    4fc4:	8d 50 0c             	lea    0xc(%eax),%edx
    4fc7:	8b 45 dc             	mov    -0x24(%ebp),%eax
    4fca:	89 44 24 08          	mov    %eax,0x8(%esp)
    4fce:	8b 45 f4             	mov    -0xc(%ebp),%eax
    4fd1:	89 44 24 04          	mov    %eax,0x4(%esp)
    4fd5:	89 14 24             	mov    %edx,(%esp)
    4fd8:	e8 2d f8 ff ff       	call   480a <ps_cas>

	return 0;
    4fdd:	b8 00 00 00 00       	mov    $0x0,%eax
}
    4fe2:	83 c4 44             	add    $0x44,%esp
    4fe5:	5b                   	pop    %ebx
    4fe6:	5d                   	pop    %ebp
    4fe7:	c3                   	ret    

00004fe8 <__capid_bump_alloc_generic>:

static capid_t
__capid_bump_alloc_generic(struct cos_compinfo *ci, capid_t *capsz_frontier, cap_sz_t sz)
{
    4fe8:	55                   	push   %ebp
    4fe9:	89 e5                	mov    %esp,%ebp
    4feb:	83 ec 28             	sub    $0x28,%esp
	printd("__capid_bump_alloc_generic\n");
	capid_t ret;

	ps_lock_take(&ci->cap_lock);
    4fee:	8b 45 08             	mov    0x8(%ebp),%eax
    4ff1:	83 c0 48             	add    $0x48,%eax
    4ff4:	89 04 24             	mov    %eax,(%esp)
    4ff7:	e8 4d f8 ff ff       	call   4849 <ps_lock_take>
	/*
	 * Do we need a new cache-line in the capability table for
	 * this size of capability?
	 */
	if (*capsz_frontier % CAPMAX_ENTRY_SZ == 0) {
    4ffc:	8b 45 0c             	mov    0xc(%ebp),%eax
    4fff:	8b 00                	mov    (%eax),%eax
    5001:	83 e0 03             	and    $0x3,%eax
    5004:	85 c0                	test   %eax,%eax
    5006:	75 42                	jne    504a <__capid_bump_alloc_generic+0x62>
		if (__capid_captbl_check_expand(ci)) goto error;
    5008:	8b 45 08             	mov    0x8(%ebp),%eax
    500b:	89 04 24             	mov    %eax,(%esp)
    500e:	e8 60 fd ff ff       	call   4d73 <__capid_captbl_check_expand>
    5013:	85 c0                	test   %eax,%eax
    5015:	74 16                	je     502d <__capid_bump_alloc_generic+0x45>
    5017:	90                   	nop
	ret = ps_faa(capsz_frontier, sz);
	ps_lock_release(&ci->cap_lock);

	return ret;
error:
	ps_lock_release(&ci->cap_lock);
    5018:	8b 45 08             	mov    0x8(%ebp),%eax
    501b:	83 c0 48             	add    $0x48,%eax
    501e:	89 04 24             	mov    %eax,(%esp)
    5021:	e8 4b f8 ff ff       	call   4871 <ps_lock_release>

	return 0;
    5026:	b8 00 00 00 00       	mov    $0x0,%eax
    502b:	eb 43                	jmp    5070 <__capid_bump_alloc_generic+0x88>
	 * Do we need a new cache-line in the capability table for
	 * this size of capability?
	 */
	if (*capsz_frontier % CAPMAX_ENTRY_SZ == 0) {
		if (__capid_captbl_check_expand(ci)) goto error;
		*capsz_frontier = ps_faa(&ci->cap_frontier, CAPMAX_ENTRY_SZ);
    502d:	8b 45 08             	mov    0x8(%ebp),%eax
    5030:	83 c0 0c             	add    $0xc,%eax
    5033:	c7 44 24 04 04 00 00 	movl   $0x4,0x4(%esp)
    503a:	00 
    503b:	89 04 24             	mov    %eax,(%esp)
    503e:	e8 ee f7 ff ff       	call   4831 <ps_faa>
    5043:	89 c2                	mov    %eax,%edx
    5045:	8b 45 0c             	mov    0xc(%ebp),%eax
    5048:	89 10                	mov    %edx,(%eax)
	}

	ret = ps_faa(capsz_frontier, sz);
    504a:	8b 45 10             	mov    0x10(%ebp),%eax
    504d:	89 44 24 04          	mov    %eax,0x4(%esp)
    5051:	8b 45 0c             	mov    0xc(%ebp),%eax
    5054:	89 04 24             	mov    %eax,(%esp)
    5057:	e8 d5 f7 ff ff       	call   4831 <ps_faa>
    505c:	89 45 f4             	mov    %eax,-0xc(%ebp)
	ps_lock_release(&ci->cap_lock);
    505f:	8b 45 08             	mov    0x8(%ebp),%eax
    5062:	83 c0 48             	add    $0x48,%eax
    5065:	89 04 24             	mov    %eax,(%esp)
    5068:	e8 04 f8 ff ff       	call   4871 <ps_lock_release>

	return ret;
    506d:	8b 45 f4             	mov    -0xc(%ebp),%eax
error:
	ps_lock_release(&ci->cap_lock);

	return 0;
}
    5070:	c9                   	leave  
    5071:	c3                   	ret    

00005072 <cos_capid_bump_alloc>:

capid_t
cos_capid_bump_alloc(struct cos_compinfo *ci, cap_t cap)
{ return __capid_bump_alloc(ci, cap); }
    5072:	55                   	push   %ebp
    5073:	89 e5                	mov    %esp,%ebp
    5075:	83 ec 18             	sub    $0x18,%esp
    5078:	8b 45 0c             	mov    0xc(%ebp),%eax
    507b:	89 44 24 04          	mov    %eax,0x4(%esp)
    507f:	8b 45 08             	mov    0x8(%ebp),%eax
    5082:	89 04 24             	mov    %eax,(%esp)
    5085:	e8 02 00 00 00       	call   508c <__capid_bump_alloc>
    508a:	c9                   	leave  
    508b:	c3                   	ret    

0000508c <__capid_bump_alloc>:

/* allocate a new capid in the booter. */
static capid_t
__capid_bump_alloc(struct cos_compinfo *ci, cap_t cap)
{
    508c:	55                   	push   %ebp
    508d:	89 e5                	mov    %esp,%ebp
    508f:	83 ec 28             	sub    $0x28,%esp
	unsigned long sz = captbl_idsize(cap);
    5092:	8b 45 0c             	mov    0xc(%ebp),%eax
    5095:	89 04 24             	mov    %eax,(%esp)
    5098:	e8 07 f3 ff ff       	call   43a4 <captbl_idsize>
    509d:	89 45 f0             	mov    %eax,-0x10(%ebp)
	capid_t *     frontier;

	printd("__capid_bump_alloc\n");

	switch (sz) {
    50a0:	8b 45 f0             	mov    -0x10(%ebp),%eax
    50a3:	83 f8 02             	cmp    $0x2,%eax
    50a6:	74 26                	je     50ce <__capid_bump_alloc+0x42>
    50a8:	83 f8 04             	cmp    $0x4,%eax
    50ab:	74 3d                	je     50ea <__capid_bump_alloc+0x5e>
    50ad:	83 f8 01             	cmp    $0x1,%eax
    50b0:	75 43                	jne    50f5 <__capid_bump_alloc+0x69>
	case CAP16B_IDSZ:
		frontier = &ci->cap16_frontier[cos_cpuid()];
    50b2:	e8 4c f5 ff ff       	call   4603 <cos_cpuid>
    50b7:	83 c0 04             	add    $0x4,%eax
    50ba:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    50c1:	8b 45 08             	mov    0x8(%ebp),%eax
    50c4:	01 d0                	add    %edx,%eax
    50c6:	83 c0 04             	add    $0x4,%eax
    50c9:	89 45 f4             	mov    %eax,-0xc(%ebp)
		break;
    50cc:	eb 2e                	jmp    50fc <__capid_bump_alloc+0x70>
	case CAP32B_IDSZ:
		frontier = &ci->cap32_frontier[cos_cpuid()];
    50ce:	e8 30 f5 ff ff       	call   4603 <cos_cpuid>
    50d3:	83 c0 04             	add    $0x4,%eax
    50d6:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    50dd:	8b 45 08             	mov    0x8(%ebp),%eax
    50e0:	01 d0                	add    %edx,%eax
    50e2:	83 c0 08             	add    $0x8,%eax
    50e5:	89 45 f4             	mov    %eax,-0xc(%ebp)
		break;
    50e8:	eb 12                	jmp    50fc <__capid_bump_alloc+0x70>
	case CAP64B_IDSZ:
		frontier = &ci->cap64_frontier;
    50ea:	8b 45 08             	mov    0x8(%ebp),%eax
    50ed:	83 c0 1c             	add    $0x1c,%eax
    50f0:	89 45 f4             	mov    %eax,-0xc(%ebp)
		break;
    50f3:	eb 07                	jmp    50fc <__capid_bump_alloc+0x70>
	default:
		return -1;
    50f5:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
    50fa:	eb 19                	jmp    5115 <__capid_bump_alloc+0x89>
	}
	return __capid_bump_alloc_generic(ci, frontier, sz);
    50fc:	8b 45 f0             	mov    -0x10(%ebp),%eax
    50ff:	89 44 24 08          	mov    %eax,0x8(%esp)
    5103:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5106:	89 44 24 04          	mov    %eax,0x4(%esp)
    510a:	8b 45 08             	mov    0x8(%ebp),%eax
    510d:	89 04 24             	mov    %eax,(%esp)
    5110:	e8 d3 fe ff ff       	call   4fe8 <__capid_bump_alloc_generic>
}
    5115:	c9                   	leave  
    5116:	c3                   	ret    

00005117 <__bump_mem_expand_intern>:

/**************** [User Virtual Memory Allocation Functions] ****************/

static pgtblcap_t
__bump_mem_expand_intern(struct cos_compinfo *ci, pgtblcap_t cipgtbl, vaddr_t mem_ptr, pgtblcap_t intern)
{
    5117:	55                   	push   %ebp
    5118:	89 e5                	mov    %esp,%ebp
    511a:	53                   	push   %ebx
    511b:	83 ec 34             	sub    $0x34,%esp
	struct cos_compinfo *meta = __compinfo_metacap(ci);
    511e:	8b 45 08             	mov    0x8(%ebp),%eax
    5121:	89 04 24             	mov    %eax,(%esp)
    5124:	e8 b8 f7 ff ff       	call   48e1 <__compinfo_metacap>
    5129:	89 45 f0             	mov    %eax,-0x10(%ebp)
	capid_t              pte_cap;
	vaddr_t              ptemem_cap;

	assert(meta == __compinfo_metacap(meta)); /* prevent unbounded structures */
    512c:	8b 45 f0             	mov    -0x10(%ebp),%eax
    512f:	89 04 24             	mov    %eax,(%esp)
    5132:	e8 aa f7 ff ff       	call   48e1 <__compinfo_metacap>
    5137:	3b 45 f0             	cmp    -0x10(%ebp),%eax
    513a:	0f 95 c0             	setne  %al
    513d:	0f b6 c0             	movzbl %al,%eax
    5140:	85 c0                	test   %eax,%eax
    5142:	74 1c                	je     5160 <__bump_mem_expand_intern+0x49>
    5144:	c7 04 24 e8 08 00 00 	movl   $0x8e8,(%esp)
    514b:	e8 2e f6 ff ff       	call   477e <prints>
    5150:	a1 40 00 00 00       	mov    0x40,%eax
    5155:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    515b:	e8 a5 f6 ff ff       	call   4805 <__cos_noret>

	if (!intern) {
    5160:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
    5164:	0f 85 a4 00 00 00    	jne    520e <__bump_mem_expand_intern+0xf7>
		pte_cap    = __capid_bump_alloc(meta, CAP_PGTBL);
    516a:	c7 44 24 04 08 00 00 	movl   $0x8,0x4(%esp)
    5171:	00 
    5172:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5175:	89 04 24             	mov    %eax,(%esp)
    5178:	e8 0f ff ff ff       	call   508c <__capid_bump_alloc>
    517d:	89 45 f4             	mov    %eax,-0xc(%ebp)
		ptemem_cap = __kmem_bump_alloc(meta);
    5180:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5183:	89 04 24             	mov    %eax,(%esp)
    5186:	e8 7f fb ff ff       	call   4d0a <__kmem_bump_alloc>
    518b:	89 45 ec             	mov    %eax,-0x14(%ebp)
		/* TODO: handle the case of running out of memory */
		if (pte_cap == 0 || ptemem_cap == 0) {
    518e:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    5192:	74 06                	je     519a <__bump_mem_expand_intern+0x83>
    5194:	83 7d ec 00          	cmpl   $0x0,-0x14(%ebp)
    5198:	75 1c                	jne    51b6 <__bump_mem_expand_intern+0x9f>
			assert(0);
    519a:	c7 04 24 18 09 00 00 	movl   $0x918,(%esp)
    51a1:	e8 d8 f5 ff ff       	call   477e <prints>
    51a6:	a1 40 00 00 00       	mov    0x40,%eax
    51ab:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    51b1:	e8 4f f6 ff ff       	call   4805 <__cos_noret>
			return 0;
		}

		/* PTE */
		if (call_cap_op(meta->captbl_cap, CAPTBL_OP_PGTBLACTIVATE, pte_cap, meta->mi.pgtbl_cap, ptemem_cap,
    51b6:	8b 5d ec             	mov    -0x14(%ebp),%ebx
    51b9:	8b 45 f0             	mov    -0x10(%ebp),%eax
    51bc:	8b 40 44             	mov    0x44(%eax),%eax
    51bf:	89 c1                	mov    %eax,%ecx
    51c1:	8b 55 f4             	mov    -0xc(%ebp),%edx
    51c4:	8b 45 f0             	mov    -0x10(%ebp),%eax
    51c7:	8b 40 04             	mov    0x4(%eax),%eax
    51ca:	c7 44 24 14 01 00 00 	movl   $0x1,0x14(%esp)
    51d1:	00 
    51d2:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    51d6:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    51da:	89 54 24 08          	mov    %edx,0x8(%esp)
    51de:	c7 44 24 04 15 00 00 	movl   $0x15,0x4(%esp)
    51e5:	00 
    51e6:	89 04 24             	mov    %eax,(%esp)
    51e9:	e8 85 f3 ff ff       	call   4573 <call_cap_op>
    51ee:	85 c0                	test   %eax,%eax
    51f0:	74 22                	je     5214 <__bump_mem_expand_intern+0xfd>
		                1)) {
			assert(0); /* race? */
    51f2:	c7 04 24 48 09 00 00 	movl   $0x948,(%esp)
    51f9:	e8 80 f5 ff ff       	call   477e <prints>
    51fe:	a1 40 00 00 00       	mov    0x40,%eax
    5203:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5209:	e8 f7 f5 ff ff       	call   4805 <__cos_noret>
			return 0;
		}
	} else {
		pte_cap = intern;
    520e:	8b 45 14             	mov    0x14(%ebp),%eax
    5211:	89 45 f4             	mov    %eax,-0xc(%ebp)
	}

	/* Construct pgtbl */
	if (call_cap_op(cipgtbl, CAPTBL_OP_CONS, pte_cap, mem_ptr, 0, 0)) {
    5214:	8b 55 10             	mov    0x10(%ebp),%edx
    5217:	8b 45 f4             	mov    -0xc(%ebp),%eax
    521a:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    5221:	00 
    5222:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    5229:	00 
    522a:	89 54 24 0c          	mov    %edx,0xc(%esp)
    522e:	89 44 24 08          	mov    %eax,0x8(%esp)
    5232:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    5239:	00 
    523a:	8b 45 0c             	mov    0xc(%ebp),%eax
    523d:	89 04 24             	mov    %eax,(%esp)
    5240:	e8 2e f3 ff ff       	call   4573 <call_cap_op>
    5245:	85 c0                	test   %eax,%eax
    5247:	74 1c                	je     5265 <__bump_mem_expand_intern+0x14e>
		assert(0); /* race? */
    5249:	c7 04 24 78 09 00 00 	movl   $0x978,(%esp)
    5250:	e8 29 f5 ff ff       	call   477e <prints>
    5255:	a1 40 00 00 00       	mov    0x40,%eax
    525a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5260:	e8 a0 f5 ff ff       	call   4805 <__cos_noret>
		return 0;
	}

	return pte_cap;
    5265:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    5268:	83 c4 34             	add    $0x34,%esp
    526b:	5b                   	pop    %ebx
    526c:	5d                   	pop    %ebp
    526d:	c3                   	ret    

0000526e <__bump_mem_expand_range>:

static vaddr_t
__bump_mem_expand_range(struct cos_compinfo *ci, pgtblcap_t cipgtbl, vaddr_t mem_ptr, unsigned long mem_sz)
{
    526e:	55                   	push   %ebp
    526f:	89 e5                	mov    %esp,%ebp
    5271:	83 ec 28             	sub    $0x28,%esp
	vaddr_t addr;

	for (addr = mem_ptr; addr < mem_ptr + mem_sz; addr += PGD_RANGE) {
    5274:	8b 45 10             	mov    0x10(%ebp),%eax
    5277:	89 45 f4             	mov    %eax,-0xc(%ebp)
    527a:	eb 28                	jmp    52a4 <__bump_mem_expand_range+0x36>
		/* ignore errors likely due to races here as we want to keep expanding regardless */
		__bump_mem_expand_intern(ci, cipgtbl, addr, 0);
    527c:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    5283:	00 
    5284:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5287:	89 44 24 08          	mov    %eax,0x8(%esp)
    528b:	8b 45 0c             	mov    0xc(%ebp),%eax
    528e:	89 44 24 04          	mov    %eax,0x4(%esp)
    5292:	8b 45 08             	mov    0x8(%ebp),%eax
    5295:	89 04 24             	mov    %eax,(%esp)
    5298:	e8 7a fe ff ff       	call   5117 <__bump_mem_expand_intern>
static vaddr_t
__bump_mem_expand_range(struct cos_compinfo *ci, pgtblcap_t cipgtbl, vaddr_t mem_ptr, unsigned long mem_sz)
{
	vaddr_t addr;

	for (addr = mem_ptr; addr < mem_ptr + mem_sz; addr += PGD_RANGE) {
    529d:	81 45 f4 00 00 40 00 	addl   $0x400000,-0xc(%ebp)
    52a4:	8b 45 14             	mov    0x14(%ebp),%eax
    52a7:	8b 55 10             	mov    0x10(%ebp),%edx
    52aa:	01 d0                	add    %edx,%eax
    52ac:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    52af:	77 cb                	ja     527c <__bump_mem_expand_range+0xe>
		/* ignore errors likely due to races here as we want to keep expanding regardless */
		__bump_mem_expand_intern(ci, cipgtbl, addr, 0);
	}

	assert(round_up_to_pgd_page(addr) == round_up_to_pgd_page(mem_ptr + mem_sz));
    52b1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    52b4:	8d 88 ff ff 3f 00    	lea    0x3fffff(%eax),%ecx
    52ba:	8b 45 14             	mov    0x14(%ebp),%eax
    52bd:	8b 55 10             	mov    0x10(%ebp),%edx
    52c0:	01 d0                	add    %edx,%eax
    52c2:	05 ff ff 3f 00       	add    $0x3fffff,%eax
    52c7:	31 c8                	xor    %ecx,%eax
    52c9:	25 00 00 c0 ff       	and    $0xffc00000,%eax
    52ce:	85 c0                	test   %eax,%eax
    52d0:	0f 95 c0             	setne  %al
    52d3:	0f b6 c0             	movzbl %al,%eax
    52d6:	85 c0                	test   %eax,%eax
    52d8:	74 1c                	je     52f6 <__bump_mem_expand_range+0x88>
    52da:	c7 04 24 a8 09 00 00 	movl   $0x9a8,(%esp)
    52e1:	e8 98 f4 ff ff       	call   477e <prints>
    52e6:	a1 40 00 00 00       	mov    0x40,%eax
    52eb:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    52f1:	e8 0f f5 ff ff       	call   4805 <__cos_noret>

	return mem_ptr;
    52f6:	8b 45 10             	mov    0x10(%ebp),%eax
}
    52f9:	c9                   	leave  
    52fa:	c3                   	ret    

000052fb <cos_pgtbl_intern_alloc>:

vaddr_t
cos_pgtbl_intern_alloc(struct cos_compinfo *ci, pgtblcap_t cipgtbl, vaddr_t mem_ptr, unsigned long mem_sz)
{
    52fb:	55                   	push   %ebp
    52fc:	89 e5                	mov    %esp,%ebp
    52fe:	83 ec 18             	sub    $0x18,%esp
	return __bump_mem_expand_range(ci, cipgtbl, mem_ptr, mem_sz);
    5301:	8b 45 14             	mov    0x14(%ebp),%eax
    5304:	89 44 24 0c          	mov    %eax,0xc(%esp)
    5308:	8b 45 10             	mov    0x10(%ebp),%eax
    530b:	89 44 24 08          	mov    %eax,0x8(%esp)
    530f:	8b 45 0c             	mov    0xc(%ebp),%eax
    5312:	89 44 24 04          	mov    %eax,0x4(%esp)
    5316:	8b 45 08             	mov    0x8(%ebp),%eax
    5319:	89 04 24             	mov    %eax,(%esp)
    531c:	e8 4d ff ff ff       	call   526e <__bump_mem_expand_range>
}
    5321:	c9                   	leave  
    5322:	c3                   	ret    

00005323 <cos_pgtbl_intern_expand>:

pgtblcap_t
cos_pgtbl_intern_expand(struct cos_compinfo *ci, vaddr_t mem_ptr, int lvl)
{
    5323:	55                   	push   %ebp
    5324:	89 e5                	mov    %esp,%ebp
    5326:	83 ec 28             	sub    $0x28,%esp
	pgtblcap_t cap;

	assert(lvl > 0);
    5329:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    532d:	0f 9e c0             	setle  %al
    5330:	0f b6 c0             	movzbl %al,%eax
    5333:	85 c0                	test   %eax,%eax
    5335:	74 1c                	je     5353 <cos_pgtbl_intern_expand+0x30>
    5337:	c7 04 24 d8 09 00 00 	movl   $0x9d8,(%esp)
    533e:	e8 3b f4 ff ff       	call   477e <prints>
    5343:	a1 40 00 00 00       	mov    0x40,%eax
    5348:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    534e:	e8 b2 f4 ff ff       	call   4805 <__cos_noret>

	ps_lock_take(&ci->va_lock);
    5353:	8b 45 08             	mov    0x8(%ebp),%eax
    5356:	83 c0 50             	add    $0x50,%eax
    5359:	89 04 24             	mov    %eax,(%esp)
    535c:	e8 e8 f4 ff ff       	call   4849 <ps_lock_take>
	if (ci->vasrange_frontier != round_to_pgd_page(mem_ptr)) goto error;
    5361:	8b 45 08             	mov    0x8(%ebp),%eax
    5364:	8b 40 24             	mov    0x24(%eax),%eax
    5367:	8b 55 0c             	mov    0xc(%ebp),%edx
    536a:	81 e2 00 00 c0 ff    	and    $0xffc00000,%edx
    5370:	39 d0                	cmp    %edx,%eax
    5372:	74 02                	je     5376 <cos_pgtbl_intern_expand+0x53>
    5374:	eb 7b                	jmp    53f1 <cos_pgtbl_intern_expand+0xce>

	cap = __bump_mem_expand_intern(ci, ci->pgtbl_cap, mem_ptr, 0);
    5376:	8b 45 08             	mov    0x8(%ebp),%eax
    5379:	8b 00                	mov    (%eax),%eax
    537b:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    5382:	00 
    5383:	8b 55 0c             	mov    0xc(%ebp),%edx
    5386:	89 54 24 08          	mov    %edx,0x8(%esp)
    538a:	89 44 24 04          	mov    %eax,0x4(%esp)
    538e:	8b 45 08             	mov    0x8(%ebp),%eax
    5391:	89 04 24             	mov    %eax,(%esp)
    5394:	e8 7e fd ff ff       	call   5117 <__bump_mem_expand_intern>
    5399:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (!cap) goto error;
    539c:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    53a0:	75 02                	jne    53a4 <cos_pgtbl_intern_expand+0x81>
    53a2:	eb 4d                	jmp    53f1 <cos_pgtbl_intern_expand+0xce>

	while (1) {
		vaddr_t tmp = ps_load(&ci->vasrange_frontier);
    53a4:	8b 45 08             	mov    0x8(%ebp),%eax
    53a7:	8b 40 24             	mov    0x24(%eax),%eax
    53aa:	89 45 f0             	mov    %eax,-0x10(%ebp)

		if (tmp >= mem_ptr + PGD_RANGE) break;
    53ad:	8b 45 0c             	mov    0xc(%ebp),%eax
    53b0:	05 00 00 40 00       	add    $0x400000,%eax
    53b5:	3b 45 f0             	cmp    -0x10(%ebp),%eax
    53b8:	77 14                	ja     53ce <cos_pgtbl_intern_expand+0xab>
    53ba:	90                   	nop
		/* If someone else beats us to this, then the range has been extended anyway */
		ps_cas(&ci->vasrange_frontier, tmp, tmp + PGD_RANGE);
	}

	ps_lock_release(&ci->va_lock);
    53bb:	8b 45 08             	mov    0x8(%ebp),%eax
    53be:	83 c0 50             	add    $0x50,%eax
    53c1:	89 04 24             	mov    %eax,(%esp)
    53c4:	e8 a8 f4 ff ff       	call   4871 <ps_lock_release>

	return cap;
    53c9:	8b 45 f4             	mov    -0xc(%ebp),%eax
    53cc:	eb 36                	jmp    5404 <cos_pgtbl_intern_expand+0xe1>
	while (1) {
		vaddr_t tmp = ps_load(&ci->vasrange_frontier);

		if (tmp >= mem_ptr + PGD_RANGE) break;
		/* If someone else beats us to this, then the range has been extended anyway */
		ps_cas(&ci->vasrange_frontier, tmp, tmp + PGD_RANGE);
    53ce:	8b 45 f0             	mov    -0x10(%ebp),%eax
    53d1:	05 00 00 40 00       	add    $0x400000,%eax
    53d6:	8b 55 08             	mov    0x8(%ebp),%edx
    53d9:	83 c2 24             	add    $0x24,%edx
    53dc:	89 44 24 08          	mov    %eax,0x8(%esp)
    53e0:	8b 45 f0             	mov    -0x10(%ebp),%eax
    53e3:	89 44 24 04          	mov    %eax,0x4(%esp)
    53e7:	89 14 24             	mov    %edx,(%esp)
    53ea:	e8 1b f4 ff ff       	call   480a <ps_cas>
	}
    53ef:	eb b3                	jmp    53a4 <cos_pgtbl_intern_expand+0x81>

	ps_lock_release(&ci->va_lock);

	return cap;
error:
	ps_lock_release(&ci->va_lock);
    53f1:	8b 45 08             	mov    0x8(%ebp),%eax
    53f4:	83 c0 50             	add    $0x50,%eax
    53f7:	89 04 24             	mov    %eax,(%esp)
    53fa:	e8 72 f4 ff ff       	call   4871 <ps_lock_release>
	return 0;
    53ff:	b8 00 00 00 00       	mov    $0x0,%eax
}
    5404:	c9                   	leave  
    5405:	c3                   	ret    

00005406 <cos_pgtbl_intern_expandwith>:

int
cos_pgtbl_intern_expandwith(struct cos_compinfo *ci, pgtblcap_t intern, vaddr_t mem)
{
    5406:	55                   	push   %ebp
    5407:	89 e5                	mov    %esp,%ebp
    5409:	83 ec 18             	sub    $0x18,%esp
	ps_lock_take(&ci->va_lock);
    540c:	8b 45 08             	mov    0x8(%ebp),%eax
    540f:	83 c0 50             	add    $0x50,%eax
    5412:	89 04 24             	mov    %eax,(%esp)
    5415:	e8 2f f4 ff ff       	call   4849 <ps_lock_take>
	if (ci->vasrange_frontier != round_to_pgd_page(mem)) goto error;
    541a:	8b 45 08             	mov    0x8(%ebp),%eax
    541d:	8b 40 24             	mov    0x24(%eax),%eax
    5420:	8b 55 10             	mov    0x10(%ebp),%edx
    5423:	81 e2 00 00 c0 ff    	and    $0xffc00000,%edx
    5429:	39 d0                	cmp    %edx,%eax
    542b:	74 05                	je     5432 <cos_pgtbl_intern_expandwith+0x2c>
    542d:	e9 9b 00 00 00       	jmp    54cd <cos_pgtbl_intern_expandwith+0xc7>

	if ((unsigned long)ps_faa(&ci->vasrange_frontier, PGD_RANGE) > round_to_pgd_page(mem)) goto error;
    5432:	8b 45 08             	mov    0x8(%ebp),%eax
    5435:	83 c0 24             	add    $0x24,%eax
    5438:	c7 44 24 04 00 00 40 	movl   $0x400000,0x4(%esp)
    543f:	00 
    5440:	89 04 24             	mov    %eax,(%esp)
    5443:	e8 e9 f3 ff ff       	call   4831 <ps_faa>
    5448:	8b 55 10             	mov    0x10(%ebp),%edx
    544b:	81 e2 00 00 c0 ff    	and    $0xffc00000,%edx
    5451:	39 d0                	cmp    %edx,%eax
    5453:	76 02                	jbe    5457 <cos_pgtbl_intern_expandwith+0x51>
    5455:	eb 76                	jmp    54cd <cos_pgtbl_intern_expandwith+0xc7>
	if ((unsigned long)ps_faa(&ci->vas_frontier, PGD_RANGE) > round_to_pgd_page(mem)) goto error;
    5457:	8b 45 08             	mov    0x8(%ebp),%eax
    545a:	83 c0 20             	add    $0x20,%eax
    545d:	c7 44 24 04 00 00 40 	movl   $0x400000,0x4(%esp)
    5464:	00 
    5465:	89 04 24             	mov    %eax,(%esp)
    5468:	e8 c4 f3 ff ff       	call   4831 <ps_faa>
    546d:	8b 55 10             	mov    0x10(%ebp),%edx
    5470:	81 e2 00 00 c0 ff    	and    $0xffc00000,%edx
    5476:	39 d0                	cmp    %edx,%eax
    5478:	76 02                	jbe    547c <cos_pgtbl_intern_expandwith+0x76>
    547a:	eb 51                	jmp    54cd <cos_pgtbl_intern_expandwith+0xc7>

	if (__bump_mem_expand_intern(ci, ci->pgtbl_cap, mem, intern) != intern) {
    547c:	8b 45 08             	mov    0x8(%ebp),%eax
    547f:	8b 00                	mov    (%eax),%eax
    5481:	8b 55 0c             	mov    0xc(%ebp),%edx
    5484:	89 54 24 0c          	mov    %edx,0xc(%esp)
    5488:	8b 55 10             	mov    0x10(%ebp),%edx
    548b:	89 54 24 08          	mov    %edx,0x8(%esp)
    548f:	89 44 24 04          	mov    %eax,0x4(%esp)
    5493:	8b 45 08             	mov    0x8(%ebp),%eax
    5496:	89 04 24             	mov    %eax,(%esp)
    5499:	e8 79 fc ff ff       	call   5117 <__bump_mem_expand_intern>
    549e:	3b 45 0c             	cmp    0xc(%ebp),%eax
    54a1:	74 15                	je     54b8 <cos_pgtbl_intern_expandwith+0xb2>
		ps_lock_release(&ci->va_lock);
    54a3:	8b 45 08             	mov    0x8(%ebp),%eax
    54a6:	83 c0 50             	add    $0x50,%eax
    54a9:	89 04 24             	mov    %eax,(%esp)
    54ac:	e8 c0 f3 ff ff       	call   4871 <ps_lock_release>
		return 1;
    54b1:	b8 01 00 00 00       	mov    $0x1,%eax
    54b6:	eb 28                	jmp    54e0 <cos_pgtbl_intern_expandwith+0xda>
	}

	ps_lock_release(&ci->va_lock);
    54b8:	8b 45 08             	mov    0x8(%ebp),%eax
    54bb:	83 c0 50             	add    $0x50,%eax
    54be:	89 04 24             	mov    %eax,(%esp)
    54c1:	e8 ab f3 ff ff       	call   4871 <ps_lock_release>
	return 0;
    54c6:	b8 00 00 00 00       	mov    $0x0,%eax
    54cb:	eb 13                	jmp    54e0 <cos_pgtbl_intern_expandwith+0xda>

error:
	ps_lock_release(&ci->va_lock);
    54cd:	8b 45 08             	mov    0x8(%ebp),%eax
    54d0:	83 c0 50             	add    $0x50,%eax
    54d3:	89 04 24             	mov    %eax,(%esp)
    54d6:	e8 96 f3 ff ff       	call   4871 <ps_lock_release>
	return -1;
    54db:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
}
    54e0:	c9                   	leave  
    54e1:	c3                   	ret    

000054e2 <__cos_meminfo_populate>:

static void
__cos_meminfo_populate(struct cos_compinfo *ci, vaddr_t untyped_ptr, unsigned long untyped_sz)
{
    54e2:	55                   	push   %ebp
    54e3:	89 e5                	mov    %esp,%ebp
    54e5:	53                   	push   %ebx
    54e6:	83 ec 34             	sub    $0x34,%esp
	vaddr_t              addr, start_addr, retaddr;
	struct cos_compinfo *meta = __compinfo_metacap(ci);
    54e9:	8b 45 08             	mov    0x8(%ebp),%eax
    54ec:	89 04 24             	mov    %eax,(%esp)
    54ef:	e8 ed f3 ff ff       	call   48e1 <__compinfo_metacap>
    54f4:	89 45 ec             	mov    %eax,-0x14(%ebp)

	assert(untyped_ptr == round_up_to_pgd_page(untyped_ptr));
    54f7:	8b 45 0c             	mov    0xc(%ebp),%eax
    54fa:	05 ff ff 3f 00       	add    $0x3fffff,%eax
    54ff:	25 00 00 c0 ff       	and    $0xffc00000,%eax
    5504:	3b 45 0c             	cmp    0xc(%ebp),%eax
    5507:	0f 95 c0             	setne  %al
    550a:	0f b6 c0             	movzbl %al,%eax
    550d:	85 c0                	test   %eax,%eax
    550f:	74 1c                	je     552d <__cos_meminfo_populate+0x4b>
    5511:	c7 04 24 08 0a 00 00 	movl   $0xa08,(%esp)
    5518:	e8 61 f2 ff ff       	call   477e <prints>
    551d:	a1 40 00 00 00       	mov    0x40,%eax
    5522:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5528:	e8 d8 f2 ff ff       	call   4805 <__cos_noret>
	assert(untyped_sz == round_up_to_pgd_page(untyped_sz));
    552d:	8b 45 10             	mov    0x10(%ebp),%eax
    5530:	05 ff ff 3f 00       	add    $0x3fffff,%eax
    5535:	25 00 00 c0 ff       	and    $0xffc00000,%eax
    553a:	3b 45 10             	cmp    0x10(%ebp),%eax
    553d:	0f 95 c0             	setne  %al
    5540:	0f b6 c0             	movzbl %al,%eax
    5543:	85 c0                	test   %eax,%eax
    5545:	74 1c                	je     5563 <__cos_meminfo_populate+0x81>
    5547:	c7 04 24 38 0a 00 00 	movl   $0xa38,(%esp)
    554e:	e8 2b f2 ff ff       	call   477e <prints>
    5553:	a1 40 00 00 00       	mov    0x40,%eax
    5558:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    555e:	e8 a2 f2 ff ff       	call   4805 <__cos_noret>

	retaddr = __bump_mem_expand_range(ci, ci->mi.pgtbl_cap, untyped_ptr, untyped_sz);
    5563:	8b 45 08             	mov    0x8(%ebp),%eax
    5566:	8b 40 44             	mov    0x44(%eax),%eax
    5569:	8b 55 10             	mov    0x10(%ebp),%edx
    556c:	89 54 24 0c          	mov    %edx,0xc(%esp)
    5570:	8b 55 0c             	mov    0xc(%ebp),%edx
    5573:	89 54 24 08          	mov    %edx,0x8(%esp)
    5577:	89 44 24 04          	mov    %eax,0x4(%esp)
    557b:	8b 45 08             	mov    0x8(%ebp),%eax
    557e:	89 04 24             	mov    %eax,(%esp)
    5581:	e8 e8 fc ff ff       	call   526e <__bump_mem_expand_range>
    5586:	89 45 e8             	mov    %eax,-0x18(%ebp)
	assert(retaddr == untyped_ptr);
    5589:	8b 45 e8             	mov    -0x18(%ebp),%eax
    558c:	3b 45 0c             	cmp    0xc(%ebp),%eax
    558f:	0f 95 c0             	setne  %al
    5592:	0f b6 c0             	movzbl %al,%eax
    5595:	85 c0                	test   %eax,%eax
    5597:	74 1c                	je     55b5 <__cos_meminfo_populate+0xd3>
    5599:	c7 04 24 68 0a 00 00 	movl   $0xa68,(%esp)
    55a0:	e8 d9 f1 ff ff       	call   477e <prints>
    55a5:	a1 40 00 00 00       	mov    0x40,%eax
    55aa:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    55b0:	e8 50 f2 ff ff       	call   4805 <__cos_noret>

	ps_lock_take(&ci->mem_lock);
    55b5:	8b 45 08             	mov    0x8(%ebp),%eax
    55b8:	83 c0 4c             	add    $0x4c,%eax
    55bb:	89 04 24             	mov    %eax,(%esp)
    55be:	e8 86 f2 ff ff       	call   4849 <ps_lock_take>
	/* untyped mem from current bump pointer */
	start_addr = ps_faa(&(meta->mi.untyped_ptr), untyped_sz);
    55c3:	8b 45 10             	mov    0x10(%ebp),%eax
    55c6:	8b 55 ec             	mov    -0x14(%ebp),%edx
    55c9:	83 c2 2c             	add    $0x2c,%edx
    55cc:	89 44 24 04          	mov    %eax,0x4(%esp)
    55d0:	89 14 24             	mov    %edx,(%esp)
    55d3:	e8 59 f2 ff ff       	call   4831 <ps_faa>
    55d8:	89 45 f0             	mov    %eax,-0x10(%ebp)
	ps_faa(&(meta->mi.untyped_frontier), untyped_sz);
    55db:	8b 45 10             	mov    0x10(%ebp),%eax
    55de:	8b 55 ec             	mov    -0x14(%ebp),%edx
    55e1:	83 c2 38             	add    $0x38,%edx
    55e4:	89 44 24 04          	mov    %eax,0x4(%esp)
    55e8:	89 14 24             	mov    %edx,(%esp)
    55eb:	e8 41 f2 ff ff       	call   4831 <ps_faa>
	ps_lock_release(&ci->mem_lock);
    55f0:	8b 45 08             	mov    0x8(%ebp),%eax
    55f3:	83 c0 4c             	add    $0x4c,%eax
    55f6:	89 04 24             	mov    %eax,(%esp)
    55f9:	e8 73 f2 ff ff       	call   4871 <ps_lock_release>

	for (addr = untyped_ptr; addr < untyped_ptr + untyped_sz; addr += PAGE_SIZE, start_addr += PAGE_SIZE) {
    55fe:	8b 45 0c             	mov    0xc(%ebp),%eax
    5601:	89 45 f4             	mov    %eax,-0xc(%ebp)
    5604:	eb 61                	jmp    5667 <__cos_meminfo_populate+0x185>
		if (call_cap_op(meta->mi.pgtbl_cap, CAPTBL_OP_MEMMOVE, start_addr, ci->mi.pgtbl_cap, addr, 0)) BUG();
    5606:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    5609:	8b 45 08             	mov    0x8(%ebp),%eax
    560c:	8b 40 44             	mov    0x44(%eax),%eax
    560f:	89 c1                	mov    %eax,%ecx
    5611:	8b 55 f0             	mov    -0x10(%ebp),%edx
    5614:	8b 45 ec             	mov    -0x14(%ebp),%eax
    5617:	8b 40 44             	mov    0x44(%eax),%eax
    561a:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    5621:	00 
    5622:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    5626:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    562a:	89 54 24 08          	mov    %edx,0x8(%esp)
    562e:	c7 44 24 04 1d 00 00 	movl   $0x1d,0x4(%esp)
    5635:	00 
    5636:	89 04 24             	mov    %eax,(%esp)
    5639:	e8 35 ef ff ff       	call   4573 <call_cap_op>
    563e:	85 c0                	test   %eax,%eax
    5640:	74 17                	je     5659 <__cos_meminfo_populate+0x177>
    5642:	c7 04 24 98 0a 00 00 	movl   $0xa98,(%esp)
    5649:	e8 30 f1 ff ff       	call   477e <prints>
    564e:	a1 40 00 00 00       	mov    0x40,%eax
    5653:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
	/* untyped mem from current bump pointer */
	start_addr = ps_faa(&(meta->mi.untyped_ptr), untyped_sz);
	ps_faa(&(meta->mi.untyped_frontier), untyped_sz);
	ps_lock_release(&ci->mem_lock);

	for (addr = untyped_ptr; addr < untyped_ptr + untyped_sz; addr += PAGE_SIZE, start_addr += PAGE_SIZE) {
    5659:	81 45 f4 00 10 00 00 	addl   $0x1000,-0xc(%ebp)
    5660:	81 45 f0 00 10 00 00 	addl   $0x1000,-0x10(%ebp)
    5667:	8b 45 10             	mov    0x10(%ebp),%eax
    566a:	8b 55 0c             	mov    0xc(%ebp),%edx
    566d:	01 d0                	add    %edx,%eax
    566f:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    5672:	77 92                	ja     5606 <__cos_meminfo_populate+0x124>
		if (call_cap_op(meta->mi.pgtbl_cap, CAPTBL_OP_MEMMOVE, start_addr, ci->mi.pgtbl_cap, addr, 0)) BUG();
	}
}
    5674:	83 c4 34             	add    $0x34,%esp
    5677:	5b                   	pop    %ebx
    5678:	5d                   	pop    %ebp
    5679:	c3                   	ret    

0000567a <cos_meminfo_alloc>:

void
cos_meminfo_alloc(struct cos_compinfo *ci, vaddr_t untyped_ptr, unsigned long untyped_sz)
{
    567a:	55                   	push   %ebp
    567b:	89 e5                	mov    %esp,%ebp
    567d:	83 ec 18             	sub    $0x18,%esp
	__cos_meminfo_populate(ci, untyped_ptr, untyped_sz);
    5680:	8b 45 10             	mov    0x10(%ebp),%eax
    5683:	89 44 24 08          	mov    %eax,0x8(%esp)
    5687:	8b 45 0c             	mov    0xc(%ebp),%eax
    568a:	89 44 24 04          	mov    %eax,0x4(%esp)
    568e:	8b 45 08             	mov    0x8(%ebp),%eax
    5691:	89 04 24             	mov    %eax,(%esp)
    5694:	e8 49 fe ff ff       	call   54e2 <__cos_meminfo_populate>

	ci->mi.untyped_ptr = ci->mi.umem_ptr = ci->mi.kmem_ptr = ci->mi.umem_frontier = ci->mi.kmem_frontier =
    5699:	8b 45 08             	mov    0x8(%ebp),%eax
    569c:	8b 55 0c             	mov    0xc(%ebp),%edx
    569f:	89 50 40             	mov    %edx,0x40(%eax)
    56a2:	8b 45 08             	mov    0x8(%ebp),%eax
    56a5:	8b 50 40             	mov    0x40(%eax),%edx
    56a8:	8b 45 08             	mov    0x8(%ebp),%eax
    56ab:	89 50 3c             	mov    %edx,0x3c(%eax)
    56ae:	8b 45 08             	mov    0x8(%ebp),%eax
    56b1:	8b 50 3c             	mov    0x3c(%eax),%edx
    56b4:	8b 45 08             	mov    0x8(%ebp),%eax
    56b7:	89 50 34             	mov    %edx,0x34(%eax)
    56ba:	8b 45 08             	mov    0x8(%ebp),%eax
    56bd:	8b 50 34             	mov    0x34(%eax),%edx
    56c0:	8b 45 08             	mov    0x8(%ebp),%eax
    56c3:	89 50 30             	mov    %edx,0x30(%eax)
    56c6:	8b 45 08             	mov    0x8(%ebp),%eax
    56c9:	8b 50 30             	mov    0x30(%eax),%edx
    56cc:	8b 45 08             	mov    0x8(%ebp),%eax
    56cf:	89 50 2c             	mov    %edx,0x2c(%eax)
	  untyped_ptr;
	ci->mi.untyped_frontier = untyped_ptr + untyped_sz;
    56d2:	8b 45 10             	mov    0x10(%ebp),%eax
    56d5:	8b 55 0c             	mov    0xc(%ebp),%edx
    56d8:	01 c2                	add    %eax,%edx
    56da:	8b 45 08             	mov    0x8(%ebp),%eax
    56dd:	89 50 38             	mov    %edx,0x38(%eax)
}
    56e0:	c9                   	leave  
    56e1:	c3                   	ret    

000056e2 <__page_bump_mem_alloc>:

static vaddr_t
__page_bump_mem_alloc(struct cos_compinfo *ci, vaddr_t *mem_addr, vaddr_t *mem_frontier, size_t sz)
{
    56e2:	55                   	push   %ebp
    56e3:	89 e5                	mov    %esp,%ebp
    56e5:	83 ec 38             	sub    $0x38,%esp
	vaddr_t              heap_vaddr, retaddr;
	struct cos_compinfo *meta = __compinfo_metacap(ci);
    56e8:	8b 45 08             	mov    0x8(%ebp),%eax
    56eb:	89 04 24             	mov    %eax,(%esp)
    56ee:	e8 ee f1 ff ff       	call   48e1 <__compinfo_metacap>
    56f3:	89 45 f4             	mov    %eax,-0xc(%ebp)
	size_t               rounded;

	printd("__page_bump_alloc\n");

	assert(sz % PAGE_SIZE == 0);
    56f6:	8b 45 14             	mov    0x14(%ebp),%eax
    56f9:	25 ff 0f 00 00       	and    $0xfff,%eax
    56fe:	85 c0                	test   %eax,%eax
    5700:	0f 95 c0             	setne  %al
    5703:	0f b6 c0             	movzbl %al,%eax
    5706:	85 c0                	test   %eax,%eax
    5708:	74 1c                	je     5726 <__page_bump_mem_alloc+0x44>
    570a:	c7 04 24 b8 0a 00 00 	movl   $0xab8,(%esp)
    5711:	e8 68 f0 ff ff       	call   477e <prints>
    5716:	a1 40 00 00 00       	mov    0x40,%eax
    571b:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5721:	e8 df f0 ff ff       	call   4805 <__cos_noret>
	assert(meta == __compinfo_metacap(meta)); /* prevent unbounded structures */
    5726:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5729:	89 04 24             	mov    %eax,(%esp)
    572c:	e8 b0 f1 ff ff       	call   48e1 <__compinfo_metacap>
    5731:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    5734:	0f 95 c0             	setne  %al
    5737:	0f b6 c0             	movzbl %al,%eax
    573a:	85 c0                	test   %eax,%eax
    573c:	74 1c                	je     575a <__page_bump_mem_alloc+0x78>
    573e:	c7 04 24 e8 0a 00 00 	movl   $0xae8,(%esp)
    5745:	e8 34 f0 ff ff       	call   477e <prints>
    574a:	a1 40 00 00 00       	mov    0x40,%eax
    574f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5755:	e8 ab f0 ff ff       	call   4805 <__cos_noret>
	heap_vaddr = ps_faa(mem_addr, sz);        /* allocate our memory addresses */
    575a:	8b 45 14             	mov    0x14(%ebp),%eax
    575d:	89 44 24 04          	mov    %eax,0x4(%esp)
    5761:	8b 45 0c             	mov    0xc(%ebp),%eax
    5764:	89 04 24             	mov    %eax,(%esp)
    5767:	e8 c5 f0 ff ff       	call   4831 <ps_faa>
    576c:	89 45 f0             	mov    %eax,-0x10(%ebp)
	rounded    = sz - (round_up_to_pgd_page(heap_vaddr) - heap_vaddr);
    576f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5772:	05 ff ff 3f 00       	add    $0x3fffff,%eax
    5777:	25 00 00 c0 ff       	and    $0xffc00000,%eax
    577c:	89 c2                	mov    %eax,%edx
    577e:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5781:	29 d0                	sub    %edx,%eax
    5783:	89 c2                	mov    %eax,%edx
    5785:	8b 45 14             	mov    0x14(%ebp),%eax
    5788:	01 d0                	add    %edx,%eax
    578a:	89 45 ec             	mov    %eax,-0x14(%ebp)

	/* Do we not need to allocate PTEs? */
	if (heap_vaddr + sz <= *mem_frontier) return heap_vaddr;
    578d:	8b 45 14             	mov    0x14(%ebp),%eax
    5790:	8b 55 f0             	mov    -0x10(%ebp),%edx
    5793:	01 c2                	add    %eax,%edx
    5795:	8b 45 10             	mov    0x10(%ebp),%eax
    5798:	8b 00                	mov    (%eax),%eax
    579a:	39 c2                	cmp    %eax,%edx
    579c:	77 08                	ja     57a6 <__page_bump_mem_alloc+0xc4>
    579e:	8b 45 f0             	mov    -0x10(%ebp),%eax
    57a1:	e9 9b 00 00 00       	jmp    5841 <__page_bump_mem_alloc+0x15f>

	retaddr = __bump_mem_expand_range(ci, ci->pgtbl_cap, round_up_to_pgd_page(heap_vaddr), rounded);
    57a6:	8b 45 f0             	mov    -0x10(%ebp),%eax
    57a9:	05 ff ff 3f 00       	add    $0x3fffff,%eax
    57ae:	25 00 00 c0 ff       	and    $0xffc00000,%eax
    57b3:	89 c1                	mov    %eax,%ecx
    57b5:	8b 45 08             	mov    0x8(%ebp),%eax
    57b8:	8b 00                	mov    (%eax),%eax
    57ba:	8b 55 ec             	mov    -0x14(%ebp),%edx
    57bd:	89 54 24 0c          	mov    %edx,0xc(%esp)
    57c1:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    57c5:	89 44 24 04          	mov    %eax,0x4(%esp)
    57c9:	8b 45 08             	mov    0x8(%ebp),%eax
    57cc:	89 04 24             	mov    %eax,(%esp)
    57cf:	e8 9a fa ff ff       	call   526e <__bump_mem_expand_range>
    57d4:	89 45 e8             	mov    %eax,-0x18(%ebp)
	assert(retaddr);
    57d7:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
    57db:	0f 94 c0             	sete   %al
    57de:	0f b6 c0             	movzbl %al,%eax
    57e1:	85 c0                	test   %eax,%eax
    57e3:	74 1c                	je     5801 <__page_bump_mem_alloc+0x11f>
    57e5:	c7 04 24 18 0b 00 00 	movl   $0xb18,(%esp)
    57ec:	e8 8d ef ff ff       	call   477e <prints>
    57f1:	a1 40 00 00 00       	mov    0x40,%eax
    57f6:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    57fc:	e8 04 f0 ff ff       	call   4805 <__cos_noret>

	while (1) {
		vaddr_t tmp = ps_load(mem_frontier);
    5801:	8b 45 10             	mov    0x10(%ebp),%eax
    5804:	8b 00                	mov    (%eax),%eax
    5806:	89 45 e4             	mov    %eax,-0x1c(%ebp)

		/* perhaps another thread already advanced the frontier? */
		if (tmp > heap_vaddr) break;
    5809:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    580c:	3b 45 f0             	cmp    -0x10(%ebp),%eax
    580f:	76 06                	jbe    5817 <__page_bump_mem_alloc+0x135>
    5811:	90                   	nop
		/* If this fails, then someone else already expanded for us...win! */
		ps_cas(mem_frontier, tmp, round_up_to_pgd_page(heap_vaddr + sz));
	}

	return heap_vaddr;
    5812:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5815:	eb 2a                	jmp    5841 <__page_bump_mem_alloc+0x15f>
		vaddr_t tmp = ps_load(mem_frontier);

		/* perhaps another thread already advanced the frontier? */
		if (tmp > heap_vaddr) break;
		/* If this fails, then someone else already expanded for us...win! */
		ps_cas(mem_frontier, tmp, round_up_to_pgd_page(heap_vaddr + sz));
    5817:	8b 45 14             	mov    0x14(%ebp),%eax
    581a:	8b 55 f0             	mov    -0x10(%ebp),%edx
    581d:	01 d0                	add    %edx,%eax
    581f:	05 ff ff 3f 00       	add    $0x3fffff,%eax
    5824:	25 00 00 c0 ff       	and    $0xffc00000,%eax
    5829:	89 44 24 08          	mov    %eax,0x8(%esp)
    582d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    5830:	89 44 24 04          	mov    %eax,0x4(%esp)
    5834:	8b 45 10             	mov    0x10(%ebp),%eax
    5837:	89 04 24             	mov    %eax,(%esp)
    583a:	e8 cb ef ff ff       	call   480a <ps_cas>
	}
    583f:	eb c0                	jmp    5801 <__page_bump_mem_alloc+0x11f>

	return heap_vaddr;
}
    5841:	c9                   	leave  
    5842:	c3                   	ret    

00005843 <__page_bump_valloc>:

static vaddr_t
__page_bump_valloc(struct cos_compinfo *ci, size_t sz)
{
    5843:	55                   	push   %ebp
    5844:	89 e5                	mov    %esp,%ebp
    5846:	83 ec 28             	sub    $0x28,%esp
	vaddr_t ret_addr = 0;
    5849:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	ps_lock_take(&ci->va_lock);
    5850:	8b 45 08             	mov    0x8(%ebp),%eax
    5853:	83 c0 50             	add    $0x50,%eax
    5856:	89 04 24             	mov    %eax,(%esp)
    5859:	e8 eb ef ff ff       	call   4849 <ps_lock_take>
	ret_addr = __page_bump_mem_alloc(ci, &ci->vas_frontier, &ci->vasrange_frontier, sz);
    585e:	8b 45 08             	mov    0x8(%ebp),%eax
    5861:	8d 48 24             	lea    0x24(%eax),%ecx
    5864:	8b 45 08             	mov    0x8(%ebp),%eax
    5867:	8d 50 20             	lea    0x20(%eax),%edx
    586a:	8b 45 0c             	mov    0xc(%ebp),%eax
    586d:	89 44 24 0c          	mov    %eax,0xc(%esp)
    5871:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    5875:	89 54 24 04          	mov    %edx,0x4(%esp)
    5879:	8b 45 08             	mov    0x8(%ebp),%eax
    587c:	89 04 24             	mov    %eax,(%esp)
    587f:	e8 5e fe ff ff       	call   56e2 <__page_bump_mem_alloc>
    5884:	89 45 f4             	mov    %eax,-0xc(%ebp)
	ps_lock_release(&ci->va_lock);
    5887:	8b 45 08             	mov    0x8(%ebp),%eax
    588a:	83 c0 50             	add    $0x50,%eax
    588d:	89 04 24             	mov    %eax,(%esp)
    5890:	e8 dc ef ff ff       	call   4871 <ps_lock_release>

	return ret_addr;
    5895:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    5898:	c9                   	leave  
    5899:	c3                   	ret    

0000589a <__page_bump_alloc>:

static vaddr_t
__page_bump_alloc(struct cos_compinfo *ci, size_t sz)
{
    589a:	55                   	push   %ebp
    589b:	89 e5                	mov    %esp,%ebp
    589d:	53                   	push   %ebx
    589e:	83 ec 44             	sub    $0x44,%esp
	struct cos_compinfo *meta = __compinfo_metacap(ci);
    58a1:	8b 45 08             	mov    0x8(%ebp),%eax
    58a4:	89 04 24             	mov    %eax,(%esp)
    58a7:	e8 35 f0 ff ff       	call   48e1 <__compinfo_metacap>
    58ac:	89 45 f0             	mov    %eax,-0x10(%ebp)

	/*
	 * Allocate the virtual address range to map into.  This is
	 * atomic, so we will get a contiguous range of sz.
	 */
	heap_vaddr = __page_bump_valloc(ci, sz);
    58af:	8b 45 0c             	mov    0xc(%ebp),%eax
    58b2:	89 44 24 04          	mov    %eax,0x4(%esp)
    58b6:	8b 45 08             	mov    0x8(%ebp),%eax
    58b9:	89 04 24             	mov    %eax,(%esp)
    58bc:	e8 82 ff ff ff       	call   5843 <__page_bump_valloc>
    58c1:	89 45 ec             	mov    %eax,-0x14(%ebp)
	if (unlikely(!heap_vaddr)) return 0;
    58c4:	83 7d ec 00          	cmpl   $0x0,-0x14(%ebp)
    58c8:	0f 94 c0             	sete   %al
    58cb:	0f b6 c0             	movzbl %al,%eax
    58ce:	85 c0                	test   %eax,%eax
    58d0:	74 0a                	je     58dc <__page_bump_alloc+0x42>
    58d2:	b8 00 00 00 00       	mov    $0x0,%eax
    58d7:	e9 c7 00 00 00       	jmp    59a3 <__page_bump_alloc+0x109>
	heap_limit = heap_vaddr + sz;
    58dc:	8b 45 0c             	mov    0xc(%ebp),%eax
    58df:	8b 55 ec             	mov    -0x14(%ebp),%edx
    58e2:	01 d0                	add    %edx,%eax
    58e4:	89 45 e8             	mov    %eax,-0x18(%ebp)
	assert(heap_limit > heap_vaddr);
    58e7:	8b 45 e8             	mov    -0x18(%ebp),%eax
    58ea:	3b 45 ec             	cmp    -0x14(%ebp),%eax
    58ed:	0f 96 c0             	setbe  %al
    58f0:	0f b6 c0             	movzbl %al,%eax
    58f3:	85 c0                	test   %eax,%eax
    58f5:	74 1c                	je     5913 <__page_bump_alloc+0x79>
    58f7:	c7 04 24 48 0b 00 00 	movl   $0xb48,(%esp)
    58fe:	e8 7b ee ff ff       	call   477e <prints>
    5903:	a1 40 00 00 00       	mov    0x40,%eax
    5908:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    590e:	e8 f2 ee ff ff       	call   4805 <__cos_noret>
	 * ensure that the virtual range is contiguous, but not the
	 * backing memory.  If we require contiguous physical memory,
	 * then this function must be called under mutual exclusion
	 * with all other memory operations.
	 */
	for (heap_cursor = heap_vaddr; heap_cursor < heap_limit; heap_cursor += PAGE_SIZE) {
    5913:	8b 45 ec             	mov    -0x14(%ebp),%eax
    5916:	89 45 f4             	mov    %eax,-0xc(%ebp)
    5919:	eb 79                	jmp    5994 <__page_bump_alloc+0xfa>
		vaddr_t umem;

		umem = __umem_bump_alloc(ci);
    591b:	8b 45 08             	mov    0x8(%ebp),%eax
    591e:	89 04 24             	mov    %eax,(%esp)
    5921:	e8 07 f4 ff ff       	call   4d2d <__umem_bump_alloc>
    5926:	89 45 e4             	mov    %eax,-0x1c(%ebp)
		if (!umem) return 0;
    5929:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    592d:	75 07                	jne    5936 <__page_bump_alloc+0x9c>
    592f:	b8 00 00 00 00       	mov    $0x0,%eax
    5934:	eb 6d                	jmp    59a3 <__page_bump_alloc+0x109>

		/* Actually map in the memory. */
		if (call_cap_op(meta->mi.pgtbl_cap, CAPTBL_OP_MEMACTIVATE, umem, ci->pgtbl_cap, heap_cursor, 0)) {
    5936:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    5939:	8b 45 08             	mov    0x8(%ebp),%eax
    593c:	8b 00                	mov    (%eax),%eax
    593e:	89 c1                	mov    %eax,%ecx
    5940:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    5943:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5946:	8b 40 44             	mov    0x44(%eax),%eax
    5949:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    5950:	00 
    5951:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    5955:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    5959:	89 54 24 08          	mov    %edx,0x8(%esp)
    595d:	c7 44 24 04 10 00 00 	movl   $0x10,0x4(%esp)
    5964:	00 
    5965:	89 04 24             	mov    %eax,(%esp)
    5968:	e8 06 ec ff ff       	call   4573 <call_cap_op>
    596d:	85 c0                	test   %eax,%eax
    596f:	74 1c                	je     598d <__page_bump_alloc+0xf3>
			assert(0);
    5971:	c7 04 24 78 0b 00 00 	movl   $0xb78,(%esp)
    5978:	e8 01 ee ff ff       	call   477e <prints>
    597d:	a1 40 00 00 00       	mov    0x40,%eax
    5982:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5988:	e8 78 ee ff ff       	call   4805 <__cos_noret>
	 * ensure that the virtual range is contiguous, but not the
	 * backing memory.  If we require contiguous physical memory,
	 * then this function must be called under mutual exclusion
	 * with all other memory operations.
	 */
	for (heap_cursor = heap_vaddr; heap_cursor < heap_limit; heap_cursor += PAGE_SIZE) {
    598d:	81 45 f4 00 10 00 00 	addl   $0x1000,-0xc(%ebp)
    5994:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5997:	3b 45 e8             	cmp    -0x18(%ebp),%eax
    599a:	0f 82 7b ff ff ff    	jb     591b <__page_bump_alloc+0x81>
			assert(0);
			return 0;
		}
	}

	return heap_vaddr;
    59a0:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    59a3:	83 c4 44             	add    $0x44,%esp
    59a6:	5b                   	pop    %ebx
    59a7:	5d                   	pop    %ebp
    59a8:	c3                   	ret    

000059a9 <livenessid_bump_alloc>:
 */
CACHE_ALIGNED static u32_t livenessid_frontier = BOOT_LIVENESS_ID_BASE;

static u32_t
livenessid_bump_alloc(void)
{
    59a9:	55                   	push   %ebp
    59aa:	89 e5                	mov    %esp,%ebp
	return livenessid_frontier++;
    59ac:	a1 c0 00 00 00       	mov    0xc0,%eax
    59b1:	8d 50 01             	lea    0x1(%eax),%edx
    59b4:	89 15 c0 00 00 00    	mov    %edx,0xc0
}
    59ba:	5d                   	pop    %ebp
    59bb:	c3                   	ret    

000059bc <__alloc_mem_cap>:

/**************** [Kernel Object Allocation] ****************/

static int
__alloc_mem_cap(struct cos_compinfo *ci, cap_t ct, vaddr_t *kmem, capid_t *cap)
{
    59bc:	55                   	push   %ebp
    59bd:	89 e5                	mov    %esp,%ebp
    59bf:	83 ec 18             	sub    $0x18,%esp
	printd("__alloc_mem_cap\n");

	*kmem = __kmem_bump_alloc(ci);
    59c2:	8b 45 08             	mov    0x8(%ebp),%eax
    59c5:	89 04 24             	mov    %eax,(%esp)
    59c8:	e8 3d f3 ff ff       	call   4d0a <__kmem_bump_alloc>
    59cd:	8b 55 10             	mov    0x10(%ebp),%edx
    59d0:	89 02                	mov    %eax,(%edx)
	if (!*kmem) return -1;
    59d2:	8b 45 10             	mov    0x10(%ebp),%eax
    59d5:	8b 00                	mov    (%eax),%eax
    59d7:	85 c0                	test   %eax,%eax
    59d9:	75 07                	jne    59e2 <__alloc_mem_cap+0x26>
    59db:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
    59e0:	eb 2c                	jmp    5a0e <__alloc_mem_cap+0x52>
	*cap = __capid_bump_alloc(ci, ct);
    59e2:	8b 45 0c             	mov    0xc(%ebp),%eax
    59e5:	89 44 24 04          	mov    %eax,0x4(%esp)
    59e9:	8b 45 08             	mov    0x8(%ebp),%eax
    59ec:	89 04 24             	mov    %eax,(%esp)
    59ef:	e8 98 f6 ff ff       	call   508c <__capid_bump_alloc>
    59f4:	8b 55 14             	mov    0x14(%ebp),%edx
    59f7:	89 02                	mov    %eax,(%edx)
	if (!*cap) return -1;
    59f9:	8b 45 14             	mov    0x14(%ebp),%eax
    59fc:	8b 00                	mov    (%eax),%eax
    59fe:	85 c0                	test   %eax,%eax
    5a00:	75 07                	jne    5a09 <__alloc_mem_cap+0x4d>
    5a02:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
    5a07:	eb 05                	jmp    5a0e <__alloc_mem_cap+0x52>
	return 0;
    5a09:	b8 00 00 00 00       	mov    $0x0,%eax
}
    5a0e:	c9                   	leave  
    5a0f:	c3                   	ret    

00005a10 <__cos_thd_alloc>:

static thdcap_t
__cos_thd_alloc(struct cos_compinfo *ci, compcap_t comp, thdclosure_index_t init_data)
{
    5a10:	55                   	push   %ebp
    5a11:	89 e5                	mov    %esp,%ebp
    5a13:	56                   	push   %esi
    5a14:	53                   	push   %ebx
    5a15:	83 ec 30             	sub    $0x30,%esp
	vaddr_t kmem;
	capid_t cap;

	printd("cos_thd_alloc\n");

	assert(ci && comp > 0);
    5a18:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    5a1c:	0f 94 c0             	sete   %al
    5a1f:	0f b6 c0             	movzbl %al,%eax
    5a22:	85 c0                	test   %eax,%eax
    5a24:	75 0e                	jne    5a34 <__cos_thd_alloc+0x24>
    5a26:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    5a2a:	0f 94 c0             	sete   %al
    5a2d:	0f b6 c0             	movzbl %al,%eax
    5a30:	85 c0                	test   %eax,%eax
    5a32:	74 1c                	je     5a50 <__cos_thd_alloc+0x40>
    5a34:	c7 04 24 a8 0b 00 00 	movl   $0xba8,(%esp)
    5a3b:	e8 3e ed ff ff       	call   477e <prints>
    5a40:	a1 40 00 00 00       	mov    0x40,%eax
    5a45:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5a4b:	e8 b5 ed ff ff       	call   4805 <__cos_noret>

	if (__alloc_mem_cap(ci, CAP_THD, &kmem, &cap)) return 0;
    5a50:	8d 45 f0             	lea    -0x10(%ebp),%eax
    5a53:	89 44 24 0c          	mov    %eax,0xc(%esp)
    5a57:	8d 45 f4             	lea    -0xc(%ebp),%eax
    5a5a:	89 44 24 08          	mov    %eax,0x8(%esp)
    5a5e:	c7 44 24 04 05 00 00 	movl   $0x5,0x4(%esp)
    5a65:	00 
    5a66:	8b 45 08             	mov    0x8(%ebp),%eax
    5a69:	89 04 24             	mov    %eax,(%esp)
    5a6c:	e8 4b ff ff ff       	call   59bc <__alloc_mem_cap>
    5a71:	85 c0                	test   %eax,%eax
    5a73:	74 0a                	je     5a7f <__cos_thd_alloc+0x6f>
    5a75:	b8 00 00 00 00       	mov    $0x0,%eax
    5a7a:	e9 9a 00 00 00       	jmp    5b19 <__cos_thd_alloc+0x109>
	assert(!(init_data & ~((1 << 16) - 1)));
    5a7f:	8b 45 10             	mov    0x10(%ebp),%eax
    5a82:	66 b8 00 00          	mov    $0x0,%ax
    5a86:	85 c0                	test   %eax,%eax
    5a88:	0f 95 c0             	setne  %al
    5a8b:	0f b6 c0             	movzbl %al,%eax
    5a8e:	85 c0                	test   %eax,%eax
    5a90:	74 1c                	je     5aae <__cos_thd_alloc+0x9e>
    5a92:	c7 04 24 d8 0b 00 00 	movl   $0xbd8,(%esp)
    5a99:	e8 e0 ec ff ff       	call   477e <prints>
    5a9e:	a1 40 00 00 00       	mov    0x40,%eax
    5aa3:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5aa9:	e8 57 ed ff ff       	call   4805 <__cos_noret>
	/* TODO: Add cap size checking */
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_THDACTIVATE, (init_data << 16) | cap,
    5aae:	8b 75 0c             	mov    0xc(%ebp),%esi
    5ab1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5ab4:	89 c3                	mov    %eax,%ebx
	                __compinfo_metacap(ci)->mi.pgtbl_cap, kmem, comp))
    5ab6:	8b 45 08             	mov    0x8(%ebp),%eax
    5ab9:	89 04 24             	mov    %eax,(%esp)
    5abc:	e8 20 ee ff ff       	call   48e1 <__compinfo_metacap>
    5ac1:	8b 40 44             	mov    0x44(%eax),%eax
	assert(ci && comp > 0);

	if (__alloc_mem_cap(ci, CAP_THD, &kmem, &cap)) return 0;
	assert(!(init_data & ~((1 << 16) - 1)));
	/* TODO: Add cap size checking */
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_THDACTIVATE, (init_data << 16) | cap,
    5ac4:	89 c1                	mov    %eax,%ecx
    5ac6:	8b 45 10             	mov    0x10(%ebp),%eax
    5ac9:	c1 e0 10             	shl    $0x10,%eax
    5acc:	89 c2                	mov    %eax,%edx
    5ace:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5ad1:	09 d0                	or     %edx,%eax
    5ad3:	89 c2                	mov    %eax,%edx
    5ad5:	8b 45 08             	mov    0x8(%ebp),%eax
    5ad8:	8b 40 04             	mov    0x4(%eax),%eax
    5adb:	89 74 24 14          	mov    %esi,0x14(%esp)
    5adf:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    5ae3:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    5ae7:	89 54 24 08          	mov    %edx,0x8(%esp)
    5aeb:	c7 44 24 04 03 00 00 	movl   $0x3,0x4(%esp)
    5af2:	00 
    5af3:	89 04 24             	mov    %eax,(%esp)
    5af6:	e8 78 ea ff ff       	call   4573 <call_cap_op>
    5afb:	85 c0                	test   %eax,%eax
    5afd:	74 17                	je     5b16 <__cos_thd_alloc+0x106>
	                __compinfo_metacap(ci)->mi.pgtbl_cap, kmem, comp))
		BUG();
    5aff:	c7 04 24 08 0c 00 00 	movl   $0xc08,(%esp)
    5b06:	e8 73 ec ff ff       	call   477e <prints>
    5b0b:	a1 40 00 00 00       	mov    0x40,%eax
    5b10:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    5b16:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    5b19:	83 c4 30             	add    $0x30,%esp
    5b1c:	5b                   	pop    %ebx
    5b1d:	5e                   	pop    %esi
    5b1e:	5d                   	pop    %ebp
    5b1f:	c3                   	ret    

00005b20 <__init_data_alloc>:

extern struct __thd_init_data __thd_init_data[COS_THD_INIT_REGION_SIZE];

static inline thdclosure_index_t
__init_data_alloc(void *fn, void *data)
{
    5b20:	55                   	push   %ebp
    5b21:	89 e5                	mov    %esp,%ebp
    5b23:	83 ec 28             	sub    $0x28,%esp
	int ret, tried = 0;
    5b26:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	thdclosure_index_t i;

	assert(fn);
    5b2d:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    5b31:	0f 94 c0             	sete   %al
    5b34:	0f b6 c0             	movzbl %al,%eax
    5b37:	85 c0                	test   %eax,%eax
    5b39:	74 1c                	je     5b57 <__init_data_alloc+0x37>
    5b3b:	c7 04 24 28 0c 00 00 	movl   $0xc28,(%esp)
    5b42:	e8 37 ec ff ff       	call   477e <prints>
    5b47:	a1 40 00 00 00       	mov    0x40,%eax
    5b4c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5b52:	e8 ae ec ff ff       	call   4805 <__cos_noret>
again:
	for (i = 0; i < COS_THD_INIT_REGION_SIZE; i++) {
    5b57:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
    5b5e:	e9 88 00 00 00       	jmp    5beb <__init_data_alloc+0xcb>
		if (__thd_init_data[i].fn == NULL) {
    5b63:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5b66:	8b 04 c5 00 00 00 00 	mov    0x0(,%eax,8),%eax
    5b6d:	85 c0                	test   %eax,%eax
    5b6f:	75 76                	jne    5be7 <__init_data_alloc+0xc7>
			ret = cos_cas((unsigned long *)&(__thd_init_data[i].fn), (unsigned long)NULL,
    5b71:	8b 45 08             	mov    0x8(%ebp),%eax
    5b74:	8b 55 f0             	mov    -0x10(%ebp),%edx
    5b77:	c1 e2 03             	shl    $0x3,%edx
    5b7a:	81 c2 00 00 00 00    	add    $0x0,%edx
    5b80:	89 44 24 08          	mov    %eax,0x8(%esp)
    5b84:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    5b8b:	00 
    5b8c:	89 14 24             	mov    %edx,(%esp)
    5b8f:	e8 2e e8 ff ff       	call   43c2 <cos_cas>
    5b94:	89 45 ec             	mov    %eax,-0x14(%ebp)
			              (unsigned long)fn);
			if (!ret) continue;
    5b97:	83 7d ec 00          	cmpl   $0x0,-0x14(%ebp)
    5b9b:	75 02                	jne    5b9f <__init_data_alloc+0x7f>
    5b9d:	eb 48                	jmp    5be7 <__init_data_alloc+0xc7>

			assert(__thd_init_data[i].fn == fn);
    5b9f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5ba2:	8b 04 c5 00 00 00 00 	mov    0x0(,%eax,8),%eax
    5ba9:	3b 45 08             	cmp    0x8(%ebp),%eax
    5bac:	0f 95 c0             	setne  %al
    5baf:	0f b6 c0             	movzbl %al,%eax
    5bb2:	85 c0                	test   %eax,%eax
    5bb4:	74 1c                	je     5bd2 <__init_data_alloc+0xb2>
    5bb6:	c7 04 24 88 0c 00 00 	movl   $0xc88,(%esp)
    5bbd:	e8 bc eb ff ff       	call   477e <prints>
    5bc2:	a1 40 00 00 00       	mov    0x40,%eax
    5bc7:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5bcd:	e8 33 ec ff ff       	call   4805 <__cos_noret>
			__thd_init_data[i].data = data;
    5bd2:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5bd5:	8b 55 0c             	mov    0xc(%ebp),%edx
    5bd8:	89 14 c5 04 00 00 00 	mov    %edx,0x4(,%eax,8)
			/* Here we offset the idx by 1 as we use 0 for bootstrap */
			return i + 1;
    5bdf:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5be2:	83 c0 01             	add    $0x1,%eax
    5be5:	eb 55                	jmp    5c3c <__init_data_alloc+0x11c>
	int ret, tried = 0;
	thdclosure_index_t i;

	assert(fn);
again:
	for (i = 0; i < COS_THD_INIT_REGION_SIZE; i++) {
    5be7:	83 45 f0 01          	addl   $0x1,-0x10(%ebp)
    5beb:	81 7d f0 ff 00 00 00 	cmpl   $0xff,-0x10(%ebp)
    5bf2:	0f 8e 6b ff ff ff    	jle    5b63 <__init_data_alloc+0x43>
			return i + 1;
		}
	}

	/* no available entry in the data region. */
	assert(i == COS_THD_INIT_REGION_SIZE);
    5bf8:	81 7d f0 00 01 00 00 	cmpl   $0x100,-0x10(%ebp)
    5bff:	0f 95 c0             	setne  %al
    5c02:	0f b6 c0             	movzbl %al,%eax
    5c05:	85 c0                	test   %eax,%eax
    5c07:	74 1c                	je     5c25 <__init_data_alloc+0x105>
    5c09:	c7 04 24 e8 0c 00 00 	movl   $0xce8,(%esp)
    5c10:	e8 69 eb ff ff       	call   477e <prints>
    5c15:	a1 40 00 00 00       	mov    0x40,%eax
    5c1a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5c20:	e8 e0 eb ff ff       	call   4805 <__cos_noret>
	if (!tried) {
    5c25:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    5c29:	75 0c                	jne    5c37 <__init_data_alloc+0x117>
		/* Try one more time. */
		tried = 1;
    5c2b:	c7 45 f4 01 00 00 00 	movl   $0x1,-0xc(%ebp)
		goto again;
    5c32:	e9 20 ff ff ff       	jmp    5b57 <__init_data_alloc+0x37>
	}
	return -1;
    5c37:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
}
    5c3c:	c9                   	leave  
    5c3d:	c3                   	ret    

00005c3e <__clear_thd_init_data>:

static inline void
__clear_thd_init_data(thdclosure_index_t idx)
{
    5c3e:	55                   	push   %ebp
    5c3f:	89 e5                	mov    %esp,%ebp
    5c41:	83 ec 18             	sub    $0x18,%esp
	assert(idx > 0 && idx <= COS_THD_INIT_REGION_SIZE && __thd_init_data[idx].fn);
    5c44:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    5c48:	0f 9e c0             	setle  %al
    5c4b:	0f b6 c0             	movzbl %al,%eax
    5c4e:	85 c0                	test   %eax,%eax
    5c50:	75 11                	jne    5c63 <__clear_thd_init_data+0x25>
    5c52:	81 7d 08 00 01 00 00 	cmpl   $0x100,0x8(%ebp)
    5c59:	0f 9f c0             	setg   %al
    5c5c:	0f b6 c0             	movzbl %al,%eax
    5c5f:	85 c0                	test   %eax,%eax
    5c61:	74 07                	je     5c6a <__clear_thd_init_data+0x2c>
    5c63:	b8 01 00 00 00       	mov    $0x1,%eax
    5c68:	eb 05                	jmp    5c6f <__clear_thd_init_data+0x31>
    5c6a:	b8 00 00 00 00       	mov    $0x0,%eax
    5c6f:	85 c0                	test   %eax,%eax
    5c71:	75 16                	jne    5c89 <__clear_thd_init_data+0x4b>
    5c73:	8b 45 08             	mov    0x8(%ebp),%eax
    5c76:	8b 04 c5 00 00 00 00 	mov    0x0(,%eax,8),%eax
    5c7d:	85 c0                	test   %eax,%eax
    5c7f:	0f 94 c0             	sete   %al
    5c82:	0f b6 c0             	movzbl %al,%eax
    5c85:	85 c0                	test   %eax,%eax
    5c87:	74 1c                	je     5ca5 <__clear_thd_init_data+0x67>
    5c89:	c7 04 24 48 0d 00 00 	movl   $0xd48,(%esp)
    5c90:	e8 e9 ea ff ff       	call   477e <prints>
    5c95:	a1 40 00 00 00       	mov    0x40,%eax
    5c9a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5ca0:	e8 60 eb ff ff       	call   4805 <__cos_noret>
	idx--; /* See comments in __init_data_alloc*/
    5ca5:	83 6d 08 01          	subl   $0x1,0x8(%ebp)
	__thd_init_data[idx].data = NULL;
    5ca9:	8b 45 08             	mov    0x8(%ebp),%eax
    5cac:	c7 04 c5 04 00 00 00 	movl   $0x0,0x4(,%eax,8)
    5cb3:	00 00 00 00 
	__thd_init_data[idx].fn   = NULL;
    5cb7:	8b 45 08             	mov    0x8(%ebp),%eax
    5cba:	c7 04 c5 00 00 00 00 	movl   $0x0,0x0(,%eax,8)
    5cc1:	00 00 00 00 

	return;
    5cc5:	90                   	nop
}
    5cc6:	c9                   	leave  
    5cc7:	c3                   	ret    

00005cc8 <cos_thd_init_alloc>:

/* See comments of cos_thd_create_remote. */
static thdclosure_index_t
cos_thd_init_alloc(void *fn, void *data)
{
    5cc8:	55                   	push   %ebp
    5cc9:	89 e5                	mov    %esp,%ebp
    5ccb:	83 ec 18             	sub    $0x18,%esp
	if (!fn) return -1;
    5cce:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    5cd2:	75 07                	jne    5cdb <cos_thd_init_alloc+0x13>
    5cd4:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
    5cd9:	eb 12                	jmp    5ced <cos_thd_init_alloc+0x25>
	return __init_data_alloc(fn, data);
    5cdb:	8b 45 0c             	mov    0xc(%ebp),%eax
    5cde:	89 44 24 04          	mov    %eax,0x4(%esp)
    5ce2:	8b 45 08             	mov    0x8(%ebp),%eax
    5ce5:	89 04 24             	mov    %eax,(%esp)
    5ce8:	e8 33 fe ff ff       	call   5b20 <__init_data_alloc>
}
    5ced:	c9                   	leave  
    5cee:	c3                   	ret    

00005cef <cos_thd_init_free>:
 * clear the entry. So this function only needs to be called if the
 * thread creation failed for some reason.
 */
static void
cos_thd_init_free(thdclosure_index_t idx)
{
    5cef:	55                   	push   %ebp
    5cf0:	89 e5                	mov    %esp,%ebp
    5cf2:	83 ec 18             	sub    $0x18,%esp
	if (idx > COS_THD_INIT_REGION_SIZE || idx <= 0 || !__thd_init_data[idx].fn) return;
    5cf5:	81 7d 08 00 01 00 00 	cmpl   $0x100,0x8(%ebp)
    5cfc:	7f 14                	jg     5d12 <cos_thd_init_free+0x23>
    5cfe:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    5d02:	7e 0e                	jle    5d12 <cos_thd_init_free+0x23>
    5d04:	8b 45 08             	mov    0x8(%ebp),%eax
    5d07:	8b 04 c5 00 00 00 00 	mov    0x0(,%eax,8),%eax
    5d0e:	85 c0                	test   %eax,%eax
    5d10:	75 02                	jne    5d14 <cos_thd_init_free+0x25>
    5d12:	eb 0c                	jmp    5d20 <cos_thd_init_free+0x31>

	__clear_thd_init_data(idx);
    5d14:	8b 45 08             	mov    0x8(%ebp),%eax
    5d17:	89 04 24             	mov    %eax,(%esp)
    5d1a:	e8 1f ff ff ff       	call   5c3e <__clear_thd_init_data>

	return;
    5d1f:	90                   	nop
}
    5d20:	c9                   	leave  
    5d21:	c3                   	ret    

00005d22 <cos_thd_alloc_ext>:

#include <cos_thd_init.h>

thdcap_t
cos_thd_alloc_ext(struct cos_compinfo *ci, compcap_t comp, thdclosure_index_t idx)
{
    5d22:	55                   	push   %ebp
    5d23:	89 e5                	mov    %esp,%ebp
    5d25:	83 ec 18             	sub    $0x18,%esp
	if (idx < 1) return 0;
    5d28:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    5d2c:	7f 07                	jg     5d35 <cos_thd_alloc_ext+0x13>
    5d2e:	b8 00 00 00 00       	mov    $0x0,%eax
    5d33:	eb 19                	jmp    5d4e <cos_thd_alloc_ext+0x2c>

	return __cos_thd_alloc(ci, comp, idx);
    5d35:	8b 45 10             	mov    0x10(%ebp),%eax
    5d38:	89 44 24 08          	mov    %eax,0x8(%esp)
    5d3c:	8b 45 0c             	mov    0xc(%ebp),%eax
    5d3f:	89 44 24 04          	mov    %eax,0x4(%esp)
    5d43:	8b 45 08             	mov    0x8(%ebp),%eax
    5d46:	89 04 24             	mov    %eax,(%esp)
    5d49:	e8 c2 fc ff ff       	call   5a10 <__cos_thd_alloc>
}
    5d4e:	c9                   	leave  
    5d4f:	c3                   	ret    

00005d50 <cos_thd_alloc>:

thdcap_t
cos_thd_alloc(struct cos_compinfo *ci, compcap_t comp, cos_thd_fn_t fn, void *data)
{
    5d50:	55                   	push   %ebp
    5d51:	89 e5                	mov    %esp,%ebp
    5d53:	83 ec 28             	sub    $0x28,%esp
	int      idx = cos_thd_init_alloc(fn, data);
    5d56:	8b 45 14             	mov    0x14(%ebp),%eax
    5d59:	89 44 24 04          	mov    %eax,0x4(%esp)
    5d5d:	8b 45 10             	mov    0x10(%ebp),%eax
    5d60:	89 04 24             	mov    %eax,(%esp)
    5d63:	e8 60 ff ff ff       	call   5cc8 <cos_thd_init_alloc>
    5d68:	89 45 f4             	mov    %eax,-0xc(%ebp)
	thdcap_t ret;

	if (idx < 1) return 0;
    5d6b:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    5d6f:	7f 07                	jg     5d78 <cos_thd_alloc+0x28>
    5d71:	b8 00 00 00 00       	mov    $0x0,%eax
    5d76:	eb 30                	jmp    5da8 <cos_thd_alloc+0x58>
	ret = __cos_thd_alloc(ci, comp, idx);
    5d78:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5d7b:	89 44 24 08          	mov    %eax,0x8(%esp)
    5d7f:	8b 45 0c             	mov    0xc(%ebp),%eax
    5d82:	89 44 24 04          	mov    %eax,0x4(%esp)
    5d86:	8b 45 08             	mov    0x8(%ebp),%eax
    5d89:	89 04 24             	mov    %eax,(%esp)
    5d8c:	e8 7f fc ff ff       	call   5a10 <__cos_thd_alloc>
    5d91:	89 45 f0             	mov    %eax,-0x10(%ebp)
	if (!ret) cos_thd_init_free(idx);
    5d94:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    5d98:	75 0b                	jne    5da5 <cos_thd_alloc+0x55>
    5d9a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5d9d:	89 04 24             	mov    %eax,(%esp)
    5da0:	e8 4a ff ff ff       	call   5cef <cos_thd_init_free>

	return ret;
    5da5:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    5da8:	c9                   	leave  
    5da9:	c3                   	ret    

00005daa <cos_initthd_alloc>:

thdcap_t
cos_initthd_alloc(struct cos_compinfo *ci, compcap_t comp)
{
    5daa:	55                   	push   %ebp
    5dab:	89 e5                	mov    %esp,%ebp
    5dad:	83 ec 18             	sub    $0x18,%esp
	return __cos_thd_alloc(ci, comp, 0);
    5db0:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    5db7:	00 
    5db8:	8b 45 0c             	mov    0xc(%ebp),%eax
    5dbb:	89 44 24 04          	mov    %eax,0x4(%esp)
    5dbf:	8b 45 08             	mov    0x8(%ebp),%eax
    5dc2:	89 04 24             	mov    %eax,(%esp)
    5dc5:	e8 46 fc ff ff       	call   5a10 <__cos_thd_alloc>
}
    5dca:	c9                   	leave  
    5dcb:	c3                   	ret    

00005dcc <cos_captbl_alloc>:

captblcap_t
cos_captbl_alloc(struct cos_compinfo *ci)
{
    5dcc:	55                   	push   %ebp
    5dcd:	89 e5                	mov    %esp,%ebp
    5dcf:	53                   	push   %ebx
    5dd0:	83 ec 34             	sub    $0x34,%esp
	vaddr_t kmem;
	capid_t cap;

	printd("cos_captbl_alloc\n");

	assert(ci);
    5dd3:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    5dd7:	0f 94 c0             	sete   %al
    5dda:	0f b6 c0             	movzbl %al,%eax
    5ddd:	85 c0                	test   %eax,%eax
    5ddf:	74 1c                	je     5dfd <cos_captbl_alloc+0x31>
    5de1:	c7 04 24 a8 0d 00 00 	movl   $0xda8,(%esp)
    5de8:	e8 91 e9 ff ff       	call   477e <prints>
    5ded:	a1 40 00 00 00       	mov    0x40,%eax
    5df2:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5df8:	e8 08 ea ff ff       	call   4805 <__cos_noret>

	if (__alloc_mem_cap(ci, CAP_CAPTBL, &kmem, &cap)) return 0;
    5dfd:	8d 45 f0             	lea    -0x10(%ebp),%eax
    5e00:	89 44 24 0c          	mov    %eax,0xc(%esp)
    5e04:	8d 45 f4             	lea    -0xc(%ebp),%eax
    5e07:	89 44 24 08          	mov    %eax,0x8(%esp)
    5e0b:	c7 44 24 04 07 00 00 	movl   $0x7,0x4(%esp)
    5e12:	00 
    5e13:	8b 45 08             	mov    0x8(%ebp),%eax
    5e16:	89 04 24             	mov    %eax,(%esp)
    5e19:	e8 9e fb ff ff       	call   59bc <__alloc_mem_cap>
    5e1e:	85 c0                	test   %eax,%eax
    5e20:	74 07                	je     5e29 <cos_captbl_alloc+0x5d>
    5e22:	b8 00 00 00 00       	mov    $0x0,%eax
    5e27:	eb 62                	jmp    5e8b <cos_captbl_alloc+0xbf>
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_CAPTBLACTIVATE, cap, __compinfo_metacap(ci)->mi.pgtbl_cap, kmem, 0))
    5e29:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5e2c:	89 c3                	mov    %eax,%ebx
    5e2e:	8b 45 08             	mov    0x8(%ebp),%eax
    5e31:	89 04 24             	mov    %eax,(%esp)
    5e34:	e8 a8 ea ff ff       	call   48e1 <__compinfo_metacap>
    5e39:	8b 40 44             	mov    0x44(%eax),%eax
    5e3c:	89 c1                	mov    %eax,%ecx
    5e3e:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5e41:	89 c2                	mov    %eax,%edx
    5e43:	8b 45 08             	mov    0x8(%ebp),%eax
    5e46:	8b 40 04             	mov    0x4(%eax),%eax
    5e49:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    5e50:	00 
    5e51:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    5e55:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    5e59:	89 54 24 08          	mov    %edx,0x8(%esp)
    5e5d:	c7 44 24 04 17 00 00 	movl   $0x17,0x4(%esp)
    5e64:	00 
    5e65:	89 04 24             	mov    %eax,(%esp)
    5e68:	e8 06 e7 ff ff       	call   4573 <call_cap_op>
    5e6d:	85 c0                	test   %eax,%eax
    5e6f:	74 17                	je     5e88 <cos_captbl_alloc+0xbc>
		BUG();
    5e71:	c7 04 24 d8 0d 00 00 	movl   $0xdd8,(%esp)
    5e78:	e8 01 e9 ff ff       	call   477e <prints>
    5e7d:	a1 40 00 00 00       	mov    0x40,%eax
    5e82:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    5e88:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    5e8b:	83 c4 34             	add    $0x34,%esp
    5e8e:	5b                   	pop    %ebx
    5e8f:	5d                   	pop    %ebp
    5e90:	c3                   	ret    

00005e91 <cos_pgtbl_alloc>:

pgtblcap_t
cos_pgtbl_alloc(struct cos_compinfo *ci)
{
    5e91:	55                   	push   %ebp
    5e92:	89 e5                	mov    %esp,%ebp
    5e94:	53                   	push   %ebx
    5e95:	83 ec 34             	sub    $0x34,%esp
	vaddr_t kmem;
	capid_t cap;

	printd("cos_pgtbl_alloc\n");

	assert(ci);
    5e98:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    5e9c:	0f 94 c0             	sete   %al
    5e9f:	0f b6 c0             	movzbl %al,%eax
    5ea2:	85 c0                	test   %eax,%eax
    5ea4:	74 1c                	je     5ec2 <cos_pgtbl_alloc+0x31>
    5ea6:	c7 04 24 f8 0d 00 00 	movl   $0xdf8,(%esp)
    5ead:	e8 cc e8 ff ff       	call   477e <prints>
    5eb2:	a1 40 00 00 00       	mov    0x40,%eax
    5eb7:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5ebd:	e8 43 e9 ff ff       	call   4805 <__cos_noret>

	if (__alloc_mem_cap(ci, CAP_PGTBL, &kmem, &cap)) return 0;
    5ec2:	8d 45 f0             	lea    -0x10(%ebp),%eax
    5ec5:	89 44 24 0c          	mov    %eax,0xc(%esp)
    5ec9:	8d 45 f4             	lea    -0xc(%ebp),%eax
    5ecc:	89 44 24 08          	mov    %eax,0x8(%esp)
    5ed0:	c7 44 24 04 08 00 00 	movl   $0x8,0x4(%esp)
    5ed7:	00 
    5ed8:	8b 45 08             	mov    0x8(%ebp),%eax
    5edb:	89 04 24             	mov    %eax,(%esp)
    5ede:	e8 d9 fa ff ff       	call   59bc <__alloc_mem_cap>
    5ee3:	85 c0                	test   %eax,%eax
    5ee5:	74 07                	je     5eee <cos_pgtbl_alloc+0x5d>
    5ee7:	b8 00 00 00 00       	mov    $0x0,%eax
    5eec:	eb 62                	jmp    5f50 <cos_pgtbl_alloc+0xbf>
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_PGTBLACTIVATE, cap, __compinfo_metacap(ci)->mi.pgtbl_cap, kmem, 0))
    5eee:	8b 45 f4             	mov    -0xc(%ebp),%eax
    5ef1:	89 c3                	mov    %eax,%ebx
    5ef3:	8b 45 08             	mov    0x8(%ebp),%eax
    5ef6:	89 04 24             	mov    %eax,(%esp)
    5ef9:	e8 e3 e9 ff ff       	call   48e1 <__compinfo_metacap>
    5efe:	8b 40 44             	mov    0x44(%eax),%eax
    5f01:	89 c1                	mov    %eax,%ecx
    5f03:	8b 45 f0             	mov    -0x10(%ebp),%eax
    5f06:	89 c2                	mov    %eax,%edx
    5f08:	8b 45 08             	mov    0x8(%ebp),%eax
    5f0b:	8b 40 04             	mov    0x4(%eax),%eax
    5f0e:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    5f15:	00 
    5f16:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    5f1a:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    5f1e:	89 54 24 08          	mov    %edx,0x8(%esp)
    5f22:	c7 44 24 04 15 00 00 	movl   $0x15,0x4(%esp)
    5f29:	00 
    5f2a:	89 04 24             	mov    %eax,(%esp)
    5f2d:	e8 41 e6 ff ff       	call   4573 <call_cap_op>
    5f32:	85 c0                	test   %eax,%eax
    5f34:	74 17                	je     5f4d <cos_pgtbl_alloc+0xbc>
		BUG();
    5f36:	c7 04 24 28 0e 00 00 	movl   $0xe28,(%esp)
    5f3d:	e8 3c e8 ff ff       	call   477e <prints>
    5f42:	a1 40 00 00 00       	mov    0x40,%eax
    5f47:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    5f4d:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    5f50:	83 c4 34             	add    $0x34,%esp
    5f53:	5b                   	pop    %ebx
    5f54:	5d                   	pop    %ebp
    5f55:	c3                   	ret    

00005f56 <cos_comp_alloc>:

compcap_t
cos_comp_alloc(struct cos_compinfo *ci, captblcap_t ctc, pgtblcap_t ptc, vaddr_t entry)
{
    5f56:	55                   	push   %ebp
    5f57:	89 e5                	mov    %esp,%ebp
    5f59:	56                   	push   %esi
    5f5a:	53                   	push   %ebx
    5f5b:	83 ec 30             	sub    $0x30,%esp
	capid_t cap;
	u32_t   lid = livenessid_bump_alloc();
    5f5e:	e8 46 fa ff ff       	call   59a9 <livenessid_bump_alloc>
    5f63:	89 45 f4             	mov    %eax,-0xc(%ebp)

	printd("cos_comp_alloc\n");

	assert(ci && ctc && ptc && lid);
    5f66:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    5f6a:	0f 94 c0             	sete   %al
    5f6d:	0f b6 c0             	movzbl %al,%eax
    5f70:	85 c0                	test   %eax,%eax
    5f72:	75 0e                	jne    5f82 <cos_comp_alloc+0x2c>
    5f74:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    5f78:	0f 94 c0             	sete   %al
    5f7b:	0f b6 c0             	movzbl %al,%eax
    5f7e:	85 c0                	test   %eax,%eax
    5f80:	74 07                	je     5f89 <cos_comp_alloc+0x33>
    5f82:	b8 01 00 00 00       	mov    $0x1,%eax
    5f87:	eb 05                	jmp    5f8e <cos_comp_alloc+0x38>
    5f89:	b8 00 00 00 00       	mov    $0x0,%eax
    5f8e:	85 c0                	test   %eax,%eax
    5f90:	75 0e                	jne    5fa0 <cos_comp_alloc+0x4a>
    5f92:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    5f96:	0f 94 c0             	sete   %al
    5f99:	0f b6 c0             	movzbl %al,%eax
    5f9c:	85 c0                	test   %eax,%eax
    5f9e:	74 07                	je     5fa7 <cos_comp_alloc+0x51>
    5fa0:	b8 01 00 00 00       	mov    $0x1,%eax
    5fa5:	eb 05                	jmp    5fac <cos_comp_alloc+0x56>
    5fa7:	b8 00 00 00 00       	mov    $0x0,%eax
    5fac:	85 c0                	test   %eax,%eax
    5fae:	75 0e                	jne    5fbe <cos_comp_alloc+0x68>
    5fb0:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    5fb4:	0f 94 c0             	sete   %al
    5fb7:	0f b6 c0             	movzbl %al,%eax
    5fba:	85 c0                	test   %eax,%eax
    5fbc:	74 1c                	je     5fda <cos_comp_alloc+0x84>
    5fbe:	c7 04 24 48 0e 00 00 	movl   $0xe48,(%esp)
    5fc5:	e8 b4 e7 ff ff       	call   477e <prints>
    5fca:	a1 40 00 00 00       	mov    0x40,%eax
    5fcf:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    5fd5:	e8 2b e8 ff ff       	call   4805 <__cos_noret>

	cap = __capid_bump_alloc(ci, CAP_COMP);
    5fda:	c7 44 24 04 06 00 00 	movl   $0x6,0x4(%esp)
    5fe1:	00 
    5fe2:	8b 45 08             	mov    0x8(%ebp),%eax
    5fe5:	89 04 24             	mov    %eax,(%esp)
    5fe8:	e8 9f f0 ff ff       	call   508c <__capid_bump_alloc>
    5fed:	89 45 f0             	mov    %eax,-0x10(%ebp)
	if (!cap) return 0;
    5ff0:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    5ff4:	75 07                	jne    5ffd <cos_comp_alloc+0xa7>
    5ff6:	b8 00 00 00 00       	mov    $0x0,%eax
    5ffb:	eb 58                	jmp    6055 <cos_comp_alloc+0xff>
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_COMPACTIVATE, cap, (ctc << 16) | ptc, lid, entry)) BUG();
    5ffd:	8b 75 14             	mov    0x14(%ebp),%esi
    6000:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    6003:	8b 45 0c             	mov    0xc(%ebp),%eax
    6006:	c1 e0 10             	shl    $0x10,%eax
    6009:	0b 45 10             	or     0x10(%ebp),%eax
    600c:	89 c1                	mov    %eax,%ecx
    600e:	8b 55 f0             	mov    -0x10(%ebp),%edx
    6011:	8b 45 08             	mov    0x8(%ebp),%eax
    6014:	8b 40 04             	mov    0x4(%eax),%eax
    6017:	89 74 24 14          	mov    %esi,0x14(%esp)
    601b:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    601f:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6023:	89 54 24 08          	mov    %edx,0x8(%esp)
    6027:	c7 44 24 04 06 00 00 	movl   $0x6,0x4(%esp)
    602e:	00 
    602f:	89 04 24             	mov    %eax,(%esp)
    6032:	e8 3c e5 ff ff       	call   4573 <call_cap_op>
    6037:	85 c0                	test   %eax,%eax
    6039:	74 17                	je     6052 <cos_comp_alloc+0xfc>
    603b:	c7 04 24 78 0e 00 00 	movl   $0xe78,(%esp)
    6042:	e8 37 e7 ff ff       	call   477e <prints>
    6047:	a1 40 00 00 00       	mov    0x40,%eax
    604c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    6052:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    6055:	83 c4 30             	add    $0x30,%esp
    6058:	5b                   	pop    %ebx
    6059:	5e                   	pop    %esi
    605a:	5d                   	pop    %ebp
    605b:	c3                   	ret    

0000605c <cos_compinfo_alloc>:

int
cos_compinfo_alloc(struct cos_compinfo *ci, vaddr_t heap_ptr, capid_t cap_frontier, vaddr_t entry,
                   struct cos_compinfo *ci_resources)
{
    605c:	55                   	push   %ebp
    605d:	89 e5                	mov    %esp,%ebp
    605f:	83 ec 38             	sub    $0x38,%esp
	captblcap_t ctc;
	compcap_t   compc;

	printd("cos_compinfo_alloc\n");

	ptc = cos_pgtbl_alloc(ci_resources);
    6062:	8b 45 18             	mov    0x18(%ebp),%eax
    6065:	89 04 24             	mov    %eax,(%esp)
    6068:	e8 fc ff ff ff       	call   6069 <cos_compinfo_alloc+0xd>
    606d:	89 45 f4             	mov    %eax,-0xc(%ebp)
	assert(ptc);
    6070:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    6074:	0f 94 c0             	sete   %al
    6077:	0f b6 c0             	movzbl %al,%eax
    607a:	85 c0                	test   %eax,%eax
    607c:	74 1c                	je     609a <cos_compinfo_alloc+0x3e>
    607e:	c7 04 24 98 0e 00 00 	movl   $0xe98,(%esp)
    6085:	e8 f4 e6 ff ff       	call   477e <prints>
    608a:	a1 40 00 00 00       	mov    0x40,%eax
    608f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6095:	e8 6b e7 ff ff       	call   4805 <__cos_noret>
	ctc = cos_captbl_alloc(ci_resources);
    609a:	8b 45 18             	mov    0x18(%ebp),%eax
    609d:	89 04 24             	mov    %eax,(%esp)
    60a0:	e8 fc ff ff ff       	call   60a1 <cos_compinfo_alloc+0x45>
    60a5:	89 45 f0             	mov    %eax,-0x10(%ebp)
	assert(ctc);
    60a8:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    60ac:	0f 94 c0             	sete   %al
    60af:	0f b6 c0             	movzbl %al,%eax
    60b2:	85 c0                	test   %eax,%eax
    60b4:	74 1c                	je     60d2 <cos_compinfo_alloc+0x76>
    60b6:	c7 04 24 c8 0e 00 00 	movl   $0xec8,(%esp)
    60bd:	e8 bc e6 ff ff       	call   477e <prints>
    60c2:	a1 40 00 00 00       	mov    0x40,%eax
    60c7:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    60cd:	e8 33 e7 ff ff       	call   4805 <__cos_noret>
	compc = cos_comp_alloc(ci_resources, ctc, ptc, entry);
    60d2:	8b 45 14             	mov    0x14(%ebp),%eax
    60d5:	89 44 24 0c          	mov    %eax,0xc(%esp)
    60d9:	8b 45 f4             	mov    -0xc(%ebp),%eax
    60dc:	89 44 24 08          	mov    %eax,0x8(%esp)
    60e0:	8b 45 f0             	mov    -0x10(%ebp),%eax
    60e3:	89 44 24 04          	mov    %eax,0x4(%esp)
    60e7:	8b 45 18             	mov    0x18(%ebp),%eax
    60ea:	89 04 24             	mov    %eax,(%esp)
    60ed:	e8 fc ff ff ff       	call   60ee <cos_compinfo_alloc+0x92>
    60f2:	89 45 ec             	mov    %eax,-0x14(%ebp)
	assert(compc);
    60f5:	83 7d ec 00          	cmpl   $0x0,-0x14(%ebp)
    60f9:	0f 94 c0             	sete   %al
    60fc:	0f b6 c0             	movzbl %al,%eax
    60ff:	85 c0                	test   %eax,%eax
    6101:	74 1c                	je     611f <cos_compinfo_alloc+0xc3>
    6103:	c7 04 24 f8 0e 00 00 	movl   $0xef8,(%esp)
    610a:	e8 6f e6 ff ff       	call   477e <prints>
    610f:	a1 40 00 00 00       	mov    0x40,%eax
    6114:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    611a:	e8 e6 e6 ff ff       	call   4805 <__cos_noret>

	cos_compinfo_init(ci, ptc, ctc, compc, heap_ptr, cap_frontier, ci_resources);
    611f:	8b 45 18             	mov    0x18(%ebp),%eax
    6122:	89 44 24 18          	mov    %eax,0x18(%esp)
    6126:	8b 45 10             	mov    0x10(%ebp),%eax
    6129:	89 44 24 14          	mov    %eax,0x14(%esp)
    612d:	8b 45 0c             	mov    0xc(%ebp),%eax
    6130:	89 44 24 10          	mov    %eax,0x10(%esp)
    6134:	8b 45 ec             	mov    -0x14(%ebp),%eax
    6137:	89 44 24 0c          	mov    %eax,0xc(%esp)
    613b:	8b 45 f0             	mov    -0x10(%ebp),%eax
    613e:	89 44 24 08          	mov    %eax,0x8(%esp)
    6142:	8b 45 f4             	mov    -0xc(%ebp),%eax
    6145:	89 44 24 04          	mov    %eax,0x4(%esp)
    6149:	8b 45 08             	mov    0x8(%ebp),%eax
    614c:	89 04 24             	mov    %eax,(%esp)
    614f:	e8 fc ff ff ff       	call   6150 <cos_compinfo_alloc+0xf4>

	return 0;
    6154:	b8 00 00 00 00       	mov    $0x0,%eax
}
    6159:	c9                   	leave  
    615a:	c3                   	ret    

0000615b <cos_sinv_alloc>:

sinvcap_t
cos_sinv_alloc(struct cos_compinfo *srcci, compcap_t dstcomp, vaddr_t entry, invtoken_t token)
{
    615b:	55                   	push   %ebp
    615c:	89 e5                	mov    %esp,%ebp
    615e:	56                   	push   %esi
    615f:	53                   	push   %ebx
    6160:	83 ec 30             	sub    $0x30,%esp
	capid_t cap;

	printd("cos_sinv_alloc\n");

	assert(srcci && dstcomp);
    6163:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    6167:	0f 94 c0             	sete   %al
    616a:	0f b6 c0             	movzbl %al,%eax
    616d:	85 c0                	test   %eax,%eax
    616f:	75 0e                	jne    617f <cos_sinv_alloc+0x24>
    6171:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    6175:	0f 94 c0             	sete   %al
    6178:	0f b6 c0             	movzbl %al,%eax
    617b:	85 c0                	test   %eax,%eax
    617d:	74 1c                	je     619b <cos_sinv_alloc+0x40>
    617f:	c7 04 24 28 0f 00 00 	movl   $0xf28,(%esp)
    6186:	e8 f3 e5 ff ff       	call   477e <prints>
    618b:	a1 40 00 00 00       	mov    0x40,%eax
    6190:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6196:	e8 6a e6 ff ff       	call   4805 <__cos_noret>

	cap = __capid_bump_alloc(srcci, CAP_COMP);
    619b:	c7 44 24 04 06 00 00 	movl   $0x6,0x4(%esp)
    61a2:	00 
    61a3:	8b 45 08             	mov    0x8(%ebp),%eax
    61a6:	89 04 24             	mov    %eax,(%esp)
    61a9:	e8 de ee ff ff       	call   508c <__capid_bump_alloc>
    61ae:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (!cap) return 0;
    61b1:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    61b5:	75 07                	jne    61be <cos_sinv_alloc+0x63>
    61b7:	b8 00 00 00 00       	mov    $0x0,%eax
    61bc:	eb 50                	jmp    620e <cos_sinv_alloc+0xb3>
	if (call_cap_op(srcci->captbl_cap, CAPTBL_OP_SINVACTIVATE, cap, dstcomp, entry, token)) BUG();
    61be:	8b 75 14             	mov    0x14(%ebp),%esi
    61c1:	8b 5d 10             	mov    0x10(%ebp),%ebx
    61c4:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    61c7:	8b 55 f4             	mov    -0xc(%ebp),%edx
    61ca:	8b 45 08             	mov    0x8(%ebp),%eax
    61cd:	8b 40 04             	mov    0x4(%eax),%eax
    61d0:	89 74 24 14          	mov    %esi,0x14(%esp)
    61d4:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    61d8:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    61dc:	89 54 24 08          	mov    %edx,0x8(%esp)
    61e0:	c7 44 24 04 08 00 00 	movl   $0x8,0x4(%esp)
    61e7:	00 
    61e8:	89 04 24             	mov    %eax,(%esp)
    61eb:	e8 83 e3 ff ff       	call   4573 <call_cap_op>
    61f0:	85 c0                	test   %eax,%eax
    61f2:	74 17                	je     620b <cos_sinv_alloc+0xb0>
    61f4:	c7 04 24 58 0f 00 00 	movl   $0xf58,(%esp)
    61fb:	e8 7e e5 ff ff       	call   477e <prints>
    6200:	a1 40 00 00 00       	mov    0x40,%eax
    6205:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    620b:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    620e:	83 c4 30             	add    $0x30,%esp
    6211:	5b                   	pop    %ebx
    6212:	5e                   	pop    %esi
    6213:	5d                   	pop    %ebp
    6214:	c3                   	ret    

00006215 <cos_sinv>:

int
cos_sinv(sinvcap_t sinv, word_t arg1, word_t arg2, word_t arg3, word_t arg4)
{
    6215:	55                   	push   %ebp
    6216:	89 e5                	mov    %esp,%ebp
    6218:	53                   	push   %ebx
    6219:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(sinv, 0, arg1, arg2, arg3, arg4);
    621c:	8b 5d 18             	mov    0x18(%ebp),%ebx
    621f:	8b 4d 14             	mov    0x14(%ebp),%ecx
    6222:	8b 55 10             	mov    0x10(%ebp),%edx
    6225:	8b 45 0c             	mov    0xc(%ebp),%eax
    6228:	89 5c 24 14          	mov    %ebx,0x14(%esp)
    622c:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    6230:	89 54 24 0c          	mov    %edx,0xc(%esp)
    6234:	89 44 24 08          	mov    %eax,0x8(%esp)
    6238:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    623f:	00 
    6240:	8b 45 08             	mov    0x8(%ebp),%eax
    6243:	89 04 24             	mov    %eax,(%esp)
    6246:	e8 28 e3 ff ff       	call   4573 <call_cap_op>
}
    624b:	83 c4 18             	add    $0x18,%esp
    624e:	5b                   	pop    %ebx
    624f:	5d                   	pop    %ebp
    6250:	c3                   	ret    

00006251 <cos_sinv_rets>:

int
cos_sinv_rets(sinvcap_t sinv, word_t arg1, word_t arg2, word_t arg3, word_t arg4, word_t *ret2, word_t *ret3)
{
    6251:	55                   	push   %ebp
    6252:	89 e5                	mov    %esp,%ebp
    6254:	56                   	push   %esi
    6255:	53                   	push   %ebx
    6256:	83 ec 20             	sub    $0x20,%esp
	return call_cap_2retvals_asm(sinv, 0, arg1, arg2, arg3, arg4, ret2, ret3);
    6259:	8b 5d 18             	mov    0x18(%ebp),%ebx
    625c:	8b 4d 14             	mov    0x14(%ebp),%ecx
    625f:	8b 55 10             	mov    0x10(%ebp),%edx
    6262:	8b 45 0c             	mov    0xc(%ebp),%eax
    6265:	8b 75 20             	mov    0x20(%ebp),%esi
    6268:	89 74 24 1c          	mov    %esi,0x1c(%esp)
    626c:	8b 75 1c             	mov    0x1c(%ebp),%esi
    626f:	89 74 24 18          	mov    %esi,0x18(%esp)
    6273:	89 5c 24 14          	mov    %ebx,0x14(%esp)
    6277:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    627b:	89 54 24 0c          	mov    %edx,0xc(%esp)
    627f:	89 44 24 08          	mov    %eax,0x8(%esp)
    6283:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    628a:	00 
    628b:	8b 45 08             	mov    0x8(%ebp),%eax
    628e:	89 04 24             	mov    %eax,(%esp)
    6291:	e8 31 e2 ff ff       	call   44c7 <call_cap_2retvals_asm>
}
    6296:	83 c4 20             	add    $0x20,%esp
    6299:	5b                   	pop    %ebx
    629a:	5e                   	pop    %esi
    629b:	5d                   	pop    %ebp
    629c:	c3                   	ret    

0000629d <cos_arcv_alloc>:
 * arcvcap: the rcv * endpoint that is the scheduler to be activated
 *          when the thread blocks on this endpoint.
 */
arcvcap_t
cos_arcv_alloc(struct cos_compinfo *ci, thdcap_t thdcap, tcap_t tcapcap, compcap_t compcap, arcvcap_t arcvcap)
{
    629d:	55                   	push   %ebp
    629e:	89 e5                	mov    %esp,%ebp
    62a0:	56                   	push   %esi
    62a1:	53                   	push   %ebx
    62a2:	83 ec 30             	sub    $0x30,%esp
	capid_t cap;

	assert(ci && thdcap && tcapcap && compcap);
    62a5:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    62a9:	0f 94 c0             	sete   %al
    62ac:	0f b6 c0             	movzbl %al,%eax
    62af:	85 c0                	test   %eax,%eax
    62b1:	75 0e                	jne    62c1 <cos_arcv_alloc+0x24>
    62b3:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    62b7:	0f 94 c0             	sete   %al
    62ba:	0f b6 c0             	movzbl %al,%eax
    62bd:	85 c0                	test   %eax,%eax
    62bf:	74 07                	je     62c8 <cos_arcv_alloc+0x2b>
    62c1:	b8 01 00 00 00       	mov    $0x1,%eax
    62c6:	eb 05                	jmp    62cd <cos_arcv_alloc+0x30>
    62c8:	b8 00 00 00 00       	mov    $0x0,%eax
    62cd:	85 c0                	test   %eax,%eax
    62cf:	75 0e                	jne    62df <cos_arcv_alloc+0x42>
    62d1:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    62d5:	0f 94 c0             	sete   %al
    62d8:	0f b6 c0             	movzbl %al,%eax
    62db:	85 c0                	test   %eax,%eax
    62dd:	74 07                	je     62e6 <cos_arcv_alloc+0x49>
    62df:	b8 01 00 00 00       	mov    $0x1,%eax
    62e4:	eb 05                	jmp    62eb <cos_arcv_alloc+0x4e>
    62e6:	b8 00 00 00 00       	mov    $0x0,%eax
    62eb:	85 c0                	test   %eax,%eax
    62ed:	75 0e                	jne    62fd <cos_arcv_alloc+0x60>
    62ef:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
    62f3:	0f 94 c0             	sete   %al
    62f6:	0f b6 c0             	movzbl %al,%eax
    62f9:	85 c0                	test   %eax,%eax
    62fb:	74 1c                	je     6319 <cos_arcv_alloc+0x7c>
    62fd:	c7 04 24 78 0f 00 00 	movl   $0xf78,(%esp)
    6304:	e8 75 e4 ff ff       	call   477e <prints>
    6309:	a1 40 00 00 00       	mov    0x40,%eax
    630e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6314:	e8 ec e4 ff ff       	call   4805 <__cos_noret>

	printd("arcv_alloc: tcap cap %d\n", (int)tcapcap);

	cap = __capid_bump_alloc(ci, CAP_ARCV);
    6319:	c7 44 24 04 04 00 00 	movl   $0x4,0x4(%esp)
    6320:	00 
    6321:	8b 45 08             	mov    0x8(%ebp),%eax
    6324:	89 04 24             	mov    %eax,(%esp)
    6327:	e8 60 ed ff ff       	call   508c <__capid_bump_alloc>
    632c:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (!cap) return 0;
    632f:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    6333:	75 07                	jne    633c <cos_arcv_alloc+0x9f>
    6335:	b8 00 00 00 00       	mov    $0x0,%eax
    633a:	eb 58                	jmp    6394 <cos_arcv_alloc+0xf7>
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_ARCVACTIVATE, cap, thdcap | (tcapcap << 16), compcap, arcvcap)) BUG();
    633c:	8b 75 18             	mov    0x18(%ebp),%esi
    633f:	8b 5d 14             	mov    0x14(%ebp),%ebx
    6342:	8b 45 10             	mov    0x10(%ebp),%eax
    6345:	c1 e0 10             	shl    $0x10,%eax
    6348:	0b 45 0c             	or     0xc(%ebp),%eax
    634b:	89 c1                	mov    %eax,%ecx
    634d:	8b 55 f4             	mov    -0xc(%ebp),%edx
    6350:	8b 45 08             	mov    0x8(%ebp),%eax
    6353:	8b 40 04             	mov    0x4(%eax),%eax
    6356:	89 74 24 14          	mov    %esi,0x14(%esp)
    635a:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    635e:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6362:	89 54 24 08          	mov    %edx,0x8(%esp)
    6366:	c7 44 24 04 0e 00 00 	movl   $0xe,0x4(%esp)
    636d:	00 
    636e:	89 04 24             	mov    %eax,(%esp)
    6371:	e8 fd e1 ff ff       	call   4573 <call_cap_op>
    6376:	85 c0                	test   %eax,%eax
    6378:	74 17                	je     6391 <cos_arcv_alloc+0xf4>
    637a:	c7 04 24 a8 0f 00 00 	movl   $0xfa8,(%esp)
    6381:	e8 f8 e3 ff ff       	call   477e <prints>
    6386:	a1 40 00 00 00       	mov    0x40,%eax
    638b:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    6391:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    6394:	83 c4 30             	add    $0x30,%esp
    6397:	5b                   	pop    %ebx
    6398:	5e                   	pop    %esi
    6399:	5d                   	pop    %ebp
    639a:	c3                   	ret    

0000639b <cos_asnd_alloc>:

asndcap_t
cos_asnd_alloc(struct cos_compinfo *ci, arcvcap_t arcvcap, captblcap_t ctcap)
{
    639b:	55                   	push   %ebp
    639c:	89 e5                	mov    %esp,%ebp
    639e:	53                   	push   %ebx
    639f:	83 ec 34             	sub    $0x34,%esp
	capid_t cap;

	assert(ci && arcvcap && ctcap);
    63a2:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    63a6:	0f 94 c0             	sete   %al
    63a9:	0f b6 c0             	movzbl %al,%eax
    63ac:	85 c0                	test   %eax,%eax
    63ae:	75 0e                	jne    63be <cos_asnd_alloc+0x23>
    63b0:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    63b4:	0f 94 c0             	sete   %al
    63b7:	0f b6 c0             	movzbl %al,%eax
    63ba:	85 c0                	test   %eax,%eax
    63bc:	74 07                	je     63c5 <cos_asnd_alloc+0x2a>
    63be:	b8 01 00 00 00       	mov    $0x1,%eax
    63c3:	eb 05                	jmp    63ca <cos_asnd_alloc+0x2f>
    63c5:	b8 00 00 00 00       	mov    $0x0,%eax
    63ca:	85 c0                	test   %eax,%eax
    63cc:	75 0e                	jne    63dc <cos_asnd_alloc+0x41>
    63ce:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    63d2:	0f 94 c0             	sete   %al
    63d5:	0f b6 c0             	movzbl %al,%eax
    63d8:	85 c0                	test   %eax,%eax
    63da:	74 1c                	je     63f8 <cos_asnd_alloc+0x5d>
    63dc:	c7 04 24 c8 0f 00 00 	movl   $0xfc8,(%esp)
    63e3:	e8 96 e3 ff ff       	call   477e <prints>
    63e8:	a1 40 00 00 00       	mov    0x40,%eax
    63ed:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    63f3:	e8 0d e4 ff ff       	call   4805 <__cos_noret>

	cap = __capid_bump_alloc(ci, CAP_ASND);
    63f8:	c7 44 24 04 03 00 00 	movl   $0x3,0x4(%esp)
    63ff:	00 
    6400:	8b 45 08             	mov    0x8(%ebp),%eax
    6403:	89 04 24             	mov    %eax,(%esp)
    6406:	e8 81 ec ff ff       	call   508c <__capid_bump_alloc>
    640b:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (!cap) return 0;
    640e:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    6412:	75 07                	jne    641b <cos_asnd_alloc+0x80>
    6414:	b8 00 00 00 00       	mov    $0x0,%eax
    6419:	eb 51                	jmp    646c <cos_asnd_alloc+0xd1>
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_ASNDACTIVATE, cap, ctcap, arcvcap, 0)) BUG();
    641b:	8b 5d 0c             	mov    0xc(%ebp),%ebx
    641e:	8b 4d 10             	mov    0x10(%ebp),%ecx
    6421:	8b 55 f4             	mov    -0xc(%ebp),%edx
    6424:	8b 45 08             	mov    0x8(%ebp),%eax
    6427:	8b 40 04             	mov    0x4(%eax),%eax
    642a:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6431:	00 
    6432:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    6436:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    643a:	89 54 24 08          	mov    %edx,0x8(%esp)
    643e:	c7 44 24 04 0c 00 00 	movl   $0xc,0x4(%esp)
    6445:	00 
    6446:	89 04 24             	mov    %eax,(%esp)
    6449:	e8 25 e1 ff ff       	call   4573 <call_cap_op>
    644e:	85 c0                	test   %eax,%eax
    6450:	74 17                	je     6469 <cos_asnd_alloc+0xce>
    6452:	c7 04 24 f8 0f 00 00 	movl   $0xff8,(%esp)
    6459:	e8 20 e3 ff ff       	call   477e <prints>
    645e:	a1 40 00 00 00       	mov    0x40,%eax
    6463:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    6469:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    646c:	83 c4 34             	add    $0x34,%esp
    646f:	5b                   	pop    %ebx
    6470:	5d                   	pop    %ebp
    6471:	c3                   	ret    

00006472 <cos_hw_alloc>:
 * TODO: bitmap must be a subset of existing one.
 *       but there is no such check now, violates access control policy.
 */
hwcap_t
cos_hw_alloc(struct cos_compinfo *ci, u32_t bitmap)
{
    6472:	55                   	push   %ebp
    6473:	89 e5                	mov    %esp,%ebp
    6475:	83 ec 38             	sub    $0x38,%esp
	capid_t cap;

	assert(ci);
    6478:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    647c:	0f 94 c0             	sete   %al
    647f:	0f b6 c0             	movzbl %al,%eax
    6482:	85 c0                	test   %eax,%eax
    6484:	74 1c                	je     64a2 <cos_hw_alloc+0x30>
    6486:	c7 04 24 18 10 00 00 	movl   $0x1018,(%esp)
    648d:	e8 ec e2 ff ff       	call   477e <prints>
    6492:	a1 40 00 00 00       	mov    0x40,%eax
    6497:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    649d:	e8 63 e3 ff ff       	call   4805 <__cos_noret>

	cap = __capid_bump_alloc(ci, CAP_HW);
    64a2:	c7 44 24 04 0d 00 00 	movl   $0xd,0x4(%esp)
    64a9:	00 
    64aa:	8b 45 08             	mov    0x8(%ebp),%eax
    64ad:	89 04 24             	mov    %eax,(%esp)
    64b0:	e8 d7 eb ff ff       	call   508c <__capid_bump_alloc>
    64b5:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (!cap) return 0;
    64b8:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    64bc:	75 07                	jne    64c5 <cos_hw_alloc+0x53>
    64be:	b8 00 00 00 00       	mov    $0x0,%eax
    64c3:	eb 52                	jmp    6517 <cos_hw_alloc+0xa5>
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_HW_ACTIVATE, cap, bitmap, 0, 0)) BUG();
    64c5:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    64c8:	8b 55 f4             	mov    -0xc(%ebp),%edx
    64cb:	8b 45 08             	mov    0x8(%ebp),%eax
    64ce:	8b 40 04             	mov    0x4(%eax),%eax
    64d1:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    64d8:	00 
    64d9:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    64e0:	00 
    64e1:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    64e5:	89 54 24 08          	mov    %edx,0x8(%esp)
    64e9:	c7 44 24 04 24 00 00 	movl   $0x24,0x4(%esp)
    64f0:	00 
    64f1:	89 04 24             	mov    %eax,(%esp)
    64f4:	e8 7a e0 ff ff       	call   4573 <call_cap_op>
    64f9:	85 c0                	test   %eax,%eax
    64fb:	74 17                	je     6514 <cos_hw_alloc+0xa2>
    64fd:	c7 04 24 48 10 00 00 	movl   $0x1048,(%esp)
    6504:	e8 75 e2 ff ff       	call   477e <prints>
    6509:	a1 40 00 00 00       	mov    0x40,%eax
    650e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    6514:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    6517:	c9                   	leave  
    6518:	c3                   	ret    

00006519 <cos_page_bump_alloc>:

void *
cos_page_bump_alloc(struct cos_compinfo *ci)
{
    6519:	55                   	push   %ebp
    651a:	89 e5                	mov    %esp,%ebp
    651c:	83 ec 18             	sub    $0x18,%esp
	return (void *)__page_bump_alloc(ci, PAGE_SIZE);
    651f:	c7 44 24 04 00 10 00 	movl   $0x1000,0x4(%esp)
    6526:	00 
    6527:	8b 45 08             	mov    0x8(%ebp),%eax
    652a:	89 04 24             	mov    %eax,(%esp)
    652d:	e8 68 f3 ff ff       	call   589a <__page_bump_alloc>
}
    6532:	c9                   	leave  
    6533:	c3                   	ret    

00006534 <cos_page_bump_allocn>:

void *
cos_page_bump_allocn(struct cos_compinfo *ci, size_t sz)
{
    6534:	55                   	push   %ebp
    6535:	89 e5                	mov    %esp,%ebp
    6537:	83 ec 18             	sub    $0x18,%esp
	assert(sz % PAGE_SIZE == 0);
    653a:	8b 45 0c             	mov    0xc(%ebp),%eax
    653d:	25 ff 0f 00 00       	and    $0xfff,%eax
    6542:	85 c0                	test   %eax,%eax
    6544:	0f 95 c0             	setne  %al
    6547:	0f b6 c0             	movzbl %al,%eax
    654a:	85 c0                	test   %eax,%eax
    654c:	74 1c                	je     656a <cos_page_bump_allocn+0x36>
    654e:	c7 04 24 68 10 00 00 	movl   $0x1068,(%esp)
    6555:	e8 24 e2 ff ff       	call   477e <prints>
    655a:	a1 40 00 00 00       	mov    0x40,%eax
    655f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6565:	e8 9b e2 ff ff       	call   4805 <__cos_noret>

	return (void *)__page_bump_alloc(ci, sz);
    656a:	8b 45 0c             	mov    0xc(%ebp),%eax
    656d:	89 44 24 04          	mov    %eax,0x4(%esp)
    6571:	8b 45 08             	mov    0x8(%ebp),%eax
    6574:	89 04 24             	mov    %eax,(%esp)
    6577:	e8 1e f3 ff ff       	call   589a <__page_bump_alloc>
}
    657c:	c9                   	leave  
    657d:	c3                   	ret    

0000657e <cos_cap_cpy>:

capid_t
cos_cap_cpy(struct cos_compinfo *dstci, struct cos_compinfo *srcci, cap_t srcctype, capid_t srccap)
{
    657e:	55                   	push   %ebp
    657f:	89 e5                	mov    %esp,%ebp
    6581:	53                   	push   %ebx
    6582:	83 ec 34             	sub    $0x34,%esp
	capid_t dstcap;

	assert(srcci && dstci);
    6585:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    6589:	0f 94 c0             	sete   %al
    658c:	0f b6 c0             	movzbl %al,%eax
    658f:	85 c0                	test   %eax,%eax
    6591:	75 0e                	jne    65a1 <cos_cap_cpy+0x23>
    6593:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    6597:	0f 94 c0             	sete   %al
    659a:	0f b6 c0             	movzbl %al,%eax
    659d:	85 c0                	test   %eax,%eax
    659f:	74 1c                	je     65bd <cos_cap_cpy+0x3f>
    65a1:	c7 04 24 98 10 00 00 	movl   $0x1098,(%esp)
    65a8:	e8 d1 e1 ff ff       	call   477e <prints>
    65ad:	a1 40 00 00 00       	mov    0x40,%eax
    65b2:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    65b8:	e8 48 e2 ff ff       	call   4805 <__cos_noret>

	dstcap = __capid_bump_alloc(dstci, srcctype);
    65bd:	8b 45 10             	mov    0x10(%ebp),%eax
    65c0:	89 44 24 04          	mov    %eax,0x4(%esp)
    65c4:	8b 45 08             	mov    0x8(%ebp),%eax
    65c7:	89 04 24             	mov    %eax,(%esp)
    65ca:	e8 bd ea ff ff       	call   508c <__capid_bump_alloc>
    65cf:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (!dstcap) return 0;
    65d2:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    65d6:	75 07                	jne    65df <cos_cap_cpy+0x61>
    65d8:	b8 00 00 00 00       	mov    $0x0,%eax
    65dd:	eb 56                	jmp    6635 <cos_cap_cpy+0xb7>

	if (call_cap_op(srcci->captbl_cap, CAPTBL_OP_CPY, srccap, dstci->captbl_cap, dstcap, 0)) BUG();
    65df:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    65e2:	8b 45 08             	mov    0x8(%ebp),%eax
    65e5:	8b 40 04             	mov    0x4(%eax),%eax
    65e8:	89 c1                	mov    %eax,%ecx
    65ea:	8b 55 14             	mov    0x14(%ebp),%edx
    65ed:	8b 45 0c             	mov    0xc(%ebp),%eax
    65f0:	8b 40 04             	mov    0x4(%eax),%eax
    65f3:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    65fa:	00 
    65fb:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    65ff:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6603:	89 54 24 08          	mov    %edx,0x8(%esp)
    6607:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    660e:	00 
    660f:	89 04 24             	mov    %eax,(%esp)
    6612:	e8 5c df ff ff       	call   4573 <call_cap_op>
    6617:	85 c0                	test   %eax,%eax
    6619:	74 17                	je     6632 <cos_cap_cpy+0xb4>
    661b:	c7 04 24 c8 10 00 00 	movl   $0x10c8,(%esp)
    6622:	e8 57 e1 ff ff       	call   477e <prints>
    6627:	a1 40 00 00 00       	mov    0x40,%eax
    662c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return dstcap;
    6632:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    6635:	83 c4 34             	add    $0x34,%esp
    6638:	5b                   	pop    %ebx
    6639:	5d                   	pop    %ebp
    663a:	c3                   	ret    

0000663b <cos_cap_cpy_at>:

int
cos_cap_cpy_at(struct cos_compinfo *dstci, capid_t dstcap, struct cos_compinfo *srcci, capid_t srccap)
{
    663b:	55                   	push   %ebp
    663c:	89 e5                	mov    %esp,%ebp
    663e:	53                   	push   %ebx
    663f:	83 ec 24             	sub    $0x24,%esp
	assert(srcci && dstci);
    6642:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    6646:	0f 94 c0             	sete   %al
    6649:	0f b6 c0             	movzbl %al,%eax
    664c:	85 c0                	test   %eax,%eax
    664e:	75 0e                	jne    665e <cos_cap_cpy_at+0x23>
    6650:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    6654:	0f 94 c0             	sete   %al
    6657:	0f b6 c0             	movzbl %al,%eax
    665a:	85 c0                	test   %eax,%eax
    665c:	74 1c                	je     667a <cos_cap_cpy_at+0x3f>
    665e:	c7 04 24 e8 10 00 00 	movl   $0x10e8,(%esp)
    6665:	e8 14 e1 ff ff       	call   477e <prints>
    666a:	a1 40 00 00 00       	mov    0x40,%eax
    666f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6675:	e8 8b e1 ff ff       	call   4805 <__cos_noret>

	if (!dstcap) return 0;
    667a:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    667e:	75 07                	jne    6687 <cos_cap_cpy_at+0x4c>
    6680:	b8 00 00 00 00       	mov    $0x0,%eax
    6685:	eb 58                	jmp    66df <cos_cap_cpy_at+0xa4>

	if (call_cap_op(srcci->captbl_cap, CAPTBL_OP_CPY, srccap, dstci->captbl_cap, dstcap, 0)) BUG();
    6687:	8b 5d 0c             	mov    0xc(%ebp),%ebx
    668a:	8b 45 08             	mov    0x8(%ebp),%eax
    668d:	8b 40 04             	mov    0x4(%eax),%eax
    6690:	89 c1                	mov    %eax,%ecx
    6692:	8b 55 14             	mov    0x14(%ebp),%edx
    6695:	8b 45 10             	mov    0x10(%ebp),%eax
    6698:	8b 40 04             	mov    0x4(%eax),%eax
    669b:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    66a2:	00 
    66a3:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    66a7:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    66ab:	89 54 24 08          	mov    %edx,0x8(%esp)
    66af:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    66b6:	00 
    66b7:	89 04 24             	mov    %eax,(%esp)
    66ba:	e8 b4 de ff ff       	call   4573 <call_cap_op>
    66bf:	85 c0                	test   %eax,%eax
    66c1:	74 17                	je     66da <cos_cap_cpy_at+0x9f>
    66c3:	c7 04 24 18 11 00 00 	movl   $0x1118,(%esp)
    66ca:	e8 af e0 ff ff       	call   477e <prints>
    66cf:	a1 40 00 00 00       	mov    0x40,%eax
    66d4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return 0;
    66da:	b8 00 00 00 00       	mov    $0x0,%eax
}
    66df:	83 c4 24             	add    $0x24,%esp
    66e2:	5b                   	pop    %ebx
    66e3:	5d                   	pop    %ebp
    66e4:	c3                   	ret    

000066e5 <cos_thd_switch>:

/**************** [Kernel Object Operations] ****************/

int
cos_thd_switch(thdcap_t c)
{
    66e5:	55                   	push   %ebp
    66e6:	89 e5                	mov    %esp,%ebp
    66e8:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(c, 0, 0, 0, 0, 0);
    66eb:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    66f2:	00 
    66f3:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    66fa:	00 
    66fb:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    6702:	00 
    6703:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    670a:	00 
    670b:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    6712:	00 
    6713:	8b 45 08             	mov    0x8(%ebp),%eax
    6716:	89 04 24             	mov    %eax,(%esp)
    6719:	e8 55 de ff ff       	call   4573 <call_cap_op>
}
    671e:	c9                   	leave  
    671f:	c3                   	ret    

00006720 <cos_thd_wakeup>:

int
cos_thd_wakeup(thdcap_t thd, tcap_t tc, tcap_prio_t prio, tcap_res_t res)
{
    6720:	55                   	push   %ebp
    6721:	89 e5                	mov    %esp,%ebp
    6723:	53                   	push   %ebx
    6724:	83 ec 24             	sub    $0x24,%esp
    6727:	8b 45 10             	mov    0x10(%ebp),%eax
    672a:	89 45 f0             	mov    %eax,-0x10(%ebp)
    672d:	8b 45 14             	mov    0x14(%ebp),%eax
    6730:	89 45 f4             	mov    %eax,-0xc(%ebp)
	return call_cap_op(tc, CAPTBL_OP_TCAP_WAKEUP, thd, (prio << 32) >> 32, prio >> 32, res);
    6733:	8b 5d 18             	mov    0x18(%ebp),%ebx
    6736:	8b 45 f0             	mov    -0x10(%ebp),%eax
    6739:	8b 55 f4             	mov    -0xc(%ebp),%edx
    673c:	89 d0                	mov    %edx,%eax
    673e:	31 d2                	xor    %edx,%edx
    6740:	89 c1                	mov    %eax,%ecx
    6742:	8b 55 f0             	mov    -0x10(%ebp),%edx
    6745:	8b 45 08             	mov    0x8(%ebp),%eax
    6748:	89 5c 24 14          	mov    %ebx,0x14(%esp)
    674c:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    6750:	89 54 24 0c          	mov    %edx,0xc(%esp)
    6754:	89 44 24 08          	mov    %eax,0x8(%esp)
    6758:	c7 44 24 04 23 00 00 	movl   $0x23,0x4(%esp)
    675f:	00 
    6760:	8b 45 0c             	mov    0xc(%ebp),%eax
    6763:	89 04 24             	mov    %eax,(%esp)
    6766:	e8 08 de ff ff       	call   4573 <call_cap_op>
}
    676b:	83 c4 24             	add    $0x24,%esp
    676e:	5b                   	pop    %ebx
    676f:	5d                   	pop    %ebp
    6770:	c3                   	ret    

00006771 <cos_sched_sync>:

sched_tok_t
cos_sched_sync(void)
{
    6771:	55                   	push   %ebp
    6772:	89 e5                	mov    %esp,%ebp
    6774:	83 ec 08             	sub    $0x8,%esp
	static sched_tok_t stok[NUM_CPU] CACHE_ALIGNED;

	return ps_faa((unsigned long *)&stok[cos_cpuid()], 1);
    6777:	e8 87 de ff ff       	call   4603 <cos_cpuid>
    677c:	c1 e0 02             	shl    $0x2,%eax
    677f:	05 80 00 00 00       	add    $0x80,%eax
    6784:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    678b:	00 
    678c:	89 04 24             	mov    %eax,(%esp)
    678f:	e8 9d e0 ff ff       	call   4831 <ps_faa>
}
    6794:	c9                   	leave  
    6795:	c3                   	ret    

00006796 <cos_switch>:

int
cos_switch(thdcap_t c, tcap_t tc, tcap_prio_t prio, tcap_time_t timeout, arcvcap_t rcv, sched_tok_t stok)
{
    6796:	55                   	push   %ebp
    6797:	89 e5                	mov    %esp,%ebp
    6799:	56                   	push   %esi
    679a:	53                   	push   %ebx
    679b:	83 ec 20             	sub    $0x20,%esp
    679e:	8b 45 10             	mov    0x10(%ebp),%eax
    67a1:	89 45 f0             	mov    %eax,-0x10(%ebp)
    67a4:	8b 45 14             	mov    0x14(%ebp),%eax
    67a7:	89 45 f4             	mov    %eax,-0xc(%ebp)
	return call_cap_op(c, (stok >> 16), tc << 16 | rcv, (prio << 32) >> 32,
    67aa:	8b 5d 18             	mov    0x18(%ebp),%ebx
	                   (((prio << 16) >> 48) << 16) | ((stok << 16) >> 16), timeout);
    67ad:	8b 45 f0             	mov    -0x10(%ebp),%eax
    67b0:	8b 55 f4             	mov    -0xc(%ebp),%edx
    67b3:	0f a4 c2 10          	shld   $0x10,%eax,%edx
    67b7:	c1 e0 10             	shl    $0x10,%eax
    67ba:	89 d0                	mov    %edx,%eax
    67bc:	31 d2                	xor    %edx,%edx
    67be:	c1 e8 10             	shr    $0x10,%eax
}

int
cos_switch(thdcap_t c, tcap_t tc, tcap_prio_t prio, tcap_time_t timeout, arcvcap_t rcv, sched_tok_t stok)
{
	return call_cap_op(c, (stok >> 16), tc << 16 | rcv, (prio << 32) >> 32,
    67c1:	c1 e0 10             	shl    $0x10,%eax
    67c4:	89 c2                	mov    %eax,%edx
    67c6:	8b 45 20             	mov    0x20(%ebp),%eax
    67c9:	0f b7 c0             	movzwl %ax,%eax
    67cc:	09 d0                	or     %edx,%eax
    67ce:	89 c1                	mov    %eax,%ecx
    67d0:	8b 55 f0             	mov    -0x10(%ebp),%edx
    67d3:	8b 45 0c             	mov    0xc(%ebp),%eax
    67d6:	c1 e0 10             	shl    $0x10,%eax
    67d9:	0b 45 1c             	or     0x1c(%ebp),%eax
    67dc:	8b 75 20             	mov    0x20(%ebp),%esi
    67df:	c1 ee 10             	shr    $0x10,%esi
    67e2:	89 5c 24 14          	mov    %ebx,0x14(%esp)
    67e6:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    67ea:	89 54 24 0c          	mov    %edx,0xc(%esp)
    67ee:	89 44 24 08          	mov    %eax,0x8(%esp)
    67f2:	89 74 24 04          	mov    %esi,0x4(%esp)
    67f6:	8b 45 08             	mov    0x8(%ebp),%eax
    67f9:	89 04 24             	mov    %eax,(%esp)
    67fc:	e8 72 dd ff ff       	call   4573 <call_cap_op>
	                   (((prio << 16) >> 48) << 16) | ((stok << 16) >> 16), timeout);
}
    6801:	83 c4 20             	add    $0x20,%esp
    6804:	5b                   	pop    %ebx
    6805:	5e                   	pop    %esi
    6806:	5d                   	pop    %ebp
    6807:	c3                   	ret    

00006808 <cos_sched_asnd>:

int
cos_sched_asnd(asndcap_t snd, tcap_time_t timeout, arcvcap_t srcv, sched_tok_t stok)
{
    6808:	55                   	push   %ebp
    6809:	89 e5                	mov    %esp,%ebp
    680b:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(snd, 0, srcv, stok, timeout, 0);
    680e:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    6811:	8b 55 14             	mov    0x14(%ebp),%edx
    6814:	8b 45 10             	mov    0x10(%ebp),%eax
    6817:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    681e:	00 
    681f:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    6823:	89 54 24 0c          	mov    %edx,0xc(%esp)
    6827:	89 44 24 08          	mov    %eax,0x8(%esp)
    682b:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    6832:	00 
    6833:	8b 45 08             	mov    0x8(%ebp),%eax
    6836:	89 04 24             	mov    %eax,(%esp)
    6839:	e8 35 dd ff ff       	call   4573 <call_cap_op>
}
    683e:	c9                   	leave  
    683f:	c3                   	ret    

00006840 <cos_asnd>:

int
cos_asnd(asndcap_t snd, int yield)
{
    6840:	55                   	push   %ebp
    6841:	89 e5                	mov    %esp,%ebp
    6843:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(snd, 0, 0, 0, 0, yield);
    6846:	8b 45 0c             	mov    0xc(%ebp),%eax
    6849:	89 44 24 14          	mov    %eax,0x14(%esp)
    684d:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    6854:	00 
    6855:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    685c:	00 
    685d:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    6864:	00 
    6865:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    686c:	00 
    686d:	8b 45 08             	mov    0x8(%ebp),%eax
    6870:	89 04 24             	mov    %eax,(%esp)
    6873:	e8 fb dc ff ff       	call   4573 <call_cap_op>
}
    6878:	c9                   	leave  
    6879:	c3                   	ret    

0000687a <cos_sched_rcv>:

int
cos_sched_rcv(arcvcap_t rcv, rcv_flags_t flags, tcap_time_t timeout,
	      int *rcvd, thdid_t *thdid, int *blocked, cycles_t *cycles, tcap_time_t *thd_timeout)
{
    687a:	55                   	push   %ebp
    687b:	89 e5                	mov    %esp,%ebp
    687d:	83 ec 34             	sub    $0x34,%esp
	unsigned long thd_state = 0;
    6880:	c7 45 f8 00 00 00 00 	movl   $0x0,-0x8(%ebp)
	unsigned long cyc       = 0;
    6887:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	int           ret;

	ret = call_cap_retvals_asm(rcv, 0, flags, timeout, 0, 0, &thd_state, &cyc, thd_timeout);
    688e:	8b 55 10             	mov    0x10(%ebp),%edx
    6891:	8b 45 0c             	mov    0xc(%ebp),%eax
    6894:	8b 4d 24             	mov    0x24(%ebp),%ecx
    6897:	89 4c 24 20          	mov    %ecx,0x20(%esp)
    689b:	8d 4d f4             	lea    -0xc(%ebp),%ecx
    689e:	89 4c 24 1c          	mov    %ecx,0x1c(%esp)
    68a2:	8d 4d f8             	lea    -0x8(%ebp),%ecx
    68a5:	89 4c 24 18          	mov    %ecx,0x18(%esp)
    68a9:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    68b0:	00 
    68b1:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    68b8:	00 
    68b9:	89 54 24 0c          	mov    %edx,0xc(%esp)
    68bd:	89 44 24 08          	mov    %eax,0x8(%esp)
    68c1:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    68c8:	00 
    68c9:	8b 45 08             	mov    0x8(%ebp),%eax
    68cc:	89 04 24             	mov    %eax,(%esp)
    68cf:	e8 7c db ff ff       	call   4450 <call_cap_retvals_asm>
    68d4:	89 45 fc             	mov    %eax,-0x4(%ebp)

	*blocked = (int)(thd_state >> (sizeof(thd_state) * 8 - 1));
    68d7:	8b 45 f8             	mov    -0x8(%ebp),%eax
    68da:	c1 e8 1f             	shr    $0x1f,%eax
    68dd:	89 c2                	mov    %eax,%edx
    68df:	8b 45 1c             	mov    0x1c(%ebp),%eax
    68e2:	89 10                	mov    %edx,(%eax)
	*thdid   = (thdid_t)(thd_state & ((1 << (sizeof(thdid_t) * 8)) - 1));
    68e4:	8b 45 f8             	mov    -0x8(%ebp),%eax
    68e7:	89 c2                	mov    %eax,%edx
    68e9:	8b 45 18             	mov    0x18(%ebp),%eax
    68ec:	66 89 10             	mov    %dx,(%eax)
	*cycles  = cyc;
    68ef:	8b 45 f4             	mov    -0xc(%ebp),%eax
    68f2:	ba 00 00 00 00       	mov    $0x0,%edx
    68f7:	8b 4d 20             	mov    0x20(%ebp),%ecx
    68fa:	89 01                	mov    %eax,(%ecx)
    68fc:	89 51 04             	mov    %edx,0x4(%ecx)

	if (ret >= 0 && flags & RCV_ALL_PENDING) {
    68ff:	83 7d fc 00          	cmpl   $0x0,-0x4(%ebp)
    6903:	78 1a                	js     691f <cos_sched_rcv+0xa5>
    6905:	8b 45 0c             	mov    0xc(%ebp),%eax
    6908:	83 e0 02             	and    $0x2,%eax
    690b:	85 c0                	test   %eax,%eax
    690d:	74 10                	je     691f <cos_sched_rcv+0xa5>
		*rcvd = (ret >> 1);
    690f:	8b 45 fc             	mov    -0x4(%ebp),%eax
    6912:	d1 f8                	sar    %eax
    6914:	89 c2                	mov    %eax,%edx
    6916:	8b 45 14             	mov    0x14(%ebp),%eax
    6919:	89 10                	mov    %edx,(%eax)
		ret &= 1;
    691b:	83 65 fc 01          	andl   $0x1,-0x4(%ebp)
	}

	return ret;
    691f:	8b 45 fc             	mov    -0x4(%ebp),%eax
}
    6922:	c9                   	leave  
    6923:	c3                   	ret    

00006924 <cos_rcv>:

int
cos_rcv(arcvcap_t rcv, rcv_flags_t flags, int *rcvd)
{
    6924:	55                   	push   %ebp
    6925:	89 e5                	mov    %esp,%ebp
    6927:	83 ec 48             	sub    $0x48,%esp
	thdid_t     tid = 0;
    692a:	66 c7 45 f2 00 00    	movw   $0x0,-0xe(%ebp)
	int         blocked;
	cycles_t    cyc;
	int         ret;
	tcap_time_t thd_timeout;

	ret = cos_sched_rcv(rcv, flags, 0, rcvd, &tid, &blocked, &cyc, &thd_timeout);
    6930:	8d 45 dc             	lea    -0x24(%ebp),%eax
    6933:	89 44 24 1c          	mov    %eax,0x1c(%esp)
    6937:	8d 45 e0             	lea    -0x20(%ebp),%eax
    693a:	89 44 24 18          	mov    %eax,0x18(%esp)
    693e:	8d 45 ec             	lea    -0x14(%ebp),%eax
    6941:	89 44 24 14          	mov    %eax,0x14(%esp)
    6945:	8d 45 f2             	lea    -0xe(%ebp),%eax
    6948:	89 44 24 10          	mov    %eax,0x10(%esp)
    694c:	8b 45 10             	mov    0x10(%ebp),%eax
    694f:	89 44 24 0c          	mov    %eax,0xc(%esp)
    6953:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    695a:	00 
    695b:	8b 45 0c             	mov    0xc(%ebp),%eax
    695e:	89 44 24 04          	mov    %eax,0x4(%esp)
    6962:	8b 45 08             	mov    0x8(%ebp),%eax
    6965:	89 04 24             	mov    %eax,(%esp)
    6968:	e8 fc ff ff ff       	call   6969 <cos_rcv+0x45>
    696d:	89 45 f4             	mov    %eax,-0xc(%ebp)
	assert(tid == 0);
    6970:	0f b7 45 f2          	movzwl -0xe(%ebp),%eax
    6974:	66 85 c0             	test   %ax,%ax
    6977:	0f 95 c0             	setne  %al
    697a:	0f b6 c0             	movzbl %al,%eax
    697d:	85 c0                	test   %eax,%eax
    697f:	74 1c                	je     699d <cos_rcv+0x79>
    6981:	c7 04 24 38 11 00 00 	movl   $0x1138,(%esp)
    6988:	e8 f1 dd ff ff       	call   477e <prints>
    698d:	a1 40 00 00 00       	mov    0x40,%eax
    6992:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6998:	e8 68 de ff ff       	call   4805 <__cos_noret>

	return ret;
    699d:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    69a0:	c9                   	leave  
    69a1:	c3                   	ret    

000069a2 <cos_mem_aliasn>:

vaddr_t
cos_mem_aliasn(struct cos_compinfo *dstci, struct cos_compinfo *srcci, vaddr_t src, size_t sz)
{
    69a2:	55                   	push   %ebp
    69a3:	89 e5                	mov    %esp,%ebp
    69a5:	53                   	push   %ebx
    69a6:	83 ec 34             	sub    $0x34,%esp
	size_t i;
	vaddr_t dst, first_dst;

	assert(srcci && dstci);
    69a9:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    69ad:	0f 94 c0             	sete   %al
    69b0:	0f b6 c0             	movzbl %al,%eax
    69b3:	85 c0                	test   %eax,%eax
    69b5:	75 0e                	jne    69c5 <cos_mem_aliasn+0x23>
    69b7:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    69bb:	0f 94 c0             	sete   %al
    69be:	0f b6 c0             	movzbl %al,%eax
    69c1:	85 c0                	test   %eax,%eax
    69c3:	74 1c                	je     69e1 <cos_mem_aliasn+0x3f>
    69c5:	c7 04 24 68 11 00 00 	movl   $0x1168,(%esp)
    69cc:	e8 ad dd ff ff       	call   477e <prints>
    69d1:	a1 40 00 00 00       	mov    0x40,%eax
    69d6:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    69dc:	e8 24 de ff ff       	call   4805 <__cos_noret>
	assert(sz && (sz % PAGE_SIZE == 0));
    69e1:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
    69e5:	0f 94 c0             	sete   %al
    69e8:	0f b6 c0             	movzbl %al,%eax
    69eb:	85 c0                	test   %eax,%eax
    69ed:	75 14                	jne    6a03 <cos_mem_aliasn+0x61>
    69ef:	8b 45 14             	mov    0x14(%ebp),%eax
    69f2:	25 ff 0f 00 00       	and    $0xfff,%eax
    69f7:	85 c0                	test   %eax,%eax
    69f9:	0f 95 c0             	setne  %al
    69fc:	0f b6 c0             	movzbl %al,%eax
    69ff:	85 c0                	test   %eax,%eax
    6a01:	74 1c                	je     6a1f <cos_mem_aliasn+0x7d>
    6a03:	c7 04 24 98 11 00 00 	movl   $0x1198,(%esp)
    6a0a:	e8 6f dd ff ff       	call   477e <prints>
    6a0f:	a1 40 00 00 00       	mov    0x40,%eax
    6a14:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6a1a:	e8 e6 dd ff ff       	call   4805 <__cos_noret>

	dst = __page_bump_valloc(dstci, sz);
    6a1f:	8b 45 14             	mov    0x14(%ebp),%eax
    6a22:	89 44 24 04          	mov    %eax,0x4(%esp)
    6a26:	8b 45 08             	mov    0x8(%ebp),%eax
    6a29:	89 04 24             	mov    %eax,(%esp)
    6a2c:	e8 12 ee ff ff       	call   5843 <__page_bump_valloc>
    6a31:	89 45 f0             	mov    %eax,-0x10(%ebp)
	if (unlikely(!dst)) return 0;
    6a34:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    6a38:	0f 94 c0             	sete   %al
    6a3b:	0f b6 c0             	movzbl %al,%eax
    6a3e:	85 c0                	test   %eax,%eax
    6a40:	74 0a                	je     6a4c <cos_mem_aliasn+0xaa>
    6a42:	b8 00 00 00 00       	mov    $0x0,%eax
    6a47:	e9 80 00 00 00       	jmp    6acc <cos_mem_aliasn+0x12a>
	first_dst = dst;
    6a4c:	8b 45 f0             	mov    -0x10(%ebp),%eax
    6a4f:	89 45 ec             	mov    %eax,-0x14(%ebp)

	for (i = 0; i < sz; i += PAGE_SIZE, src += PAGE_SIZE, dst += PAGE_SIZE) {
    6a52:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    6a59:	eb 66                	jmp    6ac1 <cos_mem_aliasn+0x11f>
		if (call_cap_op(srcci->pgtbl_cap, CAPTBL_OP_CPY, src, dstci->pgtbl_cap, dst, 0)) BUG();
    6a5b:	8b 5d f0             	mov    -0x10(%ebp),%ebx
    6a5e:	8b 45 08             	mov    0x8(%ebp),%eax
    6a61:	8b 00                	mov    (%eax),%eax
    6a63:	89 c1                	mov    %eax,%ecx
    6a65:	8b 55 10             	mov    0x10(%ebp),%edx
    6a68:	8b 45 0c             	mov    0xc(%ebp),%eax
    6a6b:	8b 00                	mov    (%eax),%eax
    6a6d:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6a74:	00 
    6a75:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    6a79:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6a7d:	89 54 24 08          	mov    %edx,0x8(%esp)
    6a81:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    6a88:	00 
    6a89:	89 04 24             	mov    %eax,(%esp)
    6a8c:	e8 e2 da ff ff       	call   4573 <call_cap_op>
    6a91:	85 c0                	test   %eax,%eax
    6a93:	74 17                	je     6aac <cos_mem_aliasn+0x10a>
    6a95:	c7 04 24 c8 11 00 00 	movl   $0x11c8,(%esp)
    6a9c:	e8 dd dc ff ff       	call   477e <prints>
    6aa1:	a1 40 00 00 00       	mov    0x40,%eax
    6aa6:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	dst = __page_bump_valloc(dstci, sz);
	if (unlikely(!dst)) return 0;
	first_dst = dst;

	for (i = 0; i < sz; i += PAGE_SIZE, src += PAGE_SIZE, dst += PAGE_SIZE) {
    6aac:	81 45 f4 00 10 00 00 	addl   $0x1000,-0xc(%ebp)
    6ab3:	81 45 10 00 10 00 00 	addl   $0x1000,0x10(%ebp)
    6aba:	81 45 f0 00 10 00 00 	addl   $0x1000,-0x10(%ebp)
    6ac1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    6ac4:	3b 45 14             	cmp    0x14(%ebp),%eax
    6ac7:	72 92                	jb     6a5b <cos_mem_aliasn+0xb9>
		if (call_cap_op(srcci->pgtbl_cap, CAPTBL_OP_CPY, src, dstci->pgtbl_cap, dst, 0)) BUG();
	}

	return first_dst;
    6ac9:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    6acc:	83 c4 34             	add    $0x34,%esp
    6acf:	5b                   	pop    %ebx
    6ad0:	5d                   	pop    %ebp
    6ad1:	c3                   	ret    

00006ad2 <cos_mem_alias>:

vaddr_t
cos_mem_alias(struct cos_compinfo *dstci, struct cos_compinfo *srcci, vaddr_t src)
{
    6ad2:	55                   	push   %ebp
    6ad3:	89 e5                	mov    %esp,%ebp
    6ad5:	83 ec 18             	sub    $0x18,%esp
	return cos_mem_aliasn(dstci, srcci, src, PAGE_SIZE);
    6ad8:	c7 44 24 0c 00 10 00 	movl   $0x1000,0xc(%esp)
    6adf:	00 
    6ae0:	8b 45 10             	mov    0x10(%ebp),%eax
    6ae3:	89 44 24 08          	mov    %eax,0x8(%esp)
    6ae7:	8b 45 0c             	mov    0xc(%ebp),%eax
    6aea:	89 44 24 04          	mov    %eax,0x4(%esp)
    6aee:	8b 45 08             	mov    0x8(%ebp),%eax
    6af1:	89 04 24             	mov    %eax,(%esp)
    6af4:	e8 fc ff ff ff       	call   6af5 <cos_mem_alias+0x23>
}
    6af9:	c9                   	leave  
    6afa:	c3                   	ret    

00006afb <cos_mem_alias_at>:

int
cos_mem_alias_at(struct cos_compinfo *dstci, vaddr_t dst, struct cos_compinfo *srcci, vaddr_t src)
{
    6afb:	55                   	push   %ebp
    6afc:	89 e5                	mov    %esp,%ebp
    6afe:	53                   	push   %ebx
    6aff:	83 ec 24             	sub    $0x24,%esp
	assert(srcci && dstci);
    6b02:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    6b06:	0f 94 c0             	sete   %al
    6b09:	0f b6 c0             	movzbl %al,%eax
    6b0c:	85 c0                	test   %eax,%eax
    6b0e:	75 0e                	jne    6b1e <cos_mem_alias_at+0x23>
    6b10:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    6b14:	0f 94 c0             	sete   %al
    6b17:	0f b6 c0             	movzbl %al,%eax
    6b1a:	85 c0                	test   %eax,%eax
    6b1c:	74 1c                	je     6b3a <cos_mem_alias_at+0x3f>
    6b1e:	c7 04 24 e8 11 00 00 	movl   $0x11e8,(%esp)
    6b25:	e8 54 dc ff ff       	call   477e <prints>
    6b2a:	a1 40 00 00 00       	mov    0x40,%eax
    6b2f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6b35:	e8 cb dc ff ff       	call   4805 <__cos_noret>

	if (call_cap_op(srcci->pgtbl_cap, CAPTBL_OP_CPY, src, dstci->pgtbl_cap, dst, 0)) BUG();
    6b3a:	8b 5d 0c             	mov    0xc(%ebp),%ebx
    6b3d:	8b 45 08             	mov    0x8(%ebp),%eax
    6b40:	8b 00                	mov    (%eax),%eax
    6b42:	89 c1                	mov    %eax,%ecx
    6b44:	8b 55 14             	mov    0x14(%ebp),%edx
    6b47:	8b 45 10             	mov    0x10(%ebp),%eax
    6b4a:	8b 00                	mov    (%eax),%eax
    6b4c:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6b53:	00 
    6b54:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    6b58:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6b5c:	89 54 24 08          	mov    %edx,0x8(%esp)
    6b60:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    6b67:	00 
    6b68:	89 04 24             	mov    %eax,(%esp)
    6b6b:	e8 03 da ff ff       	call   4573 <call_cap_op>
    6b70:	85 c0                	test   %eax,%eax
    6b72:	74 17                	je     6b8b <cos_mem_alias_at+0x90>
    6b74:	c7 04 24 18 12 00 00 	movl   $0x1218,(%esp)
    6b7b:	e8 fe db ff ff       	call   477e <prints>
    6b80:	a1 40 00 00 00       	mov    0x40,%eax
    6b85:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return 0;
    6b8b:	b8 00 00 00 00       	mov    $0x0,%eax
}
    6b90:	83 c4 24             	add    $0x24,%esp
    6b93:	5b                   	pop    %ebx
    6b94:	5d                   	pop    %ebp
    6b95:	c3                   	ret    

00006b96 <cos_mem_remove>:

int
cos_mem_remove(pgtblcap_t pt, vaddr_t addr)
{
    6b96:	55                   	push   %ebp
    6b97:	89 e5                	mov    %esp,%ebp
    6b99:	83 ec 18             	sub    $0x18,%esp
	assert(0);
    6b9c:	c7 04 24 38 12 00 00 	movl   $0x1238,(%esp)
    6ba3:	e8 d6 db ff ff       	call   477e <prints>
    6ba8:	a1 40 00 00 00       	mov    0x40,%eax
    6bad:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6bb3:	e8 4d dc ff ff       	call   4805 <__cos_noret>

00006bb8 <cos_mem_move>:
	return 0;
}

vaddr_t
cos_mem_move(struct cos_compinfo *dstci, struct cos_compinfo *srcci, vaddr_t src)
{
    6bb8:	55                   	push   %ebp
    6bb9:	89 e5                	mov    %esp,%ebp
    6bbb:	53                   	push   %ebx
    6bbc:	83 ec 34             	sub    $0x34,%esp
	vaddr_t dst;

	assert(srcci && dstci);
    6bbf:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    6bc3:	0f 94 c0             	sete   %al
    6bc6:	0f b6 c0             	movzbl %al,%eax
    6bc9:	85 c0                	test   %eax,%eax
    6bcb:	75 0e                	jne    6bdb <cos_mem_move+0x23>
    6bcd:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    6bd1:	0f 94 c0             	sete   %al
    6bd4:	0f b6 c0             	movzbl %al,%eax
    6bd7:	85 c0                	test   %eax,%eax
    6bd9:	74 1c                	je     6bf7 <cos_mem_move+0x3f>
    6bdb:	c7 04 24 68 12 00 00 	movl   $0x1268,(%esp)
    6be2:	e8 97 db ff ff       	call   477e <prints>
    6be7:	a1 40 00 00 00       	mov    0x40,%eax
    6bec:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6bf2:	e8 0e dc ff ff       	call   4805 <__cos_noret>

	dst = __page_bump_valloc(dstci, PAGE_SIZE);
    6bf7:	c7 44 24 04 00 10 00 	movl   $0x1000,0x4(%esp)
    6bfe:	00 
    6bff:	8b 45 08             	mov    0x8(%ebp),%eax
    6c02:	89 04 24             	mov    %eax,(%esp)
    6c05:	e8 39 ec ff ff       	call   5843 <__page_bump_valloc>
    6c0a:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (unlikely(!dst)) return 0;
    6c0d:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    6c11:	0f 94 c0             	sete   %al
    6c14:	0f b6 c0             	movzbl %al,%eax
    6c17:	85 c0                	test   %eax,%eax
    6c19:	74 07                	je     6c22 <cos_mem_move+0x6a>
    6c1b:	b8 00 00 00 00       	mov    $0x0,%eax
    6c20:	eb 54                	jmp    6c76 <cos_mem_move+0xbe>

	if (call_cap_op(srcci->pgtbl_cap, CAPTBL_OP_MEMMOVE, src, dstci->pgtbl_cap, dst, 0)) BUG();
    6c22:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    6c25:	8b 45 08             	mov    0x8(%ebp),%eax
    6c28:	8b 00                	mov    (%eax),%eax
    6c2a:	89 c1                	mov    %eax,%ecx
    6c2c:	8b 55 10             	mov    0x10(%ebp),%edx
    6c2f:	8b 45 0c             	mov    0xc(%ebp),%eax
    6c32:	8b 00                	mov    (%eax),%eax
    6c34:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6c3b:	00 
    6c3c:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    6c40:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6c44:	89 54 24 08          	mov    %edx,0x8(%esp)
    6c48:	c7 44 24 04 1d 00 00 	movl   $0x1d,0x4(%esp)
    6c4f:	00 
    6c50:	89 04 24             	mov    %eax,(%esp)
    6c53:	e8 1b d9 ff ff       	call   4573 <call_cap_op>
    6c58:	85 c0                	test   %eax,%eax
    6c5a:	74 17                	je     6c73 <cos_mem_move+0xbb>
    6c5c:	c7 04 24 98 12 00 00 	movl   $0x1298,(%esp)
    6c63:	e8 16 db ff ff       	call   477e <prints>
    6c68:	a1 40 00 00 00       	mov    0x40,%eax
    6c6d:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return dst;
    6c73:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    6c76:	83 c4 34             	add    $0x34,%esp
    6c79:	5b                   	pop    %ebx
    6c7a:	5d                   	pop    %ebp
    6c7b:	c3                   	ret    

00006c7c <cos_mem_move_at>:

int
cos_mem_move_at(struct cos_compinfo *dstci, vaddr_t dst, struct cos_compinfo *srcci, vaddr_t src)
{
    6c7c:	55                   	push   %ebp
    6c7d:	89 e5                	mov    %esp,%ebp
    6c7f:	53                   	push   %ebx
    6c80:	83 ec 24             	sub    $0x24,%esp
	assert(srcci && dstci);
    6c83:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    6c87:	0f 94 c0             	sete   %al
    6c8a:	0f b6 c0             	movzbl %al,%eax
    6c8d:	85 c0                	test   %eax,%eax
    6c8f:	75 0e                	jne    6c9f <cos_mem_move_at+0x23>
    6c91:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    6c95:	0f 94 c0             	sete   %al
    6c98:	0f b6 c0             	movzbl %al,%eax
    6c9b:	85 c0                	test   %eax,%eax
    6c9d:	74 1c                	je     6cbb <cos_mem_move_at+0x3f>
    6c9f:	c7 04 24 b8 12 00 00 	movl   $0x12b8,(%esp)
    6ca6:	e8 d3 da ff ff       	call   477e <prints>
    6cab:	a1 40 00 00 00       	mov    0x40,%eax
    6cb0:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6cb6:	e8 4a db ff ff       	call   4805 <__cos_noret>

	/* TODO */
	if (call_cap_op(srcci->pgtbl_cap, CAPTBL_OP_MEMMOVE, src, dstci->pgtbl_cap, dst, 0)) BUG();
    6cbb:	8b 5d 0c             	mov    0xc(%ebp),%ebx
    6cbe:	8b 45 08             	mov    0x8(%ebp),%eax
    6cc1:	8b 00                	mov    (%eax),%eax
    6cc3:	89 c1                	mov    %eax,%ecx
    6cc5:	8b 55 14             	mov    0x14(%ebp),%edx
    6cc8:	8b 45 10             	mov    0x10(%ebp),%eax
    6ccb:	8b 00                	mov    (%eax),%eax
    6ccd:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6cd4:	00 
    6cd5:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    6cd9:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6cdd:	89 54 24 08          	mov    %edx,0x8(%esp)
    6ce1:	c7 44 24 04 1d 00 00 	movl   $0x1d,0x4(%esp)
    6ce8:	00 
    6ce9:	89 04 24             	mov    %eax,(%esp)
    6cec:	e8 82 d8 ff ff       	call   4573 <call_cap_op>
    6cf1:	85 c0                	test   %eax,%eax
    6cf3:	74 17                	je     6d0c <cos_mem_move_at+0x90>
    6cf5:	c7 04 24 e8 12 00 00 	movl   $0x12e8,(%esp)
    6cfc:	e8 7d da ff ff       	call   477e <prints>
    6d01:	a1 40 00 00 00       	mov    0x40,%eax
    6d06:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return 0;
    6d0c:	b8 00 00 00 00       	mov    $0x0,%eax
}
    6d11:	83 c4 24             	add    $0x24,%esp
    6d14:	5b                   	pop    %ebx
    6d15:	5d                   	pop    %ebp
    6d16:	c3                   	ret    

00006d17 <cos_thd_mod>:

/* TODO: generalize to modify all state */
int
cos_thd_mod(struct cos_compinfo *ci, thdcap_t tc, void *tlsaddr)
{
    6d17:	55                   	push   %ebp
    6d18:	89 e5                	mov    %esp,%ebp
    6d1a:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(ci->captbl_cap, CAPTBL_OP_THDTLSSET, tc, (int)tlsaddr, 0, 0);
    6d1d:	8b 4d 10             	mov    0x10(%ebp),%ecx
    6d20:	8b 55 0c             	mov    0xc(%ebp),%edx
    6d23:	8b 45 08             	mov    0x8(%ebp),%eax
    6d26:	8b 40 04             	mov    0x4(%eax),%eax
    6d29:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6d30:	00 
    6d31:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    6d38:	00 
    6d39:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6d3d:	89 54 24 08          	mov    %edx,0x8(%esp)
    6d41:	c7 44 24 04 05 00 00 	movl   $0x5,0x4(%esp)
    6d48:	00 
    6d49:	89 04 24             	mov    %eax,(%esp)
    6d4c:	e8 22 d8 ff ff       	call   4573 <call_cap_op>
}
    6d51:	c9                   	leave  
    6d52:	c3                   	ret    

00006d53 <cos_introspect>:

/* FIXME: problems when we got to 64 bit systems with the return value */
int
cos_introspect(struct cos_compinfo *ci, capid_t cap, unsigned long op)
{
    6d53:	55                   	push   %ebp
    6d54:	89 e5                	mov    %esp,%ebp
    6d56:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(ci->captbl_cap, CAPTBL_OP_INTROSPECT, cap, (int)op, 0, 0);
    6d59:	8b 4d 10             	mov    0x10(%ebp),%ecx
    6d5c:	8b 55 0c             	mov    0xc(%ebp),%edx
    6d5f:	8b 45 08             	mov    0x8(%ebp),%eax
    6d62:	8b 40 04             	mov    0x4(%eax),%eax
    6d65:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6d6c:	00 
    6d6d:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    6d74:	00 
    6d75:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    6d79:	89 54 24 08          	mov    %edx,0x8(%esp)
    6d7d:	c7 44 24 04 1e 00 00 	movl   $0x1e,0x4(%esp)
    6d84:	00 
    6d85:	89 04 24             	mov    %eax,(%esp)
    6d88:	e8 e6 d7 ff ff       	call   4573 <call_cap_op>
}
    6d8d:	c9                   	leave  
    6d8e:	c3                   	ret    

00006d8f <cos_tcap_alloc>:

/***************** [Kernel Tcap Operations] *****************/

tcap_t
cos_tcap_alloc(struct cos_compinfo *ci)
{
    6d8f:	55                   	push   %ebp
    6d90:	89 e5                	mov    %esp,%ebp
    6d92:	56                   	push   %esi
    6d93:	53                   	push   %ebx
    6d94:	83 ec 30             	sub    $0x30,%esp
	vaddr_t kmem;
	capid_t cap;

	printd("cos_tcap_alloc\n");
	assert(ci);
    6d97:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    6d9b:	0f 94 c0             	sete   %al
    6d9e:	0f b6 c0             	movzbl %al,%eax
    6da1:	85 c0                	test   %eax,%eax
    6da3:	74 1c                	je     6dc1 <cos_tcap_alloc+0x32>
    6da5:	c7 04 24 08 13 00 00 	movl   $0x1308,(%esp)
    6dac:	e8 cd d9 ff ff       	call   477e <prints>
    6db1:	a1 40 00 00 00       	mov    0x40,%eax
    6db6:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    6dbc:	e8 44 da ff ff       	call   4805 <__cos_noret>

	if (__alloc_mem_cap(ci, CAP_TCAP, &kmem, &cap)) return 0;
    6dc1:	8d 45 f0             	lea    -0x10(%ebp),%eax
    6dc4:	89 44 24 0c          	mov    %eax,0xc(%esp)
    6dc8:	8d 45 f4             	lea    -0xc(%ebp),%eax
    6dcb:	89 44 24 08          	mov    %eax,0x8(%esp)
    6dcf:	c7 44 24 04 0c 00 00 	movl   $0xc,0x4(%esp)
    6dd6:	00 
    6dd7:	8b 45 08             	mov    0x8(%ebp),%eax
    6dda:	89 04 24             	mov    %eax,(%esp)
    6ddd:	e8 da eb ff ff       	call   59bc <__alloc_mem_cap>
    6de2:	85 c0                	test   %eax,%eax
    6de4:	74 07                	je     6ded <cos_tcap_alloc+0x5e>
    6de6:	b8 00 00 00 00       	mov    $0x0,%eax
    6deb:	eb 6b                	jmp    6e58 <cos_tcap_alloc+0xc9>
	/* TODO: Add cap size checking */
	if (call_cap_op(ci->captbl_cap, CAPTBL_OP_TCAP_ACTIVATE, (cap << 16) | __compinfo_metacap(ci)->mi.pgtbl_cap,
    6ded:	8b 45 f4             	mov    -0xc(%ebp),%eax
    6df0:	89 c3                	mov    %eax,%ebx
    6df2:	8b 45 f0             	mov    -0x10(%ebp),%eax
    6df5:	c1 e0 10             	shl    $0x10,%eax
    6df8:	89 c6                	mov    %eax,%esi
    6dfa:	8b 45 08             	mov    0x8(%ebp),%eax
    6dfd:	89 04 24             	mov    %eax,(%esp)
    6e00:	e8 dc da ff ff       	call   48e1 <__compinfo_metacap>
    6e05:	8b 40 44             	mov    0x44(%eax),%eax
    6e08:	09 f0                	or     %esi,%eax
    6e0a:	89 c2                	mov    %eax,%edx
    6e0c:	8b 45 08             	mov    0x8(%ebp),%eax
    6e0f:	8b 40 04             	mov    0x4(%eax),%eax
    6e12:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6e19:	00 
    6e1a:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    6e21:	00 
    6e22:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    6e26:	89 54 24 08          	mov    %edx,0x8(%esp)
    6e2a:	c7 44 24 04 1f 00 00 	movl   $0x1f,0x4(%esp)
    6e31:	00 
    6e32:	89 04 24             	mov    %eax,(%esp)
    6e35:	e8 39 d7 ff ff       	call   4573 <call_cap_op>
    6e3a:	85 c0                	test   %eax,%eax
    6e3c:	74 17                	je     6e55 <cos_tcap_alloc+0xc6>
	                kmem, 0, 0))
		BUG();
    6e3e:	c7 04 24 38 13 00 00 	movl   $0x1338,(%esp)
    6e45:	e8 34 d9 ff ff       	call   477e <prints>
    6e4a:	a1 40 00 00 00       	mov    0x40,%eax
    6e4f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	return cap;
    6e55:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    6e58:	83 c4 30             	add    $0x30,%esp
    6e5b:	5b                   	pop    %ebx
    6e5c:	5e                   	pop    %esi
    6e5d:	5d                   	pop    %ebp
    6e5e:	c3                   	ret    

00006e5f <cos_tcap_transfer>:

int
cos_tcap_transfer(arcvcap_t dst, tcap_t src, tcap_res_t res, tcap_prio_t prio)
{
    6e5f:	55                   	push   %ebp
    6e60:	89 e5                	mov    %esp,%ebp
    6e62:	83 ec 30             	sub    $0x30,%esp
    6e65:	8b 45 14             	mov    0x14(%ebp),%eax
    6e68:	89 45 e8             	mov    %eax,-0x18(%ebp)
    6e6b:	8b 45 18             	mov    0x18(%ebp),%eax
    6e6e:	89 45 ec             	mov    %eax,-0x14(%ebp)
	int prio_higher = (u32_t)(prio >> 32);
    6e71:	8b 45 e8             	mov    -0x18(%ebp),%eax
    6e74:	8b 55 ec             	mov    -0x14(%ebp),%edx
    6e77:	89 d0                	mov    %edx,%eax
    6e79:	31 d2                	xor    %edx,%edx
    6e7b:	89 45 fc             	mov    %eax,-0x4(%ebp)
	int prio_lower  = (u32_t)((prio << 32) >> 32);
    6e7e:	8b 45 e8             	mov    -0x18(%ebp),%eax
    6e81:	89 45 f8             	mov    %eax,-0x8(%ebp)

	return call_cap_op(src, CAPTBL_OP_TCAP_TRANSFER, dst, res, prio_higher, prio_lower);
    6e84:	8b 55 10             	mov    0x10(%ebp),%edx
    6e87:	8b 45 08             	mov    0x8(%ebp),%eax
    6e8a:	8b 4d f8             	mov    -0x8(%ebp),%ecx
    6e8d:	89 4c 24 14          	mov    %ecx,0x14(%esp)
    6e91:	8b 4d fc             	mov    -0x4(%ebp),%ecx
    6e94:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    6e98:	89 54 24 0c          	mov    %edx,0xc(%esp)
    6e9c:	89 44 24 08          	mov    %eax,0x8(%esp)
    6ea0:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
    6ea7:	00 
    6ea8:	8b 45 0c             	mov    0xc(%ebp),%eax
    6eab:	89 04 24             	mov    %eax,(%esp)
    6eae:	e8 c0 d6 ff ff       	call   4573 <call_cap_op>
}
    6eb3:	c9                   	leave  
    6eb4:	c3                   	ret    

00006eb5 <cos_tcap_delegate>:

int
cos_tcap_delegate(asndcap_t dst, tcap_t src, tcap_res_t res, tcap_prio_t prio, tcap_deleg_flags_t flags)
{
    6eb5:	55                   	push   %ebp
    6eb6:	89 e5                	mov    %esp,%ebp
    6eb8:	83 ec 30             	sub    $0x30,%esp
    6ebb:	8b 45 14             	mov    0x14(%ebp),%eax
    6ebe:	89 45 e8             	mov    %eax,-0x18(%ebp)
    6ec1:	8b 45 18             	mov    0x18(%ebp),%eax
    6ec4:	89 45 ec             	mov    %eax,-0x14(%ebp)
	u32_t yield = ((flags & TCAP_DELEG_YIELD) != 0);
    6ec7:	8b 45 1c             	mov    0x1c(%ebp),%eax
    6eca:	83 e0 02             	and    $0x2,%eax
    6ecd:	85 c0                	test   %eax,%eax
    6ecf:	0f 95 c0             	setne  %al
    6ed2:	0f b6 c0             	movzbl %al,%eax
    6ed5:	89 45 fc             	mov    %eax,-0x4(%ebp)
	/* top bit is if we are dispatching or not */
	int prio_higher = (u32_t)(prio >> 32) | (yield << ((sizeof(yield) * 8) - 1));
    6ed8:	8b 45 e8             	mov    -0x18(%ebp),%eax
    6edb:	8b 55 ec             	mov    -0x14(%ebp),%edx
    6ede:	89 d0                	mov    %edx,%eax
    6ee0:	31 d2                	xor    %edx,%edx
    6ee2:	8b 55 fc             	mov    -0x4(%ebp),%edx
    6ee5:	c1 e2 1f             	shl    $0x1f,%edx
    6ee8:	09 d0                	or     %edx,%eax
    6eea:	89 45 f8             	mov    %eax,-0x8(%ebp)
	int prio_lower  = (u32_t)((prio << 32) >> 32);
    6eed:	8b 45 e8             	mov    -0x18(%ebp),%eax
    6ef0:	89 45 f4             	mov    %eax,-0xc(%ebp)

	return call_cap_op(src, CAPTBL_OP_TCAP_DELEGATE, dst, res, prio_higher, prio_lower);
    6ef3:	8b 55 10             	mov    0x10(%ebp),%edx
    6ef6:	8b 45 08             	mov    0x8(%ebp),%eax
    6ef9:	8b 4d f4             	mov    -0xc(%ebp),%ecx
    6efc:	89 4c 24 14          	mov    %ecx,0x14(%esp)
    6f00:	8b 4d f8             	mov    -0x8(%ebp),%ecx
    6f03:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    6f07:	89 54 24 0c          	mov    %edx,0xc(%esp)
    6f0b:	89 44 24 08          	mov    %eax,0x8(%esp)
    6f0f:	c7 44 24 04 21 00 00 	movl   $0x21,0x4(%esp)
    6f16:	00 
    6f17:	8b 45 0c             	mov    0xc(%ebp),%eax
    6f1a:	89 04 24             	mov    %eax,(%esp)
    6f1d:	e8 51 d6 ff ff       	call   4573 <call_cap_op>
}
    6f22:	c9                   	leave  
    6f23:	c3                   	ret    

00006f24 <cos_tcap_merge>:

int
cos_tcap_merge(tcap_t dst, tcap_t rm)
{
    6f24:	55                   	push   %ebp
    6f25:	89 e5                	mov    %esp,%ebp
    6f27:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(dst, CAPTBL_OP_TCAP_MERGE, rm, 0, 0, 0);
    6f2a:	8b 45 0c             	mov    0xc(%ebp),%eax
    6f2d:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6f34:	00 
    6f35:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    6f3c:	00 
    6f3d:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    6f44:	00 
    6f45:	89 44 24 08          	mov    %eax,0x8(%esp)
    6f49:	c7 44 24 04 22 00 00 	movl   $0x22,0x4(%esp)
    6f50:	00 
    6f51:	8b 45 08             	mov    0x8(%ebp),%eax
    6f54:	89 04 24             	mov    %eax,(%esp)
    6f57:	e8 17 d6 ff ff       	call   4573 <call_cap_op>
}
    6f5c:	c9                   	leave  
    6f5d:	c3                   	ret    

00006f5e <cos_hw_attach>:

int
cos_hw_attach(hwcap_t hwc, hwid_t hwid, arcvcap_t arcv)
{
    6f5e:	55                   	push   %ebp
    6f5f:	89 e5                	mov    %esp,%ebp
    6f61:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(hwc, CAPTBL_OP_HW_ATTACH, hwid, arcv, 0, 0);
    6f64:	8b 55 10             	mov    0x10(%ebp),%edx
    6f67:	8b 45 0c             	mov    0xc(%ebp),%eax
    6f6a:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6f71:	00 
    6f72:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    6f79:	00 
    6f7a:	89 54 24 0c          	mov    %edx,0xc(%esp)
    6f7e:	89 44 24 08          	mov    %eax,0x8(%esp)
    6f82:	c7 44 24 04 26 00 00 	movl   $0x26,0x4(%esp)
    6f89:	00 
    6f8a:	8b 45 08             	mov    0x8(%ebp),%eax
    6f8d:	89 04 24             	mov    %eax,(%esp)
    6f90:	e8 de d5 ff ff       	call   4573 <call_cap_op>
}
    6f95:	c9                   	leave  
    6f96:	c3                   	ret    

00006f97 <cos_hw_detach>:

int
cos_hw_detach(hwcap_t hwc, hwid_t hwid)
{
    6f97:	55                   	push   %ebp
    6f98:	89 e5                	mov    %esp,%ebp
    6f9a:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(hwc, CAPTBL_OP_HW_DETACH, hwid, 0, 0, 0);
    6f9d:	8b 45 0c             	mov    0xc(%ebp),%eax
    6fa0:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6fa7:	00 
    6fa8:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    6faf:	00 
    6fb0:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    6fb7:	00 
    6fb8:	89 44 24 08          	mov    %eax,0x8(%esp)
    6fbc:	c7 44 24 04 27 00 00 	movl   $0x27,0x4(%esp)
    6fc3:	00 
    6fc4:	8b 45 08             	mov    0x8(%ebp),%eax
    6fc7:	89 04 24             	mov    %eax,(%esp)
    6fca:	e8 a4 d5 ff ff       	call   4573 <call_cap_op>
}
    6fcf:	c9                   	leave  
    6fd0:	c3                   	ret    

00006fd1 <cos_hw_cycles_per_usec>:

int
cos_hw_cycles_per_usec(hwcap_t hwc)
{
    6fd1:	55                   	push   %ebp
    6fd2:	89 e5                	mov    %esp,%ebp
    6fd4:	83 ec 18             	sub    $0x18,%esp
	static int cycs = 0;

	while (cycs <= 0) cycs = call_cap_op(hwc, CAPTBL_OP_HW_CYC_USEC, 0, 0, 0, 0);
    6fd7:	eb 38                	jmp    7011 <cos_hw_cycles_per_usec+0x40>
    6fd9:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    6fe0:	00 
    6fe1:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    6fe8:	00 
    6fe9:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    6ff0:	00 
    6ff1:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    6ff8:	00 
    6ff9:	c7 44 24 04 29 00 00 	movl   $0x29,0x4(%esp)
    7000:	00 
    7001:	8b 45 08             	mov    0x8(%ebp),%eax
    7004:	89 04 24             	mov    %eax,(%esp)
    7007:	e8 67 d5 ff ff       	call   4573 <call_cap_op>
    700c:	a3 84 00 00 00       	mov    %eax,0x84
    7011:	a1 84 00 00 00       	mov    0x84,%eax
    7016:	85 c0                	test   %eax,%eax
    7018:	7e bf                	jle    6fd9 <cos_hw_cycles_per_usec+0x8>

	return cycs;
    701a:	a1 84 00 00 00       	mov    0x84,%eax
}
    701f:	c9                   	leave  
    7020:	c3                   	ret    

00007021 <cos_hw_cycles_thresh>:

int
cos_hw_cycles_thresh(hwcap_t hwc)
{
    7021:	55                   	push   %ebp
    7022:	89 e5                	mov    %esp,%ebp
    7024:	83 ec 18             	sub    $0x18,%esp
	return call_cap_op(hwc, CAPTBL_OP_HW_CYC_THRESH, 0, 0, 0, 0);
    7027:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    702e:	00 
    702f:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    7036:	00 
    7037:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    703e:	00 
    703f:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    7046:	00 
    7047:	c7 44 24 04 2a 00 00 	movl   $0x2a,0x4(%esp)
    704e:	00 
    704f:	8b 45 08             	mov    0x8(%ebp),%eax
    7052:	89 04 24             	mov    %eax,(%esp)
    7055:	e8 19 d5 ff ff       	call   4573 <call_cap_op>
}
    705a:	c9                   	leave  
    705b:	c3                   	ret    

0000705c <cos_hw_map>:

void *
cos_hw_map(struct cos_compinfo *ci, hwcap_t hwc, paddr_t pa, unsigned int len)
{
    705c:	55                   	push   %ebp
    705d:	89 e5                	mov    %esp,%ebp
    705f:	83 ec 38             	sub    $0x38,%esp
	size_t  sz, i;
	vaddr_t va;

	assert(ci && hwc && pa && len);
    7062:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    7066:	0f 94 c0             	sete   %al
    7069:	0f b6 c0             	movzbl %al,%eax
    706c:	85 c0                	test   %eax,%eax
    706e:	75 0e                	jne    707e <cos_hw_map+0x22>
    7070:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    7074:	0f 94 c0             	sete   %al
    7077:	0f b6 c0             	movzbl %al,%eax
    707a:	85 c0                	test   %eax,%eax
    707c:	74 07                	je     7085 <cos_hw_map+0x29>
    707e:	b8 01 00 00 00       	mov    $0x1,%eax
    7083:	eb 05                	jmp    708a <cos_hw_map+0x2e>
    7085:	b8 00 00 00 00       	mov    $0x0,%eax
    708a:	85 c0                	test   %eax,%eax
    708c:	75 0e                	jne    709c <cos_hw_map+0x40>
    708e:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    7092:	0f 94 c0             	sete   %al
    7095:	0f b6 c0             	movzbl %al,%eax
    7098:	85 c0                	test   %eax,%eax
    709a:	74 07                	je     70a3 <cos_hw_map+0x47>
    709c:	b8 01 00 00 00       	mov    $0x1,%eax
    70a1:	eb 05                	jmp    70a8 <cos_hw_map+0x4c>
    70a3:	b8 00 00 00 00       	mov    $0x0,%eax
    70a8:	85 c0                	test   %eax,%eax
    70aa:	75 0e                	jne    70ba <cos_hw_map+0x5e>
    70ac:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
    70b0:	0f 94 c0             	sete   %al
    70b3:	0f b6 c0             	movzbl %al,%eax
    70b6:	85 c0                	test   %eax,%eax
    70b8:	74 1c                	je     70d6 <cos_hw_map+0x7a>
    70ba:	c7 04 24 58 13 00 00 	movl   $0x1358,(%esp)
    70c1:	e8 b8 d6 ff ff       	call   477e <prints>
    70c6:	a1 40 00 00 00       	mov    0x40,%eax
    70cb:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    70d1:	e8 2f d7 ff ff       	call   4805 <__cos_noret>

	sz = round_up_to_page(len);
    70d6:	8b 45 14             	mov    0x14(%ebp),%eax
    70d9:	05 ff 0f 00 00       	add    $0xfff,%eax
    70de:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    70e3:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va = __page_bump_valloc(ci, sz);
    70e6:	8b 45 f0             	mov    -0x10(%ebp),%eax
    70e9:	89 44 24 04          	mov    %eax,0x4(%esp)
    70ed:	8b 45 08             	mov    0x8(%ebp),%eax
    70f0:	89 04 24             	mov    %eax,(%esp)
    70f3:	e8 4b e7 ff ff       	call   5843 <__page_bump_valloc>
    70f8:	89 45 ec             	mov    %eax,-0x14(%ebp)
	if (unlikely(!va)) return NULL;
    70fb:	83 7d ec 00          	cmpl   $0x0,-0x14(%ebp)
    70ff:	0f 94 c0             	sete   %al
    7102:	0f b6 c0             	movzbl %al,%eax
    7105:	85 c0                	test   %eax,%eax
    7107:	74 07                	je     7110 <cos_hw_map+0xb4>
    7109:	b8 00 00 00 00       	mov    $0x0,%eax
    710e:	eb 76                	jmp    7186 <cos_hw_map+0x12a>

	for (i = 0; i < sz; i += PAGE_SIZE) {
    7110:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    7117:	eb 62                	jmp    717b <cos_hw_map+0x11f>
		if (call_cap_op(hwc, CAPTBL_OP_HW_MAP, ci->pgtbl_cap, va + i, pa + i, 0)) BUG();
    7119:	8b 45 f4             	mov    -0xc(%ebp),%eax
    711c:	8b 55 10             	mov    0x10(%ebp),%edx
    711f:	01 d0                	add    %edx,%eax
    7121:	89 c1                	mov    %eax,%ecx
    7123:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7126:	8b 55 ec             	mov    -0x14(%ebp),%edx
    7129:	01 d0                	add    %edx,%eax
    712b:	89 c2                	mov    %eax,%edx
    712d:	8b 45 08             	mov    0x8(%ebp),%eax
    7130:	8b 00                	mov    (%eax),%eax
    7132:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    7139:	00 
    713a:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    713e:	89 54 24 0c          	mov    %edx,0xc(%esp)
    7142:	89 44 24 08          	mov    %eax,0x8(%esp)
    7146:	c7 44 24 04 28 00 00 	movl   $0x28,0x4(%esp)
    714d:	00 
    714e:	8b 45 0c             	mov    0xc(%ebp),%eax
    7151:	89 04 24             	mov    %eax,(%esp)
    7154:	e8 1a d4 ff ff       	call   4573 <call_cap_op>
    7159:	85 c0                	test   %eax,%eax
    715b:	74 17                	je     7174 <cos_hw_map+0x118>
    715d:	c7 04 24 89 13 00 00 	movl   $0x1389,(%esp)
    7164:	e8 15 d6 ff ff       	call   477e <prints>
    7169:	a1 40 00 00 00       	mov    0x40,%eax
    716e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	sz = round_up_to_page(len);
	va = __page_bump_valloc(ci, sz);
	if (unlikely(!va)) return NULL;

	for (i = 0; i < sz; i += PAGE_SIZE) {
    7174:	81 45 f4 00 10 00 00 	addl   $0x1000,-0xc(%ebp)
    717b:	8b 45 f4             	mov    -0xc(%ebp),%eax
    717e:	3b 45 f0             	cmp    -0x10(%ebp),%eax
    7181:	72 96                	jb     7119 <cos_hw_map+0xbd>
		if (call_cap_op(hwc, CAPTBL_OP_HW_MAP, ci->pgtbl_cap, va + i, pa + i, 0)) BUG();
	}

	return (void *)va;
    7183:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    7186:	c9                   	leave  
    7187:	c3                   	ret    

00007188 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
    7188:	55                   	push   %ebp
    7189:	89 e5                	mov    %esp,%ebp
    718b:	57                   	push   %edi
    718c:	56                   	push   %esi
    718d:	53                   	push   %ebx
    718e:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    7191:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    7198:	8b 45 08             	mov    0x8(%ebp),%eax
    719b:	83 c0 01             	add    $0x1,%eax
    719e:	c1 e0 10             	shl    $0x10,%eax
    71a1:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    71a4:	8b 45 0c             	mov    0xc(%ebp),%eax
    71a7:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    71aa:	8b 45 08             	mov    0x8(%ebp),%eax
    71ad:	8b 4d 10             	mov    0x10(%ebp),%ecx
    71b0:	8b 75 14             	mov    0x14(%ebp),%esi
    71b3:	8b 7d 18             	mov    0x18(%ebp),%edi
    71b6:	8b 55 1c             	mov    0x1c(%ebp),%edx
    71b9:	89 cb                	mov    %ecx,%ebx
    71bb:	55                   	push   %ebp
    71bc:	89 e5                	mov    %esp,%ebp
    71be:	b9 d0 71 00 00       	mov    $0x71d0,%ecx
    71c3:	0f 34                	sysenter 
    71c5:	8d 76 00             	lea    0x0(%esi),%esi
    71c8:	eb 0d                	jmp    71d7 <call_cap_asm+0x4f>
    71ca:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    71d0:	b9 00 00 00 00       	mov    $0x0,%ecx
    71d5:	eb 05                	jmp    71dc <call_cap_asm+0x54>
    71d7:	b9 01 00 00 00       	mov    $0x1,%ecx
    71dc:	5d                   	pop    %ebp
    71dd:	89 ca                	mov    %ecx,%edx
    71df:	89 45 ec             	mov    %eax,-0x14(%ebp)
    71e2:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    71e5:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    71e8:	83 c4 10             	add    $0x10,%esp
    71eb:	5b                   	pop    %ebx
    71ec:	5e                   	pop    %esi
    71ed:	5f                   	pop    %edi
    71ee:	5d                   	pop    %ebp
    71ef:	c3                   	ret    

000071f0 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
    71f0:	55                   	push   %ebp
    71f1:	89 e5                	mov    %esp,%ebp
    71f3:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
    71f6:	8b 45 18             	mov    0x18(%ebp),%eax
    71f9:	89 44 24 14          	mov    %eax,0x14(%esp)
    71fd:	8b 45 14             	mov    0x14(%ebp),%eax
    7200:	89 44 24 10          	mov    %eax,0x10(%esp)
    7204:	8b 45 10             	mov    0x10(%ebp),%eax
    7207:	89 44 24 0c          	mov    %eax,0xc(%esp)
    720b:	8b 45 0c             	mov    0xc(%ebp),%eax
    720e:	89 44 24 08          	mov    %eax,0x8(%esp)
    7212:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    7219:	00 
    721a:	8b 45 08             	mov    0x8(%ebp),%eax
    721d:	89 04 24             	mov    %eax,(%esp)
    7220:	e8 63 ff ff ff       	call   7188 <call_cap_asm>
}
    7225:	c9                   	leave  
    7226:	c3                   	ret    

00007227 <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
    7227:	55                   	push   %ebp
    7228:	89 e5                	mov    %esp,%ebp
    722a:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
    722d:	8b 45 08             	mov    0x8(%ebp),%eax
    7230:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    7237:	00 
    7238:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    723f:	00 
    7240:	8b 55 0c             	mov    0xc(%ebp),%edx
    7243:	89 54 24 08          	mov    %edx,0x8(%esp)
    7247:	89 44 24 04          	mov    %eax,0x4(%esp)
    724b:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    7252:	e8 99 ff ff ff       	call   71f0 <call_cap>
}
    7257:	c9                   	leave  
    7258:	c3                   	ret    

00007259 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
    7259:	55                   	push   %ebp
    725a:	89 e5                	mov    %esp,%ebp
    725c:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
    725f:	89 e0                	mov    %esp,%eax
    7261:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
    7264:	8b 45 fc             	mov    -0x4(%ebp),%eax
    7267:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    726c:	89 c2                	mov    %eax,%edx
    726e:	8b 45 08             	mov    0x8(%ebp),%eax
    7271:	c1 e0 02             	shl    $0x2,%eax
    7274:	29 c2                	sub    %eax,%edx
    7276:	89 d0                	mov    %edx,%eax
    7278:	05 00 10 00 00       	add    $0x1000,%eax
    727d:	8b 00                	mov    (%eax),%eax
}
    727f:	c9                   	leave  
    7280:	c3                   	ret    

00007281 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
    7281:	55                   	push   %ebp
    7282:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
    7284:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
    7289:	5d                   	pop    %ebp
    728a:	c3                   	ret    

0000728b <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
    728b:	55                   	push   %ebp
    728c:	89 e5                	mov    %esp,%ebp
    728e:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
    7291:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    7298:	e8 bc ff ff ff       	call   7259 <get_stk_data>
}
    729d:	c9                   	leave  
    729e:	c3                   	ret    

0000729f <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
    729f:	55                   	push   %ebp
    72a0:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
    72a2:	e8 e4 ff ff ff       	call   728b <cos_get_thd_id>
}
    72a7:	5d                   	pop    %ebp
    72a8:	c3                   	ret    

000072a9 <cos_get_heap_ptr>:
	return cos_comp_info.cos_this_spd_id;
}

static inline void *
cos_get_heap_ptr(void)
{
    72a9:	55                   	push   %ebp
    72aa:	89 e5                	mov    %esp,%ebp
	return (void *)cos_comp_info.cos_heap_ptr;
    72ac:	a1 54 00 00 00       	mov    0x54,%eax
}
    72b1:	5d                   	pop    %ebp
    72b2:	c3                   	ret    

000072b3 <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
    72b3:	55                   	push   %ebp
    72b4:	89 e5                	mov    %esp,%ebp
    72b6:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
    72b9:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    72c0:	eb 20                	jmp    72e2 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
    72c2:	8b 45 f4             	mov    -0xc(%ebp),%eax
    72c5:	83 c0 01             	add    $0x1,%eax
    72c8:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    72cf:	8b 45 08             	mov    0x8(%ebp),%eax
    72d2:	01 d0                	add    %edx,%eax
    72d4:	8b 00                	mov    (%eax),%eax
    72d6:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
    72d9:	8b 45 f0             	mov    -0x10(%ebp),%eax
    72dc:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
    72de:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    72e2:	8b 45 08             	mov    0x8(%ebp),%eax
    72e5:	8b 00                	mov    (%eax),%eax
    72e7:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    72ea:	7f d6                	jg     72c2 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
    72ec:	c9                   	leave  
    72ed:	c3                   	ret    

000072ee <constructors_execute>:

static void
constructors_execute(void)
{
    72ee:	55                   	push   %ebp
    72ef:	89 e5                	mov    %esp,%ebp
    72f1:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
    72f4:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    72fb:	e8 b3 ff ff ff       	call   72b3 <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
    7300:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    7307:	e8 a7 ff ff ff       	call   72b3 <section_fnptrs_execute>
}
    730c:	c9                   	leave  
    730d:	c3                   	ret    

0000730e <destructors_execute>:
static void
destructors_execute(void)
{
    730e:	55                   	push   %ebp
    730f:	89 e5                	mov    %esp,%ebp
    7311:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
    7314:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    731b:	e8 93 ff ff ff       	call   72b3 <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
    7320:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    7327:	e8 87 ff ff ff       	call   72b3 <section_fnptrs_execute>
}
    732c:	c9                   	leave  
    732d:	c3                   	ret    

0000732e <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
    732e:	55                   	push   %ebp
    732f:	89 e5                	mov    %esp,%ebp
    7331:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
    7334:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    733b:	e8 73 ff ff ff       	call   72b3 <section_fnptrs_execute>
}
    7340:	c9                   	leave  
    7341:	c3                   	ret    

00007342 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
    7342:	55                   	push   %ebp
    7343:	89 e5                	mov    %esp,%ebp
    7345:	83 ec 08             	sub    $0x8,%esp
    7348:	8b 55 08             	mov    0x8(%ebp),%edx
    734b:	8b 45 0c             	mov    0xc(%ebp),%eax
    734e:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
    7352:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
    7355:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    7359:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
    735d:	ee                   	out    %al,(%dx)
}
    735e:	c9                   	leave  
    735f:	c3                   	ret    

00007360 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
    7360:	55                   	push   %ebp
    7361:	89 e5                	mov    %esp,%ebp
    7363:	83 ec 14             	sub    $0x14,%esp
    7366:	8b 45 08             	mov    0x8(%ebp),%eax
    7369:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
    736d:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
    7371:	89 c2                	mov    %eax,%edx
    7373:	ec                   	in     (%dx),%al
    7374:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
    7377:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
    737b:	c9                   	leave  
    737c:	c3                   	ret    

0000737d <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
    737d:	55                   	push   %ebp
    737e:	89 e5                	mov    %esp,%ebp
    7380:	83 ec 0c             	sub    $0xc,%esp
    7383:	8b 45 08             	mov    0x8(%ebp),%eax
    7386:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
    7389:	90                   	nop
    738a:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
    7391:	e8 ca ff ff ff       	call   7360 <inb>
    7396:	0f b6 c0             	movzbl %al,%eax
    7399:	83 e0 20             	and    $0x20,%eax
    739c:	85 c0                	test   %eax,%eax
    739e:	74 ea                	je     738a <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
    73a0:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    73a4:	0f b6 c0             	movzbl %al,%eax
    73a7:	89 44 24 04          	mov    %eax,0x4(%esp)
    73ab:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
    73b2:	e8 8b ff ff ff       	call   7342 <outb>
}
    73b7:	c9                   	leave  
    73b8:	c3                   	ret    

000073b9 <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
    73b9:	55                   	push   %ebp
    73ba:	89 e5                	mov    %esp,%ebp
    73bc:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
    73bf:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
    73c6:	eb 1a                	jmp    73e2 <cos_serial_putb+0x29>
    73c8:	8b 45 fc             	mov    -0x4(%ebp),%eax
    73cb:	8b 55 08             	mov    0x8(%ebp),%edx
    73ce:	01 d0                	add    %edx,%eax
    73d0:	0f b6 00             	movzbl (%eax),%eax
    73d3:	0f be c0             	movsbl %al,%eax
    73d6:	89 04 24             	mov    %eax,(%esp)
    73d9:	e8 9f ff ff ff       	call   737d <cos_serial_putc>
    73de:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
    73e2:	8b 45 fc             	mov    -0x4(%ebp),%eax
    73e5:	3b 45 0c             	cmp    0xc(%ebp),%eax
    73e8:	72 de                	jb     73c8 <cos_serial_putb+0xf>
}
    73ea:	c9                   	leave  
    73eb:	c3                   	ret    

000073ec <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
    73ec:	55                   	push   %ebp
    73ed:	89 e5                	mov    %esp,%ebp
    73ef:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
    73f2:	8b 45 0c             	mov    0xc(%ebp),%eax
    73f5:	89 44 24 04          	mov    %eax,0x4(%esp)
    73f9:	8b 45 08             	mov    0x8(%ebp),%eax
    73fc:	89 04 24             	mov    %eax,(%esp)
    73ff:	e8 b5 ff ff ff       	call   73b9 <cos_serial_putb>
}
    7404:	c9                   	leave  
    7405:	c3                   	ret    

00007406 <prints>:

static int
prints(char *s)
{
    7406:	55                   	push   %ebp
    7407:	89 e5                	mov    %esp,%ebp
    7409:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
    740c:	8b 45 08             	mov    0x8(%ebp),%eax
    740f:	89 04 24             	mov    %eax,(%esp)
    7412:	e8 fc ff ff ff       	call   7413 <prints+0xd>
    7417:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
    741a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    741d:	89 44 24 04          	mov    %eax,0x4(%esp)
    7421:	8b 45 08             	mov    0x8(%ebp),%eax
    7424:	89 04 24             	mov    %eax,(%esp)
    7427:	e8 fb fd ff ff       	call   7227 <cos_print>

	return len;
    742c:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    742f:	c9                   	leave  
    7430:	c3                   	ret    

00007431 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
    7431:	55                   	push   %ebp
    7432:	89 e5                	mov    %esp,%ebp
    7434:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
    743a:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
    7441:	8d 45 0c             	lea    0xc(%ebp),%eax
    7444:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
    744a:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
    7450:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7454:	8b 45 08             	mov    0x8(%ebp),%eax
    7457:	89 44 24 08          	mov    %eax,0x8(%esp)
    745b:	8b 45 f4             	mov    -0xc(%ebp),%eax
    745e:	89 44 24 04          	mov    %eax,0x4(%esp)
    7462:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    7468:	89 04 24             	mov    %eax,(%esp)
    746b:	e8 fc ff ff ff       	call   746c <printc+0x3b>
    7470:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
    7473:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7476:	89 44 24 04          	mov    %eax,0x4(%esp)
    747a:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    7480:	89 04 24             	mov    %eax,(%esp)
    7483:	e8 64 ff ff ff       	call   73ec <cos_llprint>

	return ret;
    7488:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    748b:	c9                   	leave  
    748c:	c3                   	ret    

0000748d <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
    748d:	55                   	push   %ebp
    748e:	89 e5                	mov    %esp,%ebp
	while (1)
		;
    7490:	eb fe                	jmp    7490 <__cos_noret+0x3>

00007492 <cos_aepthd_fn>:
	struct cos_aep_info sched_aep[NUM_CPU];
};

static void
cos_aepthd_fn(void *data)
{
    7492:	55                   	push   %ebp
    7493:	89 e5                	mov    %esp,%ebp
    7495:	83 ec 28             	sub    $0x28,%esp
	struct cos_aep_info *aep_info = (struct cos_aep_info *)data;
    7498:	8b 45 08             	mov    0x8(%ebp),%eax
    749b:	89 45 f4             	mov    %eax,-0xc(%ebp)
	cos_aepthd_fn_t      aep_fn   = aep_info->fn;
    749e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    74a1:	8b 40 10             	mov    0x10(%eax),%eax
    74a4:	89 45 f0             	mov    %eax,-0x10(%ebp)
	void *               fn_data  = aep_info->data;
    74a7:	8b 45 f4             	mov    -0xc(%ebp),%eax
    74aa:	8b 40 14             	mov    0x14(%eax),%eax
    74ad:	89 45 ec             	mov    %eax,-0x14(%ebp)

	(aep_fn)(aep_info->rcv, fn_data);
    74b0:	8b 45 f4             	mov    -0xc(%ebp),%eax
    74b3:	8b 40 0c             	mov    0xc(%eax),%eax
    74b6:	8b 55 ec             	mov    -0x14(%ebp),%edx
    74b9:	89 54 24 04          	mov    %edx,0x4(%esp)
    74bd:	89 04 24             	mov    %eax,(%esp)
    74c0:	8b 45 f0             	mov    -0x10(%ebp),%eax
    74c3:	ff d0                	call   *%eax

	/* TODO: handling destruction */
	assert(0);
    74c5:	c7 04 24 a8 13 00 00 	movl   $0x13a8,(%esp)
    74cc:	e8 35 ff ff ff       	call   7406 <prints>
    74d1:	a1 a0 00 00 00       	mov    0xa0,%eax
    74d6:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    74dc:	e8 ac ff ff ff       	call   748d <__cos_noret>

000074e1 <cos_defcompinfo_curr_get>:
static int                    curr_defci_init_status;
static struct cos_defcompinfo curr_defci;

struct cos_defcompinfo *
cos_defcompinfo_curr_get(void)
{
    74e1:	55                   	push   %ebp
    74e2:	89 e5                	mov    %esp,%ebp
	return &curr_defci;
    74e4:	b8 c0 00 00 00       	mov    $0xc0,%eax
}
    74e9:	5d                   	pop    %ebp
    74ea:	c3                   	ret    

000074eb <cos_compinfo_get>:

struct cos_compinfo *
cos_compinfo_get(struct cos_defcompinfo *defci)
{
    74eb:	55                   	push   %ebp
    74ec:	89 e5                	mov    %esp,%ebp
    74ee:	83 ec 18             	sub    $0x18,%esp
	assert(defci);
    74f1:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    74f5:	0f 94 c0             	sete   %al
    74f8:	0f b6 c0             	movzbl %al,%eax
    74fb:	85 c0                	test   %eax,%eax
    74fd:	74 1c                	je     751b <cos_compinfo_get+0x30>
    74ff:	c7 04 24 0c 14 00 00 	movl   $0x140c,(%esp)
    7506:	e8 fb fe ff ff       	call   7406 <prints>
    750b:	a1 a0 00 00 00       	mov    0xa0,%eax
    7510:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    7516:	e8 72 ff ff ff       	call   748d <__cos_noret>
	return &(defci->ci);
    751b:	8b 45 08             	mov    0x8(%ebp),%eax
}
    751e:	c9                   	leave  
    751f:	c3                   	ret    

00007520 <cos_sched_aep_get>:

struct cos_aep_info *
cos_sched_aep_get(struct cos_defcompinfo *defci)
{
    7520:	55                   	push   %ebp
    7521:	89 e5                	mov    %esp,%ebp
    7523:	83 ec 18             	sub    $0x18,%esp
	assert(defci);
    7526:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    752a:	0f 94 c0             	sete   %al
    752d:	0f b6 c0             	movzbl %al,%eax
    7530:	85 c0                	test   %eax,%eax
    7532:	74 1c                	je     7550 <cos_sched_aep_get+0x30>
    7534:	c7 04 24 40 14 00 00 	movl   $0x1440,(%esp)
    753b:	e8 c6 fe ff ff       	call   7406 <prints>
    7540:	a1 a0 00 00 00       	mov    0xa0,%eax
    7545:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    754b:	e8 3d ff ff ff       	call   748d <__cos_noret>
	return &(defci->sched_aep[cos_cpuid()]);
    7550:	e8 2c fd ff ff       	call   7281 <cos_cpuid>
    7555:	89 c2                	mov    %eax,%edx
    7557:	89 d0                	mov    %edx,%eax
    7559:	01 c0                	add    %eax,%eax
    755b:	01 d0                	add    %edx,%eax
    755d:	c1 e0 03             	shl    $0x3,%eax
    7560:	8d 50 50             	lea    0x50(%eax),%edx
    7563:	8b 45 08             	mov    0x8(%ebp),%eax
    7566:	01 d0                	add    %edx,%eax
    7568:	83 c0 04             	add    $0x4,%eax
}
    756b:	c9                   	leave  
    756c:	c3                   	ret    

0000756d <cos_defcompinfo_init>:

void
cos_defcompinfo_init(void)
{
    756d:	55                   	push   %ebp
    756e:	89 e5                	mov    %esp,%ebp
    7570:	57                   	push   %edi
    7571:	56                   	push   %esi
    7572:	53                   	push   %ebx
    7573:	83 ec 2c             	sub    $0x2c,%esp
	if (curr_defci_init_status == INITIALIZED) return;
    7576:	a1 a4 00 00 00       	mov    0xa4,%eax
    757b:	83 f8 01             	cmp    $0x1,%eax
    757e:	75 02                	jne    7582 <cos_defcompinfo_init+0x15>
    7580:	eb 63                	jmp    75e5 <cos_defcompinfo_init+0x78>

	cos_defcompinfo_init_ext(BOOT_CAPTBL_SELF_INITTCAP_CPU_BASE, BOOT_CAPTBL_SELF_INITTHD_CPU_BASE,
	                         BOOT_CAPTBL_SELF_INITRCV_CPU_BASE, BOOT_CAPTBL_SELF_PT, BOOT_CAPTBL_SELF_CT,
	                         BOOT_CAPTBL_SELF_COMP, (vaddr_t)cos_get_heap_ptr(), BOOT_CAPTBL_FREE);
    7582:	e8 22 fd ff ff       	call   72a9 <cos_get_heap_ptr>
void
cos_defcompinfo_init(void)
{
	if (curr_defci_init_status == INITIALIZED) return;

	cos_defcompinfo_init_ext(BOOT_CAPTBL_SELF_INITTCAP_CPU_BASE, BOOT_CAPTBL_SELF_INITTHD_CPU_BASE,
    7587:	89 c7                	mov    %eax,%edi
	                         BOOT_CAPTBL_SELF_INITRCV_CPU_BASE, BOOT_CAPTBL_SELF_PT, BOOT_CAPTBL_SELF_CT,
    7589:	e8 f3 fc ff ff       	call   7281 <cos_cpuid>
    758e:	83 c0 08             	add    $0x8,%eax
    7591:	c1 e0 02             	shl    $0x2,%eax
void
cos_defcompinfo_init(void)
{
	if (curr_defci_init_status == INITIALIZED) return;

	cos_defcompinfo_init_ext(BOOT_CAPTBL_SELF_INITTCAP_CPU_BASE, BOOT_CAPTBL_SELF_INITTHD_CPU_BASE,
    7594:	89 c6                	mov    %eax,%esi
    7596:	e8 e6 fc ff ff       	call   7281 <cos_cpuid>
    759b:	83 c0 07             	add    $0x7,%eax
    759e:	c1 e0 02             	shl    $0x2,%eax
    75a1:	89 c3                	mov    %eax,%ebx
    75a3:	e8 d9 fc ff ff       	call   7281 <cos_cpuid>
    75a8:	83 c0 07             	add    $0x7,%eax
    75ab:	c1 e0 02             	shl    $0x2,%eax
    75ae:	83 c0 01             	add    $0x1,%eax
    75b1:	c7 44 24 1c 24 00 00 	movl   $0x24,0x1c(%esp)
    75b8:	00 
    75b9:	89 7c 24 18          	mov    %edi,0x18(%esp)
    75bd:	c7 44 24 14 08 00 00 	movl   $0x8,0x14(%esp)
    75c4:	00 
    75c5:	c7 44 24 10 04 00 00 	movl   $0x4,0x10(%esp)
    75cc:	00 
    75cd:	c7 44 24 0c 06 00 00 	movl   $0x6,0xc(%esp)
    75d4:	00 
    75d5:	89 74 24 08          	mov    %esi,0x8(%esp)
    75d9:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    75dd:	89 04 24             	mov    %eax,(%esp)
    75e0:	e8 fc ff ff ff       	call   75e1 <cos_defcompinfo_init+0x74>
	                         BOOT_CAPTBL_SELF_INITRCV_CPU_BASE, BOOT_CAPTBL_SELF_PT, BOOT_CAPTBL_SELF_CT,
	                         BOOT_CAPTBL_SELF_COMP, (vaddr_t)cos_get_heap_ptr(), BOOT_CAPTBL_FREE);

}
    75e5:	83 c4 2c             	add    $0x2c,%esp
    75e8:	5b                   	pop    %ebx
    75e9:	5e                   	pop    %esi
    75ea:	5f                   	pop    %edi
    75eb:	5d                   	pop    %ebp
    75ec:	c3                   	ret    

000075ed <cos_defcompinfo_init_ext>:

void
cos_defcompinfo_init_ext(tcap_t sched_tc, thdcap_t sched_thd, arcvcap_t sched_rcv, pgtblcap_t pgtbl_cap,
                         captblcap_t captbl_cap, compcap_t comp_cap, vaddr_t heap_ptr, capid_t cap_frontier)
{
    75ed:	55                   	push   %ebp
    75ee:	89 e5                	mov    %esp,%ebp
    75f0:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *defci = cos_defcompinfo_curr_get();
    75f3:	e8 fc ff ff ff       	call   75f4 <cos_defcompinfo_init_ext+0x7>
    75f8:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_compinfo    *ci    = cos_compinfo_get(defci);
    75fb:	8b 45 f4             	mov    -0xc(%ebp),%eax
    75fe:	89 04 24             	mov    %eax,(%esp)
    7601:	e8 fc ff ff ff       	call   7602 <cos_defcompinfo_init_ext+0x15>
    7606:	89 45 f0             	mov    %eax,-0x10(%ebp)

	if (curr_defci_init_status == INITIALIZED) return;
    7609:	a1 a4 00 00 00       	mov    0xa4,%eax
    760e:	83 f8 01             	cmp    $0x1,%eax
    7611:	75 02                	jne    7615 <cos_defcompinfo_init_ext+0x28>
    7613:	eb 58                	jmp    766d <cos_defcompinfo_init_ext+0x80>

	cos_compinfo_init(ci, pgtbl_cap, captbl_cap, comp_cap, heap_ptr, cap_frontier, ci);
    7615:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7618:	89 44 24 18          	mov    %eax,0x18(%esp)
    761c:	8b 45 24             	mov    0x24(%ebp),%eax
    761f:	89 44 24 14          	mov    %eax,0x14(%esp)
    7623:	8b 45 20             	mov    0x20(%ebp),%eax
    7626:	89 44 24 10          	mov    %eax,0x10(%esp)
    762a:	8b 45 1c             	mov    0x1c(%ebp),%eax
    762d:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7631:	8b 45 18             	mov    0x18(%ebp),%eax
    7634:	89 44 24 08          	mov    %eax,0x8(%esp)
    7638:	8b 45 14             	mov    0x14(%ebp),%eax
    763b:	89 44 24 04          	mov    %eax,0x4(%esp)
    763f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7642:	89 04 24             	mov    %eax,(%esp)
    7645:	e8 fc ff ff ff       	call   7646 <cos_defcompinfo_init_ext+0x59>
	curr_defci_init_status = INITIALIZED;
    764a:	c7 05 a4 00 00 00 01 	movl   $0x1,0xa4
    7651:	00 00 00 
	cos_defcompinfo_sched_init_ext(sched_tc, sched_thd, sched_rcv);
    7654:	8b 45 10             	mov    0x10(%ebp),%eax
    7657:	89 44 24 08          	mov    %eax,0x8(%esp)
    765b:	8b 45 0c             	mov    0xc(%ebp),%eax
    765e:	89 44 24 04          	mov    %eax,0x4(%esp)
    7662:	8b 45 08             	mov    0x8(%ebp),%eax
    7665:	89 04 24             	mov    %eax,(%esp)
    7668:	e8 fc ff ff ff       	call   7669 <cos_defcompinfo_init_ext+0x7c>
}
    766d:	c9                   	leave  
    766e:	c3                   	ret    

0000766f <cos_defcompinfo_sched_init_ext>:

void
cos_defcompinfo_sched_init_ext(tcap_t sched_tc, thdcap_t sched_thd, arcvcap_t sched_rcv)
{
    766f:	55                   	push   %ebp
    7670:	89 e5                	mov    %esp,%ebp
    7672:	83 ec 28             	sub    $0x28,%esp
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    7675:	e8 fc ff ff ff       	call   7676 <cos_defcompinfo_sched_init_ext+0x7>
    767a:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_compinfo    *ci        = cos_compinfo_get(defci);
    767d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7680:	89 04 24             	mov    %eax,(%esp)
    7683:	e8 fc ff ff ff       	call   7684 <cos_defcompinfo_sched_init_ext+0x15>
    7688:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    768b:	8b 45 f4             	mov    -0xc(%ebp),%eax
    768e:	89 04 24             	mov    %eax,(%esp)
    7691:	e8 fc ff ff ff       	call   7692 <cos_defcompinfo_sched_init_ext+0x23>
    7696:	89 45 ec             	mov    %eax,-0x14(%ebp)

	assert(curr_defci_init_status == INITIALIZED);
    7699:	a1 a4 00 00 00       	mov    0xa4,%eax
    769e:	83 f8 01             	cmp    $0x1,%eax
    76a1:	0f 95 c0             	setne  %al
    76a4:	0f b6 c0             	movzbl %al,%eax
    76a7:	85 c0                	test   %eax,%eax
    76a9:	74 1c                	je     76c7 <cos_defcompinfo_sched_init_ext+0x58>
    76ab:	c7 04 24 74 14 00 00 	movl   $0x1474,(%esp)
    76b2:	e8 4f fd ff ff       	call   7406 <prints>
    76b7:	a1 a0 00 00 00       	mov    0xa0,%eax
    76bc:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    76c2:	e8 c6 fd ff ff       	call   748d <__cos_noret>

	sched_aep->tc   = sched_tc;
    76c7:	8b 45 ec             	mov    -0x14(%ebp),%eax
    76ca:	8b 55 08             	mov    0x8(%ebp),%edx
    76cd:	89 10                	mov    %edx,(%eax)
	sched_aep->thd  = sched_thd;
    76cf:	8b 45 ec             	mov    -0x14(%ebp),%eax
    76d2:	8b 55 0c             	mov    0xc(%ebp),%edx
    76d5:	89 50 04             	mov    %edx,0x4(%eax)
	sched_aep->rcv  = sched_rcv;
    76d8:	8b 45 ec             	mov    -0x14(%ebp),%eax
    76db:	8b 55 10             	mov    0x10(%ebp),%edx
    76de:	89 50 0c             	mov    %edx,0xc(%eax)
	sched_aep->fn   = NULL;
    76e1:	8b 45 ec             	mov    -0x14(%ebp),%eax
    76e4:	c7 40 10 00 00 00 00 	movl   $0x0,0x10(%eax)
	sched_aep->data = NULL;
    76eb:	8b 45 ec             	mov    -0x14(%ebp),%eax
    76ee:	c7 40 14 00 00 00 00 	movl   $0x0,0x14(%eax)
	sched_aep->tid  = cos_introspect(ci, sched_thd, THD_GET_TID);
    76f5:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    76fc:	00 
    76fd:	8b 45 0c             	mov    0xc(%ebp),%eax
    7700:	89 44 24 04          	mov    %eax,0x4(%esp)
    7704:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7707:	89 04 24             	mov    %eax,(%esp)
    770a:	e8 fc ff ff ff       	call   770b <cos_defcompinfo_sched_init_ext+0x9c>
    770f:	89 c2                	mov    %eax,%edx
    7711:	8b 45 ec             	mov    -0x14(%ebp),%eax
    7714:	66 89 50 08          	mov    %dx,0x8(%eax)
}
    7718:	c9                   	leave  
    7719:	c3                   	ret    

0000771a <cos_defcompinfo_sched_init>:

void
cos_defcompinfo_sched_init(void)
{
    771a:	55                   	push   %ebp
    771b:	89 e5                	mov    %esp,%ebp
    771d:	56                   	push   %esi
    771e:	53                   	push   %ebx
    771f:	83 ec 10             	sub    $0x10,%esp
	assert(curr_defci_init_status == INITIALIZED);
    7722:	a1 a4 00 00 00       	mov    0xa4,%eax
    7727:	83 f8 01             	cmp    $0x1,%eax
    772a:	0f 95 c0             	setne  %al
    772d:	0f b6 c0             	movzbl %al,%eax
    7730:	85 c0                	test   %eax,%eax
    7732:	74 1c                	je     7750 <cos_defcompinfo_sched_init+0x36>
    7734:	c7 04 24 a8 14 00 00 	movl   $0x14a8,(%esp)
    773b:	e8 c6 fc ff ff       	call   7406 <prints>
    7740:	a1 a0 00 00 00       	mov    0xa0,%eax
    7745:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    774b:	e8 3d fd ff ff       	call   748d <__cos_noret>

	cos_defcompinfo_sched_init_ext(BOOT_CAPTBL_SELF_INITTCAP_CPU_BASE, BOOT_CAPTBL_SELF_INITTHD_CPU_BASE,
				       BOOT_CAPTBL_SELF_INITRCV_CPU_BASE);
    7750:	e8 2c fb ff ff       	call   7281 <cos_cpuid>
    7755:	83 c0 08             	add    $0x8,%eax
    7758:	c1 e0 02             	shl    $0x2,%eax
void
cos_defcompinfo_sched_init(void)
{
	assert(curr_defci_init_status == INITIALIZED);

	cos_defcompinfo_sched_init_ext(BOOT_CAPTBL_SELF_INITTCAP_CPU_BASE, BOOT_CAPTBL_SELF_INITTHD_CPU_BASE,
    775b:	89 c6                	mov    %eax,%esi
    775d:	e8 1f fb ff ff       	call   7281 <cos_cpuid>
    7762:	83 c0 07             	add    $0x7,%eax
    7765:	c1 e0 02             	shl    $0x2,%eax
    7768:	89 c3                	mov    %eax,%ebx
    776a:	e8 12 fb ff ff       	call   7281 <cos_cpuid>
    776f:	83 c0 07             	add    $0x7,%eax
    7772:	c1 e0 02             	shl    $0x2,%eax
    7775:	83 c0 01             	add    $0x1,%eax
    7778:	89 74 24 08          	mov    %esi,0x8(%esp)
    777c:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    7780:	89 04 24             	mov    %eax,(%esp)
    7783:	e8 fc ff ff ff       	call   7784 <cos_defcompinfo_sched_init+0x6a>
				       BOOT_CAPTBL_SELF_INITRCV_CPU_BASE);
}
    7788:	83 c4 10             	add    $0x10,%esp
    778b:	5b                   	pop    %ebx
    778c:	5e                   	pop    %esi
    778d:	5d                   	pop    %ebp
    778e:	c3                   	ret    

0000778f <cos_aep_alloc_intern>:

static int
cos_aep_alloc_intern(struct cos_aep_info *aep, struct cos_defcompinfo *dst_dci, tcap_t tc, struct cos_aep_info *sched, cos_aepthd_fn_t fn, void *data, thdclosure_index_t idx)
{
    778f:	55                   	push   %ebp
    7790:	89 e5                	mov    %esp,%ebp
    7792:	53                   	push   %ebx
    7793:	83 ec 34             	sub    $0x34,%esp
	struct cos_defcompinfo *defci   = cos_defcompinfo_curr_get();
    7796:	e8 fc ff ff ff       	call   7797 <cos_aep_alloc_intern+0x8>
    779b:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_compinfo    *ci      = cos_compinfo_get(defci);
    779e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    77a1:	89 04 24             	mov    %eax,(%esp)
    77a4:	e8 fc ff ff ff       	call   77a5 <cos_aep_alloc_intern+0x16>
    77a9:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_compinfo    *dst_ci  = cos_compinfo_get(dst_dci);
    77ac:	8b 45 0c             	mov    0xc(%ebp),%eax
    77af:	89 04 24             	mov    %eax,(%esp)
    77b2:	e8 fc ff ff ff       	call   77b3 <cos_aep_alloc_intern+0x24>
    77b7:	89 45 ec             	mov    %eax,-0x14(%ebp)
	int                     is_init = (!fn && !data && !idx);
    77ba:	83 7d 18 00          	cmpl   $0x0,0x18(%ebp)
    77be:	75 13                	jne    77d3 <cos_aep_alloc_intern+0x44>
    77c0:	83 7d 1c 00          	cmpl   $0x0,0x1c(%ebp)
    77c4:	75 0d                	jne    77d3 <cos_aep_alloc_intern+0x44>
    77c6:	83 7d 20 00          	cmpl   $0x0,0x20(%ebp)
    77ca:	75 07                	jne    77d3 <cos_aep_alloc_intern+0x44>
    77cc:	b8 01 00 00 00       	mov    $0x1,%eax
    77d1:	eb 05                	jmp    77d8 <cos_aep_alloc_intern+0x49>
    77d3:	b8 00 00 00 00       	mov    $0x0,%eax
    77d8:	89 45 e8             	mov    %eax,-0x18(%ebp)

	assert(curr_defci_init_status == INITIALIZED);
    77db:	a1 a4 00 00 00       	mov    0xa4,%eax
    77e0:	83 f8 01             	cmp    $0x1,%eax
    77e3:	0f 95 c0             	setne  %al
    77e6:	0f b6 c0             	movzbl %al,%eax
    77e9:	85 c0                	test   %eax,%eax
    77eb:	74 1c                	je     7809 <cos_aep_alloc_intern+0x7a>
    77ed:	c7 04 24 dc 14 00 00 	movl   $0x14dc,(%esp)
    77f4:	e8 0d fc ff ff       	call   7406 <prints>
    77f9:	a1 a0 00 00 00       	mov    0xa0,%eax
    77fe:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    7804:	e8 84 fc ff ff       	call   748d <__cos_noret>
	memset(aep, 0, sizeof(struct cos_aep_info));
    7809:	c7 44 24 08 18 00 00 	movl   $0x18,0x8(%esp)
    7810:	00 
    7811:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    7818:	00 
    7819:	8b 45 08             	mov    0x8(%ebp),%eax
    781c:	89 04 24             	mov    %eax,(%esp)
    781f:	e8 fc ff ff ff       	call   7820 <cos_aep_alloc_intern+0x91>

	if (is_init)      aep->thd = cos_initthd_alloc(ci, dst_ci->comp_cap);
    7824:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
    7828:	74 1d                	je     7847 <cos_aep_alloc_intern+0xb8>
    782a:	8b 45 ec             	mov    -0x14(%ebp),%eax
    782d:	8b 40 08             	mov    0x8(%eax),%eax
    7830:	89 44 24 04          	mov    %eax,0x4(%esp)
    7834:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7837:	89 04 24             	mov    %eax,(%esp)
    783a:	e8 fc ff ff ff       	call   783b <cos_aep_alloc_intern+0xac>
    783f:	8b 55 08             	mov    0x8(%ebp),%edx
    7842:	89 42 04             	mov    %eax,0x4(%edx)
    7845:	eb 54                	jmp    789b <cos_aep_alloc_intern+0x10c>
	else if (idx > 0) aep->thd = cos_thd_alloc_ext(ci, dst_ci->comp_cap, idx);
    7847:	83 7d 20 00          	cmpl   $0x0,0x20(%ebp)
    784b:	7e 24                	jle    7871 <cos_aep_alloc_intern+0xe2>
    784d:	8b 45 ec             	mov    -0x14(%ebp),%eax
    7850:	8b 40 08             	mov    0x8(%eax),%eax
    7853:	8b 55 20             	mov    0x20(%ebp),%edx
    7856:	89 54 24 08          	mov    %edx,0x8(%esp)
    785a:	89 44 24 04          	mov    %eax,0x4(%esp)
    785e:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7861:	89 04 24             	mov    %eax,(%esp)
    7864:	e8 fc ff ff ff       	call   7865 <cos_aep_alloc_intern+0xd6>
    7869:	8b 55 08             	mov    0x8(%ebp),%edx
    786c:	89 42 04             	mov    %eax,0x4(%edx)
    786f:	eb 2a                	jmp    789b <cos_aep_alloc_intern+0x10c>
	else              aep->thd = cos_thd_alloc(ci, dst_ci->comp_cap, cos_aepthd_fn, (void *)aep);
    7871:	8b 45 ec             	mov    -0x14(%ebp),%eax
    7874:	8b 40 08             	mov    0x8(%eax),%eax
    7877:	8b 55 08             	mov    0x8(%ebp),%edx
    787a:	89 54 24 0c          	mov    %edx,0xc(%esp)
    787e:	c7 44 24 08 92 74 00 	movl   $0x7492,0x8(%esp)
    7885:	00 
    7886:	89 44 24 04          	mov    %eax,0x4(%esp)
    788a:	8b 45 f0             	mov    -0x10(%ebp),%eax
    788d:	89 04 24             	mov    %eax,(%esp)
    7890:	e8 fc ff ff ff       	call   7891 <cos_aep_alloc_intern+0x102>
    7895:	8b 55 08             	mov    0x8(%ebp),%edx
    7898:	89 42 04             	mov    %eax,0x4(%edx)
	assert(aep->thd);
    789b:	8b 45 08             	mov    0x8(%ebp),%eax
    789e:	8b 40 04             	mov    0x4(%eax),%eax
    78a1:	85 c0                	test   %eax,%eax
    78a3:	0f 94 c0             	sete   %al
    78a6:	0f b6 c0             	movzbl %al,%eax
    78a9:	85 c0                	test   %eax,%eax
    78ab:	74 1c                	je     78c9 <cos_aep_alloc_intern+0x13a>
    78ad:	c7 04 24 10 15 00 00 	movl   $0x1510,(%esp)
    78b4:	e8 4d fb ff ff       	call   7406 <prints>
    78b9:	a1 a0 00 00 00       	mov    0xa0,%eax
    78be:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    78c4:	e8 c4 fb ff ff       	call   748d <__cos_noret>
	aep->tid  = cos_introspect(ci, aep->thd, THD_GET_TID);
    78c9:	8b 45 08             	mov    0x8(%ebp),%eax
    78cc:	8b 40 04             	mov    0x4(%eax),%eax
    78cf:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    78d6:	00 
    78d7:	89 44 24 04          	mov    %eax,0x4(%esp)
    78db:	8b 45 f0             	mov    -0x10(%ebp),%eax
    78de:	89 04 24             	mov    %eax,(%esp)
    78e1:	e8 fc ff ff ff       	call   78e2 <cos_aep_alloc_intern+0x153>
    78e6:	89 c2                	mov    %eax,%edx
    78e8:	8b 45 08             	mov    0x8(%ebp),%eax
    78eb:	66 89 50 08          	mov    %dx,0x8(%eax)
	if (!sched && is_init) return 0;
    78ef:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
    78f3:	75 10                	jne    7905 <cos_aep_alloc_intern+0x176>
    78f5:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
    78f9:	74 0a                	je     7905 <cos_aep_alloc_intern+0x176>
    78fb:	b8 00 00 00 00       	mov    $0x0,%eax
    7900:	e9 ca 00 00 00       	jmp    79cf <cos_aep_alloc_intern+0x240>

	if (tc) {
    7905:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    7909:	74 0a                	je     7915 <cos_aep_alloc_intern+0x186>
		aep->tc = tc;
    790b:	8b 45 08             	mov    0x8(%ebp),%eax
    790e:	8b 55 10             	mov    0x10(%ebp),%edx
    7911:	89 10                	mov    %edx,(%eax)
    7913:	eb 3d                	jmp    7952 <cos_aep_alloc_intern+0x1c3>
	} else {
		aep->tc = cos_tcap_alloc(ci);
    7915:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7918:	89 04 24             	mov    %eax,(%esp)
    791b:	e8 fc ff ff ff       	call   791c <cos_aep_alloc_intern+0x18d>
    7920:	8b 55 08             	mov    0x8(%ebp),%edx
    7923:	89 02                	mov    %eax,(%edx)
		assert(aep->tc);
    7925:	8b 45 08             	mov    0x8(%ebp),%eax
    7928:	8b 00                	mov    (%eax),%eax
    792a:	85 c0                	test   %eax,%eax
    792c:	0f 94 c0             	sete   %al
    792f:	0f b6 c0             	movzbl %al,%eax
    7932:	85 c0                	test   %eax,%eax
    7934:	74 1c                	je     7952 <cos_aep_alloc_intern+0x1c3>
    7936:	c7 04 24 44 15 00 00 	movl   $0x1544,(%esp)
    793d:	e8 c4 fa ff ff       	call   7406 <prints>
    7942:	a1 a0 00 00 00       	mov    0xa0,%eax
    7947:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    794d:	e8 3b fb ff ff       	call   748d <__cos_noret>
	}

	aep->rcv  = cos_arcv_alloc(ci, aep->thd, aep->tc, ci->comp_cap, sched->rcv);
    7952:	8b 45 14             	mov    0x14(%ebp),%eax
    7955:	8b 58 0c             	mov    0xc(%eax),%ebx
    7958:	8b 45 f0             	mov    -0x10(%ebp),%eax
    795b:	8b 48 08             	mov    0x8(%eax),%ecx
    795e:	8b 45 08             	mov    0x8(%ebp),%eax
    7961:	8b 10                	mov    (%eax),%edx
    7963:	8b 45 08             	mov    0x8(%ebp),%eax
    7966:	8b 40 04             	mov    0x4(%eax),%eax
    7969:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    796d:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    7971:	89 54 24 08          	mov    %edx,0x8(%esp)
    7975:	89 44 24 04          	mov    %eax,0x4(%esp)
    7979:	8b 45 f0             	mov    -0x10(%ebp),%eax
    797c:	89 04 24             	mov    %eax,(%esp)
    797f:	e8 fc ff ff ff       	call   7980 <cos_aep_alloc_intern+0x1f1>
    7984:	8b 55 08             	mov    0x8(%ebp),%edx
    7987:	89 42 0c             	mov    %eax,0xc(%edx)
	assert(aep->rcv);
    798a:	8b 45 08             	mov    0x8(%ebp),%eax
    798d:	8b 40 0c             	mov    0xc(%eax),%eax
    7990:	85 c0                	test   %eax,%eax
    7992:	0f 94 c0             	sete   %al
    7995:	0f b6 c0             	movzbl %al,%eax
    7998:	85 c0                	test   %eax,%eax
    799a:	74 1c                	je     79b8 <cos_aep_alloc_intern+0x229>
    799c:	c7 04 24 78 15 00 00 	movl   $0x1578,(%esp)
    79a3:	e8 5e fa ff ff       	call   7406 <prints>
    79a8:	a1 a0 00 00 00       	mov    0xa0,%eax
    79ad:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    79b3:	e8 d5 fa ff ff       	call   748d <__cos_noret>
	aep->fn   = fn;
    79b8:	8b 45 08             	mov    0x8(%ebp),%eax
    79bb:	8b 55 18             	mov    0x18(%ebp),%edx
    79be:	89 50 10             	mov    %edx,0x10(%eax)
	aep->data = data;
    79c1:	8b 45 08             	mov    0x8(%ebp),%eax
    79c4:	8b 55 1c             	mov    0x1c(%ebp),%edx
    79c7:	89 50 14             	mov    %edx,0x14(%eax)

	return 0;
    79ca:	b8 00 00 00 00       	mov    $0x0,%eax
}
    79cf:	83 c4 34             	add    $0x34,%esp
    79d2:	5b                   	pop    %ebx
    79d3:	5d                   	pop    %ebp
    79d4:	c3                   	ret    

000079d5 <cos_defcompinfo_child_alloc>:

int
cos_defcompinfo_child_alloc(struct cos_defcompinfo *child_defci, vaddr_t entry, vaddr_t heap_ptr, capid_t cap_frontier,
                            int is_sched)
{
    79d5:	55                   	push   %ebp
    79d6:	89 e5                	mov    %esp,%ebp
    79d8:	83 ec 48             	sub    $0x48,%esp
	int                     ret;
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    79db:	e8 fc ff ff ff       	call   79dc <cos_defcompinfo_child_alloc+0x7>
    79e0:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    79e3:	8b 45 f4             	mov    -0xc(%ebp),%eax
    79e6:	89 04 24             	mov    %eax,(%esp)
    79e9:	e8 fc ff ff ff       	call   79ea <cos_defcompinfo_child_alloc+0x15>
    79ee:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_compinfo    *ci        = cos_compinfo_get(defci);
    79f1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    79f4:	89 04 24             	mov    %eax,(%esp)
    79f7:	e8 fc ff ff ff       	call   79f8 <cos_defcompinfo_child_alloc+0x23>
    79fc:	89 45 ec             	mov    %eax,-0x14(%ebp)
	struct cos_compinfo    *child_ci  = cos_compinfo_get(child_defci);
    79ff:	8b 45 08             	mov    0x8(%ebp),%eax
    7a02:	89 04 24             	mov    %eax,(%esp)
    7a05:	e8 fc ff ff ff       	call   7a06 <cos_defcompinfo_child_alloc+0x31>
    7a0a:	89 45 e8             	mov    %eax,-0x18(%ebp)
	struct cos_aep_info    *child_aep = cos_sched_aep_get(child_defci);
    7a0d:	8b 45 08             	mov    0x8(%ebp),%eax
    7a10:	89 04 24             	mov    %eax,(%esp)
    7a13:	e8 fc ff ff ff       	call   7a14 <cos_defcompinfo_child_alloc+0x3f>
    7a18:	89 45 e4             	mov    %eax,-0x1c(%ebp)

	assert(curr_defci_init_status == INITIALIZED);
    7a1b:	a1 a4 00 00 00       	mov    0xa4,%eax
    7a20:	83 f8 01             	cmp    $0x1,%eax
    7a23:	0f 95 c0             	setne  %al
    7a26:	0f b6 c0             	movzbl %al,%eax
    7a29:	85 c0                	test   %eax,%eax
    7a2b:	74 1c                	je     7a49 <cos_defcompinfo_child_alloc+0x74>
    7a2d:	c7 04 24 ac 15 00 00 	movl   $0x15ac,(%esp)
    7a34:	e8 cd f9 ff ff       	call   7406 <prints>
    7a39:	a1 a0 00 00 00       	mov    0xa0,%eax
    7a3e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    7a44:	e8 44 fa ff ff       	call   748d <__cos_noret>
	ret = cos_compinfo_alloc(child_ci, heap_ptr, cap_frontier, entry, ci);
    7a49:	8b 45 ec             	mov    -0x14(%ebp),%eax
    7a4c:	89 44 24 10          	mov    %eax,0x10(%esp)
    7a50:	8b 45 0c             	mov    0xc(%ebp),%eax
    7a53:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7a57:	8b 45 14             	mov    0x14(%ebp),%eax
    7a5a:	89 44 24 08          	mov    %eax,0x8(%esp)
    7a5e:	8b 45 10             	mov    0x10(%ebp),%eax
    7a61:	89 44 24 04          	mov    %eax,0x4(%esp)
    7a65:	8b 45 e8             	mov    -0x18(%ebp),%eax
    7a68:	89 04 24             	mov    %eax,(%esp)
    7a6b:	e8 fc ff ff ff       	call   7a6c <cos_defcompinfo_child_alloc+0x97>
    7a70:	89 45 e0             	mov    %eax,-0x20(%ebp)
	if (ret) return ret;
    7a73:	83 7d e0 00          	cmpl   $0x0,-0x20(%ebp)
    7a77:	74 05                	je     7a7e <cos_defcompinfo_child_alloc+0xa9>
    7a79:	8b 45 e0             	mov    -0x20(%ebp),%eax
    7a7c:	eb 4c                	jmp    7aca <cos_defcompinfo_child_alloc+0xf5>
	ret = cos_aep_alloc_intern(child_aep, child_defci, 0, is_sched ? sched_aep : NULL, NULL, NULL, 0);
    7a7e:	83 7d 18 00          	cmpl   $0x0,0x18(%ebp)
    7a82:	74 05                	je     7a89 <cos_defcompinfo_child_alloc+0xb4>
    7a84:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7a87:	eb 05                	jmp    7a8e <cos_defcompinfo_child_alloc+0xb9>
    7a89:	b8 00 00 00 00       	mov    $0x0,%eax
    7a8e:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
    7a95:	00 
    7a96:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    7a9d:	00 
    7a9e:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    7aa5:	00 
    7aa6:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7aaa:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    7ab1:	00 
    7ab2:	8b 45 08             	mov    0x8(%ebp),%eax
    7ab5:	89 44 24 04          	mov    %eax,0x4(%esp)
    7ab9:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    7abc:	89 04 24             	mov    %eax,(%esp)
    7abf:	e8 cb fc ff ff       	call   778f <cos_aep_alloc_intern>
    7ac4:	89 45 e0             	mov    %eax,-0x20(%ebp)

	return ret;
    7ac7:	8b 45 e0             	mov    -0x20(%ebp),%eax
}
    7aca:	c9                   	leave  
    7acb:	c3                   	ret    

00007acc <cos_defcompinfo_childid_init>:

void
cos_defcompinfo_childid_init(struct cos_defcompinfo *child_defci, spdid_t c)
{
    7acc:	55                   	push   %ebp
    7acd:	89 e5                	mov    %esp,%ebp
    7acf:	83 ec 18             	sub    $0x18,%esp
    7ad2:	8b 45 0c             	mov    0xc(%ebp),%eax
    7ad5:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	assert(child_defci != cos_defcompinfo_curr_get());
    7ad9:	e8 fc ff ff ff       	call   7ada <cos_defcompinfo_childid_init+0xe>
    7ade:	3b 45 08             	cmp    0x8(%ebp),%eax
    7ae1:	0f 94 c0             	sete   %al
    7ae4:	0f b6 c0             	movzbl %al,%eax
    7ae7:	85 c0                	test   %eax,%eax
    7ae9:	74 1c                	je     7b07 <cos_defcompinfo_childid_init+0x3b>
    7aeb:	c7 04 24 e0 15 00 00 	movl   $0x15e0,(%esp)
    7af2:	e8 0f f9 ff ff       	call   7406 <prints>
    7af7:	a1 a0 00 00 00       	mov    0xa0,%eax
    7afc:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    7b02:	e8 86 f9 ff ff       	call   748d <__cos_noret>

	child_defci->id = c;
    7b07:	8b 45 08             	mov    0x8(%ebp),%eax
    7b0a:	0f b7 55 f4          	movzwl -0xc(%ebp),%edx
    7b0e:	66 89 10             	mov    %dx,(%eax)
}
    7b11:	c9                   	leave  
    7b12:	c3                   	ret    

00007b13 <cos_initaep_alloc>:

int
cos_initaep_alloc(struct cos_defcompinfo *dst_dci, struct cos_aep_info *sched, int is_sched)
{
    7b13:	55                   	push   %ebp
    7b14:	89 e5                	mov    %esp,%ebp
    7b16:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    7b19:	e8 fc ff ff ff       	call   7b1a <cos_initaep_alloc+0x7>
    7b1e:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    7b21:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7b24:	89 04 24             	mov    %eax,(%esp)
    7b27:	e8 fc ff ff ff       	call   7b28 <cos_initaep_alloc+0x15>
    7b2c:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_aep_info    *child_aep = cos_sched_aep_get(dst_dci);
    7b2f:	8b 45 08             	mov    0x8(%ebp),%eax
    7b32:	89 04 24             	mov    %eax,(%esp)
    7b35:	e8 fc ff ff ff       	call   7b36 <cos_initaep_alloc+0x23>
    7b3a:	89 45 ec             	mov    %eax,-0x14(%ebp)
	struct cos_aep_info    *sched_use = is_sched ? (sched ? sched : sched_aep) : NULL;
    7b3d:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    7b41:	74 10                	je     7b53 <cos_initaep_alloc+0x40>
    7b43:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    7b47:	74 05                	je     7b4e <cos_initaep_alloc+0x3b>
    7b49:	8b 45 0c             	mov    0xc(%ebp),%eax
    7b4c:	eb 0a                	jmp    7b58 <cos_initaep_alloc+0x45>
    7b4e:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7b51:	eb 05                	jmp    7b58 <cos_initaep_alloc+0x45>
    7b53:	b8 00 00 00 00       	mov    $0x0,%eax
    7b58:	89 45 e8             	mov    %eax,-0x18(%ebp)

	return cos_aep_alloc_intern(child_aep, dst_dci, 0, sched_use, NULL, NULL, 0);
    7b5b:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
    7b62:	00 
    7b63:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    7b6a:	00 
    7b6b:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    7b72:	00 
    7b73:	8b 45 e8             	mov    -0x18(%ebp),%eax
    7b76:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7b7a:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    7b81:	00 
    7b82:	8b 45 08             	mov    0x8(%ebp),%eax
    7b85:	89 44 24 04          	mov    %eax,0x4(%esp)
    7b89:	8b 45 ec             	mov    -0x14(%ebp),%eax
    7b8c:	89 04 24             	mov    %eax,(%esp)
    7b8f:	e8 fb fb ff ff       	call   778f <cos_aep_alloc_intern>
}
    7b94:	c9                   	leave  
    7b95:	c3                   	ret    

00007b96 <cos_initaep_tcap_alloc>:

int
cos_initaep_tcap_alloc(struct cos_defcompinfo *dst_dci, tcap_t tc, struct cos_aep_info *sched)
{
    7b96:	55                   	push   %ebp
    7b97:	89 e5                	mov    %esp,%ebp
    7b99:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    7b9c:	e8 fc ff ff ff       	call   7b9d <cos_initaep_tcap_alloc+0x7>
    7ba1:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    7ba4:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7ba7:	89 04 24             	mov    %eax,(%esp)
    7baa:	e8 fc ff ff ff       	call   7bab <cos_initaep_tcap_alloc+0x15>
    7baf:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_aep_info    *child_aep = cos_sched_aep_get(dst_dci);
    7bb2:	8b 45 08             	mov    0x8(%ebp),%eax
    7bb5:	89 04 24             	mov    %eax,(%esp)
    7bb8:	e8 fc ff ff ff       	call   7bb9 <cos_initaep_tcap_alloc+0x23>
    7bbd:	89 45 ec             	mov    %eax,-0x14(%ebp)
	struct cos_aep_info    *sched_use = sched ? sched : sched_aep;
    7bc0:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    7bc4:	74 05                	je     7bcb <cos_initaep_tcap_alloc+0x35>
    7bc6:	8b 45 10             	mov    0x10(%ebp),%eax
    7bc9:	eb 03                	jmp    7bce <cos_initaep_tcap_alloc+0x38>
    7bcb:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7bce:	89 45 e8             	mov    %eax,-0x18(%ebp)

	return cos_aep_alloc_intern(child_aep, dst_dci, tc, sched_use, NULL, NULL, 0);
    7bd1:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
    7bd8:	00 
    7bd9:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    7be0:	00 
    7be1:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    7be8:	00 
    7be9:	8b 45 e8             	mov    -0x18(%ebp),%eax
    7bec:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7bf0:	8b 45 0c             	mov    0xc(%ebp),%eax
    7bf3:	89 44 24 08          	mov    %eax,0x8(%esp)
    7bf7:	8b 45 08             	mov    0x8(%ebp),%eax
    7bfa:	89 44 24 04          	mov    %eax,0x4(%esp)
    7bfe:	8b 45 ec             	mov    -0x14(%ebp),%eax
    7c01:	89 04 24             	mov    %eax,(%esp)
    7c04:	e8 86 fb ff ff       	call   778f <cos_aep_alloc_intern>
}
    7c09:	c9                   	leave  
    7c0a:	c3                   	ret    

00007c0b <cos_aep_alloc_ext>:

int
cos_aep_alloc_ext(struct cos_aep_info *aep, struct cos_defcompinfo *dst_dci, struct cos_aep_info *sched, thdclosure_index_t idx)
{
    7c0b:	55                   	push   %ebp
    7c0c:	89 e5                	mov    %esp,%ebp
    7c0e:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    7c11:	e8 fc ff ff ff       	call   7c12 <cos_aep_alloc_ext+0x7>
    7c16:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    7c19:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7c1c:	89 04 24             	mov    %eax,(%esp)
    7c1f:	e8 fc ff ff ff       	call   7c20 <cos_aep_alloc_ext+0x15>
    7c24:	89 45 f4             	mov    %eax,-0xc(%ebp)

	assert(aep && idx > 0);
    7c27:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    7c2b:	0f 94 c0             	sete   %al
    7c2e:	0f b6 c0             	movzbl %al,%eax
    7c31:	85 c0                	test   %eax,%eax
    7c33:	75 0e                	jne    7c43 <cos_aep_alloc_ext+0x38>
    7c35:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
    7c39:	0f 9e c0             	setle  %al
    7c3c:	0f b6 c0             	movzbl %al,%eax
    7c3f:	85 c0                	test   %eax,%eax
    7c41:	74 1c                	je     7c5f <cos_aep_alloc_ext+0x54>
    7c43:	c7 04 24 14 16 00 00 	movl   $0x1614,(%esp)
    7c4a:	e8 b7 f7 ff ff       	call   7406 <prints>
    7c4f:	a1 a0 00 00 00       	mov    0xa0,%eax
    7c54:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    7c5a:	e8 2e f8 ff ff       	call   748d <__cos_noret>
	if (!sched) sched_aep = cos_sched_aep_get(dst_dci);
    7c5f:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    7c63:	75 10                	jne    7c75 <cos_aep_alloc_ext+0x6a>
    7c65:	8b 45 0c             	mov    0xc(%ebp),%eax
    7c68:	89 04 24             	mov    %eax,(%esp)
    7c6b:	e8 fc ff ff ff       	call   7c6c <cos_aep_alloc_ext+0x61>
    7c70:	89 45 f4             	mov    %eax,-0xc(%ebp)
    7c73:	eb 06                	jmp    7c7b <cos_aep_alloc_ext+0x70>
	else        sched_aep = sched;
    7c75:	8b 45 10             	mov    0x10(%ebp),%eax
    7c78:	89 45 f4             	mov    %eax,-0xc(%ebp)

	return cos_aep_alloc_intern(aep, dst_dci, 0, sched_aep, NULL, NULL, idx);
    7c7b:	8b 45 14             	mov    0x14(%ebp),%eax
    7c7e:	89 44 24 18          	mov    %eax,0x18(%esp)
    7c82:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    7c89:	00 
    7c8a:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    7c91:	00 
    7c92:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7c95:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7c99:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    7ca0:	00 
    7ca1:	8b 45 0c             	mov    0xc(%ebp),%eax
    7ca4:	89 44 24 04          	mov    %eax,0x4(%esp)
    7ca8:	8b 45 08             	mov    0x8(%ebp),%eax
    7cab:	89 04 24             	mov    %eax,(%esp)
    7cae:	e8 dc fa ff ff       	call   778f <cos_aep_alloc_intern>
}
    7cb3:	c9                   	leave  
    7cb4:	c3                   	ret    

00007cb5 <cos_aep_tcap_alloc_ext>:

int
cos_aep_tcap_alloc_ext(struct cos_aep_info *aep, struct cos_defcompinfo *dst_dci, struct cos_aep_info *sched, tcap_t tc, thdclosure_index_t idx)
{
    7cb5:	55                   	push   %ebp
    7cb6:	89 e5                	mov    %esp,%ebp
    7cb8:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    7cbb:	e8 fc ff ff ff       	call   7cbc <cos_aep_tcap_alloc_ext+0x7>
    7cc0:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    7cc3:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7cc6:	89 04 24             	mov    %eax,(%esp)
    7cc9:	e8 fc ff ff ff       	call   7cca <cos_aep_tcap_alloc_ext+0x15>
    7cce:	89 45 f4             	mov    %eax,-0xc(%ebp)

	assert(aep);
    7cd1:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    7cd5:	0f 94 c0             	sete   %al
    7cd8:	0f b6 c0             	movzbl %al,%eax
    7cdb:	85 c0                	test   %eax,%eax
    7cdd:	74 1c                	je     7cfb <cos_aep_tcap_alloc_ext+0x46>
    7cdf:	c7 04 24 48 16 00 00 	movl   $0x1648,(%esp)
    7ce6:	e8 1b f7 ff ff       	call   7406 <prints>
    7ceb:	a1 a0 00 00 00       	mov    0xa0,%eax
    7cf0:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    7cf6:	e8 92 f7 ff ff       	call   748d <__cos_noret>
	assert(idx > 0);
    7cfb:	83 7d 18 00          	cmpl   $0x0,0x18(%ebp)
    7cff:	0f 9e c0             	setle  %al
    7d02:	0f b6 c0             	movzbl %al,%eax
    7d05:	85 c0                	test   %eax,%eax
    7d07:	74 1c                	je     7d25 <cos_aep_tcap_alloc_ext+0x70>
    7d09:	c7 04 24 7c 16 00 00 	movl   $0x167c,(%esp)
    7d10:	e8 f1 f6 ff ff       	call   7406 <prints>
    7d15:	a1 a0 00 00 00       	mov    0xa0,%eax
    7d1a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    7d20:	e8 68 f7 ff ff       	call   748d <__cos_noret>
	if (!sched) sched_aep = cos_sched_aep_get(dst_dci);
    7d25:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
    7d29:	75 10                	jne    7d3b <cos_aep_tcap_alloc_ext+0x86>
    7d2b:	8b 45 0c             	mov    0xc(%ebp),%eax
    7d2e:	89 04 24             	mov    %eax,(%esp)
    7d31:	e8 fc ff ff ff       	call   7d32 <cos_aep_tcap_alloc_ext+0x7d>
    7d36:	89 45 f4             	mov    %eax,-0xc(%ebp)
    7d39:	eb 06                	jmp    7d41 <cos_aep_tcap_alloc_ext+0x8c>
	else        sched_aep = sched;
    7d3b:	8b 45 10             	mov    0x10(%ebp),%eax
    7d3e:	89 45 f4             	mov    %eax,-0xc(%ebp)

	return cos_aep_alloc_intern(aep, dst_dci, tc, sched_aep, NULL, NULL, idx);
    7d41:	8b 45 18             	mov    0x18(%ebp),%eax
    7d44:	89 44 24 18          	mov    %eax,0x18(%esp)
    7d48:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    7d4f:	00 
    7d50:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    7d57:	00 
    7d58:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7d5b:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7d5f:	8b 45 14             	mov    0x14(%ebp),%eax
    7d62:	89 44 24 08          	mov    %eax,0x8(%esp)
    7d66:	8b 45 0c             	mov    0xc(%ebp),%eax
    7d69:	89 44 24 04          	mov    %eax,0x4(%esp)
    7d6d:	8b 45 08             	mov    0x8(%ebp),%eax
    7d70:	89 04 24             	mov    %eax,(%esp)
    7d73:	e8 17 fa ff ff       	call   778f <cos_aep_alloc_intern>
}
    7d78:	c9                   	leave  
    7d79:	c3                   	ret    

00007d7a <cos_aep_alloc>:

int
cos_aep_alloc(struct cos_aep_info *aep, cos_aepthd_fn_t fn, void *data)
{
    7d7a:	55                   	push   %ebp
    7d7b:	89 e5                	mov    %esp,%ebp
    7d7d:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    7d80:	e8 fc ff ff ff       	call   7d81 <cos_aep_alloc+0x7>
    7d85:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    7d88:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7d8b:	89 04 24             	mov    %eax,(%esp)
    7d8e:	e8 fc ff ff ff       	call   7d8f <cos_aep_alloc+0x15>
    7d93:	89 45 f0             	mov    %eax,-0x10(%ebp)

	return cos_aep_alloc_intern(aep, defci, 0, sched_aep, fn, data, 0);
    7d96:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
    7d9d:	00 
    7d9e:	8b 45 10             	mov    0x10(%ebp),%eax
    7da1:	89 44 24 14          	mov    %eax,0x14(%esp)
    7da5:	8b 45 0c             	mov    0xc(%ebp),%eax
    7da8:	89 44 24 10          	mov    %eax,0x10(%esp)
    7dac:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7daf:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7db3:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    7dba:	00 
    7dbb:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7dbe:	89 44 24 04          	mov    %eax,0x4(%esp)
    7dc2:	8b 45 08             	mov    0x8(%ebp),%eax
    7dc5:	89 04 24             	mov    %eax,(%esp)
    7dc8:	e8 c2 f9 ff ff       	call   778f <cos_aep_alloc_intern>
}
    7dcd:	c9                   	leave  
    7dce:	c3                   	ret    

00007dcf <cos_aep_tcap_alloc>:

int
cos_aep_tcap_alloc(struct cos_aep_info *aep, tcap_t tc, cos_aepthd_fn_t fn, void *data)
{
    7dcf:	55                   	push   %ebp
    7dd0:	89 e5                	mov    %esp,%ebp
    7dd2:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    7dd5:	e8 fc ff ff ff       	call   7dd6 <cos_aep_tcap_alloc+0x7>
    7dda:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    7ddd:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7de0:	89 04 24             	mov    %eax,(%esp)
    7de3:	e8 fc ff ff ff       	call   7de4 <cos_aep_tcap_alloc+0x15>
    7de8:	89 45 f0             	mov    %eax,-0x10(%ebp)

	return cos_aep_alloc_intern(aep, defci, tc, sched_aep, fn, data, 0);
    7deb:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
    7df2:	00 
    7df3:	8b 45 14             	mov    0x14(%ebp),%eax
    7df6:	89 44 24 14          	mov    %eax,0x14(%esp)
    7dfa:	8b 45 10             	mov    0x10(%ebp),%eax
    7dfd:	89 44 24 10          	mov    %eax,0x10(%esp)
    7e01:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7e04:	89 44 24 0c          	mov    %eax,0xc(%esp)
    7e08:	8b 45 0c             	mov    0xc(%ebp),%eax
    7e0b:	89 44 24 08          	mov    %eax,0x8(%esp)
    7e0f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7e12:	89 44 24 04          	mov    %eax,0x4(%esp)
    7e16:	8b 45 08             	mov    0x8(%ebp),%eax
    7e19:	89 04 24             	mov    %eax,(%esp)
    7e1c:	e8 6e f9 ff ff       	call   778f <cos_aep_alloc_intern>
}
    7e21:	c9                   	leave  
    7e22:	c3                   	ret    

00007e23 <cos_defswitch>:

int
cos_defswitch(thdcap_t c, tcap_prio_t p, tcap_time_t r, sched_tok_t stok)
{
    7e23:	55                   	push   %ebp
    7e24:	89 e5                	mov    %esp,%ebp
    7e26:	83 ec 48             	sub    $0x48,%esp
    7e29:	8b 45 0c             	mov    0xc(%ebp),%eax
    7e2c:	89 45 e0             	mov    %eax,-0x20(%ebp)
    7e2f:	8b 45 10             	mov    0x10(%ebp),%eax
    7e32:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	struct cos_defcompinfo *defci     = cos_defcompinfo_curr_get();
    7e35:	e8 fc ff ff ff       	call   7e36 <cos_defswitch+0x13>
    7e3a:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_aep_info    *sched_aep = cos_sched_aep_get(defci);
    7e3d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    7e40:	89 04 24             	mov    %eax,(%esp)
    7e43:	e8 fc ff ff ff       	call   7e44 <cos_defswitch+0x21>
    7e48:	89 45 f0             	mov    %eax,-0x10(%ebp)

	assert(curr_defci_init_status == INITIALIZED);
    7e4b:	a1 a4 00 00 00       	mov    0xa4,%eax
    7e50:	83 f8 01             	cmp    $0x1,%eax
    7e53:	0f 95 c0             	setne  %al
    7e56:	0f b6 c0             	movzbl %al,%eax
    7e59:	85 c0                	test   %eax,%eax
    7e5b:	74 1c                	je     7e79 <cos_defswitch+0x56>
    7e5d:	c7 04 24 b0 16 00 00 	movl   $0x16b0,(%esp)
    7e64:	e8 9d f5 ff ff       	call   7406 <prints>
    7e69:	a1 a0 00 00 00       	mov    0xa0,%eax
    7e6e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    7e74:	e8 14 f6 ff ff       	call   748d <__cos_noret>

	return cos_switch(c, sched_aep->tc, p, r, sched_aep->rcv, stok);
    7e79:	8b 45 f0             	mov    -0x10(%ebp),%eax
    7e7c:	8b 40 0c             	mov    0xc(%eax),%eax
    7e7f:	8b 55 f0             	mov    -0x10(%ebp),%edx
    7e82:	8b 0a                	mov    (%edx),%ecx
    7e84:	8b 55 18             	mov    0x18(%ebp),%edx
    7e87:	89 54 24 18          	mov    %edx,0x18(%esp)
    7e8b:	89 44 24 14          	mov    %eax,0x14(%esp)
    7e8f:	8b 45 14             	mov    0x14(%ebp),%eax
    7e92:	89 44 24 10          	mov    %eax,0x10(%esp)
    7e96:	8b 45 e0             	mov    -0x20(%ebp),%eax
    7e99:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    7e9c:	89 44 24 08          	mov    %eax,0x8(%esp)
    7ea0:	89 54 24 0c          	mov    %edx,0xc(%esp)
    7ea4:	89 4c 24 04          	mov    %ecx,0x4(%esp)
    7ea8:	8b 45 08             	mov    0x8(%ebp),%eax
    7eab:	89 04 24             	mov    %eax,(%esp)
    7eae:	e8 fc ff ff ff       	call   7eaf <cos_defswitch+0x8c>
}
    7eb3:	c9                   	leave  
    7eb4:	c3                   	ret    
    7eb5:	66 90                	xchg   %ax,%ax
    7eb7:	90                   	nop

00007eb8 <ps_list_ll_init>:

#define PS_LIST_DEF_NAME list

static inline void
ps_list_ll_init(struct ps_list *l)
{ l->n = l->p = l; }
    7eb8:	55                   	push   %ebp
    7eb9:	89 e5                	mov    %esp,%ebp
    7ebb:	8b 45 08             	mov    0x8(%ebp),%eax
    7ebe:	8b 55 08             	mov    0x8(%ebp),%edx
    7ec1:	89 50 04             	mov    %edx,0x4(%eax)
    7ec4:	8b 45 08             	mov    0x8(%ebp),%eax
    7ec7:	8b 50 04             	mov    0x4(%eax),%edx
    7eca:	8b 45 08             	mov    0x8(%ebp),%eax
    7ecd:	89 10                	mov    %edx,(%eax)
    7ecf:	5d                   	pop    %ebp
    7ed0:	c3                   	ret    

00007ed1 <ps_list_head_init>:

static inline void
ps_list_head_init(struct ps_list_head *lh)
{ ps_list_ll_init(&lh->l); }
    7ed1:	55                   	push   %ebp
    7ed2:	89 e5                	mov    %esp,%ebp
    7ed4:	83 ec 04             	sub    $0x4,%esp
    7ed7:	8b 45 08             	mov    0x8(%ebp),%eax
    7eda:	89 04 24             	mov    %eax,(%esp)
    7edd:	e8 d6 ff ff ff       	call   7eb8 <ps_list_ll_init>
    7ee2:	c9                   	leave  
    7ee3:	c3                   	ret    

00007ee4 <ps_list_ll_empty>:

static inline int
ps_list_ll_empty(struct ps_list *l)
{ return l->n == l; }
    7ee4:	55                   	push   %ebp
    7ee5:	89 e5                	mov    %esp,%ebp
    7ee7:	8b 45 08             	mov    0x8(%ebp),%eax
    7eea:	8b 00                	mov    (%eax),%eax
    7eec:	3b 45 08             	cmp    0x8(%ebp),%eax
    7eef:	0f 94 c0             	sete   %al
    7ef2:	0f b6 c0             	movzbl %al,%eax
    7ef5:	5d                   	pop    %ebp
    7ef6:	c3                   	ret    

00007ef7 <ps_list_head_empty>:

static inline int
ps_list_head_empty(struct ps_list_head *lh)
{ return ps_list_ll_empty(&lh->l); }
    7ef7:	55                   	push   %ebp
    7ef8:	89 e5                	mov    %esp,%ebp
    7efa:	83 ec 04             	sub    $0x4,%esp
    7efd:	8b 45 08             	mov    0x8(%ebp),%eax
    7f00:	89 04 24             	mov    %eax,(%esp)
    7f03:	e8 dc ff ff ff       	call   7ee4 <ps_list_ll_empty>
    7f08:	c9                   	leave  
    7f09:	c3                   	ret    

00007f0a <ps_list_ll_add>:

static inline void
ps_list_ll_add(struct ps_list *l, struct ps_list *new)
{
    7f0a:	55                   	push   %ebp
    7f0b:	89 e5                	mov    %esp,%ebp
	new->n    = l->n;
    7f0d:	8b 45 08             	mov    0x8(%ebp),%eax
    7f10:	8b 10                	mov    (%eax),%edx
    7f12:	8b 45 0c             	mov    0xc(%ebp),%eax
    7f15:	89 10                	mov    %edx,(%eax)
	new->p    = l;
    7f17:	8b 45 0c             	mov    0xc(%ebp),%eax
    7f1a:	8b 55 08             	mov    0x8(%ebp),%edx
    7f1d:	89 50 04             	mov    %edx,0x4(%eax)
	l->n      = new;
    7f20:	8b 45 08             	mov    0x8(%ebp),%eax
    7f23:	8b 55 0c             	mov    0xc(%ebp),%edx
    7f26:	89 10                	mov    %edx,(%eax)
	new->n->p = new;
    7f28:	8b 45 0c             	mov    0xc(%ebp),%eax
    7f2b:	8b 00                	mov    (%eax),%eax
    7f2d:	8b 55 0c             	mov    0xc(%ebp),%edx
    7f30:	89 50 04             	mov    %edx,0x4(%eax)
}
    7f33:	5d                   	pop    %ebp
    7f34:	c3                   	ret    

00007f35 <ps_list_ll_rem>:

static inline void
ps_list_ll_rem(struct ps_list *l)
{
    7f35:	55                   	push   %ebp
    7f36:	89 e5                	mov    %esp,%ebp
	l->n->p = l->p;
    7f38:	8b 45 08             	mov    0x8(%ebp),%eax
    7f3b:	8b 00                	mov    (%eax),%eax
    7f3d:	8b 55 08             	mov    0x8(%ebp),%edx
    7f40:	8b 52 04             	mov    0x4(%edx),%edx
    7f43:	89 50 04             	mov    %edx,0x4(%eax)
	l->p->n = l->n;
    7f46:	8b 45 08             	mov    0x8(%ebp),%eax
    7f49:	8b 40 04             	mov    0x4(%eax),%eax
    7f4c:	8b 55 08             	mov    0x8(%ebp),%edx
    7f4f:	8b 12                	mov    (%edx),%edx
    7f51:	89 10                	mov    %edx,(%eax)
	l->p = l->n = l;
    7f53:	8b 45 08             	mov    0x8(%ebp),%eax
    7f56:	8b 55 08             	mov    0x8(%ebp),%edx
    7f59:	89 10                	mov    %edx,(%eax)
    7f5b:	8b 45 08             	mov    0x8(%ebp),%eax
    7f5e:	8b 10                	mov    (%eax),%edx
    7f60:	8b 45 08             	mov    0x8(%ebp),%eax
    7f63:	89 50 04             	mov    %edx,0x4(%eax)
}
    7f66:	5d                   	pop    %ebp
    7f67:	c3                   	ret    

00007f68 <ps_cas>:
 * 0 on failure due to contention (*target != old)
 * 1 otherwise (*target == old -> *target = updated)
 */
static inline int
ps_cas(unsigned long *target, unsigned long old, unsigned long updated)
{
    7f68:	55                   	push   %ebp
    7f69:	89 e5                	mov    %esp,%ebp
    7f6b:	53                   	push   %ebx
    7f6c:	83 ec 10             	sub    $0x10,%esp
        char z;
        __asm__ __volatile__("lock " PS_CAS_STR
    7f6f:	8b 55 08             	mov    0x8(%ebp),%edx
    7f72:	8b 4d 10             	mov    0x10(%ebp),%ecx
    7f75:	8b 45 0c             	mov    0xc(%ebp),%eax
    7f78:	8b 5d 08             	mov    0x8(%ebp),%ebx
    7f7b:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    7f7f:	0f 94 c0             	sete   %al
    7f82:	88 45 fb             	mov    %al,-0x5(%ebp)
                             : "+m" (*target), "=a" (z)
                             : "q"  (updated), "a"  (old)
                             : "memory", "cc");
        return (int)z;
    7f85:	0f be 45 fb          	movsbl -0x5(%ebp),%eax
}
    7f89:	83 c4 10             	add    $0x10,%esp
    7f8c:	5b                   	pop    %ebx
    7f8d:	5d                   	pop    %ebp
    7f8e:	c3                   	ret    

00007f8f <ps_faa>:

static inline long
ps_faa(unsigned long *target, long inc)
{
    7f8f:	55                   	push   %ebp
    7f90:	89 e5                	mov    %esp,%ebp
        __asm__ __volatile__("lock " PS_FAA_STR
    7f92:	8b 55 08             	mov    0x8(%ebp),%edx
    7f95:	8b 4d 08             	mov    0x8(%ebp),%ecx
    7f98:	8b 45 0c             	mov    0xc(%ebp),%eax
    7f9b:	f0 0f c1 02          	lock xadd %eax,(%edx)
    7f9f:	89 45 0c             	mov    %eax,0xc(%ebp)
                             : "+m" (*target), "+q" (inc)
                             : : "memory", "cc");
        return inc;
    7fa2:	8b 45 0c             	mov    0xc(%ebp),%eax
}
    7fa5:	5d                   	pop    %ebp
    7fa6:	c3                   	ret    

00007fa7 <ps_tsc>:
ps_lock_init(struct ps_lock *l)
{ l->o = 0; }

static inline ps_tsc_t
ps_tsc(void)
{
    7fa7:	55                   	push   %ebp
    7fa8:	89 e5                	mov    %esp,%ebp
    7faa:	57                   	push   %edi
    7fab:	56                   	push   %esi
    7fac:	53                   	push   %ebx
    7fad:	83 ec 1c             	sub    $0x1c,%esp
	unsigned long a, d, c;

	__asm__ __volatile__("rdtsc" : "=a" (a), "=d" (d), "=c" (c) : : );
    7fb0:	0f 31                	rdtsc  
    7fb2:	89 45 ec             	mov    %eax,-0x14(%ebp)
    7fb5:	89 55 e8             	mov    %edx,-0x18(%ebp)
    7fb8:	89 4d e4             	mov    %ecx,-0x1c(%ebp)

	return ((u64_t)d << 32) | (u64_t)a;
    7fbb:	8b 45 e8             	mov    -0x18(%ebp),%eax
    7fbe:	ba 00 00 00 00       	mov    $0x0,%edx
    7fc3:	89 c2                	mov    %eax,%edx
    7fc5:	b8 00 00 00 00       	mov    $0x0,%eax
    7fca:	89 c1                	mov    %eax,%ecx
    7fcc:	89 d3                	mov    %edx,%ebx
    7fce:	8b 45 ec             	mov    -0x14(%ebp),%eax
    7fd1:	ba 00 00 00 00       	mov    $0x0,%edx
    7fd6:	89 45 d8             	mov    %eax,-0x28(%ebp)
    7fd9:	89 55 dc             	mov    %edx,-0x24(%ebp)
    7fdc:	89 c8                	mov    %ecx,%eax
    7fde:	0b 45 d8             	or     -0x28(%ebp),%eax
    7fe1:	89 c6                	mov    %eax,%esi
    7fe3:	89 d8                	mov    %ebx,%eax
    7fe5:	0b 45 dc             	or     -0x24(%ebp),%eax
    7fe8:	89 c7                	mov    %eax,%edi
    7fea:	89 f0                	mov    %esi,%eax
    7fec:	89 fa                	mov    %edi,%edx
}
    7fee:	83 c4 1c             	add    $0x1c,%esp
    7ff1:	5b                   	pop    %ebx
    7ff2:	5e                   	pop    %esi
    7ff3:	5f                   	pop    %edi
    7ff4:	5d                   	pop    %ebp
    7ff5:	c3                   	ret    

00007ff6 <tcap_time2cyc>:
#define TCAP_TIME_MAX_BITS(c) (((u64_t)c >> TCAP_TIME_MAX_ORD) << TCAP_TIME_MAX_ORD)
#define TCAP_TIME_NIL 0

static inline cycles_t
tcap_time2cyc(tcap_time_t c, cycles_t curr)
{
    7ff6:	55                   	push   %ebp
    7ff7:	89 e5                	mov    %esp,%ebp
    7ff9:	57                   	push   %edi
    7ffa:	56                   	push   %esi
    7ffb:	53                   	push   %ebx
    7ffc:	83 ec 14             	sub    $0x14,%esp
    7fff:	8b 45 0c             	mov    0xc(%ebp),%eax
    8002:	89 45 e8             	mov    %eax,-0x18(%ebp)
    8005:	8b 45 10             	mov    0x10(%ebp),%eax
    8008:	89 45 ec             	mov    %eax,-0x14(%ebp)
	return (((cycles_t)c) << TCAP_TIME_QUANTUM_ORD) | TCAP_TIME_MAX_BITS(curr);
    800b:	8b 45 08             	mov    0x8(%ebp),%eax
    800e:	ba 00 00 00 00       	mov    $0x0,%edx
    8013:	0f a4 c2 0c          	shld   $0xc,%eax,%edx
    8017:	c1 e0 0c             	shl    $0xc,%eax
    801a:	89 45 e0             	mov    %eax,-0x20(%ebp)
    801d:	89 55 e4             	mov    %edx,-0x1c(%ebp)
    8020:	8b 45 e8             	mov    -0x18(%ebp),%eax
    8023:	83 e0 00             	and    $0x0,%eax
    8026:	89 c1                	mov    %eax,%ecx
    8028:	8b 45 ec             	mov    -0x14(%ebp),%eax
    802b:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    8030:	89 c3                	mov    %eax,%ebx
    8032:	8b 45 e0             	mov    -0x20(%ebp),%eax
    8035:	09 c8                	or     %ecx,%eax
    8037:	89 c6                	mov    %eax,%esi
    8039:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    803c:	09 d8                	or     %ebx,%eax
    803e:	89 c7                	mov    %eax,%edi
    8040:	89 f0                	mov    %esi,%eax
    8042:	89 fa                	mov    %edi,%edx
}
    8044:	83 c4 14             	add    $0x14,%esp
    8047:	5b                   	pop    %ebx
    8048:	5e                   	pop    %esi
    8049:	5f                   	pop    %edi
    804a:	5d                   	pop    %ebp
    804b:	c3                   	ret    

0000804c <tcap_cyc2time>:
static inline tcap_time_t
tcap_cyc2time(cycles_t c)
{
    804c:	55                   	push   %ebp
    804d:	89 e5                	mov    %esp,%ebp
    804f:	83 ec 18             	sub    $0x18,%esp
    8052:	8b 45 08             	mov    0x8(%ebp),%eax
    8055:	89 45 e8             	mov    %eax,-0x18(%ebp)
    8058:	8b 45 0c             	mov    0xc(%ebp),%eax
    805b:	89 45 ec             	mov    %eax,-0x14(%ebp)
	tcap_time_t t = (tcap_time_t)(c >> TCAP_TIME_QUANTUM_ORD);
    805e:	8b 45 e8             	mov    -0x18(%ebp),%eax
    8061:	8b 55 ec             	mov    -0x14(%ebp),%edx
    8064:	0f ac d0 0c          	shrd   $0xc,%edx,%eax
    8068:	c1 ea 0c             	shr    $0xc,%edx
    806b:	89 45 fc             	mov    %eax,-0x4(%ebp)
	return t == TCAP_TIME_NIL ? 1 : t;
    806e:	83 7d fc 00          	cmpl   $0x0,-0x4(%ebp)
    8072:	74 05                	je     8079 <tcap_cyc2time+0x2d>
    8074:	8b 45 fc             	mov    -0x4(%ebp),%eax
    8077:	eb 05                	jmp    807e <tcap_cyc2time+0x32>
    8079:	b8 01 00 00 00       	mov    $0x1,%eax
}
    807e:	c9                   	leave  
    807f:	c3                   	ret    

00008080 <cycles_same>:
static inline int
cycles_same(cycles_t a, cycles_t b, cycles_t diff_thresh)
{
    8080:	55                   	push   %ebp
    8081:	89 e5                	mov    %esp,%ebp
    8083:	53                   	push   %ebx
    8084:	83 ec 1c             	sub    $0x1c,%esp
    8087:	8b 45 08             	mov    0x8(%ebp),%eax
    808a:	89 45 f0             	mov    %eax,-0x10(%ebp)
    808d:	8b 45 0c             	mov    0xc(%ebp),%eax
    8090:	89 45 f4             	mov    %eax,-0xc(%ebp)
    8093:	8b 45 10             	mov    0x10(%ebp),%eax
    8096:	89 45 e8             	mov    %eax,-0x18(%ebp)
    8099:	8b 45 14             	mov    0x14(%ebp),%eax
    809c:	89 45 ec             	mov    %eax,-0x14(%ebp)
    809f:	8b 45 18             	mov    0x18(%ebp),%eax
    80a2:	89 45 e0             	mov    %eax,-0x20(%ebp)
    80a5:	8b 45 1c             	mov    0x1c(%ebp),%eax
    80a8:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	return (b < a ? a - b : b - a) <= diff_thresh;
    80ab:	8b 45 e8             	mov    -0x18(%ebp),%eax
    80ae:	8b 55 ec             	mov    -0x14(%ebp),%edx
    80b1:	3b 55 f4             	cmp    -0xc(%ebp),%edx
    80b4:	77 1c                	ja     80d2 <cycles_same+0x52>
    80b6:	3b 55 f4             	cmp    -0xc(%ebp),%edx
    80b9:	72 05                	jb     80c0 <cycles_same+0x40>
    80bb:	3b 45 f0             	cmp    -0x10(%ebp),%eax
    80be:	73 12                	jae    80d2 <cycles_same+0x52>
    80c0:	8b 4d e8             	mov    -0x18(%ebp),%ecx
    80c3:	8b 5d ec             	mov    -0x14(%ebp),%ebx
    80c6:	8b 45 f0             	mov    -0x10(%ebp),%eax
    80c9:	8b 55 f4             	mov    -0xc(%ebp),%edx
    80cc:	29 c8                	sub    %ecx,%eax
    80ce:	19 da                	sbb    %ebx,%edx
    80d0:	eb 10                	jmp    80e2 <cycles_same+0x62>
    80d2:	8b 4d f0             	mov    -0x10(%ebp),%ecx
    80d5:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    80d8:	8b 45 e8             	mov    -0x18(%ebp),%eax
    80db:	8b 55 ec             	mov    -0x14(%ebp),%edx
    80de:	29 c8                	sub    %ecx,%eax
    80e0:	19 da                	sbb    %ebx,%edx
    80e2:	b9 01 00 00 00       	mov    $0x1,%ecx
    80e7:	3b 55 e4             	cmp    -0x1c(%ebp),%edx
    80ea:	72 0f                	jb     80fb <cycles_same+0x7b>
    80ec:	3b 55 e4             	cmp    -0x1c(%ebp),%edx
    80ef:	77 05                	ja     80f6 <cycles_same+0x76>
    80f1:	3b 45 e0             	cmp    -0x20(%ebp),%eax
    80f4:	76 05                	jbe    80fb <cycles_same+0x7b>
    80f6:	b9 00 00 00 00       	mov    $0x0,%ecx
    80fb:	0f b6 c1             	movzbl %cl,%eax
}
    80fe:	83 c4 1c             	add    $0x1c,%esp
    8101:	5b                   	pop    %ebx
    8102:	5d                   	pop    %ebp
    8103:	c3                   	ret    

00008104 <__bitmap_set>:
}

/* set bit v in x.  v is offset from 0. */
static inline u32_t
__bitmap_set(u32_t x, int v)
{
    8104:	55                   	push   %ebp
    8105:	89 e5                	mov    %esp,%ebp
	return x | (1 << v);
    8107:	8b 45 0c             	mov    0xc(%ebp),%eax
    810a:	ba 01 00 00 00       	mov    $0x1,%edx
    810f:	89 c1                	mov    %eax,%ecx
    8111:	d3 e2                	shl    %cl,%edx
    8113:	89 d0                	mov    %edx,%eax
    8115:	0b 45 08             	or     0x8(%ebp),%eax
}
    8118:	5d                   	pop    %ebp
    8119:	c3                   	ret    

0000811a <__bitmap_check>:

static inline int
__bitmap_check(u32_t x, int v)
{
    811a:	55                   	push   %ebp
    811b:	89 e5                	mov    %esp,%ebp
	return x & (1 << v);
    811d:	8b 45 0c             	mov    0xc(%ebp),%eax
    8120:	ba 01 00 00 00       	mov    $0x1,%edx
    8125:	89 c1                	mov    %eax,%ecx
    8127:	d3 e2                	shl    %cl,%edx
    8129:	89 d0                	mov    %edx,%eax
    812b:	23 45 08             	and    0x8(%ebp),%eax
}
    812e:	5d                   	pop    %ebp
    812f:	c3                   	ret    

00008130 <__bitmap_unset>:

static inline u32_t
__bitmap_unset(u32_t x, int v)
{
    8130:	55                   	push   %ebp
    8131:	89 e5                	mov    %esp,%ebp
	return x & ~(1 << v);
    8133:	8b 45 0c             	mov    0xc(%ebp),%eax
    8136:	ba 01 00 00 00       	mov    $0x1,%edx
    813b:	89 c1                	mov    %eax,%ecx
    813d:	d3 e2                	shl    %cl,%edx
    813f:	89 d0                	mov    %edx,%eax
    8141:	f7 d0                	not    %eax
    8143:	23 45 08             	and    0x8(%ebp),%eax
}
    8146:	5d                   	pop    %ebp
    8147:	c3                   	ret    

00008148 <bitmap_set>:

static inline void
bitmap_set(u32_t *x, int v)
{
    8148:	55                   	push   %ebp
    8149:	89 e5                	mov    %esp,%ebp
    814b:	53                   	push   %ebx
    814c:	83 ec 18             	sub    $0x18,%esp
	int idx, off;
	idx    = v / WORD_SIZE; /* WORD_SIZE = sizeof(u32_t) */
    814f:	8b 45 0c             	mov    0xc(%ebp),%eax
    8152:	8d 50 1f             	lea    0x1f(%eax),%edx
    8155:	85 c0                	test   %eax,%eax
    8157:	0f 48 c2             	cmovs  %edx,%eax
    815a:	c1 f8 05             	sar    $0x5,%eax
    815d:	89 45 f8             	mov    %eax,-0x8(%ebp)
	off    = v & (WORD_SIZE - 1);
    8160:	8b 45 0c             	mov    0xc(%ebp),%eax
    8163:	83 e0 1f             	and    $0x1f,%eax
    8166:	89 45 f4             	mov    %eax,-0xc(%ebp)
	x[idx] = __bitmap_set(x[idx], off);
    8169:	8b 45 f8             	mov    -0x8(%ebp),%eax
    816c:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    8173:	8b 45 08             	mov    0x8(%ebp),%eax
    8176:	8d 1c 02             	lea    (%edx,%eax,1),%ebx
    8179:	8b 45 f8             	mov    -0x8(%ebp),%eax
    817c:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    8183:	8b 45 08             	mov    0x8(%ebp),%eax
    8186:	01 d0                	add    %edx,%eax
    8188:	8b 00                	mov    (%eax),%eax
    818a:	8b 55 f4             	mov    -0xc(%ebp),%edx
    818d:	89 54 24 04          	mov    %edx,0x4(%esp)
    8191:	89 04 24             	mov    %eax,(%esp)
    8194:	e8 6b ff ff ff       	call   8104 <__bitmap_set>
    8199:	89 03                	mov    %eax,(%ebx)
}
    819b:	83 c4 18             	add    $0x18,%esp
    819e:	5b                   	pop    %ebx
    819f:	5d                   	pop    %ebp
    81a0:	c3                   	ret    

000081a1 <bitmap_check>:

static inline int
bitmap_check(u32_t *x, int v)
{
    81a1:	55                   	push   %ebp
    81a2:	89 e5                	mov    %esp,%ebp
    81a4:	83 ec 18             	sub    $0x18,%esp
	int idx, off;
	idx = v / WORD_SIZE; /* WORD_SIZE = sizeof(u32_t) */
    81a7:	8b 45 0c             	mov    0xc(%ebp),%eax
    81aa:	8d 50 1f             	lea    0x1f(%eax),%edx
    81ad:	85 c0                	test   %eax,%eax
    81af:	0f 48 c2             	cmovs  %edx,%eax
    81b2:	c1 f8 05             	sar    $0x5,%eax
    81b5:	89 45 fc             	mov    %eax,-0x4(%ebp)
	off = v & (WORD_SIZE - 1);
    81b8:	8b 45 0c             	mov    0xc(%ebp),%eax
    81bb:	83 e0 1f             	and    $0x1f,%eax
    81be:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return __bitmap_check(x[idx], off);
    81c1:	8b 45 fc             	mov    -0x4(%ebp),%eax
    81c4:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    81cb:	8b 45 08             	mov    0x8(%ebp),%eax
    81ce:	01 d0                	add    %edx,%eax
    81d0:	8b 00                	mov    (%eax),%eax
    81d2:	8b 55 f8             	mov    -0x8(%ebp),%edx
    81d5:	89 54 24 04          	mov    %edx,0x4(%esp)
    81d9:	89 04 24             	mov    %eax,(%esp)
    81dc:	e8 39 ff ff ff       	call   811a <__bitmap_check>
}
    81e1:	c9                   	leave  
    81e2:	c3                   	ret    

000081e3 <bitmap_unset>:

static inline void
bitmap_unset(u32_t *x, int v)
{
    81e3:	55                   	push   %ebp
    81e4:	89 e5                	mov    %esp,%ebp
    81e6:	53                   	push   %ebx
    81e7:	83 ec 18             	sub    $0x18,%esp
	int idx, off;
	idx    = v / WORD_SIZE; /* WORD_SIZE = sizeof(u32_t) */
    81ea:	8b 45 0c             	mov    0xc(%ebp),%eax
    81ed:	8d 50 1f             	lea    0x1f(%eax),%edx
    81f0:	85 c0                	test   %eax,%eax
    81f2:	0f 48 c2             	cmovs  %edx,%eax
    81f5:	c1 f8 05             	sar    $0x5,%eax
    81f8:	89 45 f8             	mov    %eax,-0x8(%ebp)
	off    = v & (WORD_SIZE - 1);
    81fb:	8b 45 0c             	mov    0xc(%ebp),%eax
    81fe:	83 e0 1f             	and    $0x1f,%eax
    8201:	89 45 f4             	mov    %eax,-0xc(%ebp)
	x[idx] = __bitmap_unset(x[idx], off);
    8204:	8b 45 f8             	mov    -0x8(%ebp),%eax
    8207:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    820e:	8b 45 08             	mov    0x8(%ebp),%eax
    8211:	8d 1c 02             	lea    (%edx,%eax,1),%ebx
    8214:	8b 45 f8             	mov    -0x8(%ebp),%eax
    8217:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    821e:	8b 45 08             	mov    0x8(%ebp),%eax
    8221:	01 d0                	add    %edx,%eax
    8223:	8b 00                	mov    (%eax),%eax
    8225:	8b 55 f4             	mov    -0xc(%ebp),%edx
    8228:	89 54 24 04          	mov    %edx,0x4(%esp)
    822c:	89 04 24             	mov    %eax,(%esp)
    822f:	e8 fc fe ff ff       	call   8130 <__bitmap_unset>
    8234:	89 03                	mov    %eax,(%ebx)
}
    8236:	83 c4 18             	add    $0x18,%esp
    8239:	5b                   	pop    %ebx
    823a:	5d                   	pop    %ebp
    823b:	c3                   	ret    

0000823c <bitmap_set_contig>:
	return ret;
}

static inline void
bitmap_set_contig(u32_t *x, int off, int extent, int one)
{
    823c:	55                   	push   %ebp
    823d:	89 e5                	mov    %esp,%ebp
    823f:	83 ec 18             	sub    $0x18,%esp
	int i;

	/* TODO: could optimize by setting blocks of 8, 16, 32... */
	for (i = off; i < off + extent; i++) {
    8242:	8b 45 0c             	mov    0xc(%ebp),%eax
    8245:	89 45 fc             	mov    %eax,-0x4(%ebp)
    8248:	eb 30                	jmp    827a <bitmap_set_contig+0x3e>
		if (one)
    824a:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
    824e:	74 14                	je     8264 <bitmap_set_contig+0x28>
			bitmap_set(x, i);
    8250:	8b 45 fc             	mov    -0x4(%ebp),%eax
    8253:	89 44 24 04          	mov    %eax,0x4(%esp)
    8257:	8b 45 08             	mov    0x8(%ebp),%eax
    825a:	89 04 24             	mov    %eax,(%esp)
    825d:	e8 e6 fe ff ff       	call   8148 <bitmap_set>
    8262:	eb 12                	jmp    8276 <bitmap_set_contig+0x3a>
		else
			bitmap_unset(x, i);
    8264:	8b 45 fc             	mov    -0x4(%ebp),%eax
    8267:	89 44 24 04          	mov    %eax,0x4(%esp)
    826b:	8b 45 08             	mov    0x8(%ebp),%eax
    826e:	89 04 24             	mov    %eax,(%esp)
    8271:	e8 6d ff ff ff       	call   81e3 <bitmap_unset>
bitmap_set_contig(u32_t *x, int off, int extent, int one)
{
	int i;

	/* TODO: could optimize by setting blocks of 8, 16, 32... */
	for (i = off; i < off + extent; i++) {
    8276:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
    827a:	8b 45 10             	mov    0x10(%ebp),%eax
    827d:	8b 55 0c             	mov    0xc(%ebp),%edx
    8280:	01 d0                	add    %edx,%eax
    8282:	3b 45 fc             	cmp    -0x4(%ebp),%eax
    8285:	7f c3                	jg     824a <bitmap_set_contig+0xe>
		if (one)
			bitmap_set(x, i);
		else
			bitmap_unset(x, i);
	}
}
    8287:	c9                   	leave  
    8288:	c3                   	ret    

00008289 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
    8289:	55                   	push   %ebp
    828a:	89 e5                	mov    %esp,%ebp
    828c:	57                   	push   %edi
    828d:	56                   	push   %esi
    828e:	53                   	push   %ebx
    828f:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    8292:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    8299:	8b 45 08             	mov    0x8(%ebp),%eax
    829c:	83 c0 01             	add    $0x1,%eax
    829f:	c1 e0 10             	shl    $0x10,%eax
    82a2:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    82a5:	8b 45 0c             	mov    0xc(%ebp),%eax
    82a8:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    82ab:	8b 45 08             	mov    0x8(%ebp),%eax
    82ae:	8b 4d 10             	mov    0x10(%ebp),%ecx
    82b1:	8b 75 14             	mov    0x14(%ebp),%esi
    82b4:	8b 7d 18             	mov    0x18(%ebp),%edi
    82b7:	8b 55 1c             	mov    0x1c(%ebp),%edx
    82ba:	89 cb                	mov    %ecx,%ebx
    82bc:	55                   	push   %ebp
    82bd:	89 e5                	mov    %esp,%ebp
    82bf:	b9 d0 82 00 00       	mov    $0x82d0,%ecx
    82c4:	0f 34                	sysenter 
    82c6:	66 90                	xchg   %ax,%ax
    82c8:	eb 0d                	jmp    82d7 <call_cap_asm+0x4e>
    82ca:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    82d0:	b9 00 00 00 00       	mov    $0x0,%ecx
    82d5:	eb 05                	jmp    82dc <call_cap_asm+0x53>
    82d7:	b9 01 00 00 00       	mov    $0x1,%ecx
    82dc:	5d                   	pop    %ebp
    82dd:	89 ca                	mov    %ecx,%edx
    82df:	89 45 ec             	mov    %eax,-0x14(%ebp)
    82e2:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    82e5:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    82e8:	83 c4 10             	add    $0x10,%esp
    82eb:	5b                   	pop    %ebx
    82ec:	5e                   	pop    %esi
    82ed:	5f                   	pop    %edi
    82ee:	5d                   	pop    %ebp
    82ef:	c3                   	ret    

000082f0 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
    82f0:	55                   	push   %ebp
    82f1:	89 e5                	mov    %esp,%ebp
    82f3:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
    82f6:	8b 45 18             	mov    0x18(%ebp),%eax
    82f9:	89 44 24 14          	mov    %eax,0x14(%esp)
    82fd:	8b 45 14             	mov    0x14(%ebp),%eax
    8300:	89 44 24 10          	mov    %eax,0x10(%esp)
    8304:	8b 45 10             	mov    0x10(%ebp),%eax
    8307:	89 44 24 0c          	mov    %eax,0xc(%esp)
    830b:	8b 45 0c             	mov    0xc(%ebp),%eax
    830e:	89 44 24 08          	mov    %eax,0x8(%esp)
    8312:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    8319:	00 
    831a:	8b 45 08             	mov    0x8(%ebp),%eax
    831d:	89 04 24             	mov    %eax,(%esp)
    8320:	e8 64 ff ff ff       	call   8289 <call_cap_asm>
}
    8325:	c9                   	leave  
    8326:	c3                   	ret    

00008327 <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
    8327:	55                   	push   %ebp
    8328:	89 e5                	mov    %esp,%ebp
    832a:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
    832d:	8b 45 08             	mov    0x8(%ebp),%eax
    8330:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    8337:	00 
    8338:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    833f:	00 
    8340:	8b 55 0c             	mov    0xc(%ebp),%edx
    8343:	89 54 24 08          	mov    %edx,0x8(%esp)
    8347:	89 44 24 04          	mov    %eax,0x4(%esp)
    834b:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    8352:	e8 99 ff ff ff       	call   82f0 <call_cap>
}
    8357:	c9                   	leave  
    8358:	c3                   	ret    

00008359 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
    8359:	55                   	push   %ebp
    835a:	89 e5                	mov    %esp,%ebp
    835c:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
    835f:	89 e0                	mov    %esp,%eax
    8361:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
    8364:	8b 45 fc             	mov    -0x4(%ebp),%eax
    8367:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    836c:	89 c2                	mov    %eax,%edx
    836e:	8b 45 08             	mov    0x8(%ebp),%eax
    8371:	c1 e0 02             	shl    $0x2,%eax
    8374:	29 c2                	sub    %eax,%edx
    8376:	89 d0                	mov    %edx,%eax
    8378:	05 00 10 00 00       	add    $0x1000,%eax
    837d:	8b 00                	mov    (%eax),%eax
}
    837f:	c9                   	leave  
    8380:	c3                   	ret    

00008381 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
    8381:	55                   	push   %ebp
    8382:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
    8384:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
    8389:	5d                   	pop    %ebp
    838a:	c3                   	ret    

0000838b <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
    838b:	55                   	push   %ebp
    838c:	89 e5                	mov    %esp,%ebp
    838e:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
    8391:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    8398:	e8 bc ff ff ff       	call   8359 <get_stk_data>
}
    839d:	c9                   	leave  
    839e:	c3                   	ret    

0000839f <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
    839f:	55                   	push   %ebp
    83a0:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
    83a2:	e8 e4 ff ff ff       	call   838b <cos_get_thd_id>
}
    83a7:	5d                   	pop    %ebp
    83a8:	c3                   	ret    

000083a9 <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
    83a9:	55                   	push   %ebp
    83aa:	89 e5                	mov    %esp,%ebp
    83ac:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
    83af:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    83b6:	eb 20                	jmp    83d8 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
    83b8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    83bb:	83 c0 01             	add    $0x1,%eax
    83be:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    83c5:	8b 45 08             	mov    0x8(%ebp),%eax
    83c8:	01 d0                	add    %edx,%eax
    83ca:	8b 00                	mov    (%eax),%eax
    83cc:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
    83cf:	8b 45 f0             	mov    -0x10(%ebp),%eax
    83d2:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
    83d4:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    83d8:	8b 45 08             	mov    0x8(%ebp),%eax
    83db:	8b 00                	mov    (%eax),%eax
    83dd:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    83e0:	7f d6                	jg     83b8 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
    83e2:	c9                   	leave  
    83e3:	c3                   	ret    

000083e4 <constructors_execute>:

static void
constructors_execute(void)
{
    83e4:	55                   	push   %ebp
    83e5:	89 e5                	mov    %esp,%ebp
    83e7:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
    83ea:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    83f1:	e8 b3 ff ff ff       	call   83a9 <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
    83f6:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    83fd:	e8 a7 ff ff ff       	call   83a9 <section_fnptrs_execute>
}
    8402:	c9                   	leave  
    8403:	c3                   	ret    

00008404 <destructors_execute>:
static void
destructors_execute(void)
{
    8404:	55                   	push   %ebp
    8405:	89 e5                	mov    %esp,%ebp
    8407:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
    840a:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    8411:	e8 93 ff ff ff       	call   83a9 <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
    8416:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    841d:	e8 87 ff ff ff       	call   83a9 <section_fnptrs_execute>
}
    8422:	c9                   	leave  
    8423:	c3                   	ret    

00008424 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
    8424:	55                   	push   %ebp
    8425:	89 e5                	mov    %esp,%ebp
    8427:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
    842a:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    8431:	e8 73 ff ff ff       	call   83a9 <section_fnptrs_execute>
}
    8436:	c9                   	leave  
    8437:	c3                   	ret    

00008438 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
    8438:	55                   	push   %ebp
    8439:	89 e5                	mov    %esp,%ebp
    843b:	83 ec 08             	sub    $0x8,%esp
    843e:	8b 55 08             	mov    0x8(%ebp),%edx
    8441:	8b 45 0c             	mov    0xc(%ebp),%eax
    8444:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
    8448:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
    844b:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    844f:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
    8453:	ee                   	out    %al,(%dx)
}
    8454:	c9                   	leave  
    8455:	c3                   	ret    

00008456 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
    8456:	55                   	push   %ebp
    8457:	89 e5                	mov    %esp,%ebp
    8459:	83 ec 14             	sub    $0x14,%esp
    845c:	8b 45 08             	mov    0x8(%ebp),%eax
    845f:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
    8463:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
    8467:	89 c2                	mov    %eax,%edx
    8469:	ec                   	in     (%dx),%al
    846a:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
    846d:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
    8471:	c9                   	leave  
    8472:	c3                   	ret    

00008473 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
    8473:	55                   	push   %ebp
    8474:	89 e5                	mov    %esp,%ebp
    8476:	83 ec 0c             	sub    $0xc,%esp
    8479:	8b 45 08             	mov    0x8(%ebp),%eax
    847c:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
    847f:	90                   	nop
    8480:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
    8487:	e8 ca ff ff ff       	call   8456 <inb>
    848c:	0f b6 c0             	movzbl %al,%eax
    848f:	83 e0 20             	and    $0x20,%eax
    8492:	85 c0                	test   %eax,%eax
    8494:	74 ea                	je     8480 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
    8496:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    849a:	0f b6 c0             	movzbl %al,%eax
    849d:	89 44 24 04          	mov    %eax,0x4(%esp)
    84a1:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
    84a8:	e8 8b ff ff ff       	call   8438 <outb>
}
    84ad:	c9                   	leave  
    84ae:	c3                   	ret    

000084af <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
    84af:	55                   	push   %ebp
    84b0:	89 e5                	mov    %esp,%ebp
    84b2:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
    84b5:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
    84bc:	eb 1a                	jmp    84d8 <cos_serial_putb+0x29>
    84be:	8b 45 fc             	mov    -0x4(%ebp),%eax
    84c1:	8b 55 08             	mov    0x8(%ebp),%edx
    84c4:	01 d0                	add    %edx,%eax
    84c6:	0f b6 00             	movzbl (%eax),%eax
    84c9:	0f be c0             	movsbl %al,%eax
    84cc:	89 04 24             	mov    %eax,(%esp)
    84cf:	e8 9f ff ff ff       	call   8473 <cos_serial_putc>
    84d4:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
    84d8:	8b 45 fc             	mov    -0x4(%ebp),%eax
    84db:	3b 45 0c             	cmp    0xc(%ebp),%eax
    84de:	72 de                	jb     84be <cos_serial_putb+0xf>
}
    84e0:	c9                   	leave  
    84e1:	c3                   	ret    

000084e2 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
    84e2:	55                   	push   %ebp
    84e3:	89 e5                	mov    %esp,%ebp
    84e5:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
    84e8:	8b 45 0c             	mov    0xc(%ebp),%eax
    84eb:	89 44 24 04          	mov    %eax,0x4(%esp)
    84ef:	8b 45 08             	mov    0x8(%ebp),%eax
    84f2:	89 04 24             	mov    %eax,(%esp)
    84f5:	e8 b5 ff ff ff       	call   84af <cos_serial_putb>
}
    84fa:	c9                   	leave  
    84fb:	c3                   	ret    

000084fc <prints>:

static int
prints(char *s)
{
    84fc:	55                   	push   %ebp
    84fd:	89 e5                	mov    %esp,%ebp
    84ff:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
    8502:	8b 45 08             	mov    0x8(%ebp),%eax
    8505:	89 04 24             	mov    %eax,(%esp)
    8508:	e8 fc ff ff ff       	call   8509 <prints+0xd>
    850d:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
    8510:	8b 45 f4             	mov    -0xc(%ebp),%eax
    8513:	89 44 24 04          	mov    %eax,0x4(%esp)
    8517:	8b 45 08             	mov    0x8(%ebp),%eax
    851a:	89 04 24             	mov    %eax,(%esp)
    851d:	e8 05 fe ff ff       	call   8327 <cos_print>

	return len;
    8522:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    8525:	c9                   	leave  
    8526:	c3                   	ret    

00008527 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
    8527:	55                   	push   %ebp
    8528:	89 e5                	mov    %esp,%ebp
    852a:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
    8530:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
    8537:	8d 45 0c             	lea    0xc(%ebp),%eax
    853a:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
    8540:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
    8546:	89 44 24 0c          	mov    %eax,0xc(%esp)
    854a:	8b 45 08             	mov    0x8(%ebp),%eax
    854d:	89 44 24 08          	mov    %eax,0x8(%esp)
    8551:	8b 45 f4             	mov    -0xc(%ebp),%eax
    8554:	89 44 24 04          	mov    %eax,0x4(%esp)
    8558:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    855e:	89 04 24             	mov    %eax,(%esp)
    8561:	e8 fc ff ff ff       	call   8562 <printc+0x3b>
    8566:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
    8569:	8b 45 f0             	mov    -0x10(%ebp),%eax
    856c:	89 44 24 04          	mov    %eax,0x4(%esp)
    8570:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    8576:	89 04 24             	mov    %eax,(%esp)
    8579:	e8 64 ff ff ff       	call   84e2 <cos_llprint>

	return ret;
    857e:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    8581:	c9                   	leave  
    8582:	c3                   	ret    

00008583 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
    8583:	55                   	push   %ebp
    8584:	89 e5                	mov    %esp,%ebp
	while (1)
		;
    8586:	eb fe                	jmp    8586 <__cos_noret+0x3>

00008588 <__slab_freelist_rem>:
static inline void __ps_slab_freelist_check(struct ps_slab_freelist *fl) { (void)fl; }
#endif /* PS_SLAB_DEBUG */

static void
__slab_freelist_rem(struct ps_slab_freelist *fl, struct ps_slab *s)
{
    8588:	55                   	push   %ebp
    8589:	89 e5                	mov    %esp,%ebp
    858b:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
    858e:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    8592:	0f 94 c0             	sete   %al
    8595:	0f b6 c0             	movzbl %al,%eax
    8598:	85 c0                	test   %eax,%eax
    859a:	75 0e                	jne    85aa <__slab_freelist_rem+0x22>
    859c:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    85a0:	0f 94 c0             	sete   %al
    85a3:	0f b6 c0             	movzbl %al,%eax
    85a6:	85 c0                	test   %eax,%eax
    85a8:	74 1c                	je     85c6 <__slab_freelist_rem+0x3e>
    85aa:	c7 04 24 e4 16 00 00 	movl   $0x16e4,(%esp)
    85b1:	e8 46 ff ff ff       	call   84fc <prints>
    85b6:	a1 40 01 00 00       	mov    0x140,%eax
    85bb:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    85c1:	e8 bd ff ff ff       	call   8583 <__cos_noret>
	if (fl->list == s) {
    85c6:	8b 45 08             	mov    0x8(%ebp),%eax
    85c9:	8b 00                	mov    (%eax),%eax
    85cb:	3b 45 0c             	cmp    0xc(%ebp),%eax
    85ce:	75 2b                	jne    85fb <__slab_freelist_rem+0x73>
		if (ps_list_singleton(s, list)) fl->list = NULL;
    85d0:	8b 45 0c             	mov    0xc(%ebp),%eax
    85d3:	83 c0 44             	add    $0x44,%eax
    85d6:	89 04 24             	mov    %eax,(%esp)
    85d9:	e8 06 f9 ff ff       	call   7ee4 <ps_list_ll_empty>
    85de:	85 c0                	test   %eax,%eax
    85e0:	74 0b                	je     85ed <__slab_freelist_rem+0x65>
    85e2:	8b 45 08             	mov    0x8(%ebp),%eax
    85e5:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    85eb:	eb 0e                	jmp    85fb <__slab_freelist_rem+0x73>
		else                            fl->list = ps_list_next(s, list);
    85ed:	8b 45 0c             	mov    0xc(%ebp),%eax
    85f0:	8b 40 44             	mov    0x44(%eax),%eax
    85f3:	8d 50 bc             	lea    -0x44(%eax),%edx
    85f6:	8b 45 08             	mov    0x8(%ebp),%eax
    85f9:	89 10                	mov    %edx,(%eax)
	}
	ps_list_rem(s, list);
    85fb:	8b 45 0c             	mov    0xc(%ebp),%eax
    85fe:	83 c0 44             	add    $0x44,%eax
    8601:	89 04 24             	mov    %eax,(%esp)
    8604:	e8 2c f9 ff ff       	call   7f35 <ps_list_ll_rem>
}
    8609:	c9                   	leave  
    860a:	c3                   	ret    

0000860b <__slab_freelist_add>:

static void
__slab_freelist_add(struct ps_slab_freelist *fl, struct ps_slab *s)
{
    860b:	55                   	push   %ebp
    860c:	89 e5                	mov    %esp,%ebp
    860e:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
    8611:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    8615:	0f 94 c0             	sete   %al
    8618:	0f b6 c0             	movzbl %al,%eax
    861b:	85 c0                	test   %eax,%eax
    861d:	75 0e                	jne    862d <__slab_freelist_add+0x22>
    861f:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    8623:	0f 94 c0             	sete   %al
    8626:	0f b6 c0             	movzbl %al,%eax
    8629:	85 c0                	test   %eax,%eax
    862b:	74 1c                	je     8649 <__slab_freelist_add+0x3e>
    862d:	c7 04 24 3c 17 00 00 	movl   $0x173c,(%esp)
    8634:	e8 c3 fe ff ff       	call   84fc <prints>
    8639:	a1 40 01 00 00       	mov    0x140,%eax
    863e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    8644:	e8 3a ff ff ff       	call   8583 <__cos_noret>
	assert(ps_list_singleton(s, list));
    8649:	8b 45 0c             	mov    0xc(%ebp),%eax
    864c:	83 c0 44             	add    $0x44,%eax
    864f:	89 04 24             	mov    %eax,(%esp)
    8652:	e8 8d f8 ff ff       	call   7ee4 <ps_list_ll_empty>
    8657:	85 c0                	test   %eax,%eax
    8659:	0f 94 c0             	sete   %al
    865c:	0f b6 c0             	movzbl %al,%eax
    865f:	85 c0                	test   %eax,%eax
    8661:	74 1c                	je     867f <__slab_freelist_add+0x74>
    8663:	c7 04 24 94 17 00 00 	movl   $0x1794,(%esp)
    866a:	e8 8d fe ff ff       	call   84fc <prints>
    866f:	a1 40 01 00 00       	mov    0x140,%eax
    8674:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    867a:	e8 04 ff ff ff       	call   8583 <__cos_noret>
	assert(s != fl->list);
    867f:	8b 45 08             	mov    0x8(%ebp),%eax
    8682:	8b 00                	mov    (%eax),%eax
    8684:	3b 45 0c             	cmp    0xc(%ebp),%eax
    8687:	0f 94 c0             	sete   %al
    868a:	0f b6 c0             	movzbl %al,%eax
    868d:	85 c0                	test   %eax,%eax
    868f:	74 1c                	je     86ad <__slab_freelist_add+0xa2>
    8691:	c7 04 24 ec 17 00 00 	movl   $0x17ec,(%esp)
    8698:	e8 5f fe ff ff       	call   84fc <prints>
    869d:	a1 40 01 00 00       	mov    0x140,%eax
    86a2:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    86a8:	e8 d6 fe ff ff       	call   8583 <__cos_noret>
	if (fl->list) ps_list_add(fl->list, s, list);
    86ad:	8b 45 08             	mov    0x8(%ebp),%eax
    86b0:	8b 00                	mov    (%eax),%eax
    86b2:	85 c0                	test   %eax,%eax
    86b4:	74 1a                	je     86d0 <__slab_freelist_add+0xc5>
    86b6:	8b 45 0c             	mov    0xc(%ebp),%eax
    86b9:	8d 50 44             	lea    0x44(%eax),%edx
    86bc:	8b 45 08             	mov    0x8(%ebp),%eax
    86bf:	8b 00                	mov    (%eax),%eax
    86c1:	83 c0 44             	add    $0x44,%eax
    86c4:	89 54 24 04          	mov    %edx,0x4(%esp)
    86c8:	89 04 24             	mov    %eax,(%esp)
    86cb:	e8 3a f8 ff ff       	call   7f0a <ps_list_ll_add>
	fl->list = s;
    86d0:	8b 45 08             	mov    0x8(%ebp),%eax
    86d3:	8b 55 0c             	mov    0xc(%ebp),%edx
    86d6:	89 10                	mov    %edx,(%eax)
	/* TODO: sort based on emptiness...just use N bins */
}
    86d8:	c9                   	leave  
    86d9:	c3                   	ret    

000086da <cos_aepthd_fn>:
	struct cos_aep_info sched_aep[NUM_CPU];
};

static void
cos_aepthd_fn(void *data)
{
    86da:	55                   	push   %ebp
    86db:	89 e5                	mov    %esp,%ebp
    86dd:	83 ec 28             	sub    $0x28,%esp
	struct cos_aep_info *aep_info = (struct cos_aep_info *)data;
    86e0:	8b 45 08             	mov    0x8(%ebp),%eax
    86e3:	89 45 f4             	mov    %eax,-0xc(%ebp)
	cos_aepthd_fn_t      aep_fn   = aep_info->fn;
    86e6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    86e9:	8b 40 10             	mov    0x10(%eax),%eax
    86ec:	89 45 f0             	mov    %eax,-0x10(%ebp)
	void *               fn_data  = aep_info->data;
    86ef:	8b 45 f4             	mov    -0xc(%ebp),%eax
    86f2:	8b 40 14             	mov    0x14(%eax),%eax
    86f5:	89 45 ec             	mov    %eax,-0x14(%ebp)

	(aep_fn)(aep_info->rcv, fn_data);
    86f8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    86fb:	8b 40 0c             	mov    0xc(%eax),%eax
    86fe:	8b 55 ec             	mov    -0x14(%ebp),%edx
    8701:	89 54 24 04          	mov    %edx,0x4(%esp)
    8705:	89 04 24             	mov    %eax,(%esp)
    8708:	8b 45 f0             	mov    -0x10(%ebp),%eax
    870b:	ff d0                	call   *%eax

	/* TODO: handling destruction */
	assert(0);
    870d:	c7 04 24 44 18 00 00 	movl   $0x1844,(%esp)
    8714:	e8 e3 fd ff ff       	call   84fc <prints>
    8719:	a1 40 01 00 00       	mov    0x140,%eax
    871e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    8724:	e8 5a fe ff ff       	call   8583 <__cos_noret>

00008729 <sched_param_get>:

static inline void
sched_param_get(sched_param_t sp, sched_param_type_t *type, unsigned int *value)
{
    8729:	55                   	push   %ebp
    872a:	89 e5                	mov    %esp,%ebp
    872c:	83 ec 10             	sub    $0x10,%esp
	struct sched_param_s s = *(struct sched_param_s *)(void *)&sp;
    872f:	8d 45 08             	lea    0x8(%ebp),%eax
    8732:	8b 00                	mov    (%eax),%eax
    8734:	89 45 fc             	mov    %eax,-0x4(%ebp)

	*type  = s.type;
    8737:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    873b:	0f b6 d0             	movzbl %al,%edx
    873e:	8b 45 0c             	mov    0xc(%ebp),%eax
    8741:	89 10                	mov    %edx,(%eax)
	*value = s.value;
    8743:	8b 45 fc             	mov    -0x4(%ebp),%eax
    8746:	c1 e8 08             	shr    $0x8,%eax
    8749:	89 c2                	mov    %eax,%edx
    874b:	8b 45 10             	mov    0x10(%ebp),%eax
    874e:	89 10                	mov    %edx,(%eax)
}
    8750:	c9                   	leave  
    8751:	c3                   	ret    

00008752 <sl_thd_aepinfo>:
	struct ps_list    SL_THD_EVENT_LIST; /* list of events for the scheduler end-point */
};

static inline struct cos_aep_info *
sl_thd_aepinfo(struct sl_thd *t)
{ return (t->aepinfo); }
    8752:	55                   	push   %ebp
    8753:	89 e5                	mov    %esp,%ebp
    8755:	8b 45 08             	mov    0x8(%ebp),%eax
    8758:	8b 40 0c             	mov    0xc(%eax),%eax
    875b:	5d                   	pop    %ebp
    875c:	c3                   	ret    

0000875d <sl_thd_thdcap>:

static inline thdcap_t
sl_thd_thdcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->thd; }
    875d:	55                   	push   %ebp
    875e:	89 e5                	mov    %esp,%ebp
    8760:	83 ec 04             	sub    $0x4,%esp
    8763:	8b 45 08             	mov    0x8(%ebp),%eax
    8766:	89 04 24             	mov    %eax,(%esp)
    8769:	e8 e4 ff ff ff       	call   8752 <sl_thd_aepinfo>
    876e:	8b 40 04             	mov    0x4(%eax),%eax
    8771:	c9                   	leave  
    8772:	c3                   	ret    

00008773 <sl_thd_tcap>:

static inline tcap_t
sl_thd_tcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->tc; }
    8773:	55                   	push   %ebp
    8774:	89 e5                	mov    %esp,%ebp
    8776:	83 ec 04             	sub    $0x4,%esp
    8779:	8b 45 08             	mov    0x8(%ebp),%eax
    877c:	89 04 24             	mov    %eax,(%esp)
    877f:	e8 ce ff ff ff       	call   8752 <sl_thd_aepinfo>
    8784:	8b 00                	mov    (%eax),%eax
    8786:	c9                   	leave  
    8787:	c3                   	ret    

00008788 <sl_thd_rcvcap>:

static inline arcvcap_t
sl_thd_rcvcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->rcv; }
    8788:	55                   	push   %ebp
    8789:	89 e5                	mov    %esp,%ebp
    878b:	83 ec 04             	sub    $0x4,%esp
    878e:	8b 45 08             	mov    0x8(%ebp),%eax
    8791:	89 04 24             	mov    %eax,(%esp)
    8794:	e8 b9 ff ff ff       	call   8752 <sl_thd_aepinfo>
    8799:	8b 40 0c             	mov    0xc(%eax),%eax
    879c:	c9                   	leave  
    879d:	c3                   	ret    

0000879e <sl_mod_thd_get>:
	struct ps_list list;
} CACHE_ALIGNED;

static inline struct sl_thd *
sl_mod_thd_get(struct sl_thd_policy *tp)
{
    879e:	55                   	push   %ebp
    879f:	89 e5                	mov    %esp,%ebp
	return &tp->thd;
    87a1:	8b 45 08             	mov    0x8(%ebp),%eax
}
    87a4:	5d                   	pop    %ebp
    87a5:	c3                   	ret    

000087a6 <sl_mod_thd_policy_get>:

static inline struct sl_thd_policy *
sl_mod_thd_policy_get(struct sl_thd *t)
{
    87a6:	55                   	push   %ebp
    87a7:	89 e5                	mov    %esp,%ebp
	return ps_container(t, struct sl_thd_policy, thd);
    87a9:	8b 45 08             	mov    0x8(%ebp),%eax
}
    87ac:	5d                   	pop    %ebp
    87ad:	c3                   	ret    

000087ae <ck_cc_ffs>:
 */
#ifndef CK_MD_CC_BUILTIN_DISABLE
#define CK_F_CC_FFS
CK_CC_INLINE static int
ck_cc_ffs(unsigned int x)
{
    87ae:	55                   	push   %ebp
    87af:	89 e5                	mov    %esp,%ebp

	return __builtin_ffsl(x);
    87b1:	8b 45 08             	mov    0x8(%ebp),%eax
    87b4:	ba ff ff ff ff       	mov    $0xffffffff,%edx
    87b9:	0f bc c0             	bsf    %eax,%eax
    87bc:	0f 44 c2             	cmove  %edx,%eax
    87bf:	83 c0 01             	add    $0x1,%eax
}
    87c2:	5d                   	pop    %ebp
    87c3:	c3                   	ret    

000087c4 <ck_cc_ffsl>:

#define CK_F_CC_FFSL
CK_CC_INLINE static int
ck_cc_ffsl(unsigned long x)
{
    87c4:	55                   	push   %ebp
    87c5:	89 e5                	mov    %esp,%ebp
    87c7:	83 ec 18             	sub    $0x18,%esp

	return __builtin_ffsll(x);
    87ca:	8b 45 08             	mov    0x8(%ebp),%eax
    87cd:	ba 00 00 00 00       	mov    $0x0,%edx
    87d2:	89 04 24             	mov    %eax,(%esp)
    87d5:	89 54 24 04          	mov    %edx,0x4(%esp)
    87d9:	e8 fc ff ff ff       	call   87da <ck_cc_ffsl+0x16>
}
    87de:	c9                   	leave  
    87df:	c3                   	ret    

000087e0 <ck_cc_ctz>:

#define CK_F_CC_CTZ
CK_CC_INLINE static int
ck_cc_ctz(unsigned int x)
{
    87e0:	55                   	push   %ebp
    87e1:	89 e5                	mov    %esp,%ebp

	return __builtin_ctz(x);
    87e3:	f3 0f bc 45 08       	tzcnt  0x8(%ebp),%eax
}
    87e8:	5d                   	pop    %ebp
    87e9:	c3                   	ret    

000087ea <ck_cc_popcount>:

#define CK_F_CC_POPCOUNT
CK_CC_INLINE static int
ck_cc_popcount(unsigned int x)
{
    87ea:	55                   	push   %ebp
    87eb:	89 e5                	mov    %esp,%ebp
    87ed:	83 ec 18             	sub    $0x18,%esp

	return __builtin_popcount(x);
    87f0:	8b 45 08             	mov    0x8(%ebp),%eax
    87f3:	89 04 24             	mov    %eax,(%esp)
    87f6:	e8 fc ff ff ff       	call   87f7 <ck_cc_popcount+0xd>
}
    87fb:	c9                   	leave  
    87fc:	c3                   	ret    

000087fd <ck_cc_ffsll>:
CK_F_CC_FFS_G(ffsl, unsigned long)
#endif /* CK_F_CC_FFSL */

#ifndef CK_F_CC_FFSLL
#define CK_F_CC_FFSLL
CK_F_CC_FFS_G(ffsll, unsigned long long)
    87fd:	55                   	push   %ebp
    87fe:	89 e5                	mov    %esp,%ebp
    8800:	53                   	push   %ebx
    8801:	83 ec 1c             	sub    $0x1c,%esp
    8804:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8807:	89 4d e0             	mov    %ecx,-0x20(%ebp)
    880a:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    880d:	89 4d e4             	mov    %ecx,-0x1c(%ebp)
    8810:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    8813:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
    8816:	09 d9                	or     %ebx,%ecx
    8818:	85 c9                	test   %ecx,%ecx
    881a:	75 07                	jne    8823 <ck_cc_ffsll+0x26>
    881c:	b8 00 00 00 00       	mov    $0x0,%eax
    8821:	eb 3a                	jmp    885d <ck_cc_ffsll+0x60>
    8823:	c7 45 f4 01 00 00 00 	movl   $0x1,-0xc(%ebp)
    882a:	eb 16                	jmp    8842 <ck_cc_ffsll+0x45>
    882c:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    8830:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    8833:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
    8836:	0f ac d9 01          	shrd   $0x1,%ebx,%ecx
    883a:	d1 eb                	shr    %ebx
    883c:	89 4d e0             	mov    %ecx,-0x20(%ebp)
    883f:	89 5d e4             	mov    %ebx,-0x1c(%ebp)
    8842:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    8845:	83 e1 01             	and    $0x1,%ecx
    8848:	89 c8                	mov    %ecx,%eax
    884a:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
    884d:	83 e1 00             	and    $0x0,%ecx
    8850:	89 ca                	mov    %ecx,%edx
    8852:	89 d1                	mov    %edx,%ecx
    8854:	09 c1                	or     %eax,%ecx
    8856:	85 c9                	test   %ecx,%ecx
    8858:	74 d2                	je     882c <ck_cc_ffsll+0x2f>
    885a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    885d:	83 c4 1c             	add    $0x1c,%esp
    8860:	5b                   	pop    %ebx
    8861:	5d                   	pop    %ebp
    8862:	c3                   	ret    

00008863 <ck_pr_stall>:
 * Prevent speculative execution in busy-wait loops (P4 <=) or "predefined
 * delay".
 */
CK_CC_INLINE static void
ck_pr_stall(void)
{
    8863:	55                   	push   %ebp
    8864:	89 e5                	mov    %esp,%ebp
	__asm__ __volatile__("pause" ::: "memory");
    8866:	f3 90                	pause  
	return;
    8868:	90                   	nop
}
    8869:	5d                   	pop    %ebp
    886a:	c3                   	ret    

0000886b <ck_pr_fence_strict_atomic>:
#define CK_MD_X86_SFENCE "sfence"
#define CK_MD_X86_LFENCE "lfence"
#define CK_MD_X86_MFENCE "mfence"
#endif /* !CK_MD_SSE_DISABLE */

CK_PR_FENCE(atomic, "")
    886b:	55                   	push   %ebp
    886c:	89 e5                	mov    %esp,%ebp
    886e:	90                   	nop
    886f:	5d                   	pop    %ebp
    8870:	c3                   	ret    

00008871 <ck_pr_fence_strict_atomic_store>:
CK_PR_FENCE(atomic_store, "")
    8871:	55                   	push   %ebp
    8872:	89 e5                	mov    %esp,%ebp
    8874:	90                   	nop
    8875:	5d                   	pop    %ebp
    8876:	c3                   	ret    

00008877 <ck_pr_fence_strict_atomic_load>:
CK_PR_FENCE(atomic_load, "")
    8877:	55                   	push   %ebp
    8878:	89 e5                	mov    %esp,%ebp
    887a:	90                   	nop
    887b:	5d                   	pop    %ebp
    887c:	c3                   	ret    

0000887d <ck_pr_fence_strict_store_atomic>:
CK_PR_FENCE(store_atomic, "")
    887d:	55                   	push   %ebp
    887e:	89 e5                	mov    %esp,%ebp
    8880:	90                   	nop
    8881:	5d                   	pop    %ebp
    8882:	c3                   	ret    

00008883 <ck_pr_fence_strict_load_atomic>:
CK_PR_FENCE(load_atomic, "")
    8883:	55                   	push   %ebp
    8884:	89 e5                	mov    %esp,%ebp
    8886:	90                   	nop
    8887:	5d                   	pop    %ebp
    8888:	c3                   	ret    

00008889 <ck_pr_fence_strict_load>:
CK_PR_FENCE(load, CK_MD_X86_LFENCE)
    8889:	55                   	push   %ebp
    888a:	89 e5                	mov    %esp,%ebp
    888c:	0f ae e8             	lfence 
    888f:	90                   	nop
    8890:	5d                   	pop    %ebp
    8891:	c3                   	ret    

00008892 <ck_pr_fence_strict_load_store>:
CK_PR_FENCE(load_store, CK_MD_X86_MFENCE)
    8892:	55                   	push   %ebp
    8893:	89 e5                	mov    %esp,%ebp
    8895:	0f ae f0             	mfence 
    8898:	90                   	nop
    8899:	5d                   	pop    %ebp
    889a:	c3                   	ret    

0000889b <ck_pr_fence_strict_store>:
CK_PR_FENCE(store, CK_MD_X86_SFENCE)
    889b:	55                   	push   %ebp
    889c:	89 e5                	mov    %esp,%ebp
    889e:	0f ae f8             	sfence 
    88a1:	90                   	nop
    88a2:	5d                   	pop    %ebp
    88a3:	c3                   	ret    

000088a4 <ck_pr_fence_strict_store_load>:
CK_PR_FENCE(store_load, CK_MD_X86_MFENCE)
    88a4:	55                   	push   %ebp
    88a5:	89 e5                	mov    %esp,%ebp
    88a7:	0f ae f0             	mfence 
    88aa:	90                   	nop
    88ab:	5d                   	pop    %ebp
    88ac:	c3                   	ret    

000088ad <ck_pr_fence_strict_memory>:
CK_PR_FENCE(memory, CK_MD_X86_MFENCE)
    88ad:	55                   	push   %ebp
    88ae:	89 e5                	mov    %esp,%ebp
    88b0:	0f ae f0             	mfence 
    88b3:	90                   	nop
    88b4:	5d                   	pop    %ebp
    88b5:	c3                   	ret    

000088b6 <ck_pr_fence_strict_release>:
CK_PR_FENCE(release, CK_MD_X86_MFENCE)
    88b6:	55                   	push   %ebp
    88b7:	89 e5                	mov    %esp,%ebp
    88b9:	0f ae f0             	mfence 
    88bc:	90                   	nop
    88bd:	5d                   	pop    %ebp
    88be:	c3                   	ret    

000088bf <ck_pr_fence_strict_acquire>:
CK_PR_FENCE(acquire, CK_MD_X86_MFENCE)
    88bf:	55                   	push   %ebp
    88c0:	89 e5                	mov    %esp,%ebp
    88c2:	0f ae f0             	mfence 
    88c5:	90                   	nop
    88c6:	5d                   	pop    %ebp
    88c7:	c3                   	ret    

000088c8 <ck_pr_fence_strict_acqrel>:
CK_PR_FENCE(acqrel, CK_MD_X86_MFENCE)
    88c8:	55                   	push   %ebp
    88c9:	89 e5                	mov    %esp,%ebp
    88cb:	0f ae f0             	mfence 
    88ce:	90                   	nop
    88cf:	5d                   	pop    %ebp
    88d0:	c3                   	ret    

000088d1 <ck_pr_fence_strict_lock>:
CK_PR_FENCE(lock, CK_MD_X86_MFENCE)
    88d1:	55                   	push   %ebp
    88d2:	89 e5                	mov    %esp,%ebp
    88d4:	0f ae f0             	mfence 
    88d7:	90                   	nop
    88d8:	5d                   	pop    %ebp
    88d9:	c3                   	ret    

000088da <ck_pr_fence_strict_unlock>:
CK_PR_FENCE(unlock, CK_MD_X86_MFENCE)
    88da:	55                   	push   %ebp
    88db:	89 e5                	mov    %esp,%ebp
    88dd:	0f ae f0             	mfence 
    88e0:	90                   	nop
    88e1:	5d                   	pop    %ebp
    88e2:	c3                   	ret    

000088e3 <ck_pr_fas_ptr>:
					:			\
					: "memory");		\
		return v;					\
	}

CK_PR_FAS(ptr, void, void *, char, "xchgl")
    88e3:	55                   	push   %ebp
    88e4:	89 e5                	mov    %esp,%ebp
    88e6:	8b 55 08             	mov    0x8(%ebp),%edx
    88e9:	8b 4d 08             	mov    0x8(%ebp),%ecx
    88ec:	8b 45 0c             	mov    0xc(%ebp),%eax
    88ef:	87 02                	xchg   %eax,(%edx)
    88f1:	89 45 0c             	mov    %eax,0xc(%ebp)
    88f4:	8b 45 0c             	mov    0xc(%ebp),%eax
    88f7:	5d                   	pop    %ebp
    88f8:	c3                   	ret    

000088f9 <ck_pr_fas_char>:

#define CK_PR_FAS_S(S, T, I) CK_PR_FAS(S, T, T, T, I)

CK_PR_FAS_S(char, char, "xchgb")
    88f9:	55                   	push   %ebp
    88fa:	89 e5                	mov    %esp,%ebp
    88fc:	83 ec 04             	sub    $0x4,%esp
    88ff:	8b 45 0c             	mov    0xc(%ebp),%eax
    8902:	88 45 fc             	mov    %al,-0x4(%ebp)
    8905:	8b 55 08             	mov    0x8(%ebp),%edx
    8908:	8b 4d 08             	mov    0x8(%ebp),%ecx
    890b:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    890f:	86 02                	xchg   %al,(%edx)
    8911:	88 45 fc             	mov    %al,-0x4(%ebp)
    8914:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    8918:	c9                   	leave  
    8919:	c3                   	ret    

0000891a <ck_pr_fas_uint>:
CK_PR_FAS_S(uint, unsigned int, "xchgl")
    891a:	55                   	push   %ebp
    891b:	89 e5                	mov    %esp,%ebp
    891d:	8b 55 08             	mov    0x8(%ebp),%edx
    8920:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8923:	8b 45 0c             	mov    0xc(%ebp),%eax
    8926:	87 02                	xchg   %eax,(%edx)
    8928:	89 45 0c             	mov    %eax,0xc(%ebp)
    892b:	8b 45 0c             	mov    0xc(%ebp),%eax
    892e:	5d                   	pop    %ebp
    892f:	c3                   	ret    

00008930 <ck_pr_fas_int>:
CK_PR_FAS_S(int, int, "xchgl")
    8930:	55                   	push   %ebp
    8931:	89 e5                	mov    %esp,%ebp
    8933:	8b 55 08             	mov    0x8(%ebp),%edx
    8936:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8939:	8b 45 0c             	mov    0xc(%ebp),%eax
    893c:	87 02                	xchg   %eax,(%edx)
    893e:	89 45 0c             	mov    %eax,0xc(%ebp)
    8941:	8b 45 0c             	mov    0xc(%ebp),%eax
    8944:	5d                   	pop    %ebp
    8945:	c3                   	ret    

00008946 <ck_pr_fas_32>:
CK_PR_FAS_S(32, uint32_t, "xchgl")
    8946:	55                   	push   %ebp
    8947:	89 e5                	mov    %esp,%ebp
    8949:	8b 55 08             	mov    0x8(%ebp),%edx
    894c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    894f:	8b 45 0c             	mov    0xc(%ebp),%eax
    8952:	87 02                	xchg   %eax,(%edx)
    8954:	89 45 0c             	mov    %eax,0xc(%ebp)
    8957:	8b 45 0c             	mov    0xc(%ebp),%eax
    895a:	5d                   	pop    %ebp
    895b:	c3                   	ret    

0000895c <ck_pr_fas_16>:
CK_PR_FAS_S(16, uint16_t, "xchgw")
    895c:	55                   	push   %ebp
    895d:	89 e5                	mov    %esp,%ebp
    895f:	83 ec 04             	sub    $0x4,%esp
    8962:	8b 45 0c             	mov    0xc(%ebp),%eax
    8965:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    8969:	8b 55 08             	mov    0x8(%ebp),%edx
    896c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    896f:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
    8973:	66 87 02             	xchg   %ax,(%edx)
    8976:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    897a:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
    897e:	c9                   	leave  
    897f:	c3                   	ret    

00008980 <ck_pr_fas_8>:
CK_PR_FAS_S(8,  uint8_t,  "xchgb")
    8980:	55                   	push   %ebp
    8981:	89 e5                	mov    %esp,%ebp
    8983:	83 ec 04             	sub    $0x4,%esp
    8986:	8b 45 0c             	mov    0xc(%ebp),%eax
    8989:	88 45 fc             	mov    %al,-0x4(%ebp)
    898c:	8b 55 08             	mov    0x8(%ebp),%edx
    898f:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8992:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    8996:	86 02                	xchg   %al,(%edx)
    8998:	88 45 fc             	mov    %al,-0x4(%ebp)
    899b:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    899f:	c9                   	leave  
    89a0:	c3                   	ret    

000089a1 <ck_pr_md_load_ptr>:
					: "m"  (*(const C *)target)	\
					: "memory");			\
		return (r);						\
	}

CK_PR_LOAD(ptr, void, void *, char, "movl")
    89a1:	55                   	push   %ebp
    89a2:	89 e5                	mov    %esp,%ebp
    89a4:	83 ec 10             	sub    $0x10,%esp
    89a7:	8b 45 08             	mov    0x8(%ebp),%eax
    89aa:	8b 00                	mov    (%eax),%eax
    89ac:	89 45 fc             	mov    %eax,-0x4(%ebp)
    89af:	8b 45 fc             	mov    -0x4(%ebp),%eax
    89b2:	c9                   	leave  
    89b3:	c3                   	ret    

000089b4 <ck_pr_md_load_char>:

#define CK_PR_LOAD_S(S, T, I) CK_PR_LOAD(S, T, T, T, I)

CK_PR_LOAD_S(char, char, "movb")
    89b4:	55                   	push   %ebp
    89b5:	89 e5                	mov    %esp,%ebp
    89b7:	83 ec 10             	sub    $0x10,%esp
    89ba:	8b 45 08             	mov    0x8(%ebp),%eax
    89bd:	8a 00                	mov    (%eax),%al
    89bf:	88 45 ff             	mov    %al,-0x1(%ebp)
    89c2:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    89c6:	c9                   	leave  
    89c7:	c3                   	ret    

000089c8 <ck_pr_md_load_uint>:
CK_PR_LOAD_S(uint, unsigned int, "movl")
    89c8:	55                   	push   %ebp
    89c9:	89 e5                	mov    %esp,%ebp
    89cb:	83 ec 10             	sub    $0x10,%esp
    89ce:	8b 45 08             	mov    0x8(%ebp),%eax
    89d1:	8b 00                	mov    (%eax),%eax
    89d3:	89 45 fc             	mov    %eax,-0x4(%ebp)
    89d6:	8b 45 fc             	mov    -0x4(%ebp),%eax
    89d9:	c9                   	leave  
    89da:	c3                   	ret    

000089db <ck_pr_md_load_int>:
CK_PR_LOAD_S(int, int, "movl")
    89db:	55                   	push   %ebp
    89dc:	89 e5                	mov    %esp,%ebp
    89de:	83 ec 10             	sub    $0x10,%esp
    89e1:	8b 45 08             	mov    0x8(%ebp),%eax
    89e4:	8b 00                	mov    (%eax),%eax
    89e6:	89 45 fc             	mov    %eax,-0x4(%ebp)
    89e9:	8b 45 fc             	mov    -0x4(%ebp),%eax
    89ec:	c9                   	leave  
    89ed:	c3                   	ret    

000089ee <ck_pr_md_load_32>:
CK_PR_LOAD_S(32, uint32_t, "movl")
    89ee:	55                   	push   %ebp
    89ef:	89 e5                	mov    %esp,%ebp
    89f1:	83 ec 10             	sub    $0x10,%esp
    89f4:	8b 45 08             	mov    0x8(%ebp),%eax
    89f7:	8b 00                	mov    (%eax),%eax
    89f9:	89 45 fc             	mov    %eax,-0x4(%ebp)
    89fc:	8b 45 fc             	mov    -0x4(%ebp),%eax
    89ff:	c9                   	leave  
    8a00:	c3                   	ret    

00008a01 <ck_pr_md_load_16>:
CK_PR_LOAD_S(16, uint16_t, "movw")
    8a01:	55                   	push   %ebp
    8a02:	89 e5                	mov    %esp,%ebp
    8a04:	83 ec 10             	sub    $0x10,%esp
    8a07:	8b 45 08             	mov    0x8(%ebp),%eax
    8a0a:	66 8b 00             	mov    (%eax),%ax
    8a0d:	66 89 45 fe          	mov    %ax,-0x2(%ebp)
    8a11:	0f b7 45 fe          	movzwl -0x2(%ebp),%eax
    8a15:	c9                   	leave  
    8a16:	c3                   	ret    

00008a17 <ck_pr_md_load_8>:
CK_PR_LOAD_S(8,  uint8_t,  "movb")
    8a17:	55                   	push   %ebp
    8a18:	89 e5                	mov    %esp,%ebp
    8a1a:	83 ec 10             	sub    $0x10,%esp
    8a1d:	8b 45 08             	mov    0x8(%ebp),%eax
    8a20:	8a 00                	mov    (%eax),%al
    8a22:	88 45 ff             	mov    %al,-0x1(%ebp)
    8a25:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    8a29:	c9                   	leave  
    8a2a:	c3                   	ret    

00008a2b <ck_pr_md_store_ptr>:
					: CK_CC_IMM "q" (v)	\
					: "memory");		\
		return;						\
	}

CK_PR_STORE(ptr, void, const void *, char, "movl")
    8a2b:	55                   	push   %ebp
    8a2c:	89 e5                	mov    %esp,%ebp
    8a2e:	8b 45 08             	mov    0x8(%ebp),%eax
    8a31:	8b 55 0c             	mov    0xc(%ebp),%edx
    8a34:	89 10                	mov    %edx,(%eax)
    8a36:	90                   	nop
    8a37:	5d                   	pop    %ebp
    8a38:	c3                   	ret    

00008a39 <ck_pr_md_store_char>:

#define CK_PR_STORE_S(S, T, I) CK_PR_STORE(S, T, T, T, I)

CK_PR_STORE_S(char, char, "movb")
    8a39:	55                   	push   %ebp
    8a3a:	89 e5                	mov    %esp,%ebp
    8a3c:	83 ec 04             	sub    $0x4,%esp
    8a3f:	8b 45 0c             	mov    0xc(%ebp),%eax
    8a42:	88 45 fc             	mov    %al,-0x4(%ebp)
    8a45:	8b 45 08             	mov    0x8(%ebp),%eax
    8a48:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    8a4c:	88 10                	mov    %dl,(%eax)
    8a4e:	90                   	nop
    8a4f:	c9                   	leave  
    8a50:	c3                   	ret    

00008a51 <ck_pr_md_store_uint>:
CK_PR_STORE_S(uint, unsigned int, "movl")
    8a51:	55                   	push   %ebp
    8a52:	89 e5                	mov    %esp,%ebp
    8a54:	8b 45 08             	mov    0x8(%ebp),%eax
    8a57:	8b 55 0c             	mov    0xc(%ebp),%edx
    8a5a:	89 10                	mov    %edx,(%eax)
    8a5c:	90                   	nop
    8a5d:	5d                   	pop    %ebp
    8a5e:	c3                   	ret    

00008a5f <ck_pr_md_store_int>:
CK_PR_STORE_S(int, int, "movl")
    8a5f:	55                   	push   %ebp
    8a60:	89 e5                	mov    %esp,%ebp
    8a62:	8b 45 08             	mov    0x8(%ebp),%eax
    8a65:	8b 55 0c             	mov    0xc(%ebp),%edx
    8a68:	89 10                	mov    %edx,(%eax)
    8a6a:	90                   	nop
    8a6b:	5d                   	pop    %ebp
    8a6c:	c3                   	ret    

00008a6d <ck_pr_md_store_32>:
CK_PR_STORE_S(32, uint32_t, "movl")
    8a6d:	55                   	push   %ebp
    8a6e:	89 e5                	mov    %esp,%ebp
    8a70:	8b 45 08             	mov    0x8(%ebp),%eax
    8a73:	8b 55 0c             	mov    0xc(%ebp),%edx
    8a76:	89 10                	mov    %edx,(%eax)
    8a78:	90                   	nop
    8a79:	5d                   	pop    %ebp
    8a7a:	c3                   	ret    

00008a7b <ck_pr_md_store_16>:
CK_PR_STORE_S(16, uint16_t, "movw")
    8a7b:	55                   	push   %ebp
    8a7c:	89 e5                	mov    %esp,%ebp
    8a7e:	83 ec 04             	sub    $0x4,%esp
    8a81:	8b 45 0c             	mov    0xc(%ebp),%eax
    8a84:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    8a88:	8b 45 08             	mov    0x8(%ebp),%eax
    8a8b:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    8a8f:	66 89 10             	mov    %dx,(%eax)
    8a92:	90                   	nop
    8a93:	c9                   	leave  
    8a94:	c3                   	ret    

00008a95 <ck_pr_md_store_8>:
CK_PR_STORE_S(8,  uint8_t, "movb")
    8a95:	55                   	push   %ebp
    8a96:	89 e5                	mov    %esp,%ebp
    8a98:	83 ec 04             	sub    $0x4,%esp
    8a9b:	8b 45 0c             	mov    0xc(%ebp),%eax
    8a9e:	88 45 fc             	mov    %al,-0x4(%ebp)
    8aa1:	8b 45 08             	mov    0x8(%ebp),%eax
    8aa4:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    8aa8:	88 10                	mov    %dl,(%eax)
    8aaa:	90                   	nop
    8aab:	c9                   	leave  
    8aac:	c3                   	ret    

00008aad <ck_pr_faa_ptr>:
					:				\
					: "memory", "cc");		\
		return (d);						\
	}

CK_PR_FAA(ptr, void, uintptr_t, char, "xaddl")
    8aad:	55                   	push   %ebp
    8aae:	89 e5                	mov    %esp,%ebp
    8ab0:	8b 55 08             	mov    0x8(%ebp),%edx
    8ab3:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8ab6:	8b 45 0c             	mov    0xc(%ebp),%eax
    8ab9:	f0 0f c1 02          	lock xadd %eax,(%edx)
    8abd:	89 45 0c             	mov    %eax,0xc(%ebp)
    8ac0:	8b 45 0c             	mov    0xc(%ebp),%eax
    8ac3:	5d                   	pop    %ebp
    8ac4:	c3                   	ret    

00008ac5 <ck_pr_faa_char>:

#define CK_PR_FAA_S(S, T, I) CK_PR_FAA(S, T, T, T, I)

CK_PR_FAA_S(char, char, "xaddb")
    8ac5:	55                   	push   %ebp
    8ac6:	89 e5                	mov    %esp,%ebp
    8ac8:	83 ec 04             	sub    $0x4,%esp
    8acb:	8b 45 0c             	mov    0xc(%ebp),%eax
    8ace:	88 45 fc             	mov    %al,-0x4(%ebp)
    8ad1:	8b 55 08             	mov    0x8(%ebp),%edx
    8ad4:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8ad7:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    8adb:	f0 0f c0 02          	lock xadd %al,(%edx)
    8adf:	88 45 fc             	mov    %al,-0x4(%ebp)
    8ae2:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    8ae6:	c9                   	leave  
    8ae7:	c3                   	ret    

00008ae8 <ck_pr_faa_uint>:
CK_PR_FAA_S(uint, unsigned int, "xaddl")
    8ae8:	55                   	push   %ebp
    8ae9:	89 e5                	mov    %esp,%ebp
    8aeb:	8b 55 08             	mov    0x8(%ebp),%edx
    8aee:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8af1:	8b 45 0c             	mov    0xc(%ebp),%eax
    8af4:	f0 0f c1 02          	lock xadd %eax,(%edx)
    8af8:	89 45 0c             	mov    %eax,0xc(%ebp)
    8afb:	8b 45 0c             	mov    0xc(%ebp),%eax
    8afe:	5d                   	pop    %ebp
    8aff:	c3                   	ret    

00008b00 <ck_pr_faa_int>:
CK_PR_FAA_S(int, int, "xaddl")
    8b00:	55                   	push   %ebp
    8b01:	89 e5                	mov    %esp,%ebp
    8b03:	8b 55 08             	mov    0x8(%ebp),%edx
    8b06:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8b09:	8b 45 0c             	mov    0xc(%ebp),%eax
    8b0c:	f0 0f c1 02          	lock xadd %eax,(%edx)
    8b10:	89 45 0c             	mov    %eax,0xc(%ebp)
    8b13:	8b 45 0c             	mov    0xc(%ebp),%eax
    8b16:	5d                   	pop    %ebp
    8b17:	c3                   	ret    

00008b18 <ck_pr_faa_32>:
CK_PR_FAA_S(32, uint32_t, "xaddl")
    8b18:	55                   	push   %ebp
    8b19:	89 e5                	mov    %esp,%ebp
    8b1b:	8b 55 08             	mov    0x8(%ebp),%edx
    8b1e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8b21:	8b 45 0c             	mov    0xc(%ebp),%eax
    8b24:	f0 0f c1 02          	lock xadd %eax,(%edx)
    8b28:	89 45 0c             	mov    %eax,0xc(%ebp)
    8b2b:	8b 45 0c             	mov    0xc(%ebp),%eax
    8b2e:	5d                   	pop    %ebp
    8b2f:	c3                   	ret    

00008b30 <ck_pr_faa_16>:
CK_PR_FAA_S(16, uint16_t, "xaddw")
    8b30:	55                   	push   %ebp
    8b31:	89 e5                	mov    %esp,%ebp
    8b33:	83 ec 04             	sub    $0x4,%esp
    8b36:	8b 45 0c             	mov    0xc(%ebp),%eax
    8b39:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    8b3d:	8b 55 08             	mov    0x8(%ebp),%edx
    8b40:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8b43:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
    8b47:	66 f0 0f c1 02       	lock xadd %ax,(%edx)
    8b4c:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    8b50:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
    8b54:	c9                   	leave  
    8b55:	c3                   	ret    

00008b56 <ck_pr_faa_8>:
CK_PR_FAA_S(8,  uint8_t,  "xaddb")
    8b56:	55                   	push   %ebp
    8b57:	89 e5                	mov    %esp,%ebp
    8b59:	83 ec 04             	sub    $0x4,%esp
    8b5c:	8b 45 0c             	mov    0xc(%ebp),%eax
    8b5f:	88 45 fc             	mov    %al,-0x4(%ebp)
    8b62:	8b 55 08             	mov    0x8(%ebp),%edx
    8b65:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8b68:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    8b6c:	f0 0f c0 02          	lock xadd %al,(%edx)
    8b70:	88 45 fc             	mov    %al,-0x4(%ebp)
    8b73:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    8b77:	c9                   	leave  
    8b78:	c3                   	ret    

00008b79 <ck_pr_inc_ptr>:
	CK_PR_UNARY_S(K, uint, unsigned int, #K "l")	\
	CK_PR_UNARY_S(K, 32, uint32_t, #K "l")		\
	CK_PR_UNARY_S(K, 16, uint16_t, #K "w")		\
	CK_PR_UNARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(inc)
    8b79:	55                   	push   %ebp
    8b7a:	89 e5                	mov    %esp,%ebp
    8b7c:	8b 45 08             	mov    0x8(%ebp),%eax
    8b7f:	8b 55 08             	mov    0x8(%ebp),%edx
    8b82:	f0 ff 00             	lock incl (%eax)
    8b85:	90                   	nop
    8b86:	5d                   	pop    %ebp
    8b87:	c3                   	ret    

00008b88 <ck_pr_inc_ptr_zero>:
    8b88:	55                   	push   %ebp
    8b89:	89 e5                	mov    %esp,%ebp
    8b8b:	8b 45 08             	mov    0x8(%ebp),%eax
    8b8e:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8b91:	8b 55 08             	mov    0x8(%ebp),%edx
    8b94:	f0 ff 00             	lock incl (%eax)
    8b97:	0f 94 01             	sete   (%ecx)
    8b9a:	90                   	nop
    8b9b:	5d                   	pop    %ebp
    8b9c:	c3                   	ret    

00008b9d <ck_pr_inc_char>:
    8b9d:	55                   	push   %ebp
    8b9e:	89 e5                	mov    %esp,%ebp
    8ba0:	8b 45 08             	mov    0x8(%ebp),%eax
    8ba3:	8b 55 08             	mov    0x8(%ebp),%edx
    8ba6:	f0 fe 00             	lock incb (%eax)
    8ba9:	90                   	nop
    8baa:	5d                   	pop    %ebp
    8bab:	c3                   	ret    

00008bac <ck_pr_inc_char_zero>:
    8bac:	55                   	push   %ebp
    8bad:	89 e5                	mov    %esp,%ebp
    8baf:	8b 45 08             	mov    0x8(%ebp),%eax
    8bb2:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8bb5:	8b 55 08             	mov    0x8(%ebp),%edx
    8bb8:	f0 fe 00             	lock incb (%eax)
    8bbb:	0f 94 01             	sete   (%ecx)
    8bbe:	90                   	nop
    8bbf:	5d                   	pop    %ebp
    8bc0:	c3                   	ret    

00008bc1 <ck_pr_inc_int>:
    8bc1:	55                   	push   %ebp
    8bc2:	89 e5                	mov    %esp,%ebp
    8bc4:	8b 45 08             	mov    0x8(%ebp),%eax
    8bc7:	8b 55 08             	mov    0x8(%ebp),%edx
    8bca:	f0 ff 00             	lock incl (%eax)
    8bcd:	90                   	nop
    8bce:	5d                   	pop    %ebp
    8bcf:	c3                   	ret    

00008bd0 <ck_pr_inc_int_zero>:
    8bd0:	55                   	push   %ebp
    8bd1:	89 e5                	mov    %esp,%ebp
    8bd3:	8b 45 08             	mov    0x8(%ebp),%eax
    8bd6:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8bd9:	8b 55 08             	mov    0x8(%ebp),%edx
    8bdc:	f0 ff 00             	lock incl (%eax)
    8bdf:	0f 94 01             	sete   (%ecx)
    8be2:	90                   	nop
    8be3:	5d                   	pop    %ebp
    8be4:	c3                   	ret    

00008be5 <ck_pr_inc_uint>:
    8be5:	55                   	push   %ebp
    8be6:	89 e5                	mov    %esp,%ebp
    8be8:	8b 45 08             	mov    0x8(%ebp),%eax
    8beb:	8b 55 08             	mov    0x8(%ebp),%edx
    8bee:	f0 ff 00             	lock incl (%eax)
    8bf1:	90                   	nop
    8bf2:	5d                   	pop    %ebp
    8bf3:	c3                   	ret    

00008bf4 <ck_pr_inc_uint_zero>:
    8bf4:	55                   	push   %ebp
    8bf5:	89 e5                	mov    %esp,%ebp
    8bf7:	8b 45 08             	mov    0x8(%ebp),%eax
    8bfa:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8bfd:	8b 55 08             	mov    0x8(%ebp),%edx
    8c00:	f0 ff 00             	lock incl (%eax)
    8c03:	0f 94 01             	sete   (%ecx)
    8c06:	90                   	nop
    8c07:	5d                   	pop    %ebp
    8c08:	c3                   	ret    

00008c09 <ck_pr_inc_32>:
    8c09:	55                   	push   %ebp
    8c0a:	89 e5                	mov    %esp,%ebp
    8c0c:	8b 45 08             	mov    0x8(%ebp),%eax
    8c0f:	8b 55 08             	mov    0x8(%ebp),%edx
    8c12:	f0 ff 00             	lock incl (%eax)
    8c15:	90                   	nop
    8c16:	5d                   	pop    %ebp
    8c17:	c3                   	ret    

00008c18 <ck_pr_inc_32_zero>:
    8c18:	55                   	push   %ebp
    8c19:	89 e5                	mov    %esp,%ebp
    8c1b:	8b 45 08             	mov    0x8(%ebp),%eax
    8c1e:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8c21:	8b 55 08             	mov    0x8(%ebp),%edx
    8c24:	f0 ff 00             	lock incl (%eax)
    8c27:	0f 94 01             	sete   (%ecx)
    8c2a:	90                   	nop
    8c2b:	5d                   	pop    %ebp
    8c2c:	c3                   	ret    

00008c2d <ck_pr_inc_16>:
    8c2d:	55                   	push   %ebp
    8c2e:	89 e5                	mov    %esp,%ebp
    8c30:	8b 45 08             	mov    0x8(%ebp),%eax
    8c33:	8b 55 08             	mov    0x8(%ebp),%edx
    8c36:	66 f0 ff 00          	lock incw (%eax)
    8c3a:	90                   	nop
    8c3b:	5d                   	pop    %ebp
    8c3c:	c3                   	ret    

00008c3d <ck_pr_inc_16_zero>:
    8c3d:	55                   	push   %ebp
    8c3e:	89 e5                	mov    %esp,%ebp
    8c40:	8b 45 08             	mov    0x8(%ebp),%eax
    8c43:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8c46:	8b 55 08             	mov    0x8(%ebp),%edx
    8c49:	66 f0 ff 00          	lock incw (%eax)
    8c4d:	0f 94 01             	sete   (%ecx)
    8c50:	90                   	nop
    8c51:	5d                   	pop    %ebp
    8c52:	c3                   	ret    

00008c53 <ck_pr_inc_8>:
    8c53:	55                   	push   %ebp
    8c54:	89 e5                	mov    %esp,%ebp
    8c56:	8b 45 08             	mov    0x8(%ebp),%eax
    8c59:	8b 55 08             	mov    0x8(%ebp),%edx
    8c5c:	f0 fe 00             	lock incb (%eax)
    8c5f:	90                   	nop
    8c60:	5d                   	pop    %ebp
    8c61:	c3                   	ret    

00008c62 <ck_pr_inc_8_zero>:
    8c62:	55                   	push   %ebp
    8c63:	89 e5                	mov    %esp,%ebp
    8c65:	8b 45 08             	mov    0x8(%ebp),%eax
    8c68:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8c6b:	8b 55 08             	mov    0x8(%ebp),%edx
    8c6e:	f0 fe 00             	lock incb (%eax)
    8c71:	0f 94 01             	sete   (%ecx)
    8c74:	90                   	nop
    8c75:	5d                   	pop    %ebp
    8c76:	c3                   	ret    

00008c77 <ck_pr_dec_ptr>:
CK_PR_GENERATE(dec)
    8c77:	55                   	push   %ebp
    8c78:	89 e5                	mov    %esp,%ebp
    8c7a:	8b 45 08             	mov    0x8(%ebp),%eax
    8c7d:	8b 55 08             	mov    0x8(%ebp),%edx
    8c80:	f0 ff 08             	lock decl (%eax)
    8c83:	90                   	nop
    8c84:	5d                   	pop    %ebp
    8c85:	c3                   	ret    

00008c86 <ck_pr_dec_ptr_zero>:
    8c86:	55                   	push   %ebp
    8c87:	89 e5                	mov    %esp,%ebp
    8c89:	8b 45 08             	mov    0x8(%ebp),%eax
    8c8c:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8c8f:	8b 55 08             	mov    0x8(%ebp),%edx
    8c92:	f0 ff 08             	lock decl (%eax)
    8c95:	0f 94 01             	sete   (%ecx)
    8c98:	90                   	nop
    8c99:	5d                   	pop    %ebp
    8c9a:	c3                   	ret    

00008c9b <ck_pr_dec_char>:
    8c9b:	55                   	push   %ebp
    8c9c:	89 e5                	mov    %esp,%ebp
    8c9e:	8b 45 08             	mov    0x8(%ebp),%eax
    8ca1:	8b 55 08             	mov    0x8(%ebp),%edx
    8ca4:	f0 fe 08             	lock decb (%eax)
    8ca7:	90                   	nop
    8ca8:	5d                   	pop    %ebp
    8ca9:	c3                   	ret    

00008caa <ck_pr_dec_char_zero>:
    8caa:	55                   	push   %ebp
    8cab:	89 e5                	mov    %esp,%ebp
    8cad:	8b 45 08             	mov    0x8(%ebp),%eax
    8cb0:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8cb3:	8b 55 08             	mov    0x8(%ebp),%edx
    8cb6:	f0 fe 08             	lock decb (%eax)
    8cb9:	0f 94 01             	sete   (%ecx)
    8cbc:	90                   	nop
    8cbd:	5d                   	pop    %ebp
    8cbe:	c3                   	ret    

00008cbf <ck_pr_dec_int>:
    8cbf:	55                   	push   %ebp
    8cc0:	89 e5                	mov    %esp,%ebp
    8cc2:	8b 45 08             	mov    0x8(%ebp),%eax
    8cc5:	8b 55 08             	mov    0x8(%ebp),%edx
    8cc8:	f0 ff 08             	lock decl (%eax)
    8ccb:	90                   	nop
    8ccc:	5d                   	pop    %ebp
    8ccd:	c3                   	ret    

00008cce <ck_pr_dec_int_zero>:
    8cce:	55                   	push   %ebp
    8ccf:	89 e5                	mov    %esp,%ebp
    8cd1:	8b 45 08             	mov    0x8(%ebp),%eax
    8cd4:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8cd7:	8b 55 08             	mov    0x8(%ebp),%edx
    8cda:	f0 ff 08             	lock decl (%eax)
    8cdd:	0f 94 01             	sete   (%ecx)
    8ce0:	90                   	nop
    8ce1:	5d                   	pop    %ebp
    8ce2:	c3                   	ret    

00008ce3 <ck_pr_dec_uint>:
    8ce3:	55                   	push   %ebp
    8ce4:	89 e5                	mov    %esp,%ebp
    8ce6:	8b 45 08             	mov    0x8(%ebp),%eax
    8ce9:	8b 55 08             	mov    0x8(%ebp),%edx
    8cec:	f0 ff 08             	lock decl (%eax)
    8cef:	90                   	nop
    8cf0:	5d                   	pop    %ebp
    8cf1:	c3                   	ret    

00008cf2 <ck_pr_dec_uint_zero>:
    8cf2:	55                   	push   %ebp
    8cf3:	89 e5                	mov    %esp,%ebp
    8cf5:	8b 45 08             	mov    0x8(%ebp),%eax
    8cf8:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8cfb:	8b 55 08             	mov    0x8(%ebp),%edx
    8cfe:	f0 ff 08             	lock decl (%eax)
    8d01:	0f 94 01             	sete   (%ecx)
    8d04:	90                   	nop
    8d05:	5d                   	pop    %ebp
    8d06:	c3                   	ret    

00008d07 <ck_pr_dec_32>:
    8d07:	55                   	push   %ebp
    8d08:	89 e5                	mov    %esp,%ebp
    8d0a:	8b 45 08             	mov    0x8(%ebp),%eax
    8d0d:	8b 55 08             	mov    0x8(%ebp),%edx
    8d10:	f0 ff 08             	lock decl (%eax)
    8d13:	90                   	nop
    8d14:	5d                   	pop    %ebp
    8d15:	c3                   	ret    

00008d16 <ck_pr_dec_32_zero>:
    8d16:	55                   	push   %ebp
    8d17:	89 e5                	mov    %esp,%ebp
    8d19:	8b 45 08             	mov    0x8(%ebp),%eax
    8d1c:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8d1f:	8b 55 08             	mov    0x8(%ebp),%edx
    8d22:	f0 ff 08             	lock decl (%eax)
    8d25:	0f 94 01             	sete   (%ecx)
    8d28:	90                   	nop
    8d29:	5d                   	pop    %ebp
    8d2a:	c3                   	ret    

00008d2b <ck_pr_dec_16>:
    8d2b:	55                   	push   %ebp
    8d2c:	89 e5                	mov    %esp,%ebp
    8d2e:	8b 45 08             	mov    0x8(%ebp),%eax
    8d31:	8b 55 08             	mov    0x8(%ebp),%edx
    8d34:	66 f0 ff 08          	lock decw (%eax)
    8d38:	90                   	nop
    8d39:	5d                   	pop    %ebp
    8d3a:	c3                   	ret    

00008d3b <ck_pr_dec_16_zero>:
    8d3b:	55                   	push   %ebp
    8d3c:	89 e5                	mov    %esp,%ebp
    8d3e:	8b 45 08             	mov    0x8(%ebp),%eax
    8d41:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8d44:	8b 55 08             	mov    0x8(%ebp),%edx
    8d47:	66 f0 ff 08          	lock decw (%eax)
    8d4b:	0f 94 01             	sete   (%ecx)
    8d4e:	90                   	nop
    8d4f:	5d                   	pop    %ebp
    8d50:	c3                   	ret    

00008d51 <ck_pr_dec_8>:
    8d51:	55                   	push   %ebp
    8d52:	89 e5                	mov    %esp,%ebp
    8d54:	8b 45 08             	mov    0x8(%ebp),%eax
    8d57:	8b 55 08             	mov    0x8(%ebp),%edx
    8d5a:	f0 fe 08             	lock decb (%eax)
    8d5d:	90                   	nop
    8d5e:	5d                   	pop    %ebp
    8d5f:	c3                   	ret    

00008d60 <ck_pr_dec_8_zero>:
    8d60:	55                   	push   %ebp
    8d61:	89 e5                	mov    %esp,%ebp
    8d63:	8b 45 08             	mov    0x8(%ebp),%eax
    8d66:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8d69:	8b 55 08             	mov    0x8(%ebp),%edx
    8d6c:	f0 fe 08             	lock decb (%eax)
    8d6f:	0f 94 01             	sete   (%ecx)
    8d72:	90                   	nop
    8d73:	5d                   	pop    %ebp
    8d74:	c3                   	ret    

00008d75 <ck_pr_neg_ptr>:
CK_PR_GENERATE(neg)
    8d75:	55                   	push   %ebp
    8d76:	89 e5                	mov    %esp,%ebp
    8d78:	8b 45 08             	mov    0x8(%ebp),%eax
    8d7b:	8b 55 08             	mov    0x8(%ebp),%edx
    8d7e:	f0 f7 18             	lock negl (%eax)
    8d81:	90                   	nop
    8d82:	5d                   	pop    %ebp
    8d83:	c3                   	ret    

00008d84 <ck_pr_neg_ptr_zero>:
    8d84:	55                   	push   %ebp
    8d85:	89 e5                	mov    %esp,%ebp
    8d87:	8b 45 08             	mov    0x8(%ebp),%eax
    8d8a:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8d8d:	8b 55 08             	mov    0x8(%ebp),%edx
    8d90:	f0 f7 18             	lock negl (%eax)
    8d93:	0f 94 01             	sete   (%ecx)
    8d96:	90                   	nop
    8d97:	5d                   	pop    %ebp
    8d98:	c3                   	ret    

00008d99 <ck_pr_neg_char>:
    8d99:	55                   	push   %ebp
    8d9a:	89 e5                	mov    %esp,%ebp
    8d9c:	8b 45 08             	mov    0x8(%ebp),%eax
    8d9f:	8b 55 08             	mov    0x8(%ebp),%edx
    8da2:	f0 f6 18             	lock negb (%eax)
    8da5:	90                   	nop
    8da6:	5d                   	pop    %ebp
    8da7:	c3                   	ret    

00008da8 <ck_pr_neg_char_zero>:
    8da8:	55                   	push   %ebp
    8da9:	89 e5                	mov    %esp,%ebp
    8dab:	8b 45 08             	mov    0x8(%ebp),%eax
    8dae:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8db1:	8b 55 08             	mov    0x8(%ebp),%edx
    8db4:	f0 f6 18             	lock negb (%eax)
    8db7:	0f 94 01             	sete   (%ecx)
    8dba:	90                   	nop
    8dbb:	5d                   	pop    %ebp
    8dbc:	c3                   	ret    

00008dbd <ck_pr_neg_int>:
    8dbd:	55                   	push   %ebp
    8dbe:	89 e5                	mov    %esp,%ebp
    8dc0:	8b 45 08             	mov    0x8(%ebp),%eax
    8dc3:	8b 55 08             	mov    0x8(%ebp),%edx
    8dc6:	f0 f7 18             	lock negl (%eax)
    8dc9:	90                   	nop
    8dca:	5d                   	pop    %ebp
    8dcb:	c3                   	ret    

00008dcc <ck_pr_neg_int_zero>:
    8dcc:	55                   	push   %ebp
    8dcd:	89 e5                	mov    %esp,%ebp
    8dcf:	8b 45 08             	mov    0x8(%ebp),%eax
    8dd2:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8dd5:	8b 55 08             	mov    0x8(%ebp),%edx
    8dd8:	f0 f7 18             	lock negl (%eax)
    8ddb:	0f 94 01             	sete   (%ecx)
    8dde:	90                   	nop
    8ddf:	5d                   	pop    %ebp
    8de0:	c3                   	ret    

00008de1 <ck_pr_neg_uint>:
    8de1:	55                   	push   %ebp
    8de2:	89 e5                	mov    %esp,%ebp
    8de4:	8b 45 08             	mov    0x8(%ebp),%eax
    8de7:	8b 55 08             	mov    0x8(%ebp),%edx
    8dea:	f0 f7 18             	lock negl (%eax)
    8ded:	90                   	nop
    8dee:	5d                   	pop    %ebp
    8def:	c3                   	ret    

00008df0 <ck_pr_neg_uint_zero>:
    8df0:	55                   	push   %ebp
    8df1:	89 e5                	mov    %esp,%ebp
    8df3:	8b 45 08             	mov    0x8(%ebp),%eax
    8df6:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8df9:	8b 55 08             	mov    0x8(%ebp),%edx
    8dfc:	f0 f7 18             	lock negl (%eax)
    8dff:	0f 94 01             	sete   (%ecx)
    8e02:	90                   	nop
    8e03:	5d                   	pop    %ebp
    8e04:	c3                   	ret    

00008e05 <ck_pr_neg_32>:
    8e05:	55                   	push   %ebp
    8e06:	89 e5                	mov    %esp,%ebp
    8e08:	8b 45 08             	mov    0x8(%ebp),%eax
    8e0b:	8b 55 08             	mov    0x8(%ebp),%edx
    8e0e:	f0 f7 18             	lock negl (%eax)
    8e11:	90                   	nop
    8e12:	5d                   	pop    %ebp
    8e13:	c3                   	ret    

00008e14 <ck_pr_neg_32_zero>:
    8e14:	55                   	push   %ebp
    8e15:	89 e5                	mov    %esp,%ebp
    8e17:	8b 45 08             	mov    0x8(%ebp),%eax
    8e1a:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8e1d:	8b 55 08             	mov    0x8(%ebp),%edx
    8e20:	f0 f7 18             	lock negl (%eax)
    8e23:	0f 94 01             	sete   (%ecx)
    8e26:	90                   	nop
    8e27:	5d                   	pop    %ebp
    8e28:	c3                   	ret    

00008e29 <ck_pr_neg_16>:
    8e29:	55                   	push   %ebp
    8e2a:	89 e5                	mov    %esp,%ebp
    8e2c:	8b 45 08             	mov    0x8(%ebp),%eax
    8e2f:	8b 55 08             	mov    0x8(%ebp),%edx
    8e32:	66 f0 f7 18          	lock negw (%eax)
    8e36:	90                   	nop
    8e37:	5d                   	pop    %ebp
    8e38:	c3                   	ret    

00008e39 <ck_pr_neg_16_zero>:
    8e39:	55                   	push   %ebp
    8e3a:	89 e5                	mov    %esp,%ebp
    8e3c:	8b 45 08             	mov    0x8(%ebp),%eax
    8e3f:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8e42:	8b 55 08             	mov    0x8(%ebp),%edx
    8e45:	66 f0 f7 18          	lock negw (%eax)
    8e49:	0f 94 01             	sete   (%ecx)
    8e4c:	90                   	nop
    8e4d:	5d                   	pop    %ebp
    8e4e:	c3                   	ret    

00008e4f <ck_pr_neg_8>:
    8e4f:	55                   	push   %ebp
    8e50:	89 e5                	mov    %esp,%ebp
    8e52:	8b 45 08             	mov    0x8(%ebp),%eax
    8e55:	8b 55 08             	mov    0x8(%ebp),%edx
    8e58:	f0 f6 18             	lock negb (%eax)
    8e5b:	90                   	nop
    8e5c:	5d                   	pop    %ebp
    8e5d:	c3                   	ret    

00008e5e <ck_pr_neg_8_zero>:
    8e5e:	55                   	push   %ebp
    8e5f:	89 e5                	mov    %esp,%ebp
    8e61:	8b 45 08             	mov    0x8(%ebp),%eax
    8e64:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    8e67:	8b 55 08             	mov    0x8(%ebp),%edx
    8e6a:	f0 f6 18             	lock negb (%eax)
    8e6d:	0f 94 01             	sete   (%ecx)
    8e70:	90                   	nop
    8e71:	5d                   	pop    %ebp
    8e72:	c3                   	ret    

00008e73 <ck_pr_not_ptr>:

/* not does not affect condition flags. */
#undef CK_PR_UNARY_V
#define CK_PR_UNARY_V(a, b, c, d, e)
CK_PR_GENERATE(not)
    8e73:	55                   	push   %ebp
    8e74:	89 e5                	mov    %esp,%ebp
    8e76:	8b 45 08             	mov    0x8(%ebp),%eax
    8e79:	8b 55 08             	mov    0x8(%ebp),%edx
    8e7c:	f0 f7 10             	lock notl (%eax)
    8e7f:	90                   	nop
    8e80:	5d                   	pop    %ebp
    8e81:	c3                   	ret    

00008e82 <ck_pr_not_char>:
    8e82:	55                   	push   %ebp
    8e83:	89 e5                	mov    %esp,%ebp
    8e85:	8b 45 08             	mov    0x8(%ebp),%eax
    8e88:	8b 55 08             	mov    0x8(%ebp),%edx
    8e8b:	f0 f6 10             	lock notb (%eax)
    8e8e:	90                   	nop
    8e8f:	5d                   	pop    %ebp
    8e90:	c3                   	ret    

00008e91 <ck_pr_not_int>:
    8e91:	55                   	push   %ebp
    8e92:	89 e5                	mov    %esp,%ebp
    8e94:	8b 45 08             	mov    0x8(%ebp),%eax
    8e97:	8b 55 08             	mov    0x8(%ebp),%edx
    8e9a:	f0 f7 10             	lock notl (%eax)
    8e9d:	90                   	nop
    8e9e:	5d                   	pop    %ebp
    8e9f:	c3                   	ret    

00008ea0 <ck_pr_not_uint>:
    8ea0:	55                   	push   %ebp
    8ea1:	89 e5                	mov    %esp,%ebp
    8ea3:	8b 45 08             	mov    0x8(%ebp),%eax
    8ea6:	8b 55 08             	mov    0x8(%ebp),%edx
    8ea9:	f0 f7 10             	lock notl (%eax)
    8eac:	90                   	nop
    8ead:	5d                   	pop    %ebp
    8eae:	c3                   	ret    

00008eaf <ck_pr_not_32>:
    8eaf:	55                   	push   %ebp
    8eb0:	89 e5                	mov    %esp,%ebp
    8eb2:	8b 45 08             	mov    0x8(%ebp),%eax
    8eb5:	8b 55 08             	mov    0x8(%ebp),%edx
    8eb8:	f0 f7 10             	lock notl (%eax)
    8ebb:	90                   	nop
    8ebc:	5d                   	pop    %ebp
    8ebd:	c3                   	ret    

00008ebe <ck_pr_not_16>:
    8ebe:	55                   	push   %ebp
    8ebf:	89 e5                	mov    %esp,%ebp
    8ec1:	8b 45 08             	mov    0x8(%ebp),%eax
    8ec4:	8b 55 08             	mov    0x8(%ebp),%edx
    8ec7:	66 f0 f7 10          	lock notw (%eax)
    8ecb:	90                   	nop
    8ecc:	5d                   	pop    %ebp
    8ecd:	c3                   	ret    

00008ece <ck_pr_not_8>:
    8ece:	55                   	push   %ebp
    8ecf:	89 e5                	mov    %esp,%ebp
    8ed1:	8b 45 08             	mov    0x8(%ebp),%eax
    8ed4:	8b 55 08             	mov    0x8(%ebp),%edx
    8ed7:	f0 f6 10             	lock notb (%eax)
    8eda:	90                   	nop
    8edb:	5d                   	pop    %ebp
    8edc:	c3                   	ret    

00008edd <ck_pr_add_ptr>:
	CK_PR_BINARY_S(K, uint, unsigned int, #K "l")		\
	CK_PR_BINARY_S(K, 32, uint32_t, #K "l")			\
	CK_PR_BINARY_S(K, 16, uint16_t, #K "w")			\
	CK_PR_BINARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(add)
    8edd:	55                   	push   %ebp
    8ede:	89 e5                	mov    %esp,%ebp
    8ee0:	8b 45 08             	mov    0x8(%ebp),%eax
    8ee3:	8b 55 0c             	mov    0xc(%ebp),%edx
    8ee6:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8ee9:	f0 01 10             	lock add %edx,(%eax)
    8eec:	90                   	nop
    8eed:	5d                   	pop    %ebp
    8eee:	c3                   	ret    

00008eef <ck_pr_add_char>:
    8eef:	55                   	push   %ebp
    8ef0:	89 e5                	mov    %esp,%ebp
    8ef2:	83 ec 04             	sub    $0x4,%esp
    8ef5:	8b 45 0c             	mov    0xc(%ebp),%eax
    8ef8:	88 45 fc             	mov    %al,-0x4(%ebp)
    8efb:	8b 45 08             	mov    0x8(%ebp),%eax
    8efe:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    8f02:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8f05:	f0 00 10             	lock add %dl,(%eax)
    8f08:	90                   	nop
    8f09:	c9                   	leave  
    8f0a:	c3                   	ret    

00008f0b <ck_pr_add_int>:
    8f0b:	55                   	push   %ebp
    8f0c:	89 e5                	mov    %esp,%ebp
    8f0e:	8b 45 08             	mov    0x8(%ebp),%eax
    8f11:	8b 55 0c             	mov    0xc(%ebp),%edx
    8f14:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8f17:	f0 01 10             	lock add %edx,(%eax)
    8f1a:	90                   	nop
    8f1b:	5d                   	pop    %ebp
    8f1c:	c3                   	ret    

00008f1d <ck_pr_add_uint>:
    8f1d:	55                   	push   %ebp
    8f1e:	89 e5                	mov    %esp,%ebp
    8f20:	8b 45 08             	mov    0x8(%ebp),%eax
    8f23:	8b 55 0c             	mov    0xc(%ebp),%edx
    8f26:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8f29:	f0 01 10             	lock add %edx,(%eax)
    8f2c:	90                   	nop
    8f2d:	5d                   	pop    %ebp
    8f2e:	c3                   	ret    

00008f2f <ck_pr_add_32>:
    8f2f:	55                   	push   %ebp
    8f30:	89 e5                	mov    %esp,%ebp
    8f32:	8b 45 08             	mov    0x8(%ebp),%eax
    8f35:	8b 55 0c             	mov    0xc(%ebp),%edx
    8f38:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8f3b:	f0 01 10             	lock add %edx,(%eax)
    8f3e:	90                   	nop
    8f3f:	5d                   	pop    %ebp
    8f40:	c3                   	ret    

00008f41 <ck_pr_add_16>:
    8f41:	55                   	push   %ebp
    8f42:	89 e5                	mov    %esp,%ebp
    8f44:	83 ec 04             	sub    $0x4,%esp
    8f47:	8b 45 0c             	mov    0xc(%ebp),%eax
    8f4a:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    8f4e:	8b 45 08             	mov    0x8(%ebp),%eax
    8f51:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    8f55:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8f58:	66 f0 01 10          	lock add %dx,(%eax)
    8f5c:	90                   	nop
    8f5d:	c9                   	leave  
    8f5e:	c3                   	ret    

00008f5f <ck_pr_add_8>:
    8f5f:	55                   	push   %ebp
    8f60:	89 e5                	mov    %esp,%ebp
    8f62:	83 ec 04             	sub    $0x4,%esp
    8f65:	8b 45 0c             	mov    0xc(%ebp),%eax
    8f68:	88 45 fc             	mov    %al,-0x4(%ebp)
    8f6b:	8b 45 08             	mov    0x8(%ebp),%eax
    8f6e:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    8f72:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8f75:	f0 00 10             	lock add %dl,(%eax)
    8f78:	90                   	nop
    8f79:	c9                   	leave  
    8f7a:	c3                   	ret    

00008f7b <ck_pr_sub_ptr>:
CK_PR_GENERATE(sub)
    8f7b:	55                   	push   %ebp
    8f7c:	89 e5                	mov    %esp,%ebp
    8f7e:	8b 45 08             	mov    0x8(%ebp),%eax
    8f81:	8b 55 0c             	mov    0xc(%ebp),%edx
    8f84:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8f87:	f0 29 10             	lock sub %edx,(%eax)
    8f8a:	90                   	nop
    8f8b:	5d                   	pop    %ebp
    8f8c:	c3                   	ret    

00008f8d <ck_pr_sub_char>:
    8f8d:	55                   	push   %ebp
    8f8e:	89 e5                	mov    %esp,%ebp
    8f90:	83 ec 04             	sub    $0x4,%esp
    8f93:	8b 45 0c             	mov    0xc(%ebp),%eax
    8f96:	88 45 fc             	mov    %al,-0x4(%ebp)
    8f99:	8b 45 08             	mov    0x8(%ebp),%eax
    8f9c:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    8fa0:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8fa3:	f0 28 10             	lock sub %dl,(%eax)
    8fa6:	90                   	nop
    8fa7:	c9                   	leave  
    8fa8:	c3                   	ret    

00008fa9 <ck_pr_sub_int>:
    8fa9:	55                   	push   %ebp
    8faa:	89 e5                	mov    %esp,%ebp
    8fac:	8b 45 08             	mov    0x8(%ebp),%eax
    8faf:	8b 55 0c             	mov    0xc(%ebp),%edx
    8fb2:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8fb5:	f0 29 10             	lock sub %edx,(%eax)
    8fb8:	90                   	nop
    8fb9:	5d                   	pop    %ebp
    8fba:	c3                   	ret    

00008fbb <ck_pr_sub_uint>:
    8fbb:	55                   	push   %ebp
    8fbc:	89 e5                	mov    %esp,%ebp
    8fbe:	8b 45 08             	mov    0x8(%ebp),%eax
    8fc1:	8b 55 0c             	mov    0xc(%ebp),%edx
    8fc4:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8fc7:	f0 29 10             	lock sub %edx,(%eax)
    8fca:	90                   	nop
    8fcb:	5d                   	pop    %ebp
    8fcc:	c3                   	ret    

00008fcd <ck_pr_sub_32>:
    8fcd:	55                   	push   %ebp
    8fce:	89 e5                	mov    %esp,%ebp
    8fd0:	8b 45 08             	mov    0x8(%ebp),%eax
    8fd3:	8b 55 0c             	mov    0xc(%ebp),%edx
    8fd6:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8fd9:	f0 29 10             	lock sub %edx,(%eax)
    8fdc:	90                   	nop
    8fdd:	5d                   	pop    %ebp
    8fde:	c3                   	ret    

00008fdf <ck_pr_sub_16>:
    8fdf:	55                   	push   %ebp
    8fe0:	89 e5                	mov    %esp,%ebp
    8fe2:	83 ec 04             	sub    $0x4,%esp
    8fe5:	8b 45 0c             	mov    0xc(%ebp),%eax
    8fe8:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    8fec:	8b 45 08             	mov    0x8(%ebp),%eax
    8fef:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    8ff3:	8b 4d 08             	mov    0x8(%ebp),%ecx
    8ff6:	66 f0 29 10          	lock sub %dx,(%eax)
    8ffa:	90                   	nop
    8ffb:	c9                   	leave  
    8ffc:	c3                   	ret    

00008ffd <ck_pr_sub_8>:
    8ffd:	55                   	push   %ebp
    8ffe:	89 e5                	mov    %esp,%ebp
    9000:	83 ec 04             	sub    $0x4,%esp
    9003:	8b 45 0c             	mov    0xc(%ebp),%eax
    9006:	88 45 fc             	mov    %al,-0x4(%ebp)
    9009:	8b 45 08             	mov    0x8(%ebp),%eax
    900c:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    9010:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9013:	f0 28 10             	lock sub %dl,(%eax)
    9016:	90                   	nop
    9017:	c9                   	leave  
    9018:	c3                   	ret    

00009019 <ck_pr_and_ptr>:
CK_PR_GENERATE(and)
    9019:	55                   	push   %ebp
    901a:	89 e5                	mov    %esp,%ebp
    901c:	8b 45 08             	mov    0x8(%ebp),%eax
    901f:	8b 55 0c             	mov    0xc(%ebp),%edx
    9022:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9025:	f0 21 10             	lock and %edx,(%eax)
    9028:	90                   	nop
    9029:	5d                   	pop    %ebp
    902a:	c3                   	ret    

0000902b <ck_pr_and_char>:
    902b:	55                   	push   %ebp
    902c:	89 e5                	mov    %esp,%ebp
    902e:	83 ec 04             	sub    $0x4,%esp
    9031:	8b 45 0c             	mov    0xc(%ebp),%eax
    9034:	88 45 fc             	mov    %al,-0x4(%ebp)
    9037:	8b 45 08             	mov    0x8(%ebp),%eax
    903a:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    903e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9041:	f0 20 10             	lock and %dl,(%eax)
    9044:	90                   	nop
    9045:	c9                   	leave  
    9046:	c3                   	ret    

00009047 <ck_pr_and_int>:
    9047:	55                   	push   %ebp
    9048:	89 e5                	mov    %esp,%ebp
    904a:	8b 45 08             	mov    0x8(%ebp),%eax
    904d:	8b 55 0c             	mov    0xc(%ebp),%edx
    9050:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9053:	f0 21 10             	lock and %edx,(%eax)
    9056:	90                   	nop
    9057:	5d                   	pop    %ebp
    9058:	c3                   	ret    

00009059 <ck_pr_and_uint>:
    9059:	55                   	push   %ebp
    905a:	89 e5                	mov    %esp,%ebp
    905c:	8b 45 08             	mov    0x8(%ebp),%eax
    905f:	8b 55 0c             	mov    0xc(%ebp),%edx
    9062:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9065:	f0 21 10             	lock and %edx,(%eax)
    9068:	90                   	nop
    9069:	5d                   	pop    %ebp
    906a:	c3                   	ret    

0000906b <ck_pr_and_32>:
    906b:	55                   	push   %ebp
    906c:	89 e5                	mov    %esp,%ebp
    906e:	8b 45 08             	mov    0x8(%ebp),%eax
    9071:	8b 55 0c             	mov    0xc(%ebp),%edx
    9074:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9077:	f0 21 10             	lock and %edx,(%eax)
    907a:	90                   	nop
    907b:	5d                   	pop    %ebp
    907c:	c3                   	ret    

0000907d <ck_pr_and_16>:
    907d:	55                   	push   %ebp
    907e:	89 e5                	mov    %esp,%ebp
    9080:	83 ec 04             	sub    $0x4,%esp
    9083:	8b 45 0c             	mov    0xc(%ebp),%eax
    9086:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    908a:	8b 45 08             	mov    0x8(%ebp),%eax
    908d:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    9091:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9094:	66 f0 21 10          	lock and %dx,(%eax)
    9098:	90                   	nop
    9099:	c9                   	leave  
    909a:	c3                   	ret    

0000909b <ck_pr_and_8>:
    909b:	55                   	push   %ebp
    909c:	89 e5                	mov    %esp,%ebp
    909e:	83 ec 04             	sub    $0x4,%esp
    90a1:	8b 45 0c             	mov    0xc(%ebp),%eax
    90a4:	88 45 fc             	mov    %al,-0x4(%ebp)
    90a7:	8b 45 08             	mov    0x8(%ebp),%eax
    90aa:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    90ae:	8b 4d 08             	mov    0x8(%ebp),%ecx
    90b1:	f0 20 10             	lock and %dl,(%eax)
    90b4:	90                   	nop
    90b5:	c9                   	leave  
    90b6:	c3                   	ret    

000090b7 <ck_pr_or_ptr>:
CK_PR_GENERATE(or)
    90b7:	55                   	push   %ebp
    90b8:	89 e5                	mov    %esp,%ebp
    90ba:	8b 45 08             	mov    0x8(%ebp),%eax
    90bd:	8b 55 0c             	mov    0xc(%ebp),%edx
    90c0:	8b 4d 08             	mov    0x8(%ebp),%ecx
    90c3:	f0 09 10             	lock or %edx,(%eax)
    90c6:	90                   	nop
    90c7:	5d                   	pop    %ebp
    90c8:	c3                   	ret    

000090c9 <ck_pr_or_char>:
    90c9:	55                   	push   %ebp
    90ca:	89 e5                	mov    %esp,%ebp
    90cc:	83 ec 04             	sub    $0x4,%esp
    90cf:	8b 45 0c             	mov    0xc(%ebp),%eax
    90d2:	88 45 fc             	mov    %al,-0x4(%ebp)
    90d5:	8b 45 08             	mov    0x8(%ebp),%eax
    90d8:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    90dc:	8b 4d 08             	mov    0x8(%ebp),%ecx
    90df:	f0 08 10             	lock or %dl,(%eax)
    90e2:	90                   	nop
    90e3:	c9                   	leave  
    90e4:	c3                   	ret    

000090e5 <ck_pr_or_int>:
    90e5:	55                   	push   %ebp
    90e6:	89 e5                	mov    %esp,%ebp
    90e8:	8b 45 08             	mov    0x8(%ebp),%eax
    90eb:	8b 55 0c             	mov    0xc(%ebp),%edx
    90ee:	8b 4d 08             	mov    0x8(%ebp),%ecx
    90f1:	f0 09 10             	lock or %edx,(%eax)
    90f4:	90                   	nop
    90f5:	5d                   	pop    %ebp
    90f6:	c3                   	ret    

000090f7 <ck_pr_or_uint>:
    90f7:	55                   	push   %ebp
    90f8:	89 e5                	mov    %esp,%ebp
    90fa:	8b 45 08             	mov    0x8(%ebp),%eax
    90fd:	8b 55 0c             	mov    0xc(%ebp),%edx
    9100:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9103:	f0 09 10             	lock or %edx,(%eax)
    9106:	90                   	nop
    9107:	5d                   	pop    %ebp
    9108:	c3                   	ret    

00009109 <ck_pr_or_32>:
    9109:	55                   	push   %ebp
    910a:	89 e5                	mov    %esp,%ebp
    910c:	8b 45 08             	mov    0x8(%ebp),%eax
    910f:	8b 55 0c             	mov    0xc(%ebp),%edx
    9112:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9115:	f0 09 10             	lock or %edx,(%eax)
    9118:	90                   	nop
    9119:	5d                   	pop    %ebp
    911a:	c3                   	ret    

0000911b <ck_pr_or_16>:
    911b:	55                   	push   %ebp
    911c:	89 e5                	mov    %esp,%ebp
    911e:	83 ec 04             	sub    $0x4,%esp
    9121:	8b 45 0c             	mov    0xc(%ebp),%eax
    9124:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    9128:	8b 45 08             	mov    0x8(%ebp),%eax
    912b:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    912f:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9132:	66 f0 09 10          	lock or %dx,(%eax)
    9136:	90                   	nop
    9137:	c9                   	leave  
    9138:	c3                   	ret    

00009139 <ck_pr_or_8>:
    9139:	55                   	push   %ebp
    913a:	89 e5                	mov    %esp,%ebp
    913c:	83 ec 04             	sub    $0x4,%esp
    913f:	8b 45 0c             	mov    0xc(%ebp),%eax
    9142:	88 45 fc             	mov    %al,-0x4(%ebp)
    9145:	8b 45 08             	mov    0x8(%ebp),%eax
    9148:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    914c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    914f:	f0 08 10             	lock or %dl,(%eax)
    9152:	90                   	nop
    9153:	c9                   	leave  
    9154:	c3                   	ret    

00009155 <ck_pr_xor_ptr>:
CK_PR_GENERATE(xor)
    9155:	55                   	push   %ebp
    9156:	89 e5                	mov    %esp,%ebp
    9158:	8b 45 08             	mov    0x8(%ebp),%eax
    915b:	8b 55 0c             	mov    0xc(%ebp),%edx
    915e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9161:	f0 31 10             	lock xor %edx,(%eax)
    9164:	90                   	nop
    9165:	5d                   	pop    %ebp
    9166:	c3                   	ret    

00009167 <ck_pr_xor_char>:
    9167:	55                   	push   %ebp
    9168:	89 e5                	mov    %esp,%ebp
    916a:	83 ec 04             	sub    $0x4,%esp
    916d:	8b 45 0c             	mov    0xc(%ebp),%eax
    9170:	88 45 fc             	mov    %al,-0x4(%ebp)
    9173:	8b 45 08             	mov    0x8(%ebp),%eax
    9176:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    917a:	8b 4d 08             	mov    0x8(%ebp),%ecx
    917d:	f0 30 10             	lock xor %dl,(%eax)
    9180:	90                   	nop
    9181:	c9                   	leave  
    9182:	c3                   	ret    

00009183 <ck_pr_xor_int>:
    9183:	55                   	push   %ebp
    9184:	89 e5                	mov    %esp,%ebp
    9186:	8b 45 08             	mov    0x8(%ebp),%eax
    9189:	8b 55 0c             	mov    0xc(%ebp),%edx
    918c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    918f:	f0 31 10             	lock xor %edx,(%eax)
    9192:	90                   	nop
    9193:	5d                   	pop    %ebp
    9194:	c3                   	ret    

00009195 <ck_pr_xor_uint>:
    9195:	55                   	push   %ebp
    9196:	89 e5                	mov    %esp,%ebp
    9198:	8b 45 08             	mov    0x8(%ebp),%eax
    919b:	8b 55 0c             	mov    0xc(%ebp),%edx
    919e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    91a1:	f0 31 10             	lock xor %edx,(%eax)
    91a4:	90                   	nop
    91a5:	5d                   	pop    %ebp
    91a6:	c3                   	ret    

000091a7 <ck_pr_xor_32>:
    91a7:	55                   	push   %ebp
    91a8:	89 e5                	mov    %esp,%ebp
    91aa:	8b 45 08             	mov    0x8(%ebp),%eax
    91ad:	8b 55 0c             	mov    0xc(%ebp),%edx
    91b0:	8b 4d 08             	mov    0x8(%ebp),%ecx
    91b3:	f0 31 10             	lock xor %edx,(%eax)
    91b6:	90                   	nop
    91b7:	5d                   	pop    %ebp
    91b8:	c3                   	ret    

000091b9 <ck_pr_xor_16>:
    91b9:	55                   	push   %ebp
    91ba:	89 e5                	mov    %esp,%ebp
    91bc:	83 ec 04             	sub    $0x4,%esp
    91bf:	8b 45 0c             	mov    0xc(%ebp),%eax
    91c2:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    91c6:	8b 45 08             	mov    0x8(%ebp),%eax
    91c9:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    91cd:	8b 4d 08             	mov    0x8(%ebp),%ecx
    91d0:	66 f0 31 10          	lock xor %dx,(%eax)
    91d4:	90                   	nop
    91d5:	c9                   	leave  
    91d6:	c3                   	ret    

000091d7 <ck_pr_xor_8>:
    91d7:	55                   	push   %ebp
    91d8:	89 e5                	mov    %esp,%ebp
    91da:	83 ec 04             	sub    $0x4,%esp
    91dd:	8b 45 0c             	mov    0xc(%ebp),%eax
    91e0:	88 45 fc             	mov    %al,-0x4(%ebp)
    91e3:	8b 45 08             	mov    0x8(%ebp),%eax
    91e6:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    91ea:	8b 4d 08             	mov    0x8(%ebp),%ecx
    91ed:	f0 30 10             	lock xor %dl,(%eax)
    91f0:	90                   	nop
    91f1:	c9                   	leave  
    91f2:	c3                   	ret    

000091f3 <ck_pr_cas_ptr>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return z;							\
	}

CK_PR_CAS(ptr, void, void *, char, "cmpxchgl")
    91f3:	55                   	push   %ebp
    91f4:	89 e5                	mov    %esp,%ebp
    91f6:	53                   	push   %ebx
    91f7:	83 ec 10             	sub    $0x10,%esp
    91fa:	8b 55 08             	mov    0x8(%ebp),%edx
    91fd:	8b 4d 10             	mov    0x10(%ebp),%ecx
    9200:	8b 45 0c             	mov    0xc(%ebp),%eax
    9203:	8b 5d 08             	mov    0x8(%ebp),%ebx
    9206:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    920a:	0f 94 c0             	sete   %al
    920d:	88 45 fb             	mov    %al,-0x5(%ebp)
    9210:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    9214:	83 c4 10             	add    $0x10,%esp
    9217:	5b                   	pop    %ebx
    9218:	5d                   	pop    %ebp
    9219:	c3                   	ret    

0000921a <ck_pr_cas_char>:

#define CK_PR_CAS_S(S, T, I) CK_PR_CAS(S, T, T, T, I)

CK_PR_CAS_S(char, char, "cmpxchgb")
    921a:	55                   	push   %ebp
    921b:	89 e5                	mov    %esp,%ebp
    921d:	53                   	push   %ebx
    921e:	83 ec 18             	sub    $0x18,%esp
    9221:	8b 55 0c             	mov    0xc(%ebp),%edx
    9224:	8b 45 10             	mov    0x10(%ebp),%eax
    9227:	88 55 e8             	mov    %dl,-0x18(%ebp)
    922a:	88 45 e4             	mov    %al,-0x1c(%ebp)
    922d:	8b 55 08             	mov    0x8(%ebp),%edx
    9230:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
    9234:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
    9238:	8b 5d 08             	mov    0x8(%ebp),%ebx
    923b:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
    923f:	0f 94 c0             	sete   %al
    9242:	88 45 fb             	mov    %al,-0x5(%ebp)
    9245:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    9249:	83 c4 18             	add    $0x18,%esp
    924c:	5b                   	pop    %ebx
    924d:	5d                   	pop    %ebp
    924e:	c3                   	ret    

0000924f <ck_pr_cas_int>:
CK_PR_CAS_S(int, int, "cmpxchgl")
    924f:	55                   	push   %ebp
    9250:	89 e5                	mov    %esp,%ebp
    9252:	53                   	push   %ebx
    9253:	83 ec 10             	sub    $0x10,%esp
    9256:	8b 55 08             	mov    0x8(%ebp),%edx
    9259:	8b 4d 10             	mov    0x10(%ebp),%ecx
    925c:	8b 45 0c             	mov    0xc(%ebp),%eax
    925f:	8b 5d 08             	mov    0x8(%ebp),%ebx
    9262:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    9266:	0f 94 c0             	sete   %al
    9269:	88 45 fb             	mov    %al,-0x5(%ebp)
    926c:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    9270:	83 c4 10             	add    $0x10,%esp
    9273:	5b                   	pop    %ebx
    9274:	5d                   	pop    %ebp
    9275:	c3                   	ret    

00009276 <ck_pr_cas_uint>:
CK_PR_CAS_S(uint, unsigned int, "cmpxchgl")
    9276:	55                   	push   %ebp
    9277:	89 e5                	mov    %esp,%ebp
    9279:	53                   	push   %ebx
    927a:	83 ec 10             	sub    $0x10,%esp
    927d:	8b 55 08             	mov    0x8(%ebp),%edx
    9280:	8b 4d 10             	mov    0x10(%ebp),%ecx
    9283:	8b 45 0c             	mov    0xc(%ebp),%eax
    9286:	8b 5d 08             	mov    0x8(%ebp),%ebx
    9289:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    928d:	0f 94 c0             	sete   %al
    9290:	88 45 fb             	mov    %al,-0x5(%ebp)
    9293:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    9297:	83 c4 10             	add    $0x10,%esp
    929a:	5b                   	pop    %ebx
    929b:	5d                   	pop    %ebp
    929c:	c3                   	ret    

0000929d <ck_pr_cas_32>:
CK_PR_CAS_S(32, uint32_t, "cmpxchgl")
    929d:	55                   	push   %ebp
    929e:	89 e5                	mov    %esp,%ebp
    92a0:	53                   	push   %ebx
    92a1:	83 ec 10             	sub    $0x10,%esp
    92a4:	8b 55 08             	mov    0x8(%ebp),%edx
    92a7:	8b 4d 10             	mov    0x10(%ebp),%ecx
    92aa:	8b 45 0c             	mov    0xc(%ebp),%eax
    92ad:	8b 5d 08             	mov    0x8(%ebp),%ebx
    92b0:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    92b4:	0f 94 c0             	sete   %al
    92b7:	88 45 fb             	mov    %al,-0x5(%ebp)
    92ba:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    92be:	83 c4 10             	add    $0x10,%esp
    92c1:	5b                   	pop    %ebx
    92c2:	5d                   	pop    %ebp
    92c3:	c3                   	ret    

000092c4 <ck_pr_cas_16>:
CK_PR_CAS_S(16, uint16_t, "cmpxchgw")
    92c4:	55                   	push   %ebp
    92c5:	89 e5                	mov    %esp,%ebp
    92c7:	53                   	push   %ebx
    92c8:	83 ec 18             	sub    $0x18,%esp
    92cb:	8b 55 0c             	mov    0xc(%ebp),%edx
    92ce:	8b 45 10             	mov    0x10(%ebp),%eax
    92d1:	66 89 55 e8          	mov    %dx,-0x18(%ebp)
    92d5:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
    92d9:	8b 55 08             	mov    0x8(%ebp),%edx
    92dc:	0f b7 4d e4          	movzwl -0x1c(%ebp),%ecx
    92e0:	0f b7 45 e8          	movzwl -0x18(%ebp),%eax
    92e4:	8b 5d 08             	mov    0x8(%ebp),%ebx
    92e7:	66 f0 0f b1 0a       	lock cmpxchg %cx,(%edx)
    92ec:	0f 94 c0             	sete   %al
    92ef:	88 45 fb             	mov    %al,-0x5(%ebp)
    92f2:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    92f6:	83 c4 18             	add    $0x18,%esp
    92f9:	5b                   	pop    %ebx
    92fa:	5d                   	pop    %ebp
    92fb:	c3                   	ret    

000092fc <ck_pr_cas_8>:
CK_PR_CAS_S(8,  uint8_t,  "cmpxchgb")
    92fc:	55                   	push   %ebp
    92fd:	89 e5                	mov    %esp,%ebp
    92ff:	53                   	push   %ebx
    9300:	83 ec 18             	sub    $0x18,%esp
    9303:	8b 55 0c             	mov    0xc(%ebp),%edx
    9306:	8b 45 10             	mov    0x10(%ebp),%eax
    9309:	88 55 e8             	mov    %dl,-0x18(%ebp)
    930c:	88 45 e4             	mov    %al,-0x1c(%ebp)
    930f:	8b 55 08             	mov    0x8(%ebp),%edx
    9312:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
    9316:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
    931a:	8b 5d 08             	mov    0x8(%ebp),%ebx
    931d:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
    9321:	0f 94 c0             	sete   %al
    9324:	88 45 fb             	mov    %al,-0x5(%ebp)
    9327:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
    932b:	83 c4 18             	add    $0x18,%esp
    932e:	5b                   	pop    %ebx
    932f:	5d                   	pop    %ebp
    9330:	c3                   	ret    

00009331 <ck_pr_cas_ptr_value>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return (bool)z;							\
	}

CK_PR_CAS_O(ptr, void, void *, char, "l", "eax")
    9331:	55                   	push   %ebp
    9332:	89 e5                	mov    %esp,%ebp
    9334:	56                   	push   %esi
    9335:	53                   	push   %ebx
    9336:	83 ec 10             	sub    $0x10,%esp
    9339:	8b 5d 08             	mov    0x8(%ebp),%ebx
    933c:	8b 75 14             	mov    0x14(%ebp),%esi
    933f:	8b 55 10             	mov    0x10(%ebp),%edx
    9342:	8b 45 0c             	mov    0xc(%ebp),%eax
    9345:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9348:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
    934c:	89 06                	mov    %eax,(%esi)
    934e:	0f 94 c0             	sete   %al
    9351:	88 45 f7             	mov    %al,-0x9(%ebp)
    9354:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    9358:	83 c4 10             	add    $0x10,%esp
    935b:	5b                   	pop    %ebx
    935c:	5e                   	pop    %esi
    935d:	5d                   	pop    %ebp
    935e:	c3                   	ret    

0000935f <ck_pr_cas_char_value>:

#define CK_PR_CAS_O_S(S, T, I, R)	\
	CK_PR_CAS_O(S, T, T, T, I, R)

CK_PR_CAS_O_S(char, char, "b", "al")
    935f:	55                   	push   %ebp
    9360:	89 e5                	mov    %esp,%ebp
    9362:	56                   	push   %esi
    9363:	53                   	push   %ebx
    9364:	83 ec 18             	sub    $0x18,%esp
    9367:	8b 55 0c             	mov    0xc(%ebp),%edx
    936a:	8b 45 10             	mov    0x10(%ebp),%eax
    936d:	88 55 e4             	mov    %dl,-0x1c(%ebp)
    9370:	88 45 e0             	mov    %al,-0x20(%ebp)
    9373:	8b 5d 08             	mov    0x8(%ebp),%ebx
    9376:	8b 75 14             	mov    0x14(%ebp),%esi
    9379:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
    937d:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
    9381:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9384:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
    9388:	88 06                	mov    %al,(%esi)
    938a:	0f 94 c0             	sete   %al
    938d:	88 45 f7             	mov    %al,-0x9(%ebp)
    9390:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    9394:	83 c4 18             	add    $0x18,%esp
    9397:	5b                   	pop    %ebx
    9398:	5e                   	pop    %esi
    9399:	5d                   	pop    %ebp
    939a:	c3                   	ret    

0000939b <ck_pr_cas_int_value>:
CK_PR_CAS_O_S(int, int, "l", "eax")
    939b:	55                   	push   %ebp
    939c:	89 e5                	mov    %esp,%ebp
    939e:	56                   	push   %esi
    939f:	53                   	push   %ebx
    93a0:	83 ec 10             	sub    $0x10,%esp
    93a3:	8b 5d 08             	mov    0x8(%ebp),%ebx
    93a6:	8b 75 14             	mov    0x14(%ebp),%esi
    93a9:	8b 55 10             	mov    0x10(%ebp),%edx
    93ac:	8b 45 0c             	mov    0xc(%ebp),%eax
    93af:	8b 4d 08             	mov    0x8(%ebp),%ecx
    93b2:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
    93b6:	89 06                	mov    %eax,(%esi)
    93b8:	0f 94 c0             	sete   %al
    93bb:	88 45 f7             	mov    %al,-0x9(%ebp)
    93be:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    93c2:	83 c4 10             	add    $0x10,%esp
    93c5:	5b                   	pop    %ebx
    93c6:	5e                   	pop    %esi
    93c7:	5d                   	pop    %ebp
    93c8:	c3                   	ret    

000093c9 <ck_pr_cas_uint_value>:
CK_PR_CAS_O_S(uint, unsigned int, "l", "eax")
    93c9:	55                   	push   %ebp
    93ca:	89 e5                	mov    %esp,%ebp
    93cc:	56                   	push   %esi
    93cd:	53                   	push   %ebx
    93ce:	83 ec 10             	sub    $0x10,%esp
    93d1:	8b 5d 08             	mov    0x8(%ebp),%ebx
    93d4:	8b 75 14             	mov    0x14(%ebp),%esi
    93d7:	8b 55 10             	mov    0x10(%ebp),%edx
    93da:	8b 45 0c             	mov    0xc(%ebp),%eax
    93dd:	8b 4d 08             	mov    0x8(%ebp),%ecx
    93e0:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
    93e4:	89 06                	mov    %eax,(%esi)
    93e6:	0f 94 c0             	sete   %al
    93e9:	88 45 f7             	mov    %al,-0x9(%ebp)
    93ec:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    93f0:	83 c4 10             	add    $0x10,%esp
    93f3:	5b                   	pop    %ebx
    93f4:	5e                   	pop    %esi
    93f5:	5d                   	pop    %ebp
    93f6:	c3                   	ret    

000093f7 <ck_pr_cas_32_value>:
CK_PR_CAS_O_S(32, uint32_t, "l", "eax")
    93f7:	55                   	push   %ebp
    93f8:	89 e5                	mov    %esp,%ebp
    93fa:	56                   	push   %esi
    93fb:	53                   	push   %ebx
    93fc:	83 ec 10             	sub    $0x10,%esp
    93ff:	8b 5d 08             	mov    0x8(%ebp),%ebx
    9402:	8b 75 14             	mov    0x14(%ebp),%esi
    9405:	8b 55 10             	mov    0x10(%ebp),%edx
    9408:	8b 45 0c             	mov    0xc(%ebp),%eax
    940b:	8b 4d 08             	mov    0x8(%ebp),%ecx
    940e:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
    9412:	89 06                	mov    %eax,(%esi)
    9414:	0f 94 c0             	sete   %al
    9417:	88 45 f7             	mov    %al,-0x9(%ebp)
    941a:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    941e:	83 c4 10             	add    $0x10,%esp
    9421:	5b                   	pop    %ebx
    9422:	5e                   	pop    %esi
    9423:	5d                   	pop    %ebp
    9424:	c3                   	ret    

00009425 <ck_pr_cas_16_value>:
CK_PR_CAS_O_S(16, uint16_t, "w", "ax")
    9425:	55                   	push   %ebp
    9426:	89 e5                	mov    %esp,%ebp
    9428:	56                   	push   %esi
    9429:	53                   	push   %ebx
    942a:	83 ec 18             	sub    $0x18,%esp
    942d:	8b 55 0c             	mov    0xc(%ebp),%edx
    9430:	8b 45 10             	mov    0x10(%ebp),%eax
    9433:	66 89 55 e4          	mov    %dx,-0x1c(%ebp)
    9437:	66 89 45 e0          	mov    %ax,-0x20(%ebp)
    943b:	8b 5d 08             	mov    0x8(%ebp),%ebx
    943e:	8b 75 14             	mov    0x14(%ebp),%esi
    9441:	0f b7 55 e0          	movzwl -0x20(%ebp),%edx
    9445:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
    9449:	8b 4d 08             	mov    0x8(%ebp),%ecx
    944c:	66 f0 0f b1 13       	lock cmpxchg %dx,(%ebx)
    9451:	66 89 06             	mov    %ax,(%esi)
    9454:	0f 94 c0             	sete   %al
    9457:	88 45 f7             	mov    %al,-0x9(%ebp)
    945a:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    945e:	83 c4 18             	add    $0x18,%esp
    9461:	5b                   	pop    %ebx
    9462:	5e                   	pop    %esi
    9463:	5d                   	pop    %ebp
    9464:	c3                   	ret    

00009465 <ck_pr_cas_8_value>:
CK_PR_CAS_O_S(8,  uint8_t,  "b", "al")
    9465:	55                   	push   %ebp
    9466:	89 e5                	mov    %esp,%ebp
    9468:	56                   	push   %esi
    9469:	53                   	push   %ebx
    946a:	83 ec 18             	sub    $0x18,%esp
    946d:	8b 55 0c             	mov    0xc(%ebp),%edx
    9470:	8b 45 10             	mov    0x10(%ebp),%eax
    9473:	88 55 e4             	mov    %dl,-0x1c(%ebp)
    9476:	88 45 e0             	mov    %al,-0x20(%ebp)
    9479:	8b 5d 08             	mov    0x8(%ebp),%ebx
    947c:	8b 75 14             	mov    0x14(%ebp),%esi
    947f:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
    9483:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
    9487:	8b 4d 08             	mov    0x8(%ebp),%ecx
    948a:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
    948e:	88 06                	mov    %al,(%esi)
    9490:	0f 94 c0             	sete   %al
    9493:	88 45 f7             	mov    %al,-0x9(%ebp)
    9496:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
    949a:	83 c4 18             	add    $0x18,%esp
    949d:	5b                   	pop    %ebx
    949e:	5e                   	pop    %esi
    949f:	5d                   	pop    %ebp
    94a0:	c3                   	ret    

000094a1 <ck_pr_btc_ptr>:
	CK_PR_BT_S(K, uint, unsigned int, #K "l %2, %0")	\
	CK_PR_BT_S(K, int, int, #K "l %2, %0")			\
	CK_PR_BT_S(K, 32, uint32_t, #K "l %2, %0")		\
	CK_PR_BT_S(K, 16, uint16_t, #K "w %w2, %0")

CK_PR_GENERATE(btc)
    94a1:	55                   	push   %ebp
    94a2:	89 e5                	mov    %esp,%ebp
    94a4:	83 ec 10             	sub    $0x10,%esp
    94a7:	8b 55 08             	mov    0x8(%ebp),%edx
    94aa:	8b 45 0c             	mov    0xc(%ebp),%eax
    94ad:	8b 4d 08             	mov    0x8(%ebp),%ecx
    94b0:	f0 0f bb 02          	lock btc %eax,(%edx)
    94b4:	0f 92 c0             	setb   %al
    94b7:	88 45 ff             	mov    %al,-0x1(%ebp)
    94ba:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    94be:	c9                   	leave  
    94bf:	c3                   	ret    

000094c0 <ck_pr_btc_uint>:
    94c0:	55                   	push   %ebp
    94c1:	89 e5                	mov    %esp,%ebp
    94c3:	83 ec 10             	sub    $0x10,%esp
    94c6:	8b 55 08             	mov    0x8(%ebp),%edx
    94c9:	8b 45 0c             	mov    0xc(%ebp),%eax
    94cc:	8b 4d 08             	mov    0x8(%ebp),%ecx
    94cf:	f0 0f bb 02          	lock btc %eax,(%edx)
    94d3:	0f 92 c0             	setb   %al
    94d6:	88 45 ff             	mov    %al,-0x1(%ebp)
    94d9:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    94dd:	c9                   	leave  
    94de:	c3                   	ret    

000094df <ck_pr_btc_int>:
    94df:	55                   	push   %ebp
    94e0:	89 e5                	mov    %esp,%ebp
    94e2:	83 ec 10             	sub    $0x10,%esp
    94e5:	8b 45 0c             	mov    0xc(%ebp),%eax
    94e8:	8b 55 08             	mov    0x8(%ebp),%edx
    94eb:	8b 4d 08             	mov    0x8(%ebp),%ecx
    94ee:	f0 0f bb 02          	lock btc %eax,(%edx)
    94f2:	0f 92 c0             	setb   %al
    94f5:	88 45 ff             	mov    %al,-0x1(%ebp)
    94f8:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    94fc:	c9                   	leave  
    94fd:	c3                   	ret    

000094fe <ck_pr_btc_32>:
    94fe:	55                   	push   %ebp
    94ff:	89 e5                	mov    %esp,%ebp
    9501:	83 ec 10             	sub    $0x10,%esp
    9504:	8b 55 08             	mov    0x8(%ebp),%edx
    9507:	8b 45 0c             	mov    0xc(%ebp),%eax
    950a:	8b 4d 08             	mov    0x8(%ebp),%ecx
    950d:	f0 0f bb 02          	lock btc %eax,(%edx)
    9511:	0f 92 c0             	setb   %al
    9514:	88 45 ff             	mov    %al,-0x1(%ebp)
    9517:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    951b:	c9                   	leave  
    951c:	c3                   	ret    

0000951d <ck_pr_btc_16>:
    951d:	55                   	push   %ebp
    951e:	89 e5                	mov    %esp,%ebp
    9520:	83 ec 10             	sub    $0x10,%esp
    9523:	8b 45 0c             	mov    0xc(%ebp),%eax
    9526:	8b 55 08             	mov    0x8(%ebp),%edx
    9529:	8b 4d 08             	mov    0x8(%ebp),%ecx
    952c:	66 f0 0f bb 02       	lock btc %ax,(%edx)
    9531:	0f 92 c0             	setb   %al
    9534:	88 45 ff             	mov    %al,-0x1(%ebp)
    9537:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    953b:	c9                   	leave  
    953c:	c3                   	ret    

0000953d <ck_pr_bts_ptr>:
CK_PR_GENERATE(bts)
    953d:	55                   	push   %ebp
    953e:	89 e5                	mov    %esp,%ebp
    9540:	83 ec 10             	sub    $0x10,%esp
    9543:	8b 55 08             	mov    0x8(%ebp),%edx
    9546:	8b 45 0c             	mov    0xc(%ebp),%eax
    9549:	8b 4d 08             	mov    0x8(%ebp),%ecx
    954c:	f0 0f ab 02          	lock bts %eax,(%edx)
    9550:	0f 92 c0             	setb   %al
    9553:	88 45 ff             	mov    %al,-0x1(%ebp)
    9556:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    955a:	c9                   	leave  
    955b:	c3                   	ret    

0000955c <ck_pr_bts_uint>:
    955c:	55                   	push   %ebp
    955d:	89 e5                	mov    %esp,%ebp
    955f:	83 ec 10             	sub    $0x10,%esp
    9562:	8b 55 08             	mov    0x8(%ebp),%edx
    9565:	8b 45 0c             	mov    0xc(%ebp),%eax
    9568:	8b 4d 08             	mov    0x8(%ebp),%ecx
    956b:	f0 0f ab 02          	lock bts %eax,(%edx)
    956f:	0f 92 c0             	setb   %al
    9572:	88 45 ff             	mov    %al,-0x1(%ebp)
    9575:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    9579:	c9                   	leave  
    957a:	c3                   	ret    

0000957b <ck_pr_bts_int>:
    957b:	55                   	push   %ebp
    957c:	89 e5                	mov    %esp,%ebp
    957e:	83 ec 10             	sub    $0x10,%esp
    9581:	8b 45 0c             	mov    0xc(%ebp),%eax
    9584:	8b 55 08             	mov    0x8(%ebp),%edx
    9587:	8b 4d 08             	mov    0x8(%ebp),%ecx
    958a:	f0 0f ab 02          	lock bts %eax,(%edx)
    958e:	0f 92 c0             	setb   %al
    9591:	88 45 ff             	mov    %al,-0x1(%ebp)
    9594:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    9598:	c9                   	leave  
    9599:	c3                   	ret    

0000959a <ck_pr_bts_32>:
    959a:	55                   	push   %ebp
    959b:	89 e5                	mov    %esp,%ebp
    959d:	83 ec 10             	sub    $0x10,%esp
    95a0:	8b 55 08             	mov    0x8(%ebp),%edx
    95a3:	8b 45 0c             	mov    0xc(%ebp),%eax
    95a6:	8b 4d 08             	mov    0x8(%ebp),%ecx
    95a9:	f0 0f ab 02          	lock bts %eax,(%edx)
    95ad:	0f 92 c0             	setb   %al
    95b0:	88 45 ff             	mov    %al,-0x1(%ebp)
    95b3:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    95b7:	c9                   	leave  
    95b8:	c3                   	ret    

000095b9 <ck_pr_bts_16>:
    95b9:	55                   	push   %ebp
    95ba:	89 e5                	mov    %esp,%ebp
    95bc:	83 ec 10             	sub    $0x10,%esp
    95bf:	8b 45 0c             	mov    0xc(%ebp),%eax
    95c2:	8b 55 08             	mov    0x8(%ebp),%edx
    95c5:	8b 4d 08             	mov    0x8(%ebp),%ecx
    95c8:	66 f0 0f ab 02       	lock bts %ax,(%edx)
    95cd:	0f 92 c0             	setb   %al
    95d0:	88 45 ff             	mov    %al,-0x1(%ebp)
    95d3:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    95d7:	c9                   	leave  
    95d8:	c3                   	ret    

000095d9 <ck_pr_btr_ptr>:
CK_PR_GENERATE(btr)
    95d9:	55                   	push   %ebp
    95da:	89 e5                	mov    %esp,%ebp
    95dc:	83 ec 10             	sub    $0x10,%esp
    95df:	8b 55 08             	mov    0x8(%ebp),%edx
    95e2:	8b 45 0c             	mov    0xc(%ebp),%eax
    95e5:	8b 4d 08             	mov    0x8(%ebp),%ecx
    95e8:	f0 0f b3 02          	lock btr %eax,(%edx)
    95ec:	0f 92 c0             	setb   %al
    95ef:	88 45 ff             	mov    %al,-0x1(%ebp)
    95f2:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    95f6:	c9                   	leave  
    95f7:	c3                   	ret    

000095f8 <ck_pr_btr_uint>:
    95f8:	55                   	push   %ebp
    95f9:	89 e5                	mov    %esp,%ebp
    95fb:	83 ec 10             	sub    $0x10,%esp
    95fe:	8b 55 08             	mov    0x8(%ebp),%edx
    9601:	8b 45 0c             	mov    0xc(%ebp),%eax
    9604:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9607:	f0 0f b3 02          	lock btr %eax,(%edx)
    960b:	0f 92 c0             	setb   %al
    960e:	88 45 ff             	mov    %al,-0x1(%ebp)
    9611:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    9615:	c9                   	leave  
    9616:	c3                   	ret    

00009617 <ck_pr_btr_int>:
    9617:	55                   	push   %ebp
    9618:	89 e5                	mov    %esp,%ebp
    961a:	83 ec 10             	sub    $0x10,%esp
    961d:	8b 45 0c             	mov    0xc(%ebp),%eax
    9620:	8b 55 08             	mov    0x8(%ebp),%edx
    9623:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9626:	f0 0f b3 02          	lock btr %eax,(%edx)
    962a:	0f 92 c0             	setb   %al
    962d:	88 45 ff             	mov    %al,-0x1(%ebp)
    9630:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    9634:	c9                   	leave  
    9635:	c3                   	ret    

00009636 <ck_pr_btr_32>:
    9636:	55                   	push   %ebp
    9637:	89 e5                	mov    %esp,%ebp
    9639:	83 ec 10             	sub    $0x10,%esp
    963c:	8b 55 08             	mov    0x8(%ebp),%edx
    963f:	8b 45 0c             	mov    0xc(%ebp),%eax
    9642:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9645:	f0 0f b3 02          	lock btr %eax,(%edx)
    9649:	0f 92 c0             	setb   %al
    964c:	88 45 ff             	mov    %al,-0x1(%ebp)
    964f:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    9653:	c9                   	leave  
    9654:	c3                   	ret    

00009655 <ck_pr_btr_16>:
    9655:	55                   	push   %ebp
    9656:	89 e5                	mov    %esp,%ebp
    9658:	83 ec 10             	sub    $0x10,%esp
    965b:	8b 45 0c             	mov    0xc(%ebp),%eax
    965e:	8b 55 08             	mov    0x8(%ebp),%edx
    9661:	8b 4d 08             	mov    0x8(%ebp),%ecx
    9664:	66 f0 0f b3 02       	lock btr %ax,(%edx)
    9669:	0f 92 c0             	setb   %al
    966c:	88 45 ff             	mov    %al,-0x1(%ebp)
    966f:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    9673:	c9                   	leave  
    9674:	c3                   	ret    

00009675 <ck_pr_barrier>:

#include <ck_cc.h>

CK_CC_INLINE static void
ck_pr_barrier(void)
{
    9675:	55                   	push   %ebp
    9676:	89 e5                	mov    %esp,%ebp

	__asm__ __volatile__("" ::: "memory");
	return;
    9678:	90                   	nop
}
    9679:	5d                   	pop    %ebp
    967a:	c3                   	ret    

0000967b <ck_pr_fence_load_depends>:

/*
 * None of the currently supported platforms allow for data-dependent
 * load ordering.
 */
CK_PR_FENCE_NOOP(load_depends)
    967b:	55                   	push   %ebp
    967c:	89 e5                	mov    %esp,%ebp
    967e:	e8 f2 ff ff ff       	call   9675 <ck_pr_barrier>
    9683:	90                   	nop
    9684:	5d                   	pop    %ebp
    9685:	c3                   	ret    

00009686 <ck_pr_fence_atomic>:
#elif defined(CK_MD_TSO)
/*
 * Only loads are re-ordered and only with respect to
 * prior stores. Atomic operations are serializing.
 */
CK_PR_FENCE_NOOP(atomic)
    9686:	55                   	push   %ebp
    9687:	89 e5                	mov    %esp,%ebp
    9689:	e8 e7 ff ff ff       	call   9675 <ck_pr_barrier>
    968e:	90                   	nop
    968f:	5d                   	pop    %ebp
    9690:	c3                   	ret    

00009691 <ck_pr_fence_atomic_load>:
CK_PR_FENCE_NOOP(atomic_load)
    9691:	55                   	push   %ebp
    9692:	89 e5                	mov    %esp,%ebp
    9694:	e8 dc ff ff ff       	call   9675 <ck_pr_barrier>
    9699:	90                   	nop
    969a:	5d                   	pop    %ebp
    969b:	c3                   	ret    

0000969c <ck_pr_fence_atomic_store>:
CK_PR_FENCE_NOOP(atomic_store)
    969c:	55                   	push   %ebp
    969d:	89 e5                	mov    %esp,%ebp
    969f:	e8 d1 ff ff ff       	call   9675 <ck_pr_barrier>
    96a4:	90                   	nop
    96a5:	5d                   	pop    %ebp
    96a6:	c3                   	ret    

000096a7 <ck_pr_fence_store_atomic>:
CK_PR_FENCE_NOOP(store_atomic)
    96a7:	55                   	push   %ebp
    96a8:	89 e5                	mov    %esp,%ebp
    96aa:	e8 c6 ff ff ff       	call   9675 <ck_pr_barrier>
    96af:	90                   	nop
    96b0:	5d                   	pop    %ebp
    96b1:	c3                   	ret    

000096b2 <ck_pr_fence_load_atomic>:
CK_PR_FENCE_NOOP(load_atomic)
    96b2:	55                   	push   %ebp
    96b3:	89 e5                	mov    %esp,%ebp
    96b5:	e8 bb ff ff ff       	call   9675 <ck_pr_barrier>
    96ba:	90                   	nop
    96bb:	5d                   	pop    %ebp
    96bc:	c3                   	ret    

000096bd <ck_pr_fence_load_store>:
CK_PR_FENCE_NOOP(load_store)
    96bd:	55                   	push   %ebp
    96be:	89 e5                	mov    %esp,%ebp
    96c0:	e8 b0 ff ff ff       	call   9675 <ck_pr_barrier>
    96c5:	90                   	nop
    96c6:	5d                   	pop    %ebp
    96c7:	c3                   	ret    

000096c8 <ck_pr_fence_store_load>:
CK_PR_FENCE_EMIT(store_load)
    96c8:	55                   	push   %ebp
    96c9:	89 e5                	mov    %esp,%ebp
    96cb:	e8 d4 f1 ff ff       	call   88a4 <ck_pr_fence_strict_store_load>
    96d0:	90                   	nop
    96d1:	5d                   	pop    %ebp
    96d2:	c3                   	ret    

000096d3 <ck_pr_fence_load>:
CK_PR_FENCE_NOOP(load)
    96d3:	55                   	push   %ebp
    96d4:	89 e5                	mov    %esp,%ebp
    96d6:	e8 9a ff ff ff       	call   9675 <ck_pr_barrier>
    96db:	90                   	nop
    96dc:	5d                   	pop    %ebp
    96dd:	c3                   	ret    

000096de <ck_pr_fence_store>:
CK_PR_FENCE_NOOP(store)
    96de:	55                   	push   %ebp
    96df:	89 e5                	mov    %esp,%ebp
    96e1:	e8 8f ff ff ff       	call   9675 <ck_pr_barrier>
    96e6:	90                   	nop
    96e7:	5d                   	pop    %ebp
    96e8:	c3                   	ret    

000096e9 <ck_pr_fence_memory>:
CK_PR_FENCE_EMIT(memory)
    96e9:	55                   	push   %ebp
    96ea:	89 e5                	mov    %esp,%ebp
    96ec:	e8 bc f1 ff ff       	call   88ad <ck_pr_fence_strict_memory>
    96f1:	90                   	nop
    96f2:	5d                   	pop    %ebp
    96f3:	c3                   	ret    

000096f4 <ck_pr_fence_acquire>:
CK_PR_FENCE_NOOP(acquire)
    96f4:	55                   	push   %ebp
    96f5:	89 e5                	mov    %esp,%ebp
    96f7:	e8 79 ff ff ff       	call   9675 <ck_pr_barrier>
    96fc:	90                   	nop
    96fd:	5d                   	pop    %ebp
    96fe:	c3                   	ret    

000096ff <ck_pr_fence_release>:
CK_PR_FENCE_NOOP(release)
    96ff:	55                   	push   %ebp
    9700:	89 e5                	mov    %esp,%ebp
    9702:	e8 6e ff ff ff       	call   9675 <ck_pr_barrier>
    9707:	90                   	nop
    9708:	5d                   	pop    %ebp
    9709:	c3                   	ret    

0000970a <ck_pr_fence_acqrel>:
CK_PR_FENCE_NOOP(acqrel)
    970a:	55                   	push   %ebp
    970b:	89 e5                	mov    %esp,%ebp
    970d:	e8 63 ff ff ff       	call   9675 <ck_pr_barrier>
    9712:	90                   	nop
    9713:	5d                   	pop    %ebp
    9714:	c3                   	ret    

00009715 <ck_pr_fence_lock>:
CK_PR_FENCE_NOOP(lock)
    9715:	55                   	push   %ebp
    9716:	89 e5                	mov    %esp,%ebp
    9718:	e8 58 ff ff ff       	call   9675 <ck_pr_barrier>
    971d:	90                   	nop
    971e:	5d                   	pop    %ebp
    971f:	c3                   	ret    

00009720 <ck_pr_fence_unlock>:
CK_PR_FENCE_NOOP(unlock)
    9720:	55                   	push   %ebp
    9721:	89 e5                	mov    %esp,%ebp
    9723:	e8 4d ff ff ff       	call   9675 <ck_pr_barrier>
    9728:	90                   	nop
    9729:	5d                   	pop    %ebp
    972a:	c3                   	ret    

0000972b <ck_pr_rfo>:

#ifndef CK_F_PR_RFO
#define CK_F_PR_RFO
CK_CC_INLINE static void
ck_pr_rfo(const void *m)
{
    972b:	55                   	push   %ebp
    972c:	89 e5                	mov    %esp,%ebp

	(void)m;
	return;
    972e:	90                   	nop
}
    972f:	5d                   	pop    %ebp
    9730:	c3                   	ret    

00009731 <ck_ring_size>:
};
typedef struct ck_ring_buffer ck_ring_buffer_t;

CK_CC_INLINE static unsigned int
ck_ring_size(const struct ck_ring *ring)
{
    9731:	55                   	push   %ebp
    9732:	89 e5                	mov    %esp,%ebp
    9734:	83 ec 14             	sub    $0x14,%esp
	unsigned int c, p;

	c = ck_pr_load_uint(&ring->c_head);
    9737:	8b 45 08             	mov    0x8(%ebp),%eax
    973a:	89 04 24             	mov    %eax,(%esp)
    973d:	e8 86 f2 ff ff       	call   89c8 <ck_pr_md_load_uint>
    9742:	89 45 fc             	mov    %eax,-0x4(%ebp)
	p = ck_pr_load_uint(&ring->p_tail);
    9745:	8b 45 08             	mov    0x8(%ebp),%eax
    9748:	83 c0 40             	add    $0x40,%eax
    974b:	89 04 24             	mov    %eax,(%esp)
    974e:	e8 75 f2 ff ff       	call   89c8 <ck_pr_md_load_uint>
    9753:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return (p - c) & ring->mask;
    9756:	8b 45 fc             	mov    -0x4(%ebp),%eax
    9759:	8b 55 f8             	mov    -0x8(%ebp),%edx
    975c:	29 c2                	sub    %eax,%edx
    975e:	8b 45 08             	mov    0x8(%ebp),%eax
    9761:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    9767:	21 d0                	and    %edx,%eax
}
    9769:	c9                   	leave  
    976a:	c3                   	ret    

0000976b <ck_ring_capacity>:

CK_CC_INLINE static unsigned int
ck_ring_capacity(const struct ck_ring *ring)
{
    976b:	55                   	push   %ebp
    976c:	89 e5                	mov    %esp,%ebp
	return ring->size;
    976e:	8b 45 08             	mov    0x8(%ebp),%eax
    9771:	8b 80 80 00 00 00    	mov    0x80(%eax),%eax
}
    9777:	5d                   	pop    %ebp
    9778:	c3                   	ret    

00009779 <ck_ring_init>:

CK_CC_INLINE static void
ck_ring_init(struct ck_ring *ring, unsigned int size)
{
    9779:	55                   	push   %ebp
    977a:	89 e5                	mov    %esp,%ebp

	ring->size = size;
    977c:	8b 45 08             	mov    0x8(%ebp),%eax
    977f:	8b 55 0c             	mov    0xc(%ebp),%edx
    9782:	89 90 80 00 00 00    	mov    %edx,0x80(%eax)
	ring->mask = size - 1;
    9788:	8b 45 0c             	mov    0xc(%ebp),%eax
    978b:	8d 50 ff             	lea    -0x1(%eax),%edx
    978e:	8b 45 08             	mov    0x8(%ebp),%eax
    9791:	89 90 84 00 00 00    	mov    %edx,0x84(%eax)
	ring->p_tail = 0;
    9797:	8b 45 08             	mov    0x8(%ebp),%eax
    979a:	c7 40 40 00 00 00 00 	movl   $0x0,0x40(%eax)
	ring->p_head = 0;
    97a1:	8b 45 08             	mov    0x8(%ebp),%eax
    97a4:	c7 40 44 00 00 00 00 	movl   $0x0,0x44(%eax)
	ring->c_head = 0;
    97ab:	8b 45 08             	mov    0x8(%ebp),%eax
    97ae:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
	return;
    97b4:	90                   	nop
}
    97b5:	5d                   	pop    %ebp
    97b6:	c3                   	ret    

000097b7 <ck_ring_enqueue_spsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
    97b7:	55                   	push   %ebp
    97b8:	89 e5                	mov    %esp,%ebp
    97ba:	83 ec 58             	sub    $0x58,%esp
    97bd:	8b 45 08             	mov    0x8(%ebp),%eax
    97c0:	89 45 f4             	mov    %eax,-0xc(%ebp)
    97c3:	8b 45 0c             	mov    0xc(%ebp),%eax
    97c6:	89 45 f0             	mov    %eax,-0x10(%ebp)
    97c9:	8d 45 10             	lea    0x10(%ebp),%eax
    97cc:	89 45 ec             	mov    %eax,-0x14(%ebp)
    97cf:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    97d6:	8b 45 14             	mov    0x14(%ebp),%eax
    97d9:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    97dc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    97df:	89 45 e0             	mov    %eax,-0x20(%ebp)
    97e2:	8b 45 f0             	mov    -0x10(%ebp),%eax
    97e5:	89 45 dc             	mov    %eax,-0x24(%ebp)
    97e8:	8b 45 ec             	mov    -0x14(%ebp),%eax
    97eb:	89 45 d8             	mov    %eax,-0x28(%ebp)
    97ee:	8b 45 e8             	mov    -0x18(%ebp),%eax
    97f1:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    97f4:	8d 45 b8             	lea    -0x48(%ebp),%eax
    97f7:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    97fa:	8b 45 e0             	mov    -0x20(%ebp),%eax
    97fd:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    9803:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    9806:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9809:	89 04 24             	mov    %eax,(%esp)
    980c:	e8 b7 f1 ff ff       	call   89c8 <ck_pr_md_load_uint>
    9811:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    9814:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9817:	8b 40 40             	mov    0x40(%eax),%eax
    981a:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    981d:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    9820:	83 c0 01             	add    $0x1,%eax
    9823:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    9826:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    982a:	74 14                	je     9840 <ck_ring_enqueue_spsc_size+0x89>
		*size = (producer - consumer) & mask;
    982c:	8b 45 c8             	mov    -0x38(%ebp),%eax
    982f:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    9832:	29 c2                	sub    %eax,%edx
    9834:	89 d0                	mov    %edx,%eax
    9836:	23 45 cc             	and    -0x34(%ebp),%eax
    9839:	89 c2                	mov    %eax,%edx
    983b:	8b 45 d0             	mov    -0x30(%ebp),%eax
    983e:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    9840:	8b 45 c0             	mov    -0x40(%ebp),%eax
    9843:	8b 55 c8             	mov    -0x38(%ebp),%edx
    9846:	31 d0                	xor    %edx,%eax
    9848:	23 45 cc             	and    -0x34(%ebp),%eax
    984b:	85 c0                	test   %eax,%eax
    984d:	0f 94 c0             	sete   %al
    9850:	0f b6 c0             	movzbl %al,%eax
    9853:	85 c0                	test   %eax,%eax
    9855:	74 07                	je     985e <ck_ring_enqueue_spsc_size+0xa7>
		return false;
    9857:	b8 00 00 00 00       	mov    $0x0,%eax
    985c:	eb 47                	jmp    98a5 <ck_ring_enqueue_spsc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    985e:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    9861:	8b 55 cc             	mov    -0x34(%ebp),%edx
    9864:	21 d0                	and    %edx,%eax
    9866:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    986a:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    986d:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    9870:	89 44 24 08          	mov    %eax,0x8(%esp)
    9874:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9877:	89 44 24 04          	mov    %eax,0x4(%esp)
    987b:	8b 45 dc             	mov    -0x24(%ebp),%eax
    987e:	89 04 24             	mov    %eax,(%esp)
    9881:	e8 fc ff ff ff       	call   9882 <ck_ring_enqueue_spsc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    9886:	e8 53 fe ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    988b:	8b 45 e0             	mov    -0x20(%ebp),%eax
    988e:	8d 50 40             	lea    0x40(%eax),%edx
    9891:	8b 45 c0             	mov    -0x40(%ebp),%eax
    9894:	89 44 24 04          	mov    %eax,0x4(%esp)
    9898:	89 14 24             	mov    %edx,(%esp)
    989b:	e8 b1 f1 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    98a0:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    98a5:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    98a8:	8b 55 b8             	mov    -0x48(%ebp),%edx
    98ab:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    98ae:	89 10                	mov    %edx,(%eax)
	return r;
    98b0:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
    98b4:	c9                   	leave  
    98b5:	c3                   	ret    

000098b6 <ck_ring_enqueue_spsc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
    98b6:	55                   	push   %ebp
    98b7:	89 e5                	mov    %esp,%ebp
    98b9:	83 ec 48             	sub    $0x48,%esp
    98bc:	8b 45 08             	mov    0x8(%ebp),%eax
    98bf:	89 45 f4             	mov    %eax,-0xc(%ebp)
    98c2:	8b 45 0c             	mov    0xc(%ebp),%eax
    98c5:	89 45 f0             	mov    %eax,-0x10(%ebp)
    98c8:	8d 45 10             	lea    0x10(%ebp),%eax
    98cb:	89 45 ec             	mov    %eax,-0x14(%ebp)
    98ce:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    98d5:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    98dc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    98df:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    98e5:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    98e8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    98eb:	89 04 24             	mov    %eax,(%esp)
    98ee:	e8 d5 f0 ff ff       	call   89c8 <ck_pr_md_load_uint>
    98f3:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    98f6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    98f9:	8b 40 40             	mov    0x40(%eax),%eax
    98fc:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    98ff:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9902:	83 c0 01             	add    $0x1,%eax
    9905:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    9908:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    990c:	74 14                	je     9922 <ck_ring_enqueue_spsc+0x6c>
		*size = (producer - consumer) & mask;
    990e:	8b 45 dc             	mov    -0x24(%ebp),%eax
    9911:	8b 55 d8             	mov    -0x28(%ebp),%edx
    9914:	29 c2                	sub    %eax,%edx
    9916:	89 d0                	mov    %edx,%eax
    9918:	23 45 e0             	and    -0x20(%ebp),%eax
    991b:	89 c2                	mov    %eax,%edx
    991d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    9920:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    9922:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    9925:	8b 55 dc             	mov    -0x24(%ebp),%edx
    9928:	31 d0                	xor    %edx,%eax
    992a:	23 45 e0             	and    -0x20(%ebp),%eax
    992d:	85 c0                	test   %eax,%eax
    992f:	0f 94 c0             	sete   %al
    9932:	0f b6 c0             	movzbl %al,%eax
    9935:	85 c0                	test   %eax,%eax
    9937:	74 07                	je     9940 <ck_ring_enqueue_spsc+0x8a>
		return false;
    9939:	b8 00 00 00 00       	mov    $0x0,%eax
    993e:	eb 47                	jmp    9987 <ck_ring_enqueue_spsc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    9940:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9943:	8b 55 e0             	mov    -0x20(%ebp),%edx
    9946:	21 d0                	and    %edx,%eax
    9948:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    994c:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    994f:	8b 45 e8             	mov    -0x18(%ebp),%eax
    9952:	89 44 24 08          	mov    %eax,0x8(%esp)
    9956:	8b 45 ec             	mov    -0x14(%ebp),%eax
    9959:	89 44 24 04          	mov    %eax,0x4(%esp)
    995d:	8b 45 f0             	mov    -0x10(%ebp),%eax
    9960:	89 04 24             	mov    %eax,(%esp)
    9963:	e8 fc ff ff ff       	call   9964 <ck_ring_enqueue_spsc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    9968:	e8 71 fd ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    996d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9970:	8d 50 40             	lea    0x40(%eax),%edx
    9973:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    9976:	89 44 24 04          	mov    %eax,0x4(%esp)
    997a:	89 14 24             	mov    %edx,(%esp)
    997d:	e8 cf f0 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    9982:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer,
	    &entry, sizeof(entry), NULL);
}
    9987:	c9                   	leave  
    9988:	c3                   	ret    

00009989 <ck_ring_dequeue_spsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    9989:	55                   	push   %ebp
    998a:	89 e5                	mov    %esp,%ebp
    998c:	83 ec 38             	sub    $0x38,%esp
    998f:	8b 45 08             	mov    0x8(%ebp),%eax
    9992:	89 45 f4             	mov    %eax,-0xc(%ebp)
    9995:	8b 45 0c             	mov    0xc(%ebp),%eax
    9998:	89 45 f0             	mov    %eax,-0x10(%ebp)
    999b:	8b 45 10             	mov    0x10(%ebp),%eax
    999e:	89 45 ec             	mov    %eax,-0x14(%ebp)
    99a1:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    99a8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    99ab:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    99b1:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    99b4:	8b 45 f4             	mov    -0xc(%ebp),%eax
    99b7:	8b 00                	mov    (%eax),%eax
    99b9:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    99bc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    99bf:	83 c0 40             	add    $0x40,%eax
    99c2:	89 04 24             	mov    %eax,(%esp)
    99c5:	e8 fe ef ff ff       	call   89c8 <ck_pr_md_load_uint>
    99ca:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    99cd:	8b 45 e0             	mov    -0x20(%ebp),%eax
    99d0:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    99d3:	0f 94 c0             	sete   %al
    99d6:	0f b6 c0             	movzbl %al,%eax
    99d9:	85 c0                	test   %eax,%eax
    99db:	74 07                	je     99e4 <ck_ring_dequeue_spsc+0x5b>
		return false;
    99dd:	b8 00 00 00 00       	mov    $0x0,%eax
    99e2:	eb 4c                	jmp    9a30 <ck_ring_dequeue_spsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    99e4:	e8 ea fc ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    99e9:	8b 45 e0             	mov    -0x20(%ebp),%eax
    99ec:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    99ef:	21 d0                	and    %edx,%eax
    99f1:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    99f5:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    99f8:	8b 45 e8             	mov    -0x18(%ebp),%eax
    99fb:	89 44 24 08          	mov    %eax,0x8(%esp)
    99ff:	8b 45 f0             	mov    -0x10(%ebp),%eax
    9a02:	89 44 24 04          	mov    %eax,0x4(%esp)
    9a06:	8b 45 ec             	mov    -0x14(%ebp),%eax
    9a09:	89 04 24             	mov    %eax,(%esp)
    9a0c:	e8 fc ff ff ff       	call   9a0d <ck_ring_dequeue_spsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    9a11:	e8 c8 fc ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    9a16:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9a19:	8d 50 01             	lea    0x1(%eax),%edx
    9a1c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9a1f:	89 54 24 04          	mov    %edx,0x4(%esp)
    9a23:	89 04 24             	mov    %eax,(%esp)
    9a26:	e8 26 f0 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    9a2b:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer,
	    (void **)data, sizeof(void *));
}
    9a30:	c9                   	leave  
    9a31:	c3                   	ret    

00009a32 <ck_ring_enqueue_mpmc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
    9a32:	55                   	push   %ebp
    9a33:	89 e5                	mov    %esp,%ebp
    9a35:	83 ec 48             	sub    $0x48,%esp
    9a38:	8b 45 08             	mov    0x8(%ebp),%eax
    9a3b:	89 45 f4             	mov    %eax,-0xc(%ebp)
    9a3e:	8b 45 0c             	mov    0xc(%ebp),%eax
    9a41:	89 45 f0             	mov    %eax,-0x10(%ebp)
    9a44:	8d 45 10             	lea    0x10(%ebp),%eax
    9a47:	89 45 ec             	mov    %eax,-0x14(%ebp)
    9a4a:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    9a51:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    9a58:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9a5b:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    9a61:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    9a64:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    9a68:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9a6b:	83 c0 44             	add    $0x44,%eax
    9a6e:	89 04 24             	mov    %eax,(%esp)
    9a71:	e8 52 ef ff ff       	call   89c8 <ck_pr_md_load_uint>
    9a76:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    9a79:	e8 55 fc ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    9a7e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9a81:	89 04 24             	mov    %eax,(%esp)
    9a84:	e8 3f ef ff ff       	call   89c8 <ck_pr_md_load_uint>
    9a89:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    9a8c:	8b 45 cc             	mov    -0x34(%ebp),%eax
    9a8f:	83 c0 01             	add    $0x1,%eax
    9a92:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    9a95:	8b 45 cc             	mov    -0x34(%ebp),%eax
    9a98:	2b 45 d8             	sub    -0x28(%ebp),%eax
    9a9b:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    9a9e:	0f 97 c0             	seta   %al
    9aa1:	0f b6 c0             	movzbl %al,%eax
    9aa4:	85 c0                	test   %eax,%eax
    9aa6:	74 29                	je     9ad1 <ck_ring_enqueue_mpmc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    9aa8:	8b 45 cc             	mov    -0x34(%ebp),%eax
    9aab:	8b 55 f4             	mov    -0xc(%ebp),%edx
    9aae:	8d 4a 44             	lea    0x44(%edx),%ecx
    9ab1:	8d 55 cc             	lea    -0x34(%ebp),%edx
    9ab4:	89 54 24 0c          	mov    %edx,0xc(%esp)
    9ab8:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    9abb:	89 54 24 08          	mov    %edx,0x8(%esp)
    9abf:	89 44 24 04          	mov    %eax,0x4(%esp)
    9ac3:	89 0c 24             	mov    %ecx,(%esp)
    9ac6:	e8 fe f8 ff ff       	call   93c9 <ck_pr_cas_uint_value>
    9acb:	84 c0                	test   %al,%al
    9acd:	75 31                	jne    9b00 <ck_ring_enqueue_mpmc+0xce>
    9acf:	eb a8                	jmp    9a79 <ck_ring_enqueue_mpmc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    9ad1:	e8 fd fb ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    9ad6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9ad9:	83 c0 44             	add    $0x44,%eax
    9adc:	89 04 24             	mov    %eax,(%esp)
    9adf:	e8 e4 ee ff ff       	call   89c8 <ck_pr_md_load_uint>
    9ae4:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    9ae7:	8b 45 cc             	mov    -0x34(%ebp),%eax
    9aea:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    9aed:	75 06                	jne    9af5 <ck_ring_enqueue_mpmc+0xc3>
				r = false;
    9aef:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    9af3:	eb 67                	jmp    9b5c <ck_ring_enqueue_mpmc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    9af5:	8b 45 d0             	mov    -0x30(%ebp),%eax
    9af8:	89 45 cc             	mov    %eax,-0x34(%ebp)
    9afb:	e9 79 ff ff ff       	jmp    9a79 <ck_ring_enqueue_mpmc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    9b00:	8b 45 cc             	mov    -0x34(%ebp),%eax
    9b03:	23 45 e0             	and    -0x20(%ebp),%eax
    9b06:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    9b0a:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    9b0d:	8b 45 e8             	mov    -0x18(%ebp),%eax
    9b10:	89 44 24 08          	mov    %eax,0x8(%esp)
    9b14:	8b 45 ec             	mov    -0x14(%ebp),%eax
    9b17:	89 44 24 04          	mov    %eax,0x4(%esp)
    9b1b:	8b 45 f0             	mov    -0x10(%ebp),%eax
    9b1e:	89 04 24             	mov    %eax,(%esp)
    9b21:	e8 fc ff ff ff       	call   9b22 <ck_ring_enqueue_mpmc+0xf0>
    9b26:	eb 05                	jmp    9b2d <ck_ring_enqueue_mpmc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    9b28:	e8 36 ed ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    9b2d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9b30:	83 c0 40             	add    $0x40,%eax
    9b33:	89 04 24             	mov    %eax,(%esp)
    9b36:	e8 8d ee ff ff       	call   89c8 <ck_pr_md_load_uint>
    9b3b:	8b 55 cc             	mov    -0x34(%ebp),%edx
    9b3e:	39 d0                	cmp    %edx,%eax
    9b40:	75 e6                	jne    9b28 <ck_ring_enqueue_mpmc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    9b42:	e8 97 fb ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    9b47:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9b4a:	8d 50 40             	lea    0x40(%eax),%edx
    9b4d:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    9b50:	89 44 24 04          	mov    %eax,0x4(%esp)
    9b54:	89 14 24             	mov    %edx,(%esp)
    9b57:	e8 f5 ee ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    9b5c:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    9b60:	74 10                	je     9b72 <ck_ring_enqueue_mpmc+0x140>
		*size = (producer - consumer) & mask;
    9b62:	8b 45 cc             	mov    -0x34(%ebp),%eax
    9b65:	2b 45 d8             	sub    -0x28(%ebp),%eax
    9b68:	23 45 e0             	and    -0x20(%ebp),%eax
    9b6b:	89 c2                	mov    %eax,%edx
    9b6d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    9b70:	89 10                	mov    %edx,(%eax)

	return r;
    9b72:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
    9b76:	c9                   	leave  
    9b77:	c3                   	ret    

00009b78 <ck_ring_enqueue_mpmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
    9b78:	55                   	push   %ebp
    9b79:	89 e5                	mov    %esp,%ebp
    9b7b:	83 ec 68             	sub    $0x68,%esp
    9b7e:	8b 45 08             	mov    0x8(%ebp),%eax
    9b81:	89 45 f4             	mov    %eax,-0xc(%ebp)
    9b84:	8b 45 0c             	mov    0xc(%ebp),%eax
    9b87:	89 45 f0             	mov    %eax,-0x10(%ebp)
    9b8a:	8d 45 10             	lea    0x10(%ebp),%eax
    9b8d:	89 45 ec             	mov    %eax,-0x14(%ebp)
    9b90:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    9b97:	8b 45 14             	mov    0x14(%ebp),%eax
    9b9a:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    9b9d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9ba0:	89 45 e0             	mov    %eax,-0x20(%ebp)
    9ba3:	8b 45 f0             	mov    -0x10(%ebp),%eax
    9ba6:	89 45 dc             	mov    %eax,-0x24(%ebp)
    9ba9:	8b 45 ec             	mov    -0x14(%ebp),%eax
    9bac:	89 45 d8             	mov    %eax,-0x28(%ebp)
    9baf:	8b 45 e8             	mov    -0x18(%ebp),%eax
    9bb2:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    9bb5:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    9bb8:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    9bbb:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9bbe:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    9bc4:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    9bc7:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    9bcb:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9bce:	83 c0 44             	add    $0x44,%eax
    9bd1:	89 04 24             	mov    %eax,(%esp)
    9bd4:	e8 ef ed ff ff       	call   89c8 <ck_pr_md_load_uint>
    9bd9:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    9bdc:	e8 f2 fa ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    9be1:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9be4:	89 04 24             	mov    %eax,(%esp)
    9be7:	e8 dc ed ff ff       	call   89c8 <ck_pr_md_load_uint>
    9bec:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    9bef:	8b 45 b0             	mov    -0x50(%ebp),%eax
    9bf2:	83 c0 01             	add    $0x1,%eax
    9bf5:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    9bf8:	8b 45 b0             	mov    -0x50(%ebp),%eax
    9bfb:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    9bfe:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    9c01:	0f 97 c0             	seta   %al
    9c04:	0f b6 c0             	movzbl %al,%eax
    9c07:	85 c0                	test   %eax,%eax
    9c09:	74 29                	je     9c34 <ck_ring_enqueue_mpmc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    9c0b:	8b 45 b0             	mov    -0x50(%ebp),%eax
    9c0e:	8b 55 e0             	mov    -0x20(%ebp),%edx
    9c11:	8d 4a 44             	lea    0x44(%edx),%ecx
    9c14:	8d 55 b0             	lea    -0x50(%ebp),%edx
    9c17:	89 54 24 0c          	mov    %edx,0xc(%esp)
    9c1b:	8b 55 c0             	mov    -0x40(%ebp),%edx
    9c1e:	89 54 24 08          	mov    %edx,0x8(%esp)
    9c22:	89 44 24 04          	mov    %eax,0x4(%esp)
    9c26:	89 0c 24             	mov    %ecx,(%esp)
    9c29:	e8 9b f7 ff ff       	call   93c9 <ck_pr_cas_uint_value>
    9c2e:	84 c0                	test   %al,%al
    9c30:	75 31                	jne    9c63 <ck_ring_enqueue_mpmc_size+0xeb>
    9c32:	eb a8                	jmp    9bdc <ck_ring_enqueue_mpmc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    9c34:	e8 9a fa ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    9c39:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9c3c:	83 c0 44             	add    $0x44,%eax
    9c3f:	89 04 24             	mov    %eax,(%esp)
    9c42:	e8 81 ed ff ff       	call   89c8 <ck_pr_md_load_uint>
    9c47:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    9c4a:	8b 45 b0             	mov    -0x50(%ebp),%eax
    9c4d:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    9c50:	75 06                	jne    9c58 <ck_ring_enqueue_mpmc_size+0xe0>
				r = false;
    9c52:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    9c56:	eb 67                	jmp    9cbf <ck_ring_enqueue_mpmc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    9c58:	8b 45 bc             	mov    -0x44(%ebp),%eax
    9c5b:	89 45 b0             	mov    %eax,-0x50(%ebp)
    9c5e:	e9 79 ff ff ff       	jmp    9bdc <ck_ring_enqueue_mpmc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    9c63:	8b 45 b0             	mov    -0x50(%ebp),%eax
    9c66:	23 45 cc             	and    -0x34(%ebp),%eax
    9c69:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    9c6d:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    9c70:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    9c73:	89 44 24 08          	mov    %eax,0x8(%esp)
    9c77:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9c7a:	89 44 24 04          	mov    %eax,0x4(%esp)
    9c7e:	8b 45 dc             	mov    -0x24(%ebp),%eax
    9c81:	89 04 24             	mov    %eax,(%esp)
    9c84:	e8 fc ff ff ff       	call   9c85 <ck_ring_enqueue_mpmc_size+0x10d>
    9c89:	eb 05                	jmp    9c90 <ck_ring_enqueue_mpmc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    9c8b:	e8 d3 eb ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    9c90:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9c93:	83 c0 40             	add    $0x40,%eax
    9c96:	89 04 24             	mov    %eax,(%esp)
    9c99:	e8 2a ed ff ff       	call   89c8 <ck_pr_md_load_uint>
    9c9e:	8b 55 b0             	mov    -0x50(%ebp),%edx
    9ca1:	39 d0                	cmp    %edx,%eax
    9ca3:	75 e6                	jne    9c8b <ck_ring_enqueue_mpmc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    9ca5:	e8 34 fa ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    9caa:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9cad:	8d 50 40             	lea    0x40(%eax),%edx
    9cb0:	8b 45 c0             	mov    -0x40(%ebp),%eax
    9cb3:	89 44 24 04          	mov    %eax,0x4(%esp)
    9cb7:	89 14 24             	mov    %edx,(%esp)
    9cba:	e8 92 ed ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    9cbf:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    9cc3:	74 10                	je     9cd5 <ck_ring_enqueue_mpmc_size+0x15d>
		*size = (producer - consumer) & mask;
    9cc5:	8b 45 b0             	mov    -0x50(%ebp),%eax
    9cc8:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    9ccb:	23 45 cc             	and    -0x34(%ebp),%eax
    9cce:	89 c2                	mov    %eax,%edx
    9cd0:	8b 45 d0             	mov    -0x30(%ebp),%eax
    9cd3:	89 10                	mov    %edx,(%eax)

	return r;
    9cd5:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    9cd9:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    9cdc:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    9cdf:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    9ce2:	89 10                	mov    %edx,(%eax)
	return r;
    9ce4:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
    9ce8:	c9                   	leave  
    9ce9:	c3                   	ret    

00009cea <ck_ring_trydequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    9cea:	55                   	push   %ebp
    9ceb:	89 e5                	mov    %esp,%ebp
    9ced:	83 ec 38             	sub    $0x38,%esp
    9cf0:	8b 45 08             	mov    0x8(%ebp),%eax
    9cf3:	89 45 f4             	mov    %eax,-0xc(%ebp)
    9cf6:	8b 45 0c             	mov    0xc(%ebp),%eax
    9cf9:	89 45 f0             	mov    %eax,-0x10(%ebp)
    9cfc:	8b 45 10             	mov    0x10(%ebp),%eax
    9cff:	89 45 ec             	mov    %eax,-0x14(%ebp)
    9d02:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    9d09:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9d0c:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    9d12:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    9d15:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9d18:	89 04 24             	mov    %eax,(%esp)
    9d1b:	e8 a8 ec ff ff       	call   89c8 <ck_pr_md_load_uint>
    9d20:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    9d23:	e8 ab f9 ff ff       	call   96d3 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    9d28:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9d2b:	83 c0 40             	add    $0x40,%eax
    9d2e:	89 04 24             	mov    %eax,(%esp)
    9d31:	e8 92 ec ff ff       	call   89c8 <ck_pr_md_load_uint>
    9d36:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    9d39:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9d3c:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    9d3f:	0f 94 c0             	sete   %al
    9d42:	0f b6 c0             	movzbl %al,%eax
    9d45:	85 c0                	test   %eax,%eax
    9d47:	74 07                	je     9d50 <ck_ring_trydequeue_mpmc+0x66>
		return false;
    9d49:	b8 00 00 00 00       	mov    $0x0,%eax
    9d4e:	eb 4e                	jmp    9d9e <ck_ring_trydequeue_mpmc+0xb4>

	ck_pr_fence_load();
    9d50:	e8 7e f9 ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    9d55:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9d58:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    9d5b:	21 d0                	and    %edx,%eax
    9d5d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    9d61:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    9d64:	8b 45 e8             	mov    -0x18(%ebp),%eax
    9d67:	89 44 24 08          	mov    %eax,0x8(%esp)
    9d6b:	8b 45 f0             	mov    -0x10(%ebp),%eax
    9d6e:	89 44 24 04          	mov    %eax,0x4(%esp)
    9d72:	8b 45 ec             	mov    -0x14(%ebp),%eax
    9d75:	89 04 24             	mov    %eax,(%esp)
    9d78:	e8 fc ff ff ff       	call   9d79 <ck_ring_trydequeue_mpmc+0x8f>

	ck_pr_fence_store_atomic();
    9d7d:	e8 25 f9 ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    9d82:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9d85:	8d 50 01             	lea    0x1(%eax),%edx
    9d88:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9d8b:	89 54 24 08          	mov    %edx,0x8(%esp)
    9d8f:	8b 55 e0             	mov    -0x20(%ebp),%edx
    9d92:	89 54 24 04          	mov    %edx,0x4(%esp)
    9d96:	89 04 24             	mov    %eax,(%esp)
    9d99:	e8 d8 f4 ff ff       	call   9276 <ck_pr_cas_uint>
    void *data)
{

	return _ck_ring_trydequeue_mc(ring,
	    buffer, (void **)data, sizeof(void *));
}
    9d9e:	c9                   	leave  
    9d9f:	c3                   	ret    

00009da0 <ck_ring_dequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    9da0:	55                   	push   %ebp
    9da1:	89 e5                	mov    %esp,%ebp
    9da3:	53                   	push   %ebx
    9da4:	83 ec 34             	sub    $0x34,%esp
    9da7:	8b 45 08             	mov    0x8(%ebp),%eax
    9daa:	89 45 f4             	mov    %eax,-0xc(%ebp)
    9dad:	8b 45 0c             	mov    0xc(%ebp),%eax
    9db0:	89 45 f0             	mov    %eax,-0x10(%ebp)
    9db3:	8b 45 10             	mov    0x10(%ebp),%eax
    9db6:	89 45 ec             	mov    %eax,-0x14(%ebp)
    9db9:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    9dc0:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9dc3:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    9dc9:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    9dcc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9dcf:	89 04 24             	mov    %eax,(%esp)
    9dd2:	e8 f1 eb ff ff       	call   89c8 <ck_pr_md_load_uint>
    9dd7:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    9dda:	e8 f4 f8 ff ff       	call   96d3 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    9ddf:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9de2:	83 c0 40             	add    $0x40,%eax
    9de5:	89 04 24             	mov    %eax,(%esp)
    9de8:	e8 db eb ff ff       	call   89c8 <ck_pr_md_load_uint>
    9ded:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    9df0:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9df3:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    9df6:	0f 94 c0             	sete   %al
    9df9:	0f b6 c0             	movzbl %al,%eax
    9dfc:	85 c0                	test   %eax,%eax
    9dfe:	74 07                	je     9e07 <ck_ring_dequeue_mpmc+0x67>
			return false;
    9e00:	b8 00 00 00 00       	mov    $0x0,%eax
    9e05:	eb 6a                	jmp    9e71 <ck_ring_dequeue_mpmc+0xd1>

		ck_pr_fence_load();
    9e07:	e8 c7 f8 ff ff       	call   96d3 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    9e0c:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9e0f:	23 45 e4             	and    -0x1c(%ebp),%eax
    9e12:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    9e16:	89 c2                	mov    %eax,%edx
    9e18:	8b 45 f0             	mov    -0x10(%ebp),%eax
    9e1b:	01 d0                	add    %edx,%eax
    9e1d:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    9e20:	8b 45 e8             	mov    -0x18(%ebp),%eax
    9e23:	89 44 24 08          	mov    %eax,0x8(%esp)
    9e27:	8b 45 dc             	mov    -0x24(%ebp),%eax
    9e2a:	89 44 24 04          	mov    %eax,0x4(%esp)
    9e2e:	8b 45 ec             	mov    -0x14(%ebp),%eax
    9e31:	89 04 24             	mov    %eax,(%esp)
    9e34:	e8 fc ff ff ff       	call   9e35 <ck_ring_dequeue_mpmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    9e39:	e8 69 f8 ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    9e3e:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9e41:	8d 58 01             	lea    0x1(%eax),%ebx
    9e44:	8b 55 d8             	mov    -0x28(%ebp),%edx
    9e47:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9e4a:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    9e4d:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    9e51:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    9e55:	89 54 24 04          	mov    %edx,0x4(%esp)
    9e59:	89 04 24             	mov    %eax,(%esp)
    9e5c:	e8 68 f5 ff ff       	call   93c9 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    9e61:	83 f0 01             	xor    $0x1,%eax
    9e64:	84 c0                	test   %al,%al
    9e66:	0f 85 6e ff ff ff    	jne    9dda <ck_ring_dequeue_mpmc+0x3a>

	return true;
    9e6c:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data,
	    sizeof(void *));
}
    9e71:	83 c4 34             	add    $0x34,%esp
    9e74:	5b                   	pop    %ebx
    9e75:	5d                   	pop    %ebp
    9e76:	c3                   	ret    

00009e77 <ck_ring_enqueue_spmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
    9e77:	55                   	push   %ebp
    9e78:	89 e5                	mov    %esp,%ebp
    9e7a:	83 ec 58             	sub    $0x58,%esp
    9e7d:	8b 45 08             	mov    0x8(%ebp),%eax
    9e80:	89 45 f4             	mov    %eax,-0xc(%ebp)
    9e83:	8b 45 0c             	mov    0xc(%ebp),%eax
    9e86:	89 45 f0             	mov    %eax,-0x10(%ebp)
    9e89:	8d 45 10             	lea    0x10(%ebp),%eax
    9e8c:	89 45 ec             	mov    %eax,-0x14(%ebp)
    9e8f:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    9e96:	8b 45 14             	mov    0x14(%ebp),%eax
    9e99:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    9e9c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9e9f:	89 45 e0             	mov    %eax,-0x20(%ebp)
    9ea2:	8b 45 f0             	mov    -0x10(%ebp),%eax
    9ea5:	89 45 dc             	mov    %eax,-0x24(%ebp)
    9ea8:	8b 45 ec             	mov    -0x14(%ebp),%eax
    9eab:	89 45 d8             	mov    %eax,-0x28(%ebp)
    9eae:	8b 45 e8             	mov    -0x18(%ebp),%eax
    9eb1:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    9eb4:	8d 45 b8             	lea    -0x48(%ebp),%eax
    9eb7:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    9eba:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9ebd:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    9ec3:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    9ec6:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9ec9:	89 04 24             	mov    %eax,(%esp)
    9ecc:	e8 f7 ea ff ff       	call   89c8 <ck_pr_md_load_uint>
    9ed1:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    9ed4:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9ed7:	8b 40 40             	mov    0x40(%eax),%eax
    9eda:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    9edd:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    9ee0:	83 c0 01             	add    $0x1,%eax
    9ee3:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    9ee6:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    9eea:	74 14                	je     9f00 <ck_ring_enqueue_spmc_size+0x89>
		*size = (producer - consumer) & mask;
    9eec:	8b 45 c8             	mov    -0x38(%ebp),%eax
    9eef:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    9ef2:	29 c2                	sub    %eax,%edx
    9ef4:	89 d0                	mov    %edx,%eax
    9ef6:	23 45 cc             	and    -0x34(%ebp),%eax
    9ef9:	89 c2                	mov    %eax,%edx
    9efb:	8b 45 d0             	mov    -0x30(%ebp),%eax
    9efe:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    9f00:	8b 45 c0             	mov    -0x40(%ebp),%eax
    9f03:	8b 55 c8             	mov    -0x38(%ebp),%edx
    9f06:	31 d0                	xor    %edx,%eax
    9f08:	23 45 cc             	and    -0x34(%ebp),%eax
    9f0b:	85 c0                	test   %eax,%eax
    9f0d:	0f 94 c0             	sete   %al
    9f10:	0f b6 c0             	movzbl %al,%eax
    9f13:	85 c0                	test   %eax,%eax
    9f15:	74 07                	je     9f1e <ck_ring_enqueue_spmc_size+0xa7>
		return false;
    9f17:	b8 00 00 00 00       	mov    $0x0,%eax
    9f1c:	eb 47                	jmp    9f65 <ck_ring_enqueue_spmc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    9f1e:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    9f21:	8b 55 cc             	mov    -0x34(%ebp),%edx
    9f24:	21 d0                	and    %edx,%eax
    9f26:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    9f2a:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    9f2d:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    9f30:	89 44 24 08          	mov    %eax,0x8(%esp)
    9f34:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9f37:	89 44 24 04          	mov    %eax,0x4(%esp)
    9f3b:	8b 45 dc             	mov    -0x24(%ebp),%eax
    9f3e:	89 04 24             	mov    %eax,(%esp)
    9f41:	e8 fc ff ff ff       	call   9f42 <ck_ring_enqueue_spmc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    9f46:	e8 93 f7 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    9f4b:	8b 45 e0             	mov    -0x20(%ebp),%eax
    9f4e:	8d 50 40             	lea    0x40(%eax),%edx
    9f51:	8b 45 c0             	mov    -0x40(%ebp),%eax
    9f54:	89 44 24 04          	mov    %eax,0x4(%esp)
    9f58:	89 14 24             	mov    %edx,(%esp)
    9f5b:	e8 f1 ea ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    9f60:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    9f65:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    9f68:	8b 55 b8             	mov    -0x48(%ebp),%edx
    9f6b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    9f6e:	89 10                	mov    %edx,(%eax)
	return r;
    9f70:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
    9f74:	c9                   	leave  
    9f75:	c3                   	ret    

00009f76 <ck_ring_enqueue_spmc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
    9f76:	55                   	push   %ebp
    9f77:	89 e5                	mov    %esp,%ebp
    9f79:	83 ec 48             	sub    $0x48,%esp
    9f7c:	8b 45 08             	mov    0x8(%ebp),%eax
    9f7f:	89 45 f4             	mov    %eax,-0xc(%ebp)
    9f82:	8b 45 0c             	mov    0xc(%ebp),%eax
    9f85:	89 45 f0             	mov    %eax,-0x10(%ebp)
    9f88:	8d 45 10             	lea    0x10(%ebp),%eax
    9f8b:	89 45 ec             	mov    %eax,-0x14(%ebp)
    9f8e:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    9f95:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    9f9c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9f9f:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    9fa5:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    9fa8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9fab:	89 04 24             	mov    %eax,(%esp)
    9fae:	e8 15 ea ff ff       	call   89c8 <ck_pr_md_load_uint>
    9fb3:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    9fb6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    9fb9:	8b 40 40             	mov    0x40(%eax),%eax
    9fbc:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    9fbf:	8b 45 d8             	mov    -0x28(%ebp),%eax
    9fc2:	83 c0 01             	add    $0x1,%eax
    9fc5:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    9fc8:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    9fcc:	74 14                	je     9fe2 <ck_ring_enqueue_spmc+0x6c>
		*size = (producer - consumer) & mask;
    9fce:	8b 45 dc             	mov    -0x24(%ebp),%eax
    9fd1:	8b 55 d8             	mov    -0x28(%ebp),%edx
    9fd4:	29 c2                	sub    %eax,%edx
    9fd6:	89 d0                	mov    %edx,%eax
    9fd8:	23 45 e0             	and    -0x20(%ebp),%eax
    9fdb:	89 c2                	mov    %eax,%edx
    9fdd:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    9fe0:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    9fe2:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    9fe5:	8b 55 dc             	mov    -0x24(%ebp),%edx
    9fe8:	31 d0                	xor    %edx,%eax
    9fea:	23 45 e0             	and    -0x20(%ebp),%eax
    9fed:	85 c0                	test   %eax,%eax
    9fef:	0f 94 c0             	sete   %al
    9ff2:	0f b6 c0             	movzbl %al,%eax
    9ff5:	85 c0                	test   %eax,%eax
    9ff7:	74 07                	je     a000 <ck_ring_enqueue_spmc+0x8a>
		return false;
    9ff9:	b8 00 00 00 00       	mov    $0x0,%eax
    9ffe:	eb 47                	jmp    a047 <ck_ring_enqueue_spmc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    a000:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a003:	8b 55 e0             	mov    -0x20(%ebp),%edx
    a006:	21 d0                	and    %edx,%eax
    a008:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a00c:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    a00f:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a012:	89 44 24 08          	mov    %eax,0x8(%esp)
    a016:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a019:	89 44 24 04          	mov    %eax,0x4(%esp)
    a01d:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a020:	89 04 24             	mov    %eax,(%esp)
    a023:	e8 fc ff ff ff       	call   a024 <ck_ring_enqueue_spmc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    a028:	e8 b1 f6 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    a02d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a030:	8d 50 40             	lea    0x40(%eax),%edx
    a033:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a036:	89 44 24 04          	mov    %eax,0x4(%esp)
    a03a:	89 14 24             	mov    %edx,(%esp)
    a03d:	e8 0f ea ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    a042:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
    a047:	c9                   	leave  
    a048:	c3                   	ret    

0000a049 <ck_ring_trydequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    a049:	55                   	push   %ebp
    a04a:	89 e5                	mov    %esp,%ebp
    a04c:	83 ec 38             	sub    $0x38,%esp
    a04f:	8b 45 08             	mov    0x8(%ebp),%eax
    a052:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a055:	8b 45 0c             	mov    0xc(%ebp),%eax
    a058:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a05b:	8b 45 10             	mov    0x10(%ebp),%eax
    a05e:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a061:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    a068:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a06b:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a071:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    a074:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a077:	89 04 24             	mov    %eax,(%esp)
    a07a:	e8 49 e9 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a07f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    a082:	e8 4c f6 ff ff       	call   96d3 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    a087:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a08a:	83 c0 40             	add    $0x40,%eax
    a08d:	89 04 24             	mov    %eax,(%esp)
    a090:	e8 33 e9 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a095:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    a098:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a09b:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    a09e:	0f 94 c0             	sete   %al
    a0a1:	0f b6 c0             	movzbl %al,%eax
    a0a4:	85 c0                	test   %eax,%eax
    a0a6:	74 07                	je     a0af <ck_ring_trydequeue_spmc+0x66>
		return false;
    a0a8:	b8 00 00 00 00       	mov    $0x0,%eax
    a0ad:	eb 4e                	jmp    a0fd <ck_ring_trydequeue_spmc+0xb4>

	ck_pr_fence_load();
    a0af:	e8 1f f6 ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    a0b4:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a0b7:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    a0ba:	21 d0                	and    %edx,%eax
    a0bc:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a0c0:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    a0c3:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a0c6:	89 44 24 08          	mov    %eax,0x8(%esp)
    a0ca:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a0cd:	89 44 24 04          	mov    %eax,0x4(%esp)
    a0d1:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a0d4:	89 04 24             	mov    %eax,(%esp)
    a0d7:	e8 fc ff ff ff       	call   a0d8 <ck_ring_trydequeue_spmc+0x8f>

	ck_pr_fence_store_atomic();
    a0dc:	e8 c6 f5 ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    a0e1:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a0e4:	8d 50 01             	lea    0x1(%eax),%edx
    a0e7:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a0ea:	89 54 24 08          	mov    %edx,0x8(%esp)
    a0ee:	8b 55 e0             	mov    -0x20(%ebp),%edx
    a0f1:	89 54 24 04          	mov    %edx,0x4(%esp)
    a0f5:	89 04 24             	mov    %eax,(%esp)
    a0f8:	e8 79 f1 ff ff       	call   9276 <ck_pr_cas_uint>
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_trydequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
    a0fd:	c9                   	leave  
    a0fe:	c3                   	ret    

0000a0ff <ck_ring_dequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    a0ff:	55                   	push   %ebp
    a100:	89 e5                	mov    %esp,%ebp
    a102:	53                   	push   %ebx
    a103:	83 ec 34             	sub    $0x34,%esp
    a106:	8b 45 08             	mov    0x8(%ebp),%eax
    a109:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a10c:	8b 45 0c             	mov    0xc(%ebp),%eax
    a10f:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a112:	8b 45 10             	mov    0x10(%ebp),%eax
    a115:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a118:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    a11f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a122:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a128:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    a12b:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a12e:	89 04 24             	mov    %eax,(%esp)
    a131:	e8 92 e8 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a136:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    a139:	e8 95 f5 ff ff       	call   96d3 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    a13e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a141:	83 c0 40             	add    $0x40,%eax
    a144:	89 04 24             	mov    %eax,(%esp)
    a147:	e8 7c e8 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a14c:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    a14f:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a152:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    a155:	0f 94 c0             	sete   %al
    a158:	0f b6 c0             	movzbl %al,%eax
    a15b:	85 c0                	test   %eax,%eax
    a15d:	74 07                	je     a166 <ck_ring_dequeue_spmc+0x67>
			return false;
    a15f:	b8 00 00 00 00       	mov    $0x0,%eax
    a164:	eb 6a                	jmp    a1d0 <ck_ring_dequeue_spmc+0xd1>

		ck_pr_fence_load();
    a166:	e8 68 f5 ff ff       	call   96d3 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    a16b:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a16e:	23 45 e4             	and    -0x1c(%ebp),%eax
    a171:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a175:	89 c2                	mov    %eax,%edx
    a177:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a17a:	01 d0                	add    %edx,%eax
    a17c:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    a17f:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a182:	89 44 24 08          	mov    %eax,0x8(%esp)
    a186:	8b 45 dc             	mov    -0x24(%ebp),%eax
    a189:	89 44 24 04          	mov    %eax,0x4(%esp)
    a18d:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a190:	89 04 24             	mov    %eax,(%esp)
    a193:	e8 fc ff ff ff       	call   a194 <ck_ring_dequeue_spmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    a198:	e8 0a f5 ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    a19d:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a1a0:	8d 58 01             	lea    0x1(%eax),%ebx
    a1a3:	8b 55 d8             	mov    -0x28(%ebp),%edx
    a1a6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a1a9:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    a1ac:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    a1b0:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    a1b4:	89 54 24 04          	mov    %edx,0x4(%esp)
    a1b8:	89 04 24             	mov    %eax,(%esp)
    a1bb:	e8 09 f2 ff ff       	call   93c9 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    a1c0:	83 f0 01             	xor    $0x1,%eax
    a1c3:	84 c0                	test   %al,%al
    a1c5:	0f 85 6e ff ff ff    	jne    a139 <ck_ring_dequeue_spmc+0x3a>

	return true;
    a1cb:	b8 01 00 00 00       	mov    $0x1,%eax
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
    a1d0:	83 c4 34             	add    $0x34,%esp
    a1d3:	5b                   	pop    %ebx
    a1d4:	5d                   	pop    %ebp
    a1d5:	c3                   	ret    

0000a1d6 <ck_ring_enqueue_mpsc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
    a1d6:	55                   	push   %ebp
    a1d7:	89 e5                	mov    %esp,%ebp
    a1d9:	83 ec 48             	sub    $0x48,%esp
    a1dc:	8b 45 08             	mov    0x8(%ebp),%eax
    a1df:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a1e2:	8b 45 0c             	mov    0xc(%ebp),%eax
    a1e5:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a1e8:	8d 45 10             	lea    0x10(%ebp),%eax
    a1eb:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a1ee:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    a1f5:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    a1fc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a1ff:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a205:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    a208:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    a20c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a20f:	83 c0 44             	add    $0x44,%eax
    a212:	89 04 24             	mov    %eax,(%esp)
    a215:	e8 ae e7 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a21a:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    a21d:	e8 b1 f4 ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    a222:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a225:	89 04 24             	mov    %eax,(%esp)
    a228:	e8 9b e7 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a22d:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    a230:	8b 45 cc             	mov    -0x34(%ebp),%eax
    a233:	83 c0 01             	add    $0x1,%eax
    a236:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    a239:	8b 45 cc             	mov    -0x34(%ebp),%eax
    a23c:	2b 45 d8             	sub    -0x28(%ebp),%eax
    a23f:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    a242:	0f 97 c0             	seta   %al
    a245:	0f b6 c0             	movzbl %al,%eax
    a248:	85 c0                	test   %eax,%eax
    a24a:	74 29                	je     a275 <ck_ring_enqueue_mpsc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    a24c:	8b 45 cc             	mov    -0x34(%ebp),%eax
    a24f:	8b 55 f4             	mov    -0xc(%ebp),%edx
    a252:	8d 4a 44             	lea    0x44(%edx),%ecx
    a255:	8d 55 cc             	lea    -0x34(%ebp),%edx
    a258:	89 54 24 0c          	mov    %edx,0xc(%esp)
    a25c:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    a25f:	89 54 24 08          	mov    %edx,0x8(%esp)
    a263:	89 44 24 04          	mov    %eax,0x4(%esp)
    a267:	89 0c 24             	mov    %ecx,(%esp)
    a26a:	e8 5a f1 ff ff       	call   93c9 <ck_pr_cas_uint_value>
    a26f:	84 c0                	test   %al,%al
    a271:	75 31                	jne    a2a4 <ck_ring_enqueue_mpsc+0xce>
    a273:	eb a8                	jmp    a21d <ck_ring_enqueue_mpsc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    a275:	e8 59 f4 ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    a27a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a27d:	83 c0 44             	add    $0x44,%eax
    a280:	89 04 24             	mov    %eax,(%esp)
    a283:	e8 40 e7 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a288:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    a28b:	8b 45 cc             	mov    -0x34(%ebp),%eax
    a28e:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    a291:	75 06                	jne    a299 <ck_ring_enqueue_mpsc+0xc3>
				r = false;
    a293:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    a297:	eb 67                	jmp    a300 <ck_ring_enqueue_mpsc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    a299:	8b 45 d0             	mov    -0x30(%ebp),%eax
    a29c:	89 45 cc             	mov    %eax,-0x34(%ebp)
    a29f:	e9 79 ff ff ff       	jmp    a21d <ck_ring_enqueue_mpsc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    a2a4:	8b 45 cc             	mov    -0x34(%ebp),%eax
    a2a7:	23 45 e0             	and    -0x20(%ebp),%eax
    a2aa:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a2ae:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    a2b1:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a2b4:	89 44 24 08          	mov    %eax,0x8(%esp)
    a2b8:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a2bb:	89 44 24 04          	mov    %eax,0x4(%esp)
    a2bf:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a2c2:	89 04 24             	mov    %eax,(%esp)
    a2c5:	e8 fc ff ff ff       	call   a2c6 <ck_ring_enqueue_mpsc+0xf0>
    a2ca:	eb 05                	jmp    a2d1 <ck_ring_enqueue_mpsc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    a2cc:	e8 92 e5 ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    a2d1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a2d4:	83 c0 40             	add    $0x40,%eax
    a2d7:	89 04 24             	mov    %eax,(%esp)
    a2da:	e8 e9 e6 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a2df:	8b 55 cc             	mov    -0x34(%ebp),%edx
    a2e2:	39 d0                	cmp    %edx,%eax
    a2e4:	75 e6                	jne    a2cc <ck_ring_enqueue_mpsc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    a2e6:	e8 f3 f3 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    a2eb:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a2ee:	8d 50 40             	lea    0x40(%eax),%edx
    a2f1:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a2f4:	89 44 24 04          	mov    %eax,0x4(%esp)
    a2f8:	89 14 24             	mov    %edx,(%esp)
    a2fb:	e8 51 e7 ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    a300:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    a304:	74 10                	je     a316 <ck_ring_enqueue_mpsc+0x140>
		*size = (producer - consumer) & mask;
    a306:	8b 45 cc             	mov    -0x34(%ebp),%eax
    a309:	2b 45 d8             	sub    -0x28(%ebp),%eax
    a30c:	23 45 e0             	and    -0x20(%ebp),%eax
    a30f:	89 c2                	mov    %eax,%edx
    a311:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    a314:	89 10                	mov    %edx,(%eax)

	return r;
    a316:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
    a31a:	c9                   	leave  
    a31b:	c3                   	ret    

0000a31c <ck_ring_enqueue_mpsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
    a31c:	55                   	push   %ebp
    a31d:	89 e5                	mov    %esp,%ebp
    a31f:	83 ec 68             	sub    $0x68,%esp
    a322:	8b 45 08             	mov    0x8(%ebp),%eax
    a325:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a328:	8b 45 0c             	mov    0xc(%ebp),%eax
    a32b:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a32e:	8d 45 10             	lea    0x10(%ebp),%eax
    a331:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a334:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
    a33b:	8b 45 14             	mov    0x14(%ebp),%eax
    a33e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    a341:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a344:	89 45 e0             	mov    %eax,-0x20(%ebp)
    a347:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a34a:	89 45 dc             	mov    %eax,-0x24(%ebp)
    a34d:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a350:	89 45 d8             	mov    %eax,-0x28(%ebp)
    a353:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a356:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    a359:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    a35c:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    a35f:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a362:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a368:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    a36b:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    a36f:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a372:	83 c0 44             	add    $0x44,%eax
    a375:	89 04 24             	mov    %eax,(%esp)
    a378:	e8 4b e6 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a37d:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    a380:	e8 4e f3 ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    a385:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a388:	89 04 24             	mov    %eax,(%esp)
    a38b:	e8 38 e6 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a390:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    a393:	8b 45 b0             	mov    -0x50(%ebp),%eax
    a396:	83 c0 01             	add    $0x1,%eax
    a399:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    a39c:	8b 45 b0             	mov    -0x50(%ebp),%eax
    a39f:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    a3a2:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    a3a5:	0f 97 c0             	seta   %al
    a3a8:	0f b6 c0             	movzbl %al,%eax
    a3ab:	85 c0                	test   %eax,%eax
    a3ad:	74 29                	je     a3d8 <ck_ring_enqueue_mpsc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    a3af:	8b 45 b0             	mov    -0x50(%ebp),%eax
    a3b2:	8b 55 e0             	mov    -0x20(%ebp),%edx
    a3b5:	8d 4a 44             	lea    0x44(%edx),%ecx
    a3b8:	8d 55 b0             	lea    -0x50(%ebp),%edx
    a3bb:	89 54 24 0c          	mov    %edx,0xc(%esp)
    a3bf:	8b 55 c0             	mov    -0x40(%ebp),%edx
    a3c2:	89 54 24 08          	mov    %edx,0x8(%esp)
    a3c6:	89 44 24 04          	mov    %eax,0x4(%esp)
    a3ca:	89 0c 24             	mov    %ecx,(%esp)
    a3cd:	e8 f7 ef ff ff       	call   93c9 <ck_pr_cas_uint_value>
    a3d2:	84 c0                	test   %al,%al
    a3d4:	75 31                	jne    a407 <ck_ring_enqueue_mpsc_size+0xeb>
    a3d6:	eb a8                	jmp    a380 <ck_ring_enqueue_mpsc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    a3d8:	e8 f6 f2 ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    a3dd:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a3e0:	83 c0 44             	add    $0x44,%eax
    a3e3:	89 04 24             	mov    %eax,(%esp)
    a3e6:	e8 dd e5 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a3eb:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    a3ee:	8b 45 b0             	mov    -0x50(%ebp),%eax
    a3f1:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    a3f4:	75 06                	jne    a3fc <ck_ring_enqueue_mpsc_size+0xe0>
				r = false;
    a3f6:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    a3fa:	eb 67                	jmp    a463 <ck_ring_enqueue_mpsc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    a3fc:	8b 45 bc             	mov    -0x44(%ebp),%eax
    a3ff:	89 45 b0             	mov    %eax,-0x50(%ebp)
    a402:	e9 79 ff ff ff       	jmp    a380 <ck_ring_enqueue_mpsc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    a407:	8b 45 b0             	mov    -0x50(%ebp),%eax
    a40a:	23 45 cc             	and    -0x34(%ebp),%eax
    a40d:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    a411:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    a414:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a417:	89 44 24 08          	mov    %eax,0x8(%esp)
    a41b:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a41e:	89 44 24 04          	mov    %eax,0x4(%esp)
    a422:	8b 45 dc             	mov    -0x24(%ebp),%eax
    a425:	89 04 24             	mov    %eax,(%esp)
    a428:	e8 fc ff ff ff       	call   a429 <ck_ring_enqueue_mpsc_size+0x10d>
    a42d:	eb 05                	jmp    a434 <ck_ring_enqueue_mpsc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    a42f:	e8 2f e4 ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    a434:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a437:	83 c0 40             	add    $0x40,%eax
    a43a:	89 04 24             	mov    %eax,(%esp)
    a43d:	e8 86 e5 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a442:	8b 55 b0             	mov    -0x50(%ebp),%edx
    a445:	39 d0                	cmp    %edx,%eax
    a447:	75 e6                	jne    a42f <ck_ring_enqueue_mpsc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    a449:	e8 90 f2 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    a44e:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a451:	8d 50 40             	lea    0x40(%eax),%edx
    a454:	8b 45 c0             	mov    -0x40(%ebp),%eax
    a457:	89 44 24 04          	mov    %eax,0x4(%esp)
    a45b:	89 14 24             	mov    %edx,(%esp)
    a45e:	e8 ee e5 ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    a463:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    a467:	74 10                	je     a479 <ck_ring_enqueue_mpsc_size+0x15d>
		*size = (producer - consumer) & mask;
    a469:	8b 45 b0             	mov    -0x50(%ebp),%eax
    a46c:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    a46f:	23 45 cc             	and    -0x34(%ebp),%eax
    a472:	89 c2                	mov    %eax,%edx
    a474:	8b 45 d0             	mov    -0x30(%ebp),%eax
    a477:	89 10                	mov    %edx,(%eax)

	return r;
    a479:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    a47d:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    a480:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    a483:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    a486:	89 10                	mov    %edx,(%eax)
	return r;
    a488:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
    a48c:	c9                   	leave  
    a48d:	c3                   	ret    

0000a48e <ck_ring_dequeue_mpsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
    a48e:	55                   	push   %ebp
    a48f:	89 e5                	mov    %esp,%ebp
    a491:	83 ec 38             	sub    $0x38,%esp
    a494:	8b 45 08             	mov    0x8(%ebp),%eax
    a497:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a49a:	8b 45 0c             	mov    0xc(%ebp),%eax
    a49d:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a4a0:	8b 45 10             	mov    0x10(%ebp),%eax
    a4a3:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a4a6:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    a4ad:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a4b0:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a4b6:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    a4b9:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a4bc:	8b 00                	mov    (%eax),%eax
    a4be:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    a4c1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a4c4:	83 c0 40             	add    $0x40,%eax
    a4c7:	89 04 24             	mov    %eax,(%esp)
    a4ca:	e8 f9 e4 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a4cf:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    a4d2:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a4d5:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    a4d8:	0f 94 c0             	sete   %al
    a4db:	0f b6 c0             	movzbl %al,%eax
    a4de:	85 c0                	test   %eax,%eax
    a4e0:	74 07                	je     a4e9 <ck_ring_dequeue_mpsc+0x5b>
		return false;
    a4e2:	b8 00 00 00 00       	mov    $0x0,%eax
    a4e7:	eb 4c                	jmp    a535 <ck_ring_dequeue_mpsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    a4e9:	e8 e5 f1 ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    a4ee:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a4f1:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    a4f4:	21 d0                	and    %edx,%eax
    a4f6:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a4fa:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    a4fd:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a500:	89 44 24 08          	mov    %eax,0x8(%esp)
    a504:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a507:	89 44 24 04          	mov    %eax,0x4(%esp)
    a50b:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a50e:	89 04 24             	mov    %eax,(%esp)
    a511:	e8 fc ff ff ff       	call   a512 <ck_ring_dequeue_mpsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    a516:	e8 c3 f1 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    a51b:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a51e:	8d 50 01             	lea    0x1(%eax),%edx
    a521:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a524:	89 54 24 04          	mov    %edx,0x4(%esp)
    a528:	89 04 24             	mov    %eax,(%esp)
    a52b:	e8 21 e5 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    a530:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer, (void **)data,
	    sizeof(void *));
}
    a535:	c9                   	leave  
    a536:	c3                   	ret    

0000a537 <ck_ring_enqueue_spsc_size_xcpu>:
    a537:	55                   	push   %ebp
    a538:	89 e5                	mov    %esp,%ebp
    a53a:	83 ec 58             	sub    $0x58,%esp
    a53d:	8b 45 08             	mov    0x8(%ebp),%eax
    a540:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a543:	8b 45 0c             	mov    0xc(%ebp),%eax
    a546:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a549:	8b 45 10             	mov    0x10(%ebp),%eax
    a54c:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a54f:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    a556:	8b 45 14             	mov    0x14(%ebp),%eax
    a559:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    a55c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a55f:	89 45 e0             	mov    %eax,-0x20(%ebp)
    a562:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a565:	89 45 dc             	mov    %eax,-0x24(%ebp)
    a568:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a56b:	89 45 d8             	mov    %eax,-0x28(%ebp)
    a56e:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a571:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    a574:	8d 45 b8             	lea    -0x48(%ebp),%eax
    a577:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    a57a:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a57d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a583:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    a586:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a589:	89 04 24             	mov    %eax,(%esp)
    a58c:	e8 37 e4 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a591:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    a594:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a597:	8b 40 40             	mov    0x40(%eax),%eax
    a59a:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    a59d:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    a5a0:	83 c0 01             	add    $0x1,%eax
    a5a3:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    a5a6:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    a5aa:	74 14                	je     a5c0 <ck_ring_enqueue_spsc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
    a5ac:	8b 45 c8             	mov    -0x38(%ebp),%eax
    a5af:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    a5b2:	29 c2                	sub    %eax,%edx
    a5b4:	89 d0                	mov    %edx,%eax
    a5b6:	23 45 cc             	and    -0x34(%ebp),%eax
    a5b9:	89 c2                	mov    %eax,%edx
    a5bb:	8b 45 d0             	mov    -0x30(%ebp),%eax
    a5be:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    a5c0:	8b 45 c0             	mov    -0x40(%ebp),%eax
    a5c3:	8b 55 c8             	mov    -0x38(%ebp),%edx
    a5c6:	31 d0                	xor    %edx,%eax
    a5c8:	23 45 cc             	and    -0x34(%ebp),%eax
    a5cb:	85 c0                	test   %eax,%eax
    a5cd:	0f 94 c0             	sete   %al
    a5d0:	0f b6 c0             	movzbl %al,%eax
    a5d3:	85 c0                	test   %eax,%eax
    a5d5:	74 07                	je     a5de <ck_ring_enqueue_spsc_size_xcpu+0xa7>
		return false;
    a5d7:	b8 00 00 00 00       	mov    $0x0,%eax
    a5dc:	eb 47                	jmp    a625 <ck_ring_enqueue_spsc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    a5de:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    a5e1:	8b 55 cc             	mov    -0x34(%ebp),%edx
    a5e4:	21 d0                	and    %edx,%eax
    a5e6:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    a5ea:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    a5ed:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a5f0:	89 44 24 08          	mov    %eax,0x8(%esp)
    a5f4:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a5f7:	89 44 24 04          	mov    %eax,0x4(%esp)
    a5fb:	8b 45 dc             	mov    -0x24(%ebp),%eax
    a5fe:	89 04 24             	mov    %eax,(%esp)
    a601:	e8 fc ff ff ff       	call   a602 <ck_ring_enqueue_spsc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    a606:	e8 d3 f0 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    a60b:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a60e:	8d 50 40             	lea    0x40(%eax),%edx
    a611:	8b 45 c0             	mov    -0x40(%ebp),%eax
    a614:	89 44 24 04          	mov    %eax,0x4(%esp)
    a618:	89 14 24             	mov    %edx,(%esp)
    a61b:	e8 31 e4 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    a620:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    a625:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    a628:	8b 55 b8             	mov    -0x48(%ebp),%edx
    a62b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    a62e:	89 10                	mov    %edx,(%eax)
	return r;
    a630:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    a634:	c9                   	leave  
    a635:	c3                   	ret    

0000a636 <ck_ring_enqueue_spsc_xcpu>:
    a636:	55                   	push   %ebp
    a637:	89 e5                	mov    %esp,%ebp
    a639:	83 ec 48             	sub    $0x48,%esp
    a63c:	8b 45 08             	mov    0x8(%ebp),%eax
    a63f:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a642:	8b 45 0c             	mov    0xc(%ebp),%eax
    a645:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a648:	8b 45 10             	mov    0x10(%ebp),%eax
    a64b:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a64e:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    a655:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    a65c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a65f:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a665:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    a668:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a66b:	89 04 24             	mov    %eax,(%esp)
    a66e:	e8 55 e3 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a673:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    a676:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a679:	8b 40 40             	mov    0x40(%eax),%eax
    a67c:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    a67f:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a682:	83 c0 01             	add    $0x1,%eax
    a685:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    a688:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    a68c:	74 14                	je     a6a2 <ck_ring_enqueue_spsc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
    a68e:	8b 45 dc             	mov    -0x24(%ebp),%eax
    a691:	8b 55 d8             	mov    -0x28(%ebp),%edx
    a694:	29 c2                	sub    %eax,%edx
    a696:	89 d0                	mov    %edx,%eax
    a698:	23 45 e0             	and    -0x20(%ebp),%eax
    a69b:	89 c2                	mov    %eax,%edx
    a69d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    a6a0:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    a6a2:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a6a5:	8b 55 dc             	mov    -0x24(%ebp),%edx
    a6a8:	31 d0                	xor    %edx,%eax
    a6aa:	23 45 e0             	and    -0x20(%ebp),%eax
    a6ad:	85 c0                	test   %eax,%eax
    a6af:	0f 94 c0             	sete   %al
    a6b2:	0f b6 c0             	movzbl %al,%eax
    a6b5:	85 c0                	test   %eax,%eax
    a6b7:	74 07                	je     a6c0 <ck_ring_enqueue_spsc_xcpu+0x8a>
		return false;
    a6b9:	b8 00 00 00 00       	mov    $0x0,%eax
    a6be:	eb 47                	jmp    a707 <ck_ring_enqueue_spsc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    a6c0:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a6c3:	8b 55 e0             	mov    -0x20(%ebp),%edx
    a6c6:	21 d0                	and    %edx,%eax
    a6c8:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a6cc:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    a6cf:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a6d2:	89 44 24 08          	mov    %eax,0x8(%esp)
    a6d6:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a6d9:	89 44 24 04          	mov    %eax,0x4(%esp)
    a6dd:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a6e0:	89 04 24             	mov    %eax,(%esp)
    a6e3:	e8 fc ff ff ff       	call   a6e4 <ck_ring_enqueue_spsc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    a6e8:	e8 f1 ef ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    a6ed:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a6f0:	8d 50 40             	lea    0x40(%eax),%edx
    a6f3:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a6f6:	89 44 24 04          	mov    %eax,0x4(%esp)
    a6fa:	89 14 24             	mov    %edx,(%esp)
    a6fd:	e8 4f e3 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    a702:	b8 01 00 00 00       	mov    $0x1,%eax
    a707:	c9                   	leave  
    a708:	c3                   	ret    

0000a709 <ck_ring_dequeue_spsc_xcpu>:
    a709:	55                   	push   %ebp
    a70a:	89 e5                	mov    %esp,%ebp
    a70c:	83 ec 38             	sub    $0x38,%esp
    a70f:	8b 45 08             	mov    0x8(%ebp),%eax
    a712:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a715:	8b 45 0c             	mov    0xc(%ebp),%eax
    a718:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a71b:	8b 45 10             	mov    0x10(%ebp),%eax
    a71e:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a721:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    a728:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a72b:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a731:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    a734:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a737:	8b 00                	mov    (%eax),%eax
    a739:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    a73c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a73f:	83 c0 40             	add    $0x40,%eax
    a742:	89 04 24             	mov    %eax,(%esp)
    a745:	e8 7e e2 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a74a:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    a74d:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a750:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    a753:	0f 94 c0             	sete   %al
    a756:	0f b6 c0             	movzbl %al,%eax
    a759:	85 c0                	test   %eax,%eax
    a75b:	74 07                	je     a764 <ck_ring_dequeue_spsc_xcpu+0x5b>
		return false;
    a75d:	b8 00 00 00 00       	mov    $0x0,%eax
    a762:	eb 4c                	jmp    a7b0 <ck_ring_dequeue_spsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    a764:	e8 6a ef ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    a769:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a76c:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    a76f:	21 d0                	and    %edx,%eax
    a771:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a775:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    a778:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a77b:	89 44 24 08          	mov    %eax,0x8(%esp)
    a77f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a782:	89 44 24 04          	mov    %eax,0x4(%esp)
    a786:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a789:	89 04 24             	mov    %eax,(%esp)
    a78c:	e8 fc ff ff ff       	call   a78d <ck_ring_dequeue_spsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    a791:	e8 48 ef ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    a796:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a799:	8d 50 01             	lea    0x1(%eax),%edx
    a79c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a79f:	89 54 24 04          	mov    %edx,0x4(%esp)
    a7a3:	89 04 24             	mov    %eax,(%esp)
    a7a6:	e8 a6 e2 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    a7ab:	b8 01 00 00 00       	mov    $0x1,%eax
    a7b0:	c9                   	leave  
    a7b1:	c3                   	ret    

0000a7b2 <ck_ring_enqueue_spmc_size_xcpu>:
    a7b2:	55                   	push   %ebp
    a7b3:	89 e5                	mov    %esp,%ebp
    a7b5:	83 ec 58             	sub    $0x58,%esp
    a7b8:	8b 45 08             	mov    0x8(%ebp),%eax
    a7bb:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a7be:	8b 45 0c             	mov    0xc(%ebp),%eax
    a7c1:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a7c4:	8b 45 10             	mov    0x10(%ebp),%eax
    a7c7:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a7ca:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    a7d1:	8b 45 14             	mov    0x14(%ebp),%eax
    a7d4:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    a7d7:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a7da:	89 45 e0             	mov    %eax,-0x20(%ebp)
    a7dd:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a7e0:	89 45 dc             	mov    %eax,-0x24(%ebp)
    a7e3:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a7e6:	89 45 d8             	mov    %eax,-0x28(%ebp)
    a7e9:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a7ec:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    a7ef:	8d 45 b8             	lea    -0x48(%ebp),%eax
    a7f2:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    a7f5:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a7f8:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a7fe:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    a801:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a804:	89 04 24             	mov    %eax,(%esp)
    a807:	e8 bc e1 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a80c:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    a80f:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a812:	8b 40 40             	mov    0x40(%eax),%eax
    a815:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    a818:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    a81b:	83 c0 01             	add    $0x1,%eax
    a81e:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    a821:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    a825:	74 14                	je     a83b <ck_ring_enqueue_spmc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
    a827:	8b 45 c8             	mov    -0x38(%ebp),%eax
    a82a:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    a82d:	29 c2                	sub    %eax,%edx
    a82f:	89 d0                	mov    %edx,%eax
    a831:	23 45 cc             	and    -0x34(%ebp),%eax
    a834:	89 c2                	mov    %eax,%edx
    a836:	8b 45 d0             	mov    -0x30(%ebp),%eax
    a839:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    a83b:	8b 45 c0             	mov    -0x40(%ebp),%eax
    a83e:	8b 55 c8             	mov    -0x38(%ebp),%edx
    a841:	31 d0                	xor    %edx,%eax
    a843:	23 45 cc             	and    -0x34(%ebp),%eax
    a846:	85 c0                	test   %eax,%eax
    a848:	0f 94 c0             	sete   %al
    a84b:	0f b6 c0             	movzbl %al,%eax
    a84e:	85 c0                	test   %eax,%eax
    a850:	74 07                	je     a859 <ck_ring_enqueue_spmc_size_xcpu+0xa7>
		return false;
    a852:	b8 00 00 00 00       	mov    $0x0,%eax
    a857:	eb 47                	jmp    a8a0 <ck_ring_enqueue_spmc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    a859:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    a85c:	8b 55 cc             	mov    -0x34(%ebp),%edx
    a85f:	21 d0                	and    %edx,%eax
    a861:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    a865:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    a868:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a86b:	89 44 24 08          	mov    %eax,0x8(%esp)
    a86f:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a872:	89 44 24 04          	mov    %eax,0x4(%esp)
    a876:	8b 45 dc             	mov    -0x24(%ebp),%eax
    a879:	89 04 24             	mov    %eax,(%esp)
    a87c:	e8 fc ff ff ff       	call   a87d <ck_ring_enqueue_spmc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    a881:	e8 58 ee ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    a886:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a889:	8d 50 40             	lea    0x40(%eax),%edx
    a88c:	8b 45 c0             	mov    -0x40(%ebp),%eax
    a88f:	89 44 24 04          	mov    %eax,0x4(%esp)
    a893:	89 14 24             	mov    %edx,(%esp)
    a896:	e8 b6 e1 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    a89b:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    a8a0:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    a8a3:	8b 55 b8             	mov    -0x48(%ebp),%edx
    a8a6:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    a8a9:	89 10                	mov    %edx,(%eax)
	return r;
    a8ab:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    a8af:	c9                   	leave  
    a8b0:	c3                   	ret    

0000a8b1 <ck_ring_enqueue_spmc_xcpu>:
    a8b1:	55                   	push   %ebp
    a8b2:	89 e5                	mov    %esp,%ebp
    a8b4:	83 ec 48             	sub    $0x48,%esp
    a8b7:	8b 45 08             	mov    0x8(%ebp),%eax
    a8ba:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a8bd:	8b 45 0c             	mov    0xc(%ebp),%eax
    a8c0:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a8c3:	8b 45 10             	mov    0x10(%ebp),%eax
    a8c6:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a8c9:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    a8d0:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    a8d7:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a8da:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a8e0:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    a8e3:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a8e6:	89 04 24             	mov    %eax,(%esp)
    a8e9:	e8 da e0 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a8ee:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    a8f1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a8f4:	8b 40 40             	mov    0x40(%eax),%eax
    a8f7:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    a8fa:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a8fd:	83 c0 01             	add    $0x1,%eax
    a900:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    a903:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    a907:	74 14                	je     a91d <ck_ring_enqueue_spmc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
    a909:	8b 45 dc             	mov    -0x24(%ebp),%eax
    a90c:	8b 55 d8             	mov    -0x28(%ebp),%edx
    a90f:	29 c2                	sub    %eax,%edx
    a911:	89 d0                	mov    %edx,%eax
    a913:	23 45 e0             	and    -0x20(%ebp),%eax
    a916:	89 c2                	mov    %eax,%edx
    a918:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    a91b:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    a91d:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a920:	8b 55 dc             	mov    -0x24(%ebp),%edx
    a923:	31 d0                	xor    %edx,%eax
    a925:	23 45 e0             	and    -0x20(%ebp),%eax
    a928:	85 c0                	test   %eax,%eax
    a92a:	0f 94 c0             	sete   %al
    a92d:	0f b6 c0             	movzbl %al,%eax
    a930:	85 c0                	test   %eax,%eax
    a932:	74 07                	je     a93b <ck_ring_enqueue_spmc_xcpu+0x8a>
		return false;
    a934:	b8 00 00 00 00       	mov    $0x0,%eax
    a939:	eb 47                	jmp    a982 <ck_ring_enqueue_spmc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    a93b:	8b 45 d8             	mov    -0x28(%ebp),%eax
    a93e:	8b 55 e0             	mov    -0x20(%ebp),%edx
    a941:	21 d0                	and    %edx,%eax
    a943:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a947:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    a94a:	8b 45 e8             	mov    -0x18(%ebp),%eax
    a94d:	89 44 24 08          	mov    %eax,0x8(%esp)
    a951:	8b 45 ec             	mov    -0x14(%ebp),%eax
    a954:	89 44 24 04          	mov    %eax,0x4(%esp)
    a958:	8b 45 f0             	mov    -0x10(%ebp),%eax
    a95b:	89 04 24             	mov    %eax,(%esp)
    a95e:	e8 fc ff ff ff       	call   a95f <ck_ring_enqueue_spmc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    a963:	e8 76 ed ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    a968:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a96b:	8d 50 40             	lea    0x40(%eax),%edx
    a96e:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    a971:	89 44 24 04          	mov    %eax,0x4(%esp)
    a975:	89 14 24             	mov    %edx,(%esp)
    a978:	e8 d4 e0 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    a97d:	b8 01 00 00 00       	mov    $0x1,%eax
    a982:	c9                   	leave  
    a983:	c3                   	ret    

0000a984 <ck_ring_trydequeue_spmc_xcpu>:
    a984:	55                   	push   %ebp
    a985:	89 e5                	mov    %esp,%ebp
    a987:	83 ec 38             	sub    $0x38,%esp
    a98a:	8b 45 08             	mov    0x8(%ebp),%eax
    a98d:	89 45 f4             	mov    %eax,-0xc(%ebp)
    a990:	8b 45 0c             	mov    0xc(%ebp),%eax
    a993:	89 45 f0             	mov    %eax,-0x10(%ebp)
    a996:	8b 45 10             	mov    0x10(%ebp),%eax
    a999:	89 45 ec             	mov    %eax,-0x14(%ebp)
    a99c:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    a9a3:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a9a6:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    a9ac:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    a9af:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a9b2:	89 04 24             	mov    %eax,(%esp)
    a9b5:	e8 0e e0 ff ff       	call   89c8 <ck_pr_md_load_uint>
    a9ba:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    a9bd:	e8 11 ed ff ff       	call   96d3 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    a9c2:	8b 45 f4             	mov    -0xc(%ebp),%eax
    a9c5:	83 c0 40             	add    $0x40,%eax
    a9c8:	89 04 24             	mov    %eax,(%esp)
    a9cb:	e8 f8 df ff ff       	call   89c8 <ck_pr_md_load_uint>
    a9d0:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    a9d3:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a9d6:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    a9d9:	0f 94 c0             	sete   %al
    a9dc:	0f b6 c0             	movzbl %al,%eax
    a9df:	85 c0                	test   %eax,%eax
    a9e1:	74 07                	je     a9ea <ck_ring_trydequeue_spmc_xcpu+0x66>
		return false;
    a9e3:	b8 00 00 00 00       	mov    $0x0,%eax
    a9e8:	eb 4e                	jmp    aa38 <ck_ring_trydequeue_spmc_xcpu+0xb4>

	ck_pr_fence_load();
    a9ea:	e8 e4 ec ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    a9ef:	8b 45 e0             	mov    -0x20(%ebp),%eax
    a9f2:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    a9f5:	21 d0                	and    %edx,%eax
    a9f7:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    a9fb:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    a9fe:	8b 45 e8             	mov    -0x18(%ebp),%eax
    aa01:	89 44 24 08          	mov    %eax,0x8(%esp)
    aa05:	8b 45 f0             	mov    -0x10(%ebp),%eax
    aa08:	89 44 24 04          	mov    %eax,0x4(%esp)
    aa0c:	8b 45 ec             	mov    -0x14(%ebp),%eax
    aa0f:	89 04 24             	mov    %eax,(%esp)
    aa12:	e8 fc ff ff ff       	call   aa13 <ck_ring_trydequeue_spmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
    aa17:	e8 8b ec ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    aa1c:	8b 45 e0             	mov    -0x20(%ebp),%eax
    aa1f:	8d 50 01             	lea    0x1(%eax),%edx
    aa22:	8b 45 f4             	mov    -0xc(%ebp),%eax
    aa25:	89 54 24 08          	mov    %edx,0x8(%esp)
    aa29:	8b 55 e0             	mov    -0x20(%ebp),%edx
    aa2c:	89 54 24 04          	mov    %edx,0x4(%esp)
    aa30:	89 04 24             	mov    %eax,(%esp)
    aa33:	e8 3e e8 ff ff       	call   9276 <ck_pr_cas_uint>
    aa38:	c9                   	leave  
    aa39:	c3                   	ret    

0000aa3a <ck_ring_dequeue_spmc_xcpu>:
    aa3a:	55                   	push   %ebp
    aa3b:	89 e5                	mov    %esp,%ebp
    aa3d:	53                   	push   %ebx
    aa3e:	83 ec 34             	sub    $0x34,%esp
    aa41:	8b 45 08             	mov    0x8(%ebp),%eax
    aa44:	89 45 f4             	mov    %eax,-0xc(%ebp)
    aa47:	8b 45 0c             	mov    0xc(%ebp),%eax
    aa4a:	89 45 f0             	mov    %eax,-0x10(%ebp)
    aa4d:	8b 45 10             	mov    0x10(%ebp),%eax
    aa50:	89 45 ec             	mov    %eax,-0x14(%ebp)
    aa53:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    aa5a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    aa5d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    aa63:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    aa66:	8b 45 f4             	mov    -0xc(%ebp),%eax
    aa69:	89 04 24             	mov    %eax,(%esp)
    aa6c:	e8 57 df ff ff       	call   89c8 <ck_pr_md_load_uint>
    aa71:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    aa74:	e8 5a ec ff ff       	call   96d3 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    aa79:	8b 45 f4             	mov    -0xc(%ebp),%eax
    aa7c:	83 c0 40             	add    $0x40,%eax
    aa7f:	89 04 24             	mov    %eax,(%esp)
    aa82:	e8 41 df ff ff       	call   89c8 <ck_pr_md_load_uint>
    aa87:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    aa8a:	8b 45 d8             	mov    -0x28(%ebp),%eax
    aa8d:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    aa90:	0f 94 c0             	sete   %al
    aa93:	0f b6 c0             	movzbl %al,%eax
    aa96:	85 c0                	test   %eax,%eax
    aa98:	74 07                	je     aaa1 <ck_ring_dequeue_spmc_xcpu+0x67>
			return false;
    aa9a:	b8 00 00 00 00       	mov    $0x0,%eax
    aa9f:	eb 6a                	jmp    ab0b <ck_ring_dequeue_spmc_xcpu+0xd1>

		ck_pr_fence_load();
    aaa1:	e8 2d ec ff ff       	call   96d3 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    aaa6:	8b 45 d8             	mov    -0x28(%ebp),%eax
    aaa9:	23 45 e4             	and    -0x1c(%ebp),%eax
    aaac:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    aab0:	89 c2                	mov    %eax,%edx
    aab2:	8b 45 f0             	mov    -0x10(%ebp),%eax
    aab5:	01 d0                	add    %edx,%eax
    aab7:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    aaba:	8b 45 e8             	mov    -0x18(%ebp),%eax
    aabd:	89 44 24 08          	mov    %eax,0x8(%esp)
    aac1:	8b 45 dc             	mov    -0x24(%ebp),%eax
    aac4:	89 44 24 04          	mov    %eax,0x4(%esp)
    aac8:	8b 45 ec             	mov    -0x14(%ebp),%eax
    aacb:	89 04 24             	mov    %eax,(%esp)
    aace:	e8 fc ff ff ff       	call   aacf <ck_ring_dequeue_spmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    aad3:	e8 cf eb ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    aad8:	8b 45 d8             	mov    -0x28(%ebp),%eax
    aadb:	8d 58 01             	lea    0x1(%eax),%ebx
    aade:	8b 55 d8             	mov    -0x28(%ebp),%edx
    aae1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    aae4:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    aae7:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    aaeb:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    aaef:	89 54 24 04          	mov    %edx,0x4(%esp)
    aaf3:	89 04 24             	mov    %eax,(%esp)
    aaf6:	e8 ce e8 ff ff       	call   93c9 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    aafb:	83 f0 01             	xor    $0x1,%eax
    aafe:	84 c0                	test   %al,%al
    ab00:	0f 85 6e ff ff ff    	jne    aa74 <ck_ring_dequeue_spmc_xcpu+0x3a>

	return true;
    ab06:	b8 01 00 00 00       	mov    $0x1,%eax
    ab0b:	83 c4 34             	add    $0x34,%esp
    ab0e:	5b                   	pop    %ebx
    ab0f:	5d                   	pop    %ebp
    ab10:	c3                   	ret    

0000ab11 <ck_ring_enqueue_mpsc_xcpu>:
    ab11:	55                   	push   %ebp
    ab12:	89 e5                	mov    %esp,%ebp
    ab14:	83 ec 48             	sub    $0x48,%esp
    ab17:	8b 45 08             	mov    0x8(%ebp),%eax
    ab1a:	89 45 f4             	mov    %eax,-0xc(%ebp)
    ab1d:	8b 45 0c             	mov    0xc(%ebp),%eax
    ab20:	89 45 f0             	mov    %eax,-0x10(%ebp)
    ab23:	8b 45 10             	mov    0x10(%ebp),%eax
    ab26:	89 45 ec             	mov    %eax,-0x14(%ebp)
    ab29:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    ab30:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    ab37:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ab3a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    ab40:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    ab43:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    ab47:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ab4a:	83 c0 44             	add    $0x44,%eax
    ab4d:	89 04 24             	mov    %eax,(%esp)
    ab50:	e8 73 de ff ff       	call   89c8 <ck_pr_md_load_uint>
    ab55:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    ab58:	e8 76 eb ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    ab5d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ab60:	89 04 24             	mov    %eax,(%esp)
    ab63:	e8 60 de ff ff       	call   89c8 <ck_pr_md_load_uint>
    ab68:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    ab6b:	8b 45 cc             	mov    -0x34(%ebp),%eax
    ab6e:	83 c0 01             	add    $0x1,%eax
    ab71:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    ab74:	8b 45 cc             	mov    -0x34(%ebp),%eax
    ab77:	2b 45 d8             	sub    -0x28(%ebp),%eax
    ab7a:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    ab7d:	0f 97 c0             	seta   %al
    ab80:	0f b6 c0             	movzbl %al,%eax
    ab83:	85 c0                	test   %eax,%eax
    ab85:	74 29                	je     abb0 <ck_ring_enqueue_mpsc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    ab87:	8b 45 cc             	mov    -0x34(%ebp),%eax
    ab8a:	8b 55 f4             	mov    -0xc(%ebp),%edx
    ab8d:	8d 4a 44             	lea    0x44(%edx),%ecx
    ab90:	8d 55 cc             	lea    -0x34(%ebp),%edx
    ab93:	89 54 24 0c          	mov    %edx,0xc(%esp)
    ab97:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    ab9a:	89 54 24 08          	mov    %edx,0x8(%esp)
    ab9e:	89 44 24 04          	mov    %eax,0x4(%esp)
    aba2:	89 0c 24             	mov    %ecx,(%esp)
    aba5:	e8 1f e8 ff ff       	call   93c9 <ck_pr_cas_uint_value>
    abaa:	84 c0                	test   %al,%al
    abac:	75 31                	jne    abdf <ck_ring_enqueue_mpsc_xcpu+0xce>
    abae:	eb a8                	jmp    ab58 <ck_ring_enqueue_mpsc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    abb0:	e8 1e eb ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    abb5:	8b 45 f4             	mov    -0xc(%ebp),%eax
    abb8:	83 c0 44             	add    $0x44,%eax
    abbb:	89 04 24             	mov    %eax,(%esp)
    abbe:	e8 05 de ff ff       	call   89c8 <ck_pr_md_load_uint>
    abc3:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    abc6:	8b 45 cc             	mov    -0x34(%ebp),%eax
    abc9:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    abcc:	75 06                	jne    abd4 <ck_ring_enqueue_mpsc_xcpu+0xc3>
				r = false;
    abce:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    abd2:	eb 67                	jmp    ac3b <ck_ring_enqueue_mpsc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    abd4:	8b 45 d0             	mov    -0x30(%ebp),%eax
    abd7:	89 45 cc             	mov    %eax,-0x34(%ebp)
    abda:	e9 79 ff ff ff       	jmp    ab58 <ck_ring_enqueue_mpsc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    abdf:	8b 45 cc             	mov    -0x34(%ebp),%eax
    abe2:	23 45 e0             	and    -0x20(%ebp),%eax
    abe5:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    abe9:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    abec:	8b 45 e8             	mov    -0x18(%ebp),%eax
    abef:	89 44 24 08          	mov    %eax,0x8(%esp)
    abf3:	8b 45 ec             	mov    -0x14(%ebp),%eax
    abf6:	89 44 24 04          	mov    %eax,0x4(%esp)
    abfa:	8b 45 f0             	mov    -0x10(%ebp),%eax
    abfd:	89 04 24             	mov    %eax,(%esp)
    ac00:	e8 fc ff ff ff       	call   ac01 <ck_ring_enqueue_mpsc_xcpu+0xf0>
    ac05:	eb 05                	jmp    ac0c <ck_ring_enqueue_mpsc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    ac07:	e8 57 dc ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    ac0c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ac0f:	83 c0 40             	add    $0x40,%eax
    ac12:	89 04 24             	mov    %eax,(%esp)
    ac15:	e8 ae dd ff ff       	call   89c8 <ck_pr_md_load_uint>
    ac1a:	8b 55 cc             	mov    -0x34(%ebp),%edx
    ac1d:	39 d0                	cmp    %edx,%eax
    ac1f:	75 e6                	jne    ac07 <ck_ring_enqueue_mpsc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    ac21:	e8 b8 ea ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    ac26:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ac29:	8d 50 40             	lea    0x40(%eax),%edx
    ac2c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    ac2f:	89 44 24 04          	mov    %eax,0x4(%esp)
    ac33:	89 14 24             	mov    %edx,(%esp)
    ac36:	e8 16 de ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    ac3b:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    ac3f:	74 10                	je     ac51 <ck_ring_enqueue_mpsc_xcpu+0x140>
		*size = (producer - consumer) & mask;
    ac41:	8b 45 cc             	mov    -0x34(%ebp),%eax
    ac44:	2b 45 d8             	sub    -0x28(%ebp),%eax
    ac47:	23 45 e0             	and    -0x20(%ebp),%eax
    ac4a:	89 c2                	mov    %eax,%edx
    ac4c:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    ac4f:	89 10                	mov    %edx,(%eax)

	return r;
    ac51:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    ac55:	c9                   	leave  
    ac56:	c3                   	ret    

0000ac57 <ck_ring_enqueue_mpsc_size_xcpu>:
    ac57:	55                   	push   %ebp
    ac58:	89 e5                	mov    %esp,%ebp
    ac5a:	83 ec 68             	sub    $0x68,%esp
    ac5d:	8b 45 08             	mov    0x8(%ebp),%eax
    ac60:	89 45 f4             	mov    %eax,-0xc(%ebp)
    ac63:	8b 45 0c             	mov    0xc(%ebp),%eax
    ac66:	89 45 f0             	mov    %eax,-0x10(%ebp)
    ac69:	8b 45 10             	mov    0x10(%ebp),%eax
    ac6c:	89 45 ec             	mov    %eax,-0x14(%ebp)
    ac6f:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    ac76:	8b 45 14             	mov    0x14(%ebp),%eax
    ac79:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    ac7c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ac7f:	89 45 e0             	mov    %eax,-0x20(%ebp)
    ac82:	8b 45 f0             	mov    -0x10(%ebp),%eax
    ac85:	89 45 dc             	mov    %eax,-0x24(%ebp)
    ac88:	8b 45 ec             	mov    -0x14(%ebp),%eax
    ac8b:	89 45 d8             	mov    %eax,-0x28(%ebp)
    ac8e:	8b 45 e8             	mov    -0x18(%ebp),%eax
    ac91:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    ac94:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    ac97:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    ac9a:	8b 45 e0             	mov    -0x20(%ebp),%eax
    ac9d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    aca3:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    aca6:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    acaa:	8b 45 e0             	mov    -0x20(%ebp),%eax
    acad:	83 c0 44             	add    $0x44,%eax
    acb0:	89 04 24             	mov    %eax,(%esp)
    acb3:	e8 10 dd ff ff       	call   89c8 <ck_pr_md_load_uint>
    acb8:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    acbb:	e8 13 ea ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    acc0:	8b 45 e0             	mov    -0x20(%ebp),%eax
    acc3:	89 04 24             	mov    %eax,(%esp)
    acc6:	e8 fd dc ff ff       	call   89c8 <ck_pr_md_load_uint>
    accb:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    acce:	8b 45 b0             	mov    -0x50(%ebp),%eax
    acd1:	83 c0 01             	add    $0x1,%eax
    acd4:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    acd7:	8b 45 b0             	mov    -0x50(%ebp),%eax
    acda:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    acdd:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    ace0:	0f 97 c0             	seta   %al
    ace3:	0f b6 c0             	movzbl %al,%eax
    ace6:	85 c0                	test   %eax,%eax
    ace8:	74 29                	je     ad13 <ck_ring_enqueue_mpsc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    acea:	8b 45 b0             	mov    -0x50(%ebp),%eax
    aced:	8b 55 e0             	mov    -0x20(%ebp),%edx
    acf0:	8d 4a 44             	lea    0x44(%edx),%ecx
    acf3:	8d 55 b0             	lea    -0x50(%ebp),%edx
    acf6:	89 54 24 0c          	mov    %edx,0xc(%esp)
    acfa:	8b 55 c0             	mov    -0x40(%ebp),%edx
    acfd:	89 54 24 08          	mov    %edx,0x8(%esp)
    ad01:	89 44 24 04          	mov    %eax,0x4(%esp)
    ad05:	89 0c 24             	mov    %ecx,(%esp)
    ad08:	e8 bc e6 ff ff       	call   93c9 <ck_pr_cas_uint_value>
    ad0d:	84 c0                	test   %al,%al
    ad0f:	75 31                	jne    ad42 <ck_ring_enqueue_mpsc_size_xcpu+0xeb>
    ad11:	eb a8                	jmp    acbb <ck_ring_enqueue_mpsc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    ad13:	e8 bb e9 ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    ad18:	8b 45 e0             	mov    -0x20(%ebp),%eax
    ad1b:	83 c0 44             	add    $0x44,%eax
    ad1e:	89 04 24             	mov    %eax,(%esp)
    ad21:	e8 a2 dc ff ff       	call   89c8 <ck_pr_md_load_uint>
    ad26:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    ad29:	8b 45 b0             	mov    -0x50(%ebp),%eax
    ad2c:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    ad2f:	75 06                	jne    ad37 <ck_ring_enqueue_mpsc_size_xcpu+0xe0>
				r = false;
    ad31:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    ad35:	eb 67                	jmp    ad9e <ck_ring_enqueue_mpsc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    ad37:	8b 45 bc             	mov    -0x44(%ebp),%eax
    ad3a:	89 45 b0             	mov    %eax,-0x50(%ebp)
    ad3d:	e9 79 ff ff ff       	jmp    acbb <ck_ring_enqueue_mpsc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    ad42:	8b 45 b0             	mov    -0x50(%ebp),%eax
    ad45:	23 45 cc             	and    -0x34(%ebp),%eax
    ad48:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    ad4c:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    ad4f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    ad52:	89 44 24 08          	mov    %eax,0x8(%esp)
    ad56:	8b 45 d8             	mov    -0x28(%ebp),%eax
    ad59:	89 44 24 04          	mov    %eax,0x4(%esp)
    ad5d:	8b 45 dc             	mov    -0x24(%ebp),%eax
    ad60:	89 04 24             	mov    %eax,(%esp)
    ad63:	e8 fc ff ff ff       	call   ad64 <ck_ring_enqueue_mpsc_size_xcpu+0x10d>
    ad68:	eb 05                	jmp    ad6f <ck_ring_enqueue_mpsc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    ad6a:	e8 f4 da ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    ad6f:	8b 45 e0             	mov    -0x20(%ebp),%eax
    ad72:	83 c0 40             	add    $0x40,%eax
    ad75:	89 04 24             	mov    %eax,(%esp)
    ad78:	e8 4b dc ff ff       	call   89c8 <ck_pr_md_load_uint>
    ad7d:	8b 55 b0             	mov    -0x50(%ebp),%edx
    ad80:	39 d0                	cmp    %edx,%eax
    ad82:	75 e6                	jne    ad6a <ck_ring_enqueue_mpsc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    ad84:	e8 55 e9 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    ad89:	8b 45 e0             	mov    -0x20(%ebp),%eax
    ad8c:	8d 50 40             	lea    0x40(%eax),%edx
    ad8f:	8b 45 c0             	mov    -0x40(%ebp),%eax
    ad92:	89 44 24 04          	mov    %eax,0x4(%esp)
    ad96:	89 14 24             	mov    %edx,(%esp)
    ad99:	e8 b3 dc ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    ad9e:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    ada2:	74 10                	je     adb4 <ck_ring_enqueue_mpsc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
    ada4:	8b 45 b0             	mov    -0x50(%ebp),%eax
    ada7:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    adaa:	23 45 cc             	and    -0x34(%ebp),%eax
    adad:	89 c2                	mov    %eax,%edx
    adaf:	8b 45 d0             	mov    -0x30(%ebp),%eax
    adb2:	89 10                	mov    %edx,(%eax)

	return r;
    adb4:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    adb8:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    adbb:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    adbe:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    adc1:	89 10                	mov    %edx,(%eax)
	return r;
    adc3:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    adc7:	c9                   	leave  
    adc8:	c3                   	ret    

0000adc9 <ck_ring_dequeue_mpsc_xcpu>:
    adc9:	55                   	push   %ebp
    adca:	89 e5                	mov    %esp,%ebp
    adcc:	83 ec 38             	sub    $0x38,%esp
    adcf:	8b 45 08             	mov    0x8(%ebp),%eax
    add2:	89 45 f4             	mov    %eax,-0xc(%ebp)
    add5:	8b 45 0c             	mov    0xc(%ebp),%eax
    add8:	89 45 f0             	mov    %eax,-0x10(%ebp)
    addb:	8b 45 10             	mov    0x10(%ebp),%eax
    adde:	89 45 ec             	mov    %eax,-0x14(%ebp)
    ade1:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    ade8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    adeb:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    adf1:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    adf4:	8b 45 f4             	mov    -0xc(%ebp),%eax
    adf7:	8b 00                	mov    (%eax),%eax
    adf9:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    adfc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    adff:	83 c0 40             	add    $0x40,%eax
    ae02:	89 04 24             	mov    %eax,(%esp)
    ae05:	e8 be db ff ff       	call   89c8 <ck_pr_md_load_uint>
    ae0a:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    ae0d:	8b 45 e0             	mov    -0x20(%ebp),%eax
    ae10:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    ae13:	0f 94 c0             	sete   %al
    ae16:	0f b6 c0             	movzbl %al,%eax
    ae19:	85 c0                	test   %eax,%eax
    ae1b:	74 07                	je     ae24 <ck_ring_dequeue_mpsc_xcpu+0x5b>
		return false;
    ae1d:	b8 00 00 00 00       	mov    $0x0,%eax
    ae22:	eb 4c                	jmp    ae70 <ck_ring_dequeue_mpsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    ae24:	e8 aa e8 ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    ae29:	8b 45 e0             	mov    -0x20(%ebp),%eax
    ae2c:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    ae2f:	21 d0                	and    %edx,%eax
    ae31:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    ae35:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    ae38:	8b 45 e8             	mov    -0x18(%ebp),%eax
    ae3b:	89 44 24 08          	mov    %eax,0x8(%esp)
    ae3f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    ae42:	89 44 24 04          	mov    %eax,0x4(%esp)
    ae46:	8b 45 ec             	mov    -0x14(%ebp),%eax
    ae49:	89 04 24             	mov    %eax,(%esp)
    ae4c:	e8 fc ff ff ff       	call   ae4d <ck_ring_dequeue_mpsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    ae51:	e8 88 e8 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    ae56:	8b 45 e0             	mov    -0x20(%ebp),%eax
    ae59:	8d 50 01             	lea    0x1(%eax),%edx
    ae5c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ae5f:	89 54 24 04          	mov    %edx,0x4(%esp)
    ae63:	89 04 24             	mov    %eax,(%esp)
    ae66:	e8 e6 db ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    ae6b:	b8 01 00 00 00       	mov    $0x1,%eax
    ae70:	c9                   	leave  
    ae71:	c3                   	ret    

0000ae72 <ck_ring_enqueue_mpmc_size_xcpu>:
    ae72:	55                   	push   %ebp
    ae73:	89 e5                	mov    %esp,%ebp
    ae75:	83 ec 68             	sub    $0x68,%esp
    ae78:	8b 45 08             	mov    0x8(%ebp),%eax
    ae7b:	89 45 f4             	mov    %eax,-0xc(%ebp)
    ae7e:	8b 45 0c             	mov    0xc(%ebp),%eax
    ae81:	89 45 f0             	mov    %eax,-0x10(%ebp)
    ae84:	8b 45 10             	mov    0x10(%ebp),%eax
    ae87:	89 45 ec             	mov    %eax,-0x14(%ebp)
    ae8a:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    ae91:	8b 45 14             	mov    0x14(%ebp),%eax
    ae94:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    ae97:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ae9a:	89 45 e0             	mov    %eax,-0x20(%ebp)
    ae9d:	8b 45 f0             	mov    -0x10(%ebp),%eax
    aea0:	89 45 dc             	mov    %eax,-0x24(%ebp)
    aea3:	8b 45 ec             	mov    -0x14(%ebp),%eax
    aea6:	89 45 d8             	mov    %eax,-0x28(%ebp)
    aea9:	8b 45 e8             	mov    -0x18(%ebp),%eax
    aeac:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    aeaf:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    aeb2:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    aeb5:	8b 45 e0             	mov    -0x20(%ebp),%eax
    aeb8:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    aebe:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    aec1:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    aec5:	8b 45 e0             	mov    -0x20(%ebp),%eax
    aec8:	83 c0 44             	add    $0x44,%eax
    aecb:	89 04 24             	mov    %eax,(%esp)
    aece:	e8 f5 da ff ff       	call   89c8 <ck_pr_md_load_uint>
    aed3:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    aed6:	e8 f8 e7 ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    aedb:	8b 45 e0             	mov    -0x20(%ebp),%eax
    aede:	89 04 24             	mov    %eax,(%esp)
    aee1:	e8 e2 da ff ff       	call   89c8 <ck_pr_md_load_uint>
    aee6:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    aee9:	8b 45 b0             	mov    -0x50(%ebp),%eax
    aeec:	83 c0 01             	add    $0x1,%eax
    aeef:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    aef2:	8b 45 b0             	mov    -0x50(%ebp),%eax
    aef5:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    aef8:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    aefb:	0f 97 c0             	seta   %al
    aefe:	0f b6 c0             	movzbl %al,%eax
    af01:	85 c0                	test   %eax,%eax
    af03:	74 29                	je     af2e <ck_ring_enqueue_mpmc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    af05:	8b 45 b0             	mov    -0x50(%ebp),%eax
    af08:	8b 55 e0             	mov    -0x20(%ebp),%edx
    af0b:	8d 4a 44             	lea    0x44(%edx),%ecx
    af0e:	8d 55 b0             	lea    -0x50(%ebp),%edx
    af11:	89 54 24 0c          	mov    %edx,0xc(%esp)
    af15:	8b 55 c0             	mov    -0x40(%ebp),%edx
    af18:	89 54 24 08          	mov    %edx,0x8(%esp)
    af1c:	89 44 24 04          	mov    %eax,0x4(%esp)
    af20:	89 0c 24             	mov    %ecx,(%esp)
    af23:	e8 a1 e4 ff ff       	call   93c9 <ck_pr_cas_uint_value>
    af28:	84 c0                	test   %al,%al
    af2a:	75 31                	jne    af5d <ck_ring_enqueue_mpmc_size_xcpu+0xeb>
    af2c:	eb a8                	jmp    aed6 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    af2e:	e8 a0 e7 ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    af33:	8b 45 e0             	mov    -0x20(%ebp),%eax
    af36:	83 c0 44             	add    $0x44,%eax
    af39:	89 04 24             	mov    %eax,(%esp)
    af3c:	e8 87 da ff ff       	call   89c8 <ck_pr_md_load_uint>
    af41:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    af44:	8b 45 b0             	mov    -0x50(%ebp),%eax
    af47:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    af4a:	75 06                	jne    af52 <ck_ring_enqueue_mpmc_size_xcpu+0xe0>
				r = false;
    af4c:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    af50:	eb 67                	jmp    afb9 <ck_ring_enqueue_mpmc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    af52:	8b 45 bc             	mov    -0x44(%ebp),%eax
    af55:	89 45 b0             	mov    %eax,-0x50(%ebp)
    af58:	e9 79 ff ff ff       	jmp    aed6 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    af5d:	8b 45 b0             	mov    -0x50(%ebp),%eax
    af60:	23 45 cc             	and    -0x34(%ebp),%eax
    af63:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    af67:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    af6a:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    af6d:	89 44 24 08          	mov    %eax,0x8(%esp)
    af71:	8b 45 d8             	mov    -0x28(%ebp),%eax
    af74:	89 44 24 04          	mov    %eax,0x4(%esp)
    af78:	8b 45 dc             	mov    -0x24(%ebp),%eax
    af7b:	89 04 24             	mov    %eax,(%esp)
    af7e:	e8 fc ff ff ff       	call   af7f <ck_ring_enqueue_mpmc_size_xcpu+0x10d>
    af83:	eb 05                	jmp    af8a <ck_ring_enqueue_mpmc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    af85:	e8 d9 d8 ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    af8a:	8b 45 e0             	mov    -0x20(%ebp),%eax
    af8d:	83 c0 40             	add    $0x40,%eax
    af90:	89 04 24             	mov    %eax,(%esp)
    af93:	e8 30 da ff ff       	call   89c8 <ck_pr_md_load_uint>
    af98:	8b 55 b0             	mov    -0x50(%ebp),%edx
    af9b:	39 d0                	cmp    %edx,%eax
    af9d:	75 e6                	jne    af85 <ck_ring_enqueue_mpmc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    af9f:	e8 3a e7 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    afa4:	8b 45 e0             	mov    -0x20(%ebp),%eax
    afa7:	8d 50 40             	lea    0x40(%eax),%edx
    afaa:	8b 45 c0             	mov    -0x40(%ebp),%eax
    afad:	89 44 24 04          	mov    %eax,0x4(%esp)
    afb1:	89 14 24             	mov    %edx,(%esp)
    afb4:	e8 98 da ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    afb9:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    afbd:	74 10                	je     afcf <ck_ring_enqueue_mpmc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
    afbf:	8b 45 b0             	mov    -0x50(%ebp),%eax
    afc2:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    afc5:	23 45 cc             	and    -0x34(%ebp),%eax
    afc8:	89 c2                	mov    %eax,%edx
    afca:	8b 45 d0             	mov    -0x30(%ebp),%eax
    afcd:	89 10                	mov    %edx,(%eax)

	return r;
    afcf:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    afd3:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    afd6:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    afd9:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    afdc:	89 10                	mov    %edx,(%eax)
	return r;
    afde:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    afe2:	c9                   	leave  
    afe3:	c3                   	ret    

0000afe4 <ck_ring_enqueue_mpmc_xcpu>:
    afe4:	55                   	push   %ebp
    afe5:	89 e5                	mov    %esp,%ebp
    afe7:	83 ec 48             	sub    $0x48,%esp
    afea:	8b 45 08             	mov    0x8(%ebp),%eax
    afed:	89 45 f4             	mov    %eax,-0xc(%ebp)
    aff0:	8b 45 0c             	mov    0xc(%ebp),%eax
    aff3:	89 45 f0             	mov    %eax,-0x10(%ebp)
    aff6:	8b 45 10             	mov    0x10(%ebp),%eax
    aff9:	89 45 ec             	mov    %eax,-0x14(%ebp)
    affc:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
    b003:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    b00a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b00d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    b013:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    b016:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    b01a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b01d:	83 c0 44             	add    $0x44,%eax
    b020:	89 04 24             	mov    %eax,(%esp)
    b023:	e8 a0 d9 ff ff       	call   89c8 <ck_pr_md_load_uint>
    b028:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    b02b:	e8 a3 e6 ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    b030:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b033:	89 04 24             	mov    %eax,(%esp)
    b036:	e8 8d d9 ff ff       	call   89c8 <ck_pr_md_load_uint>
    b03b:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    b03e:	8b 45 cc             	mov    -0x34(%ebp),%eax
    b041:	83 c0 01             	add    $0x1,%eax
    b044:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    b047:	8b 45 cc             	mov    -0x34(%ebp),%eax
    b04a:	2b 45 d8             	sub    -0x28(%ebp),%eax
    b04d:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    b050:	0f 97 c0             	seta   %al
    b053:	0f b6 c0             	movzbl %al,%eax
    b056:	85 c0                	test   %eax,%eax
    b058:	74 29                	je     b083 <ck_ring_enqueue_mpmc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    b05a:	8b 45 cc             	mov    -0x34(%ebp),%eax
    b05d:	8b 55 f4             	mov    -0xc(%ebp),%edx
    b060:	8d 4a 44             	lea    0x44(%edx),%ecx
    b063:	8d 55 cc             	lea    -0x34(%ebp),%edx
    b066:	89 54 24 0c          	mov    %edx,0xc(%esp)
    b06a:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    b06d:	89 54 24 08          	mov    %edx,0x8(%esp)
    b071:	89 44 24 04          	mov    %eax,0x4(%esp)
    b075:	89 0c 24             	mov    %ecx,(%esp)
    b078:	e8 4c e3 ff ff       	call   93c9 <ck_pr_cas_uint_value>
    b07d:	84 c0                	test   %al,%al
    b07f:	75 31                	jne    b0b2 <ck_ring_enqueue_mpmc_xcpu+0xce>
    b081:	eb a8                	jmp    b02b <ck_ring_enqueue_mpmc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    b083:	e8 4b e6 ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    b088:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b08b:	83 c0 44             	add    $0x44,%eax
    b08e:	89 04 24             	mov    %eax,(%esp)
    b091:	e8 32 d9 ff ff       	call   89c8 <ck_pr_md_load_uint>
    b096:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    b099:	8b 45 cc             	mov    -0x34(%ebp),%eax
    b09c:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    b09f:	75 06                	jne    b0a7 <ck_ring_enqueue_mpmc_xcpu+0xc3>
				r = false;
    b0a1:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    b0a5:	eb 67                	jmp    b10e <ck_ring_enqueue_mpmc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    b0a7:	8b 45 d0             	mov    -0x30(%ebp),%eax
    b0aa:	89 45 cc             	mov    %eax,-0x34(%ebp)
    b0ad:	e9 79 ff ff ff       	jmp    b02b <ck_ring_enqueue_mpmc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    b0b2:	8b 45 cc             	mov    -0x34(%ebp),%eax
    b0b5:	23 45 e0             	and    -0x20(%ebp),%eax
    b0b8:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    b0bc:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    b0bf:	8b 45 e8             	mov    -0x18(%ebp),%eax
    b0c2:	89 44 24 08          	mov    %eax,0x8(%esp)
    b0c6:	8b 45 ec             	mov    -0x14(%ebp),%eax
    b0c9:	89 44 24 04          	mov    %eax,0x4(%esp)
    b0cd:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b0d0:	89 04 24             	mov    %eax,(%esp)
    b0d3:	e8 fc ff ff ff       	call   b0d4 <ck_ring_enqueue_mpmc_xcpu+0xf0>
    b0d8:	eb 05                	jmp    b0df <ck_ring_enqueue_mpmc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    b0da:	e8 84 d7 ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    b0df:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b0e2:	83 c0 40             	add    $0x40,%eax
    b0e5:	89 04 24             	mov    %eax,(%esp)
    b0e8:	e8 db d8 ff ff       	call   89c8 <ck_pr_md_load_uint>
    b0ed:	8b 55 cc             	mov    -0x34(%ebp),%edx
    b0f0:	39 d0                	cmp    %edx,%eax
    b0f2:	75 e6                	jne    b0da <ck_ring_enqueue_mpmc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    b0f4:	e8 e5 e5 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    b0f9:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b0fc:	8d 50 40             	lea    0x40(%eax),%edx
    b0ff:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    b102:	89 44 24 04          	mov    %eax,0x4(%esp)
    b106:	89 14 24             	mov    %edx,(%esp)
    b109:	e8 43 d9 ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    b10e:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    b112:	74 10                	je     b124 <ck_ring_enqueue_mpmc_xcpu+0x140>
		*size = (producer - consumer) & mask;
    b114:	8b 45 cc             	mov    -0x34(%ebp),%eax
    b117:	2b 45 d8             	sub    -0x28(%ebp),%eax
    b11a:	23 45 e0             	and    -0x20(%ebp),%eax
    b11d:	89 c2                	mov    %eax,%edx
    b11f:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    b122:	89 10                	mov    %edx,(%eax)

	return r;
    b124:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    b128:	c9                   	leave  
    b129:	c3                   	ret    

0000b12a <ck_ring_trydequeue_mpmc_xcpu>:
    b12a:	55                   	push   %ebp
    b12b:	89 e5                	mov    %esp,%ebp
    b12d:	83 ec 38             	sub    $0x38,%esp
    b130:	8b 45 08             	mov    0x8(%ebp),%eax
    b133:	89 45 f4             	mov    %eax,-0xc(%ebp)
    b136:	8b 45 0c             	mov    0xc(%ebp),%eax
    b139:	89 45 f0             	mov    %eax,-0x10(%ebp)
    b13c:	8b 45 10             	mov    0x10(%ebp),%eax
    b13f:	89 45 ec             	mov    %eax,-0x14(%ebp)
    b142:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    b149:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b14c:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    b152:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    b155:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b158:	89 04 24             	mov    %eax,(%esp)
    b15b:	e8 68 d8 ff ff       	call   89c8 <ck_pr_md_load_uint>
    b160:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    b163:	e8 6b e5 ff ff       	call   96d3 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    b168:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b16b:	83 c0 40             	add    $0x40,%eax
    b16e:	89 04 24             	mov    %eax,(%esp)
    b171:	e8 52 d8 ff ff       	call   89c8 <ck_pr_md_load_uint>
    b176:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    b179:	8b 45 e0             	mov    -0x20(%ebp),%eax
    b17c:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    b17f:	0f 94 c0             	sete   %al
    b182:	0f b6 c0             	movzbl %al,%eax
    b185:	85 c0                	test   %eax,%eax
    b187:	74 07                	je     b190 <ck_ring_trydequeue_mpmc_xcpu+0x66>
		return false;
    b189:	b8 00 00 00 00       	mov    $0x0,%eax
    b18e:	eb 4e                	jmp    b1de <ck_ring_trydequeue_mpmc_xcpu+0xb4>

	ck_pr_fence_load();
    b190:	e8 3e e5 ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    b195:	8b 45 e0             	mov    -0x20(%ebp),%eax
    b198:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    b19b:	21 d0                	and    %edx,%eax
    b19d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    b1a1:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    b1a4:	8b 45 e8             	mov    -0x18(%ebp),%eax
    b1a7:	89 44 24 08          	mov    %eax,0x8(%esp)
    b1ab:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b1ae:	89 44 24 04          	mov    %eax,0x4(%esp)
    b1b2:	8b 45 ec             	mov    -0x14(%ebp),%eax
    b1b5:	89 04 24             	mov    %eax,(%esp)
    b1b8:	e8 fc ff ff ff       	call   b1b9 <ck_ring_trydequeue_mpmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
    b1bd:	e8 e5 e4 ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    b1c2:	8b 45 e0             	mov    -0x20(%ebp),%eax
    b1c5:	8d 50 01             	lea    0x1(%eax),%edx
    b1c8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b1cb:	89 54 24 08          	mov    %edx,0x8(%esp)
    b1cf:	8b 55 e0             	mov    -0x20(%ebp),%edx
    b1d2:	89 54 24 04          	mov    %edx,0x4(%esp)
    b1d6:	89 04 24             	mov    %eax,(%esp)
    b1d9:	e8 98 e0 ff ff       	call   9276 <ck_pr_cas_uint>
    b1de:	c9                   	leave  
    b1df:	c3                   	ret    

0000b1e0 <ck_ring_dequeue_mpmc_xcpu>:
    b1e0:	55                   	push   %ebp
    b1e1:	89 e5                	mov    %esp,%ebp
    b1e3:	53                   	push   %ebx
    b1e4:	83 ec 34             	sub    $0x34,%esp
    b1e7:	8b 45 08             	mov    0x8(%ebp),%eax
    b1ea:	89 45 f4             	mov    %eax,-0xc(%ebp)
    b1ed:	8b 45 0c             	mov    0xc(%ebp),%eax
    b1f0:	89 45 f0             	mov    %eax,-0x10(%ebp)
    b1f3:	8b 45 10             	mov    0x10(%ebp),%eax
    b1f6:	89 45 ec             	mov    %eax,-0x14(%ebp)
    b1f9:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    b200:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b203:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    b209:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    b20c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b20f:	89 04 24             	mov    %eax,(%esp)
    b212:	e8 b1 d7 ff ff       	call   89c8 <ck_pr_md_load_uint>
    b217:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    b21a:	e8 b4 e4 ff ff       	call   96d3 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    b21f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b222:	83 c0 40             	add    $0x40,%eax
    b225:	89 04 24             	mov    %eax,(%esp)
    b228:	e8 9b d7 ff ff       	call   89c8 <ck_pr_md_load_uint>
    b22d:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    b230:	8b 45 d8             	mov    -0x28(%ebp),%eax
    b233:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    b236:	0f 94 c0             	sete   %al
    b239:	0f b6 c0             	movzbl %al,%eax
    b23c:	85 c0                	test   %eax,%eax
    b23e:	74 07                	je     b247 <ck_ring_dequeue_mpmc_xcpu+0x67>
			return false;
    b240:	b8 00 00 00 00       	mov    $0x0,%eax
    b245:	eb 6a                	jmp    b2b1 <ck_ring_dequeue_mpmc_xcpu+0xd1>

		ck_pr_fence_load();
    b247:	e8 87 e4 ff ff       	call   96d3 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    b24c:	8b 45 d8             	mov    -0x28(%ebp),%eax
    b24f:	23 45 e4             	and    -0x1c(%ebp),%eax
    b252:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    b256:	89 c2                	mov    %eax,%edx
    b258:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b25b:	01 d0                	add    %edx,%eax
    b25d:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    b260:	8b 45 e8             	mov    -0x18(%ebp),%eax
    b263:	89 44 24 08          	mov    %eax,0x8(%esp)
    b267:	8b 45 dc             	mov    -0x24(%ebp),%eax
    b26a:	89 44 24 04          	mov    %eax,0x4(%esp)
    b26e:	8b 45 ec             	mov    -0x14(%ebp),%eax
    b271:	89 04 24             	mov    %eax,(%esp)
    b274:	e8 fc ff ff ff       	call   b275 <ck_ring_dequeue_mpmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    b279:	e8 29 e4 ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    b27e:	8b 45 d8             	mov    -0x28(%ebp),%eax
    b281:	8d 58 01             	lea    0x1(%eax),%ebx
    b284:	8b 55 d8             	mov    -0x28(%ebp),%edx
    b287:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b28a:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    b28d:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    b291:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    b295:	89 54 24 04          	mov    %edx,0x4(%esp)
    b299:	89 04 24             	mov    %eax,(%esp)
    b29c:	e8 28 e1 ff ff       	call   93c9 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    b2a1:	83 f0 01             	xor    $0x1,%eax
    b2a4:	84 c0                	test   %al,%al
    b2a6:	0f 85 6e ff ff ff    	jne    b21a <ck_ring_dequeue_mpmc_xcpu+0x3a>

	return true;
    b2ac:	b8 01 00 00 00       	mov    $0x1,%eax
    b2b1:	83 c4 34             	add    $0x34,%esp
    b2b4:	5b                   	pop    %ebx
    b2b5:	5d                   	pop    %ebp
    b2b6:	c3                   	ret    

0000b2b7 <sl__globals>:

extern struct sl_global sl_global_data;

static inline struct sl_global *
sl__globals(void)
{
    b2b7:	55                   	push   %ebp
    b2b8:	89 e5                	mov    %esp,%ebp
	return &sl_global_data;
    b2ba:	b8 00 00 00 00       	mov    $0x0,%eax
}
    b2bf:	5d                   	pop    %ebp
    b2c0:	c3                   	ret    

0000b2c1 <sl_cpu_active>:

static inline int
sl_cpu_active(void)
{
    b2c1:	55                   	push   %ebp
    b2c2:	89 e5                	mov    %esp,%ebp
    b2c4:	53                   	push   %ebx
    b2c5:	83 ec 08             	sub    $0x8,%esp
        return bitmap_check(sl__globals()->cpu_bmp, cos_cpuid());
    b2c8:	e8 b4 d0 ff ff       	call   8381 <cos_cpuid>
    b2cd:	89 c3                	mov    %eax,%ebx
    b2cf:	e8 e3 ff ff ff       	call   b2b7 <sl__globals>
    b2d4:	05 88 40 02 00       	add    $0x24088,%eax
    b2d9:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    b2dd:	89 04 24             	mov    %eax,(%esp)
    b2e0:	e8 bc ce ff ff       	call   81a1 <bitmap_check>
}
    b2e5:	83 c4 08             	add    $0x8,%esp
    b2e8:	5b                   	pop    %ebx
    b2e9:	5d                   	pop    %ebp
    b2ea:	c3                   	ret    

0000b2eb <sl__ring>:

static inline struct ck_ring *
sl__ring(cpuid_t cpu)
{
    b2eb:	55                   	push   %ebp
    b2ec:	89 e5                	mov    %esp,%ebp
	return &(sl__globals()->xcpu_ring[cpu]);
    b2ee:	e8 c4 ff ff ff       	call   b2b7 <sl__globals>
    b2f3:	89 c2                	mov    %eax,%edx
    b2f5:	8b 45 08             	mov    0x8(%ebp),%eax
    b2f8:	c1 e0 03             	shl    $0x3,%eax
    b2fb:	89 c1                	mov    %eax,%ecx
    b2fd:	c1 e1 04             	shl    $0x4,%ecx
    b300:	01 c8                	add    %ecx,%eax
    b302:	01 d0                	add    %edx,%eax
}
    b304:	5d                   	pop    %ebp
    b305:	c3                   	ret    

0000b306 <sl__ring_curr>:

static inline struct ck_ring *
sl__ring_curr(void)
{
    b306:	55                   	push   %ebp
    b307:	89 e5                	mov    %esp,%ebp
    b309:	83 ec 04             	sub    $0x4,%esp
	return sl__ring(cos_cpuid());
    b30c:	e8 70 d0 ff ff       	call   8381 <cos_cpuid>
    b311:	89 04 24             	mov    %eax,(%esp)
    b314:	e8 d2 ff ff ff       	call   b2eb <sl__ring>
}
    b319:	c9                   	leave  
    b31a:	c3                   	ret    

0000b31b <sl__globals_cpu>:

extern struct sl_global_cpu sl_global_cpu_data[];

static inline struct sl_global_cpu *
sl__globals_cpu(void)
{
    b31b:	55                   	push   %ebp
    b31c:	89 e5                	mov    %esp,%ebp
	return &(sl_global_cpu_data[cos_cpuid()]);
    b31e:	e8 5e d0 ff ff       	call   8381 <cos_cpuid>
    b323:	c1 e0 03             	shl    $0x3,%eax
    b326:	8d 14 c5 00 00 00 00 	lea    0x0(,%eax,8),%edx
    b32d:	29 c2                	sub    %eax,%edx
    b32f:	8d 82 00 00 00 00    	lea    0x0(%edx),%eax
}
    b335:	5d                   	pop    %ebp
    b336:	c3                   	ret    

0000b337 <sl_thd_lkup>:
/* for lazy retrieval of a child component thread in the parent */
extern struct sl_thd *sl_thd_retrieve(thdid_t tid);

static inline struct sl_thd *
sl_thd_lkup(thdid_t tid)
{
    b337:	55                   	push   %ebp
    b338:	89 e5                	mov    %esp,%ebp
    b33a:	83 ec 18             	sub    $0x18,%esp
    b33d:	8b 45 08             	mov    0x8(%ebp),%eax
    b340:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	assert(tid != 0);
    b344:	66 83 7d f4 00       	cmpw   $0x0,-0xc(%ebp)
    b349:	0f 94 c0             	sete   %al
    b34c:	0f b6 c0             	movzbl %al,%eax
    b34f:	85 c0                	test   %eax,%eax
    b351:	74 1c                	je     b36f <sl_thd_lkup+0x38>
    b353:	c7 04 24 a8 18 00 00 	movl   $0x18a8,(%esp)
    b35a:	e8 9d d1 ff ff       	call   84fc <prints>
    b35f:	a1 40 01 00 00       	mov    0x140,%eax
    b364:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b36a:	e8 14 d2 ff ff       	call   8583 <__cos_noret>
	if (unlikely(tid > MAX_NUM_THREADS)) return NULL;
    b36f:	66 83 7d f4 40       	cmpw   $0x40,-0xc(%ebp)
    b374:	0f 97 c0             	seta   %al
    b377:	0f b6 c0             	movzbl %al,%eax
    b37a:	85 c0                	test   %eax,%eax
    b37c:	74 07                	je     b385 <sl_thd_lkup+0x4e>
    b37e:	b8 00 00 00 00       	mov    $0x0,%eax
    b383:	eb 0c                	jmp    b391 <sl_thd_lkup+0x5a>

	return sl_thd_retrieve(tid);
    b385:	0f b7 45 f4          	movzwl -0xc(%ebp),%eax
    b389:	89 04 24             	mov    %eax,(%esp)
    b38c:	e8 fc ff ff ff       	call   b38d <sl_thd_lkup+0x56>
}
    b391:	c9                   	leave  
    b392:	c3                   	ret    

0000b393 <sl_thdid>:
	return t;
}

static inline thdid_t
sl_thdid(void)
{
    b393:	55                   	push   %ebp
    b394:	89 e5                	mov    %esp,%ebp
    b396:	83 ec 28             	sub    $0x28,%esp
	thdid_t tid = cos_thdid();
    b399:	e8 01 d0 ff ff       	call   839f <cos_thdid>
    b39e:	66 89 45 f6          	mov    %ax,-0xa(%ebp)

	assert(tid != 0);
    b3a2:	66 83 7d f6 00       	cmpw   $0x0,-0xa(%ebp)
    b3a7:	0f 94 c0             	sete   %al
    b3aa:	0f b6 c0             	movzbl %al,%eax
    b3ad:	85 c0                	test   %eax,%eax
    b3af:	74 1c                	je     b3cd <sl_thdid+0x3a>
    b3b1:	c7 04 24 fc 18 00 00 	movl   $0x18fc,(%esp)
    b3b8:	e8 3f d1 ff ff       	call   84fc <prints>
    b3bd:	a1 40 01 00 00       	mov    0x140,%eax
    b3c2:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b3c8:	e8 b6 d1 ff ff       	call   8583 <__cos_noret>
	assert(tid < MAX_NUM_THREADS);
    b3cd:	66 83 7d f6 3f       	cmpw   $0x3f,-0xa(%ebp)
    b3d2:	0f 97 c0             	seta   %al
    b3d5:	0f b6 c0             	movzbl %al,%eax
    b3d8:	85 c0                	test   %eax,%eax
    b3da:	74 1c                	je     b3f8 <sl_thdid+0x65>
    b3dc:	c7 04 24 50 19 00 00 	movl   $0x1950,(%esp)
    b3e3:	e8 14 d1 ff ff       	call   84fc <prints>
    b3e8:	a1 40 01 00 00       	mov    0x140,%eax
    b3ed:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b3f3:	e8 8b d1 ff ff       	call   8583 <__cos_noret>

	return tid;
    b3f8:	0f b7 45 f6          	movzwl -0xa(%ebp),%eax
}
    b3fc:	c9                   	leave  
    b3fd:	c3                   	ret    

0000b3fe <sl_thd_curr>:


static inline struct sl_thd *
sl_thd_curr(void)
{
    b3fe:	55                   	push   %ebp
    b3ff:	89 e5                	mov    %esp,%ebp
    b401:	83 ec 18             	sub    $0x18,%esp
	return sl_thd_lkup(sl_thdid());
    b404:	e8 8a ff ff ff       	call   b393 <sl_thdid>
    b409:	0f b7 c0             	movzwl %ax,%eax
    b40c:	89 04 24             	mov    %eax,(%esp)
    b40f:	e8 23 ff ff ff       	call   b337 <sl_thd_lkup>
}
    b414:	c9                   	leave  
    b415:	c3                   	ret    

0000b416 <sl_cs_owner>:

/* are we the owner of the critical section? */
static inline int
sl_cs_owner(void)
{
    b416:	55                   	push   %ebp
    b417:	89 e5                	mov    %esp,%ebp
    b419:	53                   	push   %ebx
    b41a:	83 ec 14             	sub    $0x14,%esp
	return sl__globals_cpu()->lock.u.s.owner == sl_thd_thdcap(sl_thd_curr());
    b41d:	e8 f9 fe ff ff       	call   b31b <sl__globals_cpu>
    b422:	8b 00                	mov    (%eax),%eax
    b424:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
    b429:	89 c3                	mov    %eax,%ebx
    b42b:	e8 ce ff ff ff       	call   b3fe <sl_thd_curr>
    b430:	89 04 24             	mov    %eax,(%esp)
    b433:	e8 25 d3 ff ff       	call   875d <sl_thd_thdcap>
    b438:	39 c3                	cmp    %eax,%ebx
    b43a:	0f 94 c0             	sete   %al
    b43d:	0f b6 c0             	movzbl %al,%eax
}
    b440:	83 c4 14             	add    $0x14,%esp
    b443:	5b                   	pop    %ebx
    b444:	5d                   	pop    %ebp
    b445:	c3                   	ret    

0000b446 <sl_cs_enter_nospin>:
int sl_cs_exit_contention(union sl_cs_intern *csi, union sl_cs_intern *cached, sched_tok_t tok);

/* Enter into the scheduler critical section */
static inline int
sl_cs_enter_nospin(void)
{
    b446:	55                   	push   %ebp
    b447:	89 e5                	mov    %esp,%ebp
    b449:	56                   	push   %esi
    b44a:	53                   	push   %ebx
    b44b:	83 ec 20             	sub    $0x20,%esp
	union sl_cs_intern csi, cached;
	struct sl_thd *    t = sl_thd_curr();
    b44e:	e8 ab ff ff ff       	call   b3fe <sl_thd_curr>
    b453:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sched_tok_t        tok;

	assert(t);
    b456:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    b45a:	0f 94 c0             	sete   %al
    b45d:	0f b6 c0             	movzbl %al,%eax
    b460:	85 c0                	test   %eax,%eax
    b462:	74 1c                	je     b480 <sl_cs_enter_nospin+0x3a>
    b464:	c7 04 24 a4 19 00 00 	movl   $0x19a4,(%esp)
    b46b:	e8 8c d0 ff ff       	call   84fc <prints>
    b470:	a1 40 01 00 00       	mov    0x140,%eax
    b475:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b47b:	e8 03 d1 ff ff       	call   8583 <__cos_noret>
	tok      = cos_sched_sync();
    b480:	e8 fc ff ff ff       	call   b481 <sl_cs_enter_nospin+0x3b>
    b485:	89 45 f0             	mov    %eax,-0x10(%ebp)
	csi.v    = sl__globals_cpu()->lock.u.v;
    b488:	e8 8e fe ff ff       	call   b31b <sl__globals_cpu>
    b48d:	8b 00                	mov    (%eax),%eax
    b48f:	89 45 ec             	mov    %eax,-0x14(%ebp)
	cached.v = csi.v;
    b492:	8b 45 ec             	mov    -0x14(%ebp),%eax
    b495:	89 45 e8             	mov    %eax,-0x18(%ebp)

	if (unlikely(csi.s.owner)) {
    b498:	8b 45 ec             	mov    -0x14(%ebp),%eax
    b49b:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
    b4a0:	85 c0                	test   %eax,%eax
    b4a2:	0f 95 c0             	setne  %al
    b4a5:	0f b6 c0             	movzbl %al,%eax
    b4a8:	85 c0                	test   %eax,%eax
    b4aa:	74 2a                	je     b4d6 <sl_cs_enter_nospin+0x90>
		return sl_cs_enter_contention(&csi, &cached, sl_thd_thdcap(t), tok);
    b4ac:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b4af:	89 04 24             	mov    %eax,(%esp)
    b4b2:	e8 a6 d2 ff ff       	call   875d <sl_thd_thdcap>
    b4b7:	8b 55 f0             	mov    -0x10(%ebp),%edx
    b4ba:	89 54 24 0c          	mov    %edx,0xc(%esp)
    b4be:	89 44 24 08          	mov    %eax,0x8(%esp)
    b4c2:	8d 45 e8             	lea    -0x18(%ebp),%eax
    b4c5:	89 44 24 04          	mov    %eax,0x4(%esp)
    b4c9:	8d 45 ec             	lea    -0x14(%ebp),%eax
    b4cc:	89 04 24             	mov    %eax,(%esp)
    b4cf:	e8 fc ff ff ff       	call   b4d0 <sl_cs_enter_nospin+0x8a>
    b4d4:	eb 4f                	jmp    b525 <sl_cs_enter_nospin+0xdf>
	}

	csi.s.owner = sl_thd_thdcap(t);
    b4d6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b4d9:	89 04 24             	mov    %eax,(%esp)
    b4dc:	e8 7c d2 ff ff       	call   875d <sl_thd_thdcap>
    b4e1:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
    b4e6:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
    b4eb:	89 c2                	mov    %eax,%edx
    b4ed:	8b 45 ec             	mov    -0x14(%ebp),%eax
    b4f0:	25 00 00 00 80       	and    $0x80000000,%eax
    b4f5:	09 d0                	or     %edx,%eax
    b4f7:	89 45 ec             	mov    %eax,-0x14(%ebp)
	if (!ps_cas(&sl__globals_cpu()->lock.u.v, cached.v, csi.v)) return 1;
    b4fa:	8b 75 ec             	mov    -0x14(%ebp),%esi
    b4fd:	8b 5d e8             	mov    -0x18(%ebp),%ebx
    b500:	e8 16 fe ff ff       	call   b31b <sl__globals_cpu>
    b505:	89 74 24 08          	mov    %esi,0x8(%esp)
    b509:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    b50d:	89 04 24             	mov    %eax,(%esp)
    b510:	e8 53 ca ff ff       	call   7f68 <ps_cas>
    b515:	85 c0                	test   %eax,%eax
    b517:	75 07                	jne    b520 <sl_cs_enter_nospin+0xda>
    b519:	b8 01 00 00 00       	mov    $0x1,%eax
    b51e:	eb 05                	jmp    b525 <sl_cs_enter_nospin+0xdf>

	return 0;
    b520:	b8 00 00 00 00       	mov    $0x0,%eax
}
    b525:	83 c4 20             	add    $0x20,%esp
    b528:	5b                   	pop    %ebx
    b529:	5e                   	pop    %esi
    b52a:	5d                   	pop    %ebp
    b52b:	c3                   	ret    

0000b52c <sl_cs_enter>:

/* Enter into scheduler cs from a non-sched thread context */
static inline void
sl_cs_enter(void)
{
    b52c:	55                   	push   %ebp
    b52d:	89 e5                	mov    %esp,%ebp
    b52f:	83 ec 08             	sub    $0x8,%esp
	while (sl_cs_enter_nospin())
    b532:	90                   	nop
    b533:	e8 0e ff ff ff       	call   b446 <sl_cs_enter_nospin>
    b538:	85 c0                	test   %eax,%eax
    b53a:	75 f7                	jne    b533 <sl_cs_enter+0x7>
		;
}
    b53c:	c9                   	leave  
    b53d:	c3                   	ret    

0000b53e <sl_cs_enter_sched>:
 * Enter into scheduler cs from scheduler thread context
 * @ret: returns -EBUSY if sched thread has events to process and cannot switch threads, 0 otherwise.
 */
static inline int
sl_cs_enter_sched(void)
{
    b53e:	55                   	push   %ebp
    b53f:	89 e5                	mov    %esp,%ebp
    b541:	83 ec 18             	sub    $0x18,%esp
	int ret;

	while ((ret = sl_cs_enter_nospin())) {
    b544:	eb 08                	jmp    b54e <sl_cs_enter_sched+0x10>
		if (ret == -EBUSY) break;
    b546:	83 7d f4 f0          	cmpl   $0xfffffff0,-0xc(%ebp)
    b54a:	75 02                	jne    b54e <sl_cs_enter_sched+0x10>
    b54c:	eb 0e                	jmp    b55c <sl_cs_enter_sched+0x1e>
static inline int
sl_cs_enter_sched(void)
{
	int ret;

	while ((ret = sl_cs_enter_nospin())) {
    b54e:	e8 f3 fe ff ff       	call   b446 <sl_cs_enter_nospin>
    b553:	89 45 f4             	mov    %eax,-0xc(%ebp)
    b556:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    b55a:	75 ea                	jne    b546 <sl_cs_enter_sched+0x8>
		if (ret == -EBUSY) break;
	}

	return ret;
    b55c:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    b55f:	c9                   	leave  
    b560:	c3                   	ret    

0000b561 <sl_cs_exit>:
 * Release the scheduler critical section, switch to the scheduler
 * thread if there is pending contention
 */
static inline void
sl_cs_exit(void)
{
    b561:	55                   	push   %ebp
    b562:	89 e5                	mov    %esp,%ebp
    b564:	53                   	push   %ebx
    b565:	83 ec 24             	sub    $0x24,%esp
	union sl_cs_intern csi, cached;
	sched_tok_t        tok;

	assert(sl_cs_owner());
    b568:	e8 a9 fe ff ff       	call   b416 <sl_cs_owner>
    b56d:	85 c0                	test   %eax,%eax
    b56f:	0f 94 c0             	sete   %al
    b572:	0f b6 c0             	movzbl %al,%eax
    b575:	85 c0                	test   %eax,%eax
    b577:	74 1c                	je     b595 <sl_cs_exit+0x34>
    b579:	c7 04 24 f8 19 00 00 	movl   $0x19f8,(%esp)
    b580:	e8 77 cf ff ff       	call   84fc <prints>
    b585:	a1 40 01 00 00       	mov    0x140,%eax
    b58a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b590:	e8 ee cf ff ff       	call   8583 <__cos_noret>

retry:
	tok      = cos_sched_sync();
    b595:	e8 fc ff ff ff       	call   b596 <sl_cs_exit+0x35>
    b59a:	89 45 f4             	mov    %eax,-0xc(%ebp)
	csi.v    = sl__globals_cpu()->lock.u.v;
    b59d:	e8 79 fd ff ff       	call   b31b <sl__globals_cpu>
    b5a2:	8b 00                	mov    (%eax),%eax
    b5a4:	89 45 f0             	mov    %eax,-0x10(%ebp)
	cached.v = csi.v;
    b5a7:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b5aa:	89 45 ec             	mov    %eax,-0x14(%ebp)

	if (unlikely(csi.s.contention)) {
    b5ad:	0f b6 45 f3          	movzbl -0xd(%ebp),%eax
    b5b1:	c0 e8 07             	shr    $0x7,%al
    b5b4:	0f b6 c0             	movzbl %al,%eax
    b5b7:	85 c0                	test   %eax,%eax
    b5b9:	74 1f                	je     b5da <sl_cs_exit+0x79>
		if (sl_cs_exit_contention(&csi, &cached, tok)) goto retry;
    b5bb:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b5be:	89 44 24 08          	mov    %eax,0x8(%esp)
    b5c2:	8d 45 ec             	lea    -0x14(%ebp),%eax
    b5c5:	89 44 24 04          	mov    %eax,0x4(%esp)
    b5c9:	8d 45 f0             	lea    -0x10(%ebp),%eax
    b5cc:	89 04 24             	mov    %eax,(%esp)
    b5cf:	e8 fc ff ff ff       	call   b5d0 <sl_cs_exit+0x6f>
    b5d4:	85 c0                	test   %eax,%eax
    b5d6:	74 24                	je     b5fc <sl_cs_exit+0x9b>
    b5d8:	eb bb                	jmp    b595 <sl_cs_exit+0x34>
		return;
	}

	if (!ps_cas(&sl__globals_cpu()->lock.u.v, cached.v, 0)) goto retry;
    b5da:	8b 5d ec             	mov    -0x14(%ebp),%ebx
    b5dd:	e8 39 fd ff ff       	call   b31b <sl__globals_cpu>
    b5e2:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    b5e9:	00 
    b5ea:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    b5ee:	89 04 24             	mov    %eax,(%esp)
    b5f1:	e8 72 c9 ff ff       	call   7f68 <ps_cas>
    b5f6:	85 c0                	test   %eax,%eax
    b5f8:	75 02                	jne    b5fc <sl_cs_exit+0x9b>
    b5fa:	eb 99                	jmp    b595 <sl_cs_exit+0x34>
}
    b5fc:	83 c4 24             	add    $0x24,%esp
    b5ff:	5b                   	pop    %ebx
    b600:	5d                   	pop    %ebp
    b601:	c3                   	ret    

0000b602 <sl_usec2cyc>:
	return cyc / sl__globals_cpu()->cyc_per_usec;
}

static inline cycles_t
sl_usec2cyc(microsec_t usec)
{
    b602:	55                   	push   %ebp
    b603:	89 e5                	mov    %esp,%ebp
    b605:	53                   	push   %ebx
    b606:	83 ec 0c             	sub    $0xc,%esp
    b609:	8b 45 08             	mov    0x8(%ebp),%eax
    b60c:	89 45 f0             	mov    %eax,-0x10(%ebp)
    b60f:	8b 45 0c             	mov    0xc(%ebp),%eax
    b612:	89 45 f4             	mov    %eax,-0xc(%ebp)
	return usec * sl__globals_cpu()->cyc_per_usec;
    b615:	e8 01 fd ff ff       	call   b31b <sl__globals_cpu>
    b61a:	8b 40 18             	mov    0x18(%eax),%eax
    b61d:	99                   	cltd   
    b61e:	8b 4d f0             	mov    -0x10(%ebp),%ecx
    b621:	89 cb                	mov    %ecx,%ebx
    b623:	0f af da             	imul   %edx,%ebx
    b626:	8b 4d f4             	mov    -0xc(%ebp),%ecx
    b629:	0f af c8             	imul   %eax,%ecx
    b62c:	01 d9                	add    %ebx,%ecx
    b62e:	f7 65 f0             	mull   -0x10(%ebp)
    b631:	01 d1                	add    %edx,%ecx
    b633:	89 ca                	mov    %ecx,%edx
}
    b635:	83 c4 0c             	add    $0xc,%esp
    b638:	5b                   	pop    %ebx
    b639:	5d                   	pop    %ebp
    b63a:	c3                   	ret    

0000b63b <sl_now>:

static inline cycles_t
sl_now(void)
{
    b63b:	55                   	push   %ebp
    b63c:	89 e5                	mov    %esp,%ebp
	return ps_tsc();
    b63e:	e8 64 c9 ff ff       	call   7fa7 <ps_tsc>
}
    b643:	5d                   	pop    %ebp
    b644:	c3                   	ret    

0000b645 <sl_timeout_period_get>:
 */
void sl_timeout_period(cycles_t period);

static inline cycles_t
sl_timeout_period_get(void)
{
    b645:	55                   	push   %ebp
    b646:	89 e5                	mov    %esp,%ebp
	return sl__globals_cpu()->period;
    b648:	e8 ce fc ff ff       	call   b31b <sl__globals_cpu>
    b64d:	8b 50 20             	mov    0x20(%eax),%edx
    b650:	8b 40 1c             	mov    0x1c(%eax),%eax
}
    b653:	5d                   	pop    %ebp
    b654:	c3                   	ret    

0000b655 <sl_timeout_oneshot>:

static inline void
sl_timeout_oneshot(cycles_t absolute_us)
{
    b655:	55                   	push   %ebp
    b656:	89 e5                	mov    %esp,%ebp
    b658:	53                   	push   %ebx
    b659:	83 ec 14             	sub    $0x14,%esp
    b65c:	8b 45 08             	mov    0x8(%ebp),%eax
    b65f:	89 45 f0             	mov    %eax,-0x10(%ebp)
    b662:	8b 45 0c             	mov    0xc(%ebp),%eax
    b665:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl__globals_cpu()->timer_next   = absolute_us;
    b668:	e8 ae fc ff ff       	call   b31b <sl__globals_cpu>
    b66d:	89 c1                	mov    %eax,%ecx
    b66f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b672:	8b 55 f4             	mov    -0xc(%ebp),%edx
    b675:	89 41 24             	mov    %eax,0x24(%ecx)
    b678:	89 51 28             	mov    %edx,0x28(%ecx)
	sl__globals_cpu()->timeout_next = tcap_cyc2time(absolute_us);
    b67b:	e8 9b fc ff ff       	call   b31b <sl__globals_cpu>
    b680:	89 c3                	mov    %eax,%ebx
    b682:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b685:	8b 55 f4             	mov    -0xc(%ebp),%edx
    b688:	89 04 24             	mov    %eax,(%esp)
    b68b:	89 54 24 04          	mov    %edx,0x4(%esp)
    b68f:	e8 b8 c9 ff ff       	call   804c <tcap_cyc2time>
    b694:	89 43 2c             	mov    %eax,0x2c(%ebx)
}
    b697:	83 c4 14             	add    $0x14,%esp
    b69a:	5b                   	pop    %ebx
    b69b:	5d                   	pop    %ebp
    b69c:	c3                   	ret    

0000b69d <sl_timeout_relative>:

static inline void
sl_timeout_relative(cycles_t offset)
{
    b69d:	55                   	push   %ebp
    b69e:	89 e5                	mov    %esp,%ebp
    b6a0:	53                   	push   %ebx
    b6a1:	83 ec 14             	sub    $0x14,%esp
    b6a4:	8b 45 08             	mov    0x8(%ebp),%eax
    b6a7:	89 45 f0             	mov    %eax,-0x10(%ebp)
    b6aa:	8b 45 0c             	mov    0xc(%ebp),%eax
    b6ad:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_timeout_oneshot(sl_now() + offset);
    b6b0:	e8 86 ff ff ff       	call   b63b <sl_now>
    b6b5:	8b 4d f0             	mov    -0x10(%ebp),%ecx
    b6b8:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    b6bb:	01 c8                	add    %ecx,%eax
    b6bd:	11 da                	adc    %ebx,%edx
    b6bf:	89 04 24             	mov    %eax,(%esp)
    b6c2:	89 54 24 04          	mov    %edx,0x4(%esp)
    b6c6:	e8 8a ff ff ff       	call   b655 <sl_timeout_oneshot>
}
    b6cb:	83 c4 14             	add    $0x14,%esp
    b6ce:	5b                   	pop    %ebx
    b6cf:	5d                   	pop    %ebp
    b6d0:	c3                   	ret    

0000b6d1 <sl_timeout_expended>:

static inline void
sl_timeout_expended(microsec_t now, microsec_t oldtimeout)
{
    b6d1:	55                   	push   %ebp
    b6d2:	89 e5                	mov    %esp,%ebp
    b6d4:	56                   	push   %esi
    b6d5:	53                   	push   %ebx
    b6d6:	83 ec 30             	sub    $0x30,%esp
    b6d9:	8b 45 08             	mov    0x8(%ebp),%eax
    b6dc:	89 45 e0             	mov    %eax,-0x20(%ebp)
    b6df:	8b 45 0c             	mov    0xc(%ebp),%eax
    b6e2:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    b6e5:	8b 45 10             	mov    0x10(%ebp),%eax
    b6e8:	89 45 d8             	mov    %eax,-0x28(%ebp)
    b6eb:	8b 45 14             	mov    0x14(%ebp),%eax
    b6ee:	89 45 dc             	mov    %eax,-0x24(%ebp)
	cycles_t offset;

	assert(now >= oldtimeout);
    b6f1:	b9 01 00 00 00       	mov    $0x1,%ecx
    b6f6:	8b 45 e0             	mov    -0x20(%ebp),%eax
    b6f9:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    b6fc:	3b 55 dc             	cmp    -0x24(%ebp),%edx
    b6ff:	72 0f                	jb     b710 <sl_timeout_expended+0x3f>
    b701:	3b 55 dc             	cmp    -0x24(%ebp),%edx
    b704:	77 05                	ja     b70b <sl_timeout_expended+0x3a>
    b706:	3b 45 d8             	cmp    -0x28(%ebp),%eax
    b709:	72 05                	jb     b710 <sl_timeout_expended+0x3f>
    b70b:	b9 00 00 00 00       	mov    $0x0,%ecx
    b710:	0f b6 c1             	movzbl %cl,%eax
    b713:	85 c0                	test   %eax,%eax
    b715:	74 1c                	je     b733 <sl_timeout_expended+0x62>
    b717:	c7 04 24 4c 1a 00 00 	movl   $0x1a4c,(%esp)
    b71e:	e8 d9 cd ff ff       	call   84fc <prints>
    b723:	a1 40 01 00 00       	mov    0x140,%eax
    b728:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b72e:	e8 50 ce ff ff       	call   8583 <__cos_noret>

	/* in virtual environments, or with very small periods, we might miss more than one period */
	offset = (now - oldtimeout) % sl_timeout_period_get();
    b733:	8b 4d d8             	mov    -0x28(%ebp),%ecx
    b736:	8b 5d dc             	mov    -0x24(%ebp),%ebx
    b739:	8b 45 e0             	mov    -0x20(%ebp),%eax
    b73c:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    b73f:	29 c8                	sub    %ecx,%eax
    b741:	19 da                	sbb    %ebx,%edx
    b743:	89 c3                	mov    %eax,%ebx
    b745:	89 d6                	mov    %edx,%esi
    b747:	e8 f9 fe ff ff       	call   b645 <sl_timeout_period_get>
    b74c:	89 44 24 08          	mov    %eax,0x8(%esp)
    b750:	89 54 24 0c          	mov    %edx,0xc(%esp)
    b754:	89 1c 24             	mov    %ebx,(%esp)
    b757:	89 74 24 04          	mov    %esi,0x4(%esp)
    b75b:	e8 fc ff ff ff       	call   b75c <sl_timeout_expended+0x8b>
    b760:	89 45 f0             	mov    %eax,-0x10(%ebp)
    b763:	89 55 f4             	mov    %edx,-0xc(%ebp)
	sl_timeout_oneshot(now + sl_timeout_period_get() - offset);
    b766:	e8 da fe ff ff       	call   b645 <sl_timeout_period_get>
    b76b:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    b76e:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
    b771:	01 c8                	add    %ecx,%eax
    b773:	11 da                	adc    %ebx,%edx
    b775:	2b 45 f0             	sub    -0x10(%ebp),%eax
    b778:	1b 55 f4             	sbb    -0xc(%ebp),%edx
    b77b:	89 04 24             	mov    %eax,(%esp)
    b77e:	89 54 24 04          	mov    %edx,0x4(%esp)
    b782:	e8 ce fe ff ff       	call   b655 <sl_timeout_oneshot>
}
    b787:	83 c4 30             	add    $0x30,%esp
    b78a:	5b                   	pop    %ebx
    b78b:	5e                   	pop    %esi
    b78c:	5d                   	pop    %ebp
    b78d:	c3                   	ret    

0000b78e <sl_timeout_wakeup_expired>:
struct heap *sl_timeout_heap(void);

/* wakeup any blocked threads! */
static inline void
sl_timeout_wakeup_expired(cycles_t now)
{
    b78e:	55                   	push   %ebp
    b78f:	89 e5                	mov    %esp,%ebp
    b791:	83 ec 28             	sub    $0x28,%esp
    b794:	8b 45 08             	mov    0x8(%ebp),%eax
    b797:	89 45 e0             	mov    %eax,-0x20(%ebp)
    b79a:	8b 45 0c             	mov    0xc(%ebp),%eax
    b79d:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	if (!heap_size(sl_timeout_heap())) return;
    b7a0:	e8 fc ff ff ff       	call   b7a1 <sl_timeout_wakeup_expired+0x13>
    b7a5:	89 04 24             	mov    %eax,(%esp)
    b7a8:	e8 fc ff ff ff       	call   b7a9 <sl_timeout_wakeup_expired+0x1b>
    b7ad:	85 c0                	test   %eax,%eax
    b7af:	75 05                	jne    b7b6 <sl_timeout_wakeup_expired+0x28>
    b7b1:	e9 1e 01 00 00       	jmp    b8d4 <sl_timeout_wakeup_expired+0x146>

	do {
		struct sl_thd *tp, *th;

		tp = heap_peek(sl_timeout_heap());
    b7b6:	e8 fc ff ff ff       	call   b7b7 <sl_timeout_wakeup_expired+0x29>
    b7bb:	89 04 24             	mov    %eax,(%esp)
    b7be:	e8 fc ff ff ff       	call   b7bf <sl_timeout_wakeup_expired+0x31>
    b7c3:	89 45 f4             	mov    %eax,-0xc(%ebp)
		assert(tp);
    b7c6:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    b7ca:	0f 94 c0             	sete   %al
    b7cd:	0f b6 c0             	movzbl %al,%eax
    b7d0:	85 c0                	test   %eax,%eax
    b7d2:	74 1c                	je     b7f0 <sl_timeout_wakeup_expired+0x62>
    b7d4:	c7 04 24 a0 1a 00 00 	movl   $0x1aa0,(%esp)
    b7db:	e8 1c cd ff ff       	call   84fc <prints>
    b7e0:	a1 40 01 00 00       	mov    0x140,%eax
    b7e5:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b7eb:	e8 93 cd ff ff       	call   8583 <__cos_noret>

		/* FIXME: logic for wraparound in current tsc */
		if (likely(tp->timeout_cycs > now)) break;
    b7f0:	8b 45 f4             	mov    -0xc(%ebp),%eax
    b7f3:	8b 50 50             	mov    0x50(%eax),%edx
    b7f6:	8b 40 4c             	mov    0x4c(%eax),%eax
    b7f9:	b9 01 00 00 00       	mov    $0x1,%ecx
    b7fe:	3b 55 e4             	cmp    -0x1c(%ebp),%edx
    b801:	77 0f                	ja     b812 <sl_timeout_wakeup_expired+0x84>
    b803:	3b 55 e4             	cmp    -0x1c(%ebp),%edx
    b806:	72 05                	jb     b80d <sl_timeout_wakeup_expired+0x7f>
    b808:	3b 45 e0             	cmp    -0x20(%ebp),%eax
    b80b:	77 05                	ja     b812 <sl_timeout_wakeup_expired+0x84>
    b80d:	b9 00 00 00 00       	mov    $0x0,%ecx
    b812:	0f b6 c1             	movzbl %cl,%eax
    b815:	85 c0                	test   %eax,%eax
    b817:	74 05                	je     b81e <sl_timeout_wakeup_expired+0x90>
    b819:	e9 b6 00 00 00       	jmp    b8d4 <sl_timeout_wakeup_expired+0x146>

		th = heap_highest(sl_timeout_heap());
    b81e:	e8 fc ff ff ff       	call   b81f <sl_timeout_wakeup_expired+0x91>
    b823:	89 04 24             	mov    %eax,(%esp)
    b826:	e8 fc ff ff ff       	call   b827 <sl_timeout_wakeup_expired+0x99>
    b82b:	89 45 f0             	mov    %eax,-0x10(%ebp)
		assert(th && th == tp);
    b82e:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    b832:	0f 94 c0             	sete   %al
    b835:	0f b6 c0             	movzbl %al,%eax
    b838:	85 c0                	test   %eax,%eax
    b83a:	75 10                	jne    b84c <sl_timeout_wakeup_expired+0xbe>
    b83c:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b83f:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    b842:	0f 95 c0             	setne  %al
    b845:	0f b6 c0             	movzbl %al,%eax
    b848:	85 c0                	test   %eax,%eax
    b84a:	74 1c                	je     b868 <sl_timeout_wakeup_expired+0xda>
    b84c:	c7 04 24 f4 1a 00 00 	movl   $0x1af4,(%esp)
    b853:	e8 a4 cc ff ff       	call   84fc <prints>
    b858:	a1 40 01 00 00       	mov    0x140,%eax
    b85d:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b863:	e8 1b cd ff ff       	call   8583 <__cos_noret>
		th->timeout_idx = -1;
    b868:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b86b:	c7 40 5c ff ff ff ff 	movl   $0xffffffff,0x5c(%eax)

		assert(th->wakeup_cycs == 0);
    b872:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b875:	8b 50 58             	mov    0x58(%eax),%edx
    b878:	8b 40 54             	mov    0x54(%eax),%eax
    b87b:	09 d0                	or     %edx,%eax
    b87d:	85 c0                	test   %eax,%eax
    b87f:	0f 95 c0             	setne  %al
    b882:	0f b6 c0             	movzbl %al,%eax
    b885:	85 c0                	test   %eax,%eax
    b887:	74 1c                	je     b8a5 <sl_timeout_wakeup_expired+0x117>
    b889:	c7 04 24 48 1b 00 00 	movl   $0x1b48,(%esp)
    b890:	e8 67 cc ff ff       	call   84fc <prints>
    b895:	a1 40 01 00 00       	mov    0x140,%eax
    b89a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    b8a0:	e8 de cc ff ff       	call   8583 <__cos_noret>
		th->wakeup_cycs = now;
    b8a5:	8b 4d f0             	mov    -0x10(%ebp),%ecx
    b8a8:	8b 45 e0             	mov    -0x20(%ebp),%eax
    b8ab:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    b8ae:	89 41 54             	mov    %eax,0x54(%ecx)
    b8b1:	89 51 58             	mov    %edx,0x58(%ecx)
		sl_thd_wakeup_no_cs_rm(th);
    b8b4:	8b 45 f0             	mov    -0x10(%ebp),%eax
    b8b7:	89 04 24             	mov    %eax,(%esp)
    b8ba:	e8 fc ff ff ff       	call   b8bb <sl_timeout_wakeup_expired+0x12d>
	} while (heap_size(sl_timeout_heap()));
    b8bf:	e8 fc ff ff ff       	call   b8c0 <sl_timeout_wakeup_expired+0x132>
    b8c4:	89 04 24             	mov    %eax,(%esp)
    b8c7:	e8 fc ff ff ff       	call   b8c8 <sl_timeout_wakeup_expired+0x13a>
    b8cc:	85 c0                	test   %eax,%eax
    b8ce:	0f 85 e2 fe ff ff    	jne    b7b6 <sl_timeout_wakeup_expired+0x28>
}
    b8d4:	c9                   	leave  
    b8d5:	c3                   	ret    

0000b8d6 <sl_thd_is_runnable>:

static inline int
sl_thd_is_runnable(struct sl_thd *t)
{
    b8d6:	55                   	push   %ebp
    b8d7:	89 e5                	mov    %esp,%ebp
	return (t->state == SL_THD_RUNNABLE || t->state == SL_THD_WOKEN);
    b8d9:	8b 45 08             	mov    0x8(%ebp),%eax
    b8dc:	8b 00                	mov    (%eax),%eax
    b8de:	83 f8 04             	cmp    $0x4,%eax
    b8e1:	74 0a                	je     b8ed <sl_thd_is_runnable+0x17>
    b8e3:	8b 45 08             	mov    0x8(%ebp),%eax
    b8e6:	8b 00                	mov    (%eax),%eax
    b8e8:	83 f8 03             	cmp    $0x3,%eax
    b8eb:	75 07                	jne    b8f4 <sl_thd_is_runnable+0x1e>
    b8ed:	b8 01 00 00 00       	mov    $0x1,%eax
    b8f2:	eb 05                	jmp    b8f9 <sl_thd_is_runnable+0x23>
    b8f4:	b8 00 00 00 00       	mov    $0x0,%eax
}
    b8f9:	5d                   	pop    %ebp
    b8fa:	c3                   	ret    

0000b8fb <sl_thd_activate>:

static inline int
sl_thd_activate(struct sl_thd *t, sched_tok_t tok)
{
    b8fb:	55                   	push   %ebp
    b8fc:	89 e5                	mov    %esp,%ebp
    b8fe:	57                   	push   %edi
    b8ff:	56                   	push   %esi
    b900:	53                   	push   %ebx
    b901:	83 ec 4c             	sub    $0x4c,%esp
	struct cos_defcompinfo *dci = cos_defcompinfo_curr_get();
    b904:	e8 fc ff ff ff       	call   b905 <sl_thd_activate+0xa>
    b909:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	struct cos_compinfo    *ci  = &dci->ci;
    b90c:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    b90f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	struct sl_global_cpu   *g   = sl__globals_cpu();
    b912:	e8 04 fa ff ff       	call   b31b <sl__globals_cpu>
    b917:	89 45 dc             	mov    %eax,-0x24(%ebp)
	int ret = 0;
    b91a:	c7 45 d8 00 00 00 00 	movl   $0x0,-0x28(%ebp)

	if (t->properties & SL_THD_PROPERTY_SEND) {
    b921:	8b 45 08             	mov    0x8(%ebp),%eax
    b924:	8b 40 08             	mov    0x8(%eax),%eax
    b927:	83 e0 02             	and    $0x2,%eax
    b92a:	85 c0                	test   %eax,%eax
    b92c:	74 2e                	je     b95c <sl_thd_activate+0x61>
		return cos_sched_asnd(t->sndcap, g->timeout_next, g->sched_rcv, tok);
    b92e:	8b 45 dc             	mov    -0x24(%ebp),%eax
    b931:	8b 48 0c             	mov    0xc(%eax),%ecx
    b934:	8b 45 dc             	mov    -0x24(%ebp),%eax
    b937:	8b 50 2c             	mov    0x2c(%eax),%edx
    b93a:	8b 45 08             	mov    0x8(%ebp),%eax
    b93d:	8b 40 10             	mov    0x10(%eax),%eax
    b940:	8b 5d 0c             	mov    0xc(%ebp),%ebx
    b943:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    b947:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    b94b:	89 54 24 04          	mov    %edx,0x4(%esp)
    b94f:	89 04 24             	mov    %eax,(%esp)
    b952:	e8 fc ff ff ff       	call   b953 <sl_thd_activate+0x58>
    b957:	e9 3e 01 00 00       	jmp    ba9a <sl_thd_activate+0x19f>
	} else if (t->properties & SL_THD_PROPERTY_OWN_TCAP) {
    b95c:	8b 45 08             	mov    0x8(%ebp),%eax
    b95f:	8b 40 08             	mov    0x8(%eax),%eax
    b962:	83 e0 01             	and    $0x1,%eax
    b965:	85 c0                	test   %eax,%eax
    b967:	74 61                	je     b9ca <sl_thd_activate+0xcf>
		return cos_switch(sl_thd_thdcap(t), sl_thd_tcap(t), t->prio,
    b969:	8b 45 dc             	mov    -0x24(%ebp),%eax
    b96c:	8b 40 0c             	mov    0xc(%eax),%eax
    b96f:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    b972:	8b 45 dc             	mov    -0x24(%ebp),%eax
    b975:	8b 70 2c             	mov    0x2c(%eax),%esi
    b978:	89 75 d0             	mov    %esi,-0x30(%ebp)
    b97b:	8b 45 08             	mov    0x8(%ebp),%eax
    b97e:	8b 58 28             	mov    0x28(%eax),%ebx
    b981:	8b 70 2c             	mov    0x2c(%eax),%esi
    b984:	8b 45 08             	mov    0x8(%ebp),%eax
    b987:	89 04 24             	mov    %eax,(%esp)
    b98a:	e8 e4 cd ff ff       	call   8773 <sl_thd_tcap>
    b98f:	89 c7                	mov    %eax,%edi
    b991:	8b 45 08             	mov    0x8(%ebp),%eax
    b994:	89 04 24             	mov    %eax,(%esp)
    b997:	e8 c1 cd ff ff       	call   875d <sl_thd_thdcap>
    b99c:	8b 55 0c             	mov    0xc(%ebp),%edx
    b99f:	89 54 24 18          	mov    %edx,0x18(%esp)
    b9a3:	8b 4d d4             	mov    -0x2c(%ebp),%ecx
    b9a6:	89 4c 24 14          	mov    %ecx,0x14(%esp)
    b9aa:	8b 4d d0             	mov    -0x30(%ebp),%ecx
    b9ad:	89 4c 24 10          	mov    %ecx,0x10(%esp)
    b9b1:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    b9b5:	89 74 24 0c          	mov    %esi,0xc(%esp)
    b9b9:	89 7c 24 04          	mov    %edi,0x4(%esp)
    b9bd:	89 04 24             	mov    %eax,(%esp)
    b9c0:	e8 fc ff ff ff       	call   b9c1 <sl_thd_activate+0xc6>
    b9c5:	e9 d0 00 00 00       	jmp    ba9a <sl_thd_activate+0x19f>
				  g->timeout_next, g->sched_rcv, tok);
	} else {
		ret = cos_defswitch(sl_thd_thdcap(t), t->prio, t == g->sched_thd ?
    b9ca:	8b 45 dc             	mov    -0x24(%ebp),%eax
    b9cd:	8b 40 10             	mov    0x10(%eax),%eax
    b9d0:	3b 45 08             	cmp    0x8(%ebp),%eax
    b9d3:	74 08                	je     b9dd <sl_thd_activate+0xe2>
    b9d5:	8b 45 dc             	mov    -0x24(%ebp),%eax
    b9d8:	8b 78 2c             	mov    0x2c(%eax),%edi
    b9db:	eb 05                	jmp    b9e2 <sl_thd_activate+0xe7>
    b9dd:	bf 00 00 00 00       	mov    $0x0,%edi
    b9e2:	8b 45 08             	mov    0x8(%ebp),%eax
    b9e5:	8b 58 28             	mov    0x28(%eax),%ebx
    b9e8:	8b 70 2c             	mov    0x2c(%eax),%esi
    b9eb:	8b 45 08             	mov    0x8(%ebp),%eax
    b9ee:	89 04 24             	mov    %eax,(%esp)
    b9f1:	e8 67 cd ff ff       	call   875d <sl_thd_thdcap>
    b9f6:	8b 55 0c             	mov    0xc(%ebp),%edx
    b9f9:	89 54 24 10          	mov    %edx,0x10(%esp)
    b9fd:	89 7c 24 0c          	mov    %edi,0xc(%esp)
    ba01:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    ba05:	89 74 24 08          	mov    %esi,0x8(%esp)
    ba09:	89 04 24             	mov    %eax,(%esp)
    ba0c:	e8 fc ff ff ff       	call   ba0d <sl_thd_activate+0x112>
    ba11:	89 45 d8             	mov    %eax,-0x28(%ebp)
				    TCAP_TIME_NIL : g->timeout_next, tok);
		if (likely(t != g->sched_thd && t != g->idle_thd)) return ret;
    ba14:	8b 45 dc             	mov    -0x24(%ebp),%eax
    ba17:	8b 40 10             	mov    0x10(%eax),%eax
    ba1a:	3b 45 08             	cmp    0x8(%ebp),%eax
    ba1d:	0f 95 c0             	setne  %al
    ba20:	0f b6 c0             	movzbl %al,%eax
    ba23:	85 c0                	test   %eax,%eax
    ba25:	74 18                	je     ba3f <sl_thd_activate+0x144>
    ba27:	8b 45 dc             	mov    -0x24(%ebp),%eax
    ba2a:	8b 40 14             	mov    0x14(%eax),%eax
    ba2d:	3b 45 08             	cmp    0x8(%ebp),%eax
    ba30:	0f 95 c0             	setne  %al
    ba33:	0f b6 c0             	movzbl %al,%eax
    ba36:	85 c0                	test   %eax,%eax
    ba38:	74 05                	je     ba3f <sl_thd_activate+0x144>
    ba3a:	8b 45 d8             	mov    -0x28(%ebp),%eax
    ba3d:	eb 5b                	jmp    ba9a <sl_thd_activate+0x19f>
		if (unlikely(ret != -EPERM)) return ret;
    ba3f:	83 7d d8 ff          	cmpl   $0xffffffff,-0x28(%ebp)
    ba43:	0f 95 c0             	setne  %al
    ba46:	0f b6 c0             	movzbl %al,%eax
    ba49:	85 c0                	test   %eax,%eax
    ba4b:	74 05                	je     ba52 <sl_thd_activate+0x157>
    ba4d:	8b 45 d8             	mov    -0x28(%ebp),%eax
    ba50:	eb 48                	jmp    ba9a <sl_thd_activate+0x19f>

		/*
		 * Attempting to activate scheduler thread or idle thread failed for no budget in it's tcap.
		 * Force switch to the scheduler with current tcap.
		 */
		return cos_switch(sl_thd_thdcap(g->sched_thd), 0, t->prio, 0, g->sched_rcv, tok);
    ba52:	8b 45 dc             	mov    -0x24(%ebp),%eax
    ba55:	8b 78 0c             	mov    0xc(%eax),%edi
    ba58:	8b 45 08             	mov    0x8(%ebp),%eax
    ba5b:	8b 58 28             	mov    0x28(%eax),%ebx
    ba5e:	8b 70 2c             	mov    0x2c(%eax),%esi
    ba61:	8b 45 dc             	mov    -0x24(%ebp),%eax
    ba64:	8b 40 10             	mov    0x10(%eax),%eax
    ba67:	89 04 24             	mov    %eax,(%esp)
    ba6a:	e8 ee cc ff ff       	call   875d <sl_thd_thdcap>
    ba6f:	8b 55 0c             	mov    0xc(%ebp),%edx
    ba72:	89 54 24 18          	mov    %edx,0x18(%esp)
    ba76:	89 7c 24 14          	mov    %edi,0x14(%esp)
    ba7a:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    ba81:	00 
    ba82:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    ba86:	89 74 24 0c          	mov    %esi,0xc(%esp)
    ba8a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    ba91:	00 
    ba92:	89 04 24             	mov    %eax,(%esp)
    ba95:	e8 fc ff ff ff       	call   ba96 <sl_thd_activate+0x19b>
	}
}
    ba9a:	83 c4 4c             	add    $0x4c,%esp
    ba9d:	5b                   	pop    %ebx
    ba9e:	5e                   	pop    %esi
    ba9f:	5f                   	pop    %edi
    baa0:	5d                   	pop    %ebp
    baa1:	c3                   	ret    

0000baa2 <sl_cs_exit_schedule_nospin_arg>:
 * ...which correctly handles any race-conditions on thread selection and
 * dispatch.
 */
static inline int
sl_cs_exit_schedule_nospin_arg(struct sl_thd *to)
{
    baa2:	55                   	push   %ebp
    baa3:	89 e5                	mov    %esp,%ebp
    baa5:	57                   	push   %edi
    baa6:	56                   	push   %esi
    baa7:	53                   	push   %ebx
    baa8:	83 ec 6c             	sub    $0x6c,%esp
	struct cos_defcompinfo *dci = cos_defcompinfo_curr_get();
    baab:	e8 fc ff ff ff       	call   baac <sl_cs_exit_schedule_nospin_arg+0xa>
    bab0:	89 45 dc             	mov    %eax,-0x24(%ebp)
	struct cos_compinfo    *ci = &dci->ci;
    bab3:	8b 45 dc             	mov    -0x24(%ebp),%eax
    bab6:	89 45 d8             	mov    %eax,-0x28(%ebp)
	struct sl_thd_policy   *pt;
	struct sl_thd *         t;
	struct sl_global_cpu   *globals = sl__globals_cpu();
    bab9:	e8 5d f8 ff ff       	call   b31b <sl__globals_cpu>
    babe:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	cycles_t                now;
	s64_t                   offset;
	int                     ret;

	/* Don't abuse this, it is only to enable the tight loop around this function for races... */
	if (unlikely(!sl_cs_owner())) sl_cs_enter();
    bac1:	e8 50 f9 ff ff       	call   b416 <sl_cs_owner>
    bac6:	85 c0                	test   %eax,%eax
    bac8:	0f 94 c0             	sete   %al
    bacb:	0f b6 c0             	movzbl %al,%eax
    bace:	85 c0                	test   %eax,%eax
    bad0:	74 05                	je     bad7 <sl_cs_exit_schedule_nospin_arg+0x35>
    bad2:	e8 55 fa ff ff       	call   b52c <sl_cs_enter>

	tok    = cos_sched_sync();
    bad7:	e8 fc ff ff ff       	call   bad8 <sl_cs_exit_schedule_nospin_arg+0x36>
    badc:	89 45 d0             	mov    %eax,-0x30(%ebp)
	now    = sl_now();
    badf:	e8 57 fb ff ff       	call   b63b <sl_now>
    bae4:	89 45 c8             	mov    %eax,-0x38(%ebp)
    bae7:	89 55 cc             	mov    %edx,-0x34(%ebp)
	offset = (s64_t)(globals->timer_next - now);
    baea:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    baed:	8b 50 28             	mov    0x28(%eax),%edx
    baf0:	8b 40 24             	mov    0x24(%eax),%eax
    baf3:	2b 45 c8             	sub    -0x38(%ebp),%eax
    baf6:	1b 55 cc             	sbb    -0x34(%ebp),%edx
    baf9:	89 45 c0             	mov    %eax,-0x40(%ebp)
    bafc:	89 55 c4             	mov    %edx,-0x3c(%ebp)
	if (globals->timer_next && offset <= 0) sl_timeout_expended(now, globals->timer_next);
    baff:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    bb02:	8b 50 28             	mov    0x28(%eax),%edx
    bb05:	8b 40 24             	mov    0x24(%eax),%eax
    bb08:	09 d0                	or     %edx,%eax
    bb0a:	85 c0                	test   %eax,%eax
    bb0c:	74 35                	je     bb43 <sl_cs_exit_schedule_nospin_arg+0xa1>
    bb0e:	83 7d c4 00          	cmpl   $0x0,-0x3c(%ebp)
    bb12:	7f 2f                	jg     bb43 <sl_cs_exit_schedule_nospin_arg+0xa1>
    bb14:	83 7d c4 00          	cmpl   $0x0,-0x3c(%ebp)
    bb18:	78 06                	js     bb20 <sl_cs_exit_schedule_nospin_arg+0x7e>
    bb1a:	83 7d c0 00          	cmpl   $0x0,-0x40(%ebp)
    bb1e:	77 23                	ja     bb43 <sl_cs_exit_schedule_nospin_arg+0xa1>
    bb20:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    bb23:	8b 50 28             	mov    0x28(%eax),%edx
    bb26:	8b 40 24             	mov    0x24(%eax),%eax
    bb29:	89 44 24 08          	mov    %eax,0x8(%esp)
    bb2d:	89 54 24 0c          	mov    %edx,0xc(%esp)
    bb31:	8b 45 c8             	mov    -0x38(%ebp),%eax
    bb34:	8b 55 cc             	mov    -0x34(%ebp),%edx
    bb37:	89 04 24             	mov    %eax,(%esp)
    bb3a:	89 54 24 04          	mov    %edx,0x4(%esp)
    bb3e:	e8 8e fb ff ff       	call   b6d1 <sl_timeout_expended>
	sl_timeout_wakeup_expired(now);
    bb43:	8b 45 c8             	mov    -0x38(%ebp),%eax
    bb46:	8b 55 cc             	mov    -0x34(%ebp),%edx
    bb49:	89 04 24             	mov    %eax,(%esp)
    bb4c:	89 54 24 04          	mov    %edx,0x4(%esp)
    bb50:	e8 39 fc ff ff       	call   b78e <sl_timeout_wakeup_expired>
	 * deallocated/modified, so cache it locally.  If these values
	 * are out of date, the scheduler synchronization tok will
	 * catch it.  This is a little twitchy and subtle, so lets put
	 * it in a function, here.
	 */
	if (unlikely(to)) {
    bb55:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    bb59:	0f 95 c0             	setne  %al
    bb5c:	0f b6 c0             	movzbl %al,%eax
    bb5f:	85 c0                	test   %eax,%eax
    bb61:	74 1c                	je     bb7f <sl_cs_exit_schedule_nospin_arg+0xdd>
		t = to;
    bb63:	8b 45 08             	mov    0x8(%ebp),%eax
    bb66:	89 45 e4             	mov    %eax,-0x1c(%ebp)
		if (!sl_thd_is_runnable(t)) to = NULL;
    bb69:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bb6c:	89 04 24             	mov    %eax,(%esp)
    bb6f:	e8 62 fd ff ff       	call   b8d6 <sl_thd_is_runnable>
    bb74:	85 c0                	test   %eax,%eax
    bb76:	75 07                	jne    bb7f <sl_cs_exit_schedule_nospin_arg+0xdd>
    bb78:	c7 45 08 00 00 00 00 	movl   $0x0,0x8(%ebp)
	}
	if (likely(!to)) {
    bb7f:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    bb83:	0f 94 c0             	sete   %al
    bb86:	0f b6 c0             	movzbl %al,%eax
    bb89:	85 c0                	test   %eax,%eax
    bb8b:	74 2f                	je     bbbc <sl_cs_exit_schedule_nospin_arg+0x11a>
		pt = sl_mod_schedule();
    bb8d:	e8 fc ff ff ff       	call   bb8e <sl_cs_exit_schedule_nospin_arg+0xec>
    bb92:	89 45 bc             	mov    %eax,-0x44(%ebp)
		if (unlikely(!pt))
    bb95:	83 7d bc 00          	cmpl   $0x0,-0x44(%ebp)
    bb99:	0f 94 c0             	sete   %al
    bb9c:	0f b6 c0             	movzbl %al,%eax
    bb9f:	85 c0                	test   %eax,%eax
    bba1:	74 0b                	je     bbae <sl_cs_exit_schedule_nospin_arg+0x10c>
			t = globals->idle_thd;
    bba3:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    bba6:	8b 40 14             	mov    0x14(%eax),%eax
    bba9:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    bbac:	eb 0e                	jmp    bbbc <sl_cs_exit_schedule_nospin_arg+0x11a>
		else
			t = sl_mod_thd_get(pt);
    bbae:	8b 45 bc             	mov    -0x44(%ebp),%eax
    bbb1:	89 04 24             	mov    %eax,(%esp)
    bbb4:	e8 e5 cb ff ff       	call   879e <sl_mod_thd_get>
    bbb9:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	}

	if (t->properties & SL_THD_PROPERTY_OWN_TCAP && t->budget) {
    bbbc:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bbbf:	8b 40 08             	mov    0x8(%eax),%eax
    bbc2:	83 e0 01             	and    $0x1,%eax
    bbc5:	85 c0                	test   %eax,%eax
    bbc7:	0f 84 33 02 00 00    	je     be00 <sl_cs_exit_schedule_nospin_arg+0x35e>
    bbcd:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bbd0:	8b 40 30             	mov    0x30(%eax),%eax
    bbd3:	85 c0                	test   %eax,%eax
    bbd5:	0f 84 25 02 00 00    	je     be00 <sl_cs_exit_schedule_nospin_arg+0x35e>
		assert(t->period);
    bbdb:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bbde:	8b 50 40             	mov    0x40(%eax),%edx
    bbe1:	8b 40 3c             	mov    0x3c(%eax),%eax
    bbe4:	09 d0                	or     %edx,%eax
    bbe6:	85 c0                	test   %eax,%eax
    bbe8:	0f 94 c0             	sete   %al
    bbeb:	0f b6 c0             	movzbl %al,%eax
    bbee:	85 c0                	test   %eax,%eax
    bbf0:	74 1c                	je     bc0e <sl_cs_exit_schedule_nospin_arg+0x16c>
    bbf2:	c7 04 24 9c 1b 00 00 	movl   $0x1b9c,(%esp)
    bbf9:	e8 fe c8 ff ff       	call   84fc <prints>
    bbfe:	a1 40 01 00 00       	mov    0x140,%eax
    bc03:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    bc09:	e8 75 c9 ff ff       	call   8583 <__cos_noret>
		assert(sl_thd_tcap(t) != globals->sched_tcap);
    bc0e:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bc11:	89 04 24             	mov    %eax,(%esp)
    bc14:	e8 5a cb ff ff       	call   8773 <sl_thd_tcap>
    bc19:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    bc1c:	8b 52 08             	mov    0x8(%edx),%edx
    bc1f:	39 d0                	cmp    %edx,%eax
    bc21:	0f 94 c0             	sete   %al
    bc24:	0f b6 c0             	movzbl %al,%eax
    bc27:	85 c0                	test   %eax,%eax
    bc29:	74 1c                	je     bc47 <sl_cs_exit_schedule_nospin_arg+0x1a5>
    bc2b:	c7 04 24 f0 1b 00 00 	movl   $0x1bf0,(%esp)
    bc32:	e8 c5 c8 ff ff       	call   84fc <prints>
    bc37:	a1 40 01 00 00       	mov    0x140,%eax
    bc3c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    bc42:	e8 3c c9 ff ff       	call   8583 <__cos_noret>

		if (t->last_replenish == 0 || t->last_replenish + t->period <= now) {
    bc47:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bc4a:	8b 50 38             	mov    0x38(%eax),%edx
    bc4d:	8b 40 34             	mov    0x34(%eax),%eax
    bc50:	09 d0                	or     %edx,%eax
    bc52:	85 c0                	test   %eax,%eax
    bc54:	74 2d                	je     bc83 <sl_cs_exit_schedule_nospin_arg+0x1e1>
    bc56:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bc59:	8b 48 34             	mov    0x34(%eax),%ecx
    bc5c:	8b 58 38             	mov    0x38(%eax),%ebx
    bc5f:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bc62:	8b 50 40             	mov    0x40(%eax),%edx
    bc65:	8b 40 3c             	mov    0x3c(%eax),%eax
    bc68:	01 c8                	add    %ecx,%eax
    bc6a:	11 da                	adc    %ebx,%edx
    bc6c:	3b 55 cc             	cmp    -0x34(%ebp),%edx
    bc6f:	0f 87 8b 01 00 00    	ja     be00 <sl_cs_exit_schedule_nospin_arg+0x35e>
    bc75:	3b 55 cc             	cmp    -0x34(%ebp),%edx
    bc78:	72 09                	jb     bc83 <sl_cs_exit_schedule_nospin_arg+0x1e1>
    bc7a:	3b 45 c8             	cmp    -0x38(%ebp),%eax
    bc7d:	0f 87 7d 01 00 00    	ja     be00 <sl_cs_exit_schedule_nospin_arg+0x35e>
			tcap_res_t currbudget = 0;
    bc83:	c7 45 b8 00 00 00 00 	movl   $0x0,-0x48(%ebp)
			cycles_t replenish    = now - ((now - t->last_replenish) % t->period);
    bc8a:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bc8d:	8b 48 34             	mov    0x34(%eax),%ecx
    bc90:	8b 58 38             	mov    0x38(%eax),%ebx
    bc93:	8b 45 c8             	mov    -0x38(%ebp),%eax
    bc96:	8b 55 cc             	mov    -0x34(%ebp),%edx
    bc99:	29 c8                	sub    %ecx,%eax
    bc9b:	19 da                	sbb    %ebx,%edx
    bc9d:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
    bca0:	8b 59 40             	mov    0x40(%ecx),%ebx
    bca3:	8b 49 3c             	mov    0x3c(%ecx),%ecx
    bca6:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    bcaa:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    bcae:	89 04 24             	mov    %eax,(%esp)
    bcb1:	89 54 24 04          	mov    %edx,0x4(%esp)
    bcb5:	e8 fc ff ff ff       	call   bcb6 <sl_cs_exit_schedule_nospin_arg+0x214>
    bcba:	89 c1                	mov    %eax,%ecx
    bcbc:	89 d3                	mov    %edx,%ebx
    bcbe:	8b 45 c8             	mov    -0x38(%ebp),%eax
    bcc1:	8b 55 cc             	mov    -0x34(%ebp),%edx
    bcc4:	29 c8                	sub    %ecx,%eax
    bcc6:	19 da                	sbb    %ebx,%edx
    bcc8:	89 45 b0             	mov    %eax,-0x50(%ebp)
    bccb:	89 55 b4             	mov    %edx,-0x4c(%ebp)

			ret = 0;
    bcce:	c7 45 e0 00 00 00 00 	movl   $0x0,-0x20(%ebp)
			currbudget = (tcap_res_t)cos_introspect(ci, sl_thd_tcap(t), TCAP_GET_BUDGET);
    bcd5:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bcd8:	89 04 24             	mov    %eax,(%esp)
    bcdb:	e8 93 ca ff ff       	call   8773 <sl_thd_tcap>
    bce0:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    bce7:	00 
    bce8:	89 44 24 04          	mov    %eax,0x4(%esp)
    bcec:	8b 45 d8             	mov    -0x28(%ebp),%eax
    bcef:	89 04 24             	mov    %eax,(%esp)
    bcf2:	e8 fc ff ff ff       	call   bcf3 <sl_cs_exit_schedule_nospin_arg+0x251>
    bcf7:	89 45 b8             	mov    %eax,-0x48(%ebp)

			if (!cycles_same(currbudget, t->budget, SL_CYCS_DIFF) && currbudget < t->budget) {
    bcfa:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bcfd:	8b 40 30             	mov    0x30(%eax),%eax
    bd00:	89 c1                	mov    %eax,%ecx
    bd02:	bb 00 00 00 00       	mov    $0x0,%ebx
    bd07:	8b 45 b8             	mov    -0x48(%ebp),%eax
    bd0a:	ba 00 00 00 00       	mov    $0x0,%edx
    bd0f:	c7 44 24 10 00 40 00 	movl   $0x4000,0x10(%esp)
    bd16:	00 
    bd17:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
    bd1e:	00 
    bd1f:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    bd23:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    bd27:	89 04 24             	mov    %eax,(%esp)
    bd2a:	89 54 24 04          	mov    %edx,0x4(%esp)
    bd2e:	e8 4d c3 ff ff       	call   8080 <cycles_same>
    bd33:	85 c0                	test   %eax,%eax
    bd35:	0f 85 a8 00 00 00    	jne    bde3 <sl_cs_exit_schedule_nospin_arg+0x341>
    bd3b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bd3e:	8b 40 30             	mov    0x30(%eax),%eax
    bd41:	3b 45 b8             	cmp    -0x48(%ebp),%eax
    bd44:	0f 86 99 00 00 00    	jbe    bde3 <sl_cs_exit_schedule_nospin_arg+0x341>
				tcap_res_t transfer = t->budget - currbudget;
    bd4a:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bd4d:	8b 40 30             	mov    0x30(%eax),%eax
    bd50:	2b 45 b8             	sub    -0x48(%ebp),%eax
    bd53:	89 45 ac             	mov    %eax,-0x54(%ebp)

				/* tcap_transfer will assign sched_tcap's prio to t's tcap if t->prio == 0, which we don't want. */
				assert(t->prio >= TCAP_PRIO_MAX && t->prio <= TCAP_PRIO_MIN);
    bd56:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bd59:	8b 50 2c             	mov    0x2c(%eax),%edx
    bd5c:	8b 40 28             	mov    0x28(%eax),%eax
    bd5f:	09 d0                	or     %edx,%eax
    bd61:	85 c0                	test   %eax,%eax
    bd63:	0f 94 c0             	sete   %al
    bd66:	0f b6 c0             	movzbl %al,%eax
    bd69:	85 c0                	test   %eax,%eax
    bd6b:	75 22                	jne    bd8f <sl_cs_exit_schedule_nospin_arg+0x2ed>
    bd6d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bd70:	8b 50 2c             	mov    0x2c(%eax),%edx
    bd73:	8b 40 28             	mov    0x28(%eax),%eax
    bd76:	b9 01 00 00 00       	mov    $0x1,%ecx
    bd7b:	81 fa ff ff 00 00    	cmp    $0xffff,%edx
    bd81:	77 05                	ja     bd88 <sl_cs_exit_schedule_nospin_arg+0x2e6>
    bd83:	b9 00 00 00 00       	mov    $0x0,%ecx
    bd88:	0f b6 c1             	movzbl %cl,%eax
    bd8b:	85 c0                	test   %eax,%eax
    bd8d:	74 1c                	je     bdab <sl_cs_exit_schedule_nospin_arg+0x309>
    bd8f:	c7 04 24 44 1c 00 00 	movl   $0x1c44,(%esp)
    bd96:	e8 61 c7 ff ff       	call   84fc <prints>
    bd9b:	a1 40 01 00 00       	mov    0x140,%eax
    bda0:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    bda6:	e8 d8 c7 ff ff       	call   8583 <__cos_noret>
				ret = cos_tcap_transfer(sl_thd_rcvcap(t), globals->sched_tcap, transfer, t->prio);
    bdab:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bdae:	8b 58 28             	mov    0x28(%eax),%ebx
    bdb1:	8b 70 2c             	mov    0x2c(%eax),%esi
    bdb4:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    bdb7:	8b 78 08             	mov    0x8(%eax),%edi
    bdba:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bdbd:	89 04 24             	mov    %eax,(%esp)
    bdc0:	e8 c3 c9 ff ff       	call   8788 <sl_thd_rcvcap>
    bdc5:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    bdc9:	89 74 24 10          	mov    %esi,0x10(%esp)
    bdcd:	8b 55 ac             	mov    -0x54(%ebp),%edx
    bdd0:	89 54 24 08          	mov    %edx,0x8(%esp)
    bdd4:	89 7c 24 04          	mov    %edi,0x4(%esp)
    bdd8:	89 04 24             	mov    %eax,(%esp)
    bddb:	e8 fc ff ff ff       	call   bddc <sl_cs_exit_schedule_nospin_arg+0x33a>
    bde0:	89 45 e0             	mov    %eax,-0x20(%ebp)
			}

			if (likely(ret == 0)) t->last_replenish = replenish;
    bde3:	83 7d e0 00          	cmpl   $0x0,-0x20(%ebp)
    bde7:	0f 94 c0             	sete   %al
    bdea:	0f b6 c0             	movzbl %al,%eax
    bded:	85 c0                	test   %eax,%eax
    bdef:	74 0f                	je     be00 <sl_cs_exit_schedule_nospin_arg+0x35e>
    bdf1:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
    bdf4:	8b 45 b0             	mov    -0x50(%ebp),%eax
    bdf7:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    bdfa:	89 41 34             	mov    %eax,0x34(%ecx)
    bdfd:	89 51 38             	mov    %edx,0x38(%ecx)
		}
	}

	assert(sl_thd_is_runnable(t));
    be00:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    be03:	89 04 24             	mov    %eax,(%esp)
    be06:	e8 cb fa ff ff       	call   b8d6 <sl_thd_is_runnable>
    be0b:	85 c0                	test   %eax,%eax
    be0d:	0f 94 c0             	sete   %al
    be10:	0f b6 c0             	movzbl %al,%eax
    be13:	85 c0                	test   %eax,%eax
    be15:	74 1c                	je     be33 <sl_cs_exit_schedule_nospin_arg+0x391>
    be17:	c7 04 24 98 1c 00 00 	movl   $0x1c98,(%esp)
    be1e:	e8 d9 c6 ff ff       	call   84fc <prints>
    be23:	a1 40 01 00 00       	mov    0x140,%eax
    be28:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    be2e:	e8 50 c7 ff ff       	call   8583 <__cos_noret>
	sl_cs_exit();
    be33:	e8 29 f7 ff ff       	call   b561 <sl_cs_exit>

	ret = sl_thd_activate(t, tok);
    be38:	8b 45 d0             	mov    -0x30(%ebp),%eax
    be3b:	89 44 24 04          	mov    %eax,0x4(%esp)
    be3f:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    be42:	89 04 24             	mov    %eax,(%esp)
    be45:	e8 b1 fa ff ff       	call   b8fb <sl_thd_activate>
    be4a:	89 45 e0             	mov    %eax,-0x20(%ebp)
	 * Block the thread until it's next replenishment and return to the scheduler thread.
	 *
	 * If the thread is not replenished by the scheduler (replenished "only" by
	 * the inter-component delegations), block till next timeout and try again.
	 */
	if (unlikely(ret == -EPERM)) {
    be4d:	83 7d e0 ff          	cmpl   $0xffffffff,-0x20(%ebp)
    be51:	0f 94 c0             	sete   %al
    be54:	0f b6 c0             	movzbl %al,%eax
    be57:	85 c0                	test   %eax,%eax
    be59:	74 7c                	je     bed7 <sl_cs_exit_schedule_nospin_arg+0x435>
		assert(t != globals->sched_thd && t != globals->idle_thd);
    be5b:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    be5e:	8b 40 10             	mov    0x10(%eax),%eax
    be61:	3b 45 e4             	cmp    -0x1c(%ebp),%eax
    be64:	0f 94 c0             	sete   %al
    be67:	0f b6 c0             	movzbl %al,%eax
    be6a:	85 c0                	test   %eax,%eax
    be6c:	75 13                	jne    be81 <sl_cs_exit_schedule_nospin_arg+0x3df>
    be6e:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    be71:	8b 40 14             	mov    0x14(%eax),%eax
    be74:	3b 45 e4             	cmp    -0x1c(%ebp),%eax
    be77:	0f 94 c0             	sete   %al
    be7a:	0f b6 c0             	movzbl %al,%eax
    be7d:	85 c0                	test   %eax,%eax
    be7f:	74 1c                	je     be9d <sl_cs_exit_schedule_nospin_arg+0x3fb>
    be81:	c7 04 24 ec 1c 00 00 	movl   $0x1cec,(%esp)
    be88:	e8 6f c6 ff ff       	call   84fc <prints>
    be8d:	a1 40 01 00 00       	mov    0x140,%eax
    be92:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    be98:	e8 e6 c6 ff ff       	call   8583 <__cos_noret>
		sl_thd_block_expiry(t);
    be9d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    bea0:	89 04 24             	mov    %eax,(%esp)
    bea3:	e8 fc ff ff ff       	call   bea4 <sl_cs_exit_schedule_nospin_arg+0x402>
		if (unlikely(sl_thd_curr() != globals->sched_thd)) ret = sl_thd_activate(globals->sched_thd, tok);
    bea8:	e8 51 f5 ff ff       	call   b3fe <sl_thd_curr>
    bead:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    beb0:	8b 52 10             	mov    0x10(%edx),%edx
    beb3:	39 d0                	cmp    %edx,%eax
    beb5:	0f 95 c0             	setne  %al
    beb8:	0f b6 c0             	movzbl %al,%eax
    bebb:	85 c0                	test   %eax,%eax
    bebd:	74 18                	je     bed7 <sl_cs_exit_schedule_nospin_arg+0x435>
    bebf:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    bec2:	8b 40 10             	mov    0x10(%eax),%eax
    bec5:	8b 55 d0             	mov    -0x30(%ebp),%edx
    bec8:	89 54 24 04          	mov    %edx,0x4(%esp)
    becc:	89 04 24             	mov    %eax,(%esp)
    becf:	e8 27 fa ff ff       	call   b8fb <sl_thd_activate>
    bed4:	89 45 e0             	mov    %eax,-0x20(%ebp)
	}

	return ret;
    bed7:	8b 45 e0             	mov    -0x20(%ebp),%eax
}
    beda:	83 c4 6c             	add    $0x6c,%esp
    bedd:	5b                   	pop    %ebx
    bede:	5e                   	pop    %esi
    bedf:	5f                   	pop    %edi
    bee0:	5d                   	pop    %ebp
    bee1:	c3                   	ret    

0000bee2 <sl_cs_exit_schedule_nospin>:

static inline int
sl_cs_exit_schedule_nospin(void)
{
    bee2:	55                   	push   %ebp
    bee3:	89 e5                	mov    %esp,%ebp
    bee5:	83 ec 18             	sub    $0x18,%esp
	return sl_cs_exit_schedule_nospin_arg(NULL);
    bee8:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    beef:	e8 ae fb ff ff       	call   baa2 <sl_cs_exit_schedule_nospin_arg>
}
    bef4:	c9                   	leave  
    bef5:	c3                   	ret    

0000bef6 <sl_cs_exit_schedule>:

static inline void
sl_cs_exit_schedule(void)
{
    bef6:	55                   	push   %ebp
    bef7:	89 e5                	mov    %esp,%ebp
    bef9:	83 ec 08             	sub    $0x8,%esp
	while (sl_cs_exit_schedule_nospin())
    befc:	90                   	nop
    befd:	e8 e0 ff ff ff       	call   bee2 <sl_cs_exit_schedule_nospin>
    bf02:	85 c0                	test   %eax,%eax
    bf04:	75 f7                	jne    befd <sl_cs_exit_schedule+0x7>
		;
}
    bf06:	c9                   	leave  
    bf07:	c3                   	ret    

0000bf08 <sl_cs_exit_switchto>:

static inline void
sl_cs_exit_switchto(struct sl_thd *to)
{
    bf08:	55                   	push   %ebp
    bf09:	89 e5                	mov    %esp,%ebp
    bf0b:	83 ec 18             	sub    $0x18,%esp
	 * We only try once, so it is possible that we don't end up
	 * switching to the desired thread.  However, this is always a
	 * case that the caller has to consider if the current thread
	 * has a higher priority than the "to" thread.
	 */
	if (sl_cs_exit_schedule_nospin_arg(to)) {
    bf0e:	8b 45 08             	mov    0x8(%ebp),%eax
    bf11:	89 04 24             	mov    %eax,(%esp)
    bf14:	e8 89 fb ff ff       	call   baa2 <sl_cs_exit_schedule_nospin_arg>
    bf19:	85 c0                	test   %eax,%eax
    bf1b:	74 05                	je     bf22 <sl_cs_exit_switchto+0x1a>
		sl_cs_exit_schedule();
    bf1d:	e8 d4 ff ff ff       	call   bef6 <sl_cs_exit_schedule>
	}
}
    bf22:	c9                   	leave  
    bf23:	c3                   	ret    

0000bf24 <ck_ring_enqueue_spsc_size_child>:
struct sl_child_notification {
	sl_child_notif_t type;
	thdid_t          tid;
};

CK_RING_PROTOTYPE(child, sl_child_notification);
    bf24:	55                   	push   %ebp
    bf25:	89 e5                	mov    %esp,%ebp
    bf27:	83 ec 58             	sub    $0x58,%esp
    bf2a:	8b 45 08             	mov    0x8(%ebp),%eax
    bf2d:	89 45 f4             	mov    %eax,-0xc(%ebp)
    bf30:	8b 45 0c             	mov    0xc(%ebp),%eax
    bf33:	89 45 f0             	mov    %eax,-0x10(%ebp)
    bf36:	8b 45 10             	mov    0x10(%ebp),%eax
    bf39:	89 45 ec             	mov    %eax,-0x14(%ebp)
    bf3c:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
    bf43:	8b 45 14             	mov    0x14(%ebp),%eax
    bf46:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    bf49:	8b 45 f4             	mov    -0xc(%ebp),%eax
    bf4c:	89 45 e0             	mov    %eax,-0x20(%ebp)
    bf4f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    bf52:	89 45 dc             	mov    %eax,-0x24(%ebp)
    bf55:	8b 45 ec             	mov    -0x14(%ebp),%eax
    bf58:	89 45 d8             	mov    %eax,-0x28(%ebp)
    bf5b:	8b 45 e8             	mov    -0x18(%ebp),%eax
    bf5e:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    bf61:	8d 45 b8             	lea    -0x48(%ebp),%eax
    bf64:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    bf67:	8b 45 e0             	mov    -0x20(%ebp),%eax
    bf6a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    bf70:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    bf73:	8b 45 e0             	mov    -0x20(%ebp),%eax
    bf76:	89 04 24             	mov    %eax,(%esp)
    bf79:	e8 4a ca ff ff       	call   89c8 <ck_pr_md_load_uint>
    bf7e:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    bf81:	8b 45 e0             	mov    -0x20(%ebp),%eax
    bf84:	8b 40 40             	mov    0x40(%eax),%eax
    bf87:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    bf8a:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    bf8d:	83 c0 01             	add    $0x1,%eax
    bf90:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    bf93:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    bf97:	74 14                	je     bfad <ck_ring_enqueue_spsc_size_child+0x89>
		*size = (producer - consumer) & mask;
    bf99:	8b 45 c8             	mov    -0x38(%ebp),%eax
    bf9c:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    bf9f:	29 c2                	sub    %eax,%edx
    bfa1:	89 d0                	mov    %edx,%eax
    bfa3:	23 45 cc             	and    -0x34(%ebp),%eax
    bfa6:	89 c2                	mov    %eax,%edx
    bfa8:	8b 45 d0             	mov    -0x30(%ebp),%eax
    bfab:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    bfad:	8b 45 c0             	mov    -0x40(%ebp),%eax
    bfb0:	8b 55 c8             	mov    -0x38(%ebp),%edx
    bfb3:	31 d0                	xor    %edx,%eax
    bfb5:	23 45 cc             	and    -0x34(%ebp),%eax
    bfb8:	85 c0                	test   %eax,%eax
    bfba:	0f 94 c0             	sete   %al
    bfbd:	0f b6 c0             	movzbl %al,%eax
    bfc0:	85 c0                	test   %eax,%eax
    bfc2:	74 07                	je     bfcb <ck_ring_enqueue_spsc_size_child+0xa7>
		return false;
    bfc4:	b8 00 00 00 00       	mov    $0x0,%eax
    bfc9:	eb 47                	jmp    c012 <ck_ring_enqueue_spsc_size_child+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    bfcb:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    bfce:	8b 55 cc             	mov    -0x34(%ebp),%edx
    bfd1:	21 d0                	and    %edx,%eax
    bfd3:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    bfd7:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    bfda:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    bfdd:	89 44 24 08          	mov    %eax,0x8(%esp)
    bfe1:	8b 45 d8             	mov    -0x28(%ebp),%eax
    bfe4:	89 44 24 04          	mov    %eax,0x4(%esp)
    bfe8:	8b 45 dc             	mov    -0x24(%ebp),%eax
    bfeb:	89 04 24             	mov    %eax,(%esp)
    bfee:	e8 fc ff ff ff       	call   bfef <ck_ring_enqueue_spsc_size_child+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    bff3:	e8 e6 d6 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    bff8:	8b 45 e0             	mov    -0x20(%ebp),%eax
    bffb:	8d 50 40             	lea    0x40(%eax),%edx
    bffe:	8b 45 c0             	mov    -0x40(%ebp),%eax
    c001:	89 44 24 04          	mov    %eax,0x4(%esp)
    c005:	89 14 24             	mov    %edx,(%esp)
    c008:	e8 44 ca ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    c00d:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    c012:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    c015:	8b 55 b8             	mov    -0x48(%ebp),%edx
    c018:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    c01b:	89 10                	mov    %edx,(%eax)
	return r;
    c01d:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    c021:	c9                   	leave  
    c022:	c3                   	ret    

0000c023 <ck_ring_enqueue_spsc_child>:
    c023:	55                   	push   %ebp
    c024:	89 e5                	mov    %esp,%ebp
    c026:	83 ec 48             	sub    $0x48,%esp
    c029:	8b 45 08             	mov    0x8(%ebp),%eax
    c02c:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c02f:	8b 45 0c             	mov    0xc(%ebp),%eax
    c032:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c035:	8b 45 10             	mov    0x10(%ebp),%eax
    c038:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c03b:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
    c042:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    c049:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c04c:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c052:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    c055:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c058:	89 04 24             	mov    %eax,(%esp)
    c05b:	e8 68 c9 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c060:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    c063:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c066:	8b 40 40             	mov    0x40(%eax),%eax
    c069:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    c06c:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c06f:	83 c0 01             	add    $0x1,%eax
    c072:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    c075:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    c079:	74 14                	je     c08f <ck_ring_enqueue_spsc_child+0x6c>
		*size = (producer - consumer) & mask;
    c07b:	8b 45 dc             	mov    -0x24(%ebp),%eax
    c07e:	8b 55 d8             	mov    -0x28(%ebp),%edx
    c081:	29 c2                	sub    %eax,%edx
    c083:	89 d0                	mov    %edx,%eax
    c085:	23 45 e0             	and    -0x20(%ebp),%eax
    c088:	89 c2                	mov    %eax,%edx
    c08a:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    c08d:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    c08f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    c092:	8b 55 dc             	mov    -0x24(%ebp),%edx
    c095:	31 d0                	xor    %edx,%eax
    c097:	23 45 e0             	and    -0x20(%ebp),%eax
    c09a:	85 c0                	test   %eax,%eax
    c09c:	0f 94 c0             	sete   %al
    c09f:	0f b6 c0             	movzbl %al,%eax
    c0a2:	85 c0                	test   %eax,%eax
    c0a4:	74 07                	je     c0ad <ck_ring_enqueue_spsc_child+0x8a>
		return false;
    c0a6:	b8 00 00 00 00       	mov    $0x0,%eax
    c0ab:	eb 47                	jmp    c0f4 <ck_ring_enqueue_spsc_child+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    c0ad:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c0b0:	8b 55 e0             	mov    -0x20(%ebp),%edx
    c0b3:	21 d0                	and    %edx,%eax
    c0b5:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    c0b9:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    c0bc:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c0bf:	89 44 24 08          	mov    %eax,0x8(%esp)
    c0c3:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c0c6:	89 44 24 04          	mov    %eax,0x4(%esp)
    c0ca:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c0cd:	89 04 24             	mov    %eax,(%esp)
    c0d0:	e8 fc ff ff ff       	call   c0d1 <ck_ring_enqueue_spsc_child+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    c0d5:	e8 04 d6 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    c0da:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c0dd:	8d 50 40             	lea    0x40(%eax),%edx
    c0e0:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    c0e3:	89 44 24 04          	mov    %eax,0x4(%esp)
    c0e7:	89 14 24             	mov    %edx,(%esp)
    c0ea:	e8 62 c9 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    c0ef:	b8 01 00 00 00       	mov    $0x1,%eax
    c0f4:	c9                   	leave  
    c0f5:	c3                   	ret    

0000c0f6 <ck_ring_dequeue_spsc_child>:
    c0f6:	55                   	push   %ebp
    c0f7:	89 e5                	mov    %esp,%ebp
    c0f9:	83 ec 38             	sub    $0x38,%esp
    c0fc:	8b 45 08             	mov    0x8(%ebp),%eax
    c0ff:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c102:	8b 45 0c             	mov    0xc(%ebp),%eax
    c105:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c108:	8b 45 10             	mov    0x10(%ebp),%eax
    c10b:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c10e:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    c115:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c118:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c11e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    c121:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c124:	8b 00                	mov    (%eax),%eax
    c126:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    c129:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c12c:	83 c0 40             	add    $0x40,%eax
    c12f:	89 04 24             	mov    %eax,(%esp)
    c132:	e8 91 c8 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c137:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    c13a:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c13d:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    c140:	0f 94 c0             	sete   %al
    c143:	0f b6 c0             	movzbl %al,%eax
    c146:	85 c0                	test   %eax,%eax
    c148:	74 07                	je     c151 <ck_ring_dequeue_spsc_child+0x5b>
		return false;
    c14a:	b8 00 00 00 00       	mov    $0x0,%eax
    c14f:	eb 4c                	jmp    c19d <ck_ring_dequeue_spsc_child+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    c151:	e8 7d d5 ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    c156:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c159:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    c15c:	21 d0                	and    %edx,%eax
    c15e:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    c162:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    c165:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c168:	89 44 24 08          	mov    %eax,0x8(%esp)
    c16c:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c16f:	89 44 24 04          	mov    %eax,0x4(%esp)
    c173:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c176:	89 04 24             	mov    %eax,(%esp)
    c179:	e8 fc ff ff ff       	call   c17a <ck_ring_dequeue_spsc_child+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    c17e:	e8 5b d5 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    c183:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c186:	8d 50 01             	lea    0x1(%eax),%edx
    c189:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c18c:	89 54 24 04          	mov    %edx,0x4(%esp)
    c190:	89 04 24             	mov    %eax,(%esp)
    c193:	e8 b9 c8 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    c198:	b8 01 00 00 00       	mov    $0x1,%eax
    c19d:	c9                   	leave  
    c19e:	c3                   	ret    

0000c19f <ck_ring_enqueue_spmc_size_child>:
    c19f:	55                   	push   %ebp
    c1a0:	89 e5                	mov    %esp,%ebp
    c1a2:	83 ec 58             	sub    $0x58,%esp
    c1a5:	8b 45 08             	mov    0x8(%ebp),%eax
    c1a8:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c1ab:	8b 45 0c             	mov    0xc(%ebp),%eax
    c1ae:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c1b1:	8b 45 10             	mov    0x10(%ebp),%eax
    c1b4:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c1b7:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
    c1be:	8b 45 14             	mov    0x14(%ebp),%eax
    c1c1:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    c1c4:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c1c7:	89 45 e0             	mov    %eax,-0x20(%ebp)
    c1ca:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c1cd:	89 45 dc             	mov    %eax,-0x24(%ebp)
    c1d0:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c1d3:	89 45 d8             	mov    %eax,-0x28(%ebp)
    c1d6:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c1d9:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    c1dc:	8d 45 b8             	lea    -0x48(%ebp),%eax
    c1df:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    c1e2:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c1e5:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c1eb:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    c1ee:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c1f1:	89 04 24             	mov    %eax,(%esp)
    c1f4:	e8 cf c7 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c1f9:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
    c1fc:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c1ff:	8b 40 40             	mov    0x40(%eax),%eax
    c202:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
    c205:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    c208:	83 c0 01             	add    $0x1,%eax
    c20b:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
    c20e:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    c212:	74 14                	je     c228 <ck_ring_enqueue_spmc_size_child+0x89>
		*size = (producer - consumer) & mask;
    c214:	8b 45 c8             	mov    -0x38(%ebp),%eax
    c217:	8b 55 c4             	mov    -0x3c(%ebp),%edx
    c21a:	29 c2                	sub    %eax,%edx
    c21c:	89 d0                	mov    %edx,%eax
    c21e:	23 45 cc             	and    -0x34(%ebp),%eax
    c221:	89 c2                	mov    %eax,%edx
    c223:	8b 45 d0             	mov    -0x30(%ebp),%eax
    c226:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    c228:	8b 45 c0             	mov    -0x40(%ebp),%eax
    c22b:	8b 55 c8             	mov    -0x38(%ebp),%edx
    c22e:	31 d0                	xor    %edx,%eax
    c230:	23 45 cc             	and    -0x34(%ebp),%eax
    c233:	85 c0                	test   %eax,%eax
    c235:	0f 94 c0             	sete   %al
    c238:	0f b6 c0             	movzbl %al,%eax
    c23b:	85 c0                	test   %eax,%eax
    c23d:	74 07                	je     c246 <ck_ring_enqueue_spmc_size_child+0xa7>
		return false;
    c23f:	b8 00 00 00 00       	mov    $0x0,%eax
    c244:	eb 47                	jmp    c28d <ck_ring_enqueue_spmc_size_child+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
    c246:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    c249:	8b 55 cc             	mov    -0x34(%ebp),%edx
    c24c:	21 d0                	and    %edx,%eax
    c24e:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    c252:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    c255:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    c258:	89 44 24 08          	mov    %eax,0x8(%esp)
    c25c:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c25f:	89 44 24 04          	mov    %eax,0x4(%esp)
    c263:	8b 45 dc             	mov    -0x24(%ebp),%eax
    c266:	89 04 24             	mov    %eax,(%esp)
    c269:	e8 fc ff ff ff       	call   c26a <ck_ring_enqueue_spmc_size_child+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    c26e:	e8 6b d4 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    c273:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c276:	8d 50 40             	lea    0x40(%eax),%edx
    c279:	8b 45 c0             	mov    -0x40(%ebp),%eax
    c27c:	89 44 24 04          	mov    %eax,0x4(%esp)
    c280:	89 14 24             	mov    %edx,(%esp)
    c283:	e8 c9 c7 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    c288:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
    c28d:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
    c290:	8b 55 b8             	mov    -0x48(%ebp),%edx
    c293:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    c296:	89 10                	mov    %edx,(%eax)
	return r;
    c298:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    c29c:	c9                   	leave  
    c29d:	c3                   	ret    

0000c29e <ck_ring_enqueue_spmc_child>:
    c29e:	55                   	push   %ebp
    c29f:	89 e5                	mov    %esp,%ebp
    c2a1:	83 ec 48             	sub    $0x48,%esp
    c2a4:	8b 45 08             	mov    0x8(%ebp),%eax
    c2a7:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c2aa:	8b 45 0c             	mov    0xc(%ebp),%eax
    c2ad:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c2b0:	8b 45 10             	mov    0x10(%ebp),%eax
    c2b3:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c2b6:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
    c2bd:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    c2c4:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c2c7:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c2cd:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
    c2d0:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c2d3:	89 04 24             	mov    %eax,(%esp)
    c2d6:	e8 ed c6 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c2db:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
    c2de:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c2e1:	8b 40 40             	mov    0x40(%eax),%eax
    c2e4:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
    c2e7:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c2ea:	83 c0 01             	add    $0x1,%eax
    c2ed:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
    c2f0:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    c2f4:	74 14                	je     c30a <ck_ring_enqueue_spmc_child+0x6c>
		*size = (producer - consumer) & mask;
    c2f6:	8b 45 dc             	mov    -0x24(%ebp),%eax
    c2f9:	8b 55 d8             	mov    -0x28(%ebp),%edx
    c2fc:	29 c2                	sub    %eax,%edx
    c2fe:	89 d0                	mov    %edx,%eax
    c300:	23 45 e0             	and    -0x20(%ebp),%eax
    c303:	89 c2                	mov    %eax,%edx
    c305:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    c308:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
    c30a:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    c30d:	8b 55 dc             	mov    -0x24(%ebp),%edx
    c310:	31 d0                	xor    %edx,%eax
    c312:	23 45 e0             	and    -0x20(%ebp),%eax
    c315:	85 c0                	test   %eax,%eax
    c317:	0f 94 c0             	sete   %al
    c31a:	0f b6 c0             	movzbl %al,%eax
    c31d:	85 c0                	test   %eax,%eax
    c31f:	74 07                	je     c328 <ck_ring_enqueue_spmc_child+0x8a>
		return false;
    c321:	b8 00 00 00 00       	mov    $0x0,%eax
    c326:	eb 47                	jmp    c36f <ck_ring_enqueue_spmc_child+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
    c328:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c32b:	8b 55 e0             	mov    -0x20(%ebp),%edx
    c32e:	21 d0                	and    %edx,%eax
    c330:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    c334:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    c337:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c33a:	89 44 24 08          	mov    %eax,0x8(%esp)
    c33e:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c341:	89 44 24 04          	mov    %eax,0x4(%esp)
    c345:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c348:	89 04 24             	mov    %eax,(%esp)
    c34b:	e8 fc ff ff ff       	call   c34c <ck_ring_enqueue_spmc_child+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
    c350:	e8 89 d3 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    c355:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c358:	8d 50 40             	lea    0x40(%eax),%edx
    c35b:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    c35e:	89 44 24 04          	mov    %eax,0x4(%esp)
    c362:	89 14 24             	mov    %edx,(%esp)
    c365:	e8 e7 c6 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    c36a:	b8 01 00 00 00       	mov    $0x1,%eax
    c36f:	c9                   	leave  
    c370:	c3                   	ret    

0000c371 <ck_ring_trydequeue_spmc_child>:
    c371:	55                   	push   %ebp
    c372:	89 e5                	mov    %esp,%ebp
    c374:	83 ec 38             	sub    $0x38,%esp
    c377:	8b 45 08             	mov    0x8(%ebp),%eax
    c37a:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c37d:	8b 45 0c             	mov    0xc(%ebp),%eax
    c380:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c383:	8b 45 10             	mov    0x10(%ebp),%eax
    c386:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c389:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    c390:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c393:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c399:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    c39c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c39f:	89 04 24             	mov    %eax,(%esp)
    c3a2:	e8 21 c6 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c3a7:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    c3aa:	e8 24 d3 ff ff       	call   96d3 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    c3af:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c3b2:	83 c0 40             	add    $0x40,%eax
    c3b5:	89 04 24             	mov    %eax,(%esp)
    c3b8:	e8 0b c6 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c3bd:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    c3c0:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c3c3:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    c3c6:	0f 94 c0             	sete   %al
    c3c9:	0f b6 c0             	movzbl %al,%eax
    c3cc:	85 c0                	test   %eax,%eax
    c3ce:	74 07                	je     c3d7 <ck_ring_trydequeue_spmc_child+0x66>
		return false;
    c3d0:	b8 00 00 00 00       	mov    $0x0,%eax
    c3d5:	eb 4e                	jmp    c425 <ck_ring_trydequeue_spmc_child+0xb4>

	ck_pr_fence_load();
    c3d7:	e8 f7 d2 ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    c3dc:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c3df:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    c3e2:	21 d0                	and    %edx,%eax
    c3e4:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    c3e8:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    c3eb:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c3ee:	89 44 24 08          	mov    %eax,0x8(%esp)
    c3f2:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c3f5:	89 44 24 04          	mov    %eax,0x4(%esp)
    c3f9:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c3fc:	89 04 24             	mov    %eax,(%esp)
    c3ff:	e8 fc ff ff ff       	call   c400 <ck_ring_trydequeue_spmc_child+0x8f>

	ck_pr_fence_store_atomic();
    c404:	e8 9e d2 ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    c409:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c40c:	8d 50 01             	lea    0x1(%eax),%edx
    c40f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c412:	89 54 24 08          	mov    %edx,0x8(%esp)
    c416:	8b 55 e0             	mov    -0x20(%ebp),%edx
    c419:	89 54 24 04          	mov    %edx,0x4(%esp)
    c41d:	89 04 24             	mov    %eax,(%esp)
    c420:	e8 51 ce ff ff       	call   9276 <ck_pr_cas_uint>
    c425:	c9                   	leave  
    c426:	c3                   	ret    

0000c427 <ck_ring_dequeue_spmc_child>:
    c427:	55                   	push   %ebp
    c428:	89 e5                	mov    %esp,%ebp
    c42a:	53                   	push   %ebx
    c42b:	83 ec 34             	sub    $0x34,%esp
    c42e:	8b 45 08             	mov    0x8(%ebp),%eax
    c431:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c434:	8b 45 0c             	mov    0xc(%ebp),%eax
    c437:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c43a:	8b 45 10             	mov    0x10(%ebp),%eax
    c43d:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c440:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    c447:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c44a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c450:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    c453:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c456:	89 04 24             	mov    %eax,(%esp)
    c459:	e8 6a c5 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c45e:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    c461:	e8 6d d2 ff ff       	call   96d3 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    c466:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c469:	83 c0 40             	add    $0x40,%eax
    c46c:	89 04 24             	mov    %eax,(%esp)
    c46f:	e8 54 c5 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c474:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    c477:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c47a:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    c47d:	0f 94 c0             	sete   %al
    c480:	0f b6 c0             	movzbl %al,%eax
    c483:	85 c0                	test   %eax,%eax
    c485:	74 07                	je     c48e <ck_ring_dequeue_spmc_child+0x67>
			return false;
    c487:	b8 00 00 00 00       	mov    $0x0,%eax
    c48c:	eb 6a                	jmp    c4f8 <ck_ring_dequeue_spmc_child+0xd1>

		ck_pr_fence_load();
    c48e:	e8 40 d2 ff ff       	call   96d3 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    c493:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c496:	23 45 e4             	and    -0x1c(%ebp),%eax
    c499:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    c49d:	89 c2                	mov    %eax,%edx
    c49f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c4a2:	01 d0                	add    %edx,%eax
    c4a4:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    c4a7:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c4aa:	89 44 24 08          	mov    %eax,0x8(%esp)
    c4ae:	8b 45 dc             	mov    -0x24(%ebp),%eax
    c4b1:	89 44 24 04          	mov    %eax,0x4(%esp)
    c4b5:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c4b8:	89 04 24             	mov    %eax,(%esp)
    c4bb:	e8 fc ff ff ff       	call   c4bc <ck_ring_dequeue_spmc_child+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    c4c0:	e8 e2 d1 ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    c4c5:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c4c8:	8d 58 01             	lea    0x1(%eax),%ebx
    c4cb:	8b 55 d8             	mov    -0x28(%ebp),%edx
    c4ce:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c4d1:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    c4d4:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    c4d8:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    c4dc:	89 54 24 04          	mov    %edx,0x4(%esp)
    c4e0:	89 04 24             	mov    %eax,(%esp)
    c4e3:	e8 e1 ce ff ff       	call   93c9 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    c4e8:	83 f0 01             	xor    $0x1,%eax
    c4eb:	84 c0                	test   %al,%al
    c4ed:	0f 85 6e ff ff ff    	jne    c461 <ck_ring_dequeue_spmc_child+0x3a>

	return true;
    c4f3:	b8 01 00 00 00       	mov    $0x1,%eax
    c4f8:	83 c4 34             	add    $0x34,%esp
    c4fb:	5b                   	pop    %ebx
    c4fc:	5d                   	pop    %ebp
    c4fd:	c3                   	ret    

0000c4fe <ck_ring_enqueue_mpsc_child>:
    c4fe:	55                   	push   %ebp
    c4ff:	89 e5                	mov    %esp,%ebp
    c501:	83 ec 48             	sub    $0x48,%esp
    c504:	8b 45 08             	mov    0x8(%ebp),%eax
    c507:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c50a:	8b 45 0c             	mov    0xc(%ebp),%eax
    c50d:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c510:	8b 45 10             	mov    0x10(%ebp),%eax
    c513:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c516:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
    c51d:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    c524:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c527:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c52d:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    c530:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    c534:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c537:	83 c0 44             	add    $0x44,%eax
    c53a:	89 04 24             	mov    %eax,(%esp)
    c53d:	e8 86 c4 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c542:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    c545:	e8 89 d1 ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    c54a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c54d:	89 04 24             	mov    %eax,(%esp)
    c550:	e8 73 c4 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c555:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    c558:	8b 45 cc             	mov    -0x34(%ebp),%eax
    c55b:	83 c0 01             	add    $0x1,%eax
    c55e:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    c561:	8b 45 cc             	mov    -0x34(%ebp),%eax
    c564:	2b 45 d8             	sub    -0x28(%ebp),%eax
    c567:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    c56a:	0f 97 c0             	seta   %al
    c56d:	0f b6 c0             	movzbl %al,%eax
    c570:	85 c0                	test   %eax,%eax
    c572:	74 29                	je     c59d <ck_ring_enqueue_mpsc_child+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    c574:	8b 45 cc             	mov    -0x34(%ebp),%eax
    c577:	8b 55 f4             	mov    -0xc(%ebp),%edx
    c57a:	8d 4a 44             	lea    0x44(%edx),%ecx
    c57d:	8d 55 cc             	lea    -0x34(%ebp),%edx
    c580:	89 54 24 0c          	mov    %edx,0xc(%esp)
    c584:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    c587:	89 54 24 08          	mov    %edx,0x8(%esp)
    c58b:	89 44 24 04          	mov    %eax,0x4(%esp)
    c58f:	89 0c 24             	mov    %ecx,(%esp)
    c592:	e8 32 ce ff ff       	call   93c9 <ck_pr_cas_uint_value>
    c597:	84 c0                	test   %al,%al
    c599:	75 31                	jne    c5cc <ck_ring_enqueue_mpsc_child+0xce>
    c59b:	eb a8                	jmp    c545 <ck_ring_enqueue_mpsc_child+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    c59d:	e8 31 d1 ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    c5a2:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c5a5:	83 c0 44             	add    $0x44,%eax
    c5a8:	89 04 24             	mov    %eax,(%esp)
    c5ab:	e8 18 c4 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c5b0:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    c5b3:	8b 45 cc             	mov    -0x34(%ebp),%eax
    c5b6:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    c5b9:	75 06                	jne    c5c1 <ck_ring_enqueue_mpsc_child+0xc3>
				r = false;
    c5bb:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    c5bf:	eb 67                	jmp    c628 <ck_ring_enqueue_mpsc_child+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    c5c1:	8b 45 d0             	mov    -0x30(%ebp),%eax
    c5c4:	89 45 cc             	mov    %eax,-0x34(%ebp)
    c5c7:	e9 79 ff ff ff       	jmp    c545 <ck_ring_enqueue_mpsc_child+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    c5cc:	8b 45 cc             	mov    -0x34(%ebp),%eax
    c5cf:	23 45 e0             	and    -0x20(%ebp),%eax
    c5d2:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    c5d6:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    c5d9:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c5dc:	89 44 24 08          	mov    %eax,0x8(%esp)
    c5e0:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c5e3:	89 44 24 04          	mov    %eax,0x4(%esp)
    c5e7:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c5ea:	89 04 24             	mov    %eax,(%esp)
    c5ed:	e8 fc ff ff ff       	call   c5ee <ck_ring_enqueue_mpsc_child+0xf0>
    c5f2:	eb 05                	jmp    c5f9 <ck_ring_enqueue_mpsc_child+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    c5f4:	e8 6a c2 ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    c5f9:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c5fc:	83 c0 40             	add    $0x40,%eax
    c5ff:	89 04 24             	mov    %eax,(%esp)
    c602:	e8 c1 c3 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c607:	8b 55 cc             	mov    -0x34(%ebp),%edx
    c60a:	39 d0                	cmp    %edx,%eax
    c60c:	75 e6                	jne    c5f4 <ck_ring_enqueue_mpsc_child+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    c60e:	e8 cb d0 ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    c613:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c616:	8d 50 40             	lea    0x40(%eax),%edx
    c619:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    c61c:	89 44 24 04          	mov    %eax,0x4(%esp)
    c620:	89 14 24             	mov    %edx,(%esp)
    c623:	e8 29 c4 ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    c628:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    c62c:	74 10                	je     c63e <ck_ring_enqueue_mpsc_child+0x140>
		*size = (producer - consumer) & mask;
    c62e:	8b 45 cc             	mov    -0x34(%ebp),%eax
    c631:	2b 45 d8             	sub    -0x28(%ebp),%eax
    c634:	23 45 e0             	and    -0x20(%ebp),%eax
    c637:	89 c2                	mov    %eax,%edx
    c639:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    c63c:	89 10                	mov    %edx,(%eax)

	return r;
    c63e:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    c642:	c9                   	leave  
    c643:	c3                   	ret    

0000c644 <ck_ring_enqueue_mpsc_size_child>:
    c644:	55                   	push   %ebp
    c645:	89 e5                	mov    %esp,%ebp
    c647:	83 ec 68             	sub    $0x68,%esp
    c64a:	8b 45 08             	mov    0x8(%ebp),%eax
    c64d:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c650:	8b 45 0c             	mov    0xc(%ebp),%eax
    c653:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c656:	8b 45 10             	mov    0x10(%ebp),%eax
    c659:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c65c:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
    c663:	8b 45 14             	mov    0x14(%ebp),%eax
    c666:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    c669:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c66c:	89 45 e0             	mov    %eax,-0x20(%ebp)
    c66f:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c672:	89 45 dc             	mov    %eax,-0x24(%ebp)
    c675:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c678:	89 45 d8             	mov    %eax,-0x28(%ebp)
    c67b:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c67e:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    c681:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    c684:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    c687:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c68a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c690:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    c693:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    c697:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c69a:	83 c0 44             	add    $0x44,%eax
    c69d:	89 04 24             	mov    %eax,(%esp)
    c6a0:	e8 23 c3 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c6a5:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    c6a8:	e8 26 d0 ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    c6ad:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c6b0:	89 04 24             	mov    %eax,(%esp)
    c6b3:	e8 10 c3 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c6b8:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    c6bb:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c6be:	83 c0 01             	add    $0x1,%eax
    c6c1:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    c6c4:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c6c7:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    c6ca:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    c6cd:	0f 97 c0             	seta   %al
    c6d0:	0f b6 c0             	movzbl %al,%eax
    c6d3:	85 c0                	test   %eax,%eax
    c6d5:	74 29                	je     c700 <ck_ring_enqueue_mpsc_size_child+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    c6d7:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c6da:	8b 55 e0             	mov    -0x20(%ebp),%edx
    c6dd:	8d 4a 44             	lea    0x44(%edx),%ecx
    c6e0:	8d 55 b0             	lea    -0x50(%ebp),%edx
    c6e3:	89 54 24 0c          	mov    %edx,0xc(%esp)
    c6e7:	8b 55 c0             	mov    -0x40(%ebp),%edx
    c6ea:	89 54 24 08          	mov    %edx,0x8(%esp)
    c6ee:	89 44 24 04          	mov    %eax,0x4(%esp)
    c6f2:	89 0c 24             	mov    %ecx,(%esp)
    c6f5:	e8 cf cc ff ff       	call   93c9 <ck_pr_cas_uint_value>
    c6fa:	84 c0                	test   %al,%al
    c6fc:	75 31                	jne    c72f <ck_ring_enqueue_mpsc_size_child+0xeb>
    c6fe:	eb a8                	jmp    c6a8 <ck_ring_enqueue_mpsc_size_child+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    c700:	e8 ce cf ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    c705:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c708:	83 c0 44             	add    $0x44,%eax
    c70b:	89 04 24             	mov    %eax,(%esp)
    c70e:	e8 b5 c2 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c713:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    c716:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c719:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    c71c:	75 06                	jne    c724 <ck_ring_enqueue_mpsc_size_child+0xe0>
				r = false;
    c71e:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    c722:	eb 67                	jmp    c78b <ck_ring_enqueue_mpsc_size_child+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    c724:	8b 45 bc             	mov    -0x44(%ebp),%eax
    c727:	89 45 b0             	mov    %eax,-0x50(%ebp)
    c72a:	e9 79 ff ff ff       	jmp    c6a8 <ck_ring_enqueue_mpsc_size_child+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    c72f:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c732:	23 45 cc             	and    -0x34(%ebp),%eax
    c735:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    c739:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    c73c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    c73f:	89 44 24 08          	mov    %eax,0x8(%esp)
    c743:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c746:	89 44 24 04          	mov    %eax,0x4(%esp)
    c74a:	8b 45 dc             	mov    -0x24(%ebp),%eax
    c74d:	89 04 24             	mov    %eax,(%esp)
    c750:	e8 fc ff ff ff       	call   c751 <ck_ring_enqueue_mpsc_size_child+0x10d>
    c755:	eb 05                	jmp    c75c <ck_ring_enqueue_mpsc_size_child+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    c757:	e8 07 c1 ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    c75c:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c75f:	83 c0 40             	add    $0x40,%eax
    c762:	89 04 24             	mov    %eax,(%esp)
    c765:	e8 5e c2 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c76a:	8b 55 b0             	mov    -0x50(%ebp),%edx
    c76d:	39 d0                	cmp    %edx,%eax
    c76f:	75 e6                	jne    c757 <ck_ring_enqueue_mpsc_size_child+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    c771:	e8 68 cf ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    c776:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c779:	8d 50 40             	lea    0x40(%eax),%edx
    c77c:	8b 45 c0             	mov    -0x40(%ebp),%eax
    c77f:	89 44 24 04          	mov    %eax,0x4(%esp)
    c783:	89 14 24             	mov    %edx,(%esp)
    c786:	e8 c6 c2 ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    c78b:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    c78f:	74 10                	je     c7a1 <ck_ring_enqueue_mpsc_size_child+0x15d>
		*size = (producer - consumer) & mask;
    c791:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c794:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    c797:	23 45 cc             	and    -0x34(%ebp),%eax
    c79a:	89 c2                	mov    %eax,%edx
    c79c:	8b 45 d0             	mov    -0x30(%ebp),%eax
    c79f:	89 10                	mov    %edx,(%eax)

	return r;
    c7a1:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    c7a5:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    c7a8:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    c7ab:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    c7ae:	89 10                	mov    %edx,(%eax)
	return r;
    c7b0:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    c7b4:	c9                   	leave  
    c7b5:	c3                   	ret    

0000c7b6 <ck_ring_dequeue_mpsc_child>:
    c7b6:	55                   	push   %ebp
    c7b7:	89 e5                	mov    %esp,%ebp
    c7b9:	83 ec 38             	sub    $0x38,%esp
    c7bc:	8b 45 08             	mov    0x8(%ebp),%eax
    c7bf:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c7c2:	8b 45 0c             	mov    0xc(%ebp),%eax
    c7c5:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c7c8:	8b 45 10             	mov    0x10(%ebp),%eax
    c7cb:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c7ce:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    c7d5:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c7d8:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c7de:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
    c7e1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c7e4:	8b 00                	mov    (%eax),%eax
    c7e6:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
    c7e9:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c7ec:	83 c0 40             	add    $0x40,%eax
    c7ef:	89 04 24             	mov    %eax,(%esp)
    c7f2:	e8 d1 c1 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c7f7:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    c7fa:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c7fd:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    c800:	0f 94 c0             	sete   %al
    c803:	0f b6 c0             	movzbl %al,%eax
    c806:	85 c0                	test   %eax,%eax
    c808:	74 07                	je     c811 <ck_ring_dequeue_mpsc_child+0x5b>
		return false;
    c80a:	b8 00 00 00 00       	mov    $0x0,%eax
    c80f:	eb 4c                	jmp    c85d <ck_ring_dequeue_mpsc_child+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
    c811:	e8 bd ce ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    c816:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c819:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    c81c:	21 d0                	and    %edx,%eax
    c81e:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    c822:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
    c825:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c828:	89 44 24 08          	mov    %eax,0x8(%esp)
    c82c:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c82f:	89 44 24 04          	mov    %eax,0x4(%esp)
    c833:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c836:	89 04 24             	mov    %eax,(%esp)
    c839:	e8 fc ff ff ff       	call   c83a <ck_ring_dequeue_mpsc_child+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
    c83e:	e8 9b ce ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
    c843:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c846:	8d 50 01             	lea    0x1(%eax),%edx
    c849:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c84c:	89 54 24 04          	mov    %edx,0x4(%esp)
    c850:	89 04 24             	mov    %eax,(%esp)
    c853:	e8 f9 c1 ff ff       	call   8a51 <ck_pr_md_store_uint>
	return true;
    c858:	b8 01 00 00 00       	mov    $0x1,%eax
    c85d:	c9                   	leave  
    c85e:	c3                   	ret    

0000c85f <ck_ring_enqueue_mpmc_size_child>:
    c85f:	55                   	push   %ebp
    c860:	89 e5                	mov    %esp,%ebp
    c862:	83 ec 68             	sub    $0x68,%esp
    c865:	8b 45 08             	mov    0x8(%ebp),%eax
    c868:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c86b:	8b 45 0c             	mov    0xc(%ebp),%eax
    c86e:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c871:	8b 45 10             	mov    0x10(%ebp),%eax
    c874:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c877:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
    c87e:	8b 45 14             	mov    0x14(%ebp),%eax
    c881:	89 45 e4             	mov    %eax,-0x1c(%ebp)
    c884:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c887:	89 45 e0             	mov    %eax,-0x20(%ebp)
    c88a:	8b 45 f0             	mov    -0x10(%ebp),%eax
    c88d:	89 45 dc             	mov    %eax,-0x24(%ebp)
    c890:	8b 45 ec             	mov    -0x14(%ebp),%eax
    c893:	89 45 d8             	mov    %eax,-0x28(%ebp)
    c896:	8b 45 e8             	mov    -0x18(%ebp),%eax
    c899:	89 45 d4             	mov    %eax,-0x2c(%ebp)
    c89c:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    c89f:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    c8a2:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c8a5:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    c8ab:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    c8ae:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    c8b2:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c8b5:	83 c0 44             	add    $0x44,%eax
    c8b8:	89 04 24             	mov    %eax,(%esp)
    c8bb:	e8 08 c1 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c8c0:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    c8c3:	e8 0b ce ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    c8c8:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c8cb:	89 04 24             	mov    %eax,(%esp)
    c8ce:	e8 f5 c0 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c8d3:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
    c8d6:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c8d9:	83 c0 01             	add    $0x1,%eax
    c8dc:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    c8df:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c8e2:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    c8e5:	39 45 cc             	cmp    %eax,-0x34(%ebp)
    c8e8:	0f 97 c0             	seta   %al
    c8eb:	0f b6 c0             	movzbl %al,%eax
    c8ee:	85 c0                	test   %eax,%eax
    c8f0:	74 29                	je     c91b <ck_ring_enqueue_mpmc_size_child+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
    c8f2:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c8f5:	8b 55 e0             	mov    -0x20(%ebp),%edx
    c8f8:	8d 4a 44             	lea    0x44(%edx),%ecx
    c8fb:	8d 55 b0             	lea    -0x50(%ebp),%edx
    c8fe:	89 54 24 0c          	mov    %edx,0xc(%esp)
    c902:	8b 55 c0             	mov    -0x40(%ebp),%edx
    c905:	89 54 24 08          	mov    %edx,0x8(%esp)
    c909:	89 44 24 04          	mov    %eax,0x4(%esp)
    c90d:	89 0c 24             	mov    %ecx,(%esp)
    c910:	e8 b4 ca ff ff       	call   93c9 <ck_pr_cas_uint_value>
    c915:	84 c0                	test   %al,%al
    c917:	75 31                	jne    c94a <ck_ring_enqueue_mpmc_size_child+0xeb>
    c919:	eb a8                	jmp    c8c3 <ck_ring_enqueue_mpmc_size_child+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    c91b:	e8 b3 cd ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    c920:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c923:	83 c0 44             	add    $0x44,%eax
    c926:	89 04 24             	mov    %eax,(%esp)
    c929:	e8 9a c0 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c92e:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    c931:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c934:	39 45 bc             	cmp    %eax,-0x44(%ebp)
    c937:	75 06                	jne    c93f <ck_ring_enqueue_mpmc_size_child+0xe0>
				r = false;
    c939:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
    c93d:	eb 67                	jmp    c9a6 <ck_ring_enqueue_mpmc_size_child+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    c93f:	8b 45 bc             	mov    -0x44(%ebp),%eax
    c942:	89 45 b0             	mov    %eax,-0x50(%ebp)
    c945:	e9 79 ff ff ff       	jmp    c8c3 <ck_ring_enqueue_mpmc_size_child+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    c94a:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c94d:	23 45 cc             	and    -0x34(%ebp),%eax
    c950:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
    c954:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
    c957:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    c95a:	89 44 24 08          	mov    %eax,0x8(%esp)
    c95e:	8b 45 d8             	mov    -0x28(%ebp),%eax
    c961:	89 44 24 04          	mov    %eax,0x4(%esp)
    c965:	8b 45 dc             	mov    -0x24(%ebp),%eax
    c968:	89 04 24             	mov    %eax,(%esp)
    c96b:	e8 fc ff ff ff       	call   c96c <ck_ring_enqueue_mpmc_size_child+0x10d>
    c970:	eb 05                	jmp    c977 <ck_ring_enqueue_mpmc_size_child+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    c972:	e8 ec be ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    c977:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c97a:	83 c0 40             	add    $0x40,%eax
    c97d:	89 04 24             	mov    %eax,(%esp)
    c980:	e8 43 c0 ff ff       	call   89c8 <ck_pr_md_load_uint>
    c985:	8b 55 b0             	mov    -0x50(%ebp),%edx
    c988:	39 d0                	cmp    %edx,%eax
    c98a:	75 e6                	jne    c972 <ck_ring_enqueue_mpmc_size_child+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    c98c:	e8 4d cd ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    c991:	8b 45 e0             	mov    -0x20(%ebp),%eax
    c994:	8d 50 40             	lea    0x40(%eax),%edx
    c997:	8b 45 c0             	mov    -0x40(%ebp),%eax
    c99a:	89 44 24 04          	mov    %eax,0x4(%esp)
    c99e:	89 14 24             	mov    %edx,(%esp)
    c9a1:	e8 ab c0 ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    c9a6:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    c9aa:	74 10                	je     c9bc <ck_ring_enqueue_mpmc_size_child+0x15d>
		*size = (producer - consumer) & mask;
    c9ac:	8b 45 b0             	mov    -0x50(%ebp),%eax
    c9af:	2b 45 c4             	sub    -0x3c(%ebp),%eax
    c9b2:	23 45 cc             	and    -0x34(%ebp),%eax
    c9b5:	89 c2                	mov    %eax,%edx
    c9b7:	8b 45 d0             	mov    -0x30(%ebp),%eax
    c9ba:	89 10                	mov    %edx,(%eax)

	return r;
    c9bc:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
    c9c0:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
    c9c3:	8b 55 b4             	mov    -0x4c(%ebp),%edx
    c9c6:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    c9c9:	89 10                	mov    %edx,(%eax)
	return r;
    c9cb:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    c9cf:	c9                   	leave  
    c9d0:	c3                   	ret    

0000c9d1 <ck_ring_enqueue_mpmc_child>:
    c9d1:	55                   	push   %ebp
    c9d2:	89 e5                	mov    %esp,%ebp
    c9d4:	83 ec 48             	sub    $0x48,%esp
    c9d7:	8b 45 08             	mov    0x8(%ebp),%eax
    c9da:	89 45 f4             	mov    %eax,-0xc(%ebp)
    c9dd:	8b 45 0c             	mov    0xc(%ebp),%eax
    c9e0:	89 45 f0             	mov    %eax,-0x10(%ebp)
    c9e3:	8b 45 10             	mov    0x10(%ebp),%eax
    c9e6:	89 45 ec             	mov    %eax,-0x14(%ebp)
    c9e9:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
    c9f0:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
    c9f7:	8b 45 f4             	mov    -0xc(%ebp),%eax
    c9fa:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    ca00:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
    ca03:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
    ca07:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ca0a:	83 c0 44             	add    $0x44,%eax
    ca0d:	89 04 24             	mov    %eax,(%esp)
    ca10:	e8 b3 bf ff ff       	call   89c8 <ck_pr_md_load_uint>
    ca15:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
    ca18:	e8 b6 cc ff ff       	call   96d3 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
    ca1d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ca20:	89 04 24             	mov    %eax,(%esp)
    ca23:	e8 a0 bf ff ff       	call   89c8 <ck_pr_md_load_uint>
    ca28:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
    ca2b:	8b 45 cc             	mov    -0x34(%ebp),%eax
    ca2e:	83 c0 01             	add    $0x1,%eax
    ca31:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
    ca34:	8b 45 cc             	mov    -0x34(%ebp),%eax
    ca37:	2b 45 d8             	sub    -0x28(%ebp),%eax
    ca3a:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    ca3d:	0f 97 c0             	seta   %al
    ca40:	0f b6 c0             	movzbl %al,%eax
    ca43:	85 c0                	test   %eax,%eax
    ca45:	74 29                	je     ca70 <ck_ring_enqueue_mpmc_child+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
    ca47:	8b 45 cc             	mov    -0x34(%ebp),%eax
    ca4a:	8b 55 f4             	mov    -0xc(%ebp),%edx
    ca4d:	8d 4a 44             	lea    0x44(%edx),%ecx
    ca50:	8d 55 cc             	lea    -0x34(%ebp),%edx
    ca53:	89 54 24 0c          	mov    %edx,0xc(%esp)
    ca57:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    ca5a:	89 54 24 08          	mov    %edx,0x8(%esp)
    ca5e:	89 44 24 04          	mov    %eax,0x4(%esp)
    ca62:	89 0c 24             	mov    %ecx,(%esp)
    ca65:	e8 5f c9 ff ff       	call   93c9 <ck_pr_cas_uint_value>
    ca6a:	84 c0                	test   %al,%al
    ca6c:	75 31                	jne    ca9f <ck_ring_enqueue_mpmc_child+0xce>
    ca6e:	eb a8                	jmp    ca18 <ck_ring_enqueue_mpmc_child+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
    ca70:	e8 5e cc ff ff       	call   96d3 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
    ca75:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ca78:	83 c0 44             	add    $0x44,%eax
    ca7b:	89 04 24             	mov    %eax,(%esp)
    ca7e:	e8 45 bf ff ff       	call   89c8 <ck_pr_md_load_uint>
    ca83:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
    ca86:	8b 45 cc             	mov    -0x34(%ebp),%eax
    ca89:	39 45 d0             	cmp    %eax,-0x30(%ebp)
    ca8c:	75 06                	jne    ca94 <ck_ring_enqueue_mpmc_child+0xc3>
				r = false;
    ca8e:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
    ca92:	eb 67                	jmp    cafb <ck_ring_enqueue_mpmc_child+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
    ca94:	8b 45 d0             	mov    -0x30(%ebp),%eax
    ca97:	89 45 cc             	mov    %eax,-0x34(%ebp)
    ca9a:	e9 79 ff ff ff       	jmp    ca18 <ck_ring_enqueue_mpmc_child+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
    ca9f:	8b 45 cc             	mov    -0x34(%ebp),%eax
    caa2:	23 45 e0             	and    -0x20(%ebp),%eax
    caa5:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    caa9:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
    caac:	8b 45 e8             	mov    -0x18(%ebp),%eax
    caaf:	89 44 24 08          	mov    %eax,0x8(%esp)
    cab3:	8b 45 ec             	mov    -0x14(%ebp),%eax
    cab6:	89 44 24 04          	mov    %eax,0x4(%esp)
    caba:	8b 45 f0             	mov    -0x10(%ebp),%eax
    cabd:	89 04 24             	mov    %eax,(%esp)
    cac0:	e8 fc ff ff ff       	call   cac1 <ck_ring_enqueue_mpmc_child+0xf0>
    cac5:	eb 05                	jmp    cacc <ck_ring_enqueue_mpmc_child+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
    cac7:	e8 97 bd ff ff       	call   8863 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
    cacc:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cacf:	83 c0 40             	add    $0x40,%eax
    cad2:	89 04 24             	mov    %eax,(%esp)
    cad5:	e8 ee be ff ff       	call   89c8 <ck_pr_md_load_uint>
    cada:	8b 55 cc             	mov    -0x34(%ebp),%edx
    cadd:	39 d0                	cmp    %edx,%eax
    cadf:	75 e6                	jne    cac7 <ck_ring_enqueue_mpmc_child+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
    cae1:	e8 f8 cb ff ff       	call   96de <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
    cae6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cae9:	8d 50 40             	lea    0x40(%eax),%edx
    caec:	8b 45 d4             	mov    -0x2c(%ebp),%eax
    caef:	89 44 24 04          	mov    %eax,0x4(%esp)
    caf3:	89 14 24             	mov    %edx,(%esp)
    caf6:	e8 56 bf ff ff       	call   8a51 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
    cafb:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
    caff:	74 10                	je     cb11 <ck_ring_enqueue_mpmc_child+0x140>
		*size = (producer - consumer) & mask;
    cb01:	8b 45 cc             	mov    -0x34(%ebp),%eax
    cb04:	2b 45 d8             	sub    -0x28(%ebp),%eax
    cb07:	23 45 e0             	and    -0x20(%ebp),%eax
    cb0a:	89 c2                	mov    %eax,%edx
    cb0c:	8b 45 e4             	mov    -0x1c(%ebp),%eax
    cb0f:	89 10                	mov    %edx,(%eax)

	return r;
    cb11:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    cb15:	c9                   	leave  
    cb16:	c3                   	ret    

0000cb17 <ck_ring_trydequeue_mpmc_child>:
    cb17:	55                   	push   %ebp
    cb18:	89 e5                	mov    %esp,%ebp
    cb1a:	83 ec 38             	sub    $0x38,%esp
    cb1d:	8b 45 08             	mov    0x8(%ebp),%eax
    cb20:	89 45 f4             	mov    %eax,-0xc(%ebp)
    cb23:	8b 45 0c             	mov    0xc(%ebp),%eax
    cb26:	89 45 f0             	mov    %eax,-0x10(%ebp)
    cb29:	8b 45 10             	mov    0x10(%ebp),%eax
    cb2c:	89 45 ec             	mov    %eax,-0x14(%ebp)
    cb2f:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
    cb36:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cb39:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    cb3f:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    cb42:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cb45:	89 04 24             	mov    %eax,(%esp)
    cb48:	e8 7b be ff ff       	call   89c8 <ck_pr_md_load_uint>
    cb4d:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
    cb50:	e8 7e cb ff ff       	call   96d3 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
    cb55:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cb58:	83 c0 40             	add    $0x40,%eax
    cb5b:	89 04 24             	mov    %eax,(%esp)
    cb5e:	e8 65 be ff ff       	call   89c8 <ck_pr_md_load_uint>
    cb63:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
    cb66:	8b 45 e0             	mov    -0x20(%ebp),%eax
    cb69:	3b 45 dc             	cmp    -0x24(%ebp),%eax
    cb6c:	0f 94 c0             	sete   %al
    cb6f:	0f b6 c0             	movzbl %al,%eax
    cb72:	85 c0                	test   %eax,%eax
    cb74:	74 07                	je     cb7d <ck_ring_trydequeue_mpmc_child+0x66>
		return false;
    cb76:	b8 00 00 00 00       	mov    $0x0,%eax
    cb7b:	eb 4e                	jmp    cbcb <ck_ring_trydequeue_mpmc_child+0xb4>

	ck_pr_fence_load();
    cb7d:	e8 51 cb ff ff       	call   96d3 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
    cb82:	8b 45 e0             	mov    -0x20(%ebp),%eax
    cb85:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    cb88:	21 d0                	and    %edx,%eax
    cb8a:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    cb8e:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
    cb91:	8b 45 e8             	mov    -0x18(%ebp),%eax
    cb94:	89 44 24 08          	mov    %eax,0x8(%esp)
    cb98:	8b 45 f0             	mov    -0x10(%ebp),%eax
    cb9b:	89 44 24 04          	mov    %eax,0x4(%esp)
    cb9f:	8b 45 ec             	mov    -0x14(%ebp),%eax
    cba2:	89 04 24             	mov    %eax,(%esp)
    cba5:	e8 fc ff ff ff       	call   cba6 <ck_ring_trydequeue_mpmc_child+0x8f>

	ck_pr_fence_store_atomic();
    cbaa:	e8 f8 ca ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
    cbaf:	8b 45 e0             	mov    -0x20(%ebp),%eax
    cbb2:	8d 50 01             	lea    0x1(%eax),%edx
    cbb5:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cbb8:	89 54 24 08          	mov    %edx,0x8(%esp)
    cbbc:	8b 55 e0             	mov    -0x20(%ebp),%edx
    cbbf:	89 54 24 04          	mov    %edx,0x4(%esp)
    cbc3:	89 04 24             	mov    %eax,(%esp)
    cbc6:	e8 ab c6 ff ff       	call   9276 <ck_pr_cas_uint>
    cbcb:	c9                   	leave  
    cbcc:	c3                   	ret    

0000cbcd <ck_ring_dequeue_mpmc_child>:
    cbcd:	55                   	push   %ebp
    cbce:	89 e5                	mov    %esp,%ebp
    cbd0:	53                   	push   %ebx
    cbd1:	83 ec 34             	sub    $0x34,%esp
    cbd4:	8b 45 08             	mov    0x8(%ebp),%eax
    cbd7:	89 45 f4             	mov    %eax,-0xc(%ebp)
    cbda:	8b 45 0c             	mov    0xc(%ebp),%eax
    cbdd:	89 45 f0             	mov    %eax,-0x10(%ebp)
    cbe0:	8b 45 10             	mov    0x10(%ebp),%eax
    cbe3:	89 45 ec             	mov    %eax,-0x14(%ebp)
    cbe6:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
    cbed:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cbf0:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
    cbf6:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
    cbf9:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cbfc:	89 04 24             	mov    %eax,(%esp)
    cbff:	e8 c4 bd ff ff       	call   89c8 <ck_pr_md_load_uint>
    cc04:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
    cc07:	e8 c7 ca ff ff       	call   96d3 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
    cc0c:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cc0f:	83 c0 40             	add    $0x40,%eax
    cc12:	89 04 24             	mov    %eax,(%esp)
    cc15:	e8 ae bd ff ff       	call   89c8 <ck_pr_md_load_uint>
    cc1a:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
    cc1d:	8b 45 d8             	mov    -0x28(%ebp),%eax
    cc20:	39 45 e0             	cmp    %eax,-0x20(%ebp)
    cc23:	0f 94 c0             	sete   %al
    cc26:	0f b6 c0             	movzbl %al,%eax
    cc29:	85 c0                	test   %eax,%eax
    cc2b:	74 07                	je     cc34 <ck_ring_dequeue_mpmc_child+0x67>
			return false;
    cc2d:	b8 00 00 00 00       	mov    $0x0,%eax
    cc32:	eb 6a                	jmp    cc9e <ck_ring_dequeue_mpmc_child+0xd1>

		ck_pr_fence_load();
    cc34:	e8 9a ca ff ff       	call   96d3 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
    cc39:	8b 45 d8             	mov    -0x28(%ebp),%eax
    cc3c:	23 45 e4             	and    -0x1c(%ebp),%eax
    cc3f:	0f af 45 e8          	imul   -0x18(%ebp),%eax
    cc43:	89 c2                	mov    %eax,%edx
    cc45:	8b 45 f0             	mov    -0x10(%ebp),%eax
    cc48:	01 d0                	add    %edx,%eax
    cc4a:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
    cc4d:	8b 45 e8             	mov    -0x18(%ebp),%eax
    cc50:	89 44 24 08          	mov    %eax,0x8(%esp)
    cc54:	8b 45 dc             	mov    -0x24(%ebp),%eax
    cc57:	89 44 24 04          	mov    %eax,0x4(%esp)
    cc5b:	8b 45 ec             	mov    -0x14(%ebp),%eax
    cc5e:	89 04 24             	mov    %eax,(%esp)
    cc61:	e8 fc ff ff ff       	call   cc62 <ck_ring_dequeue_mpmc_child+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
    cc66:	e8 3c ca ff ff       	call   96a7 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
    cc6b:	8b 45 d8             	mov    -0x28(%ebp),%eax
    cc6e:	8d 58 01             	lea    0x1(%eax),%ebx
    cc71:	8b 55 d8             	mov    -0x28(%ebp),%edx
    cc74:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cc77:	8d 4d d8             	lea    -0x28(%ebp),%ecx
    cc7a:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    cc7e:	89 5c 24 08          	mov    %ebx,0x8(%esp)
    cc82:	89 54 24 04          	mov    %edx,0x4(%esp)
    cc86:	89 04 24             	mov    %eax,(%esp)
    cc89:	e8 3b c7 ff ff       	call   93c9 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
    cc8e:	83 f0 01             	xor    $0x1,%eax
    cc91:	84 c0                	test   %al,%al
    cc93:	0f 85 6e ff ff ff    	jne    cc07 <ck_ring_dequeue_mpmc_child+0x3a>

	return true;
    cc99:	b8 01 00 00 00       	mov    $0x1,%eax
    cc9e:	83 c4 34             	add    $0x34,%esp
    cca1:	5b                   	pop    %ebx
    cca2:	5d                   	pop    %ebp
    cca3:	c3                   	ret    

0000cca4 <sl_cs_enter_contention>:
 * These functions are removed from the inlined fast-paths of the
 * critical section (cs) code to save on code size/locality
 */
int
sl_cs_enter_contention(union sl_cs_intern *csi, union sl_cs_intern *cached, thdcap_t curr, sched_tok_t tok)
{
    cca4:	55                   	push   %ebp
    cca5:	89 e5                	mov    %esp,%ebp
    cca7:	56                   	push   %esi
    cca8:	53                   	push   %ebx
    cca9:	83 ec 30             	sub    $0x30,%esp
	struct sl_thd        *t = sl_thd_curr();
    ccac:	e8 4d e7 ff ff       	call   b3fe <sl_thd_curr>
    ccb1:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct sl_global_cpu *g = sl__globals_cpu();
    ccb4:	e8 62 e6 ff ff       	call   b31b <sl__globals_cpu>
    ccb9:	89 45 f0             	mov    %eax,-0x10(%ebp)
	int ret;

	/* recursive locks are not allowed */
	assert(csi->s.owner != sl_thd_thdcap(t));
    ccbc:	8b 45 08             	mov    0x8(%ebp),%eax
    ccbf:	8b 00                	mov    (%eax),%eax
    ccc1:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
    ccc6:	89 c3                	mov    %eax,%ebx
    ccc8:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cccb:	89 04 24             	mov    %eax,(%esp)
    ccce:	e8 8a ba ff ff       	call   875d <sl_thd_thdcap>
    ccd3:	39 c3                	cmp    %eax,%ebx
    ccd5:	0f 94 c0             	sete   %al
    ccd8:	0f b6 c0             	movzbl %al,%eax
    ccdb:	85 c0                	test   %eax,%eax
    ccdd:	74 1c                	je     ccfb <sl_cs_enter_contention+0x57>
    ccdf:	c7 04 24 40 1d 00 00 	movl   $0x1d40,(%esp)
    cce6:	e8 11 b8 ff ff       	call   84fc <prints>
    cceb:	a1 40 01 00 00       	mov    0x140,%eax
    ccf0:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ccf6:	e8 88 b8 ff ff       	call   8583 <__cos_noret>
	if (!csi->s.contention) {
    ccfb:	8b 45 08             	mov    0x8(%ebp),%eax
    ccfe:	0f b6 40 03          	movzbl 0x3(%eax),%eax
    cd02:	83 e0 80             	and    $0xffffff80,%eax
    cd05:	84 c0                	test   %al,%al
    cd07:	75 35                	jne    cd3e <sl_cs_enter_contention+0x9a>
		csi->s.contention = 1;
    cd09:	8b 45 08             	mov    0x8(%ebp),%eax
    cd0c:	0f b6 50 03          	movzbl 0x3(%eax),%edx
    cd10:	83 ca 80             	or     $0xffffff80,%edx
    cd13:	88 50 03             	mov    %dl,0x3(%eax)
		if (!ps_cas(&g->lock.u.v, cached->v, csi->v)) return 1;
    cd16:	8b 45 08             	mov    0x8(%ebp),%eax
    cd19:	8b 08                	mov    (%eax),%ecx
    cd1b:	8b 45 0c             	mov    0xc(%ebp),%eax
    cd1e:	8b 10                	mov    (%eax),%edx
    cd20:	8b 45 f0             	mov    -0x10(%ebp),%eax
    cd23:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    cd27:	89 54 24 04          	mov    %edx,0x4(%esp)
    cd2b:	89 04 24             	mov    %eax,(%esp)
    cd2e:	e8 35 b2 ff ff       	call   7f68 <ps_cas>
    cd33:	85 c0                	test   %eax,%eax
    cd35:	75 07                	jne    cd3e <sl_cs_enter_contention+0x9a>
    cd37:	b8 01 00 00 00       	mov    $0x1,%eax
    cd3c:	eb 6d                	jmp    cdab <sl_cs_enter_contention+0x107>
	}
	/* Switch to the owner of the critical section, with inheritance using our tcap/priority */
	if ((ret = cos_defswitch(csi->s.owner, t->prio, csi->s.owner == sl_thd_thdcap(g->sched_thd) ?
    cd3e:	8b 45 08             	mov    0x8(%ebp),%eax
    cd41:	8b 00                	mov    (%eax),%eax
    cd43:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
    cd48:	89 c3                	mov    %eax,%ebx
    cd4a:	8b 45 f0             	mov    -0x10(%ebp),%eax
    cd4d:	8b 40 10             	mov    0x10(%eax),%eax
    cd50:	89 04 24             	mov    %eax,(%esp)
    cd53:	e8 05 ba ff ff       	call   875d <sl_thd_thdcap>
    cd58:	39 c3                	cmp    %eax,%ebx
    cd5a:	74 08                	je     cd64 <sl_cs_enter_contention+0xc0>
    cd5c:	8b 45 f0             	mov    -0x10(%ebp),%eax
    cd5f:	8b 48 2c             	mov    0x2c(%eax),%ecx
    cd62:	eb 05                	jmp    cd69 <sl_cs_enter_contention+0xc5>
    cd64:	b9 00 00 00 00       	mov    $0x0,%ecx
    cd69:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cd6c:	8b 50 2c             	mov    0x2c(%eax),%edx
    cd6f:	8b 40 28             	mov    0x28(%eax),%eax
    cd72:	8b 5d 08             	mov    0x8(%ebp),%ebx
    cd75:	8b 1b                	mov    (%ebx),%ebx
    cd77:	81 e3 ff ff ff 7f    	and    $0x7fffffff,%ebx
    cd7d:	8b 75 14             	mov    0x14(%ebp),%esi
    cd80:	89 74 24 10          	mov    %esi,0x10(%esp)
    cd84:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
    cd88:	89 44 24 04          	mov    %eax,0x4(%esp)
    cd8c:	89 54 24 08          	mov    %edx,0x8(%esp)
    cd90:	89 1c 24             	mov    %ebx,(%esp)
    cd93:	e8 fc ff ff ff       	call   cd94 <sl_cs_enter_contention+0xf0>
    cd98:	89 45 ec             	mov    %eax,-0x14(%ebp)
    cd9b:	83 7d ec 00          	cmpl   $0x0,-0x14(%ebp)
    cd9f:	74 05                	je     cda6 <sl_cs_enter_contention+0x102>
				 TCAP_TIME_NIL : g->timeout_next, tok))) return ret;
    cda1:	8b 45 ec             	mov    -0x14(%ebp),%eax
    cda4:	eb 05                	jmp    cdab <sl_cs_enter_contention+0x107>
	/* if we have an outdated token, then we want to use the same repeat loop, so return to that */

	return 1;
    cda6:	b8 01 00 00 00       	mov    $0x1,%eax
}
    cdab:	83 c4 30             	add    $0x30,%esp
    cdae:	5b                   	pop    %ebx
    cdaf:	5e                   	pop    %esi
    cdb0:	5d                   	pop    %ebp
    cdb1:	c3                   	ret    

0000cdb2 <sl_cs_exit_contention>:

/* Return 1 if we need a retry, 0 otherwise */
int
sl_cs_exit_contention(union sl_cs_intern *csi, union sl_cs_intern *cached, sched_tok_t tok)
{
    cdb2:	55                   	push   %ebp
    cdb3:	89 e5                	mov    %esp,%ebp
    cdb5:	53                   	push   %ebx
    cdb6:	83 ec 34             	sub    $0x34,%esp
	struct sl_thd        *t = sl_thd_curr();
    cdb9:	e8 40 e6 ff ff       	call   b3fe <sl_thd_curr>
    cdbe:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct sl_global_cpu *g = sl__globals_cpu();
    cdc1:	e8 55 e5 ff ff       	call   b31b <sl__globals_cpu>
    cdc6:	89 45 f0             	mov    %eax,-0x10(%ebp)

	if (!ps_cas(&g->lock.u.v, cached->v, 0)) return 1;
    cdc9:	8b 45 0c             	mov    0xc(%ebp),%eax
    cdcc:	8b 10                	mov    (%eax),%edx
    cdce:	8b 45 f0             	mov    -0x10(%ebp),%eax
    cdd1:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    cdd8:	00 
    cdd9:	89 54 24 04          	mov    %edx,0x4(%esp)
    cddd:	89 04 24             	mov    %eax,(%esp)
    cde0:	e8 83 b1 ff ff       	call   7f68 <ps_cas>
    cde5:	85 c0                	test   %eax,%eax
    cde7:	75 07                	jne    cdf0 <sl_cs_exit_contention+0x3e>
    cde9:	b8 01 00 00 00       	mov    $0x1,%eax
    cdee:	eb 33                	jmp    ce23 <sl_cs_exit_contention+0x71>
	/* let the scheduler thread decide which thread to run next, inheriting our budget/priority */
	cos_defswitch(g->sched_thdcap, t->prio, TCAP_TIME_NIL, tok);
    cdf0:	8b 45 f4             	mov    -0xc(%ebp),%eax
    cdf3:	8b 50 2c             	mov    0x2c(%eax),%edx
    cdf6:	8b 40 28             	mov    0x28(%eax),%eax
    cdf9:	8b 4d f0             	mov    -0x10(%ebp),%ecx
    cdfc:	8b 49 04             	mov    0x4(%ecx),%ecx
    cdff:	8b 5d 10             	mov    0x10(%ebp),%ebx
    ce02:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    ce06:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    ce0d:	00 
    ce0e:	89 44 24 04          	mov    %eax,0x4(%esp)
    ce12:	89 54 24 08          	mov    %edx,0x8(%esp)
    ce16:	89 0c 24             	mov    %ecx,(%esp)
    ce19:	e8 fc ff ff ff       	call   ce1a <sl_cs_exit_contention+0x68>

	return 0;
    ce1e:	b8 00 00 00 00       	mov    $0x0,%eax
}
    ce23:	83 c4 34             	add    $0x34,%esp
    ce26:	5b                   	pop    %ebx
    ce27:	5d                   	pop    %ebp
    ce28:	c3                   	ret    

0000ce29 <sl_timeout_heap>:

static struct timeout_heap timeout_heap[NUM_CPU] CACHE_ALIGNED;

struct heap *
sl_timeout_heap(void)
{ return &timeout_heap[cos_cpuid()].h; }
    ce29:	55                   	push   %ebp
    ce2a:	89 e5                	mov    %esp,%ebp
    ce2c:	e8 50 b5 ff ff       	call   8381 <cos_cpuid>
    ce31:	69 c0 14 01 00 00    	imul   $0x114,%eax,%eax
    ce37:	05 80 01 00 00       	add    $0x180,%eax
    ce3c:	5d                   	pop    %ebp
    ce3d:	c3                   	ret    

0000ce3e <sl_timeout_block>:

static inline void
sl_timeout_block(struct sl_thd *t, cycles_t timeout)
{
    ce3e:	55                   	push   %ebp
    ce3f:	89 e5                	mov    %esp,%ebp
    ce41:	53                   	push   %ebx
    ce42:	83 ec 24             	sub    $0x24,%esp
    ce45:	8b 45 0c             	mov    0xc(%ebp),%eax
    ce48:	89 45 e0             	mov    %eax,-0x20(%ebp)
    ce4b:	8b 45 10             	mov    0x10(%ebp),%eax
    ce4e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	assert(t && t->timeout_idx == -1);
    ce51:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    ce55:	0f 94 c0             	sete   %al
    ce58:	0f b6 c0             	movzbl %al,%eax
    ce5b:	85 c0                	test   %eax,%eax
    ce5d:	75 13                	jne    ce72 <sl_timeout_block+0x34>
    ce5f:	8b 45 08             	mov    0x8(%ebp),%eax
    ce62:	8b 40 5c             	mov    0x5c(%eax),%eax
    ce65:	83 f8 ff             	cmp    $0xffffffff,%eax
    ce68:	0f 95 c0             	setne  %al
    ce6b:	0f b6 c0             	movzbl %al,%eax
    ce6e:	85 c0                	test   %eax,%eax
    ce70:	74 1c                	je     ce8e <sl_timeout_block+0x50>
    ce72:	c7 04 24 6c 1d 00 00 	movl   $0x1d6c,(%esp)
    ce79:	e8 7e b6 ff ff       	call   84fc <prints>
    ce7e:	a1 40 01 00 00       	mov    0x140,%eax
    ce83:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ce89:	e8 f5 b6 ff ff       	call   8583 <__cos_noret>
	assert(heap_size(sl_timeout_heap()) < SL_MAX_NUM_THDS);
    ce8e:	e8 fc ff ff ff       	call   ce8f <sl_timeout_block+0x51>
    ce93:	89 04 24             	mov    %eax,(%esp)
    ce96:	e8 fc ff ff ff       	call   ce97 <sl_timeout_block+0x59>
    ce9b:	83 f8 3f             	cmp    $0x3f,%eax
    ce9e:	0f 9f c0             	setg   %al
    cea1:	0f b6 c0             	movzbl %al,%eax
    cea4:	85 c0                	test   %eax,%eax
    cea6:	74 1c                	je     cec4 <sl_timeout_block+0x86>
    cea8:	c7 04 24 98 1d 00 00 	movl   $0x1d98,(%esp)
    ceaf:	e8 48 b6 ff ff       	call   84fc <prints>
    ceb4:	a1 40 01 00 00       	mov    0x140,%eax
    ceb9:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    cebf:	e8 bf b6 ff ff       	call   8583 <__cos_noret>

	if (!timeout) {
    cec4:	8b 45 e0             	mov    -0x20(%ebp),%eax
    cec7:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    ceca:	09 d0                	or     %edx,%eax
    cecc:	85 c0                	test   %eax,%eax
    cece:	0f 85 ba 00 00 00    	jne    cf8e <sl_timeout_block+0x150>
		cycles_t tmp = t->periodic_cycs;
    ced4:	8b 45 08             	mov    0x8(%ebp),%eax
    ced7:	8b 50 48             	mov    0x48(%eax),%edx
    ceda:	8b 40 44             	mov    0x44(%eax),%eax
    cedd:	89 45 f0             	mov    %eax,-0x10(%ebp)
    cee0:	89 55 f4             	mov    %edx,-0xc(%ebp)

		assert(t->period);
    cee3:	8b 45 08             	mov    0x8(%ebp),%eax
    cee6:	8b 50 40             	mov    0x40(%eax),%edx
    cee9:	8b 40 3c             	mov    0x3c(%eax),%eax
    ceec:	09 d0                	or     %edx,%eax
    ceee:	85 c0                	test   %eax,%eax
    cef0:	0f 94 c0             	sete   %al
    cef3:	0f b6 c0             	movzbl %al,%eax
    cef6:	85 c0                	test   %eax,%eax
    cef8:	74 1c                	je     cf16 <sl_timeout_block+0xd8>
    cefa:	c7 04 24 c4 1d 00 00 	movl   $0x1dc4,(%esp)
    cf01:	e8 f6 b5 ff ff       	call   84fc <prints>
    cf06:	a1 40 01 00 00       	mov    0x140,%eax
    cf0b:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    cf11:	e8 6d b6 ff ff       	call   8583 <__cos_noret>
		t->periodic_cycs += t->period; /* implicit timeout = task period */
    cf16:	8b 45 08             	mov    0x8(%ebp),%eax
    cf19:	8b 48 44             	mov    0x44(%eax),%ecx
    cf1c:	8b 58 48             	mov    0x48(%eax),%ebx
    cf1f:	8b 45 08             	mov    0x8(%ebp),%eax
    cf22:	8b 50 40             	mov    0x40(%eax),%edx
    cf25:	8b 40 3c             	mov    0x3c(%eax),%eax
    cf28:	01 c8                	add    %ecx,%eax
    cf2a:	11 da                	adc    %ebx,%edx
    cf2c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    cf2f:	89 41 44             	mov    %eax,0x44(%ecx)
    cf32:	89 51 48             	mov    %edx,0x48(%ecx)
		assert(tmp < t->periodic_cycs); /* wraparound check */
    cf35:	8b 45 08             	mov    0x8(%ebp),%eax
    cf38:	8b 50 48             	mov    0x48(%eax),%edx
    cf3b:	8b 40 44             	mov    0x44(%eax),%eax
    cf3e:	b9 01 00 00 00       	mov    $0x1,%ecx
    cf43:	3b 55 f4             	cmp    -0xc(%ebp),%edx
    cf46:	72 0f                	jb     cf57 <sl_timeout_block+0x119>
    cf48:	3b 55 f4             	cmp    -0xc(%ebp),%edx
    cf4b:	77 05                	ja     cf52 <sl_timeout_block+0x114>
    cf4d:	3b 45 f0             	cmp    -0x10(%ebp),%eax
    cf50:	76 05                	jbe    cf57 <sl_timeout_block+0x119>
    cf52:	b9 00 00 00 00       	mov    $0x0,%ecx
    cf57:	0f b6 c1             	movzbl %cl,%eax
    cf5a:	85 c0                	test   %eax,%eax
    cf5c:	74 1c                	je     cf7a <sl_timeout_block+0x13c>
    cf5e:	c7 04 24 f0 1d 00 00 	movl   $0x1df0,(%esp)
    cf65:	e8 92 b5 ff ff       	call   84fc <prints>
    cf6a:	a1 40 01 00 00       	mov    0x140,%eax
    cf6f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    cf75:	e8 09 b6 ff ff       	call   8583 <__cos_noret>
		t->timeout_cycs   = t->periodic_cycs;
    cf7a:	8b 45 08             	mov    0x8(%ebp),%eax
    cf7d:	8b 50 48             	mov    0x48(%eax),%edx
    cf80:	8b 40 44             	mov    0x44(%eax),%eax
    cf83:	8b 4d 08             	mov    0x8(%ebp),%ecx
    cf86:	89 41 4c             	mov    %eax,0x4c(%ecx)
    cf89:	89 51 50             	mov    %edx,0x50(%ecx)
    cf8c:	eb 0f                	jmp    cf9d <sl_timeout_block+0x15f>
	} else {
		t->timeout_cycs   = timeout;
    cf8e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    cf91:	8b 45 e0             	mov    -0x20(%ebp),%eax
    cf94:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    cf97:	89 41 4c             	mov    %eax,0x4c(%ecx)
    cf9a:	89 51 50             	mov    %edx,0x50(%ecx)
	}

	t->wakeup_cycs = 0;
    cf9d:	8b 45 08             	mov    0x8(%ebp),%eax
    cfa0:	c7 40 54 00 00 00 00 	movl   $0x0,0x54(%eax)
    cfa7:	c7 40 58 00 00 00 00 	movl   $0x0,0x58(%eax)
	heap_add(sl_timeout_heap(), t);
    cfae:	e8 fc ff ff ff       	call   cfaf <sl_timeout_block+0x171>
    cfb3:	8b 55 08             	mov    0x8(%ebp),%edx
    cfb6:	89 54 24 04          	mov    %edx,0x4(%esp)
    cfba:	89 04 24             	mov    %eax,(%esp)
    cfbd:	e8 fc ff ff ff       	call   cfbe <sl_timeout_block+0x180>
}
    cfc2:	83 c4 24             	add    $0x24,%esp
    cfc5:	5b                   	pop    %ebx
    cfc6:	5d                   	pop    %ebp
    cfc7:	c3                   	ret    

0000cfc8 <sl_timeout_remove>:

static inline void
sl_timeout_remove(struct sl_thd *t)
{
    cfc8:	55                   	push   %ebp
    cfc9:	89 e5                	mov    %esp,%ebp
    cfcb:	53                   	push   %ebx
    cfcc:	83 ec 14             	sub    $0x14,%esp
	assert(t && t->timeout_idx > 0);
    cfcf:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    cfd3:	0f 94 c0             	sete   %al
    cfd6:	0f b6 c0             	movzbl %al,%eax
    cfd9:	85 c0                	test   %eax,%eax
    cfdb:	75 12                	jne    cfef <sl_timeout_remove+0x27>
    cfdd:	8b 45 08             	mov    0x8(%ebp),%eax
    cfe0:	8b 40 5c             	mov    0x5c(%eax),%eax
    cfe3:	85 c0                	test   %eax,%eax
    cfe5:	0f 9e c0             	setle  %al
    cfe8:	0f b6 c0             	movzbl %al,%eax
    cfeb:	85 c0                	test   %eax,%eax
    cfed:	74 1c                	je     d00b <sl_timeout_remove+0x43>
    cfef:	c7 04 24 1c 1e 00 00 	movl   $0x1e1c,(%esp)
    cff6:	e8 01 b5 ff ff       	call   84fc <prints>
    cffb:	a1 40 01 00 00       	mov    0x140,%eax
    d000:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d006:	e8 78 b5 ff ff       	call   8583 <__cos_noret>
	assert(heap_size(sl_timeout_heap()));
    d00b:	e8 fc ff ff ff       	call   d00c <sl_timeout_remove+0x44>
    d010:	89 04 24             	mov    %eax,(%esp)
    d013:	e8 fc ff ff ff       	call   d014 <sl_timeout_remove+0x4c>
    d018:	85 c0                	test   %eax,%eax
    d01a:	0f 94 c0             	sete   %al
    d01d:	0f b6 c0             	movzbl %al,%eax
    d020:	85 c0                	test   %eax,%eax
    d022:	74 1c                	je     d040 <sl_timeout_remove+0x78>
    d024:	c7 04 24 48 1e 00 00 	movl   $0x1e48,(%esp)
    d02b:	e8 cc b4 ff ff       	call   84fc <prints>
    d030:	a1 40 01 00 00       	mov    0x140,%eax
    d035:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d03b:	e8 43 b5 ff ff       	call   8583 <__cos_noret>

	heap_remove(sl_timeout_heap(), t->timeout_idx);
    d040:	8b 45 08             	mov    0x8(%ebp),%eax
    d043:	8b 58 5c             	mov    0x5c(%eax),%ebx
    d046:	e8 fc ff ff ff       	call   d047 <sl_timeout_remove+0x7f>
    d04b:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    d04f:	89 04 24             	mov    %eax,(%esp)
    d052:	e8 fc ff ff ff       	call   d053 <sl_timeout_remove+0x8b>
	t->timeout_idx = -1;
    d057:	8b 45 08             	mov    0x8(%ebp),%eax
    d05a:	c7 40 5c ff ff ff ff 	movl   $0xffffffff,0x5c(%eax)
}
    d061:	83 c4 14             	add    $0x14,%esp
    d064:	5b                   	pop    %ebx
    d065:	5d                   	pop    %ebp
    d066:	c3                   	ret    

0000d067 <sl_thd_free_no_cs>:

void
sl_thd_free_no_cs(struct sl_thd *t)
{
    d067:	55                   	push   %ebp
    d068:	89 e5                	mov    %esp,%ebp
    d06a:	83 ec 28             	sub    $0x28,%esp
        struct sl_thd *ct = sl_thd_curr();
    d06d:	e8 8c e3 ff ff       	call   b3fe <sl_thd_curr>
    d072:	89 45 f4             	mov    %eax,-0xc(%ebp)

        assert(t);
    d075:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    d079:	0f 94 c0             	sete   %al
    d07c:	0f b6 c0             	movzbl %al,%eax
    d07f:	85 c0                	test   %eax,%eax
    d081:	74 1c                	je     d09f <sl_thd_free_no_cs+0x38>
    d083:	c7 04 24 74 1e 00 00 	movl   $0x1e74,(%esp)
    d08a:	e8 6d b4 ff ff       	call   84fc <prints>
    d08f:	a1 40 01 00 00       	mov    0x140,%eax
    d094:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d09a:	e8 e4 b4 ff ff       	call   8583 <__cos_noret>
        assert(t->state != SL_THD_FREE);
    d09f:	8b 45 08             	mov    0x8(%ebp),%eax
    d0a2:	8b 00                	mov    (%eax),%eax
    d0a4:	85 c0                	test   %eax,%eax
    d0a6:	0f 94 c0             	sete   %al
    d0a9:	0f b6 c0             	movzbl %al,%eax
    d0ac:	85 c0                	test   %eax,%eax
    d0ae:	74 1c                	je     d0cc <sl_thd_free_no_cs+0x65>
    d0b0:	c7 04 24 a0 1e 00 00 	movl   $0x1ea0,(%esp)
    d0b7:	e8 40 b4 ff ff       	call   84fc <prints>
    d0bc:	a1 40 01 00 00       	mov    0x140,%eax
    d0c1:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d0c7:	e8 b7 b4 ff ff       	call   8583 <__cos_noret>
        if (t->state == SL_THD_BLOCKED_TIMEOUT) sl_timeout_remove(t);
    d0cc:	8b 45 08             	mov    0x8(%ebp),%eax
    d0cf:	8b 00                	mov    (%eax),%eax
    d0d1:	83 f8 02             	cmp    $0x2,%eax
    d0d4:	75 0b                	jne    d0e1 <sl_thd_free_no_cs+0x7a>
    d0d6:	8b 45 08             	mov    0x8(%ebp),%eax
    d0d9:	89 04 24             	mov    %eax,(%esp)
    d0dc:	e8 e7 fe ff ff       	call   cfc8 <sl_timeout_remove>
        sl_thd_index_rem_backend(sl_mod_thd_policy_get(t));
    d0e1:	8b 45 08             	mov    0x8(%ebp),%eax
    d0e4:	89 04 24             	mov    %eax,(%esp)
    d0e7:	e8 ba b6 ff ff       	call   87a6 <sl_mod_thd_policy_get>
    d0ec:	89 04 24             	mov    %eax,(%esp)
    d0ef:	e8 fc ff ff ff       	call   d0f0 <sl_thd_free_no_cs+0x89>
        sl_mod_thd_delete(sl_mod_thd_policy_get(t));
    d0f4:	8b 45 08             	mov    0x8(%ebp),%eax
    d0f7:	89 04 24             	mov    %eax,(%esp)
    d0fa:	e8 a7 b6 ff ff       	call   87a6 <sl_mod_thd_policy_get>
    d0ff:	89 04 24             	mov    %eax,(%esp)
    d102:	e8 fc ff ff ff       	call   d103 <sl_thd_free_no_cs+0x9c>
        t->state = SL_THD_FREE;
    d107:	8b 45 08             	mov    0x8(%ebp),%eax
    d10a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
        /* TODO: add logic for the graveyard to delay this deallocation if t == current */
        sl_thd_free_backend(sl_mod_thd_policy_get(t));
    d110:	8b 45 08             	mov    0x8(%ebp),%eax
    d113:	89 04 24             	mov    %eax,(%esp)
    d116:	e8 8b b6 ff ff       	call   87a6 <sl_mod_thd_policy_get>
    d11b:	89 04 24             	mov    %eax,(%esp)
    d11e:	e8 fc ff ff ff       	call   d11f <sl_thd_free_no_cs+0xb8>

        /* thread should not continue to run if it deletes itself. */
        if (unlikely(t == ct)) {
    d123:	8b 45 08             	mov    0x8(%ebp),%eax
    d126:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    d129:	0f 94 c0             	sete   %al
    d12c:	0f b6 c0             	movzbl %al,%eax
    d12f:	85 c0                	test   %eax,%eax
    d131:	74 07                	je     d13a <sl_thd_free_no_cs+0xd3>
                while (1) sl_cs_exit_schedule();
    d133:	e8 be ed ff ff       	call   bef6 <sl_cs_exit_schedule>
    d138:	eb f9                	jmp    d133 <sl_thd_free_no_cs+0xcc>
                /* FIXME: should never get here, but tcap mechanism can let a child scheduler run! */
        }
}
    d13a:	c9                   	leave  
    d13b:	c3                   	ret    

0000d13c <__sl_timeout_compare_min>:

static int
__sl_timeout_compare_min(void *a, void *b)
{
    d13c:	55                   	push   %ebp
    d13d:	89 e5                	mov    %esp,%ebp
    d13f:	56                   	push   %esi
    d140:	53                   	push   %ebx
	/* FIXME: logic for wraparound in either timeout_cycs */
	return ((struct sl_thd *)a)->timeout_cycs <= ((struct sl_thd *)b)->timeout_cycs;
    d141:	8b 45 08             	mov    0x8(%ebp),%eax
    d144:	8b 48 4c             	mov    0x4c(%eax),%ecx
    d147:	8b 58 50             	mov    0x50(%eax),%ebx
    d14a:	8b 45 0c             	mov    0xc(%ebp),%eax
    d14d:	8b 50 50             	mov    0x50(%eax),%edx
    d150:	8b 40 4c             	mov    0x4c(%eax),%eax
    d153:	be 01 00 00 00       	mov    $0x1,%esi
    d158:	39 d3                	cmp    %edx,%ebx
    d15a:	72 0d                	jb     d169 <__sl_timeout_compare_min+0x2d>
    d15c:	39 d3                	cmp    %edx,%ebx
    d15e:	77 04                	ja     d164 <__sl_timeout_compare_min+0x28>
    d160:	39 c1                	cmp    %eax,%ecx
    d162:	76 05                	jbe    d169 <__sl_timeout_compare_min+0x2d>
    d164:	be 00 00 00 00       	mov    $0x0,%esi
    d169:	89 f0                	mov    %esi,%eax
    d16b:	0f b6 c0             	movzbl %al,%eax
}
    d16e:	5b                   	pop    %ebx
    d16f:	5e                   	pop    %esi
    d170:	5d                   	pop    %ebp
    d171:	c3                   	ret    

0000d172 <__sl_timeout_update_idx>:

static void
__sl_timeout_update_idx(void *e, int pos)
{ ((struct sl_thd *)e)->timeout_idx = pos; }
    d172:	55                   	push   %ebp
    d173:	89 e5                	mov    %esp,%ebp
    d175:	8b 45 08             	mov    0x8(%ebp),%eax
    d178:	8b 55 0c             	mov    0xc(%ebp),%edx
    d17b:	89 50 5c             	mov    %edx,0x5c(%eax)
    d17e:	5d                   	pop    %ebp
    d17f:	c3                   	ret    

0000d180 <sl_timeout_init>:

static void
sl_timeout_init(microsec_t period)
{
    d180:	55                   	push   %ebp
    d181:	89 e5                	mov    %esp,%ebp
    d183:	83 ec 28             	sub    $0x28,%esp
    d186:	8b 45 08             	mov    0x8(%ebp),%eax
    d189:	89 45 f0             	mov    %eax,-0x10(%ebp)
    d18c:	8b 45 0c             	mov    0xc(%ebp),%eax
    d18f:	89 45 f4             	mov    %eax,-0xc(%ebp)
	assert(period >= SL_MIN_PERIOD_US);
    d192:	b8 01 00 00 00       	mov    $0x1,%eax
    d197:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    d19b:	72 14                	jb     d1b1 <sl_timeout_init+0x31>
    d19d:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    d1a1:	77 09                	ja     d1ac <sl_timeout_init+0x2c>
    d1a3:	81 7d f0 e7 03 00 00 	cmpl   $0x3e7,-0x10(%ebp)
    d1aa:	76 05                	jbe    d1b1 <sl_timeout_init+0x31>
    d1ac:	b8 00 00 00 00       	mov    $0x0,%eax
    d1b1:	0f b6 c0             	movzbl %al,%eax
    d1b4:	85 c0                	test   %eax,%eax
    d1b6:	74 1c                	je     d1d4 <sl_timeout_init+0x54>
    d1b8:	c7 04 24 cc 1e 00 00 	movl   $0x1ecc,(%esp)
    d1bf:	e8 38 b3 ff ff       	call   84fc <prints>
    d1c4:	a1 40 01 00 00       	mov    0x140,%eax
    d1c9:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d1cf:	e8 af b3 ff ff       	call   8583 <__cos_noret>

	sl_timeout_period(period);
    d1d4:	8b 45 f0             	mov    -0x10(%ebp),%eax
    d1d7:	8b 55 f4             	mov    -0xc(%ebp),%edx
    d1da:	89 04 24             	mov    %eax,(%esp)
    d1dd:	89 54 24 04          	mov    %edx,0x4(%esp)
    d1e1:	e8 fc ff ff ff       	call   d1e2 <sl_timeout_init+0x62>
	memset(&timeout_heap[cos_cpuid()], 0, sizeof(struct timeout_heap));
    d1e6:	e8 96 b1 ff ff       	call   8381 <cos_cpuid>
    d1eb:	69 c0 14 01 00 00    	imul   $0x114,%eax,%eax
    d1f1:	05 80 01 00 00       	add    $0x180,%eax
    d1f6:	c7 44 24 08 14 01 00 	movl   $0x114,0x8(%esp)
    d1fd:	00 
    d1fe:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    d205:	00 
    d206:	89 04 24             	mov    %eax,(%esp)
    d209:	e8 fc ff ff ff       	call   d20a <sl_timeout_init+0x8a>
	heap_init(sl_timeout_heap(), SL_MAX_NUM_THDS, __sl_timeout_compare_min, __sl_timeout_update_idx);
    d20e:	e8 fc ff ff ff       	call   d20f <sl_timeout_init+0x8f>
    d213:	c7 44 24 0c 72 d1 00 	movl   $0xd172,0xc(%esp)
    d21a:	00 
    d21b:	c7 44 24 08 3c d1 00 	movl   $0xd13c,0x8(%esp)
    d222:	00 
    d223:	c7 44 24 04 40 00 00 	movl   $0x40,0x4(%esp)
    d22a:	00 
    d22b:	89 04 24             	mov    %eax,(%esp)
    d22e:	e8 fc ff ff ff       	call   d22f <sl_timeout_init+0xaf>
}
    d233:	c9                   	leave  
    d234:	c3                   	ret    

0000d235 <sl_thd_sched_block_no_cs>:
 *
 * @return: 0 if it successfully blocked in this call.
 */
int
sl_thd_sched_block_no_cs(struct sl_thd *t, sl_thd_state_t block_type, cycles_t timeout)
{
    d235:	55                   	push   %ebp
    d236:	89 e5                	mov    %esp,%ebp
    d238:	83 ec 28             	sub    $0x28,%esp
    d23b:	8b 45 10             	mov    0x10(%ebp),%eax
    d23e:	89 45 f0             	mov    %eax,-0x10(%ebp)
    d241:	8b 45 14             	mov    0x14(%ebp),%eax
    d244:	89 45 f4             	mov    %eax,-0xc(%ebp)
	assert(t);
    d247:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    d24b:	0f 94 c0             	sete   %al
    d24e:	0f b6 c0             	movzbl %al,%eax
    d251:	85 c0                	test   %eax,%eax
    d253:	74 1c                	je     d271 <sl_thd_sched_block_no_cs+0x3c>
    d255:	c7 04 24 f8 1e 00 00 	movl   $0x1ef8,(%esp)
    d25c:	e8 9b b2 ff ff       	call   84fc <prints>
    d261:	a1 40 01 00 00       	mov    0x140,%eax
    d266:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d26c:	e8 12 b3 ff ff       	call   8583 <__cos_noret>
	assert(t != sl__globals_cpu()->idle_thd && t != sl__globals_cpu()->sched_thd);
    d271:	e8 a5 e0 ff ff       	call   b31b <sl__globals_cpu>
    d276:	8b 40 14             	mov    0x14(%eax),%eax
    d279:	3b 45 08             	cmp    0x8(%ebp),%eax
    d27c:	0f 94 c0             	sete   %al
    d27f:	0f b6 c0             	movzbl %al,%eax
    d282:	85 c0                	test   %eax,%eax
    d284:	75 15                	jne    d29b <sl_thd_sched_block_no_cs+0x66>
    d286:	e8 90 e0 ff ff       	call   b31b <sl__globals_cpu>
    d28b:	8b 40 10             	mov    0x10(%eax),%eax
    d28e:	3b 45 08             	cmp    0x8(%ebp),%eax
    d291:	0f 94 c0             	sete   %al
    d294:	0f b6 c0             	movzbl %al,%eax
    d297:	85 c0                	test   %eax,%eax
    d299:	74 1c                	je     d2b7 <sl_thd_sched_block_no_cs+0x82>
    d29b:	c7 04 24 24 1f 00 00 	movl   $0x1f24,(%esp)
    d2a2:	e8 55 b2 ff ff       	call   84fc <prints>
    d2a7:	a1 40 01 00 00       	mov    0x140,%eax
    d2ac:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d2b2:	e8 cc b2 ff ff       	call   8583 <__cos_noret>
	assert(block_type == SL_THD_BLOCKED_TIMEOUT || block_type == SL_THD_BLOCKED);
    d2b7:	83 7d 0c 02          	cmpl   $0x2,0xc(%ebp)
    d2bb:	0f 95 c0             	setne  %al
    d2be:	0f b6 c0             	movzbl %al,%eax
    d2c1:	85 c0                	test   %eax,%eax
    d2c3:	74 2a                	je     d2ef <sl_thd_sched_block_no_cs+0xba>
    d2c5:	83 7d 0c 01          	cmpl   $0x1,0xc(%ebp)
    d2c9:	0f 95 c0             	setne  %al
    d2cc:	0f b6 c0             	movzbl %al,%eax
    d2cf:	85 c0                	test   %eax,%eax
    d2d1:	74 1c                	je     d2ef <sl_thd_sched_block_no_cs+0xba>
    d2d3:	c7 04 24 50 1f 00 00 	movl   $0x1f50,(%esp)
    d2da:	e8 1d b2 ff ff       	call   84fc <prints>
    d2df:	a1 40 01 00 00       	mov    0x140,%eax
    d2e4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d2ea:	e8 94 b2 ff ff       	call   8583 <__cos_noret>

	if (t->schedthd) return 0;
    d2ef:	8b 45 08             	mov    0x8(%ebp),%eax
    d2f2:	8b 40 18             	mov    0x18(%eax),%eax
    d2f5:	85 c0                	test   %eax,%eax
    d2f7:	74 0a                	je     d303 <sl_thd_sched_block_no_cs+0xce>
    d2f9:	b8 00 00 00 00       	mov    $0x0,%eax
    d2fe:	e9 b9 00 00 00       	jmp    d3bc <sl_thd_sched_block_no_cs+0x187>
	 * If an AEP/a child COMP was blocked and an interrupt caused it to wakeup and run
	 * but blocks itself before the scheduler could see the wakeup event.. Scheduler
	 * will only see a BLOCKED event from the kernel.
	 * Only update the timeout if it already exists in the TIMEOUT QUEUE.
	 */
	if (unlikely(t->state == SL_THD_BLOCKED_TIMEOUT || t->state == SL_THD_BLOCKED)) {
    d303:	8b 45 08             	mov    0x8(%ebp),%eax
    d306:	8b 00                	mov    (%eax),%eax
    d308:	83 f8 02             	cmp    $0x2,%eax
    d30b:	0f 94 c0             	sete   %al
    d30e:	0f b6 c0             	movzbl %al,%eax
    d311:	85 c0                	test   %eax,%eax
    d313:	75 12                	jne    d327 <sl_thd_sched_block_no_cs+0xf2>
    d315:	8b 45 08             	mov    0x8(%ebp),%eax
    d318:	8b 00                	mov    (%eax),%eax
    d31a:	83 f8 01             	cmp    $0x1,%eax
    d31d:	0f 94 c0             	sete   %al
    d320:	0f b6 c0             	movzbl %al,%eax
    d323:	85 c0                	test   %eax,%eax
    d325:	74 19                	je     d340 <sl_thd_sched_block_no_cs+0x10b>
		if (t->state == SL_THD_BLOCKED_TIMEOUT) sl_timeout_remove(t);
    d327:	8b 45 08             	mov    0x8(%ebp),%eax
    d32a:	8b 00                	mov    (%eax),%eax
    d32c:	83 f8 02             	cmp    $0x2,%eax
    d32f:	75 0d                	jne    d33e <sl_thd_sched_block_no_cs+0x109>
    d331:	8b 45 08             	mov    0x8(%ebp),%eax
    d334:	89 04 24             	mov    %eax,(%esp)
    d337:	e8 8c fc ff ff       	call   cfc8 <sl_timeout_remove>
		goto update;
    d33c:	eb 48                	jmp    d386 <sl_thd_sched_block_no_cs+0x151>
    d33e:	eb 46                	jmp    d386 <sl_thd_sched_block_no_cs+0x151>
	}

	assert(sl_thd_is_runnable(t));
    d340:	8b 45 08             	mov    0x8(%ebp),%eax
    d343:	89 04 24             	mov    %eax,(%esp)
    d346:	e8 8b e5 ff ff       	call   b8d6 <sl_thd_is_runnable>
    d34b:	85 c0                	test   %eax,%eax
    d34d:	0f 94 c0             	sete   %al
    d350:	0f b6 c0             	movzbl %al,%eax
    d353:	85 c0                	test   %eax,%eax
    d355:	74 1c                	je     d373 <sl_thd_sched_block_no_cs+0x13e>
    d357:	c7 04 24 7c 1f 00 00 	movl   $0x1f7c,(%esp)
    d35e:	e8 99 b1 ff ff       	call   84fc <prints>
    d363:	a1 40 01 00 00       	mov    0x140,%eax
    d368:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d36e:	e8 10 b2 ff ff       	call   8583 <__cos_noret>
	sl_mod_block(sl_mod_thd_policy_get(t));
    d373:	8b 45 08             	mov    0x8(%ebp),%eax
    d376:	89 04 24             	mov    %eax,(%esp)
    d379:	e8 28 b4 ff ff       	call   87a6 <sl_mod_thd_policy_get>
    d37e:	89 04 24             	mov    %eax,(%esp)
    d381:	e8 fc ff ff ff       	call   d382 <sl_thd_sched_block_no_cs+0x14d>

update:
	t->state = block_type;
    d386:	8b 45 08             	mov    0x8(%ebp),%eax
    d389:	8b 55 0c             	mov    0xc(%ebp),%edx
    d38c:	89 10                	mov    %edx,(%eax)
	if (block_type == SL_THD_BLOCKED_TIMEOUT) sl_timeout_block(t, timeout);
    d38e:	83 7d 0c 02          	cmpl   $0x2,0xc(%ebp)
    d392:	75 19                	jne    d3ad <sl_thd_sched_block_no_cs+0x178>
    d394:	8b 45 f0             	mov    -0x10(%ebp),%eax
    d397:	8b 55 f4             	mov    -0xc(%ebp),%edx
    d39a:	89 44 24 04          	mov    %eax,0x4(%esp)
    d39e:	89 54 24 08          	mov    %edx,0x8(%esp)
    d3a2:	8b 45 08             	mov    0x8(%ebp),%eax
    d3a5:	89 04 24             	mov    %eax,(%esp)
    d3a8:	e8 91 fa ff ff       	call   ce3e <sl_timeout_block>
	t->rcv_suspended = 1;
    d3ad:	8b 45 08             	mov    0x8(%ebp),%eax
    d3b0:	c7 40 04 01 00 00 00 	movl   $0x1,0x4(%eax)

	return 0;
    d3b7:	b8 00 00 00 00       	mov    $0x0,%eax
}
    d3bc:	c9                   	leave  
    d3bd:	c3                   	ret    

0000d3be <sl_thd_sched_unblock_no_cs>:
 * Wake "t" up if it was previously blocked on cos_rcv and got
 * to run before the scheduler (tcap-activated)!
 */
static inline int
sl_thd_sched_unblock_no_cs(struct sl_thd *t)
{
    d3be:	55                   	push   %ebp
    d3bf:	89 e5                	mov    %esp,%ebp
    d3c1:	83 ec 18             	sub    $0x18,%esp
	if (unlikely(!t->rcv_suspended)) return 0;
    d3c4:	8b 45 08             	mov    0x8(%ebp),%eax
    d3c7:	8b 40 04             	mov    0x4(%eax),%eax
    d3ca:	85 c0                	test   %eax,%eax
    d3cc:	0f 94 c0             	sete   %al
    d3cf:	0f b6 c0             	movzbl %al,%eax
    d3d2:	85 c0                	test   %eax,%eax
    d3d4:	74 07                	je     d3dd <sl_thd_sched_unblock_no_cs+0x1f>
    d3d6:	b8 00 00 00 00       	mov    $0x0,%eax
    d3db:	eb 62                	jmp    d43f <sl_thd_sched_unblock_no_cs+0x81>
	t->rcv_suspended = 0;
    d3dd:	8b 45 08             	mov    0x8(%ebp),%eax
    d3e0:	c7 40 04 00 00 00 00 	movl   $0x0,0x4(%eax)
	if (unlikely(t->state != SL_THD_BLOCKED && t->state != SL_THD_BLOCKED_TIMEOUT)) return 0;
    d3e7:	8b 45 08             	mov    0x8(%ebp),%eax
    d3ea:	8b 00                	mov    (%eax),%eax
    d3ec:	83 f8 01             	cmp    $0x1,%eax
    d3ef:	0f 95 c0             	setne  %al
    d3f2:	0f b6 c0             	movzbl %al,%eax
    d3f5:	85 c0                	test   %eax,%eax
    d3f7:	74 19                	je     d412 <sl_thd_sched_unblock_no_cs+0x54>
    d3f9:	8b 45 08             	mov    0x8(%ebp),%eax
    d3fc:	8b 00                	mov    (%eax),%eax
    d3fe:	83 f8 02             	cmp    $0x2,%eax
    d401:	0f 95 c0             	setne  %al
    d404:	0f b6 c0             	movzbl %al,%eax
    d407:	85 c0                	test   %eax,%eax
    d409:	74 07                	je     d412 <sl_thd_sched_unblock_no_cs+0x54>
    d40b:	b8 00 00 00 00       	mov    $0x0,%eax
    d410:	eb 2d                	jmp    d43f <sl_thd_sched_unblock_no_cs+0x81>

	if (likely(t->state == SL_THD_BLOCKED_TIMEOUT)) sl_timeout_remove(t);
    d412:	8b 45 08             	mov    0x8(%ebp),%eax
    d415:	8b 00                	mov    (%eax),%eax
    d417:	83 f8 02             	cmp    $0x2,%eax
    d41a:	0f 94 c0             	sete   %al
    d41d:	0f b6 c0             	movzbl %al,%eax
    d420:	85 c0                	test   %eax,%eax
    d422:	74 0b                	je     d42f <sl_thd_sched_unblock_no_cs+0x71>
    d424:	8b 45 08             	mov    0x8(%ebp),%eax
    d427:	89 04 24             	mov    %eax,(%esp)
    d42a:	e8 99 fb ff ff       	call   cfc8 <sl_timeout_remove>
	/* make it RUNNABLE */
	sl_thd_wakeup_no_cs_rm(t);
    d42f:	8b 45 08             	mov    0x8(%ebp),%eax
    d432:	89 04 24             	mov    %eax,(%esp)
    d435:	e8 fc ff ff ff       	call   d436 <sl_thd_sched_unblock_no_cs+0x78>

	return 1;
    d43a:	b8 01 00 00 00       	mov    $0x1,%eax
}
    d43f:	c9                   	leave  
    d440:	c3                   	ret    

0000d441 <sl_thd_block_no_cs>:
 * @return: 1 if it's already WOKEN.
 *	    0 if it successfully blocked in this call.
 */
int
sl_thd_block_no_cs(struct sl_thd *t, sl_thd_state_t block_type, cycles_t timeout)
{
    d441:	55                   	push   %ebp
    d442:	89 e5                	mov    %esp,%ebp
    d444:	83 ec 28             	sub    $0x28,%esp
    d447:	8b 45 10             	mov    0x10(%ebp),%eax
    d44a:	89 45 f0             	mov    %eax,-0x10(%ebp)
    d44d:	8b 45 14             	mov    0x14(%ebp),%eax
    d450:	89 45 f4             	mov    %eax,-0xc(%ebp)
	assert(t);
    d453:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    d457:	0f 94 c0             	sete   %al
    d45a:	0f b6 c0             	movzbl %al,%eax
    d45d:	85 c0                	test   %eax,%eax
    d45f:	74 1c                	je     d47d <sl_thd_block_no_cs+0x3c>
    d461:	c7 04 24 a8 1f 00 00 	movl   $0x1fa8,(%esp)
    d468:	e8 8f b0 ff ff       	call   84fc <prints>
    d46d:	a1 40 01 00 00       	mov    0x140,%eax
    d472:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d478:	e8 06 b1 ff ff       	call   8583 <__cos_noret>
	assert(t != sl__globals_cpu()->idle_thd && t != sl__globals_cpu()->sched_thd);
    d47d:	e8 99 de ff ff       	call   b31b <sl__globals_cpu>
    d482:	8b 40 14             	mov    0x14(%eax),%eax
    d485:	3b 45 08             	cmp    0x8(%ebp),%eax
    d488:	0f 94 c0             	sete   %al
    d48b:	0f b6 c0             	movzbl %al,%eax
    d48e:	85 c0                	test   %eax,%eax
    d490:	75 15                	jne    d4a7 <sl_thd_block_no_cs+0x66>
    d492:	e8 84 de ff ff       	call   b31b <sl__globals_cpu>
    d497:	8b 40 10             	mov    0x10(%eax),%eax
    d49a:	3b 45 08             	cmp    0x8(%ebp),%eax
    d49d:	0f 94 c0             	sete   %al
    d4a0:	0f b6 c0             	movzbl %al,%eax
    d4a3:	85 c0                	test   %eax,%eax
    d4a5:	74 1c                	je     d4c3 <sl_thd_block_no_cs+0x82>
    d4a7:	c7 04 24 d4 1f 00 00 	movl   $0x1fd4,(%esp)
    d4ae:	e8 49 b0 ff ff       	call   84fc <prints>
    d4b3:	a1 40 01 00 00       	mov    0x140,%eax
    d4b8:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d4be:	e8 c0 b0 ff ff       	call   8583 <__cos_noret>
	assert(sl_thd_curr() == t); /* only current thread is allowed to block itself */
    d4c3:	e8 36 df ff ff       	call   b3fe <sl_thd_curr>
    d4c8:	3b 45 08             	cmp    0x8(%ebp),%eax
    d4cb:	0f 95 c0             	setne  %al
    d4ce:	0f b6 c0             	movzbl %al,%eax
    d4d1:	85 c0                	test   %eax,%eax
    d4d3:	74 1c                	je     d4f1 <sl_thd_block_no_cs+0xb0>
    d4d5:	c7 04 24 00 20 00 00 	movl   $0x2000,(%esp)
    d4dc:	e8 1b b0 ff ff       	call   84fc <prints>
    d4e1:	a1 40 01 00 00       	mov    0x140,%eax
    d4e6:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d4ec:	e8 92 b0 ff ff       	call   8583 <__cos_noret>
	assert(block_type == SL_THD_BLOCKED_TIMEOUT || block_type == SL_THD_BLOCKED);
    d4f1:	83 7d 0c 02          	cmpl   $0x2,0xc(%ebp)
    d4f5:	0f 95 c0             	setne  %al
    d4f8:	0f b6 c0             	movzbl %al,%eax
    d4fb:	85 c0                	test   %eax,%eax
    d4fd:	74 2a                	je     d529 <sl_thd_block_no_cs+0xe8>
    d4ff:	83 7d 0c 01          	cmpl   $0x1,0xc(%ebp)
    d503:	0f 95 c0             	setne  %al
    d506:	0f b6 c0             	movzbl %al,%eax
    d509:	85 c0                	test   %eax,%eax
    d50b:	74 1c                	je     d529 <sl_thd_block_no_cs+0xe8>
    d50d:	c7 04 24 2c 20 00 00 	movl   $0x202c,(%esp)
    d514:	e8 e3 af ff ff       	call   84fc <prints>
    d519:	a1 40 01 00 00       	mov    0x140,%eax
    d51e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d524:	e8 5a b0 ff ff       	call   8583 <__cos_noret>

	if (t->schedthd) {
    d529:	8b 45 08             	mov    0x8(%ebp),%eax
    d52c:	8b 40 18             	mov    0x18(%eax),%eax
    d52f:	85 c0                	test   %eax,%eax
    d531:	74 1f                	je     d552 <sl_thd_block_no_cs+0x111>
		sl_parent_notif_block_no_cs(t->schedthd, t);
    d533:	8b 45 08             	mov    0x8(%ebp),%eax
    d536:	8b 40 18             	mov    0x18(%eax),%eax
    d539:	8b 55 08             	mov    0x8(%ebp),%edx
    d53c:	89 54 24 04          	mov    %edx,0x4(%esp)
    d540:	89 04 24             	mov    %eax,(%esp)
    d543:	e8 fc ff ff ff       	call   d544 <sl_thd_block_no_cs+0x103>

		return 0;
    d548:	b8 00 00 00 00       	mov    $0x0,%eax
    d54d:	e9 c8 00 00 00       	jmp    d61a <sl_thd_block_no_cs+0x1d9>
	}

	if (unlikely(t->state == SL_THD_WOKEN)) {
    d552:	8b 45 08             	mov    0x8(%ebp),%eax
    d555:	8b 00                	mov    (%eax),%eax
    d557:	83 f8 03             	cmp    $0x3,%eax
    d55a:	0f 94 c0             	sete   %al
    d55d:	0f b6 c0             	movzbl %al,%eax
    d560:	85 c0                	test   %eax,%eax
    d562:	74 3e                	je     d5a2 <sl_thd_block_no_cs+0x161>
		assert(!t->rcv_suspended);
    d564:	8b 45 08             	mov    0x8(%ebp),%eax
    d567:	8b 40 04             	mov    0x4(%eax),%eax
    d56a:	85 c0                	test   %eax,%eax
    d56c:	0f 95 c0             	setne  %al
    d56f:	0f b6 c0             	movzbl %al,%eax
    d572:	85 c0                	test   %eax,%eax
    d574:	74 1c                	je     d592 <sl_thd_block_no_cs+0x151>
    d576:	c7 04 24 58 20 00 00 	movl   $0x2058,(%esp)
    d57d:	e8 7a af ff ff       	call   84fc <prints>
    d582:	a1 40 01 00 00       	mov    0x140,%eax
    d587:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d58d:	e8 f1 af ff ff       	call   8583 <__cos_noret>
		t->state = SL_THD_RUNNABLE;
    d592:	8b 45 08             	mov    0x8(%ebp),%eax
    d595:	c7 00 04 00 00 00    	movl   $0x4,(%eax)
		return 1;
    d59b:	b8 01 00 00 00       	mov    $0x1,%eax
    d5a0:	eb 78                	jmp    d61a <sl_thd_block_no_cs+0x1d9>
	}

	/* reset rcv_suspended if the scheduler thinks "curr" was suspended on cos_rcv previously */
	sl_thd_sched_unblock_no_cs(t);
    d5a2:	8b 45 08             	mov    0x8(%ebp),%eax
    d5a5:	89 04 24             	mov    %eax,(%esp)
    d5a8:	e8 11 fe ff ff       	call   d3be <sl_thd_sched_unblock_no_cs>
	assert(t->state == SL_THD_RUNNABLE);
    d5ad:	8b 45 08             	mov    0x8(%ebp),%eax
    d5b0:	8b 00                	mov    (%eax),%eax
    d5b2:	83 f8 04             	cmp    $0x4,%eax
    d5b5:	0f 95 c0             	setne  %al
    d5b8:	0f b6 c0             	movzbl %al,%eax
    d5bb:	85 c0                	test   %eax,%eax
    d5bd:	74 1c                	je     d5db <sl_thd_block_no_cs+0x19a>
    d5bf:	c7 04 24 84 20 00 00 	movl   $0x2084,(%esp)
    d5c6:	e8 31 af ff ff       	call   84fc <prints>
    d5cb:	a1 40 01 00 00       	mov    0x140,%eax
    d5d0:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d5d6:	e8 a8 af ff ff       	call   8583 <__cos_noret>
	sl_mod_block(sl_mod_thd_policy_get(t));
    d5db:	8b 45 08             	mov    0x8(%ebp),%eax
    d5de:	89 04 24             	mov    %eax,(%esp)
    d5e1:	e8 c0 b1 ff ff       	call   87a6 <sl_mod_thd_policy_get>
    d5e6:	89 04 24             	mov    %eax,(%esp)
    d5e9:	e8 fc ff ff ff       	call   d5ea <sl_thd_block_no_cs+0x1a9>
	t->state = block_type;
    d5ee:	8b 45 08             	mov    0x8(%ebp),%eax
    d5f1:	8b 55 0c             	mov    0xc(%ebp),%edx
    d5f4:	89 10                	mov    %edx,(%eax)
	if (block_type == SL_THD_BLOCKED_TIMEOUT) sl_timeout_block(t, timeout);
    d5f6:	83 7d 0c 02          	cmpl   $0x2,0xc(%ebp)
    d5fa:	75 19                	jne    d615 <sl_thd_block_no_cs+0x1d4>
    d5fc:	8b 45 f0             	mov    -0x10(%ebp),%eax
    d5ff:	8b 55 f4             	mov    -0xc(%ebp),%edx
    d602:	89 44 24 04          	mov    %eax,0x4(%esp)
    d606:	89 54 24 08          	mov    %edx,0x8(%esp)
    d60a:	8b 45 08             	mov    0x8(%ebp),%eax
    d60d:	89 04 24             	mov    %eax,(%esp)
    d610:	e8 29 f8 ff ff       	call   ce3e <sl_timeout_block>

	return 0;
    d615:	b8 00 00 00 00       	mov    $0x0,%eax
}
    d61a:	c9                   	leave  
    d61b:	c3                   	ret    

0000d61c <sl_thd_block>:

void
sl_thd_block(thdid_t tid)
{
    d61c:	55                   	push   %ebp
    d61d:	89 e5                	mov    %esp,%ebp
    d61f:	83 ec 38             	sub    $0x38,%esp
    d622:	8b 45 08             	mov    0x8(%ebp),%eax
    d625:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
	struct sl_thd *t;

	/* TODO: dependencies not yet supported */
	assert(!tid);
    d629:	66 83 7d e4 00       	cmpw   $0x0,-0x1c(%ebp)
    d62e:	0f 95 c0             	setne  %al
    d631:	0f b6 c0             	movzbl %al,%eax
    d634:	85 c0                	test   %eax,%eax
    d636:	74 1c                	je     d654 <sl_thd_block+0x38>
    d638:	c7 04 24 b0 20 00 00 	movl   $0x20b0,(%esp)
    d63f:	e8 b8 ae ff ff       	call   84fc <prints>
    d644:	a1 40 01 00 00       	mov    0x140,%eax
    d649:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d64f:	e8 2f af ff ff       	call   8583 <__cos_noret>

	sl_cs_enter();
    d654:	e8 d3 de ff ff       	call   b52c <sl_cs_enter>
	t = sl_thd_curr();
    d659:	e8 a0 dd ff ff       	call   b3fe <sl_thd_curr>
    d65e:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (sl_thd_block_no_cs(t, SL_THD_BLOCKED, 0)) {
    d661:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    d668:	00 
    d669:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    d670:	00 
    d671:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    d678:	00 
    d679:	8b 45 f4             	mov    -0xc(%ebp),%eax
    d67c:	89 04 24             	mov    %eax,(%esp)
    d67f:	e8 fc ff ff ff       	call   d680 <sl_thd_block+0x64>
    d684:	85 c0                	test   %eax,%eax
    d686:	74 07                	je     d68f <sl_thd_block+0x73>
		sl_cs_exit();
    d688:	e8 d4 de ff ff       	call   b561 <sl_cs_exit>
		return;
    d68d:	eb 06                	jmp    d695 <sl_thd_block+0x79>
	}
	sl_cs_exit_schedule();
    d68f:	e8 62 e8 ff ff       	call   bef6 <sl_cs_exit_schedule>

	return;
    d694:	90                   	nop
}
    d695:	c9                   	leave  
    d696:	c3                   	ret    

0000d697 <sl_thd_block_timeout_intern>:
 * if timeout == 0, blocks on timeout = last periodic wakeup + task period
 * @return: 0 if blocked in this call. 1 if already WOKEN!
 */
static inline int
sl_thd_block_timeout_intern(thdid_t tid, cycles_t timeout)
{
    d697:	55                   	push   %ebp
    d698:	89 e5                	mov    %esp,%ebp
    d69a:	83 ec 38             	sub    $0x38,%esp
    d69d:	8b 45 08             	mov    0x8(%ebp),%eax
    d6a0:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
    d6a4:	8b 45 0c             	mov    0xc(%ebp),%eax
    d6a7:	89 45 d8             	mov    %eax,-0x28(%ebp)
    d6aa:	8b 45 10             	mov    0x10(%ebp),%eax
    d6ad:	89 45 dc             	mov    %eax,-0x24(%ebp)
	struct sl_thd *t;

	sl_cs_enter();
    d6b0:	e8 77 de ff ff       	call   b52c <sl_cs_enter>
	t = sl_thd_curr();
    d6b5:	e8 44 dd ff ff       	call   b3fe <sl_thd_curr>
    d6ba:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (sl_thd_block_no_cs(t, SL_THD_BLOCKED_TIMEOUT, timeout)) {
    d6bd:	8b 45 d8             	mov    -0x28(%ebp),%eax
    d6c0:	8b 55 dc             	mov    -0x24(%ebp),%edx
    d6c3:	89 44 24 08          	mov    %eax,0x8(%esp)
    d6c7:	89 54 24 0c          	mov    %edx,0xc(%esp)
    d6cb:	c7 44 24 04 02 00 00 	movl   $0x2,0x4(%esp)
    d6d2:	00 
    d6d3:	8b 45 f4             	mov    -0xc(%ebp),%eax
    d6d6:	89 04 24             	mov    %eax,(%esp)
    d6d9:	e8 fc ff ff ff       	call   d6da <sl_thd_block_timeout_intern+0x43>
    d6de:	85 c0                	test   %eax,%eax
    d6e0:	74 0c                	je     d6ee <sl_thd_block_timeout_intern+0x57>
		sl_cs_exit();
    d6e2:	e8 7a de ff ff       	call   b561 <sl_cs_exit>
		return 1;
    d6e7:	b8 01 00 00 00       	mov    $0x1,%eax
    d6ec:	eb 0a                	jmp    d6f8 <sl_thd_block_timeout_intern+0x61>
	}
	sl_cs_exit_schedule();
    d6ee:	e8 03 e8 ff ff       	call   bef6 <sl_cs_exit_schedule>

	return 0;
    d6f3:	b8 00 00 00 00       	mov    $0x0,%eax
}
    d6f8:	c9                   	leave  
    d6f9:	c3                   	ret    

0000d6fa <sl_thd_block_timeout>:

cycles_t
sl_thd_block_timeout(thdid_t tid, cycles_t abs_timeout)
{
    d6fa:	55                   	push   %ebp
    d6fb:	89 e5                	mov    %esp,%ebp
    d6fd:	53                   	push   %ebx
    d6fe:	83 ec 44             	sub    $0x44,%esp
    d701:	8b 45 08             	mov    0x8(%ebp),%eax
    d704:	66 89 45 d4          	mov    %ax,-0x2c(%ebp)
    d708:	8b 45 0c             	mov    0xc(%ebp),%eax
    d70b:	89 45 c8             	mov    %eax,-0x38(%ebp)
    d70e:	8b 45 10             	mov    0x10(%ebp),%eax
    d711:	89 45 cc             	mov    %eax,-0x34(%ebp)
	cycles_t jitter  = 0, wcycs, tcycs;
    d714:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
    d71b:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct sl_thd *t = sl_thd_curr();
    d722:	e8 d7 dc ff ff       	call   b3fe <sl_thd_curr>
    d727:	89 45 ec             	mov    %eax,-0x14(%ebp)

	/* TODO: dependencies not yet supported */
	assert(!tid);
    d72a:	66 83 7d d4 00       	cmpw   $0x0,-0x2c(%ebp)
    d72f:	0f 95 c0             	setne  %al
    d732:	0f b6 c0             	movzbl %al,%eax
    d735:	85 c0                	test   %eax,%eax
    d737:	74 1c                	je     d755 <sl_thd_block_timeout+0x5b>
    d739:	c7 04 24 dc 20 00 00 	movl   $0x20dc,(%esp)
    d740:	e8 b7 ad ff ff       	call   84fc <prints>
    d745:	a1 40 01 00 00       	mov    0x140,%eax
    d74a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d750:	e8 2e ae ff ff       	call   8583 <__cos_noret>

	if (unlikely(!abs_timeout)) {
    d755:	8b 45 cc             	mov    -0x34(%ebp),%eax
    d758:	8b 55 c8             	mov    -0x38(%ebp),%edx
    d75b:	09 d0                	or     %edx,%eax
    d75d:	85 c0                	test   %eax,%eax
    d75f:	0f 94 c0             	sete   %al
    d762:	0f b6 c0             	movzbl %al,%eax
    d765:	85 c0                	test   %eax,%eax
    d767:	74 0e                	je     d777 <sl_thd_block_timeout+0x7d>
		sl_thd_block(tid);
    d769:	0f b7 45 d4          	movzwl -0x2c(%ebp),%eax
    d76d:	89 04 24             	mov    %eax,(%esp)
    d770:	e8 fc ff ff ff       	call   d771 <sl_thd_block_timeout+0x77>
		goto done;
    d775:	eb 69                	jmp    d7e0 <sl_thd_block_timeout+0xe6>
	}

	if (sl_thd_block_timeout_intern(tid, abs_timeout)) goto done;
    d777:	0f b7 4d d4          	movzwl -0x2c(%ebp),%ecx
    d77b:	8b 45 c8             	mov    -0x38(%ebp),%eax
    d77e:	8b 55 cc             	mov    -0x34(%ebp),%edx
    d781:	89 44 24 04          	mov    %eax,0x4(%esp)
    d785:	89 54 24 08          	mov    %edx,0x8(%esp)
    d789:	89 0c 24             	mov    %ecx,(%esp)
    d78c:	e8 06 ff ff ff       	call   d697 <sl_thd_block_timeout_intern>
    d791:	85 c0                	test   %eax,%eax
    d793:	74 02                	je     d797 <sl_thd_block_timeout+0x9d>
    d795:	eb 49                	jmp    d7e0 <sl_thd_block_timeout+0xe6>
	wcycs = t->wakeup_cycs;
    d797:	8b 45 ec             	mov    -0x14(%ebp),%eax
    d79a:	8b 50 58             	mov    0x58(%eax),%edx
    d79d:	8b 40 54             	mov    0x54(%eax),%eax
    d7a0:	89 45 e0             	mov    %eax,-0x20(%ebp)
    d7a3:	89 55 e4             	mov    %edx,-0x1c(%ebp)
	tcycs = t->timeout_cycs;
    d7a6:	8b 45 ec             	mov    -0x14(%ebp),%eax
    d7a9:	8b 50 50             	mov    0x50(%eax),%edx
    d7ac:	8b 40 4c             	mov    0x4c(%eax),%eax
    d7af:	89 45 d8             	mov    %eax,-0x28(%ebp)
    d7b2:	89 55 dc             	mov    %edx,-0x24(%ebp)
	if (wcycs > tcycs) jitter = wcycs - tcycs;
    d7b5:	8b 45 e0             	mov    -0x20(%ebp),%eax
    d7b8:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    d7bb:	3b 55 dc             	cmp    -0x24(%ebp),%edx
    d7be:	72 20                	jb     d7e0 <sl_thd_block_timeout+0xe6>
    d7c0:	3b 55 dc             	cmp    -0x24(%ebp),%edx
    d7c3:	77 05                	ja     d7ca <sl_thd_block_timeout+0xd0>
    d7c5:	3b 45 d8             	cmp    -0x28(%ebp),%eax
    d7c8:	76 16                	jbe    d7e0 <sl_thd_block_timeout+0xe6>
    d7ca:	8b 4d d8             	mov    -0x28(%ebp),%ecx
    d7cd:	8b 5d dc             	mov    -0x24(%ebp),%ebx
    d7d0:	8b 45 e0             	mov    -0x20(%ebp),%eax
    d7d3:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    d7d6:	29 c8                	sub    %ecx,%eax
    d7d8:	19 da                	sbb    %ebx,%edx
    d7da:	89 45 f0             	mov    %eax,-0x10(%ebp)
    d7dd:	89 55 f4             	mov    %edx,-0xc(%ebp)

done:
	return jitter;
    d7e0:	8b 45 f0             	mov    -0x10(%ebp),%eax
    d7e3:	8b 55 f4             	mov    -0xc(%ebp),%edx
}
    d7e6:	83 c4 44             	add    $0x44,%esp
    d7e9:	5b                   	pop    %ebx
    d7ea:	5d                   	pop    %ebp
    d7eb:	c3                   	ret    

0000d7ec <sl_thd_block_periodic>:

unsigned int
sl_thd_block_periodic(thdid_t tid)
{
    d7ec:	55                   	push   %ebp
    d7ed:	89 e5                	mov    %esp,%ebp
    d7ef:	53                   	push   %ebx
    d7f0:	83 ec 44             	sub    $0x44,%esp
    d7f3:	8b 45 08             	mov    0x8(%ebp),%eax
    d7f6:	66 89 45 d4          	mov    %ax,-0x2c(%ebp)
	cycles_t wcycs, pcycs;
	unsigned int jitter = 0;
    d7fa:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct sl_thd *t    = sl_thd_curr();
    d801:	e8 f8 db ff ff       	call   b3fe <sl_thd_curr>
    d806:	89 45 f0             	mov    %eax,-0x10(%ebp)

	/* TODO: dependencies not yet supported */
	assert(!tid);
    d809:	66 83 7d d4 00       	cmpw   $0x0,-0x2c(%ebp)
    d80e:	0f 95 c0             	setne  %al
    d811:	0f b6 c0             	movzbl %al,%eax
    d814:	85 c0                	test   %eax,%eax
    d816:	74 1c                	je     d834 <sl_thd_block_periodic+0x48>
    d818:	c7 04 24 08 21 00 00 	movl   $0x2108,(%esp)
    d81f:	e8 d8 ac ff ff       	call   84fc <prints>
    d824:	a1 40 01 00 00       	mov    0x140,%eax
    d829:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d82f:	e8 4f ad ff ff       	call   8583 <__cos_noret>

	assert(t->period);
    d834:	8b 45 f0             	mov    -0x10(%ebp),%eax
    d837:	8b 50 40             	mov    0x40(%eax),%edx
    d83a:	8b 40 3c             	mov    0x3c(%eax),%eax
    d83d:	09 d0                	or     %edx,%eax
    d83f:	85 c0                	test   %eax,%eax
    d841:	0f 94 c0             	sete   %al
    d844:	0f b6 c0             	movzbl %al,%eax
    d847:	85 c0                	test   %eax,%eax
    d849:	74 1c                	je     d867 <sl_thd_block_periodic+0x7b>
    d84b:	c7 04 24 34 21 00 00 	movl   $0x2134,(%esp)
    d852:	e8 a5 ac ff ff       	call   84fc <prints>
    d857:	a1 40 01 00 00       	mov    0x140,%eax
    d85c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d862:	e8 1c ad ff ff       	call   8583 <__cos_noret>
	if (sl_thd_block_timeout_intern(tid, 0)) goto done;
    d867:	0f b7 45 d4          	movzwl -0x2c(%ebp),%eax
    d86b:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    d872:	00 
    d873:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    d87a:	00 
    d87b:	89 04 24             	mov    %eax,(%esp)
    d87e:	e8 14 fe ff ff       	call   d697 <sl_thd_block_timeout_intern>
    d883:	85 c0                	test   %eax,%eax
    d885:	74 02                	je     d889 <sl_thd_block_periodic+0x9d>
    d887:	eb 66                	jmp    d8ef <sl_thd_block_periodic+0x103>
	wcycs = t->wakeup_cycs;
    d889:	8b 45 f0             	mov    -0x10(%ebp),%eax
    d88c:	8b 50 58             	mov    0x58(%eax),%edx
    d88f:	8b 40 54             	mov    0x54(%eax),%eax
    d892:	89 45 e8             	mov    %eax,-0x18(%ebp)
    d895:	89 55 ec             	mov    %edx,-0x14(%ebp)
	pcycs = t->periodic_cycs;
    d898:	8b 45 f0             	mov    -0x10(%ebp),%eax
    d89b:	8b 50 48             	mov    0x48(%eax),%edx
    d89e:	8b 40 44             	mov    0x44(%eax),%eax
    d8a1:	89 45 e0             	mov    %eax,-0x20(%ebp)
    d8a4:	89 55 e4             	mov    %edx,-0x1c(%ebp)
	if (wcycs > pcycs) jitter = ((unsigned int)((wcycs - pcycs) / t->period)) + 1;
    d8a7:	8b 45 e8             	mov    -0x18(%ebp),%eax
    d8aa:	8b 55 ec             	mov    -0x14(%ebp),%edx
    d8ad:	3b 55 e4             	cmp    -0x1c(%ebp),%edx
    d8b0:	72 3d                	jb     d8ef <sl_thd_block_periodic+0x103>
    d8b2:	3b 55 e4             	cmp    -0x1c(%ebp),%edx
    d8b5:	77 05                	ja     d8bc <sl_thd_block_periodic+0xd0>
    d8b7:	3b 45 e0             	cmp    -0x20(%ebp),%eax
    d8ba:	76 33                	jbe    d8ef <sl_thd_block_periodic+0x103>
    d8bc:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    d8bf:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
    d8c2:	8b 45 e8             	mov    -0x18(%ebp),%eax
    d8c5:	8b 55 ec             	mov    -0x14(%ebp),%edx
    d8c8:	29 c8                	sub    %ecx,%eax
    d8ca:	19 da                	sbb    %ebx,%edx
    d8cc:	8b 4d f0             	mov    -0x10(%ebp),%ecx
    d8cf:	8b 59 40             	mov    0x40(%ecx),%ebx
    d8d2:	8b 49 3c             	mov    0x3c(%ecx),%ecx
    d8d5:	89 4c 24 08          	mov    %ecx,0x8(%esp)
    d8d9:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
    d8dd:	89 04 24             	mov    %eax,(%esp)
    d8e0:	89 54 24 04          	mov    %edx,0x4(%esp)
    d8e4:	e8 fc ff ff ff       	call   d8e5 <sl_thd_block_periodic+0xf9>
    d8e9:	83 c0 01             	add    $0x1,%eax
    d8ec:	89 45 f4             	mov    %eax,-0xc(%ebp)

done:
	return jitter;
    d8ef:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    d8f2:	83 c4 44             	add    $0x44,%esp
    d8f5:	5b                   	pop    %ebx
    d8f6:	5d                   	pop    %ebp
    d8f7:	c3                   	ret    

0000d8f8 <sl_thd_block_expiry>:

void
sl_thd_block_expiry(struct sl_thd *t)
{
    d8f8:	55                   	push   %ebp
    d8f9:	89 e5                	mov    %esp,%ebp
    d8fb:	53                   	push   %ebx
    d8fc:	83 ec 24             	sub    $0x24,%esp
	cycles_t abs_timeout = 0;
    d8ff:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
    d906:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	assert(t != sl__globals_cpu()->idle_thd && t != sl__globals_cpu()->sched_thd);
    d90d:	e8 09 da ff ff       	call   b31b <sl__globals_cpu>
    d912:	8b 40 14             	mov    0x14(%eax),%eax
    d915:	3b 45 08             	cmp    0x8(%ebp),%eax
    d918:	0f 94 c0             	sete   %al
    d91b:	0f b6 c0             	movzbl %al,%eax
    d91e:	85 c0                	test   %eax,%eax
    d920:	75 15                	jne    d937 <sl_thd_block_expiry+0x3f>
    d922:	e8 f4 d9 ff ff       	call   b31b <sl__globals_cpu>
    d927:	8b 40 10             	mov    0x10(%eax),%eax
    d92a:	3b 45 08             	cmp    0x8(%ebp),%eax
    d92d:	0f 94 c0             	sete   %al
    d930:	0f b6 c0             	movzbl %al,%eax
    d933:	85 c0                	test   %eax,%eax
    d935:	74 1c                	je     d953 <sl_thd_block_expiry+0x5b>
    d937:	c7 04 24 60 21 00 00 	movl   $0x2160,(%esp)
    d93e:	e8 b9 ab ff ff       	call   84fc <prints>
    d943:	a1 40 01 00 00       	mov    0x140,%eax
    d948:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d94e:	e8 30 ac ff ff       	call   8583 <__cos_noret>
	sl_cs_enter();
    d953:	e8 d4 db ff ff       	call   b52c <sl_cs_enter>
	if (!(t->properties & SL_THD_PROPERTY_OWN_TCAP)) {
    d958:	8b 45 08             	mov    0x8(%ebp),%eax
    d95b:	8b 40 08             	mov    0x8(%eax),%eax
    d95e:	83 e0 01             	and    $0x1,%eax
    d961:	85 c0                	test   %eax,%eax
    d963:	75 42                	jne    d9a7 <sl_thd_block_expiry+0xaf>
		assert(!t->rcv_suspended);
    d965:	8b 45 08             	mov    0x8(%ebp),%eax
    d968:	8b 40 04             	mov    0x4(%eax),%eax
    d96b:	85 c0                	test   %eax,%eax
    d96d:	0f 95 c0             	setne  %al
    d970:	0f b6 c0             	movzbl %al,%eax
    d973:	85 c0                	test   %eax,%eax
    d975:	74 1c                	je     d993 <sl_thd_block_expiry+0x9b>
    d977:	c7 04 24 8c 21 00 00 	movl   $0x218c,(%esp)
    d97e:	e8 79 ab ff ff       	call   84fc <prints>
    d983:	a1 40 01 00 00       	mov    0x140,%eax
    d988:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d98e:	e8 f0 ab ff ff       	call   8583 <__cos_noret>
		abs_timeout = sl__globals_cpu()->timeout_next;
    d993:	e8 83 d9 ff ff       	call   b31b <sl__globals_cpu>
    d998:	8b 40 2c             	mov    0x2c(%eax),%eax
    d99b:	89 45 f0             	mov    %eax,-0x10(%ebp)
    d99e:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    d9a5:	eb 4f                	jmp    d9f6 <sl_thd_block_expiry+0xfe>
	} else {
		assert(t->period);
    d9a7:	8b 45 08             	mov    0x8(%ebp),%eax
    d9aa:	8b 50 40             	mov    0x40(%eax),%edx
    d9ad:	8b 40 3c             	mov    0x3c(%eax),%eax
    d9b0:	09 d0                	or     %edx,%eax
    d9b2:	85 c0                	test   %eax,%eax
    d9b4:	0f 94 c0             	sete   %al
    d9b7:	0f b6 c0             	movzbl %al,%eax
    d9ba:	85 c0                	test   %eax,%eax
    d9bc:	74 1c                	je     d9da <sl_thd_block_expiry+0xe2>
    d9be:	c7 04 24 b8 21 00 00 	movl   $0x21b8,(%esp)
    d9c5:	e8 32 ab ff ff       	call   84fc <prints>
    d9ca:	a1 40 01 00 00       	mov    0x140,%eax
    d9cf:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    d9d5:	e8 a9 ab ff ff       	call   8583 <__cos_noret>
		abs_timeout = t->last_replenish + t->period;
    d9da:	8b 45 08             	mov    0x8(%ebp),%eax
    d9dd:	8b 48 34             	mov    0x34(%eax),%ecx
    d9e0:	8b 58 38             	mov    0x38(%eax),%ebx
    d9e3:	8b 45 08             	mov    0x8(%ebp),%eax
    d9e6:	8b 50 40             	mov    0x40(%eax),%edx
    d9e9:	8b 40 3c             	mov    0x3c(%eax),%eax
    d9ec:	01 c8                	add    %ecx,%eax
    d9ee:	11 da                	adc    %ebx,%edx
    d9f0:	89 45 f0             	mov    %eax,-0x10(%ebp)
    d9f3:	89 55 f4             	mov    %edx,-0xc(%ebp)
	}

	/* reset rcv_suspended if the scheduler thinks "t" was suspended on cos_rcv previously */
	sl_thd_sched_unblock_no_cs(t);
    d9f6:	8b 45 08             	mov    0x8(%ebp),%eax
    d9f9:	89 04 24             	mov    %eax,(%esp)
    d9fc:	e8 bd f9 ff ff       	call   d3be <sl_thd_sched_unblock_no_cs>
	sl_thd_sched_block_no_cs(t, SL_THD_BLOCKED_TIMEOUT, abs_timeout);
    da01:	8b 45 f0             	mov    -0x10(%ebp),%eax
    da04:	8b 55 f4             	mov    -0xc(%ebp),%edx
    da07:	89 44 24 08          	mov    %eax,0x8(%esp)
    da0b:	89 54 24 0c          	mov    %edx,0xc(%esp)
    da0f:	c7 44 24 04 02 00 00 	movl   $0x2,0x4(%esp)
    da16:	00 
    da17:	8b 45 08             	mov    0x8(%ebp),%eax
    da1a:	89 04 24             	mov    %eax,(%esp)
    da1d:	e8 fc ff ff ff       	call   da1e <sl_thd_block_expiry+0x126>

	sl_cs_exit();
    da22:	e8 3a db ff ff       	call   b561 <sl_cs_exit>
}
    da27:	83 c4 24             	add    $0x24,%esp
    da2a:	5b                   	pop    %ebx
    da2b:	5d                   	pop    %ebp
    da2c:	c3                   	ret    

0000da2d <sl_thd_sched_wakeup_no_cs>:
 * @return: 1 if it's already WOKEN or RUNNABLE.
 *	    0 if it successfully blocked in this call.
 */
int
sl_thd_sched_wakeup_no_cs(struct sl_thd *t)
{
    da2d:	55                   	push   %ebp
    da2e:	89 e5                	mov    %esp,%ebp
    da30:	83 ec 18             	sub    $0x18,%esp
	assert(t);
    da33:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    da37:	0f 94 c0             	sete   %al
    da3a:	0f b6 c0             	movzbl %al,%eax
    da3d:	85 c0                	test   %eax,%eax
    da3f:	74 1c                	je     da5d <sl_thd_sched_wakeup_no_cs+0x30>
    da41:	c7 04 24 e4 21 00 00 	movl   $0x21e4,(%esp)
    da48:	e8 af aa ff ff       	call   84fc <prints>
    da4d:	a1 40 01 00 00       	mov    0x140,%eax
    da52:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    da58:	e8 26 ab ff ff       	call   8583 <__cos_noret>

	if (unlikely(!t->rcv_suspended)) return 1; /* not blocked on cos_rcv, so don't mess with user-level thread states */
    da5d:	8b 45 08             	mov    0x8(%ebp),%eax
    da60:	8b 40 04             	mov    0x4(%eax),%eax
    da63:	85 c0                	test   %eax,%eax
    da65:	0f 94 c0             	sete   %al
    da68:	0f b6 c0             	movzbl %al,%eax
    da6b:	85 c0                	test   %eax,%eax
    da6d:	74 0a                	je     da79 <sl_thd_sched_wakeup_no_cs+0x4c>
    da6f:	b8 01 00 00 00       	mov    $0x1,%eax
    da74:	e9 ab 00 00 00       	jmp    db24 <sl_thd_sched_wakeup_no_cs+0xf7>
	t->rcv_suspended = 0;
    da79:	8b 45 08             	mov    0x8(%ebp),%eax
    da7c:	c7 40 04 00 00 00 00 	movl   $0x0,0x4(%eax)
	 *
	 * Thread could be in WOKEN state:
	 * Perhaps the thread was blocked waiting for a lock and was woken up by another thread and
	 * and then scheduler sees some redundant wakeup event through "asnd" or "tcap budget expiry".
	 */
	if (unlikely(t->state == SL_THD_RUNNABLE || t->state == SL_THD_WOKEN)) return 1;
    da83:	8b 45 08             	mov    0x8(%ebp),%eax
    da86:	8b 00                	mov    (%eax),%eax
    da88:	83 f8 04             	cmp    $0x4,%eax
    da8b:	0f 94 c0             	sete   %al
    da8e:	0f b6 c0             	movzbl %al,%eax
    da91:	85 c0                	test   %eax,%eax
    da93:	75 12                	jne    daa7 <sl_thd_sched_wakeup_no_cs+0x7a>
    da95:	8b 45 08             	mov    0x8(%ebp),%eax
    da98:	8b 00                	mov    (%eax),%eax
    da9a:	83 f8 03             	cmp    $0x3,%eax
    da9d:	0f 94 c0             	sete   %al
    daa0:	0f b6 c0             	movzbl %al,%eax
    daa3:	85 c0                	test   %eax,%eax
    daa5:	74 07                	je     daae <sl_thd_sched_wakeup_no_cs+0x81>
    daa7:	b8 01 00 00 00       	mov    $0x1,%eax
    daac:	eb 76                	jmp    db24 <sl_thd_sched_wakeup_no_cs+0xf7>

	assert(t->state == SL_THD_BLOCKED || t->state == SL_THD_BLOCKED_TIMEOUT);
    daae:	8b 45 08             	mov    0x8(%ebp),%eax
    dab1:	8b 00                	mov    (%eax),%eax
    dab3:	83 f8 01             	cmp    $0x1,%eax
    dab6:	0f 95 c0             	setne  %al
    dab9:	0f b6 c0             	movzbl %al,%eax
    dabc:	85 c0                	test   %eax,%eax
    dabe:	74 2e                	je     daee <sl_thd_sched_wakeup_no_cs+0xc1>
    dac0:	8b 45 08             	mov    0x8(%ebp),%eax
    dac3:	8b 00                	mov    (%eax),%eax
    dac5:	83 f8 02             	cmp    $0x2,%eax
    dac8:	0f 95 c0             	setne  %al
    dacb:	0f b6 c0             	movzbl %al,%eax
    dace:	85 c0                	test   %eax,%eax
    dad0:	74 1c                	je     daee <sl_thd_sched_wakeup_no_cs+0xc1>
    dad2:	c7 04 24 10 22 00 00 	movl   $0x2210,(%esp)
    dad9:	e8 1e aa ff ff       	call   84fc <prints>
    dade:	a1 40 01 00 00       	mov    0x140,%eax
    dae3:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    dae9:	e8 95 aa ff ff       	call   8583 <__cos_noret>
	if (t->state == SL_THD_BLOCKED_TIMEOUT) sl_timeout_remove(t);
    daee:	8b 45 08             	mov    0x8(%ebp),%eax
    daf1:	8b 00                	mov    (%eax),%eax
    daf3:	83 f8 02             	cmp    $0x2,%eax
    daf6:	75 0b                	jne    db03 <sl_thd_sched_wakeup_no_cs+0xd6>
    daf8:	8b 45 08             	mov    0x8(%ebp),%eax
    dafb:	89 04 24             	mov    %eax,(%esp)
    dafe:	e8 c5 f4 ff ff       	call   cfc8 <sl_timeout_remove>
	t->state = SL_THD_RUNNABLE;
    db03:	8b 45 08             	mov    0x8(%ebp),%eax
    db06:	c7 00 04 00 00 00    	movl   $0x4,(%eax)
	sl_mod_wakeup(sl_mod_thd_policy_get(t));
    db0c:	8b 45 08             	mov    0x8(%ebp),%eax
    db0f:	89 04 24             	mov    %eax,(%esp)
    db12:	e8 8f ac ff ff       	call   87a6 <sl_mod_thd_policy_get>
    db17:	89 04 24             	mov    %eax,(%esp)
    db1a:	e8 fc ff ff ff       	call   db1b <sl_thd_sched_wakeup_no_cs+0xee>

	return 0;
    db1f:	b8 00 00 00 00       	mov    $0x0,%eax
}
    db24:	c9                   	leave  
    db25:	c3                   	ret    

0000db26 <sl_thd_wakeup_no_cs_rm>:
 * @return: 1 if it's already RUNNABLE.
 *          0 if it was woken up in this call
 */
int
sl_thd_wakeup_no_cs_rm(struct sl_thd *t)
{
    db26:	55                   	push   %ebp
    db27:	89 e5                	mov    %esp,%ebp
    db29:	83 ec 18             	sub    $0x18,%esp
	assert(t);
    db2c:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    db30:	0f 94 c0             	sete   %al
    db33:	0f b6 c0             	movzbl %al,%eax
    db36:	85 c0                	test   %eax,%eax
    db38:	74 1c                	je     db56 <sl_thd_wakeup_no_cs_rm+0x30>
    db3a:	c7 04 24 3c 22 00 00 	movl   $0x223c,(%esp)
    db41:	e8 b6 a9 ff ff       	call   84fc <prints>
    db46:	a1 40 01 00 00       	mov    0x140,%eax
    db4b:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    db51:	e8 2d aa ff ff       	call   8583 <__cos_noret>
	assert(t != sl__globals_cpu()->idle_thd && t != sl__globals_cpu()->sched_thd);
    db56:	e8 c0 d7 ff ff       	call   b31b <sl__globals_cpu>
    db5b:	8b 40 14             	mov    0x14(%eax),%eax
    db5e:	3b 45 08             	cmp    0x8(%ebp),%eax
    db61:	0f 94 c0             	sete   %al
    db64:	0f b6 c0             	movzbl %al,%eax
    db67:	85 c0                	test   %eax,%eax
    db69:	75 15                	jne    db80 <sl_thd_wakeup_no_cs_rm+0x5a>
    db6b:	e8 ab d7 ff ff       	call   b31b <sl__globals_cpu>
    db70:	8b 40 10             	mov    0x10(%eax),%eax
    db73:	3b 45 08             	cmp    0x8(%ebp),%eax
    db76:	0f 94 c0             	sete   %al
    db79:	0f b6 c0             	movzbl %al,%eax
    db7c:	85 c0                	test   %eax,%eax
    db7e:	74 1c                	je     db9c <sl_thd_wakeup_no_cs_rm+0x76>
    db80:	c7 04 24 68 22 00 00 	movl   $0x2268,(%esp)
    db87:	e8 70 a9 ff ff       	call   84fc <prints>
    db8c:	a1 40 01 00 00       	mov    0x140,%eax
    db91:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    db97:	e8 e7 a9 ff ff       	call   8583 <__cos_noret>

	assert(t->state == SL_THD_BLOCKED || t->state == SL_THD_BLOCKED_TIMEOUT);
    db9c:	8b 45 08             	mov    0x8(%ebp),%eax
    db9f:	8b 00                	mov    (%eax),%eax
    dba1:	83 f8 01             	cmp    $0x1,%eax
    dba4:	0f 95 c0             	setne  %al
    dba7:	0f b6 c0             	movzbl %al,%eax
    dbaa:	85 c0                	test   %eax,%eax
    dbac:	74 2e                	je     dbdc <sl_thd_wakeup_no_cs_rm+0xb6>
    dbae:	8b 45 08             	mov    0x8(%ebp),%eax
    dbb1:	8b 00                	mov    (%eax),%eax
    dbb3:	83 f8 02             	cmp    $0x2,%eax
    dbb6:	0f 95 c0             	setne  %al
    dbb9:	0f b6 c0             	movzbl %al,%eax
    dbbc:	85 c0                	test   %eax,%eax
    dbbe:	74 1c                	je     dbdc <sl_thd_wakeup_no_cs_rm+0xb6>
    dbc0:	c7 04 24 94 22 00 00 	movl   $0x2294,(%esp)
    dbc7:	e8 30 a9 ff ff       	call   84fc <prints>
    dbcc:	a1 40 01 00 00       	mov    0x140,%eax
    dbd1:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    dbd7:	e8 a7 a9 ff ff       	call   8583 <__cos_noret>
	t->state = SL_THD_RUNNABLE;
    dbdc:	8b 45 08             	mov    0x8(%ebp),%eax
    dbdf:	c7 00 04 00 00 00    	movl   $0x4,(%eax)
	sl_mod_wakeup(sl_mod_thd_policy_get(t));
    dbe5:	8b 45 08             	mov    0x8(%ebp),%eax
    dbe8:	89 04 24             	mov    %eax,(%esp)
    dbeb:	e8 b6 ab ff ff       	call   87a6 <sl_mod_thd_policy_get>
    dbf0:	89 04 24             	mov    %eax,(%esp)
    dbf3:	e8 fc ff ff ff       	call   dbf4 <sl_thd_wakeup_no_cs_rm+0xce>
	t->rcv_suspended = 0;
    dbf8:	8b 45 08             	mov    0x8(%ebp),%eax
    dbfb:	c7 40 04 00 00 00 00 	movl   $0x0,0x4(%eax)

	return 0;
    dc02:	b8 00 00 00 00       	mov    $0x0,%eax
}
    dc07:	c9                   	leave  
    dc08:	c3                   	ret    

0000dc09 <sl_thd_wakeup_no_cs>:

int
sl_thd_wakeup_no_cs(struct sl_thd *t)
{
    dc09:	55                   	push   %ebp
    dc0a:	89 e5                	mov    %esp,%ebp
    dc0c:	83 ec 18             	sub    $0x18,%esp
	assert(t);
    dc0f:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    dc13:	0f 94 c0             	sete   %al
    dc16:	0f b6 c0             	movzbl %al,%eax
    dc19:	85 c0                	test   %eax,%eax
    dc1b:	74 1c                	je     dc39 <sl_thd_wakeup_no_cs+0x30>
    dc1d:	c7 04 24 c0 22 00 00 	movl   $0x22c0,(%esp)
    dc24:	e8 d3 a8 ff ff       	call   84fc <prints>
    dc29:	a1 40 01 00 00       	mov    0x140,%eax
    dc2e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    dc34:	e8 4a a9 ff ff       	call   8583 <__cos_noret>
	assert(sl_thd_curr() != t); /* current thread is not allowed to wake itself up */
    dc39:	e8 c0 d7 ff ff       	call   b3fe <sl_thd_curr>
    dc3e:	3b 45 08             	cmp    0x8(%ebp),%eax
    dc41:	0f 94 c0             	sete   %al
    dc44:	0f b6 c0             	movzbl %al,%eax
    dc47:	85 c0                	test   %eax,%eax
    dc49:	74 1c                	je     dc67 <sl_thd_wakeup_no_cs+0x5e>
    dc4b:	c7 04 24 ec 22 00 00 	movl   $0x22ec,(%esp)
    dc52:	e8 a5 a8 ff ff       	call   84fc <prints>
    dc57:	a1 40 01 00 00       	mov    0x140,%eax
    dc5c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    dc62:	e8 1c a9 ff ff       	call   8583 <__cos_noret>

	if (t->schedthd) {
    dc67:	8b 45 08             	mov    0x8(%ebp),%eax
    dc6a:	8b 40 18             	mov    0x18(%eax),%eax
    dc6d:	85 c0                	test   %eax,%eax
    dc6f:	74 1f                	je     dc90 <sl_thd_wakeup_no_cs+0x87>
		sl_parent_notif_wakeup_no_cs(t->schedthd, t);
    dc71:	8b 45 08             	mov    0x8(%ebp),%eax
    dc74:	8b 40 18             	mov    0x18(%eax),%eax
    dc77:	8b 55 08             	mov    0x8(%ebp),%edx
    dc7a:	89 54 24 04          	mov    %edx,0x4(%esp)
    dc7e:	89 04 24             	mov    %eax,(%esp)
    dc81:	e8 fc ff ff ff       	call   dc82 <sl_thd_wakeup_no_cs+0x79>

		return 0;
    dc86:	b8 00 00 00 00       	mov    $0x0,%eax
    dc8b:	e9 87 00 00 00       	jmp    dd17 <sl_thd_wakeup_no_cs+0x10e>
	}

	if (unlikely(sl_thd_is_runnable(t))) {
    dc90:	8b 45 08             	mov    0x8(%ebp),%eax
    dc93:	89 04 24             	mov    %eax,(%esp)
    dc96:	e8 3b dc ff ff       	call   b8d6 <sl_thd_is_runnable>
    dc9b:	85 c0                	test   %eax,%eax
    dc9d:	0f 95 c0             	setne  %al
    dca0:	0f b6 c0             	movzbl %al,%eax
    dca3:	85 c0                	test   %eax,%eax
    dca5:	74 10                	je     dcb7 <sl_thd_wakeup_no_cs+0xae>
		/* t->state == SL_THD_WOKEN? multiple wakeups? */
		t->state = SL_THD_WOKEN;
    dca7:	8b 45 08             	mov    0x8(%ebp),%eax
    dcaa:	c7 00 03 00 00 00    	movl   $0x3,(%eax)
		return 1;
    dcb0:	b8 01 00 00 00       	mov    $0x1,%eax
    dcb5:	eb 60                	jmp    dd17 <sl_thd_wakeup_no_cs+0x10e>
	}

	assert(t->state == SL_THD_BLOCKED || t->state == SL_THD_BLOCKED_TIMEOUT);
    dcb7:	8b 45 08             	mov    0x8(%ebp),%eax
    dcba:	8b 00                	mov    (%eax),%eax
    dcbc:	83 f8 01             	cmp    $0x1,%eax
    dcbf:	0f 95 c0             	setne  %al
    dcc2:	0f b6 c0             	movzbl %al,%eax
    dcc5:	85 c0                	test   %eax,%eax
    dcc7:	74 2e                	je     dcf7 <sl_thd_wakeup_no_cs+0xee>
    dcc9:	8b 45 08             	mov    0x8(%ebp),%eax
    dccc:	8b 00                	mov    (%eax),%eax
    dcce:	83 f8 02             	cmp    $0x2,%eax
    dcd1:	0f 95 c0             	setne  %al
    dcd4:	0f b6 c0             	movzbl %al,%eax
    dcd7:	85 c0                	test   %eax,%eax
    dcd9:	74 1c                	je     dcf7 <sl_thd_wakeup_no_cs+0xee>
    dcdb:	c7 04 24 18 23 00 00 	movl   $0x2318,(%esp)
    dce2:	e8 15 a8 ff ff       	call   84fc <prints>
    dce7:	a1 40 01 00 00       	mov    0x140,%eax
    dcec:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    dcf2:	e8 8c a8 ff ff       	call   8583 <__cos_noret>
	if (t->state == SL_THD_BLOCKED_TIMEOUT) sl_timeout_remove(t);
    dcf7:	8b 45 08             	mov    0x8(%ebp),%eax
    dcfa:	8b 00                	mov    (%eax),%eax
    dcfc:	83 f8 02             	cmp    $0x2,%eax
    dcff:	75 0b                	jne    dd0c <sl_thd_wakeup_no_cs+0x103>
    dd01:	8b 45 08             	mov    0x8(%ebp),%eax
    dd04:	89 04 24             	mov    %eax,(%esp)
    dd07:	e8 bc f2 ff ff       	call   cfc8 <sl_timeout_remove>
	return sl_thd_wakeup_no_cs_rm(t);
    dd0c:	8b 45 08             	mov    0x8(%ebp),%eax
    dd0f:	89 04 24             	mov    %eax,(%esp)
    dd12:	e8 fc ff ff ff       	call   dd13 <sl_thd_wakeup_no_cs+0x10a>
}
    dd17:	c9                   	leave  
    dd18:	c3                   	ret    

0000dd19 <sl_thd_wakeup>:

void
sl_thd_wakeup(thdid_t tid)
{
    dd19:	55                   	push   %ebp
    dd1a:	89 e5                	mov    %esp,%ebp
    dd1c:	83 ec 28             	sub    $0x28,%esp
    dd1f:	8b 45 08             	mov    0x8(%ebp),%eax
    dd22:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
	struct sl_thd *t;

	sl_cs_enter();
    dd26:	e8 01 d8 ff ff       	call   b52c <sl_cs_enter>
	t = sl_thd_lkup(tid);
    dd2b:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
    dd2f:	89 04 24             	mov    %eax,(%esp)
    dd32:	e8 00 d6 ff ff       	call   b337 <sl_thd_lkup>
    dd37:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (unlikely(!t)) goto done;
    dd3a:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    dd3e:	0f 94 c0             	sete   %al
    dd41:	0f b6 c0             	movzbl %al,%eax
    dd44:	85 c0                	test   %eax,%eax
    dd46:	74 02                	je     dd4a <sl_thd_wakeup+0x31>
    dd48:	eb 18                	jmp    dd62 <sl_thd_wakeup+0x49>

	if (sl_thd_wakeup_no_cs(t)) goto done;
    dd4a:	8b 45 f4             	mov    -0xc(%ebp),%eax
    dd4d:	89 04 24             	mov    %eax,(%esp)
    dd50:	e8 fc ff ff ff       	call   dd51 <sl_thd_wakeup+0x38>
    dd55:	85 c0                	test   %eax,%eax
    dd57:	74 02                	je     dd5b <sl_thd_wakeup+0x42>
    dd59:	eb 07                	jmp    dd62 <sl_thd_wakeup+0x49>
	sl_cs_exit_schedule();
    dd5b:	e8 96 e1 ff ff       	call   bef6 <sl_cs_exit_schedule>

	return;
    dd60:	eb 06                	jmp    dd68 <sl_thd_wakeup+0x4f>
done:
	sl_cs_exit();
    dd62:	e8 fa d7 ff ff       	call   b561 <sl_cs_exit>
	return;
    dd67:	90                   	nop
}
    dd68:	c9                   	leave  
    dd69:	c3                   	ret    

0000dd6a <sl_thd_yield_cs_exit>:

void
sl_thd_yield_cs_exit(thdid_t tid)
{
    dd6a:	55                   	push   %ebp
    dd6b:	89 e5                	mov    %esp,%ebp
    dd6d:	83 ec 28             	sub    $0x28,%esp
    dd70:	8b 45 08             	mov    0x8(%ebp),%eax
    dd73:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
	struct sl_thd *t = sl_thd_curr();
    dd77:	e8 82 d6 ff ff       	call   b3fe <sl_thd_curr>
    dd7c:	89 45 f4             	mov    %eax,-0xc(%ebp)

	/* reset rcv_suspended if the scheduler thinks "curr" was suspended on cos_rcv previously */
	sl_thd_sched_unblock_no_cs(t);
    dd7f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    dd82:	89 04 24             	mov    %eax,(%esp)
    dd85:	e8 34 f6 ff ff       	call   d3be <sl_thd_sched_unblock_no_cs>
	if (tid) {
    dd8a:	66 83 7d e4 00       	cmpw   $0x0,-0x1c(%ebp)
    dd8f:	74 46                	je     ddd7 <sl_thd_yield_cs_exit+0x6d>
		struct sl_thd *to = sl_thd_lkup(tid);
    dd91:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
    dd95:	89 04 24             	mov    %eax,(%esp)
    dd98:	e8 9a d5 ff ff       	call   b337 <sl_thd_lkup>
    dd9d:	89 45 f0             	mov    %eax,-0x10(%ebp)

		assert(to);
    dda0:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
    dda4:	0f 94 c0             	sete   %al
    dda7:	0f b6 c0             	movzbl %al,%eax
    ddaa:	85 c0                	test   %eax,%eax
    ddac:	74 1c                	je     ddca <sl_thd_yield_cs_exit+0x60>
    ddae:	c7 04 24 44 23 00 00 	movl   $0x2344,(%esp)
    ddb5:	e8 42 a7 ff ff       	call   84fc <prints>
    ddba:	a1 40 01 00 00       	mov    0x140,%eax
    ddbf:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ddc5:	e8 b9 a7 ff ff       	call   8583 <__cos_noret>
		sl_cs_exit_switchto(to);
    ddca:	8b 45 f0             	mov    -0x10(%ebp),%eax
    ddcd:	89 04 24             	mov    %eax,(%esp)
    ddd0:	e8 33 e1 ff ff       	call   bf08 <sl_cs_exit_switchto>
    ddd5:	eb 4a                	jmp    de21 <sl_thd_yield_cs_exit+0xb7>
	} else {
		if (likely(t != sl__globals_cpu()->sched_thd && t != sl__globals_cpu()->idle_thd)) sl_mod_yield(sl_mod_thd_policy_get(t), NULL);
    ddd7:	e8 3f d5 ff ff       	call   b31b <sl__globals_cpu>
    dddc:	8b 40 10             	mov    0x10(%eax),%eax
    dddf:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    dde2:	0f 95 c0             	setne  %al
    dde5:	0f b6 c0             	movzbl %al,%eax
    dde8:	85 c0                	test   %eax,%eax
    ddea:	74 30                	je     de1c <sl_thd_yield_cs_exit+0xb2>
    ddec:	e8 2a d5 ff ff       	call   b31b <sl__globals_cpu>
    ddf1:	8b 40 14             	mov    0x14(%eax),%eax
    ddf4:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    ddf7:	0f 95 c0             	setne  %al
    ddfa:	0f b6 c0             	movzbl %al,%eax
    ddfd:	85 c0                	test   %eax,%eax
    ddff:	74 1b                	je     de1c <sl_thd_yield_cs_exit+0xb2>
    de01:	8b 45 f4             	mov    -0xc(%ebp),%eax
    de04:	89 04 24             	mov    %eax,(%esp)
    de07:	e8 9a a9 ff ff       	call   87a6 <sl_mod_thd_policy_get>
    de0c:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    de13:	00 
    de14:	89 04 24             	mov    %eax,(%esp)
    de17:	e8 fc ff ff ff       	call   de18 <sl_thd_yield_cs_exit+0xae>
		sl_cs_exit_schedule();
    de1c:	e8 d5 e0 ff ff       	call   bef6 <sl_cs_exit_schedule>
	}
}
    de21:	c9                   	leave  
    de22:	c3                   	ret    

0000de23 <sl_thd_yield>:

void
sl_thd_yield(thdid_t tid)
{
    de23:	55                   	push   %ebp
    de24:	89 e5                	mov    %esp,%ebp
    de26:	83 ec 18             	sub    $0x18,%esp
    de29:	8b 45 08             	mov    0x8(%ebp),%eax
    de2c:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	sl_cs_enter();
    de30:	e8 f7 d6 ff ff       	call   b52c <sl_cs_enter>
	sl_thd_yield_cs_exit(tid);
    de35:	0f b7 45 f4          	movzwl -0xc(%ebp),%eax
    de39:	89 04 24             	mov    %eax,(%esp)
    de3c:	e8 fc ff ff ff       	call   de3d <sl_thd_yield+0x1a>
}
    de41:	c9                   	leave  
    de42:	c3                   	ret    

0000de43 <sl_thd_event_info_reset>:

void
sl_thd_event_info_reset(struct sl_thd *t)
{
    de43:	55                   	push   %ebp
    de44:	89 e5                	mov    %esp,%ebp
	t->event_info.blocked = 0;
    de46:	8b 45 08             	mov    0x8(%ebp),%eax
    de49:	c7 40 60 00 00 00 00 	movl   $0x0,0x60(%eax)
	t->event_info.cycles  = 0;
    de50:	8b 45 08             	mov    0x8(%ebp),%eax
    de53:	c7 40 64 00 00 00 00 	movl   $0x0,0x64(%eax)
    de5a:	c7 40 68 00 00 00 00 	movl   $0x0,0x68(%eax)
	t->event_info.timeout = 0;
    de61:	8b 45 08             	mov    0x8(%ebp),%eax
    de64:	c7 40 6c 00 00 00 00 	movl   $0x0,0x6c(%eax)
}
    de6b:	5d                   	pop    %ebp
    de6c:	c3                   	ret    

0000de6d <sl_thd_event_enqueue>:

static inline void
sl_thd_event_enqueue(struct sl_thd *t, int blocked, cycles_t cycles, tcap_time_t timeout)
{
    de6d:	55                   	push   %ebp
    de6e:	89 e5                	mov    %esp,%ebp
    de70:	53                   	push   %ebx
    de71:	83 ec 24             	sub    $0x24,%esp
    de74:	8b 45 10             	mov    0x10(%ebp),%eax
    de77:	89 45 e0             	mov    %eax,-0x20(%ebp)
    de7a:	8b 45 14             	mov    0x14(%ebp),%eax
    de7d:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	struct sl_global_cpu *g = sl__globals_cpu();
    de80:	e8 96 d4 ff ff       	call   b31b <sl__globals_cpu>
    de85:	89 45 f4             	mov    %eax,-0xc(%ebp)

	if (ps_list_singleton(t, SL_THD_EVENT_LIST)) ps_list_head_append(&g->event_head, t, SL_THD_EVENT_LIST);
    de88:	8b 45 08             	mov    0x8(%ebp),%eax
    de8b:	83 c0 70             	add    $0x70,%eax
    de8e:	89 04 24             	mov    %eax,(%esp)
    de91:	e8 4e a0 ff ff       	call   7ee4 <ps_list_ll_empty>
    de96:	85 c0                	test   %eax,%eax
    de98:	74 18                	je     deb2 <sl_thd_event_enqueue+0x45>
    de9a:	8b 45 08             	mov    0x8(%ebp),%eax
    de9d:	8d 50 70             	lea    0x70(%eax),%edx
    dea0:	8b 45 f4             	mov    -0xc(%ebp),%eax
    dea3:	8b 40 34             	mov    0x34(%eax),%eax
    dea6:	89 54 24 04          	mov    %edx,0x4(%esp)
    deaa:	89 04 24             	mov    %eax,(%esp)
    dead:	e8 58 a0 ff ff       	call   7f0a <ps_list_ll_add>

	t->event_info.blocked  = blocked;
    deb2:	8b 45 08             	mov    0x8(%ebp),%eax
    deb5:	8b 55 0c             	mov    0xc(%ebp),%edx
    deb8:	89 50 60             	mov    %edx,0x60(%eax)
	t->event_info.cycles  += cycles;
    debb:	8b 45 08             	mov    0x8(%ebp),%eax
    debe:	8b 48 64             	mov    0x64(%eax),%ecx
    dec1:	8b 58 68             	mov    0x68(%eax),%ebx
    dec4:	8b 45 e0             	mov    -0x20(%ebp),%eax
    dec7:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    deca:	01 c8                	add    %ecx,%eax
    decc:	11 da                	adc    %ebx,%edx
    dece:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ded1:	89 41 64             	mov    %eax,0x64(%ecx)
    ded4:	89 51 68             	mov    %edx,0x68(%ecx)
	t->event_info.timeout  = timeout;
    ded7:	8b 45 08             	mov    0x8(%ebp),%eax
    deda:	8b 55 18             	mov    0x18(%ebp),%edx
    dedd:	89 50 6c             	mov    %edx,0x6c(%eax)
}
    dee0:	83 c4 24             	add    $0x24,%esp
    dee3:	5b                   	pop    %ebx
    dee4:	5d                   	pop    %ebp
    dee5:	c3                   	ret    

0000dee6 <sl_thd_event_dequeue>:

static inline void
sl_thd_event_dequeue(struct sl_thd *t, int *blocked, cycles_t *cycles, tcap_time_t *timeout)
{
    dee6:	55                   	push   %ebp
    dee7:	89 e5                	mov    %esp,%ebp
    dee9:	83 ec 04             	sub    $0x4,%esp
	ps_list_rem(t, SL_THD_EVENT_LIST);
    deec:	8b 45 08             	mov    0x8(%ebp),%eax
    deef:	83 c0 70             	add    $0x70,%eax
    def2:	89 04 24             	mov    %eax,(%esp)
    def5:	e8 3b a0 ff ff       	call   7f35 <ps_list_ll_rem>

	*blocked = t->event_info.blocked;
    defa:	8b 45 08             	mov    0x8(%ebp),%eax
    defd:	8b 50 60             	mov    0x60(%eax),%edx
    df00:	8b 45 0c             	mov    0xc(%ebp),%eax
    df03:	89 10                	mov    %edx,(%eax)
	*cycles  = t->event_info.cycles;
    df05:	8b 45 08             	mov    0x8(%ebp),%eax
    df08:	8b 50 68             	mov    0x68(%eax),%edx
    df0b:	8b 40 64             	mov    0x64(%eax),%eax
    df0e:	8b 4d 10             	mov    0x10(%ebp),%ecx
    df11:	89 01                	mov    %eax,(%ecx)
    df13:	89 51 04             	mov    %edx,0x4(%ecx)
	*timeout = t->event_info.timeout;
    df16:	8b 45 08             	mov    0x8(%ebp),%eax
    df19:	8b 50 6c             	mov    0x6c(%eax),%edx
    df1c:	8b 45 14             	mov    0x14(%ebp),%eax
    df1f:	89 10                	mov    %edx,(%eax)
	sl_thd_event_info_reset(t);
    df21:	8b 45 08             	mov    0x8(%ebp),%eax
    df24:	89 04 24             	mov    %eax,(%esp)
    df27:	e8 fc ff ff ff       	call   df28 <sl_thd_event_dequeue+0x42>
}
    df2c:	c9                   	leave  
    df2d:	c3                   	ret    

0000df2e <sl_thd_exit>:

void
sl_thd_exit()
{
    df2e:	55                   	push   %ebp
    df2f:	89 e5                	mov    %esp,%ebp
    df31:	83 ec 18             	sub    $0x18,%esp
	sl_thd_free(sl_thd_curr());
    df34:	e8 c5 d4 ff ff       	call   b3fe <sl_thd_curr>
    df39:	89 04 24             	mov    %eax,(%esp)
    df3c:	e8 fc ff ff ff       	call   df3d <sl_thd_exit+0xf>
}
    df41:	c9                   	leave  
    df42:	c3                   	ret    

0000df43 <sl_thd_param_set>:

void
sl_thd_param_set(struct sl_thd *t, sched_param_t sp)
{
    df43:	55                   	push   %ebp
    df44:	89 e5                	mov    %esp,%ebp
    df46:	56                   	push   %esi
    df47:	53                   	push   %ebx
    df48:	83 ec 20             	sub    $0x20,%esp
	sched_param_type_t type;
	unsigned int       value;

	assert(t);
    df4b:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    df4f:	0f 94 c0             	sete   %al
    df52:	0f b6 c0             	movzbl %al,%eax
    df55:	85 c0                	test   %eax,%eax
    df57:	74 1c                	je     df75 <sl_thd_param_set+0x32>
    df59:	c7 04 24 70 23 00 00 	movl   $0x2370,(%esp)
    df60:	e8 97 a5 ff ff       	call   84fc <prints>
    df65:	a1 40 01 00 00       	mov    0x140,%eax
    df6a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    df70:	e8 0e a6 ff ff       	call   8583 <__cos_noret>

	sched_param_get(sp, &type, &value);
    df75:	8d 45 f0             	lea    -0x10(%ebp),%eax
    df78:	89 44 24 08          	mov    %eax,0x8(%esp)
    df7c:	8d 45 f4             	lea    -0xc(%ebp),%eax
    df7f:	89 44 24 04          	mov    %eax,0x4(%esp)
    df83:	8b 45 0c             	mov    0xc(%ebp),%eax
    df86:	89 04 24             	mov    %eax,(%esp)
    df89:	e8 9b a7 ff ff       	call   8729 <sched_param_get>

	switch (type) {
    df8e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    df91:	83 f8 05             	cmp    $0x5,%eax
    df94:	74 34                	je     dfca <sl_thd_param_set+0x87>
    df96:	83 f8 06             	cmp    $0x6,%eax
    df99:	74 02                	je     df9d <sl_thd_param_set+0x5a>
	case SCHEDP_BUDGET:
	{
		t->budget = sl_usec2cyc(value);
		break;
	}
	default: break;
    df9b:	eb 4a                	jmp    dfe7 <sl_thd_param_set+0xa4>
	sched_param_get(sp, &type, &value);

	switch (type) {
	case SCHEDP_WINDOW:
	{
		t->period = sl_usec2cyc(value);
    df9d:	8b 45 f0             	mov    -0x10(%ebp),%eax
    dfa0:	ba 00 00 00 00       	mov    $0x0,%edx
    dfa5:	89 04 24             	mov    %eax,(%esp)
    dfa8:	89 54 24 04          	mov    %edx,0x4(%esp)
    dfac:	e8 51 d6 ff ff       	call   b602 <sl_usec2cyc>
    dfb1:	8b 4d 08             	mov    0x8(%ebp),%ecx
    dfb4:	89 41 3c             	mov    %eax,0x3c(%ecx)
    dfb7:	89 51 40             	mov    %edx,0x40(%ecx)
		t->periodic_cycs = sl_now(); /* TODO: synchronize for all tasks */
    dfba:	e8 7c d6 ff ff       	call   b63b <sl_now>
    dfbf:	8b 4d 08             	mov    0x8(%ebp),%ecx
    dfc2:	89 41 44             	mov    %eax,0x44(%ecx)
    dfc5:	89 51 48             	mov    %edx,0x48(%ecx)
		break;
    dfc8:	eb 1d                	jmp    dfe7 <sl_thd_param_set+0xa4>
	}
	case SCHEDP_BUDGET:
	{
		t->budget = sl_usec2cyc(value);
    dfca:	8b 45 f0             	mov    -0x10(%ebp),%eax
    dfcd:	ba 00 00 00 00       	mov    $0x0,%edx
    dfd2:	89 04 24             	mov    %eax,(%esp)
    dfd5:	89 54 24 04          	mov    %edx,0x4(%esp)
    dfd9:	e8 24 d6 ff ff       	call   b602 <sl_usec2cyc>
    dfde:	89 c2                	mov    %eax,%edx
    dfe0:	8b 45 08             	mov    0x8(%ebp),%eax
    dfe3:	89 50 30             	mov    %edx,0x30(%eax)
		break;
    dfe6:	90                   	nop
	}
	default: break;
	}

	sl_mod_thd_param_set(sl_mod_thd_policy_get(t), type, value);
    dfe7:	8b 75 f0             	mov    -0x10(%ebp),%esi
    dfea:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    dfed:	8b 45 08             	mov    0x8(%ebp),%eax
    dff0:	89 04 24             	mov    %eax,(%esp)
    dff3:	e8 ae a7 ff ff       	call   87a6 <sl_mod_thd_policy_get>
    dff8:	89 74 24 08          	mov    %esi,0x8(%esp)
    dffc:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    e000:	89 04 24             	mov    %eax,(%esp)
    e003:	e8 fc ff ff ff       	call   e004 <sl_thd_param_set+0xc1>
}
    e008:	83 c4 20             	add    $0x20,%esp
    e00b:	5b                   	pop    %ebx
    e00c:	5e                   	pop    %esi
    e00d:	5d                   	pop    %ebp
    e00e:	c3                   	ret    

0000e00f <sl_timeout_period>:

void
sl_timeout_period(microsec_t period)
{
    e00f:	55                   	push   %ebp
    e010:	89 e5                	mov    %esp,%ebp
    e012:	83 ec 20             	sub    $0x20,%esp
    e015:	8b 45 08             	mov    0x8(%ebp),%eax
    e018:	89 45 e8             	mov    %eax,-0x18(%ebp)
    e01b:	8b 45 0c             	mov    0xc(%ebp),%eax
    e01e:	89 45 ec             	mov    %eax,-0x14(%ebp)
	cycles_t p = sl_usec2cyc(period);
    e021:	8b 45 e8             	mov    -0x18(%ebp),%eax
    e024:	8b 55 ec             	mov    -0x14(%ebp),%edx
    e027:	89 04 24             	mov    %eax,(%esp)
    e02a:	89 54 24 04          	mov    %edx,0x4(%esp)
    e02e:	e8 cf d5 ff ff       	call   b602 <sl_usec2cyc>
    e033:	89 45 f8             	mov    %eax,-0x8(%ebp)
    e036:	89 55 fc             	mov    %edx,-0x4(%ebp)

	sl__globals_cpu()->period = p;
    e039:	e8 dd d2 ff ff       	call   b31b <sl__globals_cpu>
    e03e:	89 c1                	mov    %eax,%ecx
    e040:	8b 45 f8             	mov    -0x8(%ebp),%eax
    e043:	8b 55 fc             	mov    -0x4(%ebp),%edx
    e046:	89 41 1c             	mov    %eax,0x1c(%ecx)
    e049:	89 51 20             	mov    %edx,0x20(%ecx)
	sl_timeout_relative(p);
    e04c:	8b 45 f8             	mov    -0x8(%ebp),%eax
    e04f:	8b 55 fc             	mov    -0x4(%ebp),%edx
    e052:	89 04 24             	mov    %eax,(%esp)
    e055:	89 54 24 04          	mov    %edx,0x4(%esp)
    e059:	e8 3f d6 ff ff       	call   b69d <sl_timeout_relative>
}
    e05e:	c9                   	leave  
    e05f:	c3                   	ret    

0000e060 <sl_idle>:

/* engage space heater mode */
void
sl_idle(void *d)
{ while (1) ; }
    e060:	55                   	push   %ebp
    e061:	89 e5                	mov    %esp,%ebp
    e063:	eb fe                	jmp    e063 <sl_idle+0x3>

0000e065 <sl_global_init>:

/* call from the user? */
static void
sl_global_init(u32_t *cpu_bmp)
{
    e065:	55                   	push   %ebp
    e066:	89 e5                	mov    %esp,%ebp
    e068:	83 ec 28             	sub    $0x28,%esp
	struct sl_global *g = sl__globals();
    e06b:	e8 47 d2 ff ff       	call   b2b7 <sl__globals>
    e070:	89 45 f0             	mov    %eax,-0x10(%ebp)
	unsigned int i = 0;
    e073:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	memset(g, 0, sizeof(struct sl_global));
    e07a:	c7 44 24 08 c0 40 02 	movl   $0x240c0,0x8(%esp)
    e081:	00 
    e082:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    e089:	00 
    e08a:	8b 45 f0             	mov    -0x10(%ebp),%eax
    e08d:	89 04 24             	mov    %eax,(%esp)
    e090:	e8 fc ff ff ff       	call   e091 <sl_global_init+0x2c>

	for (i = 0; i < NUM_CPU; i++) {
    e095:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    e09c:	eb 4f                	jmp    e0ed <sl_global_init+0x88>
		if (!bitmap_check(cpu_bmp, i)) continue;
    e09e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e0a1:	89 44 24 04          	mov    %eax,0x4(%esp)
    e0a5:	8b 45 08             	mov    0x8(%ebp),%eax
    e0a8:	89 04 24             	mov    %eax,(%esp)
    e0ab:	e8 f1 a0 ff ff       	call   81a1 <bitmap_check>
    e0b0:	85 c0                	test   %eax,%eax
    e0b2:	75 02                	jne    e0b6 <sl_global_init+0x51>
    e0b4:	eb 33                	jmp    e0e9 <sl_global_init+0x84>

		bitmap_set(g->cpu_bmp, i);
    e0b6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e0b9:	8b 55 f0             	mov    -0x10(%ebp),%edx
    e0bc:	81 c2 88 40 02 00    	add    $0x24088,%edx
    e0c2:	89 44 24 04          	mov    %eax,0x4(%esp)
    e0c6:	89 14 24             	mov    %edx,(%esp)
    e0c9:	e8 7a a0 ff ff       	call   8148 <bitmap_set>
		ck_ring_init(sl__ring(i), SL_XCPU_RING_SIZE);
    e0ce:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e0d1:	89 04 24             	mov    %eax,(%esp)
    e0d4:	e8 12 d2 ff ff       	call   b2eb <sl__ring>
    e0d9:	c7 44 24 04 00 0c 00 	movl   $0xc00,0x4(%esp)
    e0e0:	00 
    e0e1:	89 04 24             	mov    %eax,(%esp)
    e0e4:	e8 90 b6 ff ff       	call   9779 <ck_ring_init>
	struct sl_global *g = sl__globals();
	unsigned int i = 0;

	memset(g, 0, sizeof(struct sl_global));

	for (i = 0; i < NUM_CPU; i++) {
    e0e9:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    e0ed:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    e0f1:	74 ab                	je     e09e <sl_global_init+0x39>
		if (!bitmap_check(cpu_bmp, i)) continue;

		bitmap_set(g->cpu_bmp, i);
		ck_ring_init(sl__ring(i), SL_XCPU_RING_SIZE);
	}
}
    e0f3:	c9                   	leave  
    e0f4:	c3                   	ret    

0000e0f5 <sl_init_cpubmp>:

void
sl_init_cpubmp(microsec_t period, u32_t *cpubmp)
{
    e0f5:	55                   	push   %ebp
    e0f6:	89 e5                	mov    %esp,%ebp
    e0f8:	83 ec 38             	sub    $0x38,%esp
    e0fb:	8b 45 08             	mov    0x8(%ebp),%eax
    e0fe:	89 45 e0             	mov    %eax,-0x20(%ebp)
    e101:	8b 45 0c             	mov    0xc(%ebp),%eax
    e104:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	int i;
	static volatile int first    = 1, init_done = 0;
	struct cos_defcompinfo *dci  = cos_defcompinfo_curr_get();
    e107:	e8 fc ff ff ff       	call   e108 <sl_init_cpubmp+0x13>
    e10c:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct cos_compinfo    *ci   = cos_compinfo_get(dci);
    e10f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e112:	89 04 24             	mov    %eax,(%esp)
    e115:	e8 fc ff ff ff       	call   e116 <sl_init_cpubmp+0x21>
    e11a:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct sl_global_cpu   *g    = sl__globals_cpu();
    e11d:	e8 f9 d1 ff ff       	call   b31b <sl__globals_cpu>
    e122:	89 45 ec             	mov    %eax,-0x14(%ebp)
	struct cos_aep_info    *saep = cos_sched_aep_get(dci);
    e125:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e128:	89 04 24             	mov    %eax,(%esp)
    e12b:	e8 fc ff ff ff       	call   e12c <sl_init_cpubmp+0x37>
    e130:	89 45 e8             	mov    %eax,-0x18(%ebp)

	if (ps_cas((unsigned long *)&first, 1, 0)) {
    e133:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    e13a:	00 
    e13b:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    e142:	00 
    e143:	c7 04 24 c4 00 00 00 	movl   $0xc4,(%esp)
    e14a:	e8 19 9e ff ff       	call   7f68 <ps_cas>
    e14f:	85 c0                	test   %eax,%eax
    e151:	74 21                	je     e174 <sl_init_cpubmp+0x7f>
		sl_global_init(cpubmp);
    e153:	8b 45 10             	mov    0x10(%ebp),%eax
    e156:	89 04 24             	mov    %eax,(%esp)
    e159:	e8 07 ff ff ff       	call   e065 <sl_global_init>

		ps_faa((unsigned long *)&init_done, 1);
    e15e:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    e165:	00 
    e166:	c7 04 24 94 02 00 00 	movl   $0x294,(%esp)
    e16d:	e8 1d 9e ff ff       	call   7f8f <ps_faa>
    e172:	eb 39                	jmp    e1ad <sl_init_cpubmp+0xb8>
	} else {
		/* wait until global ring buffers are initialized correctly! */
		while (!ps_load((unsigned long *)&init_done)) ;
    e174:	90                   	nop
    e175:	b8 94 02 00 00       	mov    $0x294,%eax
    e17a:	8b 00                	mov    (%eax),%eax
    e17c:	85 c0                	test   %eax,%eax
    e17e:	74 f5                	je     e175 <sl_init_cpubmp+0x80>
		/* make sure this scheduler is active on this cpu/core */
		assert(sl_cpu_active());
    e180:	e8 3c d1 ff ff       	call   b2c1 <sl_cpu_active>
    e185:	85 c0                	test   %eax,%eax
    e187:	0f 94 c0             	sete   %al
    e18a:	0f b6 c0             	movzbl %al,%eax
    e18d:	85 c0                	test   %eax,%eax
    e18f:	74 1c                	je     e1ad <sl_init_cpubmp+0xb8>
    e191:	c7 04 24 9c 23 00 00 	movl   $0x239c,(%esp)
    e198:	e8 5f a3 ff ff       	call   84fc <prints>
    e19d:	a1 40 01 00 00       	mov    0x140,%eax
    e1a2:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    e1a8:	e8 d6 a3 ff ff       	call   8583 <__cos_noret>
	}

	/* must fit in a word */
	assert(sizeof(struct sl_cs) <= sizeof(unsigned long));
	memset(g, 0, sizeof(struct sl_global_cpu));
    e1ad:	c7 44 24 08 38 00 00 	movl   $0x38,0x8(%esp)
    e1b4:	00 
    e1b5:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    e1bc:	00 
    e1bd:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e1c0:	89 04 24             	mov    %eax,(%esp)
    e1c3:	e8 fc ff ff ff       	call   e1c4 <sl_init_cpubmp+0xcf>

	g->cyc_per_usec    = cos_hw_cycles_per_usec(BOOT_CAPTBL_SELF_INITHW_BASE);
    e1c8:	c7 04 24 18 00 00 00 	movl   $0x18,(%esp)
    e1cf:	e8 fc ff ff ff       	call   e1d0 <sl_init_cpubmp+0xdb>
    e1d4:	8b 55 ec             	mov    -0x14(%ebp),%edx
    e1d7:	89 42 18             	mov    %eax,0x18(%edx)
	g->lock.u.v        = 0;
    e1da:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e1dd:	c7 00 00 00 00 00    	movl   $0x0,(%eax)

	sl_thd_init_backend();
    e1e3:	e8 fc ff ff ff       	call   e1e4 <sl_init_cpubmp+0xef>
	sl_mod_init();
    e1e8:	e8 fc ff ff ff       	call   e1e9 <sl_init_cpubmp+0xf4>
	sl_timeout_init(period);
    e1ed:	8b 45 e0             	mov    -0x20(%ebp),%eax
    e1f0:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    e1f3:	89 04 24             	mov    %eax,(%esp)
    e1f6:	89 54 24 04          	mov    %edx,0x4(%esp)
    e1fa:	e8 81 ef ff ff       	call   d180 <sl_timeout_init>

	/* Create the scheduler thread for us. cos_sched_aep_get() is from global(static) memory */
	g->sched_thd       = sl_thd_alloc_init(saep, 0, 0);
    e1ff:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    e206:	00 
    e207:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    e20e:	00 
    e20f:	8b 45 e8             	mov    -0x18(%ebp),%eax
    e212:	89 04 24             	mov    %eax,(%esp)
    e215:	e8 fc ff ff ff       	call   e216 <sl_init_cpubmp+0x121>
    e21a:	8b 55 ec             	mov    -0x14(%ebp),%edx
    e21d:	89 42 10             	mov    %eax,0x10(%edx)
	assert(g->sched_thd);
    e220:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e223:	8b 40 10             	mov    0x10(%eax),%eax
    e226:	85 c0                	test   %eax,%eax
    e228:	0f 94 c0             	sete   %al
    e22b:	0f b6 c0             	movzbl %al,%eax
    e22e:	85 c0                	test   %eax,%eax
    e230:	74 1c                	je     e24e <sl_init_cpubmp+0x159>
    e232:	c7 04 24 c8 23 00 00 	movl   $0x23c8,(%esp)
    e239:	e8 be a2 ff ff       	call   84fc <prints>
    e23e:	a1 40 01 00 00       	mov    0x140,%eax
    e243:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    e249:	e8 35 a3 ff ff       	call   8583 <__cos_noret>
	g->sched_thdcap    = saep->thd;
    e24e:	8b 45 e8             	mov    -0x18(%ebp),%eax
    e251:	8b 50 04             	mov    0x4(%eax),%edx
    e254:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e257:	89 50 04             	mov    %edx,0x4(%eax)
	g->sched_tcap      = saep->tc;
    e25a:	8b 45 e8             	mov    -0x18(%ebp),%eax
    e25d:	8b 10                	mov    (%eax),%edx
    e25f:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e262:	89 50 08             	mov    %edx,0x8(%eax)
	g->sched_rcv       = saep->rcv;
    e265:	8b 45 e8             	mov    -0x18(%ebp),%eax
    e268:	8b 50 0c             	mov    0xc(%eax),%edx
    e26b:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e26e:	89 50 0c             	mov    %edx,0xc(%eax)
	assert(g->sched_rcv);
    e271:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e274:	8b 40 0c             	mov    0xc(%eax),%eax
    e277:	85 c0                	test   %eax,%eax
    e279:	0f 94 c0             	sete   %al
    e27c:	0f b6 c0             	movzbl %al,%eax
    e27f:	85 c0                	test   %eax,%eax
    e281:	74 1c                	je     e29f <sl_init_cpubmp+0x1aa>
    e283:	c7 04 24 f4 23 00 00 	movl   $0x23f4,(%esp)
    e28a:	e8 6d a2 ff ff       	call   84fc <prints>
    e28f:	a1 40 01 00 00       	mov    0x140,%eax
    e294:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    e29a:	e8 e4 a2 ff ff       	call   8583 <__cos_noret>
	g->sched_thd->prio = TCAP_PRIO_MAX;
    e29f:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e2a2:	8b 40 10             	mov    0x10(%eax),%eax
    e2a5:	c7 40 28 01 00 00 00 	movl   $0x1,0x28(%eax)
    e2ac:	c7 40 2c 00 00 00 00 	movl   $0x0,0x2c(%eax)
	ps_list_head_init(&g->event_head);
    e2b3:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e2b6:	83 c0 30             	add    $0x30,%eax
    e2b9:	89 04 24             	mov    %eax,(%esp)
    e2bc:	e8 10 9c ff ff       	call   7ed1 <ps_list_head_init>

	g->idle_thd        = sl_thd_alloc(sl_idle, NULL);
    e2c1:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    e2c8:	00 
    e2c9:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    e2d0:	e8 fc ff ff ff       	call   e2d1 <sl_init_cpubmp+0x1dc>
    e2d5:	8b 55 ec             	mov    -0x14(%ebp),%edx
    e2d8:	89 42 14             	mov    %eax,0x14(%edx)
	assert(g->idle_thd);
    e2db:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e2de:	8b 40 14             	mov    0x14(%eax),%eax
    e2e1:	85 c0                	test   %eax,%eax
    e2e3:	0f 94 c0             	sete   %al
    e2e6:	0f b6 c0             	movzbl %al,%eax
    e2e9:	85 c0                	test   %eax,%eax
    e2eb:	74 1c                	je     e309 <sl_init_cpubmp+0x214>
    e2ed:	c7 04 24 20 24 00 00 	movl   $0x2420,(%esp)
    e2f4:	e8 03 a2 ff ff       	call   84fc <prints>
    e2f9:	a1 40 01 00 00       	mov    0x140,%eax
    e2fe:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    e304:	e8 7a a2 ff ff       	call   8583 <__cos_noret>

	/* all cores that this sched runs on, must be initialized by now so "asnd"s can be created! */
	sl_xcpu_asnd_alloc();
    e309:	e8 fc ff ff ff       	call   e30a <sl_init_cpubmp+0x215>

	return;
    e30e:	90                   	nop
}
    e30f:	c9                   	leave  
    e310:	c3                   	ret    

0000e311 <sl_init>:


void
sl_init(microsec_t period)
{
    e311:	55                   	push   %ebp
    e312:	89 e5                	mov    %esp,%ebp
    e314:	83 ec 38             	sub    $0x38,%esp
    e317:	8b 45 08             	mov    0x8(%ebp),%eax
    e31a:	89 45 e0             	mov    %eax,-0x20(%ebp)
    e31d:	8b 45 0c             	mov    0xc(%ebp),%eax
    e320:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	u32_t cpubmp[NUM_CPU_BMP_WORDS] = { 0 };
    e323:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	/* runs on all cores.. */
	bitmap_set_contig(cpubmp, 0, NUM_CPU, 1);
    e32a:	c7 44 24 0c 01 00 00 	movl   $0x1,0xc(%esp)
    e331:	00 
    e332:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
    e339:	00 
    e33a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    e341:	00 
    e342:	8d 45 f4             	lea    -0xc(%ebp),%eax
    e345:	89 04 24             	mov    %eax,(%esp)
    e348:	e8 ef 9e ff ff       	call   823c <bitmap_set_contig>
	sl_init_cpubmp(period, cpubmp);
    e34d:	8d 45 f4             	lea    -0xc(%ebp),%eax
    e350:	89 44 24 08          	mov    %eax,0x8(%esp)
    e354:	8b 45 e0             	mov    -0x20(%ebp),%eax
    e357:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    e35a:	89 04 24             	mov    %eax,(%esp)
    e35d:	89 54 24 04          	mov    %edx,0x4(%esp)
    e361:	e8 fc ff ff ff       	call   e362 <sl_init+0x51>
}
    e366:	c9                   	leave  
    e367:	c3                   	ret    

0000e368 <sl_sched_loop_intern>:

static void
sl_sched_loop_intern(int non_block)
{
    e368:	55                   	push   %ebp
    e369:	89 e5                	mov    %esp,%ebp
    e36b:	56                   	push   %esi
    e36c:	53                   	push   %ebx
    e36d:	83 ec 70             	sub    $0x70,%esp
	struct sl_global_cpu *g   = sl__globals_cpu();
    e370:	e8 a6 cf ff ff       	call   b31b <sl__globals_cpu>
    e375:	89 45 dc             	mov    %eax,-0x24(%ebp)
	rcv_flags_t           rfl = (non_block ? RCV_NON_BLOCKING : 0) | RCV_ALL_PENDING;
    e378:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    e37c:	74 07                	je     e385 <sl_sched_loop_intern+0x1d>
    e37e:	b8 03 00 00 00       	mov    $0x3,%eax
    e383:	eb 05                	jmp    e38a <sl_sched_loop_intern+0x22>
    e385:	b8 02 00 00 00       	mov    $0x2,%eax
    e38a:	89 45 d8             	mov    %eax,-0x28(%ebp)

	assert(sl_cpu_active());
    e38d:	e8 2f cf ff ff       	call   b2c1 <sl_cpu_active>
    e392:	85 c0                	test   %eax,%eax
    e394:	0f 94 c0             	sete   %al
    e397:	0f b6 c0             	movzbl %al,%eax
    e39a:	85 c0                	test   %eax,%eax
    e39c:	74 1c                	je     e3ba <sl_sched_loop_intern+0x52>
    e39e:	c7 04 24 4c 24 00 00 	movl   $0x244c,(%esp)
    e3a5:	e8 52 a1 ff ff       	call   84fc <prints>
    e3aa:	a1 40 01 00 00       	mov    0x140,%eax
    e3af:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    e3b5:	e8 c9 a1 ff ff       	call   8583 <__cos_noret>

		do {
			thdid_t        tid;
			int            blocked, rcvd;
			cycles_t       cycles;
			tcap_time_t    timeout = g->timeout_next, thd_timeout;
    e3ba:	8b 45 dc             	mov    -0x24(%ebp),%eax
    e3bd:	8b 40 2c             	mov    0x2c(%eax),%eax
    e3c0:	89 45 d4             	mov    %eax,-0x2c(%ebp)
			struct sl_thd *t = NULL, *tn = NULL;
    e3c3:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    e3ca:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
			/*
			 * a child scheduler may receive both scheduling notifications (block/unblock
			 * states of it's child threads) and normal notifications (mainly activations from
			 * it's parent scheduler).
			 */
			pending = cos_sched_rcv(g->sched_rcv, rfl, timeout,
    e3d1:	8b 45 dc             	mov    -0x24(%ebp),%eax
    e3d4:	8b 40 0c             	mov    0xc(%eax),%eax
    e3d7:	8d 55 b4             	lea    -0x4c(%ebp),%edx
    e3da:	89 54 24 1c          	mov    %edx,0x1c(%esp)
    e3de:	8d 55 b8             	lea    -0x48(%ebp),%edx
    e3e1:	89 54 24 18          	mov    %edx,0x18(%esp)
    e3e5:	8d 55 c4             	lea    -0x3c(%ebp),%edx
    e3e8:	89 54 24 14          	mov    %edx,0x14(%esp)
    e3ec:	8d 55 ca             	lea    -0x36(%ebp),%edx
    e3ef:	89 54 24 10          	mov    %edx,0x10(%esp)
    e3f3:	8d 55 c0             	lea    -0x40(%ebp),%edx
    e3f6:	89 54 24 0c          	mov    %edx,0xc(%esp)
    e3fa:	8b 55 d4             	mov    -0x2c(%ebp),%edx
    e3fd:	89 54 24 08          	mov    %edx,0x8(%esp)
    e401:	8b 55 d8             	mov    -0x28(%ebp),%edx
    e404:	89 54 24 04          	mov    %edx,0x4(%esp)
    e408:	89 04 24             	mov    %eax,(%esp)
    e40b:	e8 fc ff ff ff       	call   e40c <sl_sched_loop_intern+0xa4>
    e410:	89 45 d0             	mov    %eax,-0x30(%ebp)
						&rcvd, &tid, &blocked, &cycles, &thd_timeout);
			if (!tid) goto pending_events;
    e413:	0f b7 45 ca          	movzwl -0x36(%ebp),%eax
    e417:	66 85 c0             	test   %ax,%ax
    e41a:	75 05                	jne    e421 <sl_sched_loop_intern+0xb9>
    e41c:	e9 87 00 00 00       	jmp    e4a8 <sl_sched_loop_intern+0x140>

			t = sl_thd_lkup(tid);
    e421:	0f b7 45 ca          	movzwl -0x36(%ebp),%eax
    e425:	0f b7 c0             	movzwl %ax,%eax
    e428:	89 04 24             	mov    %eax,(%esp)
    e42b:	e8 07 cf ff ff       	call   b337 <sl_thd_lkup>
    e430:	89 45 f4             	mov    %eax,-0xc(%ebp)
			assert(t);
    e433:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    e437:	0f 94 c0             	sete   %al
    e43a:	0f b6 c0             	movzbl %al,%eax
    e43d:	85 c0                	test   %eax,%eax
    e43f:	74 1c                	je     e45d <sl_sched_loop_intern+0xf5>
    e441:	c7 04 24 78 24 00 00 	movl   $0x2478,(%esp)
    e448:	e8 af a0 ff ff       	call   84fc <prints>
    e44d:	a1 40 01 00 00       	mov    0x140,%eax
    e452:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    e458:	e8 26 a1 ff ff       	call   8583 <__cos_noret>
			/* don't report the idle thread or a freed thread */
			if (unlikely(t == g->idle_thd || t->state == SL_THD_FREE)) goto pending_events;
    e45d:	8b 45 dc             	mov    -0x24(%ebp),%eax
    e460:	8b 40 14             	mov    0x14(%eax),%eax
    e463:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    e466:	0f 94 c0             	sete   %al
    e469:	0f b6 c0             	movzbl %al,%eax
    e46c:	85 c0                	test   %eax,%eax
    e46e:	75 38                	jne    e4a8 <sl_sched_loop_intern+0x140>
    e470:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e473:	8b 00                	mov    (%eax),%eax
    e475:	85 c0                	test   %eax,%eax
    e477:	0f 94 c0             	sete   %al
    e47a:	0f b6 c0             	movzbl %al,%eax
    e47d:	85 c0                	test   %eax,%eax
    e47f:	75 27                	jne    e4a8 <sl_sched_loop_intern+0x140>
			 * that thread cannot succeed because scheduler has pending events causes the event
			 * just received to be dropped.
			 * To avoid dropping events, add the events to the scheduler event list and processing all
			 * the pending events after the scheduler can successfully take the lock.
			 */
			sl_thd_event_enqueue(t, blocked, cycles, thd_timeout);
    e481:	8b 5d b4             	mov    -0x4c(%ebp),%ebx
    e484:	8b 45 b8             	mov    -0x48(%ebp),%eax
    e487:	8b 55 bc             	mov    -0x44(%ebp),%edx
    e48a:	8b 4d c4             	mov    -0x3c(%ebp),%ecx
    e48d:	89 5c 24 10          	mov    %ebx,0x10(%esp)
    e491:	89 44 24 08          	mov    %eax,0x8(%esp)
    e495:	89 54 24 0c          	mov    %edx,0xc(%esp)
    e499:	89 4c 24 04          	mov    %ecx,0x4(%esp)
    e49d:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e4a0:	89 04 24             	mov    %eax,(%esp)
    e4a3:	e8 c5 f9 ff ff       	call   de6d <sl_thd_event_enqueue>

pending_events:
			if (ps_list_head_empty(&g->event_head) &&
    e4a8:	8b 45 dc             	mov    -0x24(%ebp),%eax
    e4ab:	83 c0 30             	add    $0x30,%eax
    e4ae:	89 04 24             	mov    %eax,(%esp)
    e4b1:	e8 41 9a ff ff       	call   7ef7 <ps_list_head_empty>
    e4b6:	85 c0                	test   %eax,%eax
    e4b8:	74 1f                	je     e4d9 <sl_sched_loop_intern+0x171>
			    ck_ring_size(sl__ring_curr()) == 0 &&
    e4ba:	e8 47 ce ff ff       	call   b306 <sl__ring_curr>
    e4bf:	89 04 24             	mov    %eax,(%esp)
    e4c2:	e8 6a b2 ff ff       	call   9731 <ck_ring_size>
			 * the pending events after the scheduler can successfully take the lock.
			 */
			sl_thd_event_enqueue(t, blocked, cycles, thd_timeout);

pending_events:
			if (ps_list_head_empty(&g->event_head) &&
    e4c7:	85 c0                	test   %eax,%eax
    e4c9:	75 0e                	jne    e4d9 <sl_sched_loop_intern+0x171>
			    ck_ring_size(sl__ring_curr()) == 0 &&
			    sl_child_notif_empty()) continue;
    e4cb:	e8 fc ff ff ff       	call   e4cc <sl_sched_loop_intern+0x164>
			 */
			sl_thd_event_enqueue(t, blocked, cycles, thd_timeout);

pending_events:
			if (ps_list_head_empty(&g->event_head) &&
			    ck_ring_size(sl__ring_curr()) == 0 &&
    e4d0:	85 c0                	test   %eax,%eax
    e4d2:	74 05                	je     e4d9 <sl_sched_loop_intern+0x171>
			    sl_child_notif_empty()) continue;
    e4d4:	e9 8d 01 00 00       	jmp    e666 <sl_sched_loop_intern+0x2fe>
			 * 1. scheduler thread can often be blocked in rcv, which can add to
			 *    interrupt execution or even AEP thread execution overheads.
			 * 2. scheduler events are not acting on the sl_thd or the policy structures, so
			 *    having finer grained locks around the code that modifies sl_thd states is better.
			 */
			if (sl_cs_enter_sched()) continue;
    e4d9:	e8 60 d0 ff ff       	call   b53e <sl_cs_enter_sched>
    e4de:	85 c0                	test   %eax,%eax
    e4e0:	74 05                	je     e4e7 <sl_sched_loop_intern+0x17f>
    e4e2:	e9 7f 01 00 00       	jmp    e666 <sl_sched_loop_intern+0x2fe>

			ps_list_foreach_del(&g->event_head, t, tn, SL_THD_EVENT_LIST) {
    e4e7:	8b 45 dc             	mov    -0x24(%ebp),%eax
    e4ea:	8b 40 30             	mov    0x30(%eax),%eax
    e4ed:	83 e8 70             	sub    $0x70,%eax
    e4f0:	89 45 f4             	mov    %eax,-0xc(%ebp)
    e4f3:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e4f6:	8b 40 70             	mov    0x70(%eax),%eax
    e4f9:	83 e8 70             	sub    $0x70,%eax
    e4fc:	89 45 f0             	mov    %eax,-0x10(%ebp)
    e4ff:	e9 ec 00 00 00       	jmp    e5f0 <sl_sched_loop_intern+0x288>
				/* remove the event from the list and get event info */
				sl_thd_event_dequeue(t, &blocked, &cycles, &thd_timeout);
    e504:	8d 45 b4             	lea    -0x4c(%ebp),%eax
    e507:	89 44 24 0c          	mov    %eax,0xc(%esp)
    e50b:	8d 45 b8             	lea    -0x48(%ebp),%eax
    e50e:	89 44 24 08          	mov    %eax,0x8(%esp)
    e512:	8d 45 c4             	lea    -0x3c(%ebp),%eax
    e515:	89 44 24 04          	mov    %eax,0x4(%esp)
    e519:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e51c:	89 04 24             	mov    %eax,(%esp)
    e51f:	e8 c2 f9 ff ff       	call   dee6 <sl_thd_event_dequeue>

				/* outdated event for a freed thread */
				if (t->state == SL_THD_FREE) continue;
    e524:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e527:	8b 00                	mov    (%eax),%eax
    e529:	85 c0                	test   %eax,%eax
    e52b:	75 05                	jne    e532 <sl_sched_loop_intern+0x1ca>
    e52d:	e9 ac 00 00 00       	jmp    e5de <sl_sched_loop_intern+0x276>

				sl_mod_execution(sl_mod_thd_policy_get(t), cycles);
    e532:	8b 5d b8             	mov    -0x48(%ebp),%ebx
    e535:	8b 75 bc             	mov    -0x44(%ebp),%esi
    e538:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e53b:	89 04 24             	mov    %eax,(%esp)
    e53e:	e8 63 a2 ff ff       	call   87a6 <sl_mod_thd_policy_get>
    e543:	89 5c 24 04          	mov    %ebx,0x4(%esp)
    e547:	89 74 24 08          	mov    %esi,0x8(%esp)
    e54b:	89 04 24             	mov    %eax,(%esp)
    e54e:	e8 fc ff ff ff       	call   e54f <sl_sched_loop_intern+0x1e7>

				if (blocked) {
    e553:	8b 45 c4             	mov    -0x3c(%ebp),%eax
    e556:	85 c0                	test   %eax,%eax
    e558:	74 79                	je     e5d3 <sl_sched_loop_intern+0x26b>
					sl_thd_state_t state = SL_THD_BLOCKED;
    e55a:	c7 45 ec 01 00 00 00 	movl   $0x1,-0x14(%ebp)
					cycles_t abs_timeout = 0;
    e561:	c7 45 e0 00 00 00 00 	movl   $0x0,-0x20(%ebp)
    e568:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)

					if (likely(cycles)) {
    e56f:	8b 45 b8             	mov    -0x48(%ebp),%eax
    e572:	8b 55 bc             	mov    -0x44(%ebp),%edx
    e575:	09 d0                	or     %edx,%eax
    e577:	85 c0                	test   %eax,%eax
    e579:	0f 95 c0             	setne  %al
    e57c:	0f b6 c0             	movzbl %al,%eax
    e57f:	85 c0                	test   %eax,%eax
    e581:	74 4e                	je     e5d1 <sl_sched_loop_intern+0x269>
						if (thd_timeout) {
    e583:	8b 45 b4             	mov    -0x4c(%ebp),%eax
    e586:	85 c0                	test   %eax,%eax
    e588:	74 25                	je     e5af <sl_sched_loop_intern+0x247>
							state       = SL_THD_BLOCKED_TIMEOUT;
    e58a:	c7 45 ec 02 00 00 00 	movl   $0x2,-0x14(%ebp)
							abs_timeout = tcap_time2cyc(thd_timeout, sl_now());
    e591:	e8 a5 d0 ff ff       	call   b63b <sl_now>
    e596:	8b 4d b4             	mov    -0x4c(%ebp),%ecx
    e599:	89 44 24 04          	mov    %eax,0x4(%esp)
    e59d:	89 54 24 08          	mov    %edx,0x8(%esp)
    e5a1:	89 0c 24             	mov    %ecx,(%esp)
    e5a4:	e8 4d 9a ff ff       	call   7ff6 <tcap_time2cyc>
    e5a9:	89 45 e0             	mov    %eax,-0x20(%ebp)
    e5ac:	89 55 e4             	mov    %edx,-0x1c(%ebp)
						}
						sl_thd_sched_block_no_cs(t, state, abs_timeout);
    e5af:	8b 45 e0             	mov    -0x20(%ebp),%eax
    e5b2:	8b 55 e4             	mov    -0x1c(%ebp),%edx
    e5b5:	89 44 24 08          	mov    %eax,0x8(%esp)
    e5b9:	89 54 24 0c          	mov    %edx,0xc(%esp)
    e5bd:	8b 45 ec             	mov    -0x14(%ebp),%eax
    e5c0:	89 44 24 04          	mov    %eax,0x4(%esp)
    e5c4:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e5c7:	89 04 24             	mov    %eax,(%esp)
    e5ca:	e8 fc ff ff ff       	call   e5cb <sl_sched_loop_intern+0x263>
    e5cf:	eb 0d                	jmp    e5de <sl_sched_loop_intern+0x276>
    e5d1:	eb 0b                	jmp    e5de <sl_sched_loop_intern+0x276>
					}
				} else {
					sl_thd_sched_wakeup_no_cs(t);
    e5d3:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e5d6:	89 04 24             	mov    %eax,(%esp)
    e5d9:	e8 fc ff ff ff       	call   e5da <sl_sched_loop_intern+0x272>
			 * 2. scheduler events are not acting on the sl_thd or the policy structures, so
			 *    having finer grained locks around the code that modifies sl_thd states is better.
			 */
			if (sl_cs_enter_sched()) continue;

			ps_list_foreach_del(&g->event_head, t, tn, SL_THD_EVENT_LIST) {
    e5de:	8b 45 f0             	mov    -0x10(%ebp),%eax
    e5e1:	89 45 f4             	mov    %eax,-0xc(%ebp)
    e5e4:	8b 45 f0             	mov    -0x10(%ebp),%eax
    e5e7:	8b 40 70             	mov    0x70(%eax),%eax
    e5ea:	83 e8 70             	sub    $0x70,%eax
    e5ed:	89 45 f0             	mov    %eax,-0x10(%ebp)
    e5f0:	8b 45 dc             	mov    -0x24(%ebp),%eax
    e5f3:	83 c0 30             	add    $0x30,%eax
    e5f6:	83 e8 70             	sub    $0x70,%eax
    e5f9:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    e5fc:	0f 85 02 ff ff ff    	jne    e504 <sl_sched_loop_intern+0x19c>
					sl_thd_sched_wakeup_no_cs(t);
				}
			}

			/* process notifications from the parent of my threads */
			while (sl_child_notif_dequeue(&notif)) {
    e602:	eb 49                	jmp    e64d <sl_sched_loop_intern+0x2e5>
				struct sl_thd *t = sl_thd_lkup(notif.tid);
    e604:	0f b7 45 b0          	movzwl -0x50(%ebp),%eax
    e608:	0f b7 c0             	movzwl %ax,%eax
    e60b:	89 04 24             	mov    %eax,(%esp)
    e60e:	e8 24 cd ff ff       	call   b337 <sl_thd_lkup>
    e613:	89 45 cc             	mov    %eax,-0x34(%ebp)

				if (notif.type == SL_CHILD_THD_BLOCK) sl_thd_block_no_cs(t, SL_THD_BLOCKED, 0);
    e616:	8b 45 ac             	mov    -0x54(%ebp),%eax
    e619:	85 c0                	test   %eax,%eax
    e61b:	75 25                	jne    e642 <sl_sched_loop_intern+0x2da>
    e61d:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
    e624:	00 
    e625:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    e62c:	00 
    e62d:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    e634:	00 
    e635:	8b 45 cc             	mov    -0x34(%ebp),%eax
    e638:	89 04 24             	mov    %eax,(%esp)
    e63b:	e8 fc ff ff ff       	call   e63c <sl_sched_loop_intern+0x2d4>
    e640:	eb 0b                	jmp    e64d <sl_sched_loop_intern+0x2e5>
				else                                  sl_thd_wakeup_no_cs(t);
    e642:	8b 45 cc             	mov    -0x34(%ebp),%eax
    e645:	89 04 24             	mov    %eax,(%esp)
    e648:	e8 fc ff ff ff       	call   e649 <sl_sched_loop_intern+0x2e1>
					sl_thd_sched_wakeup_no_cs(t);
				}
			}

			/* process notifications from the parent of my threads */
			while (sl_child_notif_dequeue(&notif)) {
    e64d:	8d 45 ac             	lea    -0x54(%ebp),%eax
    e650:	89 04 24             	mov    %eax,(%esp)
    e653:	e8 fc ff ff ff       	call   e654 <sl_sched_loop_intern+0x2ec>
    e658:	85 c0                	test   %eax,%eax
    e65a:	75 a8                	jne    e604 <sl_sched_loop_intern+0x29c>
				if (notif.type == SL_CHILD_THD_BLOCK) sl_thd_block_no_cs(t, SL_THD_BLOCKED, 0);
				else                                  sl_thd_wakeup_no_cs(t);
			}

			/* process cross-core requests */
			sl_xcpu_process_no_cs();
    e65c:	e8 fc ff ff ff       	call   e65d <sl_sched_loop_intern+0x2f5>

			sl_cs_exit();
    e661:	e8 fb ce ff ff       	call   b561 <sl_cs_exit>
		} while (pending > 0);
    e666:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
    e66a:	0f 8f 4a fd ff ff    	jg     e3ba <sl_sched_loop_intern+0x52>

		if (sl_cs_enter_sched()) continue;
    e670:	e8 c9 ce ff ff       	call   b53e <sl_cs_enter_sched>
    e675:	85 c0                	test   %eax,%eax
    e677:	74 06                	je     e67f <sl_sched_loop_intern+0x317>
    e679:	90                   	nop
		/* If switch returns an inconsistency, we retry anyway */
		sl_cs_exit_schedule_nospin();
	}
    e67a:	e9 3b fd ff ff       	jmp    e3ba <sl_sched_loop_intern+0x52>
			sl_cs_exit();
		} while (pending > 0);

		if (sl_cs_enter_sched()) continue;
		/* If switch returns an inconsistency, we retry anyway */
		sl_cs_exit_schedule_nospin();
    e67f:	e8 5e d8 ff ff       	call   bee2 <sl_cs_exit_schedule_nospin>
	}
    e684:	e9 31 fd ff ff       	jmp    e3ba <sl_sched_loop_intern+0x52>

0000e689 <sl_sched_loop>:
}

void
sl_sched_loop(void)
{
    e689:	55                   	push   %ebp
    e68a:	89 e5                	mov    %esp,%ebp
    e68c:	83 ec 18             	sub    $0x18,%esp
	sl_sched_loop_intern(0);
    e68f:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    e696:	e8 cd fc ff ff       	call   e368 <sl_sched_loop_intern>

0000e69b <sl_sched_loop_nonblock>:
}

void
sl_sched_loop_nonblock(void)
{
    e69b:	55                   	push   %ebp
    e69c:	89 e5                	mov    %esp,%ebp
    e69e:	83 ec 18             	sub    $0x18,%esp
	sl_sched_loop_intern(1);
    e6a1:	c7 04 24 01 00 00 00 	movl   $0x1,(%esp)
    e6a8:	e8 bb fc ff ff       	call   e368 <sl_sched_loop_intern>
    e6ad:	66 90                	xchg   %ax,%ax
    e6af:	90                   	nop

0000e6b0 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
    e6b0:	55                   	push   %ebp
    e6b1:	89 e5                	mov    %esp,%ebp
    e6b3:	57                   	push   %edi
    e6b4:	56                   	push   %esi
    e6b5:	53                   	push   %ebx
    e6b6:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    e6b9:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    e6c0:	8b 45 08             	mov    0x8(%ebp),%eax
    e6c3:	83 c0 01             	add    $0x1,%eax
    e6c6:	c1 e0 10             	shl    $0x10,%eax
    e6c9:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    e6cc:	8b 45 0c             	mov    0xc(%ebp),%eax
    e6cf:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    e6d2:	8b 45 08             	mov    0x8(%ebp),%eax
    e6d5:	8b 4d 10             	mov    0x10(%ebp),%ecx
    e6d8:	8b 75 14             	mov    0x14(%ebp),%esi
    e6db:	8b 7d 18             	mov    0x18(%ebp),%edi
    e6de:	8b 55 1c             	mov    0x1c(%ebp),%edx
    e6e1:	89 cb                	mov    %ecx,%ebx
    e6e3:	55                   	push   %ebp
    e6e4:	89 e5                	mov    %esp,%ebp
    e6e6:	b9 f8 e6 00 00       	mov    $0xe6f8,%ecx
    e6eb:	0f 34                	sysenter 
    e6ed:	8d 76 00             	lea    0x0(%esi),%esi
    e6f0:	eb 0d                	jmp    e6ff <call_cap_asm+0x4f>
    e6f2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    e6f8:	b9 00 00 00 00       	mov    $0x0,%ecx
    e6fd:	eb 05                	jmp    e704 <call_cap_asm+0x54>
    e6ff:	b9 01 00 00 00       	mov    $0x1,%ecx
    e704:	5d                   	pop    %ebp
    e705:	89 ca                	mov    %ecx,%edx
    e707:	89 45 ec             	mov    %eax,-0x14(%ebp)
    e70a:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    e70d:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    e710:	83 c4 10             	add    $0x10,%esp
    e713:	5b                   	pop    %ebx
    e714:	5e                   	pop    %esi
    e715:	5f                   	pop    %edi
    e716:	5d                   	pop    %ebp
    e717:	c3                   	ret    

0000e718 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
    e718:	55                   	push   %ebp
    e719:	89 e5                	mov    %esp,%ebp
    e71b:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
    e71e:	8b 45 18             	mov    0x18(%ebp),%eax
    e721:	89 44 24 14          	mov    %eax,0x14(%esp)
    e725:	8b 45 14             	mov    0x14(%ebp),%eax
    e728:	89 44 24 10          	mov    %eax,0x10(%esp)
    e72c:	8b 45 10             	mov    0x10(%ebp),%eax
    e72f:	89 44 24 0c          	mov    %eax,0xc(%esp)
    e733:	8b 45 0c             	mov    0xc(%ebp),%eax
    e736:	89 44 24 08          	mov    %eax,0x8(%esp)
    e73a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    e741:	00 
    e742:	8b 45 08             	mov    0x8(%ebp),%eax
    e745:	89 04 24             	mov    %eax,(%esp)
    e748:	e8 63 ff ff ff       	call   e6b0 <call_cap_asm>
}
    e74d:	c9                   	leave  
    e74e:	c3                   	ret    

0000e74f <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
    e74f:	55                   	push   %ebp
    e750:	89 e5                	mov    %esp,%ebp
    e752:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
    e755:	8b 45 08             	mov    0x8(%ebp),%eax
    e758:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    e75f:	00 
    e760:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    e767:	00 
    e768:	8b 55 0c             	mov    0xc(%ebp),%edx
    e76b:	89 54 24 08          	mov    %edx,0x8(%esp)
    e76f:	89 44 24 04          	mov    %eax,0x4(%esp)
    e773:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    e77a:	e8 99 ff ff ff       	call   e718 <call_cap>
}
    e77f:	c9                   	leave  
    e780:	c3                   	ret    

0000e781 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
    e781:	55                   	push   %ebp
    e782:	89 e5                	mov    %esp,%ebp
    e784:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
    e787:	89 e0                	mov    %esp,%eax
    e789:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
    e78c:	8b 45 fc             	mov    -0x4(%ebp),%eax
    e78f:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    e794:	89 c2                	mov    %eax,%edx
    e796:	8b 45 08             	mov    0x8(%ebp),%eax
    e799:	c1 e0 02             	shl    $0x2,%eax
    e79c:	29 c2                	sub    %eax,%edx
    e79e:	89 d0                	mov    %edx,%eax
    e7a0:	05 00 10 00 00       	add    $0x1000,%eax
    e7a5:	8b 00                	mov    (%eax),%eax
}
    e7a7:	c9                   	leave  
    e7a8:	c3                   	ret    

0000e7a9 <cos_get_thd_id>:
	return get_stk_data(CPUID_OFFSET);
}

static inline unsigned short int
cos_get_thd_id(void)
{
    e7a9:	55                   	push   %ebp
    e7aa:	89 e5                	mov    %esp,%ebp
    e7ac:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
    e7af:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    e7b6:	e8 c6 ff ff ff       	call   e781 <get_stk_data>
}
    e7bb:	c9                   	leave  
    e7bc:	c3                   	ret    

0000e7bd <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
    e7bd:	55                   	push   %ebp
    e7be:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
    e7c0:	e8 e4 ff ff ff       	call   e7a9 <cos_get_thd_id>
}
    e7c5:	5d                   	pop    %ebp
    e7c6:	c3                   	ret    

0000e7c7 <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
    e7c7:	55                   	push   %ebp
    e7c8:	89 e5                	mov    %esp,%ebp
    e7ca:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
    e7cd:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    e7d4:	eb 20                	jmp    e7f6 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
    e7d6:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e7d9:	83 c0 01             	add    $0x1,%eax
    e7dc:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    e7e3:	8b 45 08             	mov    0x8(%ebp),%eax
    e7e6:	01 d0                	add    %edx,%eax
    e7e8:	8b 00                	mov    (%eax),%eax
    e7ea:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
    e7ed:	8b 45 f0             	mov    -0x10(%ebp),%eax
    e7f0:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
    e7f2:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    e7f6:	8b 45 08             	mov    0x8(%ebp),%eax
    e7f9:	8b 00                	mov    (%eax),%eax
    e7fb:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    e7fe:	7f d6                	jg     e7d6 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
    e800:	c9                   	leave  
    e801:	c3                   	ret    

0000e802 <constructors_execute>:

static void
constructors_execute(void)
{
    e802:	55                   	push   %ebp
    e803:	89 e5                	mov    %esp,%ebp
    e805:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
    e808:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    e80f:	e8 b3 ff ff ff       	call   e7c7 <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
    e814:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    e81b:	e8 a7 ff ff ff       	call   e7c7 <section_fnptrs_execute>
}
    e820:	c9                   	leave  
    e821:	c3                   	ret    

0000e822 <destructors_execute>:
static void
destructors_execute(void)
{
    e822:	55                   	push   %ebp
    e823:	89 e5                	mov    %esp,%ebp
    e825:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
    e828:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    e82f:	e8 93 ff ff ff       	call   e7c7 <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
    e834:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    e83b:	e8 87 ff ff ff       	call   e7c7 <section_fnptrs_execute>
}
    e840:	c9                   	leave  
    e841:	c3                   	ret    

0000e842 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
    e842:	55                   	push   %ebp
    e843:	89 e5                	mov    %esp,%ebp
    e845:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
    e848:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    e84f:	e8 73 ff ff ff       	call   e7c7 <section_fnptrs_execute>
}
    e854:	c9                   	leave  
    e855:	c3                   	ret    

0000e856 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
    e856:	55                   	push   %ebp
    e857:	89 e5                	mov    %esp,%ebp
    e859:	83 ec 08             	sub    $0x8,%esp
    e85c:	8b 55 08             	mov    0x8(%ebp),%edx
    e85f:	8b 45 0c             	mov    0xc(%ebp),%eax
    e862:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
    e866:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
    e869:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    e86d:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
    e871:	ee                   	out    %al,(%dx)
}
    e872:	c9                   	leave  
    e873:	c3                   	ret    

0000e874 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
    e874:	55                   	push   %ebp
    e875:	89 e5                	mov    %esp,%ebp
    e877:	83 ec 14             	sub    $0x14,%esp
    e87a:	8b 45 08             	mov    0x8(%ebp),%eax
    e87d:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
    e881:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
    e885:	89 c2                	mov    %eax,%edx
    e887:	ec                   	in     (%dx),%al
    e888:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
    e88b:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
    e88f:	c9                   	leave  
    e890:	c3                   	ret    

0000e891 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
    e891:	55                   	push   %ebp
    e892:	89 e5                	mov    %esp,%ebp
    e894:	83 ec 0c             	sub    $0xc,%esp
    e897:	8b 45 08             	mov    0x8(%ebp),%eax
    e89a:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
    e89d:	90                   	nop
    e89e:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
    e8a5:	e8 ca ff ff ff       	call   e874 <inb>
    e8aa:	0f b6 c0             	movzbl %al,%eax
    e8ad:	83 e0 20             	and    $0x20,%eax
    e8b0:	85 c0                	test   %eax,%eax
    e8b2:	74 ea                	je     e89e <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
    e8b4:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    e8b8:	0f b6 c0             	movzbl %al,%eax
    e8bb:	89 44 24 04          	mov    %eax,0x4(%esp)
    e8bf:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
    e8c6:	e8 8b ff ff ff       	call   e856 <outb>
}
    e8cb:	c9                   	leave  
    e8cc:	c3                   	ret    

0000e8cd <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
    e8cd:	55                   	push   %ebp
    e8ce:	89 e5                	mov    %esp,%ebp
    e8d0:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
    e8d3:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
    e8da:	eb 1a                	jmp    e8f6 <cos_serial_putb+0x29>
    e8dc:	8b 45 fc             	mov    -0x4(%ebp),%eax
    e8df:	8b 55 08             	mov    0x8(%ebp),%edx
    e8e2:	01 d0                	add    %edx,%eax
    e8e4:	0f b6 00             	movzbl (%eax),%eax
    e8e7:	0f be c0             	movsbl %al,%eax
    e8ea:	89 04 24             	mov    %eax,(%esp)
    e8ed:	e8 9f ff ff ff       	call   e891 <cos_serial_putc>
    e8f2:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
    e8f6:	8b 45 fc             	mov    -0x4(%ebp),%eax
    e8f9:	3b 45 0c             	cmp    0xc(%ebp),%eax
    e8fc:	72 de                	jb     e8dc <cos_serial_putb+0xf>
}
    e8fe:	c9                   	leave  
    e8ff:	c3                   	ret    

0000e900 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
    e900:	55                   	push   %ebp
    e901:	89 e5                	mov    %esp,%ebp
    e903:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
    e906:	8b 45 0c             	mov    0xc(%ebp),%eax
    e909:	89 44 24 04          	mov    %eax,0x4(%esp)
    e90d:	8b 45 08             	mov    0x8(%ebp),%eax
    e910:	89 04 24             	mov    %eax,(%esp)
    e913:	e8 b5 ff ff ff       	call   e8cd <cos_serial_putb>
}
    e918:	c9                   	leave  
    e919:	c3                   	ret    

0000e91a <prints>:

static int
prints(char *s)
{
    e91a:	55                   	push   %ebp
    e91b:	89 e5                	mov    %esp,%ebp
    e91d:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
    e920:	8b 45 08             	mov    0x8(%ebp),%eax
    e923:	89 04 24             	mov    %eax,(%esp)
    e926:	e8 fc ff ff ff       	call   e927 <prints+0xd>
    e92b:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
    e92e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e931:	89 44 24 04          	mov    %eax,0x4(%esp)
    e935:	8b 45 08             	mov    0x8(%ebp),%eax
    e938:	89 04 24             	mov    %eax,(%esp)
    e93b:	e8 0f fe ff ff       	call   e74f <cos_print>

	return len;
    e940:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    e943:	c9                   	leave  
    e944:	c3                   	ret    

0000e945 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
    e945:	55                   	push   %ebp
    e946:	89 e5                	mov    %esp,%ebp
    e948:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
    e94e:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
    e955:	8d 45 0c             	lea    0xc(%ebp),%eax
    e958:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
    e95e:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
    e964:	89 44 24 0c          	mov    %eax,0xc(%esp)
    e968:	8b 45 08             	mov    0x8(%ebp),%eax
    e96b:	89 44 24 08          	mov    %eax,0x8(%esp)
    e96f:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e972:	89 44 24 04          	mov    %eax,0x4(%esp)
    e976:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    e97c:	89 04 24             	mov    %eax,(%esp)
    e97f:	e8 fc ff ff ff       	call   e980 <printc+0x3b>
    e984:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
    e987:	8b 45 f0             	mov    -0x10(%ebp),%eax
    e98a:	89 44 24 04          	mov    %eax,0x4(%esp)
    e98e:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    e994:	89 04 24             	mov    %eax,(%esp)
    e997:	e8 64 ff ff ff       	call   e900 <cos_llprint>

	return ret;
    e99c:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    e99f:	c9                   	leave  
    e9a0:	c3                   	ret    

0000e9a1 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
    e9a1:	55                   	push   %ebp
    e9a2:	89 e5                	mov    %esp,%ebp
	while (1)
		;
    e9a4:	eb fe                	jmp    e9a4 <__cos_noret+0x3>

0000e9a6 <swap_entries>:
#define debug(format, ...)
#endif

static inline void
swap_entries(void *arr[], int a, int b, update_fn_t u)
{
    e9a6:	55                   	push   %ebp
    e9a7:	89 e5                	mov    %esp,%ebp
    e9a9:	83 ec 28             	sub    $0x28,%esp
	void *t;

	t      = arr[a];
    e9ac:	8b 45 0c             	mov    0xc(%ebp),%eax
    e9af:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    e9b6:	8b 45 08             	mov    0x8(%ebp),%eax
    e9b9:	01 d0                	add    %edx,%eax
    e9bb:	8b 00                	mov    (%eax),%eax
    e9bd:	89 45 f4             	mov    %eax,-0xc(%ebp)
	arr[a] = arr[b];
    e9c0:	8b 45 0c             	mov    0xc(%ebp),%eax
    e9c3:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    e9ca:	8b 45 08             	mov    0x8(%ebp),%eax
    e9cd:	01 c2                	add    %eax,%edx
    e9cf:	8b 45 10             	mov    0x10(%ebp),%eax
    e9d2:	8d 0c 85 00 00 00 00 	lea    0x0(,%eax,4),%ecx
    e9d9:	8b 45 08             	mov    0x8(%ebp),%eax
    e9dc:	01 c8                	add    %ecx,%eax
    e9de:	8b 00                	mov    (%eax),%eax
    e9e0:	89 02                	mov    %eax,(%edx)
	arr[b] = t;
    e9e2:	8b 45 10             	mov    0x10(%ebp),%eax
    e9e5:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    e9ec:	8b 45 08             	mov    0x8(%ebp),%eax
    e9ef:	01 c2                	add    %eax,%edx
    e9f1:	8b 45 f4             	mov    -0xc(%ebp),%eax
    e9f4:	89 02                	mov    %eax,(%edx)

	u(arr[a], a);
    e9f6:	8b 45 0c             	mov    0xc(%ebp),%eax
    e9f9:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    ea00:	8b 45 08             	mov    0x8(%ebp),%eax
    ea03:	01 d0                	add    %edx,%eax
    ea05:	8b 00                	mov    (%eax),%eax
    ea07:	8b 55 0c             	mov    0xc(%ebp),%edx
    ea0a:	89 54 24 04          	mov    %edx,0x4(%esp)
    ea0e:	89 04 24             	mov    %eax,(%esp)
    ea11:	8b 45 14             	mov    0x14(%ebp),%eax
    ea14:	ff d0                	call   *%eax
	u(arr[b], b);
    ea16:	8b 45 10             	mov    0x10(%ebp),%eax
    ea19:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    ea20:	8b 45 08             	mov    0x8(%ebp),%eax
    ea23:	01 d0                	add    %edx,%eax
    ea25:	8b 00                	mov    (%eax),%eax
    ea27:	8b 55 10             	mov    0x10(%ebp),%edx
    ea2a:	89 54 24 04          	mov    %edx,0x4(%esp)
    ea2e:	89 04 24             	mov    %eax,(%esp)
    ea31:	8b 45 14             	mov    0x14(%ebp),%eax
    ea34:	ff d0                	call   *%eax
}
    ea36:	c9                   	leave  
    ea37:	c3                   	ret    

0000ea38 <swap_down>:
 * c: current index
 * e: end index
 */
static inline int
swap_down(struct heap *h, int c)
{
    ea38:	55                   	push   %ebp
    ea39:	89 e5                	mov    %esp,%ebp
    ea3b:	53                   	push   %ebx
    ea3c:	83 ec 24             	sub    $0x24,%esp
	int l; /* last entry */

	assert(c != 0);
    ea3f:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    ea43:	0f 94 c0             	sete   %al
    ea46:	0f b6 c0             	movzbl %al,%eax
    ea49:	85 c0                	test   %eax,%eax
    ea4b:	74 1c                	je     ea69 <swap_down+0x31>
    ea4d:	c7 04 24 a4 24 00 00 	movl   $0x24a4,(%esp)
    ea54:	e8 c1 fe ff ff       	call   e91a <prints>
    ea59:	a1 98 02 00 00       	mov    0x298,%eax
    ea5e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ea64:	e8 38 ff ff ff       	call   e9a1 <__cos_noret>
	assert(c <= h->e);
    ea69:	8b 45 08             	mov    0x8(%ebp),%eax
    ea6c:	8b 00                	mov    (%eax),%eax
    ea6e:	3b 45 0c             	cmp    0xc(%ebp),%eax
    ea71:	0f 9c c0             	setl   %al
    ea74:	0f b6 c0             	movzbl %al,%eax
    ea77:	85 c0                	test   %eax,%eax
    ea79:	74 1c                	je     ea97 <swap_down+0x5f>
    ea7b:	c7 04 24 cc 24 00 00 	movl   $0x24cc,(%esp)
    ea82:	e8 93 fe ff ff       	call   e91a <prints>
    ea87:	a1 98 02 00 00       	mov    0x298,%eax
    ea8c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ea92:	e8 0a ff ff ff       	call   e9a1 <__cos_noret>

	l = h->e - 1;
    ea97:	8b 45 08             	mov    0x8(%ebp),%eax
    ea9a:	8b 00                	mov    (%eax),%eax
    ea9c:	83 e8 01             	sub    $0x1,%eax
    ea9f:	89 45 f0             	mov    %eax,-0x10(%ebp)
	while (c <= l / 2) { /* not a leaf? */
    eaa2:	e9 f3 00 00 00       	jmp    eb9a <swap_down+0x162>
		int n;       /* next index */
		int left, right;

		left  = 2 * c;
    eaa7:	8b 45 0c             	mov    0xc(%ebp),%eax
    eaaa:	01 c0                	add    %eax,%eax
    eaac:	89 45 ec             	mov    %eax,-0x14(%ebp)
		right = 2 * c + 1;
    eaaf:	8b 45 0c             	mov    0xc(%ebp),%eax
    eab2:	01 c0                	add    %eax,%eax
    eab4:	83 c0 01             	add    $0x1,%eax
    eab7:	89 45 e8             	mov    %eax,-0x18(%ebp)

		if (right > l) {
    eaba:	8b 45 e8             	mov    -0x18(%ebp),%eax
    eabd:	3b 45 f0             	cmp    -0x10(%ebp),%eax
    eac0:	7e 08                	jle    eaca <swap_down+0x92>
			n = left;
    eac2:	8b 45 ec             	mov    -0x14(%ebp),%eax
    eac5:	89 45 f4             	mov    %eax,-0xc(%ebp)
    eac8:	eb 41                	jmp    eb0b <swap_down+0xd3>
		} else if (h->c(h->data[left], h->data[right])) {
    eaca:	8b 45 08             	mov    0x8(%ebp),%eax
    eacd:	8b 40 08             	mov    0x8(%eax),%eax
    ead0:	8b 55 08             	mov    0x8(%ebp),%edx
    ead3:	8b 52 10             	mov    0x10(%edx),%edx
    ead6:	8b 4d e8             	mov    -0x18(%ebp),%ecx
    ead9:	c1 e1 02             	shl    $0x2,%ecx
    eadc:	01 ca                	add    %ecx,%edx
    eade:	8b 0a                	mov    (%edx),%ecx
    eae0:	8b 55 08             	mov    0x8(%ebp),%edx
    eae3:	8b 52 10             	mov    0x10(%edx),%edx
    eae6:	8b 5d ec             	mov    -0x14(%ebp),%ebx
    eae9:	c1 e3 02             	shl    $0x2,%ebx
    eaec:	01 da                	add    %ebx,%edx
    eaee:	8b 12                	mov    (%edx),%edx
    eaf0:	89 4c 24 04          	mov    %ecx,0x4(%esp)
    eaf4:	89 14 24             	mov    %edx,(%esp)
    eaf7:	ff d0                	call   *%eax
    eaf9:	85 c0                	test   %eax,%eax
    eafb:	74 08                	je     eb05 <swap_down+0xcd>
			n = left;
    eafd:	8b 45 ec             	mov    -0x14(%ebp),%eax
    eb00:	89 45 f4             	mov    %eax,-0xc(%ebp)
    eb03:	eb 06                	jmp    eb0b <swap_down+0xd3>
		} else {
			n = right;
    eb05:	8b 45 e8             	mov    -0x18(%ebp),%eax
    eb08:	89 45 f4             	mov    %eax,-0xc(%ebp)
		}

		assert(n < h->e);
    eb0b:	8b 45 08             	mov    0x8(%ebp),%eax
    eb0e:	8b 00                	mov    (%eax),%eax
    eb10:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    eb13:	0f 9e c0             	setle  %al
    eb16:	0f b6 c0             	movzbl %al,%eax
    eb19:	85 c0                	test   %eax,%eax
    eb1b:	74 1c                	je     eb39 <swap_down+0x101>
    eb1d:	c7 04 24 f4 24 00 00 	movl   $0x24f4,(%esp)
    eb24:	e8 f1 fd ff ff       	call   e91a <prints>
    eb29:	a1 98 02 00 00       	mov    0x298,%eax
    eb2e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    eb34:	e8 68 fe ff ff       	call   e9a1 <__cos_noret>
		if (h->c(h->data[c], h->data[n])) break; /* done? */
    eb39:	8b 45 08             	mov    0x8(%ebp),%eax
    eb3c:	8b 40 08             	mov    0x8(%eax),%eax
    eb3f:	8b 55 08             	mov    0x8(%ebp),%edx
    eb42:	8b 52 10             	mov    0x10(%edx),%edx
    eb45:	8b 4d f4             	mov    -0xc(%ebp),%ecx
    eb48:	c1 e1 02             	shl    $0x2,%ecx
    eb4b:	01 ca                	add    %ecx,%edx
    eb4d:	8b 0a                	mov    (%edx),%ecx
    eb4f:	8b 55 08             	mov    0x8(%ebp),%edx
    eb52:	8b 52 10             	mov    0x10(%edx),%edx
    eb55:	8b 5d 0c             	mov    0xc(%ebp),%ebx
    eb58:	c1 e3 02             	shl    $0x2,%ebx
    eb5b:	01 da                	add    %ebx,%edx
    eb5d:	8b 12                	mov    (%edx),%edx
    eb5f:	89 4c 24 04          	mov    %ecx,0x4(%esp)
    eb63:	89 14 24             	mov    %edx,(%esp)
    eb66:	ff d0                	call   *%eax
    eb68:	85 c0                	test   %eax,%eax
    eb6a:	74 02                	je     eb6e <swap_down+0x136>
    eb6c:	eb 41                	jmp    ebaf <swap_down+0x177>

		swap_entries(h->data, n, c, h->u);
    eb6e:	8b 45 08             	mov    0x8(%ebp),%eax
    eb71:	8b 50 0c             	mov    0xc(%eax),%edx
    eb74:	8b 45 08             	mov    0x8(%ebp),%eax
    eb77:	8b 40 10             	mov    0x10(%eax),%eax
    eb7a:	89 54 24 0c          	mov    %edx,0xc(%esp)
    eb7e:	8b 55 0c             	mov    0xc(%ebp),%edx
    eb81:	89 54 24 08          	mov    %edx,0x8(%esp)
    eb85:	8b 55 f4             	mov    -0xc(%ebp),%edx
    eb88:	89 54 24 04          	mov    %edx,0x4(%esp)
    eb8c:	89 04 24             	mov    %eax,(%esp)
    eb8f:	e8 12 fe ff ff       	call   e9a6 <swap_entries>
		c = n;
    eb94:	8b 45 f4             	mov    -0xc(%ebp),%eax
    eb97:	89 45 0c             	mov    %eax,0xc(%ebp)

	assert(c != 0);
	assert(c <= h->e);

	l = h->e - 1;
	while (c <= l / 2) { /* not a leaf? */
    eb9a:	8b 45 f0             	mov    -0x10(%ebp),%eax
    eb9d:	89 c2                	mov    %eax,%edx
    eb9f:	c1 ea 1f             	shr    $0x1f,%edx
    eba2:	01 d0                	add    %edx,%eax
    eba4:	d1 f8                	sar    %eax
    eba6:	3b 45 0c             	cmp    0xc(%ebp),%eax
    eba9:	0f 8d f8 fe ff ff    	jge    eaa7 <swap_down+0x6f>

		swap_entries(h->data, n, c, h->u);
		c = n;
	}

	return c;
    ebaf:	8b 45 0c             	mov    0xc(%ebp),%eax
}
    ebb2:	83 c4 24             	add    $0x24,%esp
    ebb5:	5b                   	pop    %ebx
    ebb6:	5d                   	pop    %ebp
    ebb7:	c3                   	ret    

0000ebb8 <swap_up>:

static inline int
swap_up(struct heap *h, int c)
{
    ebb8:	55                   	push   %ebp
    ebb9:	89 e5                	mov    %esp,%ebp
    ebbb:	53                   	push   %ebx
    ebbc:	83 ec 24             	sub    $0x24,%esp
	assert(c <= h->e);
    ebbf:	8b 45 08             	mov    0x8(%ebp),%eax
    ebc2:	8b 00                	mov    (%eax),%eax
    ebc4:	3b 45 0c             	cmp    0xc(%ebp),%eax
    ebc7:	0f 9c c0             	setl   %al
    ebca:	0f b6 c0             	movzbl %al,%eax
    ebcd:	85 c0                	test   %eax,%eax
    ebcf:	74 1c                	je     ebed <swap_up+0x35>
    ebd1:	c7 04 24 1c 25 00 00 	movl   $0x251c,(%esp)
    ebd8:	e8 3d fd ff ff       	call   e91a <prints>
    ebdd:	a1 98 02 00 00       	mov    0x298,%eax
    ebe2:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ebe8:	e8 b4 fd ff ff       	call   e9a1 <__cos_noret>
	assert(c > 0);
    ebed:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    ebf1:	0f 9e c0             	setle  %al
    ebf4:	0f b6 c0             	movzbl %al,%eax
    ebf7:	85 c0                	test   %eax,%eax
    ebf9:	74 1c                	je     ec17 <swap_up+0x5f>
    ebfb:	c7 04 24 44 25 00 00 	movl   $0x2544,(%esp)
    ec02:	e8 13 fd ff ff       	call   e91a <prints>
    ec07:	a1 98 02 00 00       	mov    0x298,%eax
    ec0c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ec12:	e8 8a fd ff ff       	call   e9a1 <__cos_noret>

	while (c > 1) {
    ec17:	e9 9a 00 00 00       	jmp    ecb6 <swap_up+0xfe>
		int p; /* parent index */

		p = c / 2;
    ec1c:	8b 45 0c             	mov    0xc(%ebp),%eax
    ec1f:	89 c2                	mov    %eax,%edx
    ec21:	c1 ea 1f             	shr    $0x1f,%edx
    ec24:	01 d0                	add    %edx,%eax
    ec26:	d1 f8                	sar    %eax
    ec28:	89 45 f4             	mov    %eax,-0xc(%ebp)
		assert(p != 0);
    ec2b:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
    ec2f:	0f 94 c0             	sete   %al
    ec32:	0f b6 c0             	movzbl %al,%eax
    ec35:	85 c0                	test   %eax,%eax
    ec37:	74 1c                	je     ec55 <swap_up+0x9d>
    ec39:	c7 04 24 6c 25 00 00 	movl   $0x256c,(%esp)
    ec40:	e8 d5 fc ff ff       	call   e91a <prints>
    ec45:	a1 98 02 00 00       	mov    0x298,%eax
    ec4a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ec50:	e8 4c fd ff ff       	call   e9a1 <__cos_noret>
		if (h->c(h->data[p], h->data[c])) break; /* done? */
    ec55:	8b 45 08             	mov    0x8(%ebp),%eax
    ec58:	8b 40 08             	mov    0x8(%eax),%eax
    ec5b:	8b 55 08             	mov    0x8(%ebp),%edx
    ec5e:	8b 52 10             	mov    0x10(%edx),%edx
    ec61:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    ec64:	c1 e1 02             	shl    $0x2,%ecx
    ec67:	01 ca                	add    %ecx,%edx
    ec69:	8b 0a                	mov    (%edx),%ecx
    ec6b:	8b 55 08             	mov    0x8(%ebp),%edx
    ec6e:	8b 52 10             	mov    0x10(%edx),%edx
    ec71:	8b 5d f4             	mov    -0xc(%ebp),%ebx
    ec74:	c1 e3 02             	shl    $0x2,%ebx
    ec77:	01 da                	add    %ebx,%edx
    ec79:	8b 12                	mov    (%edx),%edx
    ec7b:	89 4c 24 04          	mov    %ecx,0x4(%esp)
    ec7f:	89 14 24             	mov    %edx,(%esp)
    ec82:	ff d0                	call   *%eax
    ec84:	85 c0                	test   %eax,%eax
    ec86:	74 02                	je     ec8a <swap_up+0xd2>
    ec88:	eb 36                	jmp    ecc0 <swap_up+0x108>

		swap_entries(h->data, p, c, h->u);
    ec8a:	8b 45 08             	mov    0x8(%ebp),%eax
    ec8d:	8b 50 0c             	mov    0xc(%eax),%edx
    ec90:	8b 45 08             	mov    0x8(%ebp),%eax
    ec93:	8b 40 10             	mov    0x10(%eax),%eax
    ec96:	89 54 24 0c          	mov    %edx,0xc(%esp)
    ec9a:	8b 55 0c             	mov    0xc(%ebp),%edx
    ec9d:	89 54 24 08          	mov    %edx,0x8(%esp)
    eca1:	8b 55 f4             	mov    -0xc(%ebp),%edx
    eca4:	89 54 24 04          	mov    %edx,0x4(%esp)
    eca8:	89 04 24             	mov    %eax,(%esp)
    ecab:	e8 f6 fc ff ff       	call   e9a6 <swap_entries>
		c = p;
    ecb0:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ecb3:	89 45 0c             	mov    %eax,0xc(%ebp)
swap_up(struct heap *h, int c)
{
	assert(c <= h->e);
	assert(c > 0);

	while (c > 1) {
    ecb6:	83 7d 0c 01          	cmpl   $0x1,0xc(%ebp)
    ecba:	0f 8f 5c ff ff ff    	jg     ec1c <swap_up+0x64>
		if (h->c(h->data[p], h->data[c])) break; /* done? */

		swap_entries(h->data, p, c, h->u);
		c = p;
	}
	assert(c != 0);
    ecc0:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    ecc4:	0f 94 c0             	sete   %al
    ecc7:	0f b6 c0             	movzbl %al,%eax
    ecca:	85 c0                	test   %eax,%eax
    eccc:	74 1c                	je     ecea <swap_up+0x132>
    ecce:	c7 04 24 94 25 00 00 	movl   $0x2594,(%esp)
    ecd5:	e8 40 fc ff ff       	call   e91a <prints>
    ecda:	a1 98 02 00 00       	mov    0x298,%eax
    ecdf:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ece5:	e8 b7 fc ff ff       	call   e9a1 <__cos_noret>

	return c;
    ecea:	8b 45 0c             	mov    0xc(%ebp),%eax
}
    eced:	83 c4 24             	add    $0x24,%esp
    ecf0:	5b                   	pop    %ebx
    ecf1:	5d                   	pop    %ebp
    ecf2:	c3                   	ret    

0000ecf3 <heapify>:

/* return c's final index */
static inline int
heapify(struct heap *h, int c)
{
    ecf3:	55                   	push   %ebp
    ecf4:	89 e5                	mov    %esp,%ebp
    ecf6:	83 ec 18             	sub    $0x18,%esp
	c = swap_up(h, c);
    ecf9:	8b 45 0c             	mov    0xc(%ebp),%eax
    ecfc:	89 44 24 04          	mov    %eax,0x4(%esp)
    ed00:	8b 45 08             	mov    0x8(%ebp),%eax
    ed03:	89 04 24             	mov    %eax,(%esp)
    ed06:	e8 ad fe ff ff       	call   ebb8 <swap_up>
    ed0b:	89 45 0c             	mov    %eax,0xc(%ebp)
	return swap_down(h, c);
    ed0e:	8b 45 0c             	mov    0xc(%ebp),%eax
    ed11:	89 44 24 04          	mov    %eax,0x4(%esp)
    ed15:	8b 45 08             	mov    0x8(%ebp),%eax
    ed18:	89 04 24             	mov    %eax,(%esp)
    ed1b:	e8 18 fd ff ff       	call   ea38 <swap_down>
}
    ed20:	c9                   	leave  
    ed21:	c3                   	ret    

0000ed22 <heap_init>:
#endif

/* public functions */
void
heap_init(struct heap *h, int max_sz, cmp_fn_t c, update_fn_t u)
{
    ed22:	55                   	push   %ebp
    ed23:	89 e5                	mov    %esp,%ebp
    ed25:	83 ec 18             	sub    $0x18,%esp
	assert(h);
    ed28:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    ed2c:	0f 94 c0             	sete   %al
    ed2f:	0f b6 c0             	movzbl %al,%eax
    ed32:	85 c0                	test   %eax,%eax
    ed34:	74 1c                	je     ed52 <heap_init+0x30>
    ed36:	c7 04 24 bc 25 00 00 	movl   $0x25bc,(%esp)
    ed3d:	e8 d8 fb ff ff       	call   e91a <prints>
    ed42:	a1 98 02 00 00       	mov    0x298,%eax
    ed47:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ed4d:	e8 4f fc ff ff       	call   e9a1 <__cos_noret>

	h->max_sz = max_sz + 1;
    ed52:	8b 45 0c             	mov    0xc(%ebp),%eax
    ed55:	8d 50 01             	lea    0x1(%eax),%edx
    ed58:	8b 45 08             	mov    0x8(%ebp),%eax
    ed5b:	89 50 04             	mov    %edx,0x4(%eax)
	h->e      = 1;
    ed5e:	8b 45 08             	mov    0x8(%ebp),%eax
    ed61:	c7 00 01 00 00 00    	movl   $0x1,(%eax)
	h->c      = c;
    ed67:	8b 45 08             	mov    0x8(%ebp),%eax
    ed6a:	8b 55 10             	mov    0x10(%ebp),%edx
    ed6d:	89 50 08             	mov    %edx,0x8(%eax)
	h->u      = u;
    ed70:	8b 45 08             	mov    0x8(%ebp),%eax
    ed73:	8b 55 14             	mov    0x14(%ebp),%edx
    ed76:	89 50 0c             	mov    %edx,0xc(%eax)
	h->data   = (void *)&h[1];
    ed79:	8b 45 08             	mov    0x8(%ebp),%eax
    ed7c:	8d 50 14             	lea    0x14(%eax),%edx
    ed7f:	8b 45 08             	mov    0x8(%ebp),%eax
    ed82:	89 50 10             	mov    %edx,0x10(%eax)
	assert(!heap_verify(h));
}
    ed85:	c9                   	leave  
    ed86:	c3                   	ret    

0000ed87 <heap_alloc>:

struct heap *
heap_alloc(int max_sz, cmp_fn_t c, update_fn_t u)
{
    ed87:	55                   	push   %ebp
    ed88:	89 e5                	mov    %esp,%ebp
    ed8a:	83 ec 10             	sub    $0x10,%esp
	struct heap *h = NULL;
    ed8d:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
	if (NULL == h) return NULL;

	heap_init(h, max_sz, c, u);
#endif

	return h;
    ed94:	8b 45 fc             	mov    -0x4(%ebp),%eax
}
    ed97:	c9                   	leave  
    ed98:	c3                   	ret    

0000ed99 <heap_destroy>:

void
heap_destroy(struct heap *h)
{
    ed99:	55                   	push   %ebp
    ed9a:	89 e5                	mov    %esp,%ebp
    ed9c:	83 ec 18             	sub    $0x18,%esp
	assert(h && h->data);
    ed9f:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    eda3:	0f 94 c0             	sete   %al
    eda6:	0f b6 c0             	movzbl %al,%eax
    eda9:	85 c0                	test   %eax,%eax
    edab:	75 12                	jne    edbf <heap_destroy+0x26>
    edad:	8b 45 08             	mov    0x8(%ebp),%eax
    edb0:	8b 40 10             	mov    0x10(%eax),%eax
    edb3:	85 c0                	test   %eax,%eax
    edb5:	0f 94 c0             	sete   %al
    edb8:	0f b6 c0             	movzbl %al,%eax
    edbb:	85 c0                	test   %eax,%eax
    edbd:	74 1c                	je     eddb <heap_destroy+0x42>
    edbf:	c7 04 24 e4 25 00 00 	movl   $0x25e4,(%esp)
    edc6:	e8 4f fb ff ff       	call   e91a <prints>
    edcb:	a1 98 02 00 00       	mov    0x298,%eax
    edd0:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    edd6:	e8 c6 fb ff ff       	call   e9a1 <__cos_noret>

#ifdef LINUX
	free(h);
#endif
}
    eddb:	c9                   	leave  
    eddc:	c3                   	ret    

0000eddd <heap_add>:

int
heap_add(struct heap *h, void *new)
{
    eddd:	55                   	push   %ebp
    edde:	89 e5                	mov    %esp,%ebp
    ede0:	83 ec 28             	sub    $0x28,%esp
	int c;

	if (h->max_sz == h->e) return -1;
    ede3:	8b 45 08             	mov    0x8(%ebp),%eax
    ede6:	8b 50 04             	mov    0x4(%eax),%edx
    ede9:	8b 45 08             	mov    0x8(%ebp),%eax
    edec:	8b 00                	mov    (%eax),%eax
    edee:	39 c2                	cmp    %eax,%edx
    edf0:	75 07                	jne    edf9 <heap_add+0x1c>
    edf2:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
    edf7:	eb 54                	jmp    ee4d <heap_add+0x70>

	debug("heap_add(%p,%d) %p\n", h, h->e, new);

	assert(!heap_verify(h));
	c          = h->e;
    edf9:	8b 45 08             	mov    0x8(%ebp),%eax
    edfc:	8b 00                	mov    (%eax),%eax
    edfe:	89 45 f4             	mov    %eax,-0xc(%ebp)
	h->data[c] = new;
    ee01:	8b 45 08             	mov    0x8(%ebp),%eax
    ee04:	8b 40 10             	mov    0x10(%eax),%eax
    ee07:	8b 55 f4             	mov    -0xc(%ebp),%edx
    ee0a:	c1 e2 02             	shl    $0x2,%edx
    ee0d:	01 c2                	add    %eax,%edx
    ee0f:	8b 45 0c             	mov    0xc(%ebp),%eax
    ee12:	89 02                	mov    %eax,(%edx)
	h->u(new, c);
    ee14:	8b 45 08             	mov    0x8(%ebp),%eax
    ee17:	8b 40 0c             	mov    0xc(%eax),%eax
    ee1a:	8b 55 f4             	mov    -0xc(%ebp),%edx
    ee1d:	89 54 24 04          	mov    %edx,0x4(%esp)
    ee21:	8b 55 0c             	mov    0xc(%ebp),%edx
    ee24:	89 14 24             	mov    %edx,(%esp)
    ee27:	ff d0                	call   *%eax
	h->e++;
    ee29:	8b 45 08             	mov    0x8(%ebp),%eax
    ee2c:	8b 00                	mov    (%eax),%eax
    ee2e:	8d 50 01             	lea    0x1(%eax),%edx
    ee31:	8b 45 08             	mov    0x8(%ebp),%eax
    ee34:	89 10                	mov    %edx,(%eax)
	heapify(h, c);
    ee36:	8b 45 f4             	mov    -0xc(%ebp),%eax
    ee39:	89 44 24 04          	mov    %eax,0x4(%esp)
    ee3d:	8b 45 08             	mov    0x8(%ebp),%eax
    ee40:	89 04 24             	mov    %eax,(%esp)
    ee43:	e8 ab fe ff ff       	call   ecf3 <heapify>
	assert(!heap_verify(h));

	return 0;
    ee48:	b8 00 00 00 00       	mov    $0x0,%eax
}
    ee4d:	c9                   	leave  
    ee4e:	c3                   	ret    

0000ee4f <heap_highest>:

void *
heap_highest(struct heap *h)
{
    ee4f:	55                   	push   %ebp
    ee50:	89 e5                	mov    %esp,%ebp
    ee52:	83 ec 28             	sub    $0x28,%esp
	void *r;

	if (h->e == 1) return NULL;
    ee55:	8b 45 08             	mov    0x8(%ebp),%eax
    ee58:	8b 00                	mov    (%eax),%eax
    ee5a:	83 f8 01             	cmp    $0x1,%eax
    ee5d:	75 0a                	jne    ee69 <heap_highest+0x1a>
    ee5f:	b8 00 00 00 00       	mov    $0x0,%eax
    ee64:	e9 80 00 00 00       	jmp    eee9 <heap_highest+0x9a>

	assert(!heap_verify(h));
	r = h->data[1];
    ee69:	8b 45 08             	mov    0x8(%ebp),%eax
    ee6c:	8b 40 10             	mov    0x10(%eax),%eax
    ee6f:	8b 40 04             	mov    0x4(%eax),%eax
    ee72:	89 45 f4             	mov    %eax,-0xc(%ebp)
	debug("heap_highest(%p,%d) %p\n", h, h->e, r);

	h->e--;
    ee75:	8b 45 08             	mov    0x8(%ebp),%eax
    ee78:	8b 00                	mov    (%eax),%eax
    ee7a:	8d 50 ff             	lea    -0x1(%eax),%edx
    ee7d:	8b 45 08             	mov    0x8(%ebp),%eax
    ee80:	89 10                	mov    %edx,(%eax)
	h->data[1] = h->data[h->e];
    ee82:	8b 45 08             	mov    0x8(%ebp),%eax
    ee85:	8b 40 10             	mov    0x10(%eax),%eax
    ee88:	8d 50 04             	lea    0x4(%eax),%edx
    ee8b:	8b 45 08             	mov    0x8(%ebp),%eax
    ee8e:	8b 48 10             	mov    0x10(%eax),%ecx
    ee91:	8b 45 08             	mov    0x8(%ebp),%eax
    ee94:	8b 00                	mov    (%eax),%eax
    ee96:	c1 e0 02             	shl    $0x2,%eax
    ee99:	01 c8                	add    %ecx,%eax
    ee9b:	8b 00                	mov    (%eax),%eax
    ee9d:	89 02                	mov    %eax,(%edx)
	h->u(h->data[1], 1);
    ee9f:	8b 45 08             	mov    0x8(%ebp),%eax
    eea2:	8b 40 0c             	mov    0xc(%eax),%eax
    eea5:	8b 55 08             	mov    0x8(%ebp),%edx
    eea8:	8b 52 10             	mov    0x10(%edx),%edx
    eeab:	83 c2 04             	add    $0x4,%edx
    eeae:	8b 12                	mov    (%edx),%edx
    eeb0:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    eeb7:	00 
    eeb8:	89 14 24             	mov    %edx,(%esp)
    eebb:	ff d0                	call   *%eax
	swap_down(h, 1);
    eebd:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
    eec4:	00 
    eec5:	8b 45 08             	mov    0x8(%ebp),%eax
    eec8:	89 04 24             	mov    %eax,(%esp)
    eecb:	e8 68 fb ff ff       	call   ea38 <swap_down>
	assert(!heap_verify(h));
	h->u(r, 0);
    eed0:	8b 45 08             	mov    0x8(%ebp),%eax
    eed3:	8b 40 0c             	mov    0xc(%eax),%eax
    eed6:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    eedd:	00 
    eede:	8b 55 f4             	mov    -0xc(%ebp),%edx
    eee1:	89 14 24             	mov    %edx,(%esp)
    eee4:	ff d0                	call   *%eax

	return r;
    eee6:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    eee9:	c9                   	leave  
    eeea:	c3                   	ret    

0000eeeb <heap_peek>:

void *
heap_peek(struct heap *h)
{
    eeeb:	55                   	push   %ebp
    eeec:	89 e5                	mov    %esp,%ebp
	if (h->e == 1) return NULL;
    eeee:	8b 45 08             	mov    0x8(%ebp),%eax
    eef1:	8b 00                	mov    (%eax),%eax
    eef3:	83 f8 01             	cmp    $0x1,%eax
    eef6:	75 07                	jne    eeff <heap_peek+0x14>
    eef8:	b8 00 00 00 00       	mov    $0x0,%eax
    eefd:	eb 09                	jmp    ef08 <heap_peek+0x1d>
	assert(!heap_verify(h));
	return h->data[1];
    eeff:	8b 45 08             	mov    0x8(%ebp),%eax
    ef02:	8b 40 10             	mov    0x10(%eax),%eax
    ef05:	8b 40 04             	mov    0x4(%eax),%eax
}
    ef08:	5d                   	pop    %ebp
    ef09:	c3                   	ret    

0000ef0a <heap_adjust>:

void
heap_adjust(struct heap *h, int c)
{
    ef0a:	55                   	push   %ebp
    ef0b:	89 e5                	mov    %esp,%ebp
    ef0d:	83 ec 18             	sub    $0x18,%esp
	assert(c < h->e);
    ef10:	8b 45 08             	mov    0x8(%ebp),%eax
    ef13:	8b 00                	mov    (%eax),%eax
    ef15:	3b 45 0c             	cmp    0xc(%ebp),%eax
    ef18:	0f 9e c0             	setle  %al
    ef1b:	0f b6 c0             	movzbl %al,%eax
    ef1e:	85 c0                	test   %eax,%eax
    ef20:	74 1c                	je     ef3e <heap_adjust+0x34>
    ef22:	c7 04 24 0c 26 00 00 	movl   $0x260c,(%esp)
    ef29:	e8 ec f9 ff ff       	call   e91a <prints>
    ef2e:	a1 98 02 00 00       	mov    0x298,%eax
    ef33:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ef39:	e8 63 fa ff ff       	call   e9a1 <__cos_noret>
	assert(c > 0);
    ef3e:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    ef42:	0f 9e c0             	setle  %al
    ef45:	0f b6 c0             	movzbl %al,%eax
    ef48:	85 c0                	test   %eax,%eax
    ef4a:	74 1c                	je     ef68 <heap_adjust+0x5e>
    ef4c:	c7 04 24 34 26 00 00 	movl   $0x2634,(%esp)
    ef53:	e8 c2 f9 ff ff       	call   e91a <prints>
    ef58:	a1 98 02 00 00       	mov    0x298,%eax
    ef5d:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    ef63:	e8 39 fa ff ff       	call   e9a1 <__cos_noret>

	debug("heap_adjust(%p,%d) %p@%d\n", h, h->e, h->data[c], c);
	heapify(h, c);
    ef68:	8b 45 0c             	mov    0xc(%ebp),%eax
    ef6b:	89 44 24 04          	mov    %eax,0x4(%esp)
    ef6f:	8b 45 08             	mov    0x8(%ebp),%eax
    ef72:	89 04 24             	mov    %eax,(%esp)
    ef75:	e8 79 fd ff ff       	call   ecf3 <heapify>
	assert(!heap_verify(h));
}
    ef7a:	c9                   	leave  
    ef7b:	c3                   	ret    

0000ef7c <heap_remove>:

void *
heap_remove(struct heap *h, int c)
{
    ef7c:	55                   	push   %ebp
    ef7d:	89 e5                	mov    %esp,%ebp
    ef7f:	83 ec 28             	sub    $0x28,%esp
	void *r;

	assert(c < h->e);
    ef82:	8b 45 08             	mov    0x8(%ebp),%eax
    ef85:	8b 00                	mov    (%eax),%eax
    ef87:	3b 45 0c             	cmp    0xc(%ebp),%eax
    ef8a:	0f 9e c0             	setle  %al
    ef8d:	0f b6 c0             	movzbl %al,%eax
    ef90:	85 c0                	test   %eax,%eax
    ef92:	74 1c                	je     efb0 <heap_remove+0x34>
    ef94:	c7 04 24 5c 26 00 00 	movl   $0x265c,(%esp)
    ef9b:	e8 7a f9 ff ff       	call   e91a <prints>
    efa0:	a1 98 02 00 00       	mov    0x298,%eax
    efa5:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    efab:	e8 f1 f9 ff ff       	call   e9a1 <__cos_noret>
	assert(c >= 1);
    efb0:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    efb4:	0f 9e c0             	setle  %al
    efb7:	0f b6 c0             	movzbl %al,%eax
    efba:	85 c0                	test   %eax,%eax
    efbc:	74 1c                	je     efda <heap_remove+0x5e>
    efbe:	c7 04 24 84 26 00 00 	movl   $0x2684,(%esp)
    efc5:	e8 50 f9 ff ff       	call   e91a <prints>
    efca:	a1 98 02 00 00       	mov    0x298,%eax
    efcf:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    efd5:	e8 c7 f9 ff ff       	call   e9a1 <__cos_noret>
	if (h->e == 1) return NULL;
    efda:	8b 45 08             	mov    0x8(%ebp),%eax
    efdd:	8b 00                	mov    (%eax),%eax
    efdf:	83 f8 01             	cmp    $0x1,%eax
    efe2:	75 0a                	jne    efee <heap_remove+0x72>
    efe4:	b8 00 00 00 00       	mov    $0x0,%eax
    efe9:	e9 9e 00 00 00       	jmp    f08c <heap_remove+0x110>

	assert(!heap_verify(h));
	r = h->data[c];
    efee:	8b 45 08             	mov    0x8(%ebp),%eax
    eff1:	8b 40 10             	mov    0x10(%eax),%eax
    eff4:	8b 55 0c             	mov    0xc(%ebp),%edx
    eff7:	c1 e2 02             	shl    $0x2,%edx
    effa:	01 d0                	add    %edx,%eax
    effc:	8b 00                	mov    (%eax),%eax
    effe:	89 45 f4             	mov    %eax,-0xc(%ebp)
	debug("heap_remove(%p,%d) %p@%d\n", h, h->e, h->data[c], c);
	h->e--;
    f001:	8b 45 08             	mov    0x8(%ebp),%eax
    f004:	8b 00                	mov    (%eax),%eax
    f006:	8d 50 ff             	lea    -0x1(%eax),%edx
    f009:	8b 45 08             	mov    0x8(%ebp),%eax
    f00c:	89 10                	mov    %edx,(%eax)
	h->u(r, 0);
    f00e:	8b 45 08             	mov    0x8(%ebp),%eax
    f011:	8b 40 0c             	mov    0xc(%eax),%eax
    f014:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    f01b:	00 
    f01c:	8b 55 f4             	mov    -0xc(%ebp),%edx
    f01f:	89 14 24             	mov    %edx,(%esp)
    f022:	ff d0                	call   *%eax

	if (c == h->e) {
    f024:	8b 45 08             	mov    0x8(%ebp),%eax
    f027:	8b 00                	mov    (%eax),%eax
    f029:	3b 45 0c             	cmp    0xc(%ebp),%eax
    f02c:	75 05                	jne    f033 <heap_remove+0xb7>
		assert(!heap_verify(h));
		return r;
    f02e:	8b 45 f4             	mov    -0xc(%ebp),%eax
    f031:	eb 59                	jmp    f08c <heap_remove+0x110>
	}
	h->data[c] = h->data[h->e];
    f033:	8b 45 08             	mov    0x8(%ebp),%eax
    f036:	8b 40 10             	mov    0x10(%eax),%eax
    f039:	8b 55 0c             	mov    0xc(%ebp),%edx
    f03c:	c1 e2 02             	shl    $0x2,%edx
    f03f:	01 c2                	add    %eax,%edx
    f041:	8b 45 08             	mov    0x8(%ebp),%eax
    f044:	8b 48 10             	mov    0x10(%eax),%ecx
    f047:	8b 45 08             	mov    0x8(%ebp),%eax
    f04a:	8b 00                	mov    (%eax),%eax
    f04c:	c1 e0 02             	shl    $0x2,%eax
    f04f:	01 c8                	add    %ecx,%eax
    f051:	8b 00                	mov    (%eax),%eax
    f053:	89 02                	mov    %eax,(%edx)
	h->u(h->data[c], c);
    f055:	8b 45 08             	mov    0x8(%ebp),%eax
    f058:	8b 40 0c             	mov    0xc(%eax),%eax
    f05b:	8b 55 08             	mov    0x8(%ebp),%edx
    f05e:	8b 52 10             	mov    0x10(%edx),%edx
    f061:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    f064:	c1 e1 02             	shl    $0x2,%ecx
    f067:	01 ca                	add    %ecx,%edx
    f069:	8b 12                	mov    (%edx),%edx
    f06b:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    f06e:	89 4c 24 04          	mov    %ecx,0x4(%esp)
    f072:	89 14 24             	mov    %edx,(%esp)
    f075:	ff d0                	call   *%eax
	heap_adjust(h, c);
    f077:	8b 45 0c             	mov    0xc(%ebp),%eax
    f07a:	89 44 24 04          	mov    %eax,0x4(%esp)
    f07e:	8b 45 08             	mov    0x8(%ebp),%eax
    f081:	89 04 24             	mov    %eax,(%esp)
    f084:	e8 fc ff ff ff       	call   f085 <heap_remove+0x109>
	assert(!heap_verify(h));

	return r;
    f089:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    f08c:	c9                   	leave  
    f08d:	c3                   	ret    

0000f08e <heap_size>:

int
heap_size(struct heap *h)
{
    f08e:	55                   	push   %ebp
    f08f:	89 e5                	mov    %esp,%ebp
	return h->e - 1;
    f091:	8b 45 08             	mov    0x8(%ebp),%eax
    f094:	8b 00                	mov    (%eax),%eax
    f096:	83 e8 01             	sub    $0x1,%eax
}
    f099:	5d                   	pop    %ebp
    f09a:	c3                   	ret    
    f09b:	66 90                	xchg   %ax,%ax
    f09d:	66 90                	xchg   %ax,%ax
    f09f:	90                   	nop

0000f0a0 <ps_list_ll_empty>:
ps_list_head_init(struct ps_list_head *lh)
{ ps_list_ll_init(&lh->l); }

static inline int
ps_list_ll_empty(struct ps_list *l)
{ return l->n == l; }
    f0a0:	55                   	push   %ebp
    f0a1:	89 e5                	mov    %esp,%ebp
    f0a3:	8b 45 08             	mov    0x8(%ebp),%eax
    f0a6:	8b 00                	mov    (%eax),%eax
    f0a8:	3b 45 08             	cmp    0x8(%ebp),%eax
    f0ab:	0f 94 c0             	sete   %al
    f0ae:	0f b6 c0             	movzbl %al,%eax
    f0b1:	5d                   	pop    %ebp
    f0b2:	c3                   	ret    

0000f0b3 <ps_list_ll_add>:
ps_list_head_empty(struct ps_list_head *lh)
{ return ps_list_ll_empty(&lh->l); }

static inline void
ps_list_ll_add(struct ps_list *l, struct ps_list *new)
{
    f0b3:	55                   	push   %ebp
    f0b4:	89 e5                	mov    %esp,%ebp
	new->n    = l->n;
    f0b6:	8b 45 08             	mov    0x8(%ebp),%eax
    f0b9:	8b 10                	mov    (%eax),%edx
    f0bb:	8b 45 0c             	mov    0xc(%ebp),%eax
    f0be:	89 10                	mov    %edx,(%eax)
	new->p    = l;
    f0c0:	8b 45 0c             	mov    0xc(%ebp),%eax
    f0c3:	8b 55 08             	mov    0x8(%ebp),%edx
    f0c6:	89 50 04             	mov    %edx,0x4(%eax)
	l->n      = new;
    f0c9:	8b 45 08             	mov    0x8(%ebp),%eax
    f0cc:	8b 55 0c             	mov    0xc(%ebp),%edx
    f0cf:	89 10                	mov    %edx,(%eax)
	new->n->p = new;
    f0d1:	8b 45 0c             	mov    0xc(%ebp),%eax
    f0d4:	8b 00                	mov    (%eax),%eax
    f0d6:	8b 55 0c             	mov    0xc(%ebp),%edx
    f0d9:	89 50 04             	mov    %edx,0x4(%eax)
}
    f0dc:	5d                   	pop    %ebp
    f0dd:	c3                   	ret    

0000f0de <ps_list_ll_rem>:

static inline void
ps_list_ll_rem(struct ps_list *l)
{
    f0de:	55                   	push   %ebp
    f0df:	89 e5                	mov    %esp,%ebp
	l->n->p = l->p;
    f0e1:	8b 45 08             	mov    0x8(%ebp),%eax
    f0e4:	8b 00                	mov    (%eax),%eax
    f0e6:	8b 55 08             	mov    0x8(%ebp),%edx
    f0e9:	8b 52 04             	mov    0x4(%edx),%edx
    f0ec:	89 50 04             	mov    %edx,0x4(%eax)
	l->p->n = l->n;
    f0ef:	8b 45 08             	mov    0x8(%ebp),%eax
    f0f2:	8b 40 04             	mov    0x4(%eax),%eax
    f0f5:	8b 55 08             	mov    0x8(%ebp),%edx
    f0f8:	8b 12                	mov    (%edx),%edx
    f0fa:	89 10                	mov    %edx,(%eax)
	l->p = l->n = l;
    f0fc:	8b 45 08             	mov    0x8(%ebp),%eax
    f0ff:	8b 55 08             	mov    0x8(%ebp),%edx
    f102:	89 10                	mov    %edx,(%eax)
    f104:	8b 45 08             	mov    0x8(%ebp),%eax
    f107:	8b 10                	mov    (%eax),%edx
    f109:	8b 45 08             	mov    0x8(%ebp),%eax
    f10c:	89 50 04             	mov    %edx,0x4(%eax)
}
    f10f:	5d                   	pop    %ebp
    f110:	c3                   	ret    

0000f111 <ps_cas>:
 * 0 on failure due to contention (*target != old)
 * 1 otherwise (*target == old -> *target = updated)
 */
static inline int
ps_cas(unsigned long *target, unsigned long old, unsigned long updated)
{
    f111:	55                   	push   %ebp
    f112:	89 e5                	mov    %esp,%ebp
    f114:	53                   	push   %ebx
    f115:	83 ec 10             	sub    $0x10,%esp
        char z;
        __asm__ __volatile__("lock " PS_CAS_STR
    f118:	8b 55 08             	mov    0x8(%ebp),%edx
    f11b:	8b 4d 10             	mov    0x10(%ebp),%ecx
    f11e:	8b 45 0c             	mov    0xc(%ebp),%eax
    f121:	8b 5d 08             	mov    0x8(%ebp),%ebx
    f124:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
    f128:	0f 94 c0             	sete   %al
    f12b:	88 45 fb             	mov    %al,-0x5(%ebp)
                             : "+m" (*target), "=a" (z)
                             : "q"  (updated), "a"  (old)
                             : "memory", "cc");
        return (int)z;
    f12e:	0f be 45 fb          	movsbl -0x5(%ebp),%eax
}
    f132:	83 c4 10             	add    $0x10,%esp
    f135:	5b                   	pop    %ebx
    f136:	5d                   	pop    %ebp
    f137:	c3                   	ret    

0000f138 <__bitmap_check>:
	return x | (1 << v);
}

static inline int
__bitmap_check(u32_t x, int v)
{
    f138:	55                   	push   %ebp
    f139:	89 e5                	mov    %esp,%ebp
	return x & (1 << v);
    f13b:	8b 45 0c             	mov    0xc(%ebp),%eax
    f13e:	ba 01 00 00 00       	mov    $0x1,%edx
    f143:	89 c1                	mov    %eax,%ecx
    f145:	d3 e2                	shl    %cl,%edx
    f147:	89 d0                	mov    %edx,%eax
    f149:	23 45 08             	and    0x8(%ebp),%eax
}
    f14c:	5d                   	pop    %ebp
    f14d:	c3                   	ret    

0000f14e <bitmap_check>:
	x[idx] = __bitmap_set(x[idx], off);
}

static inline int
bitmap_check(u32_t *x, int v)
{
    f14e:	55                   	push   %ebp
    f14f:	89 e5                	mov    %esp,%ebp
    f151:	83 ec 18             	sub    $0x18,%esp
	int idx, off;
	idx = v / WORD_SIZE; /* WORD_SIZE = sizeof(u32_t) */
    f154:	8b 45 0c             	mov    0xc(%ebp),%eax
    f157:	8d 50 1f             	lea    0x1f(%eax),%edx
    f15a:	85 c0                	test   %eax,%eax
    f15c:	0f 48 c2             	cmovs  %edx,%eax
    f15f:	c1 f8 05             	sar    $0x5,%eax
    f162:	89 45 fc             	mov    %eax,-0x4(%ebp)
	off = v & (WORD_SIZE - 1);
    f165:	8b 45 0c             	mov    0xc(%ebp),%eax
    f168:	83 e0 1f             	and    $0x1f,%eax
    f16b:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return __bitmap_check(x[idx], off);
    f16e:	8b 45 fc             	mov    -0x4(%ebp),%eax
    f171:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    f178:	8b 45 08             	mov    0x8(%ebp),%eax
    f17b:	01 d0                	add    %edx,%eax
    f17d:	8b 00                	mov    (%eax),%eax
    f17f:	8b 55 f8             	mov    -0x8(%ebp),%edx
    f182:	89 54 24 04          	mov    %edx,0x4(%esp)
    f186:	89 04 24             	mov    %eax,(%esp)
    f189:	e8 aa ff ff ff       	call   f138 <__bitmap_check>
}
    f18e:	c9                   	leave  
    f18f:	c3                   	ret    

0000f190 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
    f190:	55                   	push   %ebp
    f191:	89 e5                	mov    %esp,%ebp
    f193:	57                   	push   %edi
    f194:	56                   	push   %esi
    f195:	53                   	push   %ebx
    f196:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
    f199:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
    f1a0:	8b 45 08             	mov    0x8(%ebp),%eax
    f1a3:	83 c0 01             	add    $0x1,%eax
    f1a6:	c1 e0 10             	shl    $0x10,%eax
    f1a9:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
    f1ac:	8b 45 0c             	mov    0xc(%ebp),%eax
    f1af:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
    f1b2:	8b 45 08             	mov    0x8(%ebp),%eax
    f1b5:	8b 4d 10             	mov    0x10(%ebp),%ecx
    f1b8:	8b 75 14             	mov    0x14(%ebp),%esi
    f1bb:	8b 7d 18             	mov    0x18(%ebp),%edi
    f1be:	8b 55 1c             	mov    0x1c(%ebp),%edx
    f1c1:	89 cb                	mov    %ecx,%ebx
    f1c3:	55                   	push   %ebp
    f1c4:	89 e5                	mov    %esp,%ebp
    f1c6:	b9 d8 f1 00 00       	mov    $0xf1d8,%ecx
    f1cb:	0f 34                	sysenter 
    f1cd:	8d 76 00             	lea    0x0(%esi),%esi
    f1d0:	eb 0d                	jmp    f1df <call_cap_asm+0x4f>
    f1d2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
    f1d8:	b9 00 00 00 00       	mov    $0x0,%ecx
    f1dd:	eb 05                	jmp    f1e4 <call_cap_asm+0x54>
    f1df:	b9 01 00 00 00       	mov    $0x1,%ecx
    f1e4:	5d                   	pop    %ebp
    f1e5:	89 ca                	mov    %ecx,%edx
    f1e7:	89 45 ec             	mov    %eax,-0x14(%ebp)
    f1ea:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
    f1ed:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
    f1f0:	83 c4 10             	add    $0x10,%esp
    f1f3:	5b                   	pop    %ebx
    f1f4:	5e                   	pop    %esi
    f1f5:	5f                   	pop    %edi
    f1f6:	5d                   	pop    %ebp
    f1f7:	c3                   	ret    

0000f1f8 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
    f1f8:	55                   	push   %ebp
    f1f9:	89 e5                	mov    %esp,%ebp
    f1fb:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
    f1fe:	8b 45 18             	mov    0x18(%ebp),%eax
    f201:	89 44 24 14          	mov    %eax,0x14(%esp)
    f205:	8b 45 14             	mov    0x14(%ebp),%eax
    f208:	89 44 24 10          	mov    %eax,0x10(%esp)
    f20c:	8b 45 10             	mov    0x10(%ebp),%eax
    f20f:	89 44 24 0c          	mov    %eax,0xc(%esp)
    f213:	8b 45 0c             	mov    0xc(%ebp),%eax
    f216:	89 44 24 08          	mov    %eax,0x8(%esp)
    f21a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
    f221:	00 
    f222:	8b 45 08             	mov    0x8(%ebp),%eax
    f225:	89 04 24             	mov    %eax,(%esp)
    f228:	e8 63 ff ff ff       	call   f190 <call_cap_asm>
}
    f22d:	c9                   	leave  
    f22e:	c3                   	ret    

0000f22f <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
    f22f:	55                   	push   %ebp
    f230:	89 e5                	mov    %esp,%ebp
    f232:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
    f235:	8b 45 08             	mov    0x8(%ebp),%eax
    f238:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
    f23f:	00 
    f240:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
    f247:	00 
    f248:	8b 55 0c             	mov    0xc(%ebp),%edx
    f24b:	89 54 24 08          	mov    %edx,0x8(%esp)
    f24f:	89 44 24 04          	mov    %eax,0x4(%esp)
    f253:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    f25a:	e8 99 ff ff ff       	call   f1f8 <call_cap>
}
    f25f:	c9                   	leave  
    f260:	c3                   	ret    

0000f261 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
    f261:	55                   	push   %ebp
    f262:	89 e5                	mov    %esp,%ebp
    f264:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
    f267:	89 e0                	mov    %esp,%eax
    f269:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
    f26c:	8b 45 fc             	mov    -0x4(%ebp),%eax
    f26f:	25 00 f0 ff ff       	and    $0xfffff000,%eax
    f274:	89 c2                	mov    %eax,%edx
    f276:	8b 45 08             	mov    0x8(%ebp),%eax
    f279:	c1 e0 02             	shl    $0x2,%eax
    f27c:	29 c2                	sub    %eax,%edx
    f27e:	89 d0                	mov    %edx,%eax
    f280:	05 00 10 00 00       	add    $0x1000,%eax
    f285:	8b 00                	mov    (%eax),%eax
}
    f287:	c9                   	leave  
    f288:	c3                   	ret    

0000f289 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
    f289:	55                   	push   %ebp
    f28a:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
    f28c:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
    f291:	5d                   	pop    %ebp
    f292:	c3                   	ret    

0000f293 <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
    f293:	55                   	push   %ebp
    f294:	89 e5                	mov    %esp,%ebp
    f296:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
    f299:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
    f2a0:	e8 bc ff ff ff       	call   f261 <get_stk_data>
}
    f2a5:	c9                   	leave  
    f2a6:	c3                   	ret    

0000f2a7 <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
    f2a7:	55                   	push   %ebp
    f2a8:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
    f2aa:	e8 e4 ff ff ff       	call   f293 <cos_get_thd_id>
}
    f2af:	5d                   	pop    %ebp
    f2b0:	c3                   	ret    

0000f2b1 <cos_spd_id>:
		goto label;      \
	} while (0)

static inline long
cos_spd_id(void)
{
    f2b1:	55                   	push   %ebp
    f2b2:	89 e5                	mov    %esp,%ebp
	return cos_comp_info.cos_this_spd_id;
    f2b4:	a1 40 00 00 00       	mov    0x40,%eax
}
    f2b9:	5d                   	pop    %ebp
    f2ba:	c3                   	ret    

0000f2bb <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
    f2bb:	55                   	push   %ebp
    f2bc:	89 e5                	mov    %esp,%ebp
    f2be:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
    f2c1:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
    f2c8:	eb 20                	jmp    f2ea <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
    f2ca:	8b 45 f4             	mov    -0xc(%ebp),%eax
    f2cd:	83 c0 01             	add    $0x1,%eax
    f2d0:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
    f2d7:	8b 45 08             	mov    0x8(%ebp),%eax
    f2da:	01 d0                	add    %edx,%eax
    f2dc:	8b 00                	mov    (%eax),%eax
    f2de:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
    f2e1:	8b 45 f0             	mov    -0x10(%ebp),%eax
    f2e4:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
    f2e6:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    f2ea:	8b 45 08             	mov    0x8(%ebp),%eax
    f2ed:	8b 00                	mov    (%eax),%eax
    f2ef:	3b 45 f4             	cmp    -0xc(%ebp),%eax
    f2f2:	7f d6                	jg     f2ca <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
    f2f4:	c9                   	leave  
    f2f5:	c3                   	ret    

0000f2f6 <constructors_execute>:

static void
constructors_execute(void)
{
    f2f6:	55                   	push   %ebp
    f2f7:	89 e5                	mov    %esp,%ebp
    f2f9:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
    f2fc:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    f303:	e8 b3 ff ff ff       	call   f2bb <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
    f308:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    f30f:	e8 a7 ff ff ff       	call   f2bb <section_fnptrs_execute>
}
    f314:	c9                   	leave  
    f315:	c3                   	ret    

0000f316 <destructors_execute>:
static void
destructors_execute(void)
{
    f316:	55                   	push   %ebp
    f317:	89 e5                	mov    %esp,%ebp
    f319:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
    f31c:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    f323:	e8 93 ff ff ff       	call   f2bb <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
    f328:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    f32f:	e8 87 ff ff ff       	call   f2bb <section_fnptrs_execute>
}
    f334:	c9                   	leave  
    f335:	c3                   	ret    

0000f336 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
    f336:	55                   	push   %ebp
    f337:	89 e5                	mov    %esp,%ebp
    f339:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
    f33c:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
    f343:	e8 73 ff ff ff       	call   f2bb <section_fnptrs_execute>
}
    f348:	c9                   	leave  
    f349:	c3                   	ret    

0000f34a <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
    f34a:	55                   	push   %ebp
    f34b:	89 e5                	mov    %esp,%ebp
    f34d:	83 ec 08             	sub    $0x8,%esp
    f350:	8b 55 08             	mov    0x8(%ebp),%edx
    f353:	8b 45 0c             	mov    0xc(%ebp),%eax
    f356:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
    f35a:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
    f35d:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    f361:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
    f365:	ee                   	out    %al,(%dx)
}
    f366:	c9                   	leave  
    f367:	c3                   	ret    

0000f368 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
    f368:	55                   	push   %ebp
    f369:	89 e5                	mov    %esp,%ebp
    f36b:	83 ec 14             	sub    $0x14,%esp
    f36e:	8b 45 08             	mov    0x8(%ebp),%eax
    f371:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
    f375:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
    f379:	89 c2                	mov    %eax,%edx
    f37b:	ec                   	in     (%dx),%al
    f37c:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
    f37f:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
    f383:	c9                   	leave  
    f384:	c3                   	ret    

0000f385 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
    f385:	55                   	push   %ebp
    f386:	89 e5                	mov    %esp,%ebp
    f388:	83 ec 0c             	sub    $0xc,%esp
    f38b:	8b 45 08             	mov    0x8(%ebp),%eax
    f38e:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
    f391:	90                   	nop
    f392:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
    f399:	e8 ca ff ff ff       	call   f368 <inb>
    f39e:	0f b6 c0             	movzbl %al,%eax
    f3a1:	83 e0 20             	and    $0x20,%eax
    f3a4:	85 c0                	test   %eax,%eax
    f3a6:	74 ea                	je     f392 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
    f3a8:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f3ac:	0f b6 c0             	movzbl %al,%eax
    f3af:	89 44 24 04          	mov    %eax,0x4(%esp)
    f3b3:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
    f3ba:	e8 8b ff ff ff       	call   f34a <outb>
}
    f3bf:	c9                   	leave  
    f3c0:	c3                   	ret    

0000f3c1 <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
    f3c1:	55                   	push   %ebp
    f3c2:	89 e5                	mov    %esp,%ebp
    f3c4:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
    f3c7:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
    f3ce:	eb 1a                	jmp    f3ea <cos_serial_putb+0x29>
    f3d0:	8b 45 fc             	mov    -0x4(%ebp),%eax
    f3d3:	8b 55 08             	mov    0x8(%ebp),%edx
    f3d6:	01 d0                	add    %edx,%eax
    f3d8:	0f b6 00             	movzbl (%eax),%eax
    f3db:	0f be c0             	movsbl %al,%eax
    f3de:	89 04 24             	mov    %eax,(%esp)
    f3e1:	e8 9f ff ff ff       	call   f385 <cos_serial_putc>
    f3e6:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
    f3ea:	8b 45 fc             	mov    -0x4(%ebp),%eax
    f3ed:	3b 45 0c             	cmp    0xc(%ebp),%eax
    f3f0:	72 de                	jb     f3d0 <cos_serial_putb+0xf>
}
    f3f2:	c9                   	leave  
    f3f3:	c3                   	ret    

0000f3f4 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
    f3f4:	55                   	push   %ebp
    f3f5:	89 e5                	mov    %esp,%ebp
    f3f7:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
    f3fa:	8b 45 0c             	mov    0xc(%ebp),%eax
    f3fd:	89 44 24 04          	mov    %eax,0x4(%esp)
    f401:	8b 45 08             	mov    0x8(%ebp),%eax
    f404:	89 04 24             	mov    %eax,(%esp)
    f407:	e8 b5 ff ff ff       	call   f3c1 <cos_serial_putb>
}
    f40c:	c9                   	leave  
    f40d:	c3                   	ret    

0000f40e <prints>:

static int
prints(char *s)
{
    f40e:	55                   	push   %ebp
    f40f:	89 e5                	mov    %esp,%ebp
    f411:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
    f414:	8b 45 08             	mov    0x8(%ebp),%eax
    f417:	89 04 24             	mov    %eax,(%esp)
    f41a:	e8 fc ff ff ff       	call   f41b <prints+0xd>
    f41f:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
    f422:	8b 45 f4             	mov    -0xc(%ebp),%eax
    f425:	89 44 24 04          	mov    %eax,0x4(%esp)
    f429:	8b 45 08             	mov    0x8(%ebp),%eax
    f42c:	89 04 24             	mov    %eax,(%esp)
    f42f:	e8 fb fd ff ff       	call   f22f <cos_print>

	return len;
    f434:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
    f437:	c9                   	leave  
    f438:	c3                   	ret    

0000f439 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
    f439:	55                   	push   %ebp
    f43a:	89 e5                	mov    %esp,%ebp
    f43c:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
    f442:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
    f449:	8d 45 0c             	lea    0xc(%ebp),%eax
    f44c:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
    f452:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
    f458:	89 44 24 0c          	mov    %eax,0xc(%esp)
    f45c:	8b 45 08             	mov    0x8(%ebp),%eax
    f45f:	89 44 24 08          	mov    %eax,0x8(%esp)
    f463:	8b 45 f4             	mov    -0xc(%ebp),%eax
    f466:	89 44 24 04          	mov    %eax,0x4(%esp)
    f46a:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    f470:	89 04 24             	mov    %eax,(%esp)
    f473:	e8 fc ff ff ff       	call   f474 <printc+0x3b>
    f478:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
    f47b:	8b 45 f0             	mov    -0x10(%ebp),%eax
    f47e:	89 44 24 04          	mov    %eax,0x4(%esp)
    f482:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
    f488:	89 04 24             	mov    %eax,(%esp)
    f48b:	e8 64 ff ff ff       	call   f3f4 <cos_llprint>

	return ret;
    f490:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
    f493:	c9                   	leave  
    f494:	c3                   	ret    

0000f495 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
    f495:	55                   	push   %ebp
    f496:	89 e5                	mov    %esp,%ebp
	while (1)
		;
    f498:	eb fe                	jmp    f498 <__cos_noret+0x3>

0000f49a <__slab_freelist_rem>:
static inline void __ps_slab_freelist_check(struct ps_slab_freelist *fl) { (void)fl; }
#endif /* PS_SLAB_DEBUG */

static void
__slab_freelist_rem(struct ps_slab_freelist *fl, struct ps_slab *s)
{
    f49a:	55                   	push   %ebp
    f49b:	89 e5                	mov    %esp,%ebp
    f49d:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
    f4a0:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    f4a4:	0f 94 c0             	sete   %al
    f4a7:	0f b6 c0             	movzbl %al,%eax
    f4aa:	85 c0                	test   %eax,%eax
    f4ac:	75 0e                	jne    f4bc <__slab_freelist_rem+0x22>
    f4ae:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    f4b2:	0f 94 c0             	sete   %al
    f4b5:	0f b6 c0             	movzbl %al,%eax
    f4b8:	85 c0                	test   %eax,%eax
    f4ba:	74 1c                	je     f4d8 <__slab_freelist_rem+0x3e>
    f4bc:	c7 04 24 ac 26 00 00 	movl   $0x26ac,(%esp)
    f4c3:	e8 46 ff ff ff       	call   f40e <prints>
    f4c8:	a1 9c 02 00 00       	mov    0x29c,%eax
    f4cd:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    f4d3:	e8 bd ff ff ff       	call   f495 <__cos_noret>
	if (fl->list == s) {
    f4d8:	8b 45 08             	mov    0x8(%ebp),%eax
    f4db:	8b 00                	mov    (%eax),%eax
    f4dd:	3b 45 0c             	cmp    0xc(%ebp),%eax
    f4e0:	75 2b                	jne    f50d <__slab_freelist_rem+0x73>
		if (ps_list_singleton(s, list)) fl->list = NULL;
    f4e2:	8b 45 0c             	mov    0xc(%ebp),%eax
    f4e5:	83 c0 44             	add    $0x44,%eax
    f4e8:	89 04 24             	mov    %eax,(%esp)
    f4eb:	e8 b0 fb ff ff       	call   f0a0 <ps_list_ll_empty>
    f4f0:	85 c0                	test   %eax,%eax
    f4f2:	74 0b                	je     f4ff <__slab_freelist_rem+0x65>
    f4f4:	8b 45 08             	mov    0x8(%ebp),%eax
    f4f7:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    f4fd:	eb 0e                	jmp    f50d <__slab_freelist_rem+0x73>
		else                            fl->list = ps_list_next(s, list);
    f4ff:	8b 45 0c             	mov    0xc(%ebp),%eax
    f502:	8b 40 44             	mov    0x44(%eax),%eax
    f505:	8d 50 bc             	lea    -0x44(%eax),%edx
    f508:	8b 45 08             	mov    0x8(%ebp),%eax
    f50b:	89 10                	mov    %edx,(%eax)
	}
	ps_list_rem(s, list);
    f50d:	8b 45 0c             	mov    0xc(%ebp),%eax
    f510:	83 c0 44             	add    $0x44,%eax
    f513:	89 04 24             	mov    %eax,(%esp)
    f516:	e8 c3 fb ff ff       	call   f0de <ps_list_ll_rem>
}
    f51b:	c9                   	leave  
    f51c:	c3                   	ret    

0000f51d <__slab_freelist_add>:

static void
__slab_freelist_add(struct ps_slab_freelist *fl, struct ps_slab *s)
{
    f51d:	55                   	push   %ebp
    f51e:	89 e5                	mov    %esp,%ebp
    f520:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
    f523:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
    f527:	0f 94 c0             	sete   %al
    f52a:	0f b6 c0             	movzbl %al,%eax
    f52d:	85 c0                	test   %eax,%eax
    f52f:	75 0e                	jne    f53f <__slab_freelist_add+0x22>
    f531:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
    f535:	0f 94 c0             	sete   %al
    f538:	0f b6 c0             	movzbl %al,%eax
    f53b:	85 c0                	test   %eax,%eax
    f53d:	74 1c                	je     f55b <__slab_freelist_add+0x3e>
    f53f:	c7 04 24 04 27 00 00 	movl   $0x2704,(%esp)
    f546:	e8 c3 fe ff ff       	call   f40e <prints>
    f54b:	a1 9c 02 00 00       	mov    0x29c,%eax
    f550:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    f556:	e8 3a ff ff ff       	call   f495 <__cos_noret>
	assert(ps_list_singleton(s, list));
    f55b:	8b 45 0c             	mov    0xc(%ebp),%eax
    f55e:	83 c0 44             	add    $0x44,%eax
    f561:	89 04 24             	mov    %eax,(%esp)
    f564:	e8 37 fb ff ff       	call   f0a0 <ps_list_ll_empty>
    f569:	85 c0                	test   %eax,%eax
    f56b:	0f 94 c0             	sete   %al
    f56e:	0f b6 c0             	movzbl %al,%eax
    f571:	85 c0                	test   %eax,%eax
    f573:	74 1c                	je     f591 <__slab_freelist_add+0x74>
    f575:	c7 04 24 5c 27 00 00 	movl   $0x275c,(%esp)
    f57c:	e8 8d fe ff ff       	call   f40e <prints>
    f581:	a1 9c 02 00 00       	mov    0x29c,%eax
    f586:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    f58c:	e8 04 ff ff ff       	call   f495 <__cos_noret>
	assert(s != fl->list);
    f591:	8b 45 08             	mov    0x8(%ebp),%eax
    f594:	8b 00                	mov    (%eax),%eax
    f596:	3b 45 0c             	cmp    0xc(%ebp),%eax
    f599:	0f 94 c0             	sete   %al
    f59c:	0f b6 c0             	movzbl %al,%eax
    f59f:	85 c0                	test   %eax,%eax
    f5a1:	74 1c                	je     f5bf <__slab_freelist_add+0xa2>
    f5a3:	c7 04 24 b4 27 00 00 	movl   $0x27b4,(%esp)
    f5aa:	e8 5f fe ff ff       	call   f40e <prints>
    f5af:	a1 9c 02 00 00       	mov    0x29c,%eax
    f5b4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
    f5ba:	e8 d6 fe ff ff       	call   f495 <__cos_noret>
	if (fl->list) ps_list_add(fl->list, s, list);
    f5bf:	8b 45 08             	mov    0x8(%ebp),%eax
    f5c2:	8b 00                	mov    (%eax),%eax
    f5c4:	85 c0                	test   %eax,%eax
    f5c6:	74 1a                	je     f5e2 <__slab_freelist_add+0xc5>
    f5c8:	8b 45 0c             	mov    0xc(%ebp),%eax
    f5cb:	8d 50 44             	lea    0x44(%eax),%edx
    f5ce:	8b 45 08             	mov    0x8(%ebp),%eax
    f5d1:	8b 00                	mov    (%eax),%eax
    f5d3:	83 c0 44             	add    $0x44,%eax
    f5d6:	89 54 24 04          	mov    %edx,0x4(%esp)
    f5da:	89 04 24             	mov    %eax,(%esp)
    f5dd:	e8 d1 fa ff ff       	call   f0b3 <ps_list_ll_add>
	fl->list = s;
    f5e2:	8b 45 08             	mov    0x8(%ebp),%eax
    f5e5:	8b 55 0c             	mov    0xc(%ebp),%edx
    f5e8:	89 10                	mov    %edx,(%eax)
	/* TODO: sort based on emptiness...just use N bins */
}
    f5ea:	c9                   	leave  
    f5eb:	c3                   	ret    

0000f5ec <ck_cc_ffs>:
 */
#ifndef CK_MD_CC_BUILTIN_DISABLE
#define CK_F_CC_FFS
CK_CC_INLINE static int
ck_cc_ffs(unsigned int x)
{
    f5ec:	55                   	push   %ebp
    f5ed:	89 e5                	mov    %esp,%ebp

	return __builtin_ffsl(x);
    f5ef:	8b 45 08             	mov    0x8(%ebp),%eax
    f5f2:	ba ff ff ff ff       	mov    $0xffffffff,%edx
    f5f7:	0f bc c0             	bsf    %eax,%eax
    f5fa:	0f 44 c2             	cmove  %edx,%eax
    f5fd:	83 c0 01             	add    $0x1,%eax
}
    f600:	5d                   	pop    %ebp
    f601:	c3                   	ret    

0000f602 <ck_cc_ffsl>:

#define CK_F_CC_FFSL
CK_CC_INLINE static int
ck_cc_ffsl(unsigned long x)
{
    f602:	55                   	push   %ebp
    f603:	89 e5                	mov    %esp,%ebp
    f605:	83 ec 18             	sub    $0x18,%esp

	return __builtin_ffsll(x);
    f608:	8b 45 08             	mov    0x8(%ebp),%eax
    f60b:	ba 00 00 00 00       	mov    $0x0,%edx
    f610:	89 04 24             	mov    %eax,(%esp)
    f613:	89 54 24 04          	mov    %edx,0x4(%esp)
    f617:	e8 fc ff ff ff       	call   f618 <ck_cc_ffsl+0x16>
}
    f61c:	c9                   	leave  
    f61d:	c3                   	ret    

0000f61e <ck_cc_ctz>:

#define CK_F_CC_CTZ
CK_CC_INLINE static int
ck_cc_ctz(unsigned int x)
{
    f61e:	55                   	push   %ebp
    f61f:	89 e5                	mov    %esp,%ebp

	return __builtin_ctz(x);
    f621:	f3 0f bc 45 08       	tzcnt  0x8(%ebp),%eax
}
    f626:	5d                   	pop    %ebp
    f627:	c3                   	ret    

0000f628 <ck_cc_popcount>:

#define CK_F_CC_POPCOUNT
CK_CC_INLINE static int
ck_cc_popcount(unsigned int x)
{
    f628:	55                   	push   %ebp
    f629:	89 e5                	mov    %esp,%ebp
    f62b:	83 ec 18             	sub    $0x18,%esp

	return __builtin_popcount(x);
    f62e:	8b 45 08             	mov    0x8(%ebp),%eax
    f631:	89 04 24             	mov    %eax,(%esp)
    f634:	e8 fc ff ff ff       	call   f635 <ck_cc_popcount+0xd>
}
    f639:	c9                   	leave  
    f63a:	c3                   	ret    

0000f63b <ck_cc_ffsll>:
    f63b:	55                   	push   %ebp
    f63c:	89 e5                	mov    %esp,%ebp
    f63e:	53                   	push   %ebx
    f63f:	83 ec 1c             	sub    $0x1c,%esp
    f642:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f645:	89 4d e0             	mov    %ecx,-0x20(%ebp)
    f648:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    f64b:	89 4d e4             	mov    %ecx,-0x1c(%ebp)
    f64e:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    f651:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
    f654:	09 d9                	or     %ebx,%ecx
    f656:	85 c9                	test   %ecx,%ecx
    f658:	75 07                	jne    f661 <ck_cc_ffsll+0x26>
    f65a:	b8 00 00 00 00       	mov    $0x0,%eax
    f65f:	eb 3a                	jmp    f69b <ck_cc_ffsll+0x60>
    f661:	c7 45 f4 01 00 00 00 	movl   $0x1,-0xc(%ebp)
    f668:	eb 16                	jmp    f680 <ck_cc_ffsll+0x45>
    f66a:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
    f66e:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    f671:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
    f674:	0f ac d9 01          	shrd   $0x1,%ebx,%ecx
    f678:	d1 eb                	shr    %ebx
    f67a:	89 4d e0             	mov    %ecx,-0x20(%ebp)
    f67d:	89 5d e4             	mov    %ebx,-0x1c(%ebp)
    f680:	8b 4d e0             	mov    -0x20(%ebp),%ecx
    f683:	83 e1 01             	and    $0x1,%ecx
    f686:	89 c8                	mov    %ecx,%eax
    f688:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
    f68b:	83 e1 00             	and    $0x0,%ecx
    f68e:	89 ca                	mov    %ecx,%edx
    f690:	89 d1                	mov    %edx,%ecx
    f692:	09 c1                	or     %eax,%ecx
    f694:	85 c9                	test   %ecx,%ecx
    f696:	74 d2                	je     f66a <ck_cc_ffsll+0x2f>
    f698:	8b 45 f4             	mov    -0xc(%ebp),%eax
    f69b:	83 c4 1c             	add    $0x1c,%esp
    f69e:	5b                   	pop    %ebx
    f69f:	5d                   	pop    %ebp
    f6a0:	c3                   	ret    

0000f6a1 <ck_pr_stall>:
 * Prevent speculative execution in busy-wait loops (P4 <=) or "predefined
 * delay".
 */
CK_CC_INLINE static void
ck_pr_stall(void)
{
    f6a1:	55                   	push   %ebp
    f6a2:	89 e5                	mov    %esp,%ebp
	__asm__ __volatile__("pause" ::: "memory");
    f6a4:	f3 90                	pause  
	return;
    f6a6:	90                   	nop
}
    f6a7:	5d                   	pop    %ebp
    f6a8:	c3                   	ret    

0000f6a9 <ck_pr_fence_strict_atomic>:
#define CK_MD_X86_SFENCE "sfence"
#define CK_MD_X86_LFENCE "lfence"
#define CK_MD_X86_MFENCE "mfence"
#endif /* !CK_MD_SSE_DISABLE */

CK_PR_FENCE(atomic, "")
    f6a9:	55                   	push   %ebp
    f6aa:	89 e5                	mov    %esp,%ebp
    f6ac:	90                   	nop
    f6ad:	5d                   	pop    %ebp
    f6ae:	c3                   	ret    

0000f6af <ck_pr_fence_strict_atomic_store>:
CK_PR_FENCE(atomic_store, "")
    f6af:	55                   	push   %ebp
    f6b0:	89 e5                	mov    %esp,%ebp
    f6b2:	90                   	nop
    f6b3:	5d                   	pop    %ebp
    f6b4:	c3                   	ret    

0000f6b5 <ck_pr_fence_strict_atomic_load>:
CK_PR_FENCE(atomic_load, "")
    f6b5:	55                   	push   %ebp
    f6b6:	89 e5                	mov    %esp,%ebp
    f6b8:	90                   	nop
    f6b9:	5d                   	pop    %ebp
    f6ba:	c3                   	ret    

0000f6bb <ck_pr_fence_strict_store_atomic>:
CK_PR_FENCE(store_atomic, "")
    f6bb:	55                   	push   %ebp
    f6bc:	89 e5                	mov    %esp,%ebp
    f6be:	90                   	nop
    f6bf:	5d                   	pop    %ebp
    f6c0:	c3                   	ret    

0000f6c1 <ck_pr_fence_strict_load_atomic>:
CK_PR_FENCE(load_atomic, "")
    f6c1:	55                   	push   %ebp
    f6c2:	89 e5                	mov    %esp,%ebp
    f6c4:	90                   	nop
    f6c5:	5d                   	pop    %ebp
    f6c6:	c3                   	ret    

0000f6c7 <ck_pr_fence_strict_load>:
CK_PR_FENCE(load, CK_MD_X86_LFENCE)
    f6c7:	55                   	push   %ebp
    f6c8:	89 e5                	mov    %esp,%ebp
    f6ca:	0f ae e8             	lfence 
    f6cd:	90                   	nop
    f6ce:	5d                   	pop    %ebp
    f6cf:	c3                   	ret    

0000f6d0 <ck_pr_fence_strict_load_store>:
CK_PR_FENCE(load_store, CK_MD_X86_MFENCE)
    f6d0:	55                   	push   %ebp
    f6d1:	89 e5                	mov    %esp,%ebp
    f6d3:	0f ae f0             	mfence 
    f6d6:	90                   	nop
    f6d7:	5d                   	pop    %ebp
    f6d8:	c3                   	ret    

0000f6d9 <ck_pr_fence_strict_store>:
CK_PR_FENCE(store, CK_MD_X86_SFENCE)
    f6d9:	55                   	push   %ebp
    f6da:	89 e5                	mov    %esp,%ebp
    f6dc:	0f ae f8             	sfence 
    f6df:	90                   	nop
    f6e0:	5d                   	pop    %ebp
    f6e1:	c3                   	ret    

0000f6e2 <ck_pr_fence_strict_store_load>:
CK_PR_FENCE(store_load, CK_MD_X86_MFENCE)
    f6e2:	55                   	push   %ebp
    f6e3:	89 e5                	mov    %esp,%ebp
    f6e5:	0f ae f0             	mfence 
    f6e8:	90                   	nop
    f6e9:	5d                   	pop    %ebp
    f6ea:	c3                   	ret    

0000f6eb <ck_pr_fence_strict_memory>:
CK_PR_FENCE(memory, CK_MD_X86_MFENCE)
    f6eb:	55                   	push   %ebp
    f6ec:	89 e5                	mov    %esp,%ebp
    f6ee:	0f ae f0             	mfence 
    f6f1:	90                   	nop
    f6f2:	5d                   	pop    %ebp
    f6f3:	c3                   	ret    

0000f6f4 <ck_pr_fence_strict_release>:
CK_PR_FENCE(release, CK_MD_X86_MFENCE)
    f6f4:	55                   	push   %ebp
    f6f5:	89 e5                	mov    %esp,%ebp
    f6f7:	0f ae f0             	mfence 
    f6fa:	90                   	nop
    f6fb:	5d                   	pop    %ebp
    f6fc:	c3                   	ret    

0000f6fd <ck_pr_fence_strict_acquire>:
CK_PR_FENCE(acquire, CK_MD_X86_MFENCE)
    f6fd:	55                   	push   %ebp
    f6fe:	89 e5                	mov    %esp,%ebp
    f700:	0f ae f0             	mfence 
    f703:	90                   	nop
    f704:	5d                   	pop    %ebp
    f705:	c3                   	ret    

0000f706 <ck_pr_fence_strict_acqrel>:
CK_PR_FENCE(acqrel, CK_MD_X86_MFENCE)
    f706:	55                   	push   %ebp
    f707:	89 e5                	mov    %esp,%ebp
    f709:	0f ae f0             	mfence 
    f70c:	90                   	nop
    f70d:	5d                   	pop    %ebp
    f70e:	c3                   	ret    

0000f70f <ck_pr_fence_strict_lock>:
CK_PR_FENCE(lock, CK_MD_X86_MFENCE)
    f70f:	55                   	push   %ebp
    f710:	89 e5                	mov    %esp,%ebp
    f712:	0f ae f0             	mfence 
    f715:	90                   	nop
    f716:	5d                   	pop    %ebp
    f717:	c3                   	ret    

0000f718 <ck_pr_fence_strict_unlock>:
CK_PR_FENCE(unlock, CK_MD_X86_MFENCE)
    f718:	55                   	push   %ebp
    f719:	89 e5                	mov    %esp,%ebp
    f71b:	0f ae f0             	mfence 
    f71e:	90                   	nop
    f71f:	5d                   	pop    %ebp
    f720:	c3                   	ret    

0000f721 <ck_pr_fas_ptr>:
					:			\
					: "memory");		\
		return v;					\
	}

CK_PR_FAS(ptr, void, void *, char, "xchgl")
    f721:	55                   	push   %ebp
    f722:	89 e5                	mov    %esp,%ebp
    f724:	8b 55 08             	mov    0x8(%ebp),%edx
    f727:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f72a:	8b 45 0c             	mov    0xc(%ebp),%eax
    f72d:	87 02                	xchg   %eax,(%edx)
    f72f:	89 45 0c             	mov    %eax,0xc(%ebp)
    f732:	8b 45 0c             	mov    0xc(%ebp),%eax
    f735:	5d                   	pop    %ebp
    f736:	c3                   	ret    

0000f737 <ck_pr_fas_char>:

#define CK_PR_FAS_S(S, T, I) CK_PR_FAS(S, T, T, T, I)

CK_PR_FAS_S(char, char, "xchgb")
    f737:	55                   	push   %ebp
    f738:	89 e5                	mov    %esp,%ebp
    f73a:	83 ec 04             	sub    $0x4,%esp
    f73d:	8b 45 0c             	mov    0xc(%ebp),%eax
    f740:	88 45 fc             	mov    %al,-0x4(%ebp)
    f743:	8b 55 08             	mov    0x8(%ebp),%edx
    f746:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f749:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f74d:	86 02                	xchg   %al,(%edx)
    f74f:	88 45 fc             	mov    %al,-0x4(%ebp)
    f752:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f756:	c9                   	leave  
    f757:	c3                   	ret    

0000f758 <ck_pr_fas_uint>:
CK_PR_FAS_S(uint, unsigned int, "xchgl")
    f758:	55                   	push   %ebp
    f759:	89 e5                	mov    %esp,%ebp
    f75b:	8b 55 08             	mov    0x8(%ebp),%edx
    f75e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f761:	8b 45 0c             	mov    0xc(%ebp),%eax
    f764:	87 02                	xchg   %eax,(%edx)
    f766:	89 45 0c             	mov    %eax,0xc(%ebp)
    f769:	8b 45 0c             	mov    0xc(%ebp),%eax
    f76c:	5d                   	pop    %ebp
    f76d:	c3                   	ret    

0000f76e <ck_pr_fas_int>:
CK_PR_FAS_S(int, int, "xchgl")
    f76e:	55                   	push   %ebp
    f76f:	89 e5                	mov    %esp,%ebp
    f771:	8b 55 08             	mov    0x8(%ebp),%edx
    f774:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f777:	8b 45 0c             	mov    0xc(%ebp),%eax
    f77a:	87 02                	xchg   %eax,(%edx)
    f77c:	89 45 0c             	mov    %eax,0xc(%ebp)
    f77f:	8b 45 0c             	mov    0xc(%ebp),%eax
    f782:	5d                   	pop    %ebp
    f783:	c3                   	ret    

0000f784 <ck_pr_fas_32>:
CK_PR_FAS_S(32, uint32_t, "xchgl")
    f784:	55                   	push   %ebp
    f785:	89 e5                	mov    %esp,%ebp
    f787:	8b 55 08             	mov    0x8(%ebp),%edx
    f78a:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f78d:	8b 45 0c             	mov    0xc(%ebp),%eax
    f790:	87 02                	xchg   %eax,(%edx)
    f792:	89 45 0c             	mov    %eax,0xc(%ebp)
    f795:	8b 45 0c             	mov    0xc(%ebp),%eax
    f798:	5d                   	pop    %ebp
    f799:	c3                   	ret    

0000f79a <ck_pr_fas_16>:
CK_PR_FAS_S(16, uint16_t, "xchgw")
    f79a:	55                   	push   %ebp
    f79b:	89 e5                	mov    %esp,%ebp
    f79d:	83 ec 04             	sub    $0x4,%esp
    f7a0:	8b 45 0c             	mov    0xc(%ebp),%eax
    f7a3:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    f7a7:	8b 55 08             	mov    0x8(%ebp),%edx
    f7aa:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f7ad:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
    f7b1:	66 87 02             	xchg   %ax,(%edx)
    f7b4:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    f7b8:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
    f7bc:	c9                   	leave  
    f7bd:	c3                   	ret    

0000f7be <ck_pr_fas_8>:
CK_PR_FAS_S(8,  uint8_t,  "xchgb")
    f7be:	55                   	push   %ebp
    f7bf:	89 e5                	mov    %esp,%ebp
    f7c1:	83 ec 04             	sub    $0x4,%esp
    f7c4:	8b 45 0c             	mov    0xc(%ebp),%eax
    f7c7:	88 45 fc             	mov    %al,-0x4(%ebp)
    f7ca:	8b 55 08             	mov    0x8(%ebp),%edx
    f7cd:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f7d0:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f7d4:	86 02                	xchg   %al,(%edx)
    f7d6:	88 45 fc             	mov    %al,-0x4(%ebp)
    f7d9:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f7dd:	c9                   	leave  
    f7de:	c3                   	ret    

0000f7df <ck_pr_md_load_ptr>:
					: "m"  (*(const C *)target)	\
					: "memory");			\
		return (r);						\
	}

CK_PR_LOAD(ptr, void, void *, char, "movl")
    f7df:	55                   	push   %ebp
    f7e0:	89 e5                	mov    %esp,%ebp
    f7e2:	83 ec 10             	sub    $0x10,%esp
    f7e5:	8b 45 08             	mov    0x8(%ebp),%eax
    f7e8:	8b 00                	mov    (%eax),%eax
    f7ea:	89 45 fc             	mov    %eax,-0x4(%ebp)
    f7ed:	8b 45 fc             	mov    -0x4(%ebp),%eax
    f7f0:	c9                   	leave  
    f7f1:	c3                   	ret    

0000f7f2 <ck_pr_md_load_char>:

#define CK_PR_LOAD_S(S, T, I) CK_PR_LOAD(S, T, T, T, I)

CK_PR_LOAD_S(char, char, "movb")
    f7f2:	55                   	push   %ebp
    f7f3:	89 e5                	mov    %esp,%ebp
    f7f5:	83 ec 10             	sub    $0x10,%esp
    f7f8:	8b 45 08             	mov    0x8(%ebp),%eax
    f7fb:	8a 00                	mov    (%eax),%al
    f7fd:	88 45 ff             	mov    %al,-0x1(%ebp)
    f800:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    f804:	c9                   	leave  
    f805:	c3                   	ret    

0000f806 <ck_pr_md_load_uint>:
CK_PR_LOAD_S(uint, unsigned int, "movl")
    f806:	55                   	push   %ebp
    f807:	89 e5                	mov    %esp,%ebp
    f809:	83 ec 10             	sub    $0x10,%esp
    f80c:	8b 45 08             	mov    0x8(%ebp),%eax
    f80f:	8b 00                	mov    (%eax),%eax
    f811:	89 45 fc             	mov    %eax,-0x4(%ebp)
    f814:	8b 45 fc             	mov    -0x4(%ebp),%eax
    f817:	c9                   	leave  
    f818:	c3                   	ret    

0000f819 <ck_pr_md_load_int>:
CK_PR_LOAD_S(int, int, "movl")
    f819:	55                   	push   %ebp
    f81a:	89 e5                	mov    %esp,%ebp
    f81c:	83 ec 10             	sub    $0x10,%esp
    f81f:	8b 45 08             	mov    0x8(%ebp),%eax
    f822:	8b 00                	mov    (%eax),%eax
    f824:	89 45 fc             	mov    %eax,-0x4(%ebp)
    f827:	8b 45 fc             	mov    -0x4(%ebp),%eax
    f82a:	c9                   	leave  
    f82b:	c3                   	ret    

0000f82c <ck_pr_md_load_32>:
CK_PR_LOAD_S(32, uint32_t, "movl")
    f82c:	55                   	push   %ebp
    f82d:	89 e5                	mov    %esp,%ebp
    f82f:	83 ec 10             	sub    $0x10,%esp
    f832:	8b 45 08             	mov    0x8(%ebp),%eax
    f835:	8b 00                	mov    (%eax),%eax
    f837:	89 45 fc             	mov    %eax,-0x4(%ebp)
    f83a:	8b 45 fc             	mov    -0x4(%ebp),%eax
    f83d:	c9                   	leave  
    f83e:	c3                   	ret    

0000f83f <ck_pr_md_load_16>:
CK_PR_LOAD_S(16, uint16_t, "movw")
    f83f:	55                   	push   %ebp
    f840:	89 e5                	mov    %esp,%ebp
    f842:	83 ec 10             	sub    $0x10,%esp
    f845:	8b 45 08             	mov    0x8(%ebp),%eax
    f848:	66 8b 00             	mov    (%eax),%ax
    f84b:	66 89 45 fe          	mov    %ax,-0x2(%ebp)
    f84f:	0f b7 45 fe          	movzwl -0x2(%ebp),%eax
    f853:	c9                   	leave  
    f854:	c3                   	ret    

0000f855 <ck_pr_md_load_8>:
CK_PR_LOAD_S(8,  uint8_t,  "movb")
    f855:	55                   	push   %ebp
    f856:	89 e5                	mov    %esp,%ebp
    f858:	83 ec 10             	sub    $0x10,%esp
    f85b:	8b 45 08             	mov    0x8(%ebp),%eax
    f85e:	8a 00                	mov    (%eax),%al
    f860:	88 45 ff             	mov    %al,-0x1(%ebp)
    f863:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
    f867:	c9                   	leave  
    f868:	c3                   	ret    

0000f869 <ck_pr_md_store_ptr>:
					: CK_CC_IMM "q" (v)	\
					: "memory");		\
		return;						\
	}

CK_PR_STORE(ptr, void, const void *, char, "movl")
    f869:	55                   	push   %ebp
    f86a:	89 e5                	mov    %esp,%ebp
    f86c:	8b 45 08             	mov    0x8(%ebp),%eax
    f86f:	8b 55 0c             	mov    0xc(%ebp),%edx
    f872:	89 10                	mov    %edx,(%eax)
    f874:	90                   	nop
    f875:	5d                   	pop    %ebp
    f876:	c3                   	ret    

0000f877 <ck_pr_md_store_char>:

#define CK_PR_STORE_S(S, T, I) CK_PR_STORE(S, T, T, T, I)

CK_PR_STORE_S(char, char, "movb")
    f877:	55                   	push   %ebp
    f878:	89 e5                	mov    %esp,%ebp
    f87a:	83 ec 04             	sub    $0x4,%esp
    f87d:	8b 45 0c             	mov    0xc(%ebp),%eax
    f880:	88 45 fc             	mov    %al,-0x4(%ebp)
    f883:	8b 45 08             	mov    0x8(%ebp),%eax
    f886:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    f88a:	88 10                	mov    %dl,(%eax)
    f88c:	90                   	nop
    f88d:	c9                   	leave  
    f88e:	c3                   	ret    

0000f88f <ck_pr_md_store_uint>:
CK_PR_STORE_S(uint, unsigned int, "movl")
    f88f:	55                   	push   %ebp
    f890:	89 e5                	mov    %esp,%ebp
    f892:	8b 45 08             	mov    0x8(%ebp),%eax
    f895:	8b 55 0c             	mov    0xc(%ebp),%edx
    f898:	89 10                	mov    %edx,(%eax)
    f89a:	90                   	nop
    f89b:	5d                   	pop    %ebp
    f89c:	c3                   	ret    

0000f89d <ck_pr_md_store_int>:
CK_PR_STORE_S(int, int, "movl")
    f89d:	55                   	push   %ebp
    f89e:	89 e5                	mov    %esp,%ebp
    f8a0:	8b 45 08             	mov    0x8(%ebp),%eax
    f8a3:	8b 55 0c             	mov    0xc(%ebp),%edx
    f8a6:	89 10                	mov    %edx,(%eax)
    f8a8:	90                   	nop
    f8a9:	5d                   	pop    %ebp
    f8aa:	c3                   	ret    

0000f8ab <ck_pr_md_store_32>:
CK_PR_STORE_S(32, uint32_t, "movl")
    f8ab:	55                   	push   %ebp
    f8ac:	89 e5                	mov    %esp,%ebp
    f8ae:	8b 45 08             	mov    0x8(%ebp),%eax
    f8b1:	8b 55 0c             	mov    0xc(%ebp),%edx
    f8b4:	89 10                	mov    %edx,(%eax)
    f8b6:	90                   	nop
    f8b7:	5d                   	pop    %ebp
    f8b8:	c3                   	ret    

0000f8b9 <ck_pr_md_store_16>:
CK_PR_STORE_S(16, uint16_t, "movw")
    f8b9:	55                   	push   %ebp
    f8ba:	89 e5                	mov    %esp,%ebp
    f8bc:	83 ec 04             	sub    $0x4,%esp
    f8bf:	8b 45 0c             	mov    0xc(%ebp),%eax
    f8c2:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    f8c6:	8b 45 08             	mov    0x8(%ebp),%eax
    f8c9:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    f8cd:	66 89 10             	mov    %dx,(%eax)
    f8d0:	90                   	nop
    f8d1:	c9                   	leave  
    f8d2:	c3                   	ret    

0000f8d3 <ck_pr_md_store_8>:
CK_PR_STORE_S(8,  uint8_t, "movb")
    f8d3:	55                   	push   %ebp
    f8d4:	89 e5                	mov    %esp,%ebp
    f8d6:	83 ec 04             	sub    $0x4,%esp
    f8d9:	8b 45 0c             	mov    0xc(%ebp),%eax
    f8dc:	88 45 fc             	mov    %al,-0x4(%ebp)
    f8df:	8b 45 08             	mov    0x8(%ebp),%eax
    f8e2:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    f8e6:	88 10                	mov    %dl,(%eax)
    f8e8:	90                   	nop
    f8e9:	c9                   	leave  
    f8ea:	c3                   	ret    

0000f8eb <ck_pr_faa_ptr>:
					:				\
					: "memory", "cc");		\
		return (d);						\
	}

CK_PR_FAA(ptr, void, uintptr_t, char, "xaddl")
    f8eb:	55                   	push   %ebp
    f8ec:	89 e5                	mov    %esp,%ebp
    f8ee:	8b 55 08             	mov    0x8(%ebp),%edx
    f8f1:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f8f4:	8b 45 0c             	mov    0xc(%ebp),%eax
    f8f7:	f0 0f c1 02          	lock xadd %eax,(%edx)
    f8fb:	89 45 0c             	mov    %eax,0xc(%ebp)
    f8fe:	8b 45 0c             	mov    0xc(%ebp),%eax
    f901:	5d                   	pop    %ebp
    f902:	c3                   	ret    

0000f903 <ck_pr_faa_char>:

#define CK_PR_FAA_S(S, T, I) CK_PR_FAA(S, T, T, T, I)

CK_PR_FAA_S(char, char, "xaddb")
    f903:	55                   	push   %ebp
    f904:	89 e5                	mov    %esp,%ebp
    f906:	83 ec 04             	sub    $0x4,%esp
    f909:	8b 45 0c             	mov    0xc(%ebp),%eax
    f90c:	88 45 fc             	mov    %al,-0x4(%ebp)
    f90f:	8b 55 08             	mov    0x8(%ebp),%edx
    f912:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f915:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f919:	f0 0f c0 02          	lock xadd %al,(%edx)
    f91d:	88 45 fc             	mov    %al,-0x4(%ebp)
    f920:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f924:	c9                   	leave  
    f925:	c3                   	ret    

0000f926 <ck_pr_faa_uint>:
CK_PR_FAA_S(uint, unsigned int, "xaddl")
    f926:	55                   	push   %ebp
    f927:	89 e5                	mov    %esp,%ebp
    f929:	8b 55 08             	mov    0x8(%ebp),%edx
    f92c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f92f:	8b 45 0c             	mov    0xc(%ebp),%eax
    f932:	f0 0f c1 02          	lock xadd %eax,(%edx)
    f936:	89 45 0c             	mov    %eax,0xc(%ebp)
    f939:	8b 45 0c             	mov    0xc(%ebp),%eax
    f93c:	5d                   	pop    %ebp
    f93d:	c3                   	ret    

0000f93e <ck_pr_faa_int>:
CK_PR_FAA_S(int, int, "xaddl")
    f93e:	55                   	push   %ebp
    f93f:	89 e5                	mov    %esp,%ebp
    f941:	8b 55 08             	mov    0x8(%ebp),%edx
    f944:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f947:	8b 45 0c             	mov    0xc(%ebp),%eax
    f94a:	f0 0f c1 02          	lock xadd %eax,(%edx)
    f94e:	89 45 0c             	mov    %eax,0xc(%ebp)
    f951:	8b 45 0c             	mov    0xc(%ebp),%eax
    f954:	5d                   	pop    %ebp
    f955:	c3                   	ret    

0000f956 <ck_pr_faa_32>:
CK_PR_FAA_S(32, uint32_t, "xaddl")
    f956:	55                   	push   %ebp
    f957:	89 e5                	mov    %esp,%ebp
    f959:	8b 55 08             	mov    0x8(%ebp),%edx
    f95c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f95f:	8b 45 0c             	mov    0xc(%ebp),%eax
    f962:	f0 0f c1 02          	lock xadd %eax,(%edx)
    f966:	89 45 0c             	mov    %eax,0xc(%ebp)
    f969:	8b 45 0c             	mov    0xc(%ebp),%eax
    f96c:	5d                   	pop    %ebp
    f96d:	c3                   	ret    

0000f96e <ck_pr_faa_16>:
CK_PR_FAA_S(16, uint16_t, "xaddw")
    f96e:	55                   	push   %ebp
    f96f:	89 e5                	mov    %esp,%ebp
    f971:	83 ec 04             	sub    $0x4,%esp
    f974:	8b 45 0c             	mov    0xc(%ebp),%eax
    f977:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    f97b:	8b 55 08             	mov    0x8(%ebp),%edx
    f97e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f981:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
    f985:	66 f0 0f c1 02       	lock xadd %ax,(%edx)
    f98a:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    f98e:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
    f992:	c9                   	leave  
    f993:	c3                   	ret    

0000f994 <ck_pr_faa_8>:
CK_PR_FAA_S(8,  uint8_t,  "xaddb")
    f994:	55                   	push   %ebp
    f995:	89 e5                	mov    %esp,%ebp
    f997:	83 ec 04             	sub    $0x4,%esp
    f99a:	8b 45 0c             	mov    0xc(%ebp),%eax
    f99d:	88 45 fc             	mov    %al,-0x4(%ebp)
    f9a0:	8b 55 08             	mov    0x8(%ebp),%edx
    f9a3:	8b 4d 08             	mov    0x8(%ebp),%ecx
    f9a6:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f9aa:	f0 0f c0 02          	lock xadd %al,(%edx)
    f9ae:	88 45 fc             	mov    %al,-0x4(%ebp)
    f9b1:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
    f9b5:	c9                   	leave  
    f9b6:	c3                   	ret    

0000f9b7 <ck_pr_inc_ptr>:
	CK_PR_UNARY_S(K, uint, unsigned int, #K "l")	\
	CK_PR_UNARY_S(K, 32, uint32_t, #K "l")		\
	CK_PR_UNARY_S(K, 16, uint16_t, #K "w")		\
	CK_PR_UNARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(inc)
    f9b7:	55                   	push   %ebp
    f9b8:	89 e5                	mov    %esp,%ebp
    f9ba:	8b 45 08             	mov    0x8(%ebp),%eax
    f9bd:	8b 55 08             	mov    0x8(%ebp),%edx
    f9c0:	f0 ff 00             	lock incl (%eax)
    f9c3:	90                   	nop
    f9c4:	5d                   	pop    %ebp
    f9c5:	c3                   	ret    

0000f9c6 <ck_pr_inc_ptr_zero>:
    f9c6:	55                   	push   %ebp
    f9c7:	89 e5                	mov    %esp,%ebp
    f9c9:	8b 45 08             	mov    0x8(%ebp),%eax
    f9cc:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    f9cf:	8b 55 08             	mov    0x8(%ebp),%edx
    f9d2:	f0 ff 00             	lock incl (%eax)
    f9d5:	0f 94 01             	sete   (%ecx)
    f9d8:	90                   	nop
    f9d9:	5d                   	pop    %ebp
    f9da:	c3                   	ret    

0000f9db <ck_pr_inc_char>:
    f9db:	55                   	push   %ebp
    f9dc:	89 e5                	mov    %esp,%ebp
    f9de:	8b 45 08             	mov    0x8(%ebp),%eax
    f9e1:	8b 55 08             	mov    0x8(%ebp),%edx
    f9e4:	f0 fe 00             	lock incb (%eax)
    f9e7:	90                   	nop
    f9e8:	5d                   	pop    %ebp
    f9e9:	c3                   	ret    

0000f9ea <ck_pr_inc_char_zero>:
    f9ea:	55                   	push   %ebp
    f9eb:	89 e5                	mov    %esp,%ebp
    f9ed:	8b 45 08             	mov    0x8(%ebp),%eax
    f9f0:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    f9f3:	8b 55 08             	mov    0x8(%ebp),%edx
    f9f6:	f0 fe 00             	lock incb (%eax)
    f9f9:	0f 94 01             	sete   (%ecx)
    f9fc:	90                   	nop
    f9fd:	5d                   	pop    %ebp
    f9fe:	c3                   	ret    

0000f9ff <ck_pr_inc_int>:
    f9ff:	55                   	push   %ebp
    fa00:	89 e5                	mov    %esp,%ebp
    fa02:	8b 45 08             	mov    0x8(%ebp),%eax
    fa05:	8b 55 08             	mov    0x8(%ebp),%edx
    fa08:	f0 ff 00             	lock incl (%eax)
    fa0b:	90                   	nop
    fa0c:	5d                   	pop    %ebp
    fa0d:	c3                   	ret    

0000fa0e <ck_pr_inc_int_zero>:
    fa0e:	55                   	push   %ebp
    fa0f:	89 e5                	mov    %esp,%ebp
    fa11:	8b 45 08             	mov    0x8(%ebp),%eax
    fa14:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fa17:	8b 55 08             	mov    0x8(%ebp),%edx
    fa1a:	f0 ff 00             	lock incl (%eax)
    fa1d:	0f 94 01             	sete   (%ecx)
    fa20:	90                   	nop
    fa21:	5d                   	pop    %ebp
    fa22:	c3                   	ret    

0000fa23 <ck_pr_inc_uint>:
    fa23:	55                   	push   %ebp
    fa24:	89 e5                	mov    %esp,%ebp
    fa26:	8b 45 08             	mov    0x8(%ebp),%eax
    fa29:	8b 55 08             	mov    0x8(%ebp),%edx
    fa2c:	f0 ff 00             	lock incl (%eax)
    fa2f:	90                   	nop
    fa30:	5d                   	pop    %ebp
    fa31:	c3                   	ret    

0000fa32 <ck_pr_inc_uint_zero>:
    fa32:	55                   	push   %ebp
    fa33:	89 e5                	mov    %esp,%ebp
    fa35:	8b 45 08             	mov    0x8(%ebp),%eax
    fa38:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fa3b:	8b 55 08             	mov    0x8(%ebp),%edx
    fa3e:	f0 ff 00             	lock incl (%eax)
    fa41:	0f 94 01             	sete   (%ecx)
    fa44:	90                   	nop
    fa45:	5d                   	pop    %ebp
    fa46:	c3                   	ret    

0000fa47 <ck_pr_inc_32>:
    fa47:	55                   	push   %ebp
    fa48:	89 e5                	mov    %esp,%ebp
    fa4a:	8b 45 08             	mov    0x8(%ebp),%eax
    fa4d:	8b 55 08             	mov    0x8(%ebp),%edx
    fa50:	f0 ff 00             	lock incl (%eax)
    fa53:	90                   	nop
    fa54:	5d                   	pop    %ebp
    fa55:	c3                   	ret    

0000fa56 <ck_pr_inc_32_zero>:
    fa56:	55                   	push   %ebp
    fa57:	89 e5                	mov    %esp,%ebp
    fa59:	8b 45 08             	mov    0x8(%ebp),%eax
    fa5c:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fa5f:	8b 55 08             	mov    0x8(%ebp),%edx
    fa62:	f0 ff 00             	lock incl (%eax)
    fa65:	0f 94 01             	sete   (%ecx)
    fa68:	90                   	nop
    fa69:	5d                   	pop    %ebp
    fa6a:	c3                   	ret    

0000fa6b <ck_pr_inc_16>:
    fa6b:	55                   	push   %ebp
    fa6c:	89 e5                	mov    %esp,%ebp
    fa6e:	8b 45 08             	mov    0x8(%ebp),%eax
    fa71:	8b 55 08             	mov    0x8(%ebp),%edx
    fa74:	66 f0 ff 00          	lock incw (%eax)
    fa78:	90                   	nop
    fa79:	5d                   	pop    %ebp
    fa7a:	c3                   	ret    

0000fa7b <ck_pr_inc_16_zero>:
    fa7b:	55                   	push   %ebp
    fa7c:	89 e5                	mov    %esp,%ebp
    fa7e:	8b 45 08             	mov    0x8(%ebp),%eax
    fa81:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fa84:	8b 55 08             	mov    0x8(%ebp),%edx
    fa87:	66 f0 ff 00          	lock incw (%eax)
    fa8b:	0f 94 01             	sete   (%ecx)
    fa8e:	90                   	nop
    fa8f:	5d                   	pop    %ebp
    fa90:	c3                   	ret    

0000fa91 <ck_pr_inc_8>:
    fa91:	55                   	push   %ebp
    fa92:	89 e5                	mov    %esp,%ebp
    fa94:	8b 45 08             	mov    0x8(%ebp),%eax
    fa97:	8b 55 08             	mov    0x8(%ebp),%edx
    fa9a:	f0 fe 00             	lock incb (%eax)
    fa9d:	90                   	nop
    fa9e:	5d                   	pop    %ebp
    fa9f:	c3                   	ret    

0000faa0 <ck_pr_inc_8_zero>:
    faa0:	55                   	push   %ebp
    faa1:	89 e5                	mov    %esp,%ebp
    faa3:	8b 45 08             	mov    0x8(%ebp),%eax
    faa6:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    faa9:	8b 55 08             	mov    0x8(%ebp),%edx
    faac:	f0 fe 00             	lock incb (%eax)
    faaf:	0f 94 01             	sete   (%ecx)
    fab2:	90                   	nop
    fab3:	5d                   	pop    %ebp
    fab4:	c3                   	ret    

0000fab5 <ck_pr_dec_ptr>:
CK_PR_GENERATE(dec)
    fab5:	55                   	push   %ebp
    fab6:	89 e5                	mov    %esp,%ebp
    fab8:	8b 45 08             	mov    0x8(%ebp),%eax
    fabb:	8b 55 08             	mov    0x8(%ebp),%edx
    fabe:	f0 ff 08             	lock decl (%eax)
    fac1:	90                   	nop
    fac2:	5d                   	pop    %ebp
    fac3:	c3                   	ret    

0000fac4 <ck_pr_dec_ptr_zero>:
    fac4:	55                   	push   %ebp
    fac5:	89 e5                	mov    %esp,%ebp
    fac7:	8b 45 08             	mov    0x8(%ebp),%eax
    faca:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    facd:	8b 55 08             	mov    0x8(%ebp),%edx
    fad0:	f0 ff 08             	lock decl (%eax)
    fad3:	0f 94 01             	sete   (%ecx)
    fad6:	90                   	nop
    fad7:	5d                   	pop    %ebp
    fad8:	c3                   	ret    

0000fad9 <ck_pr_dec_char>:
    fad9:	55                   	push   %ebp
    fada:	89 e5                	mov    %esp,%ebp
    fadc:	8b 45 08             	mov    0x8(%ebp),%eax
    fadf:	8b 55 08             	mov    0x8(%ebp),%edx
    fae2:	f0 fe 08             	lock decb (%eax)
    fae5:	90                   	nop
    fae6:	5d                   	pop    %ebp
    fae7:	c3                   	ret    

0000fae8 <ck_pr_dec_char_zero>:
    fae8:	55                   	push   %ebp
    fae9:	89 e5                	mov    %esp,%ebp
    faeb:	8b 45 08             	mov    0x8(%ebp),%eax
    faee:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    faf1:	8b 55 08             	mov    0x8(%ebp),%edx
    faf4:	f0 fe 08             	lock decb (%eax)
    faf7:	0f 94 01             	sete   (%ecx)
    fafa:	90                   	nop
    fafb:	5d                   	pop    %ebp
    fafc:	c3                   	ret    

0000fafd <ck_pr_dec_int>:
    fafd:	55                   	push   %ebp
    fafe:	89 e5                	mov    %esp,%ebp
    fb00:	8b 45 08             	mov    0x8(%ebp),%eax
    fb03:	8b 55 08             	mov    0x8(%ebp),%edx
    fb06:	f0 ff 08             	lock decl (%eax)
    fb09:	90                   	nop
    fb0a:	5d                   	pop    %ebp
    fb0b:	c3                   	ret    

0000fb0c <ck_pr_dec_int_zero>:
    fb0c:	55                   	push   %ebp
    fb0d:	89 e5                	mov    %esp,%ebp
    fb0f:	8b 45 08             	mov    0x8(%ebp),%eax
    fb12:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fb15:	8b 55 08             	mov    0x8(%ebp),%edx
    fb18:	f0 ff 08             	lock decl (%eax)
    fb1b:	0f 94 01             	sete   (%ecx)
    fb1e:	90                   	nop
    fb1f:	5d                   	pop    %ebp
    fb20:	c3                   	ret    

0000fb21 <ck_pr_dec_uint>:
    fb21:	55                   	push   %ebp
    fb22:	89 e5                	mov    %esp,%ebp
    fb24:	8b 45 08             	mov    0x8(%ebp),%eax
    fb27:	8b 55 08             	mov    0x8(%ebp),%edx
    fb2a:	f0 ff 08             	lock decl (%eax)
    fb2d:	90                   	nop
    fb2e:	5d                   	pop    %ebp
    fb2f:	c3                   	ret    

0000fb30 <ck_pr_dec_uint_zero>:
    fb30:	55                   	push   %ebp
    fb31:	89 e5                	mov    %esp,%ebp
    fb33:	8b 45 08             	mov    0x8(%ebp),%eax
    fb36:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fb39:	8b 55 08             	mov    0x8(%ebp),%edx
    fb3c:	f0 ff 08             	lock decl (%eax)
    fb3f:	0f 94 01             	sete   (%ecx)
    fb42:	90                   	nop
    fb43:	5d                   	pop    %ebp
    fb44:	c3                   	ret    

0000fb45 <ck_pr_dec_32>:
    fb45:	55                   	push   %ebp
    fb46:	89 e5                	mov    %esp,%ebp
    fb48:	8b 45 08             	mov    0x8(%ebp),%eax
    fb4b:	8b 55 08             	mov    0x8(%ebp),%edx
    fb4e:	f0 ff 08             	lock decl (%eax)
    fb51:	90                   	nop
    fb52:	5d                   	pop    %ebp
    fb53:	c3                   	ret    

0000fb54 <ck_pr_dec_32_zero>:
    fb54:	55                   	push   %ebp
    fb55:	89 e5                	mov    %esp,%ebp
    fb57:	8b 45 08             	mov    0x8(%ebp),%eax
    fb5a:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fb5d:	8b 55 08             	mov    0x8(%ebp),%edx
    fb60:	f0 ff 08             	lock decl (%eax)
    fb63:	0f 94 01             	sete   (%ecx)
    fb66:	90                   	nop
    fb67:	5d                   	pop    %ebp
    fb68:	c3                   	ret    

0000fb69 <ck_pr_dec_16>:
    fb69:	55                   	push   %ebp
    fb6a:	89 e5                	mov    %esp,%ebp
    fb6c:	8b 45 08             	mov    0x8(%ebp),%eax
    fb6f:	8b 55 08             	mov    0x8(%ebp),%edx
    fb72:	66 f0 ff 08          	lock decw (%eax)
    fb76:	90                   	nop
    fb77:	5d                   	pop    %ebp
    fb78:	c3                   	ret    

0000fb79 <ck_pr_dec_16_zero>:
    fb79:	55                   	push   %ebp
    fb7a:	89 e5                	mov    %esp,%ebp
    fb7c:	8b 45 08             	mov    0x8(%ebp),%eax
    fb7f:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fb82:	8b 55 08             	mov    0x8(%ebp),%edx
    fb85:	66 f0 ff 08          	lock decw (%eax)
    fb89:	0f 94 01             	sete   (%ecx)
    fb8c:	90                   	nop
    fb8d:	5d                   	pop    %ebp
    fb8e:	c3                   	ret    

0000fb8f <ck_pr_dec_8>:
    fb8f:	55                   	push   %ebp
    fb90:	89 e5                	mov    %esp,%ebp
    fb92:	8b 45 08             	mov    0x8(%ebp),%eax
    fb95:	8b 55 08             	mov    0x8(%ebp),%edx
    fb98:	f0 fe 08             	lock decb (%eax)
    fb9b:	90                   	nop
    fb9c:	5d                   	pop    %ebp
    fb9d:	c3                   	ret    

0000fb9e <ck_pr_dec_8_zero>:
    fb9e:	55                   	push   %ebp
    fb9f:	89 e5                	mov    %esp,%ebp
    fba1:	8b 45 08             	mov    0x8(%ebp),%eax
    fba4:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fba7:	8b 55 08             	mov    0x8(%ebp),%edx
    fbaa:	f0 fe 08             	lock decb (%eax)
    fbad:	0f 94 01             	sete   (%ecx)
    fbb0:	90                   	nop
    fbb1:	5d                   	pop    %ebp
    fbb2:	c3                   	ret    

0000fbb3 <ck_pr_neg_ptr>:
CK_PR_GENERATE(neg)
    fbb3:	55                   	push   %ebp
    fbb4:	89 e5                	mov    %esp,%ebp
    fbb6:	8b 45 08             	mov    0x8(%ebp),%eax
    fbb9:	8b 55 08             	mov    0x8(%ebp),%edx
    fbbc:	f0 f7 18             	lock negl (%eax)
    fbbf:	90                   	nop
    fbc0:	5d                   	pop    %ebp
    fbc1:	c3                   	ret    

0000fbc2 <ck_pr_neg_ptr_zero>:
    fbc2:	55                   	push   %ebp
    fbc3:	89 e5                	mov    %esp,%ebp
    fbc5:	8b 45 08             	mov    0x8(%ebp),%eax
    fbc8:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fbcb:	8b 55 08             	mov    0x8(%ebp),%edx
    fbce:	f0 f7 18             	lock negl (%eax)
    fbd1:	0f 94 01             	sete   (%ecx)
    fbd4:	90                   	nop
    fbd5:	5d                   	pop    %ebp
    fbd6:	c3                   	ret    

0000fbd7 <ck_pr_neg_char>:
    fbd7:	55                   	push   %ebp
    fbd8:	89 e5                	mov    %esp,%ebp
    fbda:	8b 45 08             	mov    0x8(%ebp),%eax
    fbdd:	8b 55 08             	mov    0x8(%ebp),%edx
    fbe0:	f0 f6 18             	lock negb (%eax)
    fbe3:	90                   	nop
    fbe4:	5d                   	pop    %ebp
    fbe5:	c3                   	ret    

0000fbe6 <ck_pr_neg_char_zero>:
    fbe6:	55                   	push   %ebp
    fbe7:	89 e5                	mov    %esp,%ebp
    fbe9:	8b 45 08             	mov    0x8(%ebp),%eax
    fbec:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fbef:	8b 55 08             	mov    0x8(%ebp),%edx
    fbf2:	f0 f6 18             	lock negb (%eax)
    fbf5:	0f 94 01             	sete   (%ecx)
    fbf8:	90                   	nop
    fbf9:	5d                   	pop    %ebp
    fbfa:	c3                   	ret    

0000fbfb <ck_pr_neg_int>:
    fbfb:	55                   	push   %ebp
    fbfc:	89 e5                	mov    %esp,%ebp
    fbfe:	8b 45 08             	mov    0x8(%ebp),%eax
    fc01:	8b 55 08             	mov    0x8(%ebp),%edx
    fc04:	f0 f7 18             	lock negl (%eax)
    fc07:	90                   	nop
    fc08:	5d                   	pop    %ebp
    fc09:	c3                   	ret    

0000fc0a <ck_pr_neg_int_zero>:
    fc0a:	55                   	push   %ebp
    fc0b:	89 e5                	mov    %esp,%ebp
    fc0d:	8b 45 08             	mov    0x8(%ebp),%eax
    fc10:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fc13:	8b 55 08             	mov    0x8(%ebp),%edx
    fc16:	f0 f7 18             	lock negl (%eax)
    fc19:	0f 94 01             	sete   (%ecx)
    fc1c:	90                   	nop
    fc1d:	5d                   	pop    %ebp
    fc1e:	c3                   	ret    

0000fc1f <ck_pr_neg_uint>:
    fc1f:	55                   	push   %ebp
    fc20:	89 e5                	mov    %esp,%ebp
    fc22:	8b 45 08             	mov    0x8(%ebp),%eax
    fc25:	8b 55 08             	mov    0x8(%ebp),%edx
    fc28:	f0 f7 18             	lock negl (%eax)
    fc2b:	90                   	nop
    fc2c:	5d                   	pop    %ebp
    fc2d:	c3                   	ret    

0000fc2e <ck_pr_neg_uint_zero>:
    fc2e:	55                   	push   %ebp
    fc2f:	89 e5                	mov    %esp,%ebp
    fc31:	8b 45 08             	mov    0x8(%ebp),%eax
    fc34:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fc37:	8b 55 08             	mov    0x8(%ebp),%edx
    fc3a:	f0 f7 18             	lock negl (%eax)
    fc3d:	0f 94 01             	sete   (%ecx)
    fc40:	90                   	nop
    fc41:	5d                   	pop    %ebp
    fc42:	c3                   	ret    

0000fc43 <ck_pr_neg_32>:
    fc43:	55                   	push   %ebp
    fc44:	89 e5                	mov    %esp,%ebp
    fc46:	8b 45 08             	mov    0x8(%ebp),%eax
    fc49:	8b 55 08             	mov    0x8(%ebp),%edx
    fc4c:	f0 f7 18             	lock negl (%eax)
    fc4f:	90                   	nop
    fc50:	5d                   	pop    %ebp
    fc51:	c3                   	ret    

0000fc52 <ck_pr_neg_32_zero>:
    fc52:	55                   	push   %ebp
    fc53:	89 e5                	mov    %esp,%ebp
    fc55:	8b 45 08             	mov    0x8(%ebp),%eax
    fc58:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fc5b:	8b 55 08             	mov    0x8(%ebp),%edx
    fc5e:	f0 f7 18             	lock negl (%eax)
    fc61:	0f 94 01             	sete   (%ecx)
    fc64:	90                   	nop
    fc65:	5d                   	pop    %ebp
    fc66:	c3                   	ret    

0000fc67 <ck_pr_neg_16>:
    fc67:	55                   	push   %ebp
    fc68:	89 e5                	mov    %esp,%ebp
    fc6a:	8b 45 08             	mov    0x8(%ebp),%eax
    fc6d:	8b 55 08             	mov    0x8(%ebp),%edx
    fc70:	66 f0 f7 18          	lock negw (%eax)
    fc74:	90                   	nop
    fc75:	5d                   	pop    %ebp
    fc76:	c3                   	ret    

0000fc77 <ck_pr_neg_16_zero>:
    fc77:	55                   	push   %ebp
    fc78:	89 e5                	mov    %esp,%ebp
    fc7a:	8b 45 08             	mov    0x8(%ebp),%eax
    fc7d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fc80:	8b 55 08             	mov    0x8(%ebp),%edx
    fc83:	66 f0 f7 18          	lock negw (%eax)
    fc87:	0f 94 01             	sete   (%ecx)
    fc8a:	90                   	nop
    fc8b:	5d                   	pop    %ebp
    fc8c:	c3                   	ret    

0000fc8d <ck_pr_neg_8>:
    fc8d:	55                   	push   %ebp
    fc8e:	89 e5                	mov    %esp,%ebp
    fc90:	8b 45 08             	mov    0x8(%ebp),%eax
    fc93:	8b 55 08             	mov    0x8(%ebp),%edx
    fc96:	f0 f6 18             	lock negb (%eax)
    fc99:	90                   	nop
    fc9a:	5d                   	pop    %ebp
    fc9b:	c3                   	ret    

0000fc9c <ck_pr_neg_8_zero>:
    fc9c:	55                   	push   %ebp
    fc9d:	89 e5                	mov    %esp,%ebp
    fc9f:	8b 45 08             	mov    0x8(%ebp),%eax
    fca2:	8b 4d 0c             	mov    0xc(%ebp),%ecx
    fca5:	8b 55 08             	mov    0x8(%ebp),%edx
    fca8:	f0 f6 18             	lock negb (%eax)
    fcab:	0f 94 01             	sete   (%ecx)
    fcae:	90                   	nop
    fcaf:	5d                   	pop    %ebp
    fcb0:	c3                   	ret    

0000fcb1 <ck_pr_not_ptr>:

/* not does not affect condition flags. */
#undef CK_PR_UNARY_V
#define CK_PR_UNARY_V(a, b, c, d, e)
CK_PR_GENERATE(not)
    fcb1:	55                   	push   %ebp
    fcb2:	89 e5                	mov    %esp,%ebp
    fcb4:	8b 45 08             	mov    0x8(%ebp),%eax
    fcb7:	8b 55 08             	mov    0x8(%ebp),%edx
    fcba:	f0 f7 10             	lock notl (%eax)
    fcbd:	90                   	nop
    fcbe:	5d                   	pop    %ebp
    fcbf:	c3                   	ret    

0000fcc0 <ck_pr_not_char>:
    fcc0:	55                   	push   %ebp
    fcc1:	89 e5                	mov    %esp,%ebp
    fcc3:	8b 45 08             	mov    0x8(%ebp),%eax
    fcc6:	8b 55 08             	mov    0x8(%ebp),%edx
    fcc9:	f0 f6 10             	lock notb (%eax)
    fccc:	90                   	nop
    fccd:	5d                   	pop    %ebp
    fcce:	c3                   	ret    

0000fccf <ck_pr_not_int>:
    fccf:	55                   	push   %ebp
    fcd0:	89 e5                	mov    %esp,%ebp
    fcd2:	8b 45 08             	mov    0x8(%ebp),%eax
    fcd5:	8b 55 08             	mov    0x8(%ebp),%edx
    fcd8:	f0 f7 10             	lock notl (%eax)
    fcdb:	90                   	nop
    fcdc:	5d                   	pop    %ebp
    fcdd:	c3                   	ret    

0000fcde <ck_pr_not_uint>:
    fcde:	55                   	push   %ebp
    fcdf:	89 e5                	mov    %esp,%ebp
    fce1:	8b 45 08             	mov    0x8(%ebp),%eax
    fce4:	8b 55 08             	mov    0x8(%ebp),%edx
    fce7:	f0 f7 10             	lock notl (%eax)
    fcea:	90                   	nop
    fceb:	5d                   	pop    %ebp
    fcec:	c3                   	ret    

0000fced <ck_pr_not_32>:
    fced:	55                   	push   %ebp
    fcee:	89 e5                	mov    %esp,%ebp
    fcf0:	8b 45 08             	mov    0x8(%ebp),%eax
    fcf3:	8b 55 08             	mov    0x8(%ebp),%edx
    fcf6:	f0 f7 10             	lock notl (%eax)
    fcf9:	90                   	nop
    fcfa:	5d                   	pop    %ebp
    fcfb:	c3                   	ret    

0000fcfc <ck_pr_not_16>:
    fcfc:	55                   	push   %ebp
    fcfd:	89 e5                	mov    %esp,%ebp
    fcff:	8b 45 08             	mov    0x8(%ebp),%eax
    fd02:	8b 55 08             	mov    0x8(%ebp),%edx
    fd05:	66 f0 f7 10          	lock notw (%eax)
    fd09:	90                   	nop
    fd0a:	5d                   	pop    %ebp
    fd0b:	c3                   	ret    

0000fd0c <ck_pr_not_8>:
    fd0c:	55                   	push   %ebp
    fd0d:	89 e5                	mov    %esp,%ebp
    fd0f:	8b 45 08             	mov    0x8(%ebp),%eax
    fd12:	8b 55 08             	mov    0x8(%ebp),%edx
    fd15:	f0 f6 10             	lock notb (%eax)
    fd18:	90                   	nop
    fd19:	5d                   	pop    %ebp
    fd1a:	c3                   	ret    

0000fd1b <ck_pr_add_ptr>:
	CK_PR_BINARY_S(K, uint, unsigned int, #K "l")		\
	CK_PR_BINARY_S(K, 32, uint32_t, #K "l")			\
	CK_PR_BINARY_S(K, 16, uint16_t, #K "w")			\
	CK_PR_BINARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(add)
    fd1b:	55                   	push   %ebp
    fd1c:	89 e5                	mov    %esp,%ebp
    fd1e:	8b 45 08             	mov    0x8(%ebp),%eax
    fd21:	8b 55 0c             	mov    0xc(%ebp),%edx
    fd24:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fd27:	f0 01 10             	lock add %edx,(%eax)
    fd2a:	90                   	nop
    fd2b:	5d                   	pop    %ebp
    fd2c:	c3                   	ret    

0000fd2d <ck_pr_add_char>:
    fd2d:	55                   	push   %ebp
    fd2e:	89 e5                	mov    %esp,%ebp
    fd30:	83 ec 04             	sub    $0x4,%esp
    fd33:	8b 45 0c             	mov    0xc(%ebp),%eax
    fd36:	88 45 fc             	mov    %al,-0x4(%ebp)
    fd39:	8b 45 08             	mov    0x8(%ebp),%eax
    fd3c:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    fd40:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fd43:	f0 00 10             	lock add %dl,(%eax)
    fd46:	90                   	nop
    fd47:	c9                   	leave  
    fd48:	c3                   	ret    

0000fd49 <ck_pr_add_int>:
    fd49:	55                   	push   %ebp
    fd4a:	89 e5                	mov    %esp,%ebp
    fd4c:	8b 45 08             	mov    0x8(%ebp),%eax
    fd4f:	8b 55 0c             	mov    0xc(%ebp),%edx
    fd52:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fd55:	f0 01 10             	lock add %edx,(%eax)
    fd58:	90                   	nop
    fd59:	5d                   	pop    %ebp
    fd5a:	c3                   	ret    

0000fd5b <ck_pr_add_uint>:
    fd5b:	55                   	push   %ebp
    fd5c:	89 e5                	mov    %esp,%ebp
    fd5e:	8b 45 08             	mov    0x8(%ebp),%eax
    fd61:	8b 55 0c             	mov    0xc(%ebp),%edx
    fd64:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fd67:	f0 01 10             	lock add %edx,(%eax)
    fd6a:	90                   	nop
    fd6b:	5d                   	pop    %ebp
    fd6c:	c3                   	ret    

0000fd6d <ck_pr_add_32>:
    fd6d:	55                   	push   %ebp
    fd6e:	89 e5                	mov    %esp,%ebp
    fd70:	8b 45 08             	mov    0x8(%ebp),%eax
    fd73:	8b 55 0c             	mov    0xc(%ebp),%edx
    fd76:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fd79:	f0 01 10             	lock add %edx,(%eax)
    fd7c:	90                   	nop
    fd7d:	5d                   	pop    %ebp
    fd7e:	c3                   	ret    

0000fd7f <ck_pr_add_16>:
    fd7f:	55                   	push   %ebp
    fd80:	89 e5                	mov    %esp,%ebp
    fd82:	83 ec 04             	sub    $0x4,%esp
    fd85:	8b 45 0c             	mov    0xc(%ebp),%eax
    fd88:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    fd8c:	8b 45 08             	mov    0x8(%ebp),%eax
    fd8f:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    fd93:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fd96:	66 f0 01 10          	lock add %dx,(%eax)
    fd9a:	90                   	nop
    fd9b:	c9                   	leave  
    fd9c:	c3                   	ret    

0000fd9d <ck_pr_add_8>:
    fd9d:	55                   	push   %ebp
    fd9e:	89 e5                	mov    %esp,%ebp
    fda0:	83 ec 04             	sub    $0x4,%esp
    fda3:	8b 45 0c             	mov    0xc(%ebp),%eax
    fda6:	88 45 fc             	mov    %al,-0x4(%ebp)
    fda9:	8b 45 08             	mov    0x8(%ebp),%eax
    fdac:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    fdb0:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fdb3:	f0 00 10             	lock add %dl,(%eax)
    fdb6:	90                   	nop
    fdb7:	c9                   	leave  
    fdb8:	c3                   	ret    

0000fdb9 <ck_pr_sub_ptr>:
CK_PR_GENERATE(sub)
    fdb9:	55                   	push   %ebp
    fdba:	89 e5                	mov    %esp,%ebp
    fdbc:	8b 45 08             	mov    0x8(%ebp),%eax
    fdbf:	8b 55 0c             	mov    0xc(%ebp),%edx
    fdc2:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fdc5:	f0 29 10             	lock sub %edx,(%eax)
    fdc8:	90                   	nop
    fdc9:	5d                   	pop    %ebp
    fdca:	c3                   	ret    

0000fdcb <ck_pr_sub_char>:
    fdcb:	55                   	push   %ebp
    fdcc:	89 e5                	mov    %esp,%ebp
    fdce:	83 ec 04             	sub    $0x4,%esp
    fdd1:	8b 45 0c             	mov    0xc(%ebp),%eax
    fdd4:	88 45 fc             	mov    %al,-0x4(%ebp)
    fdd7:	8b 45 08             	mov    0x8(%ebp),%eax
    fdda:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    fdde:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fde1:	f0 28 10             	lock sub %dl,(%eax)
    fde4:	90                   	nop
    fde5:	c9                   	leave  
    fde6:	c3                   	ret    

0000fde7 <ck_pr_sub_int>:
    fde7:	55                   	push   %ebp
    fde8:	89 e5                	mov    %esp,%ebp
    fdea:	8b 45 08             	mov    0x8(%ebp),%eax
    fded:	8b 55 0c             	mov    0xc(%ebp),%edx
    fdf0:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fdf3:	f0 29 10             	lock sub %edx,(%eax)
    fdf6:	90                   	nop
    fdf7:	5d                   	pop    %ebp
    fdf8:	c3                   	ret    

0000fdf9 <ck_pr_sub_uint>:
    fdf9:	55                   	push   %ebp
    fdfa:	89 e5                	mov    %esp,%ebp
    fdfc:	8b 45 08             	mov    0x8(%ebp),%eax
    fdff:	8b 55 0c             	mov    0xc(%ebp),%edx
    fe02:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fe05:	f0 29 10             	lock sub %edx,(%eax)
    fe08:	90                   	nop
    fe09:	5d                   	pop    %ebp
    fe0a:	c3                   	ret    

0000fe0b <ck_pr_sub_32>:
    fe0b:	55                   	push   %ebp
    fe0c:	89 e5                	mov    %esp,%ebp
    fe0e:	8b 45 08             	mov    0x8(%ebp),%eax
    fe11:	8b 55 0c             	mov    0xc(%ebp),%edx
    fe14:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fe17:	f0 29 10             	lock sub %edx,(%eax)
    fe1a:	90                   	nop
    fe1b:	5d                   	pop    %ebp
    fe1c:	c3                   	ret    

0000fe1d <ck_pr_sub_16>:
    fe1d:	55                   	push   %ebp
    fe1e:	89 e5                	mov    %esp,%ebp
    fe20:	83 ec 04             	sub    $0x4,%esp
    fe23:	8b 45 0c             	mov    0xc(%ebp),%eax
    fe26:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    fe2a:	8b 45 08             	mov    0x8(%ebp),%eax
    fe2d:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    fe31:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fe34:	66 f0 29 10          	lock sub %dx,(%eax)
    fe38:	90                   	nop
    fe39:	c9                   	leave  
    fe3a:	c3                   	ret    

0000fe3b <ck_pr_sub_8>:
    fe3b:	55                   	push   %ebp
    fe3c:	89 e5                	mov    %esp,%ebp
    fe3e:	83 ec 04             	sub    $0x4,%esp
    fe41:	8b 45 0c             	mov    0xc(%ebp),%eax
    fe44:	88 45 fc             	mov    %al,-0x4(%ebp)
    fe47:	8b 45 08             	mov    0x8(%ebp),%eax
    fe4a:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    fe4e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fe51:	f0 28 10             	lock sub %dl,(%eax)
    fe54:	90                   	nop
    fe55:	c9                   	leave  
    fe56:	c3                   	ret    

0000fe57 <ck_pr_and_ptr>:
CK_PR_GENERATE(and)
    fe57:	55                   	push   %ebp
    fe58:	89 e5                	mov    %esp,%ebp
    fe5a:	8b 45 08             	mov    0x8(%ebp),%eax
    fe5d:	8b 55 0c             	mov    0xc(%ebp),%edx
    fe60:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fe63:	f0 21 10             	lock and %edx,(%eax)
    fe66:	90                   	nop
    fe67:	5d                   	pop    %ebp
    fe68:	c3                   	ret    

0000fe69 <ck_pr_and_char>:
    fe69:	55                   	push   %ebp
    fe6a:	89 e5                	mov    %esp,%ebp
    fe6c:	83 ec 04             	sub    $0x4,%esp
    fe6f:	8b 45 0c             	mov    0xc(%ebp),%eax
    fe72:	88 45 fc             	mov    %al,-0x4(%ebp)
    fe75:	8b 45 08             	mov    0x8(%ebp),%eax
    fe78:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    fe7c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fe7f:	f0 20 10             	lock and %dl,(%eax)
    fe82:	90                   	nop
    fe83:	c9                   	leave  
    fe84:	c3                   	ret    

0000fe85 <ck_pr_and_int>:
    fe85:	55                   	push   %ebp
    fe86:	89 e5                	mov    %esp,%ebp
    fe88:	8b 45 08             	mov    0x8(%ebp),%eax
    fe8b:	8b 55 0c             	mov    0xc(%ebp),%edx
    fe8e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fe91:	f0 21 10             	lock and %edx,(%eax)
    fe94:	90                   	nop
    fe95:	5d                   	pop    %ebp
    fe96:	c3                   	ret    

0000fe97 <ck_pr_and_uint>:
    fe97:	55                   	push   %ebp
    fe98:	89 e5                	mov    %esp,%ebp
    fe9a:	8b 45 08             	mov    0x8(%ebp),%eax
    fe9d:	8b 55 0c             	mov    0xc(%ebp),%edx
    fea0:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fea3:	f0 21 10             	lock and %edx,(%eax)
    fea6:	90                   	nop
    fea7:	5d                   	pop    %ebp
    fea8:	c3                   	ret    

0000fea9 <ck_pr_and_32>:
    fea9:	55                   	push   %ebp
    feaa:	89 e5                	mov    %esp,%ebp
    feac:	8b 45 08             	mov    0x8(%ebp),%eax
    feaf:	8b 55 0c             	mov    0xc(%ebp),%edx
    feb2:	8b 4d 08             	mov    0x8(%ebp),%ecx
    feb5:	f0 21 10             	lock and %edx,(%eax)
    feb8:	90                   	nop
    feb9:	5d                   	pop    %ebp
    feba:	c3                   	ret    

0000febb <ck_pr_and_16>:
    febb:	55                   	push   %ebp
    febc:	89 e5                	mov    %esp,%ebp
    febe:	83 ec 04             	sub    $0x4,%esp
    fec1:	8b 45 0c             	mov    0xc(%ebp),%eax
    fec4:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    fec8:	8b 45 08             	mov    0x8(%ebp),%eax
    fecb:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    fecf:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fed2:	66 f0 21 10          	lock and %dx,(%eax)
    fed6:	90                   	nop
    fed7:	c9                   	leave  
    fed8:	c3                   	ret    

0000fed9 <ck_pr_and_8>:
    fed9:	55                   	push   %ebp
    feda:	89 e5                	mov    %esp,%ebp
    fedc:	83 ec 04             	sub    $0x4,%esp
    fedf:	8b 45 0c             	mov    0xc(%ebp),%eax
    fee2:	88 45 fc             	mov    %al,-0x4(%ebp)
    fee5:	8b 45 08             	mov    0x8(%ebp),%eax
    fee8:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    feec:	8b 4d 08             	mov    0x8(%ebp),%ecx
    feef:	f0 20 10             	lock and %dl,(%eax)
    fef2:	90                   	nop
    fef3:	c9                   	leave  
    fef4:	c3                   	ret    

0000fef5 <ck_pr_or_ptr>:
CK_PR_GENERATE(or)
    fef5:	55                   	push   %ebp
    fef6:	89 e5                	mov    %esp,%ebp
    fef8:	8b 45 08             	mov    0x8(%ebp),%eax
    fefb:	8b 55 0c             	mov    0xc(%ebp),%edx
    fefe:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ff01:	f0 09 10             	lock or %edx,(%eax)
    ff04:	90                   	nop
    ff05:	5d                   	pop    %ebp
    ff06:	c3                   	ret    

0000ff07 <ck_pr_or_char>:
    ff07:	55                   	push   %ebp
    ff08:	89 e5                	mov    %esp,%ebp
    ff0a:	83 ec 04             	sub    $0x4,%esp
    ff0d:	8b 45 0c             	mov    0xc(%ebp),%eax
    ff10:	88 45 fc             	mov    %al,-0x4(%ebp)
    ff13:	8b 45 08             	mov    0x8(%ebp),%eax
    ff16:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    ff1a:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ff1d:	f0 08 10             	lock or %dl,(%eax)
    ff20:	90                   	nop
    ff21:	c9                   	leave  
    ff22:	c3                   	ret    

0000ff23 <ck_pr_or_int>:
    ff23:	55                   	push   %ebp
    ff24:	89 e5                	mov    %esp,%ebp
    ff26:	8b 45 08             	mov    0x8(%ebp),%eax
    ff29:	8b 55 0c             	mov    0xc(%ebp),%edx
    ff2c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ff2f:	f0 09 10             	lock or %edx,(%eax)
    ff32:	90                   	nop
    ff33:	5d                   	pop    %ebp
    ff34:	c3                   	ret    

0000ff35 <ck_pr_or_uint>:
    ff35:	55                   	push   %ebp
    ff36:	89 e5                	mov    %esp,%ebp
    ff38:	8b 45 08             	mov    0x8(%ebp),%eax
    ff3b:	8b 55 0c             	mov    0xc(%ebp),%edx
    ff3e:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ff41:	f0 09 10             	lock or %edx,(%eax)
    ff44:	90                   	nop
    ff45:	5d                   	pop    %ebp
    ff46:	c3                   	ret    

0000ff47 <ck_pr_or_32>:
    ff47:	55                   	push   %ebp
    ff48:	89 e5                	mov    %esp,%ebp
    ff4a:	8b 45 08             	mov    0x8(%ebp),%eax
    ff4d:	8b 55 0c             	mov    0xc(%ebp),%edx
    ff50:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ff53:	f0 09 10             	lock or %edx,(%eax)
    ff56:	90                   	nop
    ff57:	5d                   	pop    %ebp
    ff58:	c3                   	ret    

0000ff59 <ck_pr_or_16>:
    ff59:	55                   	push   %ebp
    ff5a:	89 e5                	mov    %esp,%ebp
    ff5c:	83 ec 04             	sub    $0x4,%esp
    ff5f:	8b 45 0c             	mov    0xc(%ebp),%eax
    ff62:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
    ff66:	8b 45 08             	mov    0x8(%ebp),%eax
    ff69:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
    ff6d:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ff70:	66 f0 09 10          	lock or %dx,(%eax)
    ff74:	90                   	nop
    ff75:	c9                   	leave  
    ff76:	c3                   	ret    

0000ff77 <ck_pr_or_8>:
    ff77:	55                   	push   %ebp
    ff78:	89 e5                	mov    %esp,%ebp
    ff7a:	83 ec 04             	sub    $0x4,%esp
    ff7d:	8b 45 0c             	mov    0xc(%ebp),%eax
    ff80:	88 45 fc             	mov    %al,-0x4(%ebp)
    ff83:	8b 45 08             	mov    0x8(%ebp),%eax
    ff86:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    ff8a:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ff8d:	f0 08 10             	lock or %dl,(%eax)
    ff90:	90                   	nop
    ff91:	c9                   	leave  
    ff92:	c3                   	ret    

0000ff93 <ck_pr_xor_ptr>:
CK_PR_GENERATE(xor)
    ff93:	55                   	push   %ebp
    ff94:	89 e5                	mov    %esp,%ebp
    ff96:	8b 45 08             	mov    0x8(%ebp),%eax
    ff99:	8b 55 0c             	mov    0xc(%ebp),%edx
    ff9c:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ff9f:	f0 31 10             	lock xor %edx,(%eax)
    ffa2:	90                   	nop
    ffa3:	5d                   	pop    %ebp
    ffa4:	c3                   	ret    

0000ffa5 <ck_pr_xor_char>:
    ffa5:	55                   	push   %ebp
    ffa6:	89 e5                	mov    %esp,%ebp
    ffa8:	83 ec 04             	sub    $0x4,%esp
    ffab:	8b 45 0c             	mov    0xc(%ebp),%eax
    ffae:	88 45 fc             	mov    %al,-0x4(%ebp)
    ffb1:	8b 45 08             	mov    0x8(%ebp),%eax
    ffb4:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
    ffb8:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ffbb:	f0 30 10             	lock xor %dl,(%eax)
    ffbe:	90                   	nop
    ffbf:	c9                   	leave  
    ffc0:	c3                   	ret    

0000ffc1 <ck_pr_xor_int>:
    ffc1:	55                   	push   %ebp
    ffc2:	89 e5                	mov    %esp,%ebp
    ffc4:	8b 45 08             	mov    0x8(%ebp),%eax
    ffc7:	8b 55 0c             	mov    0xc(%ebp),%edx
    ffca:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ffcd:	f0 31 10             	lock xor %edx,(%eax)
    ffd0:	90                   	nop
    ffd1:	5d                   	pop    %ebp
    ffd2:	c3                   	ret    

0000ffd3 <ck_pr_xor_uint>:
    ffd3:	55                   	push   %ebp
    ffd4:	89 e5                	mov    %esp,%ebp
    ffd6:	8b 45 08             	mov    0x8(%ebp),%eax
    ffd9:	8b 55 0c             	mov    0xc(%ebp),%edx
    ffdc:	8b 4d 08             	mov    0x8(%ebp),%ecx
    ffdf:	f0 31 10             	lock xor %edx,(%eax)
    ffe2:	90                   	nop
    ffe3:	5d                   	pop    %ebp
    ffe4:	c3                   	ret    

0000ffe5 <ck_pr_xor_32>:
    ffe5:	55                   	push   %ebp
    ffe6:	89 e5                	mov    %esp,%ebp
    ffe8:	8b 45 08             	mov    0x8(%ebp),%eax
    ffeb:	8b 55 0c             	mov    0xc(%ebp),%edx
    ffee:	8b 4d 08             	mov    0x8(%ebp),%ecx
    fff1:	f0 31 10             	lock xor %edx,(%eax)
    fff4:	90                   	nop
    fff5:	5d                   	pop    %ebp
    fff6:	c3                   	ret    

0000fff7 <ck_pr_xor_16>:
    fff7:	55                   	push   %ebp
    fff8:	89 e5                	mov    %esp,%ebp
    fffa:	83 ec 04             	sub    $0x4,%esp
    fffd:	8b 45 0c             	mov    0xc(%ebp),%eax
   10000:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   10004:	8b 45 08             	mov    0x8(%ebp),%eax
   10007:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1000b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1000e:	66 f0 31 10          	lock xor %dx,(%eax)
   10012:	90                   	nop
   10013:	c9                   	leave  
   10014:	c3                   	ret    

00010015 <ck_pr_xor_8>:
   10015:	55                   	push   %ebp
   10016:	89 e5                	mov    %esp,%ebp
   10018:	83 ec 04             	sub    $0x4,%esp
   1001b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1001e:	88 45 fc             	mov    %al,-0x4(%ebp)
   10021:	8b 45 08             	mov    0x8(%ebp),%eax
   10024:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   10028:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1002b:	f0 30 10             	lock xor %dl,(%eax)
   1002e:	90                   	nop
   1002f:	c9                   	leave  
   10030:	c3                   	ret    

00010031 <ck_pr_cas_ptr>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return z;							\
	}

CK_PR_CAS(ptr, void, void *, char, "cmpxchgl")
   10031:	55                   	push   %ebp
   10032:	89 e5                	mov    %esp,%ebp
   10034:	53                   	push   %ebx
   10035:	83 ec 10             	sub    $0x10,%esp
   10038:	8b 55 08             	mov    0x8(%ebp),%edx
   1003b:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1003e:	8b 45 0c             	mov    0xc(%ebp),%eax
   10041:	8b 5d 08             	mov    0x8(%ebp),%ebx
   10044:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   10048:	0f 94 c0             	sete   %al
   1004b:	88 45 fb             	mov    %al,-0x5(%ebp)
   1004e:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   10052:	83 c4 10             	add    $0x10,%esp
   10055:	5b                   	pop    %ebx
   10056:	5d                   	pop    %ebp
   10057:	c3                   	ret    

00010058 <ck_pr_cas_char>:

#define CK_PR_CAS_S(S, T, I) CK_PR_CAS(S, T, T, T, I)

CK_PR_CAS_S(char, char, "cmpxchgb")
   10058:	55                   	push   %ebp
   10059:	89 e5                	mov    %esp,%ebp
   1005b:	53                   	push   %ebx
   1005c:	83 ec 18             	sub    $0x18,%esp
   1005f:	8b 55 0c             	mov    0xc(%ebp),%edx
   10062:	8b 45 10             	mov    0x10(%ebp),%eax
   10065:	88 55 e8             	mov    %dl,-0x18(%ebp)
   10068:	88 45 e4             	mov    %al,-0x1c(%ebp)
   1006b:	8b 55 08             	mov    0x8(%ebp),%edx
   1006e:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   10072:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   10076:	8b 5d 08             	mov    0x8(%ebp),%ebx
   10079:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   1007d:	0f 94 c0             	sete   %al
   10080:	88 45 fb             	mov    %al,-0x5(%ebp)
   10083:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   10087:	83 c4 18             	add    $0x18,%esp
   1008a:	5b                   	pop    %ebx
   1008b:	5d                   	pop    %ebp
   1008c:	c3                   	ret    

0001008d <ck_pr_cas_int>:
CK_PR_CAS_S(int, int, "cmpxchgl")
   1008d:	55                   	push   %ebp
   1008e:	89 e5                	mov    %esp,%ebp
   10090:	53                   	push   %ebx
   10091:	83 ec 10             	sub    $0x10,%esp
   10094:	8b 55 08             	mov    0x8(%ebp),%edx
   10097:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1009a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1009d:	8b 5d 08             	mov    0x8(%ebp),%ebx
   100a0:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   100a4:	0f 94 c0             	sete   %al
   100a7:	88 45 fb             	mov    %al,-0x5(%ebp)
   100aa:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   100ae:	83 c4 10             	add    $0x10,%esp
   100b1:	5b                   	pop    %ebx
   100b2:	5d                   	pop    %ebp
   100b3:	c3                   	ret    

000100b4 <ck_pr_cas_uint>:
CK_PR_CAS_S(uint, unsigned int, "cmpxchgl")
   100b4:	55                   	push   %ebp
   100b5:	89 e5                	mov    %esp,%ebp
   100b7:	53                   	push   %ebx
   100b8:	83 ec 10             	sub    $0x10,%esp
   100bb:	8b 55 08             	mov    0x8(%ebp),%edx
   100be:	8b 4d 10             	mov    0x10(%ebp),%ecx
   100c1:	8b 45 0c             	mov    0xc(%ebp),%eax
   100c4:	8b 5d 08             	mov    0x8(%ebp),%ebx
   100c7:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   100cb:	0f 94 c0             	sete   %al
   100ce:	88 45 fb             	mov    %al,-0x5(%ebp)
   100d1:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   100d5:	83 c4 10             	add    $0x10,%esp
   100d8:	5b                   	pop    %ebx
   100d9:	5d                   	pop    %ebp
   100da:	c3                   	ret    

000100db <ck_pr_cas_32>:
CK_PR_CAS_S(32, uint32_t, "cmpxchgl")
   100db:	55                   	push   %ebp
   100dc:	89 e5                	mov    %esp,%ebp
   100de:	53                   	push   %ebx
   100df:	83 ec 10             	sub    $0x10,%esp
   100e2:	8b 55 08             	mov    0x8(%ebp),%edx
   100e5:	8b 4d 10             	mov    0x10(%ebp),%ecx
   100e8:	8b 45 0c             	mov    0xc(%ebp),%eax
   100eb:	8b 5d 08             	mov    0x8(%ebp),%ebx
   100ee:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   100f2:	0f 94 c0             	sete   %al
   100f5:	88 45 fb             	mov    %al,-0x5(%ebp)
   100f8:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   100fc:	83 c4 10             	add    $0x10,%esp
   100ff:	5b                   	pop    %ebx
   10100:	5d                   	pop    %ebp
   10101:	c3                   	ret    

00010102 <ck_pr_cas_16>:
CK_PR_CAS_S(16, uint16_t, "cmpxchgw")
   10102:	55                   	push   %ebp
   10103:	89 e5                	mov    %esp,%ebp
   10105:	53                   	push   %ebx
   10106:	83 ec 18             	sub    $0x18,%esp
   10109:	8b 55 0c             	mov    0xc(%ebp),%edx
   1010c:	8b 45 10             	mov    0x10(%ebp),%eax
   1010f:	66 89 55 e8          	mov    %dx,-0x18(%ebp)
   10113:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   10117:	8b 55 08             	mov    0x8(%ebp),%edx
   1011a:	0f b7 4d e4          	movzwl -0x1c(%ebp),%ecx
   1011e:	0f b7 45 e8          	movzwl -0x18(%ebp),%eax
   10122:	8b 5d 08             	mov    0x8(%ebp),%ebx
   10125:	66 f0 0f b1 0a       	lock cmpxchg %cx,(%edx)
   1012a:	0f 94 c0             	sete   %al
   1012d:	88 45 fb             	mov    %al,-0x5(%ebp)
   10130:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   10134:	83 c4 18             	add    $0x18,%esp
   10137:	5b                   	pop    %ebx
   10138:	5d                   	pop    %ebp
   10139:	c3                   	ret    

0001013a <ck_pr_cas_8>:
CK_PR_CAS_S(8,  uint8_t,  "cmpxchgb")
   1013a:	55                   	push   %ebp
   1013b:	89 e5                	mov    %esp,%ebp
   1013d:	53                   	push   %ebx
   1013e:	83 ec 18             	sub    $0x18,%esp
   10141:	8b 55 0c             	mov    0xc(%ebp),%edx
   10144:	8b 45 10             	mov    0x10(%ebp),%eax
   10147:	88 55 e8             	mov    %dl,-0x18(%ebp)
   1014a:	88 45 e4             	mov    %al,-0x1c(%ebp)
   1014d:	8b 55 08             	mov    0x8(%ebp),%edx
   10150:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   10154:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   10158:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1015b:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   1015f:	0f 94 c0             	sete   %al
   10162:	88 45 fb             	mov    %al,-0x5(%ebp)
   10165:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   10169:	83 c4 18             	add    $0x18,%esp
   1016c:	5b                   	pop    %ebx
   1016d:	5d                   	pop    %ebp
   1016e:	c3                   	ret    

0001016f <ck_pr_cas_ptr_value>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return (bool)z;							\
	}

CK_PR_CAS_O(ptr, void, void *, char, "l", "eax")
   1016f:	55                   	push   %ebp
   10170:	89 e5                	mov    %esp,%ebp
   10172:	56                   	push   %esi
   10173:	53                   	push   %ebx
   10174:	83 ec 10             	sub    $0x10,%esp
   10177:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1017a:	8b 75 14             	mov    0x14(%ebp),%esi
   1017d:	8b 55 10             	mov    0x10(%ebp),%edx
   10180:	8b 45 0c             	mov    0xc(%ebp),%eax
   10183:	8b 4d 08             	mov    0x8(%ebp),%ecx
   10186:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1018a:	89 06                	mov    %eax,(%esi)
   1018c:	0f 94 c0             	sete   %al
   1018f:	88 45 f7             	mov    %al,-0x9(%ebp)
   10192:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   10196:	83 c4 10             	add    $0x10,%esp
   10199:	5b                   	pop    %ebx
   1019a:	5e                   	pop    %esi
   1019b:	5d                   	pop    %ebp
   1019c:	c3                   	ret    

0001019d <ck_pr_cas_char_value>:

#define CK_PR_CAS_O_S(S, T, I, R)	\
	CK_PR_CAS_O(S, T, T, T, I, R)

CK_PR_CAS_O_S(char, char, "b", "al")
   1019d:	55                   	push   %ebp
   1019e:	89 e5                	mov    %esp,%ebp
   101a0:	56                   	push   %esi
   101a1:	53                   	push   %ebx
   101a2:	83 ec 18             	sub    $0x18,%esp
   101a5:	8b 55 0c             	mov    0xc(%ebp),%edx
   101a8:	8b 45 10             	mov    0x10(%ebp),%eax
   101ab:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   101ae:	88 45 e0             	mov    %al,-0x20(%ebp)
   101b1:	8b 5d 08             	mov    0x8(%ebp),%ebx
   101b4:	8b 75 14             	mov    0x14(%ebp),%esi
   101b7:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   101bb:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   101bf:	8b 4d 08             	mov    0x8(%ebp),%ecx
   101c2:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   101c6:	88 06                	mov    %al,(%esi)
   101c8:	0f 94 c0             	sete   %al
   101cb:	88 45 f7             	mov    %al,-0x9(%ebp)
   101ce:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   101d2:	83 c4 18             	add    $0x18,%esp
   101d5:	5b                   	pop    %ebx
   101d6:	5e                   	pop    %esi
   101d7:	5d                   	pop    %ebp
   101d8:	c3                   	ret    

000101d9 <ck_pr_cas_int_value>:
CK_PR_CAS_O_S(int, int, "l", "eax")
   101d9:	55                   	push   %ebp
   101da:	89 e5                	mov    %esp,%ebp
   101dc:	56                   	push   %esi
   101dd:	53                   	push   %ebx
   101de:	83 ec 10             	sub    $0x10,%esp
   101e1:	8b 5d 08             	mov    0x8(%ebp),%ebx
   101e4:	8b 75 14             	mov    0x14(%ebp),%esi
   101e7:	8b 55 10             	mov    0x10(%ebp),%edx
   101ea:	8b 45 0c             	mov    0xc(%ebp),%eax
   101ed:	8b 4d 08             	mov    0x8(%ebp),%ecx
   101f0:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   101f4:	89 06                	mov    %eax,(%esi)
   101f6:	0f 94 c0             	sete   %al
   101f9:	88 45 f7             	mov    %al,-0x9(%ebp)
   101fc:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   10200:	83 c4 10             	add    $0x10,%esp
   10203:	5b                   	pop    %ebx
   10204:	5e                   	pop    %esi
   10205:	5d                   	pop    %ebp
   10206:	c3                   	ret    

00010207 <ck_pr_cas_uint_value>:
CK_PR_CAS_O_S(uint, unsigned int, "l", "eax")
   10207:	55                   	push   %ebp
   10208:	89 e5                	mov    %esp,%ebp
   1020a:	56                   	push   %esi
   1020b:	53                   	push   %ebx
   1020c:	83 ec 10             	sub    $0x10,%esp
   1020f:	8b 5d 08             	mov    0x8(%ebp),%ebx
   10212:	8b 75 14             	mov    0x14(%ebp),%esi
   10215:	8b 55 10             	mov    0x10(%ebp),%edx
   10218:	8b 45 0c             	mov    0xc(%ebp),%eax
   1021b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1021e:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   10222:	89 06                	mov    %eax,(%esi)
   10224:	0f 94 c0             	sete   %al
   10227:	88 45 f7             	mov    %al,-0x9(%ebp)
   1022a:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1022e:	83 c4 10             	add    $0x10,%esp
   10231:	5b                   	pop    %ebx
   10232:	5e                   	pop    %esi
   10233:	5d                   	pop    %ebp
   10234:	c3                   	ret    

00010235 <ck_pr_cas_32_value>:
CK_PR_CAS_O_S(32, uint32_t, "l", "eax")
   10235:	55                   	push   %ebp
   10236:	89 e5                	mov    %esp,%ebp
   10238:	56                   	push   %esi
   10239:	53                   	push   %ebx
   1023a:	83 ec 10             	sub    $0x10,%esp
   1023d:	8b 5d 08             	mov    0x8(%ebp),%ebx
   10240:	8b 75 14             	mov    0x14(%ebp),%esi
   10243:	8b 55 10             	mov    0x10(%ebp),%edx
   10246:	8b 45 0c             	mov    0xc(%ebp),%eax
   10249:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1024c:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   10250:	89 06                	mov    %eax,(%esi)
   10252:	0f 94 c0             	sete   %al
   10255:	88 45 f7             	mov    %al,-0x9(%ebp)
   10258:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1025c:	83 c4 10             	add    $0x10,%esp
   1025f:	5b                   	pop    %ebx
   10260:	5e                   	pop    %esi
   10261:	5d                   	pop    %ebp
   10262:	c3                   	ret    

00010263 <ck_pr_cas_16_value>:
CK_PR_CAS_O_S(16, uint16_t, "w", "ax")
   10263:	55                   	push   %ebp
   10264:	89 e5                	mov    %esp,%ebp
   10266:	56                   	push   %esi
   10267:	53                   	push   %ebx
   10268:	83 ec 18             	sub    $0x18,%esp
   1026b:	8b 55 0c             	mov    0xc(%ebp),%edx
   1026e:	8b 45 10             	mov    0x10(%ebp),%eax
   10271:	66 89 55 e4          	mov    %dx,-0x1c(%ebp)
   10275:	66 89 45 e0          	mov    %ax,-0x20(%ebp)
   10279:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1027c:	8b 75 14             	mov    0x14(%ebp),%esi
   1027f:	0f b7 55 e0          	movzwl -0x20(%ebp),%edx
   10283:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
   10287:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1028a:	66 f0 0f b1 13       	lock cmpxchg %dx,(%ebx)
   1028f:	66 89 06             	mov    %ax,(%esi)
   10292:	0f 94 c0             	sete   %al
   10295:	88 45 f7             	mov    %al,-0x9(%ebp)
   10298:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1029c:	83 c4 18             	add    $0x18,%esp
   1029f:	5b                   	pop    %ebx
   102a0:	5e                   	pop    %esi
   102a1:	5d                   	pop    %ebp
   102a2:	c3                   	ret    

000102a3 <ck_pr_cas_8_value>:
CK_PR_CAS_O_S(8,  uint8_t,  "b", "al")
   102a3:	55                   	push   %ebp
   102a4:	89 e5                	mov    %esp,%ebp
   102a6:	56                   	push   %esi
   102a7:	53                   	push   %ebx
   102a8:	83 ec 18             	sub    $0x18,%esp
   102ab:	8b 55 0c             	mov    0xc(%ebp),%edx
   102ae:	8b 45 10             	mov    0x10(%ebp),%eax
   102b1:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   102b4:	88 45 e0             	mov    %al,-0x20(%ebp)
   102b7:	8b 5d 08             	mov    0x8(%ebp),%ebx
   102ba:	8b 75 14             	mov    0x14(%ebp),%esi
   102bd:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   102c1:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   102c5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   102c8:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   102cc:	88 06                	mov    %al,(%esi)
   102ce:	0f 94 c0             	sete   %al
   102d1:	88 45 f7             	mov    %al,-0x9(%ebp)
   102d4:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   102d8:	83 c4 18             	add    $0x18,%esp
   102db:	5b                   	pop    %ebx
   102dc:	5e                   	pop    %esi
   102dd:	5d                   	pop    %ebp
   102de:	c3                   	ret    

000102df <ck_pr_btc_ptr>:
	CK_PR_BT_S(K, uint, unsigned int, #K "l %2, %0")	\
	CK_PR_BT_S(K, int, int, #K "l %2, %0")			\
	CK_PR_BT_S(K, 32, uint32_t, #K "l %2, %0")		\
	CK_PR_BT_S(K, 16, uint16_t, #K "w %w2, %0")

CK_PR_GENERATE(btc)
   102df:	55                   	push   %ebp
   102e0:	89 e5                	mov    %esp,%ebp
   102e2:	83 ec 10             	sub    $0x10,%esp
   102e5:	8b 55 08             	mov    0x8(%ebp),%edx
   102e8:	8b 45 0c             	mov    0xc(%ebp),%eax
   102eb:	8b 4d 08             	mov    0x8(%ebp),%ecx
   102ee:	f0 0f bb 02          	lock btc %eax,(%edx)
   102f2:	0f 92 c0             	setb   %al
   102f5:	88 45 ff             	mov    %al,-0x1(%ebp)
   102f8:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   102fc:	c9                   	leave  
   102fd:	c3                   	ret    

000102fe <ck_pr_btc_uint>:
   102fe:	55                   	push   %ebp
   102ff:	89 e5                	mov    %esp,%ebp
   10301:	83 ec 10             	sub    $0x10,%esp
   10304:	8b 55 08             	mov    0x8(%ebp),%edx
   10307:	8b 45 0c             	mov    0xc(%ebp),%eax
   1030a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1030d:	f0 0f bb 02          	lock btc %eax,(%edx)
   10311:	0f 92 c0             	setb   %al
   10314:	88 45 ff             	mov    %al,-0x1(%ebp)
   10317:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1031b:	c9                   	leave  
   1031c:	c3                   	ret    

0001031d <ck_pr_btc_int>:
   1031d:	55                   	push   %ebp
   1031e:	89 e5                	mov    %esp,%ebp
   10320:	83 ec 10             	sub    $0x10,%esp
   10323:	8b 45 0c             	mov    0xc(%ebp),%eax
   10326:	8b 55 08             	mov    0x8(%ebp),%edx
   10329:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1032c:	f0 0f bb 02          	lock btc %eax,(%edx)
   10330:	0f 92 c0             	setb   %al
   10333:	88 45 ff             	mov    %al,-0x1(%ebp)
   10336:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1033a:	c9                   	leave  
   1033b:	c3                   	ret    

0001033c <ck_pr_btc_32>:
   1033c:	55                   	push   %ebp
   1033d:	89 e5                	mov    %esp,%ebp
   1033f:	83 ec 10             	sub    $0x10,%esp
   10342:	8b 55 08             	mov    0x8(%ebp),%edx
   10345:	8b 45 0c             	mov    0xc(%ebp),%eax
   10348:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1034b:	f0 0f bb 02          	lock btc %eax,(%edx)
   1034f:	0f 92 c0             	setb   %al
   10352:	88 45 ff             	mov    %al,-0x1(%ebp)
   10355:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   10359:	c9                   	leave  
   1035a:	c3                   	ret    

0001035b <ck_pr_btc_16>:
   1035b:	55                   	push   %ebp
   1035c:	89 e5                	mov    %esp,%ebp
   1035e:	83 ec 10             	sub    $0x10,%esp
   10361:	8b 45 0c             	mov    0xc(%ebp),%eax
   10364:	8b 55 08             	mov    0x8(%ebp),%edx
   10367:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1036a:	66 f0 0f bb 02       	lock btc %ax,(%edx)
   1036f:	0f 92 c0             	setb   %al
   10372:	88 45 ff             	mov    %al,-0x1(%ebp)
   10375:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   10379:	c9                   	leave  
   1037a:	c3                   	ret    

0001037b <ck_pr_bts_ptr>:
CK_PR_GENERATE(bts)
   1037b:	55                   	push   %ebp
   1037c:	89 e5                	mov    %esp,%ebp
   1037e:	83 ec 10             	sub    $0x10,%esp
   10381:	8b 55 08             	mov    0x8(%ebp),%edx
   10384:	8b 45 0c             	mov    0xc(%ebp),%eax
   10387:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1038a:	f0 0f ab 02          	lock bts %eax,(%edx)
   1038e:	0f 92 c0             	setb   %al
   10391:	88 45 ff             	mov    %al,-0x1(%ebp)
   10394:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   10398:	c9                   	leave  
   10399:	c3                   	ret    

0001039a <ck_pr_bts_uint>:
   1039a:	55                   	push   %ebp
   1039b:	89 e5                	mov    %esp,%ebp
   1039d:	83 ec 10             	sub    $0x10,%esp
   103a0:	8b 55 08             	mov    0x8(%ebp),%edx
   103a3:	8b 45 0c             	mov    0xc(%ebp),%eax
   103a6:	8b 4d 08             	mov    0x8(%ebp),%ecx
   103a9:	f0 0f ab 02          	lock bts %eax,(%edx)
   103ad:	0f 92 c0             	setb   %al
   103b0:	88 45 ff             	mov    %al,-0x1(%ebp)
   103b3:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   103b7:	c9                   	leave  
   103b8:	c3                   	ret    

000103b9 <ck_pr_bts_int>:
   103b9:	55                   	push   %ebp
   103ba:	89 e5                	mov    %esp,%ebp
   103bc:	83 ec 10             	sub    $0x10,%esp
   103bf:	8b 45 0c             	mov    0xc(%ebp),%eax
   103c2:	8b 55 08             	mov    0x8(%ebp),%edx
   103c5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   103c8:	f0 0f ab 02          	lock bts %eax,(%edx)
   103cc:	0f 92 c0             	setb   %al
   103cf:	88 45 ff             	mov    %al,-0x1(%ebp)
   103d2:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   103d6:	c9                   	leave  
   103d7:	c3                   	ret    

000103d8 <ck_pr_bts_32>:
   103d8:	55                   	push   %ebp
   103d9:	89 e5                	mov    %esp,%ebp
   103db:	83 ec 10             	sub    $0x10,%esp
   103de:	8b 55 08             	mov    0x8(%ebp),%edx
   103e1:	8b 45 0c             	mov    0xc(%ebp),%eax
   103e4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   103e7:	f0 0f ab 02          	lock bts %eax,(%edx)
   103eb:	0f 92 c0             	setb   %al
   103ee:	88 45 ff             	mov    %al,-0x1(%ebp)
   103f1:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   103f5:	c9                   	leave  
   103f6:	c3                   	ret    

000103f7 <ck_pr_bts_16>:
   103f7:	55                   	push   %ebp
   103f8:	89 e5                	mov    %esp,%ebp
   103fa:	83 ec 10             	sub    $0x10,%esp
   103fd:	8b 45 0c             	mov    0xc(%ebp),%eax
   10400:	8b 55 08             	mov    0x8(%ebp),%edx
   10403:	8b 4d 08             	mov    0x8(%ebp),%ecx
   10406:	66 f0 0f ab 02       	lock bts %ax,(%edx)
   1040b:	0f 92 c0             	setb   %al
   1040e:	88 45 ff             	mov    %al,-0x1(%ebp)
   10411:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   10415:	c9                   	leave  
   10416:	c3                   	ret    

00010417 <ck_pr_btr_ptr>:
CK_PR_GENERATE(btr)
   10417:	55                   	push   %ebp
   10418:	89 e5                	mov    %esp,%ebp
   1041a:	83 ec 10             	sub    $0x10,%esp
   1041d:	8b 55 08             	mov    0x8(%ebp),%edx
   10420:	8b 45 0c             	mov    0xc(%ebp),%eax
   10423:	8b 4d 08             	mov    0x8(%ebp),%ecx
   10426:	f0 0f b3 02          	lock btr %eax,(%edx)
   1042a:	0f 92 c0             	setb   %al
   1042d:	88 45 ff             	mov    %al,-0x1(%ebp)
   10430:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   10434:	c9                   	leave  
   10435:	c3                   	ret    

00010436 <ck_pr_btr_uint>:
   10436:	55                   	push   %ebp
   10437:	89 e5                	mov    %esp,%ebp
   10439:	83 ec 10             	sub    $0x10,%esp
   1043c:	8b 55 08             	mov    0x8(%ebp),%edx
   1043f:	8b 45 0c             	mov    0xc(%ebp),%eax
   10442:	8b 4d 08             	mov    0x8(%ebp),%ecx
   10445:	f0 0f b3 02          	lock btr %eax,(%edx)
   10449:	0f 92 c0             	setb   %al
   1044c:	88 45 ff             	mov    %al,-0x1(%ebp)
   1044f:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   10453:	c9                   	leave  
   10454:	c3                   	ret    

00010455 <ck_pr_btr_int>:
   10455:	55                   	push   %ebp
   10456:	89 e5                	mov    %esp,%ebp
   10458:	83 ec 10             	sub    $0x10,%esp
   1045b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1045e:	8b 55 08             	mov    0x8(%ebp),%edx
   10461:	8b 4d 08             	mov    0x8(%ebp),%ecx
   10464:	f0 0f b3 02          	lock btr %eax,(%edx)
   10468:	0f 92 c0             	setb   %al
   1046b:	88 45 ff             	mov    %al,-0x1(%ebp)
   1046e:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   10472:	c9                   	leave  
   10473:	c3                   	ret    

00010474 <ck_pr_btr_32>:
   10474:	55                   	push   %ebp
   10475:	89 e5                	mov    %esp,%ebp
   10477:	83 ec 10             	sub    $0x10,%esp
   1047a:	8b 55 08             	mov    0x8(%ebp),%edx
   1047d:	8b 45 0c             	mov    0xc(%ebp),%eax
   10480:	8b 4d 08             	mov    0x8(%ebp),%ecx
   10483:	f0 0f b3 02          	lock btr %eax,(%edx)
   10487:	0f 92 c0             	setb   %al
   1048a:	88 45 ff             	mov    %al,-0x1(%ebp)
   1048d:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   10491:	c9                   	leave  
   10492:	c3                   	ret    

00010493 <ck_pr_btr_16>:
   10493:	55                   	push   %ebp
   10494:	89 e5                	mov    %esp,%ebp
   10496:	83 ec 10             	sub    $0x10,%esp
   10499:	8b 45 0c             	mov    0xc(%ebp),%eax
   1049c:	8b 55 08             	mov    0x8(%ebp),%edx
   1049f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   104a2:	66 f0 0f b3 02       	lock btr %ax,(%edx)
   104a7:	0f 92 c0             	setb   %al
   104aa:	88 45 ff             	mov    %al,-0x1(%ebp)
   104ad:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   104b1:	c9                   	leave  
   104b2:	c3                   	ret    

000104b3 <ck_pr_barrier>:

#include <ck_cc.h>

CK_CC_INLINE static void
ck_pr_barrier(void)
{
   104b3:	55                   	push   %ebp
   104b4:	89 e5                	mov    %esp,%ebp

	__asm__ __volatile__("" ::: "memory");
	return;
   104b6:	90                   	nop
}
   104b7:	5d                   	pop    %ebp
   104b8:	c3                   	ret    

000104b9 <ck_pr_fence_load_depends>:

/*
 * None of the currently supported platforms allow for data-dependent
 * load ordering.
 */
CK_PR_FENCE_NOOP(load_depends)
   104b9:	55                   	push   %ebp
   104ba:	89 e5                	mov    %esp,%ebp
   104bc:	e8 f2 ff ff ff       	call   104b3 <ck_pr_barrier>
   104c1:	90                   	nop
   104c2:	5d                   	pop    %ebp
   104c3:	c3                   	ret    

000104c4 <ck_pr_fence_atomic>:
#elif defined(CK_MD_TSO)
/*
 * Only loads are re-ordered and only with respect to
 * prior stores. Atomic operations are serializing.
 */
CK_PR_FENCE_NOOP(atomic)
   104c4:	55                   	push   %ebp
   104c5:	89 e5                	mov    %esp,%ebp
   104c7:	e8 e7 ff ff ff       	call   104b3 <ck_pr_barrier>
   104cc:	90                   	nop
   104cd:	5d                   	pop    %ebp
   104ce:	c3                   	ret    

000104cf <ck_pr_fence_atomic_load>:
CK_PR_FENCE_NOOP(atomic_load)
   104cf:	55                   	push   %ebp
   104d0:	89 e5                	mov    %esp,%ebp
   104d2:	e8 dc ff ff ff       	call   104b3 <ck_pr_barrier>
   104d7:	90                   	nop
   104d8:	5d                   	pop    %ebp
   104d9:	c3                   	ret    

000104da <ck_pr_fence_atomic_store>:
CK_PR_FENCE_NOOP(atomic_store)
   104da:	55                   	push   %ebp
   104db:	89 e5                	mov    %esp,%ebp
   104dd:	e8 d1 ff ff ff       	call   104b3 <ck_pr_barrier>
   104e2:	90                   	nop
   104e3:	5d                   	pop    %ebp
   104e4:	c3                   	ret    

000104e5 <ck_pr_fence_store_atomic>:
CK_PR_FENCE_NOOP(store_atomic)
   104e5:	55                   	push   %ebp
   104e6:	89 e5                	mov    %esp,%ebp
   104e8:	e8 c6 ff ff ff       	call   104b3 <ck_pr_barrier>
   104ed:	90                   	nop
   104ee:	5d                   	pop    %ebp
   104ef:	c3                   	ret    

000104f0 <ck_pr_fence_load_atomic>:
CK_PR_FENCE_NOOP(load_atomic)
   104f0:	55                   	push   %ebp
   104f1:	89 e5                	mov    %esp,%ebp
   104f3:	e8 bb ff ff ff       	call   104b3 <ck_pr_barrier>
   104f8:	90                   	nop
   104f9:	5d                   	pop    %ebp
   104fa:	c3                   	ret    

000104fb <ck_pr_fence_load_store>:
CK_PR_FENCE_NOOP(load_store)
   104fb:	55                   	push   %ebp
   104fc:	89 e5                	mov    %esp,%ebp
   104fe:	e8 b0 ff ff ff       	call   104b3 <ck_pr_barrier>
   10503:	90                   	nop
   10504:	5d                   	pop    %ebp
   10505:	c3                   	ret    

00010506 <ck_pr_fence_store_load>:
CK_PR_FENCE_EMIT(store_load)
   10506:	55                   	push   %ebp
   10507:	89 e5                	mov    %esp,%ebp
   10509:	e8 d4 f1 ff ff       	call   f6e2 <ck_pr_fence_strict_store_load>
   1050e:	90                   	nop
   1050f:	5d                   	pop    %ebp
   10510:	c3                   	ret    

00010511 <ck_pr_fence_load>:
CK_PR_FENCE_NOOP(load)
   10511:	55                   	push   %ebp
   10512:	89 e5                	mov    %esp,%ebp
   10514:	e8 9a ff ff ff       	call   104b3 <ck_pr_barrier>
   10519:	90                   	nop
   1051a:	5d                   	pop    %ebp
   1051b:	c3                   	ret    

0001051c <ck_pr_fence_store>:
CK_PR_FENCE_NOOP(store)
   1051c:	55                   	push   %ebp
   1051d:	89 e5                	mov    %esp,%ebp
   1051f:	e8 8f ff ff ff       	call   104b3 <ck_pr_barrier>
   10524:	90                   	nop
   10525:	5d                   	pop    %ebp
   10526:	c3                   	ret    

00010527 <ck_pr_fence_memory>:
CK_PR_FENCE_EMIT(memory)
   10527:	55                   	push   %ebp
   10528:	89 e5                	mov    %esp,%ebp
   1052a:	e8 bc f1 ff ff       	call   f6eb <ck_pr_fence_strict_memory>
   1052f:	90                   	nop
   10530:	5d                   	pop    %ebp
   10531:	c3                   	ret    

00010532 <ck_pr_fence_acquire>:
CK_PR_FENCE_NOOP(acquire)
   10532:	55                   	push   %ebp
   10533:	89 e5                	mov    %esp,%ebp
   10535:	e8 79 ff ff ff       	call   104b3 <ck_pr_barrier>
   1053a:	90                   	nop
   1053b:	5d                   	pop    %ebp
   1053c:	c3                   	ret    

0001053d <ck_pr_fence_release>:
CK_PR_FENCE_NOOP(release)
   1053d:	55                   	push   %ebp
   1053e:	89 e5                	mov    %esp,%ebp
   10540:	e8 6e ff ff ff       	call   104b3 <ck_pr_barrier>
   10545:	90                   	nop
   10546:	5d                   	pop    %ebp
   10547:	c3                   	ret    

00010548 <ck_pr_fence_acqrel>:
CK_PR_FENCE_NOOP(acqrel)
   10548:	55                   	push   %ebp
   10549:	89 e5                	mov    %esp,%ebp
   1054b:	e8 63 ff ff ff       	call   104b3 <ck_pr_barrier>
   10550:	90                   	nop
   10551:	5d                   	pop    %ebp
   10552:	c3                   	ret    

00010553 <ck_pr_fence_lock>:
CK_PR_FENCE_NOOP(lock)
   10553:	55                   	push   %ebp
   10554:	89 e5                	mov    %esp,%ebp
   10556:	e8 58 ff ff ff       	call   104b3 <ck_pr_barrier>
   1055b:	90                   	nop
   1055c:	5d                   	pop    %ebp
   1055d:	c3                   	ret    

0001055e <ck_pr_fence_unlock>:
CK_PR_FENCE_NOOP(unlock)
   1055e:	55                   	push   %ebp
   1055f:	89 e5                	mov    %esp,%ebp
   10561:	e8 4d ff ff ff       	call   104b3 <ck_pr_barrier>
   10566:	90                   	nop
   10567:	5d                   	pop    %ebp
   10568:	c3                   	ret    

00010569 <ck_pr_rfo>:

#ifndef CK_F_PR_RFO
#define CK_F_PR_RFO
CK_CC_INLINE static void
ck_pr_rfo(const void *m)
{
   10569:	55                   	push   %ebp
   1056a:	89 e5                	mov    %esp,%ebp

	(void)m;
	return;
   1056c:	90                   	nop
}
   1056d:	5d                   	pop    %ebp
   1056e:	c3                   	ret    

0001056f <ck_ring_size>:
};
typedef struct ck_ring_buffer ck_ring_buffer_t;

CK_CC_INLINE static unsigned int
ck_ring_size(const struct ck_ring *ring)
{
   1056f:	55                   	push   %ebp
   10570:	89 e5                	mov    %esp,%ebp
   10572:	83 ec 14             	sub    $0x14,%esp
	unsigned int c, p;

	c = ck_pr_load_uint(&ring->c_head);
   10575:	8b 45 08             	mov    0x8(%ebp),%eax
   10578:	89 04 24             	mov    %eax,(%esp)
   1057b:	e8 86 f2 ff ff       	call   f806 <ck_pr_md_load_uint>
   10580:	89 45 fc             	mov    %eax,-0x4(%ebp)
	p = ck_pr_load_uint(&ring->p_tail);
   10583:	8b 45 08             	mov    0x8(%ebp),%eax
   10586:	83 c0 40             	add    $0x40,%eax
   10589:	89 04 24             	mov    %eax,(%esp)
   1058c:	e8 75 f2 ff ff       	call   f806 <ck_pr_md_load_uint>
   10591:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return (p - c) & ring->mask;
   10594:	8b 45 fc             	mov    -0x4(%ebp),%eax
   10597:	8b 55 f8             	mov    -0x8(%ebp),%edx
   1059a:	29 c2                	sub    %eax,%edx
   1059c:	8b 45 08             	mov    0x8(%ebp),%eax
   1059f:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   105a5:	21 d0                	and    %edx,%eax
}
   105a7:	c9                   	leave  
   105a8:	c3                   	ret    

000105a9 <ck_ring_capacity>:

CK_CC_INLINE static unsigned int
ck_ring_capacity(const struct ck_ring *ring)
{
   105a9:	55                   	push   %ebp
   105aa:	89 e5                	mov    %esp,%ebp
	return ring->size;
   105ac:	8b 45 08             	mov    0x8(%ebp),%eax
   105af:	8b 80 80 00 00 00    	mov    0x80(%eax),%eax
}
   105b5:	5d                   	pop    %ebp
   105b6:	c3                   	ret    

000105b7 <ck_ring_init>:

CK_CC_INLINE static void
ck_ring_init(struct ck_ring *ring, unsigned int size)
{
   105b7:	55                   	push   %ebp
   105b8:	89 e5                	mov    %esp,%ebp

	ring->size = size;
   105ba:	8b 45 08             	mov    0x8(%ebp),%eax
   105bd:	8b 55 0c             	mov    0xc(%ebp),%edx
   105c0:	89 90 80 00 00 00    	mov    %edx,0x80(%eax)
	ring->mask = size - 1;
   105c6:	8b 45 0c             	mov    0xc(%ebp),%eax
   105c9:	8d 50 ff             	lea    -0x1(%eax),%edx
   105cc:	8b 45 08             	mov    0x8(%ebp),%eax
   105cf:	89 90 84 00 00 00    	mov    %edx,0x84(%eax)
	ring->p_tail = 0;
   105d5:	8b 45 08             	mov    0x8(%ebp),%eax
   105d8:	c7 40 40 00 00 00 00 	movl   $0x0,0x40(%eax)
	ring->p_head = 0;
   105df:	8b 45 08             	mov    0x8(%ebp),%eax
   105e2:	c7 40 44 00 00 00 00 	movl   $0x0,0x44(%eax)
	ring->c_head = 0;
   105e9:	8b 45 08             	mov    0x8(%ebp),%eax
   105ec:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
	return;
   105f2:	90                   	nop
}
   105f3:	5d                   	pop    %ebp
   105f4:	c3                   	ret    

000105f5 <ck_ring_enqueue_spsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   105f5:	55                   	push   %ebp
   105f6:	89 e5                	mov    %esp,%ebp
   105f8:	83 ec 58             	sub    $0x58,%esp
   105fb:	8b 45 08             	mov    0x8(%ebp),%eax
   105fe:	89 45 f4             	mov    %eax,-0xc(%ebp)
   10601:	8b 45 0c             	mov    0xc(%ebp),%eax
   10604:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10607:	8d 45 10             	lea    0x10(%ebp),%eax
   1060a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1060d:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   10614:	8b 45 14             	mov    0x14(%ebp),%eax
   10617:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1061a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1061d:	89 45 e0             	mov    %eax,-0x20(%ebp)
   10620:	8b 45 f0             	mov    -0x10(%ebp),%eax
   10623:	89 45 dc             	mov    %eax,-0x24(%ebp)
   10626:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10629:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1062c:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1062f:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   10632:	8d 45 b8             	lea    -0x48(%ebp),%eax
   10635:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   10638:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1063b:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10641:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   10644:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10647:	89 04 24             	mov    %eax,(%esp)
   1064a:	e8 b7 f1 ff ff       	call   f806 <ck_pr_md_load_uint>
   1064f:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   10652:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10655:	8b 40 40             	mov    0x40(%eax),%eax
   10658:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1065b:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1065e:	83 c0 01             	add    $0x1,%eax
   10661:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   10664:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   10668:	74 14                	je     1067e <ck_ring_enqueue_spsc_size+0x89>
		*size = (producer - consumer) & mask;
   1066a:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1066d:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   10670:	29 c2                	sub    %eax,%edx
   10672:	89 d0                	mov    %edx,%eax
   10674:	23 45 cc             	and    -0x34(%ebp),%eax
   10677:	89 c2                	mov    %eax,%edx
   10679:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1067c:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1067e:	8b 45 c0             	mov    -0x40(%ebp),%eax
   10681:	8b 55 c8             	mov    -0x38(%ebp),%edx
   10684:	31 d0                	xor    %edx,%eax
   10686:	23 45 cc             	and    -0x34(%ebp),%eax
   10689:	85 c0                	test   %eax,%eax
   1068b:	0f 94 c0             	sete   %al
   1068e:	0f b6 c0             	movzbl %al,%eax
   10691:	85 c0                	test   %eax,%eax
   10693:	74 07                	je     1069c <ck_ring_enqueue_spsc_size+0xa7>
		return false;
   10695:	b8 00 00 00 00       	mov    $0x0,%eax
   1069a:	eb 47                	jmp    106e3 <ck_ring_enqueue_spsc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1069c:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1069f:	8b 55 cc             	mov    -0x34(%ebp),%edx
   106a2:	21 d0                	and    %edx,%eax
   106a4:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   106a8:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   106ab:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   106ae:	89 44 24 08          	mov    %eax,0x8(%esp)
   106b2:	8b 45 d8             	mov    -0x28(%ebp),%eax
   106b5:	89 44 24 04          	mov    %eax,0x4(%esp)
   106b9:	8b 45 dc             	mov    -0x24(%ebp),%eax
   106bc:	89 04 24             	mov    %eax,(%esp)
   106bf:	e8 fc ff ff ff       	call   106c0 <ck_ring_enqueue_spsc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   106c4:	e8 53 fe ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   106c9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   106cc:	8d 50 40             	lea    0x40(%eax),%edx
   106cf:	8b 45 c0             	mov    -0x40(%ebp),%eax
   106d2:	89 44 24 04          	mov    %eax,0x4(%esp)
   106d6:	89 14 24             	mov    %edx,(%esp)
   106d9:	e8 b1 f1 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   106de:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   106e3:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   106e6:	8b 55 b8             	mov    -0x48(%ebp),%edx
   106e9:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   106ec:	89 10                	mov    %edx,(%eax)
	return r;
   106ee:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   106f2:	c9                   	leave  
   106f3:	c3                   	ret    

000106f4 <ck_ring_enqueue_spsc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   106f4:	55                   	push   %ebp
   106f5:	89 e5                	mov    %esp,%ebp
   106f7:	83 ec 48             	sub    $0x48,%esp
   106fa:	8b 45 08             	mov    0x8(%ebp),%eax
   106fd:	89 45 f4             	mov    %eax,-0xc(%ebp)
   10700:	8b 45 0c             	mov    0xc(%ebp),%eax
   10703:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10706:	8d 45 10             	lea    0x10(%ebp),%eax
   10709:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1070c:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   10713:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1071a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1071d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10723:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   10726:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10729:	89 04 24             	mov    %eax,(%esp)
   1072c:	e8 d5 f0 ff ff       	call   f806 <ck_pr_md_load_uint>
   10731:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   10734:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10737:	8b 40 40             	mov    0x40(%eax),%eax
   1073a:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1073d:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10740:	83 c0 01             	add    $0x1,%eax
   10743:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   10746:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1074a:	74 14                	je     10760 <ck_ring_enqueue_spsc+0x6c>
		*size = (producer - consumer) & mask;
   1074c:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1074f:	8b 55 d8             	mov    -0x28(%ebp),%edx
   10752:	29 c2                	sub    %eax,%edx
   10754:	89 d0                	mov    %edx,%eax
   10756:	23 45 e0             	and    -0x20(%ebp),%eax
   10759:	89 c2                	mov    %eax,%edx
   1075b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1075e:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   10760:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   10763:	8b 55 dc             	mov    -0x24(%ebp),%edx
   10766:	31 d0                	xor    %edx,%eax
   10768:	23 45 e0             	and    -0x20(%ebp),%eax
   1076b:	85 c0                	test   %eax,%eax
   1076d:	0f 94 c0             	sete   %al
   10770:	0f b6 c0             	movzbl %al,%eax
   10773:	85 c0                	test   %eax,%eax
   10775:	74 07                	je     1077e <ck_ring_enqueue_spsc+0x8a>
		return false;
   10777:	b8 00 00 00 00       	mov    $0x0,%eax
   1077c:	eb 47                	jmp    107c5 <ck_ring_enqueue_spsc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1077e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10781:	8b 55 e0             	mov    -0x20(%ebp),%edx
   10784:	21 d0                	and    %edx,%eax
   10786:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1078a:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1078d:	8b 45 e8             	mov    -0x18(%ebp),%eax
   10790:	89 44 24 08          	mov    %eax,0x8(%esp)
   10794:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10797:	89 44 24 04          	mov    %eax,0x4(%esp)
   1079b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1079e:	89 04 24             	mov    %eax,(%esp)
   107a1:	e8 fc ff ff ff       	call   107a2 <ck_ring_enqueue_spsc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   107a6:	e8 71 fd ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   107ab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   107ae:	8d 50 40             	lea    0x40(%eax),%edx
   107b1:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   107b4:	89 44 24 04          	mov    %eax,0x4(%esp)
   107b8:	89 14 24             	mov    %edx,(%esp)
   107bb:	e8 cf f0 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   107c0:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer,
	    &entry, sizeof(entry), NULL);
}
   107c5:	c9                   	leave  
   107c6:	c3                   	ret    

000107c7 <ck_ring_dequeue_spsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   107c7:	55                   	push   %ebp
   107c8:	89 e5                	mov    %esp,%ebp
   107ca:	83 ec 38             	sub    $0x38,%esp
   107cd:	8b 45 08             	mov    0x8(%ebp),%eax
   107d0:	89 45 f4             	mov    %eax,-0xc(%ebp)
   107d3:	8b 45 0c             	mov    0xc(%ebp),%eax
   107d6:	89 45 f0             	mov    %eax,-0x10(%ebp)
   107d9:	8b 45 10             	mov    0x10(%ebp),%eax
   107dc:	89 45 ec             	mov    %eax,-0x14(%ebp)
   107df:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   107e6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   107e9:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   107ef:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   107f2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   107f5:	8b 00                	mov    (%eax),%eax
   107f7:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   107fa:	8b 45 f4             	mov    -0xc(%ebp),%eax
   107fd:	83 c0 40             	add    $0x40,%eax
   10800:	89 04 24             	mov    %eax,(%esp)
   10803:	e8 fe ef ff ff       	call   f806 <ck_pr_md_load_uint>
   10808:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1080b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1080e:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   10811:	0f 94 c0             	sete   %al
   10814:	0f b6 c0             	movzbl %al,%eax
   10817:	85 c0                	test   %eax,%eax
   10819:	74 07                	je     10822 <ck_ring_dequeue_spsc+0x5b>
		return false;
   1081b:	b8 00 00 00 00       	mov    $0x0,%eax
   10820:	eb 4c                	jmp    1086e <ck_ring_dequeue_spsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   10822:	e8 ea fc ff ff       	call   10511 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   10827:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1082a:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1082d:	21 d0                	and    %edx,%eax
   1082f:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   10833:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   10836:	8b 45 e8             	mov    -0x18(%ebp),%eax
   10839:	89 44 24 08          	mov    %eax,0x8(%esp)
   1083d:	8b 45 f0             	mov    -0x10(%ebp),%eax
   10840:	89 44 24 04          	mov    %eax,0x4(%esp)
   10844:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10847:	89 04 24             	mov    %eax,(%esp)
   1084a:	e8 fc ff ff ff       	call   1084b <ck_ring_dequeue_spsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   1084f:	e8 c8 fc ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   10854:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10857:	8d 50 01             	lea    0x1(%eax),%edx
   1085a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1085d:	89 54 24 04          	mov    %edx,0x4(%esp)
   10861:	89 04 24             	mov    %eax,(%esp)
   10864:	e8 26 f0 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   10869:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer,
	    (void **)data, sizeof(void *));
}
   1086e:	c9                   	leave  
   1086f:	c3                   	ret    

00010870 <ck_ring_enqueue_mpmc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   10870:	55                   	push   %ebp
   10871:	89 e5                	mov    %esp,%ebp
   10873:	83 ec 48             	sub    $0x48,%esp
   10876:	8b 45 08             	mov    0x8(%ebp),%eax
   10879:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1087c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1087f:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10882:	8d 45 10             	lea    0x10(%ebp),%eax
   10885:	89 45 ec             	mov    %eax,-0x14(%ebp)
   10888:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1088f:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   10896:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10899:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1089f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   108a2:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   108a6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   108a9:	83 c0 44             	add    $0x44,%eax
   108ac:	89 04 24             	mov    %eax,(%esp)
   108af:	e8 52 ef ff ff       	call   f806 <ck_pr_md_load_uint>
   108b4:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   108b7:	e8 55 fc ff ff       	call   10511 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   108bc:	8b 45 f4             	mov    -0xc(%ebp),%eax
   108bf:	89 04 24             	mov    %eax,(%esp)
   108c2:	e8 3f ef ff ff       	call   f806 <ck_pr_md_load_uint>
   108c7:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   108ca:	8b 45 cc             	mov    -0x34(%ebp),%eax
   108cd:	83 c0 01             	add    $0x1,%eax
   108d0:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   108d3:	8b 45 cc             	mov    -0x34(%ebp),%eax
   108d6:	2b 45 d8             	sub    -0x28(%ebp),%eax
   108d9:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   108dc:	0f 97 c0             	seta   %al
   108df:	0f b6 c0             	movzbl %al,%eax
   108e2:	85 c0                	test   %eax,%eax
   108e4:	74 29                	je     1090f <ck_ring_enqueue_mpmc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   108e6:	8b 45 cc             	mov    -0x34(%ebp),%eax
   108e9:	8b 55 f4             	mov    -0xc(%ebp),%edx
   108ec:	8d 4a 44             	lea    0x44(%edx),%ecx
   108ef:	8d 55 cc             	lea    -0x34(%ebp),%edx
   108f2:	89 54 24 0c          	mov    %edx,0xc(%esp)
   108f6:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   108f9:	89 54 24 08          	mov    %edx,0x8(%esp)
   108fd:	89 44 24 04          	mov    %eax,0x4(%esp)
   10901:	89 0c 24             	mov    %ecx,(%esp)
   10904:	e8 fe f8 ff ff       	call   10207 <ck_pr_cas_uint_value>
   10909:	84 c0                	test   %al,%al
   1090b:	75 31                	jne    1093e <ck_ring_enqueue_mpmc+0xce>
   1090d:	eb a8                	jmp    108b7 <ck_ring_enqueue_mpmc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1090f:	e8 fd fb ff ff       	call   10511 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   10914:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10917:	83 c0 44             	add    $0x44,%eax
   1091a:	89 04 24             	mov    %eax,(%esp)
   1091d:	e8 e4 ee ff ff       	call   f806 <ck_pr_md_load_uint>
   10922:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   10925:	8b 45 cc             	mov    -0x34(%ebp),%eax
   10928:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   1092b:	75 06                	jne    10933 <ck_ring_enqueue_mpmc+0xc3>
				r = false;
   1092d:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   10931:	eb 67                	jmp    1099a <ck_ring_enqueue_mpmc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   10933:	8b 45 d0             	mov    -0x30(%ebp),%eax
   10936:	89 45 cc             	mov    %eax,-0x34(%ebp)
   10939:	e9 79 ff ff ff       	jmp    108b7 <ck_ring_enqueue_mpmc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1093e:	8b 45 cc             	mov    -0x34(%ebp),%eax
   10941:	23 45 e0             	and    -0x20(%ebp),%eax
   10944:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   10948:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1094b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1094e:	89 44 24 08          	mov    %eax,0x8(%esp)
   10952:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10955:	89 44 24 04          	mov    %eax,0x4(%esp)
   10959:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1095c:	89 04 24             	mov    %eax,(%esp)
   1095f:	e8 fc ff ff ff       	call   10960 <ck_ring_enqueue_mpmc+0xf0>
   10964:	eb 05                	jmp    1096b <ck_ring_enqueue_mpmc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   10966:	e8 36 ed ff ff       	call   f6a1 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1096b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1096e:	83 c0 40             	add    $0x40,%eax
   10971:	89 04 24             	mov    %eax,(%esp)
   10974:	e8 8d ee ff ff       	call   f806 <ck_pr_md_load_uint>
   10979:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1097c:	39 d0                	cmp    %edx,%eax
   1097e:	75 e6                	jne    10966 <ck_ring_enqueue_mpmc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   10980:	e8 97 fb ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   10985:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10988:	8d 50 40             	lea    0x40(%eax),%edx
   1098b:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1098e:	89 44 24 04          	mov    %eax,0x4(%esp)
   10992:	89 14 24             	mov    %edx,(%esp)
   10995:	e8 f5 ee ff ff       	call   f88f <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1099a:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1099e:	74 10                	je     109b0 <ck_ring_enqueue_mpmc+0x140>
		*size = (producer - consumer) & mask;
   109a0:	8b 45 cc             	mov    -0x34(%ebp),%eax
   109a3:	2b 45 d8             	sub    -0x28(%ebp),%eax
   109a6:	23 45 e0             	and    -0x20(%ebp),%eax
   109a9:	89 c2                	mov    %eax,%edx
   109ab:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   109ae:	89 10                	mov    %edx,(%eax)

	return r;
   109b0:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   109b4:	c9                   	leave  
   109b5:	c3                   	ret    

000109b6 <ck_ring_enqueue_mpmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   109b6:	55                   	push   %ebp
   109b7:	89 e5                	mov    %esp,%ebp
   109b9:	83 ec 68             	sub    $0x68,%esp
   109bc:	8b 45 08             	mov    0x8(%ebp),%eax
   109bf:	89 45 f4             	mov    %eax,-0xc(%ebp)
   109c2:	8b 45 0c             	mov    0xc(%ebp),%eax
   109c5:	89 45 f0             	mov    %eax,-0x10(%ebp)
   109c8:	8d 45 10             	lea    0x10(%ebp),%eax
   109cb:	89 45 ec             	mov    %eax,-0x14(%ebp)
   109ce:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   109d5:	8b 45 14             	mov    0x14(%ebp),%eax
   109d8:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   109db:	8b 45 f4             	mov    -0xc(%ebp),%eax
   109de:	89 45 e0             	mov    %eax,-0x20(%ebp)
   109e1:	8b 45 f0             	mov    -0x10(%ebp),%eax
   109e4:	89 45 dc             	mov    %eax,-0x24(%ebp)
   109e7:	8b 45 ec             	mov    -0x14(%ebp),%eax
   109ea:	89 45 d8             	mov    %eax,-0x28(%ebp)
   109ed:	8b 45 e8             	mov    -0x18(%ebp),%eax
   109f0:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   109f3:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   109f6:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   109f9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   109fc:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10a02:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   10a05:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   10a09:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10a0c:	83 c0 44             	add    $0x44,%eax
   10a0f:	89 04 24             	mov    %eax,(%esp)
   10a12:	e8 ef ed ff ff       	call   f806 <ck_pr_md_load_uint>
   10a17:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   10a1a:	e8 f2 fa ff ff       	call   10511 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   10a1f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10a22:	89 04 24             	mov    %eax,(%esp)
   10a25:	e8 dc ed ff ff       	call   f806 <ck_pr_md_load_uint>
   10a2a:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   10a2d:	8b 45 b0             	mov    -0x50(%ebp),%eax
   10a30:	83 c0 01             	add    $0x1,%eax
   10a33:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   10a36:	8b 45 b0             	mov    -0x50(%ebp),%eax
   10a39:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   10a3c:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   10a3f:	0f 97 c0             	seta   %al
   10a42:	0f b6 c0             	movzbl %al,%eax
   10a45:	85 c0                	test   %eax,%eax
   10a47:	74 29                	je     10a72 <ck_ring_enqueue_mpmc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   10a49:	8b 45 b0             	mov    -0x50(%ebp),%eax
   10a4c:	8b 55 e0             	mov    -0x20(%ebp),%edx
   10a4f:	8d 4a 44             	lea    0x44(%edx),%ecx
   10a52:	8d 55 b0             	lea    -0x50(%ebp),%edx
   10a55:	89 54 24 0c          	mov    %edx,0xc(%esp)
   10a59:	8b 55 c0             	mov    -0x40(%ebp),%edx
   10a5c:	89 54 24 08          	mov    %edx,0x8(%esp)
   10a60:	89 44 24 04          	mov    %eax,0x4(%esp)
   10a64:	89 0c 24             	mov    %ecx,(%esp)
   10a67:	e8 9b f7 ff ff       	call   10207 <ck_pr_cas_uint_value>
   10a6c:	84 c0                	test   %al,%al
   10a6e:	75 31                	jne    10aa1 <ck_ring_enqueue_mpmc_size+0xeb>
   10a70:	eb a8                	jmp    10a1a <ck_ring_enqueue_mpmc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   10a72:	e8 9a fa ff ff       	call   10511 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   10a77:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10a7a:	83 c0 44             	add    $0x44,%eax
   10a7d:	89 04 24             	mov    %eax,(%esp)
   10a80:	e8 81 ed ff ff       	call   f806 <ck_pr_md_load_uint>
   10a85:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   10a88:	8b 45 b0             	mov    -0x50(%ebp),%eax
   10a8b:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   10a8e:	75 06                	jne    10a96 <ck_ring_enqueue_mpmc_size+0xe0>
				r = false;
   10a90:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   10a94:	eb 67                	jmp    10afd <ck_ring_enqueue_mpmc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   10a96:	8b 45 bc             	mov    -0x44(%ebp),%eax
   10a99:	89 45 b0             	mov    %eax,-0x50(%ebp)
   10a9c:	e9 79 ff ff ff       	jmp    10a1a <ck_ring_enqueue_mpmc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   10aa1:	8b 45 b0             	mov    -0x50(%ebp),%eax
   10aa4:	23 45 cc             	and    -0x34(%ebp),%eax
   10aa7:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   10aab:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   10aae:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   10ab1:	89 44 24 08          	mov    %eax,0x8(%esp)
   10ab5:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10ab8:	89 44 24 04          	mov    %eax,0x4(%esp)
   10abc:	8b 45 dc             	mov    -0x24(%ebp),%eax
   10abf:	89 04 24             	mov    %eax,(%esp)
   10ac2:	e8 fc ff ff ff       	call   10ac3 <ck_ring_enqueue_mpmc_size+0x10d>
   10ac7:	eb 05                	jmp    10ace <ck_ring_enqueue_mpmc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   10ac9:	e8 d3 eb ff ff       	call   f6a1 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   10ace:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10ad1:	83 c0 40             	add    $0x40,%eax
   10ad4:	89 04 24             	mov    %eax,(%esp)
   10ad7:	e8 2a ed ff ff       	call   f806 <ck_pr_md_load_uint>
   10adc:	8b 55 b0             	mov    -0x50(%ebp),%edx
   10adf:	39 d0                	cmp    %edx,%eax
   10ae1:	75 e6                	jne    10ac9 <ck_ring_enqueue_mpmc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   10ae3:	e8 34 fa ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   10ae8:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10aeb:	8d 50 40             	lea    0x40(%eax),%edx
   10aee:	8b 45 c0             	mov    -0x40(%ebp),%eax
   10af1:	89 44 24 04          	mov    %eax,0x4(%esp)
   10af5:	89 14 24             	mov    %edx,(%esp)
   10af8:	e8 92 ed ff ff       	call   f88f <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   10afd:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   10b01:	74 10                	je     10b13 <ck_ring_enqueue_mpmc_size+0x15d>
		*size = (producer - consumer) & mask;
   10b03:	8b 45 b0             	mov    -0x50(%ebp),%eax
   10b06:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   10b09:	23 45 cc             	and    -0x34(%ebp),%eax
   10b0c:	89 c2                	mov    %eax,%edx
   10b0e:	8b 45 d0             	mov    -0x30(%ebp),%eax
   10b11:	89 10                	mov    %edx,(%eax)

	return r;
   10b13:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   10b17:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   10b1a:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   10b1d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   10b20:	89 10                	mov    %edx,(%eax)
	return r;
   10b22:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   10b26:	c9                   	leave  
   10b27:	c3                   	ret    

00010b28 <ck_ring_trydequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   10b28:	55                   	push   %ebp
   10b29:	89 e5                	mov    %esp,%ebp
   10b2b:	83 ec 38             	sub    $0x38,%esp
   10b2e:	8b 45 08             	mov    0x8(%ebp),%eax
   10b31:	89 45 f4             	mov    %eax,-0xc(%ebp)
   10b34:	8b 45 0c             	mov    0xc(%ebp),%eax
   10b37:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10b3a:	8b 45 10             	mov    0x10(%ebp),%eax
   10b3d:	89 45 ec             	mov    %eax,-0x14(%ebp)
   10b40:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   10b47:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10b4a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10b50:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   10b53:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10b56:	89 04 24             	mov    %eax,(%esp)
   10b59:	e8 a8 ec ff ff       	call   f806 <ck_pr_md_load_uint>
   10b5e:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   10b61:	e8 ab f9 ff ff       	call   10511 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   10b66:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10b69:	83 c0 40             	add    $0x40,%eax
   10b6c:	89 04 24             	mov    %eax,(%esp)
   10b6f:	e8 92 ec ff ff       	call   f806 <ck_pr_md_load_uint>
   10b74:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   10b77:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10b7a:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   10b7d:	0f 94 c0             	sete   %al
   10b80:	0f b6 c0             	movzbl %al,%eax
   10b83:	85 c0                	test   %eax,%eax
   10b85:	74 07                	je     10b8e <ck_ring_trydequeue_mpmc+0x66>
		return false;
   10b87:	b8 00 00 00 00       	mov    $0x0,%eax
   10b8c:	eb 4e                	jmp    10bdc <ck_ring_trydequeue_mpmc+0xb4>

	ck_pr_fence_load();
   10b8e:	e8 7e f9 ff ff       	call   10511 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   10b93:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10b96:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   10b99:	21 d0                	and    %edx,%eax
   10b9b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   10b9f:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   10ba2:	8b 45 e8             	mov    -0x18(%ebp),%eax
   10ba5:	89 44 24 08          	mov    %eax,0x8(%esp)
   10ba9:	8b 45 f0             	mov    -0x10(%ebp),%eax
   10bac:	89 44 24 04          	mov    %eax,0x4(%esp)
   10bb0:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10bb3:	89 04 24             	mov    %eax,(%esp)
   10bb6:	e8 fc ff ff ff       	call   10bb7 <ck_ring_trydequeue_mpmc+0x8f>

	ck_pr_fence_store_atomic();
   10bbb:	e8 25 f9 ff ff       	call   104e5 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   10bc0:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10bc3:	8d 50 01             	lea    0x1(%eax),%edx
   10bc6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10bc9:	89 54 24 08          	mov    %edx,0x8(%esp)
   10bcd:	8b 55 e0             	mov    -0x20(%ebp),%edx
   10bd0:	89 54 24 04          	mov    %edx,0x4(%esp)
   10bd4:	89 04 24             	mov    %eax,(%esp)
   10bd7:	e8 d8 f4 ff ff       	call   100b4 <ck_pr_cas_uint>
    void *data)
{

	return _ck_ring_trydequeue_mc(ring,
	    buffer, (void **)data, sizeof(void *));
}
   10bdc:	c9                   	leave  
   10bdd:	c3                   	ret    

00010bde <ck_ring_dequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   10bde:	55                   	push   %ebp
   10bdf:	89 e5                	mov    %esp,%ebp
   10be1:	53                   	push   %ebx
   10be2:	83 ec 34             	sub    $0x34,%esp
   10be5:	8b 45 08             	mov    0x8(%ebp),%eax
   10be8:	89 45 f4             	mov    %eax,-0xc(%ebp)
   10beb:	8b 45 0c             	mov    0xc(%ebp),%eax
   10bee:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10bf1:	8b 45 10             	mov    0x10(%ebp),%eax
   10bf4:	89 45 ec             	mov    %eax,-0x14(%ebp)
   10bf7:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   10bfe:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10c01:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10c07:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   10c0a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10c0d:	89 04 24             	mov    %eax,(%esp)
   10c10:	e8 f1 eb ff ff       	call   f806 <ck_pr_md_load_uint>
   10c15:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   10c18:	e8 f4 f8 ff ff       	call   10511 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   10c1d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10c20:	83 c0 40             	add    $0x40,%eax
   10c23:	89 04 24             	mov    %eax,(%esp)
   10c26:	e8 db eb ff ff       	call   f806 <ck_pr_md_load_uint>
   10c2b:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   10c2e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10c31:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   10c34:	0f 94 c0             	sete   %al
   10c37:	0f b6 c0             	movzbl %al,%eax
   10c3a:	85 c0                	test   %eax,%eax
   10c3c:	74 07                	je     10c45 <ck_ring_dequeue_mpmc+0x67>
			return false;
   10c3e:	b8 00 00 00 00       	mov    $0x0,%eax
   10c43:	eb 6a                	jmp    10caf <ck_ring_dequeue_mpmc+0xd1>

		ck_pr_fence_load();
   10c45:	e8 c7 f8 ff ff       	call   10511 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   10c4a:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10c4d:	23 45 e4             	and    -0x1c(%ebp),%eax
   10c50:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   10c54:	89 c2                	mov    %eax,%edx
   10c56:	8b 45 f0             	mov    -0x10(%ebp),%eax
   10c59:	01 d0                	add    %edx,%eax
   10c5b:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   10c5e:	8b 45 e8             	mov    -0x18(%ebp),%eax
   10c61:	89 44 24 08          	mov    %eax,0x8(%esp)
   10c65:	8b 45 dc             	mov    -0x24(%ebp),%eax
   10c68:	89 44 24 04          	mov    %eax,0x4(%esp)
   10c6c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10c6f:	89 04 24             	mov    %eax,(%esp)
   10c72:	e8 fc ff ff ff       	call   10c73 <ck_ring_dequeue_mpmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   10c77:	e8 69 f8 ff ff       	call   104e5 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   10c7c:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10c7f:	8d 58 01             	lea    0x1(%eax),%ebx
   10c82:	8b 55 d8             	mov    -0x28(%ebp),%edx
   10c85:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10c88:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   10c8b:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   10c8f:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   10c93:	89 54 24 04          	mov    %edx,0x4(%esp)
   10c97:	89 04 24             	mov    %eax,(%esp)
   10c9a:	e8 68 f5 ff ff       	call   10207 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   10c9f:	83 f0 01             	xor    $0x1,%eax
   10ca2:	84 c0                	test   %al,%al
   10ca4:	0f 85 6e ff ff ff    	jne    10c18 <ck_ring_dequeue_mpmc+0x3a>

	return true;
   10caa:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   10caf:	83 c4 34             	add    $0x34,%esp
   10cb2:	5b                   	pop    %ebx
   10cb3:	5d                   	pop    %ebp
   10cb4:	c3                   	ret    

00010cb5 <ck_ring_enqueue_spmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   10cb5:	55                   	push   %ebp
   10cb6:	89 e5                	mov    %esp,%ebp
   10cb8:	83 ec 58             	sub    $0x58,%esp
   10cbb:	8b 45 08             	mov    0x8(%ebp),%eax
   10cbe:	89 45 f4             	mov    %eax,-0xc(%ebp)
   10cc1:	8b 45 0c             	mov    0xc(%ebp),%eax
   10cc4:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10cc7:	8d 45 10             	lea    0x10(%ebp),%eax
   10cca:	89 45 ec             	mov    %eax,-0x14(%ebp)
   10ccd:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   10cd4:	8b 45 14             	mov    0x14(%ebp),%eax
   10cd7:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   10cda:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10cdd:	89 45 e0             	mov    %eax,-0x20(%ebp)
   10ce0:	8b 45 f0             	mov    -0x10(%ebp),%eax
   10ce3:	89 45 dc             	mov    %eax,-0x24(%ebp)
   10ce6:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10ce9:	89 45 d8             	mov    %eax,-0x28(%ebp)
   10cec:	8b 45 e8             	mov    -0x18(%ebp),%eax
   10cef:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   10cf2:	8d 45 b8             	lea    -0x48(%ebp),%eax
   10cf5:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   10cf8:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10cfb:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10d01:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   10d04:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10d07:	89 04 24             	mov    %eax,(%esp)
   10d0a:	e8 f7 ea ff ff       	call   f806 <ck_pr_md_load_uint>
   10d0f:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   10d12:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10d15:	8b 40 40             	mov    0x40(%eax),%eax
   10d18:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   10d1b:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   10d1e:	83 c0 01             	add    $0x1,%eax
   10d21:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   10d24:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   10d28:	74 14                	je     10d3e <ck_ring_enqueue_spmc_size+0x89>
		*size = (producer - consumer) & mask;
   10d2a:	8b 45 c8             	mov    -0x38(%ebp),%eax
   10d2d:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   10d30:	29 c2                	sub    %eax,%edx
   10d32:	89 d0                	mov    %edx,%eax
   10d34:	23 45 cc             	and    -0x34(%ebp),%eax
   10d37:	89 c2                	mov    %eax,%edx
   10d39:	8b 45 d0             	mov    -0x30(%ebp),%eax
   10d3c:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   10d3e:	8b 45 c0             	mov    -0x40(%ebp),%eax
   10d41:	8b 55 c8             	mov    -0x38(%ebp),%edx
   10d44:	31 d0                	xor    %edx,%eax
   10d46:	23 45 cc             	and    -0x34(%ebp),%eax
   10d49:	85 c0                	test   %eax,%eax
   10d4b:	0f 94 c0             	sete   %al
   10d4e:	0f b6 c0             	movzbl %al,%eax
   10d51:	85 c0                	test   %eax,%eax
   10d53:	74 07                	je     10d5c <ck_ring_enqueue_spmc_size+0xa7>
		return false;
   10d55:	b8 00 00 00 00       	mov    $0x0,%eax
   10d5a:	eb 47                	jmp    10da3 <ck_ring_enqueue_spmc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   10d5c:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   10d5f:	8b 55 cc             	mov    -0x34(%ebp),%edx
   10d62:	21 d0                	and    %edx,%eax
   10d64:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   10d68:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   10d6b:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   10d6e:	89 44 24 08          	mov    %eax,0x8(%esp)
   10d72:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10d75:	89 44 24 04          	mov    %eax,0x4(%esp)
   10d79:	8b 45 dc             	mov    -0x24(%ebp),%eax
   10d7c:	89 04 24             	mov    %eax,(%esp)
   10d7f:	e8 fc ff ff ff       	call   10d80 <ck_ring_enqueue_spmc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   10d84:	e8 93 f7 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   10d89:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10d8c:	8d 50 40             	lea    0x40(%eax),%edx
   10d8f:	8b 45 c0             	mov    -0x40(%ebp),%eax
   10d92:	89 44 24 04          	mov    %eax,0x4(%esp)
   10d96:	89 14 24             	mov    %edx,(%esp)
   10d99:	e8 f1 ea ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   10d9e:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   10da3:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   10da6:	8b 55 b8             	mov    -0x48(%ebp),%edx
   10da9:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   10dac:	89 10                	mov    %edx,(%eax)
	return r;
   10dae:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   10db2:	c9                   	leave  
   10db3:	c3                   	ret    

00010db4 <ck_ring_enqueue_spmc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   10db4:	55                   	push   %ebp
   10db5:	89 e5                	mov    %esp,%ebp
   10db7:	83 ec 48             	sub    $0x48,%esp
   10dba:	8b 45 08             	mov    0x8(%ebp),%eax
   10dbd:	89 45 f4             	mov    %eax,-0xc(%ebp)
   10dc0:	8b 45 0c             	mov    0xc(%ebp),%eax
   10dc3:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10dc6:	8d 45 10             	lea    0x10(%ebp),%eax
   10dc9:	89 45 ec             	mov    %eax,-0x14(%ebp)
   10dcc:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   10dd3:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   10dda:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10ddd:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10de3:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   10de6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10de9:	89 04 24             	mov    %eax,(%esp)
   10dec:	e8 15 ea ff ff       	call   f806 <ck_pr_md_load_uint>
   10df1:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   10df4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10df7:	8b 40 40             	mov    0x40(%eax),%eax
   10dfa:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   10dfd:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10e00:	83 c0 01             	add    $0x1,%eax
   10e03:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   10e06:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   10e0a:	74 14                	je     10e20 <ck_ring_enqueue_spmc+0x6c>
		*size = (producer - consumer) & mask;
   10e0c:	8b 45 dc             	mov    -0x24(%ebp),%eax
   10e0f:	8b 55 d8             	mov    -0x28(%ebp),%edx
   10e12:	29 c2                	sub    %eax,%edx
   10e14:	89 d0                	mov    %edx,%eax
   10e16:	23 45 e0             	and    -0x20(%ebp),%eax
   10e19:	89 c2                	mov    %eax,%edx
   10e1b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   10e1e:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   10e20:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   10e23:	8b 55 dc             	mov    -0x24(%ebp),%edx
   10e26:	31 d0                	xor    %edx,%eax
   10e28:	23 45 e0             	and    -0x20(%ebp),%eax
   10e2b:	85 c0                	test   %eax,%eax
   10e2d:	0f 94 c0             	sete   %al
   10e30:	0f b6 c0             	movzbl %al,%eax
   10e33:	85 c0                	test   %eax,%eax
   10e35:	74 07                	je     10e3e <ck_ring_enqueue_spmc+0x8a>
		return false;
   10e37:	b8 00 00 00 00       	mov    $0x0,%eax
   10e3c:	eb 47                	jmp    10e85 <ck_ring_enqueue_spmc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   10e3e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10e41:	8b 55 e0             	mov    -0x20(%ebp),%edx
   10e44:	21 d0                	and    %edx,%eax
   10e46:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   10e4a:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   10e4d:	8b 45 e8             	mov    -0x18(%ebp),%eax
   10e50:	89 44 24 08          	mov    %eax,0x8(%esp)
   10e54:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10e57:	89 44 24 04          	mov    %eax,0x4(%esp)
   10e5b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   10e5e:	89 04 24             	mov    %eax,(%esp)
   10e61:	e8 fc ff ff ff       	call   10e62 <ck_ring_enqueue_spmc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   10e66:	e8 b1 f6 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   10e6b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10e6e:	8d 50 40             	lea    0x40(%eax),%edx
   10e71:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   10e74:	89 44 24 04          	mov    %eax,0x4(%esp)
   10e78:	89 14 24             	mov    %edx,(%esp)
   10e7b:	e8 0f ea ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   10e80:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   10e85:	c9                   	leave  
   10e86:	c3                   	ret    

00010e87 <ck_ring_trydequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   10e87:	55                   	push   %ebp
   10e88:	89 e5                	mov    %esp,%ebp
   10e8a:	83 ec 38             	sub    $0x38,%esp
   10e8d:	8b 45 08             	mov    0x8(%ebp),%eax
   10e90:	89 45 f4             	mov    %eax,-0xc(%ebp)
   10e93:	8b 45 0c             	mov    0xc(%ebp),%eax
   10e96:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10e99:	8b 45 10             	mov    0x10(%ebp),%eax
   10e9c:	89 45 ec             	mov    %eax,-0x14(%ebp)
   10e9f:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   10ea6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10ea9:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10eaf:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   10eb2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10eb5:	89 04 24             	mov    %eax,(%esp)
   10eb8:	e8 49 e9 ff ff       	call   f806 <ck_pr_md_load_uint>
   10ebd:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   10ec0:	e8 4c f6 ff ff       	call   10511 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   10ec5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10ec8:	83 c0 40             	add    $0x40,%eax
   10ecb:	89 04 24             	mov    %eax,(%esp)
   10ece:	e8 33 e9 ff ff       	call   f806 <ck_pr_md_load_uint>
   10ed3:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   10ed6:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10ed9:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   10edc:	0f 94 c0             	sete   %al
   10edf:	0f b6 c0             	movzbl %al,%eax
   10ee2:	85 c0                	test   %eax,%eax
   10ee4:	74 07                	je     10eed <ck_ring_trydequeue_spmc+0x66>
		return false;
   10ee6:	b8 00 00 00 00       	mov    $0x0,%eax
   10eeb:	eb 4e                	jmp    10f3b <ck_ring_trydequeue_spmc+0xb4>

	ck_pr_fence_load();
   10eed:	e8 1f f6 ff ff       	call   10511 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   10ef2:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10ef5:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   10ef8:	21 d0                	and    %edx,%eax
   10efa:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   10efe:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   10f01:	8b 45 e8             	mov    -0x18(%ebp),%eax
   10f04:	89 44 24 08          	mov    %eax,0x8(%esp)
   10f08:	8b 45 f0             	mov    -0x10(%ebp),%eax
   10f0b:	89 44 24 04          	mov    %eax,0x4(%esp)
   10f0f:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10f12:	89 04 24             	mov    %eax,(%esp)
   10f15:	e8 fc ff ff ff       	call   10f16 <ck_ring_trydequeue_spmc+0x8f>

	ck_pr_fence_store_atomic();
   10f1a:	e8 c6 f5 ff ff       	call   104e5 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   10f1f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   10f22:	8d 50 01             	lea    0x1(%eax),%edx
   10f25:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10f28:	89 54 24 08          	mov    %edx,0x8(%esp)
   10f2c:	8b 55 e0             	mov    -0x20(%ebp),%edx
   10f2f:	89 54 24 04          	mov    %edx,0x4(%esp)
   10f33:	89 04 24             	mov    %eax,(%esp)
   10f36:	e8 79 f1 ff ff       	call   100b4 <ck_pr_cas_uint>
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_trydequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   10f3b:	c9                   	leave  
   10f3c:	c3                   	ret    

00010f3d <ck_ring_dequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   10f3d:	55                   	push   %ebp
   10f3e:	89 e5                	mov    %esp,%ebp
   10f40:	53                   	push   %ebx
   10f41:	83 ec 34             	sub    $0x34,%esp
   10f44:	8b 45 08             	mov    0x8(%ebp),%eax
   10f47:	89 45 f4             	mov    %eax,-0xc(%ebp)
   10f4a:	8b 45 0c             	mov    0xc(%ebp),%eax
   10f4d:	89 45 f0             	mov    %eax,-0x10(%ebp)
   10f50:	8b 45 10             	mov    0x10(%ebp),%eax
   10f53:	89 45 ec             	mov    %eax,-0x14(%ebp)
   10f56:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   10f5d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10f60:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   10f66:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   10f69:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10f6c:	89 04 24             	mov    %eax,(%esp)
   10f6f:	e8 92 e8 ff ff       	call   f806 <ck_pr_md_load_uint>
   10f74:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   10f77:	e8 95 f5 ff ff       	call   10511 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   10f7c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10f7f:	83 c0 40             	add    $0x40,%eax
   10f82:	89 04 24             	mov    %eax,(%esp)
   10f85:	e8 7c e8 ff ff       	call   f806 <ck_pr_md_load_uint>
   10f8a:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   10f8d:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10f90:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   10f93:	0f 94 c0             	sete   %al
   10f96:	0f b6 c0             	movzbl %al,%eax
   10f99:	85 c0                	test   %eax,%eax
   10f9b:	74 07                	je     10fa4 <ck_ring_dequeue_spmc+0x67>
			return false;
   10f9d:	b8 00 00 00 00       	mov    $0x0,%eax
   10fa2:	eb 6a                	jmp    1100e <ck_ring_dequeue_spmc+0xd1>

		ck_pr_fence_load();
   10fa4:	e8 68 f5 ff ff       	call   10511 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   10fa9:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10fac:	23 45 e4             	and    -0x1c(%ebp),%eax
   10faf:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   10fb3:	89 c2                	mov    %eax,%edx
   10fb5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   10fb8:	01 d0                	add    %edx,%eax
   10fba:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   10fbd:	8b 45 e8             	mov    -0x18(%ebp),%eax
   10fc0:	89 44 24 08          	mov    %eax,0x8(%esp)
   10fc4:	8b 45 dc             	mov    -0x24(%ebp),%eax
   10fc7:	89 44 24 04          	mov    %eax,0x4(%esp)
   10fcb:	8b 45 ec             	mov    -0x14(%ebp),%eax
   10fce:	89 04 24             	mov    %eax,(%esp)
   10fd1:	e8 fc ff ff ff       	call   10fd2 <ck_ring_dequeue_spmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   10fd6:	e8 0a f5 ff ff       	call   104e5 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   10fdb:	8b 45 d8             	mov    -0x28(%ebp),%eax
   10fde:	8d 58 01             	lea    0x1(%eax),%ebx
   10fe1:	8b 55 d8             	mov    -0x28(%ebp),%edx
   10fe4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   10fe7:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   10fea:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   10fee:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   10ff2:	89 54 24 04          	mov    %edx,0x4(%esp)
   10ff6:	89 04 24             	mov    %eax,(%esp)
   10ff9:	e8 09 f2 ff ff       	call   10207 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   10ffe:	83 f0 01             	xor    $0x1,%eax
   11001:	84 c0                	test   %al,%al
   11003:	0f 85 6e ff ff ff    	jne    10f77 <ck_ring_dequeue_spmc+0x3a>

	return true;
   11009:	b8 01 00 00 00       	mov    $0x1,%eax
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   1100e:	83 c4 34             	add    $0x34,%esp
   11011:	5b                   	pop    %ebx
   11012:	5d                   	pop    %ebp
   11013:	c3                   	ret    

00011014 <ck_ring_enqueue_mpsc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   11014:	55                   	push   %ebp
   11015:	89 e5                	mov    %esp,%ebp
   11017:	83 ec 48             	sub    $0x48,%esp
   1101a:	8b 45 08             	mov    0x8(%ebp),%eax
   1101d:	89 45 f4             	mov    %eax,-0xc(%ebp)
   11020:	8b 45 0c             	mov    0xc(%ebp),%eax
   11023:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11026:	8d 45 10             	lea    0x10(%ebp),%eax
   11029:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1102c:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   11033:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1103a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1103d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   11043:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   11046:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1104a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1104d:	83 c0 44             	add    $0x44,%eax
   11050:	89 04 24             	mov    %eax,(%esp)
   11053:	e8 ae e7 ff ff       	call   f806 <ck_pr_md_load_uint>
   11058:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1105b:	e8 b1 f4 ff ff       	call   10511 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   11060:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11063:	89 04 24             	mov    %eax,(%esp)
   11066:	e8 9b e7 ff ff       	call   f806 <ck_pr_md_load_uint>
   1106b:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1106e:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11071:	83 c0 01             	add    $0x1,%eax
   11074:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   11077:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1107a:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1107d:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   11080:	0f 97 c0             	seta   %al
   11083:	0f b6 c0             	movzbl %al,%eax
   11086:	85 c0                	test   %eax,%eax
   11088:	74 29                	je     110b3 <ck_ring_enqueue_mpsc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1108a:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1108d:	8b 55 f4             	mov    -0xc(%ebp),%edx
   11090:	8d 4a 44             	lea    0x44(%edx),%ecx
   11093:	8d 55 cc             	lea    -0x34(%ebp),%edx
   11096:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1109a:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   1109d:	89 54 24 08          	mov    %edx,0x8(%esp)
   110a1:	89 44 24 04          	mov    %eax,0x4(%esp)
   110a5:	89 0c 24             	mov    %ecx,(%esp)
   110a8:	e8 5a f1 ff ff       	call   10207 <ck_pr_cas_uint_value>
   110ad:	84 c0                	test   %al,%al
   110af:	75 31                	jne    110e2 <ck_ring_enqueue_mpsc+0xce>
   110b1:	eb a8                	jmp    1105b <ck_ring_enqueue_mpsc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   110b3:	e8 59 f4 ff ff       	call   10511 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   110b8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   110bb:	83 c0 44             	add    $0x44,%eax
   110be:	89 04 24             	mov    %eax,(%esp)
   110c1:	e8 40 e7 ff ff       	call   f806 <ck_pr_md_load_uint>
   110c6:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   110c9:	8b 45 cc             	mov    -0x34(%ebp),%eax
   110cc:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   110cf:	75 06                	jne    110d7 <ck_ring_enqueue_mpsc+0xc3>
				r = false;
   110d1:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   110d5:	eb 67                	jmp    1113e <ck_ring_enqueue_mpsc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   110d7:	8b 45 d0             	mov    -0x30(%ebp),%eax
   110da:	89 45 cc             	mov    %eax,-0x34(%ebp)
   110dd:	e9 79 ff ff ff       	jmp    1105b <ck_ring_enqueue_mpsc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   110e2:	8b 45 cc             	mov    -0x34(%ebp),%eax
   110e5:	23 45 e0             	and    -0x20(%ebp),%eax
   110e8:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   110ec:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   110ef:	8b 45 e8             	mov    -0x18(%ebp),%eax
   110f2:	89 44 24 08          	mov    %eax,0x8(%esp)
   110f6:	8b 45 ec             	mov    -0x14(%ebp),%eax
   110f9:	89 44 24 04          	mov    %eax,0x4(%esp)
   110fd:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11100:	89 04 24             	mov    %eax,(%esp)
   11103:	e8 fc ff ff ff       	call   11104 <ck_ring_enqueue_mpsc+0xf0>
   11108:	eb 05                	jmp    1110f <ck_ring_enqueue_mpsc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1110a:	e8 92 e5 ff ff       	call   f6a1 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1110f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11112:	83 c0 40             	add    $0x40,%eax
   11115:	89 04 24             	mov    %eax,(%esp)
   11118:	e8 e9 e6 ff ff       	call   f806 <ck_pr_md_load_uint>
   1111d:	8b 55 cc             	mov    -0x34(%ebp),%edx
   11120:	39 d0                	cmp    %edx,%eax
   11122:	75 e6                	jne    1110a <ck_ring_enqueue_mpsc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   11124:	e8 f3 f3 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   11129:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1112c:	8d 50 40             	lea    0x40(%eax),%edx
   1112f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   11132:	89 44 24 04          	mov    %eax,0x4(%esp)
   11136:	89 14 24             	mov    %edx,(%esp)
   11139:	e8 51 e7 ff ff       	call   f88f <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1113e:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   11142:	74 10                	je     11154 <ck_ring_enqueue_mpsc+0x140>
		*size = (producer - consumer) & mask;
   11144:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11147:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1114a:	23 45 e0             	and    -0x20(%ebp),%eax
   1114d:	89 c2                	mov    %eax,%edx
   1114f:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   11152:	89 10                	mov    %edx,(%eax)

	return r;
   11154:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   11158:	c9                   	leave  
   11159:	c3                   	ret    

0001115a <ck_ring_enqueue_mpsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1115a:	55                   	push   %ebp
   1115b:	89 e5                	mov    %esp,%ebp
   1115d:	83 ec 68             	sub    $0x68,%esp
   11160:	8b 45 08             	mov    0x8(%ebp),%eax
   11163:	89 45 f4             	mov    %eax,-0xc(%ebp)
   11166:	8b 45 0c             	mov    0xc(%ebp),%eax
   11169:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1116c:	8d 45 10             	lea    0x10(%ebp),%eax
   1116f:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11172:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   11179:	8b 45 14             	mov    0x14(%ebp),%eax
   1117c:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1117f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11182:	89 45 e0             	mov    %eax,-0x20(%ebp)
   11185:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11188:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1118b:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1118e:	89 45 d8             	mov    %eax,-0x28(%ebp)
   11191:	8b 45 e8             	mov    -0x18(%ebp),%eax
   11194:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   11197:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1119a:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1119d:	8b 45 e0             	mov    -0x20(%ebp),%eax
   111a0:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   111a6:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   111a9:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   111ad:	8b 45 e0             	mov    -0x20(%ebp),%eax
   111b0:	83 c0 44             	add    $0x44,%eax
   111b3:	89 04 24             	mov    %eax,(%esp)
   111b6:	e8 4b e6 ff ff       	call   f806 <ck_pr_md_load_uint>
   111bb:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   111be:	e8 4e f3 ff ff       	call   10511 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   111c3:	8b 45 e0             	mov    -0x20(%ebp),%eax
   111c6:	89 04 24             	mov    %eax,(%esp)
   111c9:	e8 38 e6 ff ff       	call   f806 <ck_pr_md_load_uint>
   111ce:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   111d1:	8b 45 b0             	mov    -0x50(%ebp),%eax
   111d4:	83 c0 01             	add    $0x1,%eax
   111d7:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   111da:	8b 45 b0             	mov    -0x50(%ebp),%eax
   111dd:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   111e0:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   111e3:	0f 97 c0             	seta   %al
   111e6:	0f b6 c0             	movzbl %al,%eax
   111e9:	85 c0                	test   %eax,%eax
   111eb:	74 29                	je     11216 <ck_ring_enqueue_mpsc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   111ed:	8b 45 b0             	mov    -0x50(%ebp),%eax
   111f0:	8b 55 e0             	mov    -0x20(%ebp),%edx
   111f3:	8d 4a 44             	lea    0x44(%edx),%ecx
   111f6:	8d 55 b0             	lea    -0x50(%ebp),%edx
   111f9:	89 54 24 0c          	mov    %edx,0xc(%esp)
   111fd:	8b 55 c0             	mov    -0x40(%ebp),%edx
   11200:	89 54 24 08          	mov    %edx,0x8(%esp)
   11204:	89 44 24 04          	mov    %eax,0x4(%esp)
   11208:	89 0c 24             	mov    %ecx,(%esp)
   1120b:	e8 f7 ef ff ff       	call   10207 <ck_pr_cas_uint_value>
   11210:	84 c0                	test   %al,%al
   11212:	75 31                	jne    11245 <ck_ring_enqueue_mpsc_size+0xeb>
   11214:	eb a8                	jmp    111be <ck_ring_enqueue_mpsc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   11216:	e8 f6 f2 ff ff       	call   10511 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1121b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1121e:	83 c0 44             	add    $0x44,%eax
   11221:	89 04 24             	mov    %eax,(%esp)
   11224:	e8 dd e5 ff ff       	call   f806 <ck_pr_md_load_uint>
   11229:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1122c:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1122f:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   11232:	75 06                	jne    1123a <ck_ring_enqueue_mpsc_size+0xe0>
				r = false;
   11234:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   11238:	eb 67                	jmp    112a1 <ck_ring_enqueue_mpsc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1123a:	8b 45 bc             	mov    -0x44(%ebp),%eax
   1123d:	89 45 b0             	mov    %eax,-0x50(%ebp)
   11240:	e9 79 ff ff ff       	jmp    111be <ck_ring_enqueue_mpsc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   11245:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11248:	23 45 cc             	and    -0x34(%ebp),%eax
   1124b:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1124f:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   11252:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   11255:	89 44 24 08          	mov    %eax,0x8(%esp)
   11259:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1125c:	89 44 24 04          	mov    %eax,0x4(%esp)
   11260:	8b 45 dc             	mov    -0x24(%ebp),%eax
   11263:	89 04 24             	mov    %eax,(%esp)
   11266:	e8 fc ff ff ff       	call   11267 <ck_ring_enqueue_mpsc_size+0x10d>
   1126b:	eb 05                	jmp    11272 <ck_ring_enqueue_mpsc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1126d:	e8 2f e4 ff ff       	call   f6a1 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   11272:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11275:	83 c0 40             	add    $0x40,%eax
   11278:	89 04 24             	mov    %eax,(%esp)
   1127b:	e8 86 e5 ff ff       	call   f806 <ck_pr_md_load_uint>
   11280:	8b 55 b0             	mov    -0x50(%ebp),%edx
   11283:	39 d0                	cmp    %edx,%eax
   11285:	75 e6                	jne    1126d <ck_ring_enqueue_mpsc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   11287:	e8 90 f2 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1128c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1128f:	8d 50 40             	lea    0x40(%eax),%edx
   11292:	8b 45 c0             	mov    -0x40(%ebp),%eax
   11295:	89 44 24 04          	mov    %eax,0x4(%esp)
   11299:	89 14 24             	mov    %edx,(%esp)
   1129c:	e8 ee e5 ff ff       	call   f88f <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   112a1:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   112a5:	74 10                	je     112b7 <ck_ring_enqueue_mpsc_size+0x15d>
		*size = (producer - consumer) & mask;
   112a7:	8b 45 b0             	mov    -0x50(%ebp),%eax
   112aa:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   112ad:	23 45 cc             	and    -0x34(%ebp),%eax
   112b0:	89 c2                	mov    %eax,%edx
   112b2:	8b 45 d0             	mov    -0x30(%ebp),%eax
   112b5:	89 10                	mov    %edx,(%eax)

	return r;
   112b7:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   112bb:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   112be:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   112c1:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   112c4:	89 10                	mov    %edx,(%eax)
	return r;
   112c6:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   112ca:	c9                   	leave  
   112cb:	c3                   	ret    

000112cc <ck_ring_dequeue_mpsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   112cc:	55                   	push   %ebp
   112cd:	89 e5                	mov    %esp,%ebp
   112cf:	83 ec 38             	sub    $0x38,%esp
   112d2:	8b 45 08             	mov    0x8(%ebp),%eax
   112d5:	89 45 f4             	mov    %eax,-0xc(%ebp)
   112d8:	8b 45 0c             	mov    0xc(%ebp),%eax
   112db:	89 45 f0             	mov    %eax,-0x10(%ebp)
   112de:	8b 45 10             	mov    0x10(%ebp),%eax
   112e1:	89 45 ec             	mov    %eax,-0x14(%ebp)
   112e4:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   112eb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   112ee:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   112f4:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   112f7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   112fa:	8b 00                	mov    (%eax),%eax
   112fc:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   112ff:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11302:	83 c0 40             	add    $0x40,%eax
   11305:	89 04 24             	mov    %eax,(%esp)
   11308:	e8 f9 e4 ff ff       	call   f806 <ck_pr_md_load_uint>
   1130d:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   11310:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11313:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   11316:	0f 94 c0             	sete   %al
   11319:	0f b6 c0             	movzbl %al,%eax
   1131c:	85 c0                	test   %eax,%eax
   1131e:	74 07                	je     11327 <ck_ring_dequeue_mpsc+0x5b>
		return false;
   11320:	b8 00 00 00 00       	mov    $0x0,%eax
   11325:	eb 4c                	jmp    11373 <ck_ring_dequeue_mpsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   11327:	e8 e5 f1 ff ff       	call   10511 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1132c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1132f:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   11332:	21 d0                	and    %edx,%eax
   11334:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   11338:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   1133b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1133e:	89 44 24 08          	mov    %eax,0x8(%esp)
   11342:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11345:	89 44 24 04          	mov    %eax,0x4(%esp)
   11349:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1134c:	89 04 24             	mov    %eax,(%esp)
   1134f:	e8 fc ff ff ff       	call   11350 <ck_ring_dequeue_mpsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   11354:	e8 c3 f1 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   11359:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1135c:	8d 50 01             	lea    0x1(%eax),%edx
   1135f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11362:	89 54 24 04          	mov    %edx,0x4(%esp)
   11366:	89 04 24             	mov    %eax,(%esp)
   11369:	e8 21 e5 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   1136e:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   11373:	c9                   	leave  
   11374:	c3                   	ret    

00011375 <cos_aepthd_fn>:
	struct cos_aep_info sched_aep[NUM_CPU];
};

static void
cos_aepthd_fn(void *data)
{
   11375:	55                   	push   %ebp
   11376:	89 e5                	mov    %esp,%ebp
   11378:	83 ec 28             	sub    $0x28,%esp
	struct cos_aep_info *aep_info = (struct cos_aep_info *)data;
   1137b:	8b 45 08             	mov    0x8(%ebp),%eax
   1137e:	89 45 f4             	mov    %eax,-0xc(%ebp)
	cos_aepthd_fn_t      aep_fn   = aep_info->fn;
   11381:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11384:	8b 40 10             	mov    0x10(%eax),%eax
   11387:	89 45 f0             	mov    %eax,-0x10(%ebp)
	void *               fn_data  = aep_info->data;
   1138a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1138d:	8b 40 14             	mov    0x14(%eax),%eax
   11390:	89 45 ec             	mov    %eax,-0x14(%ebp)

	(aep_fn)(aep_info->rcv, fn_data);
   11393:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11396:	8b 40 0c             	mov    0xc(%eax),%eax
   11399:	8b 55 ec             	mov    -0x14(%ebp),%edx
   1139c:	89 54 24 04          	mov    %edx,0x4(%esp)
   113a0:	89 04 24             	mov    %eax,(%esp)
   113a3:	8b 45 f0             	mov    -0x10(%ebp),%eax
   113a6:	ff d0                	call   *%eax

	/* TODO: handling destruction */
	assert(0);
   113a8:	c7 04 24 0c 28 00 00 	movl   $0x280c,(%esp)
   113af:	e8 5a e0 ff ff       	call   f40e <prints>
   113b4:	a1 9c 02 00 00       	mov    0x29c,%eax
   113b9:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   113bf:	e8 d1 e0 ff ff       	call   f495 <__cos_noret>

000113c4 <ck_ring_enqueue_spsc_size_xcpu>:
			struct cos_defcompinfo *dci, *sched;
		} sl_xcpu_req_initaep_alloc;
	};
};

CK_RING_PROTOTYPE(xcpu, sl_xcpu_request);
   113c4:	55                   	push   %ebp
   113c5:	89 e5                	mov    %esp,%ebp
   113c7:	83 ec 58             	sub    $0x58,%esp
   113ca:	8b 45 08             	mov    0x8(%ebp),%eax
   113cd:	89 45 f4             	mov    %eax,-0xc(%ebp)
   113d0:	8b 45 0c             	mov    0xc(%ebp),%eax
   113d3:	89 45 f0             	mov    %eax,-0x10(%ebp)
   113d6:	8b 45 10             	mov    0x10(%ebp),%eax
   113d9:	89 45 ec             	mov    %eax,-0x14(%ebp)
   113dc:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   113e3:	8b 45 14             	mov    0x14(%ebp),%eax
   113e6:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   113e9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   113ec:	89 45 e0             	mov    %eax,-0x20(%ebp)
   113ef:	8b 45 f0             	mov    -0x10(%ebp),%eax
   113f2:	89 45 dc             	mov    %eax,-0x24(%ebp)
   113f5:	8b 45 ec             	mov    -0x14(%ebp),%eax
   113f8:	89 45 d8             	mov    %eax,-0x28(%ebp)
   113fb:	8b 45 e8             	mov    -0x18(%ebp),%eax
   113fe:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   11401:	8d 45 b8             	lea    -0x48(%ebp),%eax
   11404:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   11407:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1140a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   11410:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   11413:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11416:	89 04 24             	mov    %eax,(%esp)
   11419:	e8 e8 e3 ff ff       	call   f806 <ck_pr_md_load_uint>
   1141e:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   11421:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11424:	8b 40 40             	mov    0x40(%eax),%eax
   11427:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1142a:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1142d:	83 c0 01             	add    $0x1,%eax
   11430:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   11433:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   11437:	74 14                	je     1144d <ck_ring_enqueue_spsc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   11439:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1143c:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   1143f:	29 c2                	sub    %eax,%edx
   11441:	89 d0                	mov    %edx,%eax
   11443:	23 45 cc             	and    -0x34(%ebp),%eax
   11446:	89 c2                	mov    %eax,%edx
   11448:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1144b:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1144d:	8b 45 c0             	mov    -0x40(%ebp),%eax
   11450:	8b 55 c8             	mov    -0x38(%ebp),%edx
   11453:	31 d0                	xor    %edx,%eax
   11455:	23 45 cc             	and    -0x34(%ebp),%eax
   11458:	85 c0                	test   %eax,%eax
   1145a:	0f 94 c0             	sete   %al
   1145d:	0f b6 c0             	movzbl %al,%eax
   11460:	85 c0                	test   %eax,%eax
   11462:	74 07                	je     1146b <ck_ring_enqueue_spsc_size_xcpu+0xa7>
		return false;
   11464:	b8 00 00 00 00       	mov    $0x0,%eax
   11469:	eb 47                	jmp    114b2 <ck_ring_enqueue_spsc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1146b:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1146e:	8b 55 cc             	mov    -0x34(%ebp),%edx
   11471:	21 d0                	and    %edx,%eax
   11473:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   11477:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1147a:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1147d:	89 44 24 08          	mov    %eax,0x8(%esp)
   11481:	8b 45 d8             	mov    -0x28(%ebp),%eax
   11484:	89 44 24 04          	mov    %eax,0x4(%esp)
   11488:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1148b:	89 04 24             	mov    %eax,(%esp)
   1148e:	e8 fc ff ff ff       	call   1148f <ck_ring_enqueue_spsc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   11493:	e8 84 f0 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   11498:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1149b:	8d 50 40             	lea    0x40(%eax),%edx
   1149e:	8b 45 c0             	mov    -0x40(%ebp),%eax
   114a1:	89 44 24 04          	mov    %eax,0x4(%esp)
   114a5:	89 14 24             	mov    %edx,(%esp)
   114a8:	e8 e2 e3 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   114ad:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   114b2:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   114b5:	8b 55 b8             	mov    -0x48(%ebp),%edx
   114b8:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   114bb:	89 10                	mov    %edx,(%eax)
	return r;
   114bd:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   114c1:	c9                   	leave  
   114c2:	c3                   	ret    

000114c3 <ck_ring_enqueue_spsc_xcpu>:
   114c3:	55                   	push   %ebp
   114c4:	89 e5                	mov    %esp,%ebp
   114c6:	83 ec 48             	sub    $0x48,%esp
   114c9:	8b 45 08             	mov    0x8(%ebp),%eax
   114cc:	89 45 f4             	mov    %eax,-0xc(%ebp)
   114cf:	8b 45 0c             	mov    0xc(%ebp),%eax
   114d2:	89 45 f0             	mov    %eax,-0x10(%ebp)
   114d5:	8b 45 10             	mov    0x10(%ebp),%eax
   114d8:	89 45 ec             	mov    %eax,-0x14(%ebp)
   114db:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   114e2:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   114e9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   114ec:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   114f2:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   114f5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   114f8:	89 04 24             	mov    %eax,(%esp)
   114fb:	e8 06 e3 ff ff       	call   f806 <ck_pr_md_load_uint>
   11500:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   11503:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11506:	8b 40 40             	mov    0x40(%eax),%eax
   11509:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1150c:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1150f:	83 c0 01             	add    $0x1,%eax
   11512:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   11515:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   11519:	74 14                	je     1152f <ck_ring_enqueue_spsc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   1151b:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1151e:	8b 55 d8             	mov    -0x28(%ebp),%edx
   11521:	29 c2                	sub    %eax,%edx
   11523:	89 d0                	mov    %edx,%eax
   11525:	23 45 e0             	and    -0x20(%ebp),%eax
   11528:	89 c2                	mov    %eax,%edx
   1152a:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1152d:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1152f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   11532:	8b 55 dc             	mov    -0x24(%ebp),%edx
   11535:	31 d0                	xor    %edx,%eax
   11537:	23 45 e0             	and    -0x20(%ebp),%eax
   1153a:	85 c0                	test   %eax,%eax
   1153c:	0f 94 c0             	sete   %al
   1153f:	0f b6 c0             	movzbl %al,%eax
   11542:	85 c0                	test   %eax,%eax
   11544:	74 07                	je     1154d <ck_ring_enqueue_spsc_xcpu+0x8a>
		return false;
   11546:	b8 00 00 00 00       	mov    $0x0,%eax
   1154b:	eb 47                	jmp    11594 <ck_ring_enqueue_spsc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1154d:	8b 45 d8             	mov    -0x28(%ebp),%eax
   11550:	8b 55 e0             	mov    -0x20(%ebp),%edx
   11553:	21 d0                	and    %edx,%eax
   11555:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   11559:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1155c:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1155f:	89 44 24 08          	mov    %eax,0x8(%esp)
   11563:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11566:	89 44 24 04          	mov    %eax,0x4(%esp)
   1156a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1156d:	89 04 24             	mov    %eax,(%esp)
   11570:	e8 fc ff ff ff       	call   11571 <ck_ring_enqueue_spsc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   11575:	e8 a2 ef ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1157a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1157d:	8d 50 40             	lea    0x40(%eax),%edx
   11580:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   11583:	89 44 24 04          	mov    %eax,0x4(%esp)
   11587:	89 14 24             	mov    %edx,(%esp)
   1158a:	e8 00 e3 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   1158f:	b8 01 00 00 00       	mov    $0x1,%eax
   11594:	c9                   	leave  
   11595:	c3                   	ret    

00011596 <ck_ring_dequeue_spsc_xcpu>:
   11596:	55                   	push   %ebp
   11597:	89 e5                	mov    %esp,%ebp
   11599:	83 ec 38             	sub    $0x38,%esp
   1159c:	8b 45 08             	mov    0x8(%ebp),%eax
   1159f:	89 45 f4             	mov    %eax,-0xc(%ebp)
   115a2:	8b 45 0c             	mov    0xc(%ebp),%eax
   115a5:	89 45 f0             	mov    %eax,-0x10(%ebp)
   115a8:	8b 45 10             	mov    0x10(%ebp),%eax
   115ab:	89 45 ec             	mov    %eax,-0x14(%ebp)
   115ae:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   115b5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   115b8:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   115be:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   115c1:	8b 45 f4             	mov    -0xc(%ebp),%eax
   115c4:	8b 00                	mov    (%eax),%eax
   115c6:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   115c9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   115cc:	83 c0 40             	add    $0x40,%eax
   115cf:	89 04 24             	mov    %eax,(%esp)
   115d2:	e8 2f e2 ff ff       	call   f806 <ck_pr_md_load_uint>
   115d7:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   115da:	8b 45 e0             	mov    -0x20(%ebp),%eax
   115dd:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   115e0:	0f 94 c0             	sete   %al
   115e3:	0f b6 c0             	movzbl %al,%eax
   115e6:	85 c0                	test   %eax,%eax
   115e8:	74 07                	je     115f1 <ck_ring_dequeue_spsc_xcpu+0x5b>
		return false;
   115ea:	b8 00 00 00 00       	mov    $0x0,%eax
   115ef:	eb 4c                	jmp    1163d <ck_ring_dequeue_spsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   115f1:	e8 1b ef ff ff       	call   10511 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   115f6:	8b 45 e0             	mov    -0x20(%ebp),%eax
   115f9:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   115fc:	21 d0                	and    %edx,%eax
   115fe:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   11602:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   11605:	8b 45 e8             	mov    -0x18(%ebp),%eax
   11608:	89 44 24 08          	mov    %eax,0x8(%esp)
   1160c:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1160f:	89 44 24 04          	mov    %eax,0x4(%esp)
   11613:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11616:	89 04 24             	mov    %eax,(%esp)
   11619:	e8 fc ff ff ff       	call   1161a <ck_ring_dequeue_spsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   1161e:	e8 f9 ee ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   11623:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11626:	8d 50 01             	lea    0x1(%eax),%edx
   11629:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1162c:	89 54 24 04          	mov    %edx,0x4(%esp)
   11630:	89 04 24             	mov    %eax,(%esp)
   11633:	e8 57 e2 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   11638:	b8 01 00 00 00       	mov    $0x1,%eax
   1163d:	c9                   	leave  
   1163e:	c3                   	ret    

0001163f <ck_ring_enqueue_spmc_size_xcpu>:
   1163f:	55                   	push   %ebp
   11640:	89 e5                	mov    %esp,%ebp
   11642:	83 ec 58             	sub    $0x58,%esp
   11645:	8b 45 08             	mov    0x8(%ebp),%eax
   11648:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1164b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1164e:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11651:	8b 45 10             	mov    0x10(%ebp),%eax
   11654:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11657:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1165e:	8b 45 14             	mov    0x14(%ebp),%eax
   11661:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   11664:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11667:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1166a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1166d:	89 45 dc             	mov    %eax,-0x24(%ebp)
   11670:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11673:	89 45 d8             	mov    %eax,-0x28(%ebp)
   11676:	8b 45 e8             	mov    -0x18(%ebp),%eax
   11679:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1167c:	8d 45 b8             	lea    -0x48(%ebp),%eax
   1167f:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   11682:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11685:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1168b:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1168e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11691:	89 04 24             	mov    %eax,(%esp)
   11694:	e8 6d e1 ff ff       	call   f806 <ck_pr_md_load_uint>
   11699:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   1169c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1169f:	8b 40 40             	mov    0x40(%eax),%eax
   116a2:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   116a5:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   116a8:	83 c0 01             	add    $0x1,%eax
   116ab:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   116ae:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   116b2:	74 14                	je     116c8 <ck_ring_enqueue_spmc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   116b4:	8b 45 c8             	mov    -0x38(%ebp),%eax
   116b7:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   116ba:	29 c2                	sub    %eax,%edx
   116bc:	89 d0                	mov    %edx,%eax
   116be:	23 45 cc             	and    -0x34(%ebp),%eax
   116c1:	89 c2                	mov    %eax,%edx
   116c3:	8b 45 d0             	mov    -0x30(%ebp),%eax
   116c6:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   116c8:	8b 45 c0             	mov    -0x40(%ebp),%eax
   116cb:	8b 55 c8             	mov    -0x38(%ebp),%edx
   116ce:	31 d0                	xor    %edx,%eax
   116d0:	23 45 cc             	and    -0x34(%ebp),%eax
   116d3:	85 c0                	test   %eax,%eax
   116d5:	0f 94 c0             	sete   %al
   116d8:	0f b6 c0             	movzbl %al,%eax
   116db:	85 c0                	test   %eax,%eax
   116dd:	74 07                	je     116e6 <ck_ring_enqueue_spmc_size_xcpu+0xa7>
		return false;
   116df:	b8 00 00 00 00       	mov    $0x0,%eax
   116e4:	eb 47                	jmp    1172d <ck_ring_enqueue_spmc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   116e6:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   116e9:	8b 55 cc             	mov    -0x34(%ebp),%edx
   116ec:	21 d0                	and    %edx,%eax
   116ee:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   116f2:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   116f5:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   116f8:	89 44 24 08          	mov    %eax,0x8(%esp)
   116fc:	8b 45 d8             	mov    -0x28(%ebp),%eax
   116ff:	89 44 24 04          	mov    %eax,0x4(%esp)
   11703:	8b 45 dc             	mov    -0x24(%ebp),%eax
   11706:	89 04 24             	mov    %eax,(%esp)
   11709:	e8 fc ff ff ff       	call   1170a <ck_ring_enqueue_spmc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1170e:	e8 09 ee ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   11713:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11716:	8d 50 40             	lea    0x40(%eax),%edx
   11719:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1171c:	89 44 24 04          	mov    %eax,0x4(%esp)
   11720:	89 14 24             	mov    %edx,(%esp)
   11723:	e8 67 e1 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   11728:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   1172d:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   11730:	8b 55 b8             	mov    -0x48(%ebp),%edx
   11733:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   11736:	89 10                	mov    %edx,(%eax)
	return r;
   11738:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   1173c:	c9                   	leave  
   1173d:	c3                   	ret    

0001173e <ck_ring_enqueue_spmc_xcpu>:
   1173e:	55                   	push   %ebp
   1173f:	89 e5                	mov    %esp,%ebp
   11741:	83 ec 48             	sub    $0x48,%esp
   11744:	8b 45 08             	mov    0x8(%ebp),%eax
   11747:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1174a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1174d:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11750:	8b 45 10             	mov    0x10(%ebp),%eax
   11753:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11756:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1175d:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   11764:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11767:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1176d:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   11770:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11773:	89 04 24             	mov    %eax,(%esp)
   11776:	e8 8b e0 ff ff       	call   f806 <ck_pr_md_load_uint>
   1177b:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   1177e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11781:	8b 40 40             	mov    0x40(%eax),%eax
   11784:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   11787:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1178a:	83 c0 01             	add    $0x1,%eax
   1178d:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   11790:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   11794:	74 14                	je     117aa <ck_ring_enqueue_spmc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   11796:	8b 45 dc             	mov    -0x24(%ebp),%eax
   11799:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1179c:	29 c2                	sub    %eax,%edx
   1179e:	89 d0                	mov    %edx,%eax
   117a0:	23 45 e0             	and    -0x20(%ebp),%eax
   117a3:	89 c2                	mov    %eax,%edx
   117a5:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   117a8:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   117aa:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   117ad:	8b 55 dc             	mov    -0x24(%ebp),%edx
   117b0:	31 d0                	xor    %edx,%eax
   117b2:	23 45 e0             	and    -0x20(%ebp),%eax
   117b5:	85 c0                	test   %eax,%eax
   117b7:	0f 94 c0             	sete   %al
   117ba:	0f b6 c0             	movzbl %al,%eax
   117bd:	85 c0                	test   %eax,%eax
   117bf:	74 07                	je     117c8 <ck_ring_enqueue_spmc_xcpu+0x8a>
		return false;
   117c1:	b8 00 00 00 00       	mov    $0x0,%eax
   117c6:	eb 47                	jmp    1180f <ck_ring_enqueue_spmc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   117c8:	8b 45 d8             	mov    -0x28(%ebp),%eax
   117cb:	8b 55 e0             	mov    -0x20(%ebp),%edx
   117ce:	21 d0                	and    %edx,%eax
   117d0:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   117d4:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   117d7:	8b 45 e8             	mov    -0x18(%ebp),%eax
   117da:	89 44 24 08          	mov    %eax,0x8(%esp)
   117de:	8b 45 ec             	mov    -0x14(%ebp),%eax
   117e1:	89 44 24 04          	mov    %eax,0x4(%esp)
   117e5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   117e8:	89 04 24             	mov    %eax,(%esp)
   117eb:	e8 fc ff ff ff       	call   117ec <ck_ring_enqueue_spmc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   117f0:	e8 27 ed ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   117f5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   117f8:	8d 50 40             	lea    0x40(%eax),%edx
   117fb:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   117fe:	89 44 24 04          	mov    %eax,0x4(%esp)
   11802:	89 14 24             	mov    %edx,(%esp)
   11805:	e8 85 e0 ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   1180a:	b8 01 00 00 00       	mov    $0x1,%eax
   1180f:	c9                   	leave  
   11810:	c3                   	ret    

00011811 <ck_ring_trydequeue_spmc_xcpu>:
   11811:	55                   	push   %ebp
   11812:	89 e5                	mov    %esp,%ebp
   11814:	83 ec 38             	sub    $0x38,%esp
   11817:	8b 45 08             	mov    0x8(%ebp),%eax
   1181a:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1181d:	8b 45 0c             	mov    0xc(%ebp),%eax
   11820:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11823:	8b 45 10             	mov    0x10(%ebp),%eax
   11826:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11829:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   11830:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11833:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   11839:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1183c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1183f:	89 04 24             	mov    %eax,(%esp)
   11842:	e8 bf df ff ff       	call   f806 <ck_pr_md_load_uint>
   11847:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   1184a:	e8 c2 ec ff ff       	call   10511 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   1184f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11852:	83 c0 40             	add    $0x40,%eax
   11855:	89 04 24             	mov    %eax,(%esp)
   11858:	e8 a9 df ff ff       	call   f806 <ck_pr_md_load_uint>
   1185d:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   11860:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11863:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   11866:	0f 94 c0             	sete   %al
   11869:	0f b6 c0             	movzbl %al,%eax
   1186c:	85 c0                	test   %eax,%eax
   1186e:	74 07                	je     11877 <ck_ring_trydequeue_spmc_xcpu+0x66>
		return false;
   11870:	b8 00 00 00 00       	mov    $0x0,%eax
   11875:	eb 4e                	jmp    118c5 <ck_ring_trydequeue_spmc_xcpu+0xb4>

	ck_pr_fence_load();
   11877:	e8 95 ec ff ff       	call   10511 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1187c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1187f:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   11882:	21 d0                	and    %edx,%eax
   11884:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   11888:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1188b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1188e:	89 44 24 08          	mov    %eax,0x8(%esp)
   11892:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11895:	89 44 24 04          	mov    %eax,0x4(%esp)
   11899:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1189c:	89 04 24             	mov    %eax,(%esp)
   1189f:	e8 fc ff ff ff       	call   118a0 <ck_ring_trydequeue_spmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   118a4:	e8 3c ec ff ff       	call   104e5 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   118a9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   118ac:	8d 50 01             	lea    0x1(%eax),%edx
   118af:	8b 45 f4             	mov    -0xc(%ebp),%eax
   118b2:	89 54 24 08          	mov    %edx,0x8(%esp)
   118b6:	8b 55 e0             	mov    -0x20(%ebp),%edx
   118b9:	89 54 24 04          	mov    %edx,0x4(%esp)
   118bd:	89 04 24             	mov    %eax,(%esp)
   118c0:	e8 ef e7 ff ff       	call   100b4 <ck_pr_cas_uint>
   118c5:	c9                   	leave  
   118c6:	c3                   	ret    

000118c7 <ck_ring_dequeue_spmc_xcpu>:
   118c7:	55                   	push   %ebp
   118c8:	89 e5                	mov    %esp,%ebp
   118ca:	53                   	push   %ebx
   118cb:	83 ec 34             	sub    $0x34,%esp
   118ce:	8b 45 08             	mov    0x8(%ebp),%eax
   118d1:	89 45 f4             	mov    %eax,-0xc(%ebp)
   118d4:	8b 45 0c             	mov    0xc(%ebp),%eax
   118d7:	89 45 f0             	mov    %eax,-0x10(%ebp)
   118da:	8b 45 10             	mov    0x10(%ebp),%eax
   118dd:	89 45 ec             	mov    %eax,-0x14(%ebp)
   118e0:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   118e7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   118ea:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   118f0:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   118f3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   118f6:	89 04 24             	mov    %eax,(%esp)
   118f9:	e8 08 df ff ff       	call   f806 <ck_pr_md_load_uint>
   118fe:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   11901:	e8 0b ec ff ff       	call   10511 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   11906:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11909:	83 c0 40             	add    $0x40,%eax
   1190c:	89 04 24             	mov    %eax,(%esp)
   1190f:	e8 f2 de ff ff       	call   f806 <ck_pr_md_load_uint>
   11914:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   11917:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1191a:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1191d:	0f 94 c0             	sete   %al
   11920:	0f b6 c0             	movzbl %al,%eax
   11923:	85 c0                	test   %eax,%eax
   11925:	74 07                	je     1192e <ck_ring_dequeue_spmc_xcpu+0x67>
			return false;
   11927:	b8 00 00 00 00       	mov    $0x0,%eax
   1192c:	eb 6a                	jmp    11998 <ck_ring_dequeue_spmc_xcpu+0xd1>

		ck_pr_fence_load();
   1192e:	e8 de eb ff ff       	call   10511 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   11933:	8b 45 d8             	mov    -0x28(%ebp),%eax
   11936:	23 45 e4             	and    -0x1c(%ebp),%eax
   11939:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1193d:	89 c2                	mov    %eax,%edx
   1193f:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11942:	01 d0                	add    %edx,%eax
   11944:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   11947:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1194a:	89 44 24 08          	mov    %eax,0x8(%esp)
   1194e:	8b 45 dc             	mov    -0x24(%ebp),%eax
   11951:	89 44 24 04          	mov    %eax,0x4(%esp)
   11955:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11958:	89 04 24             	mov    %eax,(%esp)
   1195b:	e8 fc ff ff ff       	call   1195c <ck_ring_dequeue_spmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   11960:	e8 80 eb ff ff       	call   104e5 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   11965:	8b 45 d8             	mov    -0x28(%ebp),%eax
   11968:	8d 58 01             	lea    0x1(%eax),%ebx
   1196b:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1196e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11971:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   11974:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   11978:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1197c:	89 54 24 04          	mov    %edx,0x4(%esp)
   11980:	89 04 24             	mov    %eax,(%esp)
   11983:	e8 7f e8 ff ff       	call   10207 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   11988:	83 f0 01             	xor    $0x1,%eax
   1198b:	84 c0                	test   %al,%al
   1198d:	0f 85 6e ff ff ff    	jne    11901 <ck_ring_dequeue_spmc_xcpu+0x3a>

	return true;
   11993:	b8 01 00 00 00       	mov    $0x1,%eax
   11998:	83 c4 34             	add    $0x34,%esp
   1199b:	5b                   	pop    %ebx
   1199c:	5d                   	pop    %ebp
   1199d:	c3                   	ret    

0001199e <ck_ring_enqueue_mpsc_xcpu>:
   1199e:	55                   	push   %ebp
   1199f:	89 e5                	mov    %esp,%ebp
   119a1:	83 ec 48             	sub    $0x48,%esp
   119a4:	8b 45 08             	mov    0x8(%ebp),%eax
   119a7:	89 45 f4             	mov    %eax,-0xc(%ebp)
   119aa:	8b 45 0c             	mov    0xc(%ebp),%eax
   119ad:	89 45 f0             	mov    %eax,-0x10(%ebp)
   119b0:	8b 45 10             	mov    0x10(%ebp),%eax
   119b3:	89 45 ec             	mov    %eax,-0x14(%ebp)
   119b6:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   119bd:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   119c4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   119c7:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   119cd:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   119d0:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   119d4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   119d7:	83 c0 44             	add    $0x44,%eax
   119da:	89 04 24             	mov    %eax,(%esp)
   119dd:	e8 24 de ff ff       	call   f806 <ck_pr_md_load_uint>
   119e2:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   119e5:	e8 27 eb ff ff       	call   10511 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   119ea:	8b 45 f4             	mov    -0xc(%ebp),%eax
   119ed:	89 04 24             	mov    %eax,(%esp)
   119f0:	e8 11 de ff ff       	call   f806 <ck_pr_md_load_uint>
   119f5:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   119f8:	8b 45 cc             	mov    -0x34(%ebp),%eax
   119fb:	83 c0 01             	add    $0x1,%eax
   119fe:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   11a01:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11a04:	2b 45 d8             	sub    -0x28(%ebp),%eax
   11a07:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   11a0a:	0f 97 c0             	seta   %al
   11a0d:	0f b6 c0             	movzbl %al,%eax
   11a10:	85 c0                	test   %eax,%eax
   11a12:	74 29                	je     11a3d <ck_ring_enqueue_mpsc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   11a14:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11a17:	8b 55 f4             	mov    -0xc(%ebp),%edx
   11a1a:	8d 4a 44             	lea    0x44(%edx),%ecx
   11a1d:	8d 55 cc             	lea    -0x34(%ebp),%edx
   11a20:	89 54 24 0c          	mov    %edx,0xc(%esp)
   11a24:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   11a27:	89 54 24 08          	mov    %edx,0x8(%esp)
   11a2b:	89 44 24 04          	mov    %eax,0x4(%esp)
   11a2f:	89 0c 24             	mov    %ecx,(%esp)
   11a32:	e8 d0 e7 ff ff       	call   10207 <ck_pr_cas_uint_value>
   11a37:	84 c0                	test   %al,%al
   11a39:	75 31                	jne    11a6c <ck_ring_enqueue_mpsc_xcpu+0xce>
   11a3b:	eb a8                	jmp    119e5 <ck_ring_enqueue_mpsc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   11a3d:	e8 cf ea ff ff       	call   10511 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   11a42:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11a45:	83 c0 44             	add    $0x44,%eax
   11a48:	89 04 24             	mov    %eax,(%esp)
   11a4b:	e8 b6 dd ff ff       	call   f806 <ck_pr_md_load_uint>
   11a50:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   11a53:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11a56:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   11a59:	75 06                	jne    11a61 <ck_ring_enqueue_mpsc_xcpu+0xc3>
				r = false;
   11a5b:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   11a5f:	eb 67                	jmp    11ac8 <ck_ring_enqueue_mpsc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   11a61:	8b 45 d0             	mov    -0x30(%ebp),%eax
   11a64:	89 45 cc             	mov    %eax,-0x34(%ebp)
   11a67:	e9 79 ff ff ff       	jmp    119e5 <ck_ring_enqueue_mpsc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   11a6c:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11a6f:	23 45 e0             	and    -0x20(%ebp),%eax
   11a72:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   11a76:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   11a79:	8b 45 e8             	mov    -0x18(%ebp),%eax
   11a7c:	89 44 24 08          	mov    %eax,0x8(%esp)
   11a80:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11a83:	89 44 24 04          	mov    %eax,0x4(%esp)
   11a87:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11a8a:	89 04 24             	mov    %eax,(%esp)
   11a8d:	e8 fc ff ff ff       	call   11a8e <ck_ring_enqueue_mpsc_xcpu+0xf0>
   11a92:	eb 05                	jmp    11a99 <ck_ring_enqueue_mpsc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   11a94:	e8 08 dc ff ff       	call   f6a1 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   11a99:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11a9c:	83 c0 40             	add    $0x40,%eax
   11a9f:	89 04 24             	mov    %eax,(%esp)
   11aa2:	e8 5f dd ff ff       	call   f806 <ck_pr_md_load_uint>
   11aa7:	8b 55 cc             	mov    -0x34(%ebp),%edx
   11aaa:	39 d0                	cmp    %edx,%eax
   11aac:	75 e6                	jne    11a94 <ck_ring_enqueue_mpsc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   11aae:	e8 69 ea ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   11ab3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11ab6:	8d 50 40             	lea    0x40(%eax),%edx
   11ab9:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   11abc:	89 44 24 04          	mov    %eax,0x4(%esp)
   11ac0:	89 14 24             	mov    %edx,(%esp)
   11ac3:	e8 c7 dd ff ff       	call   f88f <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   11ac8:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   11acc:	74 10                	je     11ade <ck_ring_enqueue_mpsc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   11ace:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11ad1:	2b 45 d8             	sub    -0x28(%ebp),%eax
   11ad4:	23 45 e0             	and    -0x20(%ebp),%eax
   11ad7:	89 c2                	mov    %eax,%edx
   11ad9:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   11adc:	89 10                	mov    %edx,(%eax)

	return r;
   11ade:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   11ae2:	c9                   	leave  
   11ae3:	c3                   	ret    

00011ae4 <ck_ring_enqueue_mpsc_size_xcpu>:
   11ae4:	55                   	push   %ebp
   11ae5:	89 e5                	mov    %esp,%ebp
   11ae7:	83 ec 68             	sub    $0x68,%esp
   11aea:	8b 45 08             	mov    0x8(%ebp),%eax
   11aed:	89 45 f4             	mov    %eax,-0xc(%ebp)
   11af0:	8b 45 0c             	mov    0xc(%ebp),%eax
   11af3:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11af6:	8b 45 10             	mov    0x10(%ebp),%eax
   11af9:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11afc:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   11b03:	8b 45 14             	mov    0x14(%ebp),%eax
   11b06:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   11b09:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11b0c:	89 45 e0             	mov    %eax,-0x20(%ebp)
   11b0f:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11b12:	89 45 dc             	mov    %eax,-0x24(%ebp)
   11b15:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11b18:	89 45 d8             	mov    %eax,-0x28(%ebp)
   11b1b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   11b1e:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   11b21:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   11b24:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   11b27:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11b2a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   11b30:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   11b33:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   11b37:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11b3a:	83 c0 44             	add    $0x44,%eax
   11b3d:	89 04 24             	mov    %eax,(%esp)
   11b40:	e8 c1 dc ff ff       	call   f806 <ck_pr_md_load_uint>
   11b45:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   11b48:	e8 c4 e9 ff ff       	call   10511 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   11b4d:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11b50:	89 04 24             	mov    %eax,(%esp)
   11b53:	e8 ae dc ff ff       	call   f806 <ck_pr_md_load_uint>
   11b58:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   11b5b:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11b5e:	83 c0 01             	add    $0x1,%eax
   11b61:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   11b64:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11b67:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   11b6a:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   11b6d:	0f 97 c0             	seta   %al
   11b70:	0f b6 c0             	movzbl %al,%eax
   11b73:	85 c0                	test   %eax,%eax
   11b75:	74 29                	je     11ba0 <ck_ring_enqueue_mpsc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   11b77:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11b7a:	8b 55 e0             	mov    -0x20(%ebp),%edx
   11b7d:	8d 4a 44             	lea    0x44(%edx),%ecx
   11b80:	8d 55 b0             	lea    -0x50(%ebp),%edx
   11b83:	89 54 24 0c          	mov    %edx,0xc(%esp)
   11b87:	8b 55 c0             	mov    -0x40(%ebp),%edx
   11b8a:	89 54 24 08          	mov    %edx,0x8(%esp)
   11b8e:	89 44 24 04          	mov    %eax,0x4(%esp)
   11b92:	89 0c 24             	mov    %ecx,(%esp)
   11b95:	e8 6d e6 ff ff       	call   10207 <ck_pr_cas_uint_value>
   11b9a:	84 c0                	test   %al,%al
   11b9c:	75 31                	jne    11bcf <ck_ring_enqueue_mpsc_size_xcpu+0xeb>
   11b9e:	eb a8                	jmp    11b48 <ck_ring_enqueue_mpsc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   11ba0:	e8 6c e9 ff ff       	call   10511 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   11ba5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11ba8:	83 c0 44             	add    $0x44,%eax
   11bab:	89 04 24             	mov    %eax,(%esp)
   11bae:	e8 53 dc ff ff       	call   f806 <ck_pr_md_load_uint>
   11bb3:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   11bb6:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11bb9:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   11bbc:	75 06                	jne    11bc4 <ck_ring_enqueue_mpsc_size_xcpu+0xe0>
				r = false;
   11bbe:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   11bc2:	eb 67                	jmp    11c2b <ck_ring_enqueue_mpsc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   11bc4:	8b 45 bc             	mov    -0x44(%ebp),%eax
   11bc7:	89 45 b0             	mov    %eax,-0x50(%ebp)
   11bca:	e9 79 ff ff ff       	jmp    11b48 <ck_ring_enqueue_mpsc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   11bcf:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11bd2:	23 45 cc             	and    -0x34(%ebp),%eax
   11bd5:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   11bd9:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   11bdc:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   11bdf:	89 44 24 08          	mov    %eax,0x8(%esp)
   11be3:	8b 45 d8             	mov    -0x28(%ebp),%eax
   11be6:	89 44 24 04          	mov    %eax,0x4(%esp)
   11bea:	8b 45 dc             	mov    -0x24(%ebp),%eax
   11bed:	89 04 24             	mov    %eax,(%esp)
   11bf0:	e8 fc ff ff ff       	call   11bf1 <ck_ring_enqueue_mpsc_size_xcpu+0x10d>
   11bf5:	eb 05                	jmp    11bfc <ck_ring_enqueue_mpsc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   11bf7:	e8 a5 da ff ff       	call   f6a1 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   11bfc:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11bff:	83 c0 40             	add    $0x40,%eax
   11c02:	89 04 24             	mov    %eax,(%esp)
   11c05:	e8 fc db ff ff       	call   f806 <ck_pr_md_load_uint>
   11c0a:	8b 55 b0             	mov    -0x50(%ebp),%edx
   11c0d:	39 d0                	cmp    %edx,%eax
   11c0f:	75 e6                	jne    11bf7 <ck_ring_enqueue_mpsc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   11c11:	e8 06 e9 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   11c16:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11c19:	8d 50 40             	lea    0x40(%eax),%edx
   11c1c:	8b 45 c0             	mov    -0x40(%ebp),%eax
   11c1f:	89 44 24 04          	mov    %eax,0x4(%esp)
   11c23:	89 14 24             	mov    %edx,(%esp)
   11c26:	e8 64 dc ff ff       	call   f88f <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   11c2b:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   11c2f:	74 10                	je     11c41 <ck_ring_enqueue_mpsc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   11c31:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11c34:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   11c37:	23 45 cc             	and    -0x34(%ebp),%eax
   11c3a:	89 c2                	mov    %eax,%edx
   11c3c:	8b 45 d0             	mov    -0x30(%ebp),%eax
   11c3f:	89 10                	mov    %edx,(%eax)

	return r;
   11c41:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   11c45:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   11c48:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   11c4b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   11c4e:	89 10                	mov    %edx,(%eax)
	return r;
   11c50:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   11c54:	c9                   	leave  
   11c55:	c3                   	ret    

00011c56 <ck_ring_dequeue_mpsc_xcpu>:
   11c56:	55                   	push   %ebp
   11c57:	89 e5                	mov    %esp,%ebp
   11c59:	83 ec 38             	sub    $0x38,%esp
   11c5c:	8b 45 08             	mov    0x8(%ebp),%eax
   11c5f:	89 45 f4             	mov    %eax,-0xc(%ebp)
   11c62:	8b 45 0c             	mov    0xc(%ebp),%eax
   11c65:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11c68:	8b 45 10             	mov    0x10(%ebp),%eax
   11c6b:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11c6e:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   11c75:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11c78:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   11c7e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   11c81:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11c84:	8b 00                	mov    (%eax),%eax
   11c86:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   11c89:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11c8c:	83 c0 40             	add    $0x40,%eax
   11c8f:	89 04 24             	mov    %eax,(%esp)
   11c92:	e8 6f db ff ff       	call   f806 <ck_pr_md_load_uint>
   11c97:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   11c9a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11c9d:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   11ca0:	0f 94 c0             	sete   %al
   11ca3:	0f b6 c0             	movzbl %al,%eax
   11ca6:	85 c0                	test   %eax,%eax
   11ca8:	74 07                	je     11cb1 <ck_ring_dequeue_mpsc_xcpu+0x5b>
		return false;
   11caa:	b8 00 00 00 00       	mov    $0x0,%eax
   11caf:	eb 4c                	jmp    11cfd <ck_ring_dequeue_mpsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   11cb1:	e8 5b e8 ff ff       	call   10511 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   11cb6:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11cb9:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   11cbc:	21 d0                	and    %edx,%eax
   11cbe:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   11cc2:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   11cc5:	8b 45 e8             	mov    -0x18(%ebp),%eax
   11cc8:	89 44 24 08          	mov    %eax,0x8(%esp)
   11ccc:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11ccf:	89 44 24 04          	mov    %eax,0x4(%esp)
   11cd3:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11cd6:	89 04 24             	mov    %eax,(%esp)
   11cd9:	e8 fc ff ff ff       	call   11cda <ck_ring_dequeue_mpsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   11cde:	e8 39 e8 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   11ce3:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11ce6:	8d 50 01             	lea    0x1(%eax),%edx
   11ce9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11cec:	89 54 24 04          	mov    %edx,0x4(%esp)
   11cf0:	89 04 24             	mov    %eax,(%esp)
   11cf3:	e8 97 db ff ff       	call   f88f <ck_pr_md_store_uint>
	return true;
   11cf8:	b8 01 00 00 00       	mov    $0x1,%eax
   11cfd:	c9                   	leave  
   11cfe:	c3                   	ret    

00011cff <ck_ring_enqueue_mpmc_size_xcpu>:
   11cff:	55                   	push   %ebp
   11d00:	89 e5                	mov    %esp,%ebp
   11d02:	83 ec 68             	sub    $0x68,%esp
   11d05:	8b 45 08             	mov    0x8(%ebp),%eax
   11d08:	89 45 f4             	mov    %eax,-0xc(%ebp)
   11d0b:	8b 45 0c             	mov    0xc(%ebp),%eax
   11d0e:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11d11:	8b 45 10             	mov    0x10(%ebp),%eax
   11d14:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11d17:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   11d1e:	8b 45 14             	mov    0x14(%ebp),%eax
   11d21:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   11d24:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11d27:	89 45 e0             	mov    %eax,-0x20(%ebp)
   11d2a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11d2d:	89 45 dc             	mov    %eax,-0x24(%ebp)
   11d30:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11d33:	89 45 d8             	mov    %eax,-0x28(%ebp)
   11d36:	8b 45 e8             	mov    -0x18(%ebp),%eax
   11d39:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   11d3c:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   11d3f:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   11d42:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11d45:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   11d4b:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   11d4e:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   11d52:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11d55:	83 c0 44             	add    $0x44,%eax
   11d58:	89 04 24             	mov    %eax,(%esp)
   11d5b:	e8 a6 da ff ff       	call   f806 <ck_pr_md_load_uint>
   11d60:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   11d63:	e8 a9 e7 ff ff       	call   10511 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   11d68:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11d6b:	89 04 24             	mov    %eax,(%esp)
   11d6e:	e8 93 da ff ff       	call   f806 <ck_pr_md_load_uint>
   11d73:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   11d76:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11d79:	83 c0 01             	add    $0x1,%eax
   11d7c:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   11d7f:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11d82:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   11d85:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   11d88:	0f 97 c0             	seta   %al
   11d8b:	0f b6 c0             	movzbl %al,%eax
   11d8e:	85 c0                	test   %eax,%eax
   11d90:	74 29                	je     11dbb <ck_ring_enqueue_mpmc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   11d92:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11d95:	8b 55 e0             	mov    -0x20(%ebp),%edx
   11d98:	8d 4a 44             	lea    0x44(%edx),%ecx
   11d9b:	8d 55 b0             	lea    -0x50(%ebp),%edx
   11d9e:	89 54 24 0c          	mov    %edx,0xc(%esp)
   11da2:	8b 55 c0             	mov    -0x40(%ebp),%edx
   11da5:	89 54 24 08          	mov    %edx,0x8(%esp)
   11da9:	89 44 24 04          	mov    %eax,0x4(%esp)
   11dad:	89 0c 24             	mov    %ecx,(%esp)
   11db0:	e8 52 e4 ff ff       	call   10207 <ck_pr_cas_uint_value>
   11db5:	84 c0                	test   %al,%al
   11db7:	75 31                	jne    11dea <ck_ring_enqueue_mpmc_size_xcpu+0xeb>
   11db9:	eb a8                	jmp    11d63 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   11dbb:	e8 51 e7 ff ff       	call   10511 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   11dc0:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11dc3:	83 c0 44             	add    $0x44,%eax
   11dc6:	89 04 24             	mov    %eax,(%esp)
   11dc9:	e8 38 da ff ff       	call   f806 <ck_pr_md_load_uint>
   11dce:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   11dd1:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11dd4:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   11dd7:	75 06                	jne    11ddf <ck_ring_enqueue_mpmc_size_xcpu+0xe0>
				r = false;
   11dd9:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   11ddd:	eb 67                	jmp    11e46 <ck_ring_enqueue_mpmc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   11ddf:	8b 45 bc             	mov    -0x44(%ebp),%eax
   11de2:	89 45 b0             	mov    %eax,-0x50(%ebp)
   11de5:	e9 79 ff ff ff       	jmp    11d63 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   11dea:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11ded:	23 45 cc             	and    -0x34(%ebp),%eax
   11df0:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   11df4:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   11df7:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   11dfa:	89 44 24 08          	mov    %eax,0x8(%esp)
   11dfe:	8b 45 d8             	mov    -0x28(%ebp),%eax
   11e01:	89 44 24 04          	mov    %eax,0x4(%esp)
   11e05:	8b 45 dc             	mov    -0x24(%ebp),%eax
   11e08:	89 04 24             	mov    %eax,(%esp)
   11e0b:	e8 fc ff ff ff       	call   11e0c <ck_ring_enqueue_mpmc_size_xcpu+0x10d>
   11e10:	eb 05                	jmp    11e17 <ck_ring_enqueue_mpmc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   11e12:	e8 8a d8 ff ff       	call   f6a1 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   11e17:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11e1a:	83 c0 40             	add    $0x40,%eax
   11e1d:	89 04 24             	mov    %eax,(%esp)
   11e20:	e8 e1 d9 ff ff       	call   f806 <ck_pr_md_load_uint>
   11e25:	8b 55 b0             	mov    -0x50(%ebp),%edx
   11e28:	39 d0                	cmp    %edx,%eax
   11e2a:	75 e6                	jne    11e12 <ck_ring_enqueue_mpmc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   11e2c:	e8 eb e6 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   11e31:	8b 45 e0             	mov    -0x20(%ebp),%eax
   11e34:	8d 50 40             	lea    0x40(%eax),%edx
   11e37:	8b 45 c0             	mov    -0x40(%ebp),%eax
   11e3a:	89 44 24 04          	mov    %eax,0x4(%esp)
   11e3e:	89 14 24             	mov    %edx,(%esp)
   11e41:	e8 49 da ff ff       	call   f88f <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   11e46:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   11e4a:	74 10                	je     11e5c <ck_ring_enqueue_mpmc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   11e4c:	8b 45 b0             	mov    -0x50(%ebp),%eax
   11e4f:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   11e52:	23 45 cc             	and    -0x34(%ebp),%eax
   11e55:	89 c2                	mov    %eax,%edx
   11e57:	8b 45 d0             	mov    -0x30(%ebp),%eax
   11e5a:	89 10                	mov    %edx,(%eax)

	return r;
   11e5c:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   11e60:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   11e63:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   11e66:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   11e69:	89 10                	mov    %edx,(%eax)
	return r;
   11e6b:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   11e6f:	c9                   	leave  
   11e70:	c3                   	ret    

00011e71 <ck_ring_enqueue_mpmc_xcpu>:
   11e71:	55                   	push   %ebp
   11e72:	89 e5                	mov    %esp,%ebp
   11e74:	83 ec 48             	sub    $0x48,%esp
   11e77:	8b 45 08             	mov    0x8(%ebp),%eax
   11e7a:	89 45 f4             	mov    %eax,-0xc(%ebp)
   11e7d:	8b 45 0c             	mov    0xc(%ebp),%eax
   11e80:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11e83:	8b 45 10             	mov    0x10(%ebp),%eax
   11e86:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11e89:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   11e90:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   11e97:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11e9a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   11ea0:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   11ea3:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   11ea7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11eaa:	83 c0 44             	add    $0x44,%eax
   11ead:	89 04 24             	mov    %eax,(%esp)
   11eb0:	e8 51 d9 ff ff       	call   f806 <ck_pr_md_load_uint>
   11eb5:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   11eb8:	e8 54 e6 ff ff       	call   10511 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   11ebd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11ec0:	89 04 24             	mov    %eax,(%esp)
   11ec3:	e8 3e d9 ff ff       	call   f806 <ck_pr_md_load_uint>
   11ec8:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   11ecb:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11ece:	83 c0 01             	add    $0x1,%eax
   11ed1:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   11ed4:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11ed7:	2b 45 d8             	sub    -0x28(%ebp),%eax
   11eda:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   11edd:	0f 97 c0             	seta   %al
   11ee0:	0f b6 c0             	movzbl %al,%eax
   11ee3:	85 c0                	test   %eax,%eax
   11ee5:	74 29                	je     11f10 <ck_ring_enqueue_mpmc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   11ee7:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11eea:	8b 55 f4             	mov    -0xc(%ebp),%edx
   11eed:	8d 4a 44             	lea    0x44(%edx),%ecx
   11ef0:	8d 55 cc             	lea    -0x34(%ebp),%edx
   11ef3:	89 54 24 0c          	mov    %edx,0xc(%esp)
   11ef7:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   11efa:	89 54 24 08          	mov    %edx,0x8(%esp)
   11efe:	89 44 24 04          	mov    %eax,0x4(%esp)
   11f02:	89 0c 24             	mov    %ecx,(%esp)
   11f05:	e8 fd e2 ff ff       	call   10207 <ck_pr_cas_uint_value>
   11f0a:	84 c0                	test   %al,%al
   11f0c:	75 31                	jne    11f3f <ck_ring_enqueue_mpmc_xcpu+0xce>
   11f0e:	eb a8                	jmp    11eb8 <ck_ring_enqueue_mpmc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   11f10:	e8 fc e5 ff ff       	call   10511 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   11f15:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11f18:	83 c0 44             	add    $0x44,%eax
   11f1b:	89 04 24             	mov    %eax,(%esp)
   11f1e:	e8 e3 d8 ff ff       	call   f806 <ck_pr_md_load_uint>
   11f23:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   11f26:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11f29:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   11f2c:	75 06                	jne    11f34 <ck_ring_enqueue_mpmc_xcpu+0xc3>
				r = false;
   11f2e:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   11f32:	eb 67                	jmp    11f9b <ck_ring_enqueue_mpmc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   11f34:	8b 45 d0             	mov    -0x30(%ebp),%eax
   11f37:	89 45 cc             	mov    %eax,-0x34(%ebp)
   11f3a:	e9 79 ff ff ff       	jmp    11eb8 <ck_ring_enqueue_mpmc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   11f3f:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11f42:	23 45 e0             	and    -0x20(%ebp),%eax
   11f45:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   11f49:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   11f4c:	8b 45 e8             	mov    -0x18(%ebp),%eax
   11f4f:	89 44 24 08          	mov    %eax,0x8(%esp)
   11f53:	8b 45 ec             	mov    -0x14(%ebp),%eax
   11f56:	89 44 24 04          	mov    %eax,0x4(%esp)
   11f5a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   11f5d:	89 04 24             	mov    %eax,(%esp)
   11f60:	e8 fc ff ff ff       	call   11f61 <ck_ring_enqueue_mpmc_xcpu+0xf0>
   11f65:	eb 05                	jmp    11f6c <ck_ring_enqueue_mpmc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   11f67:	e8 35 d7 ff ff       	call   f6a1 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   11f6c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11f6f:	83 c0 40             	add    $0x40,%eax
   11f72:	89 04 24             	mov    %eax,(%esp)
   11f75:	e8 8c d8 ff ff       	call   f806 <ck_pr_md_load_uint>
   11f7a:	8b 55 cc             	mov    -0x34(%ebp),%edx
   11f7d:	39 d0                	cmp    %edx,%eax
   11f7f:	75 e6                	jne    11f67 <ck_ring_enqueue_mpmc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   11f81:	e8 96 e5 ff ff       	call   1051c <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   11f86:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11f89:	8d 50 40             	lea    0x40(%eax),%edx
   11f8c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   11f8f:	89 44 24 04          	mov    %eax,0x4(%esp)
   11f93:	89 14 24             	mov    %edx,(%esp)
   11f96:	e8 f4 d8 ff ff       	call   f88f <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   11f9b:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   11f9f:	74 10                	je     11fb1 <ck_ring_enqueue_mpmc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   11fa1:	8b 45 cc             	mov    -0x34(%ebp),%eax
   11fa4:	2b 45 d8             	sub    -0x28(%ebp),%eax
   11fa7:	23 45 e0             	and    -0x20(%ebp),%eax
   11faa:	89 c2                	mov    %eax,%edx
   11fac:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   11faf:	89 10                	mov    %edx,(%eax)

	return r;
   11fb1:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   11fb5:	c9                   	leave  
   11fb6:	c3                   	ret    

00011fb7 <ck_ring_trydequeue_mpmc_xcpu>:
   11fb7:	55                   	push   %ebp
   11fb8:	89 e5                	mov    %esp,%ebp
   11fba:	83 ec 38             	sub    $0x38,%esp
   11fbd:	8b 45 08             	mov    0x8(%ebp),%eax
   11fc0:	89 45 f4             	mov    %eax,-0xc(%ebp)
   11fc3:	8b 45 0c             	mov    0xc(%ebp),%eax
   11fc6:	89 45 f0             	mov    %eax,-0x10(%ebp)
   11fc9:	8b 45 10             	mov    0x10(%ebp),%eax
   11fcc:	89 45 ec             	mov    %eax,-0x14(%ebp)
   11fcf:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   11fd6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11fd9:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   11fdf:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   11fe2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11fe5:	89 04 24             	mov    %eax,(%esp)
   11fe8:	e8 19 d8 ff ff       	call   f806 <ck_pr_md_load_uint>
   11fed:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   11ff0:	e8 1c e5 ff ff       	call   10511 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   11ff5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   11ff8:	83 c0 40             	add    $0x40,%eax
   11ffb:	89 04 24             	mov    %eax,(%esp)
   11ffe:	e8 03 d8 ff ff       	call   f806 <ck_pr_md_load_uint>
   12003:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   12006:	8b 45 e0             	mov    -0x20(%ebp),%eax
   12009:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1200c:	0f 94 c0             	sete   %al
   1200f:	0f b6 c0             	movzbl %al,%eax
   12012:	85 c0                	test   %eax,%eax
   12014:	74 07                	je     1201d <ck_ring_trydequeue_mpmc_xcpu+0x66>
		return false;
   12016:	b8 00 00 00 00       	mov    $0x0,%eax
   1201b:	eb 4e                	jmp    1206b <ck_ring_trydequeue_mpmc_xcpu+0xb4>

	ck_pr_fence_load();
   1201d:	e8 ef e4 ff ff       	call   10511 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   12022:	8b 45 e0             	mov    -0x20(%ebp),%eax
   12025:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   12028:	21 d0                	and    %edx,%eax
   1202a:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1202e:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   12031:	8b 45 e8             	mov    -0x18(%ebp),%eax
   12034:	89 44 24 08          	mov    %eax,0x8(%esp)
   12038:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1203b:	89 44 24 04          	mov    %eax,0x4(%esp)
   1203f:	8b 45 ec             	mov    -0x14(%ebp),%eax
   12042:	89 04 24             	mov    %eax,(%esp)
   12045:	e8 fc ff ff ff       	call   12046 <ck_ring_trydequeue_mpmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   1204a:	e8 96 e4 ff ff       	call   104e5 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1204f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   12052:	8d 50 01             	lea    0x1(%eax),%edx
   12055:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12058:	89 54 24 08          	mov    %edx,0x8(%esp)
   1205c:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1205f:	89 54 24 04          	mov    %edx,0x4(%esp)
   12063:	89 04 24             	mov    %eax,(%esp)
   12066:	e8 49 e0 ff ff       	call   100b4 <ck_pr_cas_uint>
   1206b:	c9                   	leave  
   1206c:	c3                   	ret    

0001206d <ck_ring_dequeue_mpmc_xcpu>:
   1206d:	55                   	push   %ebp
   1206e:	89 e5                	mov    %esp,%ebp
   12070:	53                   	push   %ebx
   12071:	83 ec 34             	sub    $0x34,%esp
   12074:	8b 45 08             	mov    0x8(%ebp),%eax
   12077:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1207a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1207d:	89 45 f0             	mov    %eax,-0x10(%ebp)
   12080:	8b 45 10             	mov    0x10(%ebp),%eax
   12083:	89 45 ec             	mov    %eax,-0x14(%ebp)
   12086:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   1208d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12090:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   12096:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   12099:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1209c:	89 04 24             	mov    %eax,(%esp)
   1209f:	e8 62 d7 ff ff       	call   f806 <ck_pr_md_load_uint>
   120a4:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   120a7:	e8 65 e4 ff ff       	call   10511 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   120ac:	8b 45 f4             	mov    -0xc(%ebp),%eax
   120af:	83 c0 40             	add    $0x40,%eax
   120b2:	89 04 24             	mov    %eax,(%esp)
   120b5:	e8 4c d7 ff ff       	call   f806 <ck_pr_md_load_uint>
   120ba:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   120bd:	8b 45 d8             	mov    -0x28(%ebp),%eax
   120c0:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   120c3:	0f 94 c0             	sete   %al
   120c6:	0f b6 c0             	movzbl %al,%eax
   120c9:	85 c0                	test   %eax,%eax
   120cb:	74 07                	je     120d4 <ck_ring_dequeue_mpmc_xcpu+0x67>
			return false;
   120cd:	b8 00 00 00 00       	mov    $0x0,%eax
   120d2:	eb 6a                	jmp    1213e <ck_ring_dequeue_mpmc_xcpu+0xd1>

		ck_pr_fence_load();
   120d4:	e8 38 e4 ff ff       	call   10511 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   120d9:	8b 45 d8             	mov    -0x28(%ebp),%eax
   120dc:	23 45 e4             	and    -0x1c(%ebp),%eax
   120df:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   120e3:	89 c2                	mov    %eax,%edx
   120e5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   120e8:	01 d0                	add    %edx,%eax
   120ea:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   120ed:	8b 45 e8             	mov    -0x18(%ebp),%eax
   120f0:	89 44 24 08          	mov    %eax,0x8(%esp)
   120f4:	8b 45 dc             	mov    -0x24(%ebp),%eax
   120f7:	89 44 24 04          	mov    %eax,0x4(%esp)
   120fb:	8b 45 ec             	mov    -0x14(%ebp),%eax
   120fe:	89 04 24             	mov    %eax,(%esp)
   12101:	e8 fc ff ff ff       	call   12102 <ck_ring_dequeue_mpmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   12106:	e8 da e3 ff ff       	call   104e5 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1210b:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1210e:	8d 58 01             	lea    0x1(%eax),%ebx
   12111:	8b 55 d8             	mov    -0x28(%ebp),%edx
   12114:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12117:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1211a:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1211e:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   12122:	89 54 24 04          	mov    %edx,0x4(%esp)
   12126:	89 04 24             	mov    %eax,(%esp)
   12129:	e8 d9 e0 ff ff       	call   10207 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   1212e:	83 f0 01             	xor    $0x1,%eax
   12131:	84 c0                	test   %al,%al
   12133:	0f 85 6e ff ff ff    	jne    120a7 <ck_ring_dequeue_mpmc_xcpu+0x3a>

	return true;
   12139:	b8 01 00 00 00       	mov    $0x1,%eax
   1213e:	83 c4 34             	add    $0x34,%esp
   12141:	5b                   	pop    %ebx
   12142:	5d                   	pop    %ebp
   12143:	c3                   	ret    

00012144 <sl__globals>:

extern struct sl_global sl_global_data;

static inline struct sl_global *
sl__globals(void)
{
   12144:	55                   	push   %ebp
   12145:	89 e5                	mov    %esp,%ebp
	return &sl_global_data;
   12147:	b8 00 00 00 00       	mov    $0x0,%eax
}
   1214c:	5d                   	pop    %ebp
   1214d:	c3                   	ret    

0001214e <sl__ring>:
        return bitmap_check(sl__globals()->cpu_bmp, cos_cpuid());
}

static inline struct ck_ring *
sl__ring(cpuid_t cpu)
{
   1214e:	55                   	push   %ebp
   1214f:	89 e5                	mov    %esp,%ebp
	return &(sl__globals()->xcpu_ring[cpu]);
   12151:	e8 ee ff ff ff       	call   12144 <sl__globals>
   12156:	89 c2                	mov    %eax,%edx
   12158:	8b 45 08             	mov    0x8(%ebp),%eax
   1215b:	c1 e0 03             	shl    $0x3,%eax
   1215e:	89 c1                	mov    %eax,%ecx
   12160:	c1 e1 04             	shl    $0x4,%ecx
   12163:	01 c8                	add    %ecx,%eax
   12165:	01 d0                	add    %edx,%eax
}
   12167:	5d                   	pop    %ebp
   12168:	c3                   	ret    

00012169 <sl__ring_curr>:

static inline struct ck_ring *
sl__ring_curr(void)
{
   12169:	55                   	push   %ebp
   1216a:	89 e5                	mov    %esp,%ebp
   1216c:	83 ec 04             	sub    $0x4,%esp
	return sl__ring(cos_cpuid());
   1216f:	e8 15 d1 ff ff       	call   f289 <cos_cpuid>
   12174:	89 04 24             	mov    %eax,(%esp)
   12177:	e8 d2 ff ff ff       	call   1214e <sl__ring>
}
   1217c:	c9                   	leave  
   1217d:	c3                   	ret    

0001217e <sl__ring_buffer>:

static inline struct sl_xcpu_request *
sl__ring_buffer(cpuid_t cpu)
{
   1217e:	55                   	push   %ebp
   1217f:	89 e5                	mov    %esp,%ebp
	return (sl__globals()->xcpu_rbuf[cpu]);
   12181:	e8 be ff ff ff       	call   12144 <sl__globals>
   12186:	89 c1                	mov    %eax,%ecx
   12188:	8b 55 08             	mov    0x8(%ebp),%edx
   1218b:	89 d0                	mov    %edx,%eax
   1218d:	c1 e0 03             	shl    $0x3,%eax
   12190:	01 d0                	add    %edx,%eax
   12192:	c1 e0 0e             	shl    $0xe,%eax
   12195:	83 e8 80             	sub    $0xffffff80,%eax
   12198:	01 c8                	add    %ecx,%eax
   1219a:	83 c0 08             	add    $0x8,%eax
}
   1219d:	5d                   	pop    %ebp
   1219e:	c3                   	ret    

0001219f <sl__ring_buffer_curr>:

static inline struct sl_xcpu_request *
sl__ring_buffer_curr(void)
{
   1219f:	55                   	push   %ebp
   121a0:	89 e5                	mov    %esp,%ebp
   121a2:	83 ec 04             	sub    $0x4,%esp
	return sl__ring_buffer(cos_cpuid());
   121a5:	e8 df d0 ff ff       	call   f289 <cos_cpuid>
   121aa:	89 04 24             	mov    %eax,(%esp)
   121ad:	e8 cc ff ff ff       	call   1217e <sl__ring_buffer>
}
   121b2:	c9                   	leave  
   121b3:	c3                   	ret    

000121b4 <sl_thd_aepinfo>:
	struct ps_list    SL_THD_EVENT_LIST; /* list of events for the scheduler end-point */
};

static inline struct cos_aep_info *
sl_thd_aepinfo(struct sl_thd *t)
{ return (t->aepinfo); }
   121b4:	55                   	push   %ebp
   121b5:	89 e5                	mov    %esp,%ebp
   121b7:	8b 45 08             	mov    0x8(%ebp),%eax
   121ba:	8b 40 0c             	mov    0xc(%eax),%eax
   121bd:	5d                   	pop    %ebp
   121be:	c3                   	ret    

000121bf <sl_thd_thdcap>:

static inline thdcap_t
sl_thd_thdcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->thd; }
   121bf:	55                   	push   %ebp
   121c0:	89 e5                	mov    %esp,%ebp
   121c2:	83 ec 04             	sub    $0x4,%esp
   121c5:	8b 45 08             	mov    0x8(%ebp),%eax
   121c8:	89 04 24             	mov    %eax,(%esp)
   121cb:	e8 e4 ff ff ff       	call   121b4 <sl_thd_aepinfo>
   121d0:	8b 40 04             	mov    0x4(%eax),%eax
   121d3:	c9                   	leave  
   121d4:	c3                   	ret    

000121d5 <sl__globals_cpu>:

extern struct sl_global_cpu sl_global_cpu_data[];

static inline struct sl_global_cpu *
sl__globals_cpu(void)
{
   121d5:	55                   	push   %ebp
   121d6:	89 e5                	mov    %esp,%ebp
	return &(sl_global_cpu_data[cos_cpuid()]);
   121d8:	e8 ac d0 ff ff       	call   f289 <cos_cpuid>
   121dd:	c1 e0 03             	shl    $0x3,%eax
   121e0:	8d 14 c5 00 00 00 00 	lea    0x0(,%eax,8),%edx
   121e7:	29 c2                	sub    %eax,%edx
   121e9:	8d 82 00 00 00 00    	lea    0x0(%edx),%eax
}
   121ef:	5d                   	pop    %ebp
   121f0:	c3                   	ret    

000121f1 <sl_thd_lkup>:
/* for lazy retrieval of a child component thread in the parent */
extern struct sl_thd *sl_thd_retrieve(thdid_t tid);

static inline struct sl_thd *
sl_thd_lkup(thdid_t tid)
{
   121f1:	55                   	push   %ebp
   121f2:	89 e5                	mov    %esp,%ebp
   121f4:	83 ec 18             	sub    $0x18,%esp
   121f7:	8b 45 08             	mov    0x8(%ebp),%eax
   121fa:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	assert(tid != 0);
   121fe:	66 83 7d f4 00       	cmpw   $0x0,-0xc(%ebp)
   12203:	0f 94 c0             	sete   %al
   12206:	0f b6 c0             	movzbl %al,%eax
   12209:	85 c0                	test   %eax,%eax
   1220b:	74 1c                	je     12229 <sl_thd_lkup+0x38>
   1220d:	c7 04 24 70 28 00 00 	movl   $0x2870,(%esp)
   12214:	e8 f5 d1 ff ff       	call   f40e <prints>
   12219:	a1 9c 02 00 00       	mov    0x29c,%eax
   1221e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12224:	e8 6c d2 ff ff       	call   f495 <__cos_noret>
	if (unlikely(tid > MAX_NUM_THREADS)) return NULL;
   12229:	66 83 7d f4 40       	cmpw   $0x40,-0xc(%ebp)
   1222e:	0f 97 c0             	seta   %al
   12231:	0f b6 c0             	movzbl %al,%eax
   12234:	85 c0                	test   %eax,%eax
   12236:	74 07                	je     1223f <sl_thd_lkup+0x4e>
   12238:	b8 00 00 00 00       	mov    $0x0,%eax
   1223d:	eb 0c                	jmp    1224b <sl_thd_lkup+0x5a>

	return sl_thd_retrieve(tid);
   1223f:	0f b7 45 f4          	movzwl -0xc(%ebp),%eax
   12243:	89 04 24             	mov    %eax,(%esp)
   12246:	e8 fc ff ff ff       	call   12247 <sl_thd_lkup+0x56>
}
   1224b:	c9                   	leave  
   1224c:	c3                   	ret    

0001224d <sl_thdid>:
	return t;
}

static inline thdid_t
sl_thdid(void)
{
   1224d:	55                   	push   %ebp
   1224e:	89 e5                	mov    %esp,%ebp
   12250:	83 ec 28             	sub    $0x28,%esp
	thdid_t tid = cos_thdid();
   12253:	e8 4f d0 ff ff       	call   f2a7 <cos_thdid>
   12258:	66 89 45 f6          	mov    %ax,-0xa(%ebp)

	assert(tid != 0);
   1225c:	66 83 7d f6 00       	cmpw   $0x0,-0xa(%ebp)
   12261:	0f 94 c0             	sete   %al
   12264:	0f b6 c0             	movzbl %al,%eax
   12267:	85 c0                	test   %eax,%eax
   12269:	74 1c                	je     12287 <sl_thdid+0x3a>
   1226b:	c7 04 24 c4 28 00 00 	movl   $0x28c4,(%esp)
   12272:	e8 97 d1 ff ff       	call   f40e <prints>
   12277:	a1 9c 02 00 00       	mov    0x29c,%eax
   1227c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12282:	e8 0e d2 ff ff       	call   f495 <__cos_noret>
	assert(tid < MAX_NUM_THREADS);
   12287:	66 83 7d f6 3f       	cmpw   $0x3f,-0xa(%ebp)
   1228c:	0f 97 c0             	seta   %al
   1228f:	0f b6 c0             	movzbl %al,%eax
   12292:	85 c0                	test   %eax,%eax
   12294:	74 1c                	je     122b2 <sl_thdid+0x65>
   12296:	c7 04 24 18 29 00 00 	movl   $0x2918,(%esp)
   1229d:	e8 6c d1 ff ff       	call   f40e <prints>
   122a2:	a1 9c 02 00 00       	mov    0x29c,%eax
   122a7:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   122ad:	e8 e3 d1 ff ff       	call   f495 <__cos_noret>

	return tid;
   122b2:	0f b7 45 f6          	movzwl -0xa(%ebp),%eax
}
   122b6:	c9                   	leave  
   122b7:	c3                   	ret    

000122b8 <sl_thd_curr>:


static inline struct sl_thd *
sl_thd_curr(void)
{
   122b8:	55                   	push   %ebp
   122b9:	89 e5                	mov    %esp,%ebp
   122bb:	83 ec 18             	sub    $0x18,%esp
	return sl_thd_lkup(sl_thdid());
   122be:	e8 8a ff ff ff       	call   1224d <sl_thdid>
   122c3:	0f b7 c0             	movzwl %ax,%eax
   122c6:	89 04 24             	mov    %eax,(%esp)
   122c9:	e8 23 ff ff ff       	call   121f1 <sl_thd_lkup>
}
   122ce:	c9                   	leave  
   122cf:	c3                   	ret    

000122d0 <sl_cs_owner>:

/* are we the owner of the critical section? */
static inline int
sl_cs_owner(void)
{
   122d0:	55                   	push   %ebp
   122d1:	89 e5                	mov    %esp,%ebp
   122d3:	53                   	push   %ebx
   122d4:	83 ec 14             	sub    $0x14,%esp
	return sl__globals_cpu()->lock.u.s.owner == sl_thd_thdcap(sl_thd_curr());
   122d7:	e8 f9 fe ff ff       	call   121d5 <sl__globals_cpu>
   122dc:	8b 00                	mov    (%eax),%eax
   122de:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   122e3:	89 c3                	mov    %eax,%ebx
   122e5:	e8 ce ff ff ff       	call   122b8 <sl_thd_curr>
   122ea:	89 04 24             	mov    %eax,(%esp)
   122ed:	e8 cd fe ff ff       	call   121bf <sl_thd_thdcap>
   122f2:	39 c3                	cmp    %eax,%ebx
   122f4:	0f 94 c0             	sete   %al
   122f7:	0f b6 c0             	movzbl %al,%eax
}
   122fa:	83 c4 14             	add    $0x14,%esp
   122fd:	5b                   	pop    %ebx
   122fe:	5d                   	pop    %ebp
   122ff:	c3                   	ret    

00012300 <sl_cs_enter_nospin>:
int sl_cs_exit_contention(union sl_cs_intern *csi, union sl_cs_intern *cached, sched_tok_t tok);

/* Enter into the scheduler critical section */
static inline int
sl_cs_enter_nospin(void)
{
   12300:	55                   	push   %ebp
   12301:	89 e5                	mov    %esp,%ebp
   12303:	56                   	push   %esi
   12304:	53                   	push   %ebx
   12305:	83 ec 20             	sub    $0x20,%esp
	union sl_cs_intern csi, cached;
	struct sl_thd *    t = sl_thd_curr();
   12308:	e8 ab ff ff ff       	call   122b8 <sl_thd_curr>
   1230d:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sched_tok_t        tok;

	assert(t);
   12310:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
   12314:	0f 94 c0             	sete   %al
   12317:	0f b6 c0             	movzbl %al,%eax
   1231a:	85 c0                	test   %eax,%eax
   1231c:	74 1c                	je     1233a <sl_cs_enter_nospin+0x3a>
   1231e:	c7 04 24 6c 29 00 00 	movl   $0x296c,(%esp)
   12325:	e8 e4 d0 ff ff       	call   f40e <prints>
   1232a:	a1 9c 02 00 00       	mov    0x29c,%eax
   1232f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12335:	e8 5b d1 ff ff       	call   f495 <__cos_noret>
	tok      = cos_sched_sync();
   1233a:	e8 fc ff ff ff       	call   1233b <sl_cs_enter_nospin+0x3b>
   1233f:	89 45 f0             	mov    %eax,-0x10(%ebp)
	csi.v    = sl__globals_cpu()->lock.u.v;
   12342:	e8 8e fe ff ff       	call   121d5 <sl__globals_cpu>
   12347:	8b 00                	mov    (%eax),%eax
   12349:	89 45 ec             	mov    %eax,-0x14(%ebp)
	cached.v = csi.v;
   1234c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1234f:	89 45 e8             	mov    %eax,-0x18(%ebp)

	if (unlikely(csi.s.owner)) {
   12352:	8b 45 ec             	mov    -0x14(%ebp),%eax
   12355:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   1235a:	85 c0                	test   %eax,%eax
   1235c:	0f 95 c0             	setne  %al
   1235f:	0f b6 c0             	movzbl %al,%eax
   12362:	85 c0                	test   %eax,%eax
   12364:	74 2a                	je     12390 <sl_cs_enter_nospin+0x90>
		return sl_cs_enter_contention(&csi, &cached, sl_thd_thdcap(t), tok);
   12366:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12369:	89 04 24             	mov    %eax,(%esp)
   1236c:	e8 4e fe ff ff       	call   121bf <sl_thd_thdcap>
   12371:	8b 55 f0             	mov    -0x10(%ebp),%edx
   12374:	89 54 24 0c          	mov    %edx,0xc(%esp)
   12378:	89 44 24 08          	mov    %eax,0x8(%esp)
   1237c:	8d 45 e8             	lea    -0x18(%ebp),%eax
   1237f:	89 44 24 04          	mov    %eax,0x4(%esp)
   12383:	8d 45 ec             	lea    -0x14(%ebp),%eax
   12386:	89 04 24             	mov    %eax,(%esp)
   12389:	e8 fc ff ff ff       	call   1238a <sl_cs_enter_nospin+0x8a>
   1238e:	eb 4f                	jmp    123df <sl_cs_enter_nospin+0xdf>
	}

	csi.s.owner = sl_thd_thdcap(t);
   12390:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12393:	89 04 24             	mov    %eax,(%esp)
   12396:	e8 24 fe ff ff       	call   121bf <sl_thd_thdcap>
   1239b:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   123a0:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   123a5:	89 c2                	mov    %eax,%edx
   123a7:	8b 45 ec             	mov    -0x14(%ebp),%eax
   123aa:	25 00 00 00 80       	and    $0x80000000,%eax
   123af:	09 d0                	or     %edx,%eax
   123b1:	89 45 ec             	mov    %eax,-0x14(%ebp)
	if (!ps_cas(&sl__globals_cpu()->lock.u.v, cached.v, csi.v)) return 1;
   123b4:	8b 75 ec             	mov    -0x14(%ebp),%esi
   123b7:	8b 5d e8             	mov    -0x18(%ebp),%ebx
   123ba:	e8 16 fe ff ff       	call   121d5 <sl__globals_cpu>
   123bf:	89 74 24 08          	mov    %esi,0x8(%esp)
   123c3:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   123c7:	89 04 24             	mov    %eax,(%esp)
   123ca:	e8 42 cd ff ff       	call   f111 <ps_cas>
   123cf:	85 c0                	test   %eax,%eax
   123d1:	75 07                	jne    123da <sl_cs_enter_nospin+0xda>
   123d3:	b8 01 00 00 00       	mov    $0x1,%eax
   123d8:	eb 05                	jmp    123df <sl_cs_enter_nospin+0xdf>

	return 0;
   123da:	b8 00 00 00 00       	mov    $0x0,%eax
}
   123df:	83 c4 20             	add    $0x20,%esp
   123e2:	5b                   	pop    %ebx
   123e3:	5e                   	pop    %esi
   123e4:	5d                   	pop    %ebp
   123e5:	c3                   	ret    

000123e6 <sl_cs_enter>:

/* Enter into scheduler cs from a non-sched thread context */
static inline void
sl_cs_enter(void)
{
   123e6:	55                   	push   %ebp
   123e7:	89 e5                	mov    %esp,%ebp
   123e9:	83 ec 08             	sub    $0x8,%esp
	while (sl_cs_enter_nospin())
   123ec:	90                   	nop
   123ed:	e8 0e ff ff ff       	call   12300 <sl_cs_enter_nospin>
   123f2:	85 c0                	test   %eax,%eax
   123f4:	75 f7                	jne    123ed <sl_cs_enter+0x7>
		;
}
   123f6:	c9                   	leave  
   123f7:	c3                   	ret    

000123f8 <sl_cs_exit>:
 * Release the scheduler critical section, switch to the scheduler
 * thread if there is pending contention
 */
static inline void
sl_cs_exit(void)
{
   123f8:	55                   	push   %ebp
   123f9:	89 e5                	mov    %esp,%ebp
   123fb:	53                   	push   %ebx
   123fc:	83 ec 24             	sub    $0x24,%esp
	union sl_cs_intern csi, cached;
	sched_tok_t        tok;

	assert(sl_cs_owner());
   123ff:	e8 cc fe ff ff       	call   122d0 <sl_cs_owner>
   12404:	85 c0                	test   %eax,%eax
   12406:	0f 94 c0             	sete   %al
   12409:	0f b6 c0             	movzbl %al,%eax
   1240c:	85 c0                	test   %eax,%eax
   1240e:	74 1c                	je     1242c <sl_cs_exit+0x34>
   12410:	c7 04 24 c0 29 00 00 	movl   $0x29c0,(%esp)
   12417:	e8 f2 cf ff ff       	call   f40e <prints>
   1241c:	a1 9c 02 00 00       	mov    0x29c,%eax
   12421:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12427:	e8 69 d0 ff ff       	call   f495 <__cos_noret>

retry:
	tok      = cos_sched_sync();
   1242c:	e8 fc ff ff ff       	call   1242d <sl_cs_exit+0x35>
   12431:	89 45 f4             	mov    %eax,-0xc(%ebp)
	csi.v    = sl__globals_cpu()->lock.u.v;
   12434:	e8 9c fd ff ff       	call   121d5 <sl__globals_cpu>
   12439:	8b 00                	mov    (%eax),%eax
   1243b:	89 45 f0             	mov    %eax,-0x10(%ebp)
	cached.v = csi.v;
   1243e:	8b 45 f0             	mov    -0x10(%ebp),%eax
   12441:	89 45 ec             	mov    %eax,-0x14(%ebp)

	if (unlikely(csi.s.contention)) {
   12444:	0f b6 45 f3          	movzbl -0xd(%ebp),%eax
   12448:	c0 e8 07             	shr    $0x7,%al
   1244b:	0f b6 c0             	movzbl %al,%eax
   1244e:	85 c0                	test   %eax,%eax
   12450:	74 1f                	je     12471 <sl_cs_exit+0x79>
		if (sl_cs_exit_contention(&csi, &cached, tok)) goto retry;
   12452:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12455:	89 44 24 08          	mov    %eax,0x8(%esp)
   12459:	8d 45 ec             	lea    -0x14(%ebp),%eax
   1245c:	89 44 24 04          	mov    %eax,0x4(%esp)
   12460:	8d 45 f0             	lea    -0x10(%ebp),%eax
   12463:	89 04 24             	mov    %eax,(%esp)
   12466:	e8 fc ff ff ff       	call   12467 <sl_cs_exit+0x6f>
   1246b:	85 c0                	test   %eax,%eax
   1246d:	74 24                	je     12493 <sl_cs_exit+0x9b>
   1246f:	eb bb                	jmp    1242c <sl_cs_exit+0x34>
		return;
	}

	if (!ps_cas(&sl__globals_cpu()->lock.u.v, cached.v, 0)) goto retry;
   12471:	8b 5d ec             	mov    -0x14(%ebp),%ebx
   12474:	e8 5c fd ff ff       	call   121d5 <sl__globals_cpu>
   12479:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   12480:	00 
   12481:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   12485:	89 04 24             	mov    %eax,(%esp)
   12488:	e8 84 cc ff ff       	call   f111 <ps_cas>
   1248d:	85 c0                	test   %eax,%eax
   1248f:	75 02                	jne    12493 <sl_cs_exit+0x9b>
   12491:	eb 99                	jmp    1242c <sl_cs_exit+0x34>
}
   12493:	83 c4 24             	add    $0x24,%esp
   12496:	5b                   	pop    %ebx
   12497:	5d                   	pop    %ebp
   12498:	c3                   	ret    

00012499 <sl_xcpu_thd_alloc>:

extern struct sl_thd *sl_thd_alloc_no_cs(cos_thd_fn_t fn, void *data);

int
sl_xcpu_thd_alloc(cpuid_t cpu, cos_thd_fn_t fn, void *data, sched_param_t params[])
{
   12499:	55                   	push   %ebp
   1249a:	89 e5                	mov    %esp,%ebp
   1249c:	53                   	push   %ebx
   1249d:	83 ec 54             	sub    $0x54,%esp
	int i, sz = sizeof(params) / sizeof(params[0]);
   124a0:	c7 45 ec 01 00 00 00 	movl   $0x1,-0x14(%ebp)
	int ret = 0;
   124a7:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	asndcap_t snd = 0;
   124ae:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	struct sl_xcpu_request req;

	if (cpu == cos_cpuid()) return -EINVAL;
   124b5:	e8 cf cd ff ff       	call   f289 <cos_cpuid>
   124ba:	3b 45 08             	cmp    0x8(%ebp),%eax
   124bd:	75 0a                	jne    124c9 <sl_xcpu_thd_alloc+0x30>
   124bf:	b8 ea ff ff ff       	mov    $0xffffffea,%eax
   124c4:	e9 20 01 00 00       	jmp    125e9 <sl_xcpu_thd_alloc+0x150>
	if (!bitmap_check(sl__globals()->cpu_bmp, cpu)) return -EINVAL;
   124c9:	e8 76 fc ff ff       	call   12144 <sl__globals>
   124ce:	8d 90 88 40 02 00    	lea    0x24088(%eax),%edx
   124d4:	8b 45 08             	mov    0x8(%ebp),%eax
   124d7:	89 44 24 04          	mov    %eax,0x4(%esp)
   124db:	89 14 24             	mov    %edx,(%esp)
   124de:	e8 6b cc ff ff       	call   f14e <bitmap_check>
   124e3:	85 c0                	test   %eax,%eax
   124e5:	75 0a                	jne    124f1 <sl_xcpu_thd_alloc+0x58>
   124e7:	b8 ea ff ff ff       	mov    $0xffffffea,%eax
   124ec:	e9 f8 00 00 00       	jmp    125e9 <sl_xcpu_thd_alloc+0x150>

	sl_cs_enter();
   124f1:	e8 f0 fe ff ff       	call   123e6 <sl_cs_enter>

	SL_REQ_THD_ALLOC(req, fn, data);
   124f6:	c7 45 bc 00 00 00 00 	movl   $0x0,-0x44(%ebp)
   124fd:	e8 87 cd ff ff       	call   f289 <cos_cpuid>
   12502:	89 45 c0             	mov    %eax,-0x40(%ebp)
   12505:	c7 45 c4 00 00 00 00 	movl   $0x0,-0x3c(%ebp)
   1250c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1250f:	89 45 dc             	mov    %eax,-0x24(%ebp)
   12512:	8b 45 10             	mov    0x10(%ebp),%eax
   12515:	89 45 e0             	mov    %eax,-0x20(%ebp)
	memcpy(req.params, params, sizeof(sched_param_t) * sz);
   12518:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1251b:	c1 e0 02             	shl    $0x2,%eax
   1251e:	89 44 24 08          	mov    %eax,0x8(%esp)
   12522:	8b 45 14             	mov    0x14(%ebp),%eax
   12525:	89 44 24 04          	mov    %eax,0x4(%esp)
   12529:	8d 45 bc             	lea    -0x44(%ebp),%eax
   1252c:	83 c0 0c             	add    $0xc,%eax
   1252f:	89 04 24             	mov    %eax,(%esp)
   12532:	e8 fc ff ff ff       	call   12533 <sl_xcpu_thd_alloc+0x9a>
	req.param_count = sz;
   12537:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1253a:	89 45 d8             	mov    %eax,-0x28(%ebp)
	if (ck_ring_enqueue_mpsc_xcpu(sl__ring(cpu), sl__ring_buffer(cpu), &req) != true) {
   1253d:	8b 45 08             	mov    0x8(%ebp),%eax
   12540:	89 04 24             	mov    %eax,(%esp)
   12543:	e8 36 fc ff ff       	call   1217e <sl__ring_buffer>
   12548:	89 c3                	mov    %eax,%ebx
   1254a:	8b 45 08             	mov    0x8(%ebp),%eax
   1254d:	89 04 24             	mov    %eax,(%esp)
   12550:	e8 f9 fb ff ff       	call   1214e <sl__ring>
   12555:	8d 55 bc             	lea    -0x44(%ebp),%edx
   12558:	89 54 24 08          	mov    %edx,0x8(%esp)
   1255c:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   12560:	89 04 24             	mov    %eax,(%esp)
   12563:	e8 36 f4 ff ff       	call   1199e <ck_ring_enqueue_mpsc_xcpu>
   12568:	83 f0 01             	xor    $0x1,%eax
   1256b:	84 c0                	test   %al,%al
   1256d:	74 09                	je     12578 <sl_xcpu_thd_alloc+0xdf>
		ret = -ENOMEM;
   1256f:	c7 45 f4 f4 ff ff ff 	movl   $0xfffffff4,-0xc(%ebp)
   12576:	eb 47                	jmp    125bf <sl_xcpu_thd_alloc+0x126>
	} else {
		snd = sl__globals()->xcpu_asnd[cos_cpuid()][cpu];
   12578:	e8 c7 fb ff ff       	call   12144 <sl__globals>
   1257d:	89 c3                	mov    %eax,%ebx
   1257f:	e8 05 cd ff ff       	call   f289 <cos_cpuid>
   12584:	8b 55 08             	mov    0x8(%ebp),%edx
   12587:	01 d0                	add    %edx,%eax
   12589:	05 20 90 00 00       	add    $0x9020,%eax
   1258e:	8b 44 83 0c          	mov    0xc(%ebx,%eax,4),%eax
   12592:	89 45 f0             	mov    %eax,-0x10(%ebp)
		assert(snd);
   12595:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
   12599:	0f 94 c0             	sete   %al
   1259c:	0f b6 c0             	movzbl %al,%eax
   1259f:	85 c0                	test   %eax,%eax
   125a1:	74 1c                	je     125bf <sl_xcpu_thd_alloc+0x126>
   125a3:	c7 04 24 14 2a 00 00 	movl   $0x2a14,(%esp)
   125aa:	e8 5f ce ff ff       	call   f40e <prints>
   125af:	a1 9c 02 00 00       	mov    0x29c,%eax
   125b4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   125ba:	e8 d6 ce ff ff       	call   f495 <__cos_noret>
	}

	sl_cs_exit();
   125bf:	e8 34 fe ff ff       	call   123f8 <sl_cs_exit>

	if (!snd || ret) goto done;
   125c4:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
   125c8:	74 1c                	je     125e6 <sl_xcpu_thd_alloc+0x14d>
   125ca:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
   125ce:	75 16                	jne    125e6 <sl_xcpu_thd_alloc+0x14d>

	/* send an IPI for the request */
	ret = cos_asnd(snd, 1);
   125d0:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
   125d7:	00 
   125d8:	8b 45 f0             	mov    -0x10(%ebp),%eax
   125db:	89 04 24             	mov    %eax,(%esp)
   125de:	e8 fc ff ff ff       	call   125df <sl_xcpu_thd_alloc+0x146>
   125e3:	89 45 f4             	mov    %eax,-0xc(%ebp)

done:
	return ret;
   125e6:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   125e9:	83 c4 54             	add    $0x54,%esp
   125ec:	5b                   	pop    %ebx
   125ed:	5d                   	pop    %ebp
   125ee:	c3                   	ret    

000125ef <sl_xcpu_thd_alloc_ext>:

int
sl_xcpu_thd_alloc_ext(cpuid_t cpu, struct cos_defcompinfo *dci, thdclosure_index_t idx, sched_param_t params[])
{
   125ef:	55                   	push   %ebp
   125f0:	89 e5                	mov    %esp,%ebp
	return -ENOTSUP;
   125f2:	b8 a1 ff ff ff       	mov    $0xffffffa1,%eax
}
   125f7:	5d                   	pop    %ebp
   125f8:	c3                   	ret    

000125f9 <sl_xcpu_aep_alloc>:

int
sl_xcpu_aep_alloc(cpuid_t cpu, cos_thd_fn_t fn, void *data, int own_tcap, cos_channelkey_t key, sched_param_t params[])
{
   125f9:	55                   	push   %ebp
   125fa:	89 e5                	mov    %esp,%ebp
   125fc:	83 ec 04             	sub    $0x4,%esp
   125ff:	8b 45 18             	mov    0x18(%ebp),%eax
   12602:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
	return -ENOTSUP;
   12606:	b8 a1 ff ff ff       	mov    $0xffffffa1,%eax
}
   1260b:	c9                   	leave  
   1260c:	c3                   	ret    

0001260d <sl_xcpu_aep_alloc_ext>:

int
sl_xcpu_aep_alloc_ext(cpuid_t cpu, struct cos_defcompinfo *dci, thdclosure_index_t idx, int own_tcap, cos_channelkey_t key, sched_param_t params[])
{
   1260d:	55                   	push   %ebp
   1260e:	89 e5                	mov    %esp,%ebp
   12610:	83 ec 04             	sub    $0x4,%esp
   12613:	8b 45 18             	mov    0x18(%ebp),%eax
   12616:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
	return -ENOTSUP;
   1261a:	b8 a1 ff ff ff       	mov    $0xffffffa1,%eax
}
   1261f:	c9                   	leave  
   12620:	c3                   	ret    

00012621 <sl_xcpu_initaep_alloc>:

int
sl_xcpu_initaep_alloc(cpuid_t cpu, struct cos_defcompinfo *dci, int own_tcap, cos_channelkey_t key, sched_param_t params[])
{
   12621:	55                   	push   %ebp
   12622:	89 e5                	mov    %esp,%ebp
   12624:	83 ec 04             	sub    $0x4,%esp
   12627:	8b 45 14             	mov    0x14(%ebp),%eax
   1262a:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
	return -ENOTSUP;
   1262e:	b8 a1 ff ff ff       	mov    $0xffffffa1,%eax
}
   12633:	c9                   	leave  
   12634:	c3                   	ret    

00012635 <sl_xcpu_initaep_alloc_ext>:

int
sl_xcpu_initaep_alloc_ext(cpuid_t cpu, struct cos_defcompinfo *dci, struct cos_defcompinfo *sched, int own_tcap, cos_channelkey_t key, sched_param_t params[])
{
   12635:	55                   	push   %ebp
   12636:	89 e5                	mov    %esp,%ebp
   12638:	83 ec 04             	sub    $0x4,%esp
   1263b:	8b 45 18             	mov    0x18(%ebp),%eax
   1263e:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
	return -ENOTSUP;
   12642:	b8 a1 ff ff ff       	mov    $0xffffffa1,%eax
}
   12647:	c9                   	leave  
   12648:	c3                   	ret    

00012649 <sl_xcpu_process_no_cs>:

int
sl_xcpu_process_no_cs(void)
{
   12649:	55                   	push   %ebp
   1264a:	89 e5                	mov    %esp,%ebp
   1264c:	56                   	push   %esi
   1264d:	53                   	push   %ebx
   1264e:	83 ec 60             	sub    $0x60,%esp
	int num = 0;
   12651:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct sl_xcpu_request xcpu_req;

	while (ck_ring_dequeue_mpsc_xcpu(sl__ring_curr(), sl__ring_buffer_curr(), &xcpu_req) == true) {
   12658:	e9 2a 01 00 00       	jmp    12787 <sl_xcpu_process_no_cs+0x13e>

		assert(xcpu_req.client != cos_cpuid());
   1265d:	8b 5d b8             	mov    -0x48(%ebp),%ebx
   12660:	e8 24 cc ff ff       	call   f289 <cos_cpuid>
   12665:	39 c3                	cmp    %eax,%ebx
   12667:	0f 94 c0             	sete   %al
   1266a:	0f b6 c0             	movzbl %al,%eax
   1266d:	85 c0                	test   %eax,%eax
   1266f:	74 1c                	je     1268d <sl_xcpu_process_no_cs+0x44>
   12671:	c7 04 24 3c 2a 00 00 	movl   $0x2a3c,(%esp)
   12678:	e8 91 cd ff ff       	call   f40e <prints>
   1267d:	a1 9c 02 00 00       	mov    0x29c,%eax
   12682:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12688:	e8 08 ce ff ff       	call   f495 <__cos_noret>
		switch(xcpu_req.type) {
   1268d:	8b 45 b4             	mov    -0x4c(%ebp),%eax
   12690:	85 c0                	test   %eax,%eax
   12692:	0f 85 a7 00 00 00    	jne    1273f <sl_xcpu_process_no_cs+0xf6>
		case SL_XCPU_THD_ALLOC:
		{
			cos_thd_fn_t   fn   = xcpu_req.sl_xcpu_req_thd_alloc.fn;
   12698:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1269b:	89 45 ec             	mov    %eax,-0x14(%ebp)
			void          *data = xcpu_req.sl_xcpu_req_thd_alloc.data;
   1269e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   126a1:	89 45 e8             	mov    %eax,-0x18(%ebp)
			struct sl_thd *t;
			int i;

			assert(fn);
   126a4:	83 7d ec 00          	cmpl   $0x0,-0x14(%ebp)
   126a8:	0f 94 c0             	sete   %al
   126ab:	0f b6 c0             	movzbl %al,%eax
   126ae:	85 c0                	test   %eax,%eax
   126b0:	74 1c                	je     126ce <sl_xcpu_process_no_cs+0x85>
   126b2:	c7 04 24 64 2a 00 00 	movl   $0x2a64,(%esp)
   126b9:	e8 50 cd ff ff       	call   f40e <prints>
   126be:	a1 9c 02 00 00       	mov    0x29c,%eax
   126c3:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   126c9:	e8 c7 cd ff ff       	call   f495 <__cos_noret>

			t = sl_thd_alloc_no_cs(fn, data);
   126ce:	8b 45 e8             	mov    -0x18(%ebp),%eax
   126d1:	89 44 24 04          	mov    %eax,0x4(%esp)
   126d5:	8b 45 ec             	mov    -0x14(%ebp),%eax
   126d8:	89 04 24             	mov    %eax,(%esp)
   126db:	e8 fc ff ff ff       	call   126dc <sl_xcpu_process_no_cs+0x93>
   126e0:	89 45 e4             	mov    %eax,-0x1c(%ebp)
			assert(t);
   126e3:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   126e7:	0f 94 c0             	sete   %al
   126ea:	0f b6 c0             	movzbl %al,%eax
   126ed:	85 c0                	test   %eax,%eax
   126ef:	74 1c                	je     1270d <sl_xcpu_process_no_cs+0xc4>
   126f1:	c7 04 24 90 2a 00 00 	movl   $0x2a90,(%esp)
   126f8:	e8 11 cd ff ff       	call   f40e <prints>
   126fd:	a1 9c 02 00 00       	mov    0x29c,%eax
   12702:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12708:	e8 88 cd ff ff       	call   f495 <__cos_noret>
			for (i = 0; i < xcpu_req.param_count; i++) {
   1270d:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
   12714:	eb 1a                	jmp    12730 <sl_xcpu_process_no_cs+0xe7>
				sl_thd_param_set(t, xcpu_req.params[i]);
   12716:	8b 45 f0             	mov    -0x10(%ebp),%eax
   12719:	8b 44 85 c0          	mov    -0x40(%ebp,%eax,4),%eax
   1271d:	89 44 24 04          	mov    %eax,0x4(%esp)
   12721:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   12724:	89 04 24             	mov    %eax,(%esp)
   12727:	e8 fc ff ff ff       	call   12728 <sl_xcpu_process_no_cs+0xdf>

			assert(fn);

			t = sl_thd_alloc_no_cs(fn, data);
			assert(t);
			for (i = 0; i < xcpu_req.param_count; i++) {
   1272c:	83 45 f0 01          	addl   $0x1,-0x10(%ebp)
   12730:	8b 45 d0             	mov    -0x30(%ebp),%eax
   12733:	3b 45 f0             	cmp    -0x10(%ebp),%eax
   12736:	7f de                	jg     12716 <sl_xcpu_process_no_cs+0xcd>
				sl_thd_param_set(t, xcpu_req.params[i]);
			}

			break;
   12738:	90                   	nop
		{
			PRINTC("Unimplemented request! Aborting!\n");
			assert(0);
		}
		}
		num ++;
   12739:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   1273d:	eb 48                	jmp    12787 <sl_xcpu_process_no_cs+0x13e>
		case SL_XCPU_AEP_ALLOC_EXT:
		case SL_XCPU_INITAEP_ALLOC:
		case SL_XCPU_THD_DEALLOC:
		default:
		{
			PRINTC("Unimplemented request! Aborting!\n");
   1273f:	e8 6d cb ff ff       	call   f2b1 <cos_spd_id>
   12744:	89 c3                	mov    %eax,%ebx
   12746:	e8 5c cb ff ff       	call   f2a7 <cos_thdid>
   1274b:	0f b7 f0             	movzwl %ax,%esi
   1274e:	e8 36 cb ff ff       	call   f289 <cos_cpuid>
   12753:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
   12757:	89 74 24 08          	mov    %esi,0x8(%esp)
   1275b:	89 44 24 04          	mov    %eax,0x4(%esp)
   1275f:	c7 04 24 bc 2a 00 00 	movl   $0x2abc,(%esp)
   12766:	e8 ce cc ff ff       	call   f439 <printc>
			assert(0);
   1276b:	c7 04 24 ec 2a 00 00 	movl   $0x2aec,(%esp)
   12772:	e8 97 cc ff ff       	call   f40e <prints>
   12777:	a1 9c 02 00 00       	mov    0x29c,%eax
   1277c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12782:	e8 0e cd ff ff       	call   f495 <__cos_noret>
sl_xcpu_process_no_cs(void)
{
	int num = 0;
	struct sl_xcpu_request xcpu_req;

	while (ck_ring_dequeue_mpsc_xcpu(sl__ring_curr(), sl__ring_buffer_curr(), &xcpu_req) == true) {
   12787:	e8 13 fa ff ff       	call   1219f <sl__ring_buffer_curr>
   1278c:	89 c3                	mov    %eax,%ebx
   1278e:	e8 d6 f9 ff ff       	call   12169 <sl__ring_curr>
   12793:	8d 55 b4             	lea    -0x4c(%ebp),%edx
   12796:	89 54 24 08          	mov    %edx,0x8(%esp)
   1279a:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   1279e:	89 04 24             	mov    %eax,(%esp)
   127a1:	e8 b0 f4 ff ff       	call   11c56 <ck_ring_dequeue_mpsc_xcpu>
   127a6:	84 c0                	test   %al,%al
   127a8:	0f 85 af fe ff ff    	jne    1265d <sl_xcpu_process_no_cs+0x14>
		}
		}
		num ++;
	}

	return num; /* number of requests processed */
   127ae:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   127b1:	83 c4 60             	add    $0x60,%esp
   127b4:	5b                   	pop    %ebx
   127b5:	5e                   	pop    %esi
   127b6:	5d                   	pop    %ebp
   127b7:	c3                   	ret    

000127b8 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
   127b8:	55                   	push   %ebp
   127b9:	89 e5                	mov    %esp,%ebp
   127bb:	57                   	push   %edi
   127bc:	56                   	push   %esi
   127bd:	53                   	push   %ebx
   127be:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
   127c1:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
   127c8:	8b 45 08             	mov    0x8(%ebp),%eax
   127cb:	83 c0 01             	add    $0x1,%eax
   127ce:	c1 e0 10             	shl    $0x10,%eax
   127d1:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
   127d4:	8b 45 0c             	mov    0xc(%ebp),%eax
   127d7:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
   127da:	8b 45 08             	mov    0x8(%ebp),%eax
   127dd:	8b 4d 10             	mov    0x10(%ebp),%ecx
   127e0:	8b 75 14             	mov    0x14(%ebp),%esi
   127e3:	8b 7d 18             	mov    0x18(%ebp),%edi
   127e6:	8b 55 1c             	mov    0x1c(%ebp),%edx
   127e9:	89 cb                	mov    %ecx,%ebx
   127eb:	55                   	push   %ebp
   127ec:	89 e5                	mov    %esp,%ebp
   127ee:	b9 00 28 01 00       	mov    $0x12800,%ecx
   127f3:	0f 34                	sysenter 
   127f5:	8d 76 00             	lea    0x0(%esi),%esi
   127f8:	eb 0d                	jmp    12807 <call_cap_asm+0x4f>
   127fa:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   12800:	b9 00 00 00 00       	mov    $0x0,%ecx
   12805:	eb 05                	jmp    1280c <call_cap_asm+0x54>
   12807:	b9 01 00 00 00       	mov    $0x1,%ecx
   1280c:	5d                   	pop    %ebp
   1280d:	89 ca                	mov    %ecx,%edx
   1280f:	89 45 ec             	mov    %eax,-0x14(%ebp)
   12812:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
   12815:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
   12818:	83 c4 10             	add    $0x10,%esp
   1281b:	5b                   	pop    %ebx
   1281c:	5e                   	pop    %esi
   1281d:	5f                   	pop    %edi
   1281e:	5d                   	pop    %ebp
   1281f:	c3                   	ret    

00012820 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
   12820:	55                   	push   %ebp
   12821:	89 e5                	mov    %esp,%ebp
   12823:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
   12826:	8b 45 18             	mov    0x18(%ebp),%eax
   12829:	89 44 24 14          	mov    %eax,0x14(%esp)
   1282d:	8b 45 14             	mov    0x14(%ebp),%eax
   12830:	89 44 24 10          	mov    %eax,0x10(%esp)
   12834:	8b 45 10             	mov    0x10(%ebp),%eax
   12837:	89 44 24 0c          	mov    %eax,0xc(%esp)
   1283b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1283e:	89 44 24 08          	mov    %eax,0x8(%esp)
   12842:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   12849:	00 
   1284a:	8b 45 08             	mov    0x8(%ebp),%eax
   1284d:	89 04 24             	mov    %eax,(%esp)
   12850:	e8 63 ff ff ff       	call   127b8 <call_cap_asm>
}
   12855:	c9                   	leave  
   12856:	c3                   	ret    

00012857 <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
   12857:	55                   	push   %ebp
   12858:	89 e5                	mov    %esp,%ebp
   1285a:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
   1285d:	8b 45 08             	mov    0x8(%ebp),%eax
   12860:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   12867:	00 
   12868:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   1286f:	00 
   12870:	8b 55 0c             	mov    0xc(%ebp),%edx
   12873:	89 54 24 08          	mov    %edx,0x8(%esp)
   12877:	89 44 24 04          	mov    %eax,0x4(%esp)
   1287b:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
   12882:	e8 99 ff ff ff       	call   12820 <call_cap>
}
   12887:	c9                   	leave  
   12888:	c3                   	ret    

00012889 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
   12889:	55                   	push   %ebp
   1288a:	89 e5                	mov    %esp,%ebp
   1288c:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
   1288f:	89 e0                	mov    %esp,%eax
   12891:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
   12894:	8b 45 fc             	mov    -0x4(%ebp),%eax
   12897:	25 00 f0 ff ff       	and    $0xfffff000,%eax
   1289c:	89 c2                	mov    %eax,%edx
   1289e:	8b 45 08             	mov    0x8(%ebp),%eax
   128a1:	c1 e0 02             	shl    $0x2,%eax
   128a4:	29 c2                	sub    %eax,%edx
   128a6:	89 d0                	mov    %edx,%eax
   128a8:	05 00 10 00 00       	add    $0x1000,%eax
   128ad:	8b 00                	mov    (%eax),%eax
}
   128af:	c9                   	leave  
   128b0:	c3                   	ret    

000128b1 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
   128b1:	55                   	push   %ebp
   128b2:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
   128b4:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
   128b9:	5d                   	pop    %ebp
   128ba:	c3                   	ret    

000128bb <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
   128bb:	55                   	push   %ebp
   128bc:	89 e5                	mov    %esp,%ebp
   128be:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
   128c1:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
   128c8:	e8 bc ff ff ff       	call   12889 <get_stk_data>
}
   128cd:	c9                   	leave  
   128ce:	c3                   	ret    

000128cf <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
   128cf:	55                   	push   %ebp
   128d0:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
   128d2:	e8 e4 ff ff ff       	call   128bb <cos_get_thd_id>
}
   128d7:	5d                   	pop    %ebp
   128d8:	c3                   	ret    

000128d9 <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
   128d9:	55                   	push   %ebp
   128da:	89 e5                	mov    %esp,%ebp
   128dc:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
   128df:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
   128e6:	eb 20                	jmp    12908 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
   128e8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   128eb:	83 c0 01             	add    $0x1,%eax
   128ee:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
   128f5:	8b 45 08             	mov    0x8(%ebp),%eax
   128f8:	01 d0                	add    %edx,%eax
   128fa:	8b 00                	mov    (%eax),%eax
   128fc:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
   128ff:	8b 45 f0             	mov    -0x10(%ebp),%eax
   12902:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
   12904:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   12908:	8b 45 08             	mov    0x8(%ebp),%eax
   1290b:	8b 00                	mov    (%eax),%eax
   1290d:	3b 45 f4             	cmp    -0xc(%ebp),%eax
   12910:	7f d6                	jg     128e8 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
   12912:	c9                   	leave  
   12913:	c3                   	ret    

00012914 <constructors_execute>:

static void
constructors_execute(void)
{
   12914:	55                   	push   %ebp
   12915:	89 e5                	mov    %esp,%ebp
   12917:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
   1291a:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   12921:	e8 b3 ff ff ff       	call   128d9 <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
   12926:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1292d:	e8 a7 ff ff ff       	call   128d9 <section_fnptrs_execute>
}
   12932:	c9                   	leave  
   12933:	c3                   	ret    

00012934 <destructors_execute>:
static void
destructors_execute(void)
{
   12934:	55                   	push   %ebp
   12935:	89 e5                	mov    %esp,%ebp
   12937:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
   1293a:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   12941:	e8 93 ff ff ff       	call   128d9 <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
   12946:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1294d:	e8 87 ff ff ff       	call   128d9 <section_fnptrs_execute>
}
   12952:	c9                   	leave  
   12953:	c3                   	ret    

00012954 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
   12954:	55                   	push   %ebp
   12955:	89 e5                	mov    %esp,%ebp
   12957:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
   1295a:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   12961:	e8 73 ff ff ff       	call   128d9 <section_fnptrs_execute>
}
   12966:	c9                   	leave  
   12967:	c3                   	ret    

00012968 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
   12968:	55                   	push   %ebp
   12969:	89 e5                	mov    %esp,%ebp
   1296b:	83 ec 08             	sub    $0x8,%esp
   1296e:	8b 55 08             	mov    0x8(%ebp),%edx
   12971:	8b 45 0c             	mov    0xc(%ebp),%eax
   12974:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
   12978:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
   1297b:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1297f:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
   12983:	ee                   	out    %al,(%dx)
}
   12984:	c9                   	leave  
   12985:	c3                   	ret    

00012986 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
   12986:	55                   	push   %ebp
   12987:	89 e5                	mov    %esp,%ebp
   12989:	83 ec 14             	sub    $0x14,%esp
   1298c:	8b 45 08             	mov    0x8(%ebp),%eax
   1298f:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
   12993:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
   12997:	89 c2                	mov    %eax,%edx
   12999:	ec                   	in     (%dx),%al
   1299a:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
   1299d:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
   129a1:	c9                   	leave  
   129a2:	c3                   	ret    

000129a3 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
   129a3:	55                   	push   %ebp
   129a4:	89 e5                	mov    %esp,%ebp
   129a6:	83 ec 0c             	sub    $0xc,%esp
   129a9:	8b 45 08             	mov    0x8(%ebp),%eax
   129ac:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
   129af:	90                   	nop
   129b0:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
   129b7:	e8 ca ff ff ff       	call   12986 <inb>
   129bc:	0f b6 c0             	movzbl %al,%eax
   129bf:	83 e0 20             	and    $0x20,%eax
   129c2:	85 c0                	test   %eax,%eax
   129c4:	74 ea                	je     129b0 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
   129c6:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   129ca:	0f b6 c0             	movzbl %al,%eax
   129cd:	89 44 24 04          	mov    %eax,0x4(%esp)
   129d1:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
   129d8:	e8 8b ff ff ff       	call   12968 <outb>
}
   129dd:	c9                   	leave  
   129de:	c3                   	ret    

000129df <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
   129df:	55                   	push   %ebp
   129e0:	89 e5                	mov    %esp,%ebp
   129e2:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
   129e5:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
   129ec:	eb 1a                	jmp    12a08 <cos_serial_putb+0x29>
   129ee:	8b 45 fc             	mov    -0x4(%ebp),%eax
   129f1:	8b 55 08             	mov    0x8(%ebp),%edx
   129f4:	01 d0                	add    %edx,%eax
   129f6:	0f b6 00             	movzbl (%eax),%eax
   129f9:	0f be c0             	movsbl %al,%eax
   129fc:	89 04 24             	mov    %eax,(%esp)
   129ff:	e8 9f ff ff ff       	call   129a3 <cos_serial_putc>
   12a04:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
   12a08:	8b 45 fc             	mov    -0x4(%ebp),%eax
   12a0b:	3b 45 0c             	cmp    0xc(%ebp),%eax
   12a0e:	72 de                	jb     129ee <cos_serial_putb+0xf>
}
   12a10:	c9                   	leave  
   12a11:	c3                   	ret    

00012a12 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
   12a12:	55                   	push   %ebp
   12a13:	89 e5                	mov    %esp,%ebp
   12a15:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
   12a18:	8b 45 0c             	mov    0xc(%ebp),%eax
   12a1b:	89 44 24 04          	mov    %eax,0x4(%esp)
   12a1f:	8b 45 08             	mov    0x8(%ebp),%eax
   12a22:	89 04 24             	mov    %eax,(%esp)
   12a25:	e8 b5 ff ff ff       	call   129df <cos_serial_putb>
}
   12a2a:	c9                   	leave  
   12a2b:	c3                   	ret    

00012a2c <prints>:

static int
prints(char *s)
{
   12a2c:	55                   	push   %ebp
   12a2d:	89 e5                	mov    %esp,%ebp
   12a2f:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
   12a32:	8b 45 08             	mov    0x8(%ebp),%eax
   12a35:	89 04 24             	mov    %eax,(%esp)
   12a38:	e8 fc ff ff ff       	call   12a39 <prints+0xd>
   12a3d:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
   12a40:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12a43:	89 44 24 04          	mov    %eax,0x4(%esp)
   12a47:	8b 45 08             	mov    0x8(%ebp),%eax
   12a4a:	89 04 24             	mov    %eax,(%esp)
   12a4d:	e8 05 fe ff ff       	call   12857 <cos_print>

	return len;
   12a52:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   12a55:	c9                   	leave  
   12a56:	c3                   	ret    

00012a57 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
   12a57:	55                   	push   %ebp
   12a58:	89 e5                	mov    %esp,%ebp
   12a5a:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
   12a60:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
   12a67:	8d 45 0c             	lea    0xc(%ebp),%eax
   12a6a:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
   12a70:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
   12a76:	89 44 24 0c          	mov    %eax,0xc(%esp)
   12a7a:	8b 45 08             	mov    0x8(%ebp),%eax
   12a7d:	89 44 24 08          	mov    %eax,0x8(%esp)
   12a81:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12a84:	89 44 24 04          	mov    %eax,0x4(%esp)
   12a88:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
   12a8e:	89 04 24             	mov    %eax,(%esp)
   12a91:	e8 fc ff ff ff       	call   12a92 <printc+0x3b>
   12a96:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
   12a99:	8b 45 f0             	mov    -0x10(%ebp),%eax
   12a9c:	89 44 24 04          	mov    %eax,0x4(%esp)
   12aa0:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
   12aa6:	89 04 24             	mov    %eax,(%esp)
   12aa9:	e8 64 ff ff ff       	call   12a12 <cos_llprint>

	return ret;
   12aae:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
   12ab1:	c9                   	leave  
   12ab2:	c3                   	ret    

00012ab3 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
   12ab3:	55                   	push   %ebp
   12ab4:	89 e5                	mov    %esp,%ebp
	while (1)
		;
   12ab6:	eb fe                	jmp    12ab6 <__cos_noret+0x3>

00012ab8 <ps_cas>:
 * 0 on failure due to contention (*target != old)
 * 1 otherwise (*target == old -> *target = updated)
 */
static inline int
ps_cas(unsigned long *target, unsigned long old, unsigned long updated)
{
   12ab8:	55                   	push   %ebp
   12ab9:	89 e5                	mov    %esp,%ebp
   12abb:	53                   	push   %ebx
   12abc:	83 ec 10             	sub    $0x10,%esp
        char z;
        __asm__ __volatile__("lock " PS_CAS_STR
   12abf:	8b 55 08             	mov    0x8(%ebp),%edx
   12ac2:	8b 4d 10             	mov    0x10(%ebp),%ecx
   12ac5:	8b 45 0c             	mov    0xc(%ebp),%eax
   12ac8:	8b 5d 08             	mov    0x8(%ebp),%ebx
   12acb:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   12acf:	0f 94 c0             	sete   %al
   12ad2:	88 45 fb             	mov    %al,-0x5(%ebp)
                             : "+m" (*target), "=a" (z)
                             : "q"  (updated), "a"  (old)
                             : "memory", "cc");
        return (int)z;
   12ad5:	0f be 45 fb          	movsbl -0x5(%ebp),%eax
}
   12ad9:	83 c4 10             	add    $0x10,%esp
   12adc:	5b                   	pop    %ebx
   12add:	5d                   	pop    %ebp
   12ade:	c3                   	ret    

00012adf <cos_aepthd_fn>:
	struct cos_aep_info sched_aep[NUM_CPU];
};

static void
cos_aepthd_fn(void *data)
{
   12adf:	55                   	push   %ebp
   12ae0:	89 e5                	mov    %esp,%ebp
   12ae2:	83 ec 28             	sub    $0x28,%esp
	struct cos_aep_info *aep_info = (struct cos_aep_info *)data;
   12ae5:	8b 45 08             	mov    0x8(%ebp),%eax
   12ae8:	89 45 f4             	mov    %eax,-0xc(%ebp)
	cos_aepthd_fn_t      aep_fn   = aep_info->fn;
   12aeb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12aee:	8b 40 10             	mov    0x10(%eax),%eax
   12af1:	89 45 f0             	mov    %eax,-0x10(%ebp)
	void *               fn_data  = aep_info->data;
   12af4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12af7:	8b 40 14             	mov    0x14(%eax),%eax
   12afa:	89 45 ec             	mov    %eax,-0x14(%ebp)

	(aep_fn)(aep_info->rcv, fn_data);
   12afd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12b00:	8b 40 0c             	mov    0xc(%eax),%eax
   12b03:	8b 55 ec             	mov    -0x14(%ebp),%edx
   12b06:	89 54 24 04          	mov    %edx,0x4(%esp)
   12b0a:	89 04 24             	mov    %eax,(%esp)
   12b0d:	8b 45 f0             	mov    -0x10(%ebp),%eax
   12b10:	ff d0                	call   *%eax

	/* TODO: handling destruction */
	assert(0);
   12b12:	c7 04 24 18 2b 00 00 	movl   $0x2b18,(%esp)
   12b19:	e8 0e ff ff ff       	call   12a2c <prints>
   12b1e:	a1 a0 02 00 00       	mov    0x2a0,%eax
   12b23:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12b29:	e8 85 ff ff ff       	call   12ab3 <__cos_noret>

00012b2e <ps_list_ll_empty>:
ps_list_head_init(struct ps_list_head *lh)
{ ps_list_ll_init(&lh->l); }

static inline int
ps_list_ll_empty(struct ps_list *l)
{ return l->n == l; }
   12b2e:	55                   	push   %ebp
   12b2f:	89 e5                	mov    %esp,%ebp
   12b31:	8b 45 08             	mov    0x8(%ebp),%eax
   12b34:	8b 00                	mov    (%eax),%eax
   12b36:	3b 45 08             	cmp    0x8(%ebp),%eax
   12b39:	0f 94 c0             	sete   %al
   12b3c:	0f b6 c0             	movzbl %al,%eax
   12b3f:	5d                   	pop    %ebp
   12b40:	c3                   	ret    

00012b41 <ps_list_ll_add>:
ps_list_head_empty(struct ps_list_head *lh)
{ return ps_list_ll_empty(&lh->l); }

static inline void
ps_list_ll_add(struct ps_list *l, struct ps_list *new)
{
   12b41:	55                   	push   %ebp
   12b42:	89 e5                	mov    %esp,%ebp
	new->n    = l->n;
   12b44:	8b 45 08             	mov    0x8(%ebp),%eax
   12b47:	8b 10                	mov    (%eax),%edx
   12b49:	8b 45 0c             	mov    0xc(%ebp),%eax
   12b4c:	89 10                	mov    %edx,(%eax)
	new->p    = l;
   12b4e:	8b 45 0c             	mov    0xc(%ebp),%eax
   12b51:	8b 55 08             	mov    0x8(%ebp),%edx
   12b54:	89 50 04             	mov    %edx,0x4(%eax)
	l->n      = new;
   12b57:	8b 45 08             	mov    0x8(%ebp),%eax
   12b5a:	8b 55 0c             	mov    0xc(%ebp),%edx
   12b5d:	89 10                	mov    %edx,(%eax)
	new->n->p = new;
   12b5f:	8b 45 0c             	mov    0xc(%ebp),%eax
   12b62:	8b 00                	mov    (%eax),%eax
   12b64:	8b 55 0c             	mov    0xc(%ebp),%edx
   12b67:	89 50 04             	mov    %edx,0x4(%eax)
}
   12b6a:	5d                   	pop    %ebp
   12b6b:	c3                   	ret    

00012b6c <ps_list_ll_rem>:

static inline void
ps_list_ll_rem(struct ps_list *l)
{
   12b6c:	55                   	push   %ebp
   12b6d:	89 e5                	mov    %esp,%ebp
	l->n->p = l->p;
   12b6f:	8b 45 08             	mov    0x8(%ebp),%eax
   12b72:	8b 00                	mov    (%eax),%eax
   12b74:	8b 55 08             	mov    0x8(%ebp),%edx
   12b77:	8b 52 04             	mov    0x4(%edx),%edx
   12b7a:	89 50 04             	mov    %edx,0x4(%eax)
	l->p->n = l->n;
   12b7d:	8b 45 08             	mov    0x8(%ebp),%eax
   12b80:	8b 40 04             	mov    0x4(%eax),%eax
   12b83:	8b 55 08             	mov    0x8(%ebp),%edx
   12b86:	8b 12                	mov    (%edx),%edx
   12b88:	89 10                	mov    %edx,(%eax)
	l->p = l->n = l;
   12b8a:	8b 45 08             	mov    0x8(%ebp),%eax
   12b8d:	8b 55 08             	mov    0x8(%ebp),%edx
   12b90:	89 10                	mov    %edx,(%eax)
   12b92:	8b 45 08             	mov    0x8(%ebp),%eax
   12b95:	8b 10                	mov    (%eax),%edx
   12b97:	8b 45 08             	mov    0x8(%ebp),%eax
   12b9a:	89 50 04             	mov    %edx,0x4(%eax)
}
   12b9d:	5d                   	pop    %ebp
   12b9e:	c3                   	ret    

00012b9f <__slab_freelist_rem>:
static inline void __ps_slab_freelist_check(struct ps_slab_freelist *fl) { (void)fl; }
#endif /* PS_SLAB_DEBUG */

static void
__slab_freelist_rem(struct ps_slab_freelist *fl, struct ps_slab *s)
{
   12b9f:	55                   	push   %ebp
   12ba0:	89 e5                	mov    %esp,%ebp
   12ba2:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
   12ba5:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   12ba9:	0f 94 c0             	sete   %al
   12bac:	0f b6 c0             	movzbl %al,%eax
   12baf:	85 c0                	test   %eax,%eax
   12bb1:	75 0e                	jne    12bc1 <__slab_freelist_rem+0x22>
   12bb3:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   12bb7:	0f 94 c0             	sete   %al
   12bba:	0f b6 c0             	movzbl %al,%eax
   12bbd:	85 c0                	test   %eax,%eax
   12bbf:	74 1c                	je     12bdd <__slab_freelist_rem+0x3e>
   12bc1:	c7 04 24 7c 2b 00 00 	movl   $0x2b7c,(%esp)
   12bc8:	e8 5f fe ff ff       	call   12a2c <prints>
   12bcd:	a1 a0 02 00 00       	mov    0x2a0,%eax
   12bd2:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12bd8:	e8 d6 fe ff ff       	call   12ab3 <__cos_noret>
	if (fl->list == s) {
   12bdd:	8b 45 08             	mov    0x8(%ebp),%eax
   12be0:	8b 00                	mov    (%eax),%eax
   12be2:	3b 45 0c             	cmp    0xc(%ebp),%eax
   12be5:	75 2b                	jne    12c12 <__slab_freelist_rem+0x73>
		if (ps_list_singleton(s, list)) fl->list = NULL;
   12be7:	8b 45 0c             	mov    0xc(%ebp),%eax
   12bea:	83 c0 44             	add    $0x44,%eax
   12bed:	89 04 24             	mov    %eax,(%esp)
   12bf0:	e8 39 ff ff ff       	call   12b2e <ps_list_ll_empty>
   12bf5:	85 c0                	test   %eax,%eax
   12bf7:	74 0b                	je     12c04 <__slab_freelist_rem+0x65>
   12bf9:	8b 45 08             	mov    0x8(%ebp),%eax
   12bfc:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12c02:	eb 0e                	jmp    12c12 <__slab_freelist_rem+0x73>
		else                            fl->list = ps_list_next(s, list);
   12c04:	8b 45 0c             	mov    0xc(%ebp),%eax
   12c07:	8b 40 44             	mov    0x44(%eax),%eax
   12c0a:	8d 50 bc             	lea    -0x44(%eax),%edx
   12c0d:	8b 45 08             	mov    0x8(%ebp),%eax
   12c10:	89 10                	mov    %edx,(%eax)
	}
	ps_list_rem(s, list);
   12c12:	8b 45 0c             	mov    0xc(%ebp),%eax
   12c15:	83 c0 44             	add    $0x44,%eax
   12c18:	89 04 24             	mov    %eax,(%esp)
   12c1b:	e8 4c ff ff ff       	call   12b6c <ps_list_ll_rem>
}
   12c20:	c9                   	leave  
   12c21:	c3                   	ret    

00012c22 <__slab_freelist_add>:

static void
__slab_freelist_add(struct ps_slab_freelist *fl, struct ps_slab *s)
{
   12c22:	55                   	push   %ebp
   12c23:	89 e5                	mov    %esp,%ebp
   12c25:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
   12c28:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   12c2c:	0f 94 c0             	sete   %al
   12c2f:	0f b6 c0             	movzbl %al,%eax
   12c32:	85 c0                	test   %eax,%eax
   12c34:	75 0e                	jne    12c44 <__slab_freelist_add+0x22>
   12c36:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   12c3a:	0f 94 c0             	sete   %al
   12c3d:	0f b6 c0             	movzbl %al,%eax
   12c40:	85 c0                	test   %eax,%eax
   12c42:	74 1c                	je     12c60 <__slab_freelist_add+0x3e>
   12c44:	c7 04 24 d4 2b 00 00 	movl   $0x2bd4,(%esp)
   12c4b:	e8 dc fd ff ff       	call   12a2c <prints>
   12c50:	a1 a0 02 00 00       	mov    0x2a0,%eax
   12c55:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12c5b:	e8 53 fe ff ff       	call   12ab3 <__cos_noret>
	assert(ps_list_singleton(s, list));
   12c60:	8b 45 0c             	mov    0xc(%ebp),%eax
   12c63:	83 c0 44             	add    $0x44,%eax
   12c66:	89 04 24             	mov    %eax,(%esp)
   12c69:	e8 c0 fe ff ff       	call   12b2e <ps_list_ll_empty>
   12c6e:	85 c0                	test   %eax,%eax
   12c70:	0f 94 c0             	sete   %al
   12c73:	0f b6 c0             	movzbl %al,%eax
   12c76:	85 c0                	test   %eax,%eax
   12c78:	74 1c                	je     12c96 <__slab_freelist_add+0x74>
   12c7a:	c7 04 24 2c 2c 00 00 	movl   $0x2c2c,(%esp)
   12c81:	e8 a6 fd ff ff       	call   12a2c <prints>
   12c86:	a1 a0 02 00 00       	mov    0x2a0,%eax
   12c8b:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12c91:	e8 1d fe ff ff       	call   12ab3 <__cos_noret>
	assert(s != fl->list);
   12c96:	8b 45 08             	mov    0x8(%ebp),%eax
   12c99:	8b 00                	mov    (%eax),%eax
   12c9b:	3b 45 0c             	cmp    0xc(%ebp),%eax
   12c9e:	0f 94 c0             	sete   %al
   12ca1:	0f b6 c0             	movzbl %al,%eax
   12ca4:	85 c0                	test   %eax,%eax
   12ca6:	74 1c                	je     12cc4 <__slab_freelist_add+0xa2>
   12ca8:	c7 04 24 84 2c 00 00 	movl   $0x2c84,(%esp)
   12caf:	e8 78 fd ff ff       	call   12a2c <prints>
   12cb4:	a1 a0 02 00 00       	mov    0x2a0,%eax
   12cb9:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   12cbf:	e8 ef fd ff ff       	call   12ab3 <__cos_noret>
	if (fl->list) ps_list_add(fl->list, s, list);
   12cc4:	8b 45 08             	mov    0x8(%ebp),%eax
   12cc7:	8b 00                	mov    (%eax),%eax
   12cc9:	85 c0                	test   %eax,%eax
   12ccb:	74 1a                	je     12ce7 <__slab_freelist_add+0xc5>
   12ccd:	8b 45 0c             	mov    0xc(%ebp),%eax
   12cd0:	8d 50 44             	lea    0x44(%eax),%edx
   12cd3:	8b 45 08             	mov    0x8(%ebp),%eax
   12cd6:	8b 00                	mov    (%eax),%eax
   12cd8:	83 c0 44             	add    $0x44,%eax
   12cdb:	89 54 24 04          	mov    %edx,0x4(%esp)
   12cdf:	89 04 24             	mov    %eax,(%esp)
   12ce2:	e8 5a fe ff ff       	call   12b41 <ps_list_ll_add>
	fl->list = s;
   12ce7:	8b 45 08             	mov    0x8(%ebp),%eax
   12cea:	8b 55 0c             	mov    0xc(%ebp),%edx
   12ced:	89 10                	mov    %edx,(%eax)
	/* TODO: sort based on emptiness...just use N bins */
}
   12cef:	c9                   	leave  
   12cf0:	c3                   	ret    

00012cf1 <sl_thd_aepinfo>:
	struct ps_list    SL_THD_EVENT_LIST; /* list of events for the scheduler end-point */
};

static inline struct cos_aep_info *
sl_thd_aepinfo(struct sl_thd *t)
{ return (t->aepinfo); }
   12cf1:	55                   	push   %ebp
   12cf2:	89 e5                	mov    %esp,%ebp
   12cf4:	8b 45 08             	mov    0x8(%ebp),%eax
   12cf7:	8b 40 0c             	mov    0xc(%eax),%eax
   12cfa:	5d                   	pop    %ebp
   12cfb:	c3                   	ret    

00012cfc <sl_thd_thdcap>:

static inline thdcap_t
sl_thd_thdcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->thd; }
   12cfc:	55                   	push   %ebp
   12cfd:	89 e5                	mov    %esp,%ebp
   12cff:	83 ec 04             	sub    $0x4,%esp
   12d02:	8b 45 08             	mov    0x8(%ebp),%eax
   12d05:	89 04 24             	mov    %eax,(%esp)
   12d08:	e8 e4 ff ff ff       	call   12cf1 <sl_thd_aepinfo>
   12d0d:	8b 40 04             	mov    0x4(%eax),%eax
   12d10:	c9                   	leave  
   12d11:	c3                   	ret    

00012d12 <sl_thd_asndcap>:
sl_thd_rcvcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->rcv; }

static inline asndcap_t
sl_thd_asndcap(struct sl_thd *t)
{ return t->sndcap; }
   12d12:	55                   	push   %ebp
   12d13:	89 e5                	mov    %esp,%ebp
   12d15:	8b 45 08             	mov    0x8(%ebp),%eax
   12d18:	8b 40 10             	mov    0x10(%eax),%eax
   12d1b:	5d                   	pop    %ebp
   12d1c:	c3                   	ret    

00012d1d <sl_thd_thdid>:

static inline thdid_t
sl_thd_thdid(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->tid; }
   12d1d:	55                   	push   %ebp
   12d1e:	89 e5                	mov    %esp,%ebp
   12d20:	83 ec 04             	sub    $0x4,%esp
   12d23:	8b 45 08             	mov    0x8(%ebp),%eax
   12d26:	89 04 24             	mov    %eax,(%esp)
   12d29:	e8 c3 ff ff ff       	call   12cf1 <sl_thd_aepinfo>
   12d2e:	0f b7 40 08          	movzwl 0x8(%eax),%eax
   12d32:	c9                   	leave  
   12d33:	c3                   	ret    

00012d34 <ck_cc_ffs>:
 */
#ifndef CK_MD_CC_BUILTIN_DISABLE
#define CK_F_CC_FFS
CK_CC_INLINE static int
ck_cc_ffs(unsigned int x)
{
   12d34:	55                   	push   %ebp
   12d35:	89 e5                	mov    %esp,%ebp

	return __builtin_ffsl(x);
   12d37:	8b 45 08             	mov    0x8(%ebp),%eax
   12d3a:	ba ff ff ff ff       	mov    $0xffffffff,%edx
   12d3f:	0f bc c0             	bsf    %eax,%eax
   12d42:	0f 44 c2             	cmove  %edx,%eax
   12d45:	83 c0 01             	add    $0x1,%eax
}
   12d48:	5d                   	pop    %ebp
   12d49:	c3                   	ret    

00012d4a <ck_cc_ffsl>:

#define CK_F_CC_FFSL
CK_CC_INLINE static int
ck_cc_ffsl(unsigned long x)
{
   12d4a:	55                   	push   %ebp
   12d4b:	89 e5                	mov    %esp,%ebp
   12d4d:	83 ec 18             	sub    $0x18,%esp

	return __builtin_ffsll(x);
   12d50:	8b 45 08             	mov    0x8(%ebp),%eax
   12d53:	ba 00 00 00 00       	mov    $0x0,%edx
   12d58:	89 04 24             	mov    %eax,(%esp)
   12d5b:	89 54 24 04          	mov    %edx,0x4(%esp)
   12d5f:	e8 fc ff ff ff       	call   12d60 <ck_cc_ffsl+0x16>
}
   12d64:	c9                   	leave  
   12d65:	c3                   	ret    

00012d66 <ck_cc_ctz>:

#define CK_F_CC_CTZ
CK_CC_INLINE static int
ck_cc_ctz(unsigned int x)
{
   12d66:	55                   	push   %ebp
   12d67:	89 e5                	mov    %esp,%ebp

	return __builtin_ctz(x);
   12d69:	f3 0f bc 45 08       	tzcnt  0x8(%ebp),%eax
}
   12d6e:	5d                   	pop    %ebp
   12d6f:	c3                   	ret    

00012d70 <ck_cc_popcount>:

#define CK_F_CC_POPCOUNT
CK_CC_INLINE static int
ck_cc_popcount(unsigned int x)
{
   12d70:	55                   	push   %ebp
   12d71:	89 e5                	mov    %esp,%ebp
   12d73:	83 ec 18             	sub    $0x18,%esp

	return __builtin_popcount(x);
   12d76:	8b 45 08             	mov    0x8(%ebp),%eax
   12d79:	89 04 24             	mov    %eax,(%esp)
   12d7c:	e8 fc ff ff ff       	call   12d7d <ck_cc_popcount+0xd>
}
   12d81:	c9                   	leave  
   12d82:	c3                   	ret    

00012d83 <ck_cc_ffsll>:
   12d83:	55                   	push   %ebp
   12d84:	89 e5                	mov    %esp,%ebp
   12d86:	53                   	push   %ebx
   12d87:	83 ec 1c             	sub    $0x1c,%esp
   12d8a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   12d8d:	89 4d e0             	mov    %ecx,-0x20(%ebp)
   12d90:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   12d93:	89 4d e4             	mov    %ecx,-0x1c(%ebp)
   12d96:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   12d99:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
   12d9c:	09 d9                	or     %ebx,%ecx
   12d9e:	85 c9                	test   %ecx,%ecx
   12da0:	75 07                	jne    12da9 <ck_cc_ffsll+0x26>
   12da2:	b8 00 00 00 00       	mov    $0x0,%eax
   12da7:	eb 3a                	jmp    12de3 <ck_cc_ffsll+0x60>
   12da9:	c7 45 f4 01 00 00 00 	movl   $0x1,-0xc(%ebp)
   12db0:	eb 16                	jmp    12dc8 <ck_cc_ffsll+0x45>
   12db2:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   12db6:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   12db9:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
   12dbc:	0f ac d9 01          	shrd   $0x1,%ebx,%ecx
   12dc0:	d1 eb                	shr    %ebx
   12dc2:	89 4d e0             	mov    %ecx,-0x20(%ebp)
   12dc5:	89 5d e4             	mov    %ebx,-0x1c(%ebp)
   12dc8:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   12dcb:	83 e1 01             	and    $0x1,%ecx
   12dce:	89 c8                	mov    %ecx,%eax
   12dd0:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
   12dd3:	83 e1 00             	and    $0x0,%ecx
   12dd6:	89 ca                	mov    %ecx,%edx
   12dd8:	89 d1                	mov    %edx,%ecx
   12dda:	09 c1                	or     %eax,%ecx
   12ddc:	85 c9                	test   %ecx,%ecx
   12dde:	74 d2                	je     12db2 <ck_cc_ffsll+0x2f>
   12de0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   12de3:	83 c4 1c             	add    $0x1c,%esp
   12de6:	5b                   	pop    %ebx
   12de7:	5d                   	pop    %ebp
   12de8:	c3                   	ret    

00012de9 <ck_pr_stall>:
 * Prevent speculative execution in busy-wait loops (P4 <=) or "predefined
 * delay".
 */
CK_CC_INLINE static void
ck_pr_stall(void)
{
   12de9:	55                   	push   %ebp
   12dea:	89 e5                	mov    %esp,%ebp
	__asm__ __volatile__("pause" ::: "memory");
   12dec:	f3 90                	pause  
	return;
   12dee:	90                   	nop
}
   12def:	5d                   	pop    %ebp
   12df0:	c3                   	ret    

00012df1 <ck_pr_fence_strict_atomic>:
#define CK_MD_X86_SFENCE "sfence"
#define CK_MD_X86_LFENCE "lfence"
#define CK_MD_X86_MFENCE "mfence"
#endif /* !CK_MD_SSE_DISABLE */

CK_PR_FENCE(atomic, "")
   12df1:	55                   	push   %ebp
   12df2:	89 e5                	mov    %esp,%ebp
   12df4:	90                   	nop
   12df5:	5d                   	pop    %ebp
   12df6:	c3                   	ret    

00012df7 <ck_pr_fence_strict_atomic_store>:
CK_PR_FENCE(atomic_store, "")
   12df7:	55                   	push   %ebp
   12df8:	89 e5                	mov    %esp,%ebp
   12dfa:	90                   	nop
   12dfb:	5d                   	pop    %ebp
   12dfc:	c3                   	ret    

00012dfd <ck_pr_fence_strict_atomic_load>:
CK_PR_FENCE(atomic_load, "")
   12dfd:	55                   	push   %ebp
   12dfe:	89 e5                	mov    %esp,%ebp
   12e00:	90                   	nop
   12e01:	5d                   	pop    %ebp
   12e02:	c3                   	ret    

00012e03 <ck_pr_fence_strict_store_atomic>:
CK_PR_FENCE(store_atomic, "")
   12e03:	55                   	push   %ebp
   12e04:	89 e5                	mov    %esp,%ebp
   12e06:	90                   	nop
   12e07:	5d                   	pop    %ebp
   12e08:	c3                   	ret    

00012e09 <ck_pr_fence_strict_load_atomic>:
CK_PR_FENCE(load_atomic, "")
   12e09:	55                   	push   %ebp
   12e0a:	89 e5                	mov    %esp,%ebp
   12e0c:	90                   	nop
   12e0d:	5d                   	pop    %ebp
   12e0e:	c3                   	ret    

00012e0f <ck_pr_fence_strict_load>:
CK_PR_FENCE(load, CK_MD_X86_LFENCE)
   12e0f:	55                   	push   %ebp
   12e10:	89 e5                	mov    %esp,%ebp
   12e12:	0f ae e8             	lfence 
   12e15:	90                   	nop
   12e16:	5d                   	pop    %ebp
   12e17:	c3                   	ret    

00012e18 <ck_pr_fence_strict_load_store>:
CK_PR_FENCE(load_store, CK_MD_X86_MFENCE)
   12e18:	55                   	push   %ebp
   12e19:	89 e5                	mov    %esp,%ebp
   12e1b:	0f ae f0             	mfence 
   12e1e:	90                   	nop
   12e1f:	5d                   	pop    %ebp
   12e20:	c3                   	ret    

00012e21 <ck_pr_fence_strict_store>:
CK_PR_FENCE(store, CK_MD_X86_SFENCE)
   12e21:	55                   	push   %ebp
   12e22:	89 e5                	mov    %esp,%ebp
   12e24:	0f ae f8             	sfence 
   12e27:	90                   	nop
   12e28:	5d                   	pop    %ebp
   12e29:	c3                   	ret    

00012e2a <ck_pr_fence_strict_store_load>:
CK_PR_FENCE(store_load, CK_MD_X86_MFENCE)
   12e2a:	55                   	push   %ebp
   12e2b:	89 e5                	mov    %esp,%ebp
   12e2d:	0f ae f0             	mfence 
   12e30:	90                   	nop
   12e31:	5d                   	pop    %ebp
   12e32:	c3                   	ret    

00012e33 <ck_pr_fence_strict_memory>:
CK_PR_FENCE(memory, CK_MD_X86_MFENCE)
   12e33:	55                   	push   %ebp
   12e34:	89 e5                	mov    %esp,%ebp
   12e36:	0f ae f0             	mfence 
   12e39:	90                   	nop
   12e3a:	5d                   	pop    %ebp
   12e3b:	c3                   	ret    

00012e3c <ck_pr_fence_strict_release>:
CK_PR_FENCE(release, CK_MD_X86_MFENCE)
   12e3c:	55                   	push   %ebp
   12e3d:	89 e5                	mov    %esp,%ebp
   12e3f:	0f ae f0             	mfence 
   12e42:	90                   	nop
   12e43:	5d                   	pop    %ebp
   12e44:	c3                   	ret    

00012e45 <ck_pr_fence_strict_acquire>:
CK_PR_FENCE(acquire, CK_MD_X86_MFENCE)
   12e45:	55                   	push   %ebp
   12e46:	89 e5                	mov    %esp,%ebp
   12e48:	0f ae f0             	mfence 
   12e4b:	90                   	nop
   12e4c:	5d                   	pop    %ebp
   12e4d:	c3                   	ret    

00012e4e <ck_pr_fence_strict_acqrel>:
CK_PR_FENCE(acqrel, CK_MD_X86_MFENCE)
   12e4e:	55                   	push   %ebp
   12e4f:	89 e5                	mov    %esp,%ebp
   12e51:	0f ae f0             	mfence 
   12e54:	90                   	nop
   12e55:	5d                   	pop    %ebp
   12e56:	c3                   	ret    

00012e57 <ck_pr_fence_strict_lock>:
CK_PR_FENCE(lock, CK_MD_X86_MFENCE)
   12e57:	55                   	push   %ebp
   12e58:	89 e5                	mov    %esp,%ebp
   12e5a:	0f ae f0             	mfence 
   12e5d:	90                   	nop
   12e5e:	5d                   	pop    %ebp
   12e5f:	c3                   	ret    

00012e60 <ck_pr_fence_strict_unlock>:
CK_PR_FENCE(unlock, CK_MD_X86_MFENCE)
   12e60:	55                   	push   %ebp
   12e61:	89 e5                	mov    %esp,%ebp
   12e63:	0f ae f0             	mfence 
   12e66:	90                   	nop
   12e67:	5d                   	pop    %ebp
   12e68:	c3                   	ret    

00012e69 <ck_pr_fas_ptr>:
					:			\
					: "memory");		\
		return v;					\
	}

CK_PR_FAS(ptr, void, void *, char, "xchgl")
   12e69:	55                   	push   %ebp
   12e6a:	89 e5                	mov    %esp,%ebp
   12e6c:	8b 55 08             	mov    0x8(%ebp),%edx
   12e6f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   12e72:	8b 45 0c             	mov    0xc(%ebp),%eax
   12e75:	87 02                	xchg   %eax,(%edx)
   12e77:	89 45 0c             	mov    %eax,0xc(%ebp)
   12e7a:	8b 45 0c             	mov    0xc(%ebp),%eax
   12e7d:	5d                   	pop    %ebp
   12e7e:	c3                   	ret    

00012e7f <ck_pr_fas_char>:

#define CK_PR_FAS_S(S, T, I) CK_PR_FAS(S, T, T, T, I)

CK_PR_FAS_S(char, char, "xchgb")
   12e7f:	55                   	push   %ebp
   12e80:	89 e5                	mov    %esp,%ebp
   12e82:	83 ec 04             	sub    $0x4,%esp
   12e85:	8b 45 0c             	mov    0xc(%ebp),%eax
   12e88:	88 45 fc             	mov    %al,-0x4(%ebp)
   12e8b:	8b 55 08             	mov    0x8(%ebp),%edx
   12e8e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   12e91:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   12e95:	86 02                	xchg   %al,(%edx)
   12e97:	88 45 fc             	mov    %al,-0x4(%ebp)
   12e9a:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   12e9e:	c9                   	leave  
   12e9f:	c3                   	ret    

00012ea0 <ck_pr_fas_uint>:
CK_PR_FAS_S(uint, unsigned int, "xchgl")
   12ea0:	55                   	push   %ebp
   12ea1:	89 e5                	mov    %esp,%ebp
   12ea3:	8b 55 08             	mov    0x8(%ebp),%edx
   12ea6:	8b 4d 08             	mov    0x8(%ebp),%ecx
   12ea9:	8b 45 0c             	mov    0xc(%ebp),%eax
   12eac:	87 02                	xchg   %eax,(%edx)
   12eae:	89 45 0c             	mov    %eax,0xc(%ebp)
   12eb1:	8b 45 0c             	mov    0xc(%ebp),%eax
   12eb4:	5d                   	pop    %ebp
   12eb5:	c3                   	ret    

00012eb6 <ck_pr_fas_int>:
CK_PR_FAS_S(int, int, "xchgl")
   12eb6:	55                   	push   %ebp
   12eb7:	89 e5                	mov    %esp,%ebp
   12eb9:	8b 55 08             	mov    0x8(%ebp),%edx
   12ebc:	8b 4d 08             	mov    0x8(%ebp),%ecx
   12ebf:	8b 45 0c             	mov    0xc(%ebp),%eax
   12ec2:	87 02                	xchg   %eax,(%edx)
   12ec4:	89 45 0c             	mov    %eax,0xc(%ebp)
   12ec7:	8b 45 0c             	mov    0xc(%ebp),%eax
   12eca:	5d                   	pop    %ebp
   12ecb:	c3                   	ret    

00012ecc <ck_pr_fas_32>:
CK_PR_FAS_S(32, uint32_t, "xchgl")
   12ecc:	55                   	push   %ebp
   12ecd:	89 e5                	mov    %esp,%ebp
   12ecf:	8b 55 08             	mov    0x8(%ebp),%edx
   12ed2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   12ed5:	8b 45 0c             	mov    0xc(%ebp),%eax
   12ed8:	87 02                	xchg   %eax,(%edx)
   12eda:	89 45 0c             	mov    %eax,0xc(%ebp)
   12edd:	8b 45 0c             	mov    0xc(%ebp),%eax
   12ee0:	5d                   	pop    %ebp
   12ee1:	c3                   	ret    

00012ee2 <ck_pr_fas_16>:
CK_PR_FAS_S(16, uint16_t, "xchgw")
   12ee2:	55                   	push   %ebp
   12ee3:	89 e5                	mov    %esp,%ebp
   12ee5:	83 ec 04             	sub    $0x4,%esp
   12ee8:	8b 45 0c             	mov    0xc(%ebp),%eax
   12eeb:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   12eef:	8b 55 08             	mov    0x8(%ebp),%edx
   12ef2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   12ef5:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   12ef9:	66 87 02             	xchg   %ax,(%edx)
   12efc:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   12f00:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   12f04:	c9                   	leave  
   12f05:	c3                   	ret    

00012f06 <ck_pr_fas_8>:
CK_PR_FAS_S(8,  uint8_t,  "xchgb")
   12f06:	55                   	push   %ebp
   12f07:	89 e5                	mov    %esp,%ebp
   12f09:	83 ec 04             	sub    $0x4,%esp
   12f0c:	8b 45 0c             	mov    0xc(%ebp),%eax
   12f0f:	88 45 fc             	mov    %al,-0x4(%ebp)
   12f12:	8b 55 08             	mov    0x8(%ebp),%edx
   12f15:	8b 4d 08             	mov    0x8(%ebp),%ecx
   12f18:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   12f1c:	86 02                	xchg   %al,(%edx)
   12f1e:	88 45 fc             	mov    %al,-0x4(%ebp)
   12f21:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   12f25:	c9                   	leave  
   12f26:	c3                   	ret    

00012f27 <ck_pr_md_load_ptr>:
					: "m"  (*(const C *)target)	\
					: "memory");			\
		return (r);						\
	}

CK_PR_LOAD(ptr, void, void *, char, "movl")
   12f27:	55                   	push   %ebp
   12f28:	89 e5                	mov    %esp,%ebp
   12f2a:	83 ec 10             	sub    $0x10,%esp
   12f2d:	8b 45 08             	mov    0x8(%ebp),%eax
   12f30:	8b 00                	mov    (%eax),%eax
   12f32:	89 45 fc             	mov    %eax,-0x4(%ebp)
   12f35:	8b 45 fc             	mov    -0x4(%ebp),%eax
   12f38:	c9                   	leave  
   12f39:	c3                   	ret    

00012f3a <ck_pr_md_load_char>:

#define CK_PR_LOAD_S(S, T, I) CK_PR_LOAD(S, T, T, T, I)

CK_PR_LOAD_S(char, char, "movb")
   12f3a:	55                   	push   %ebp
   12f3b:	89 e5                	mov    %esp,%ebp
   12f3d:	83 ec 10             	sub    $0x10,%esp
   12f40:	8b 45 08             	mov    0x8(%ebp),%eax
   12f43:	8a 00                	mov    (%eax),%al
   12f45:	88 45 ff             	mov    %al,-0x1(%ebp)
   12f48:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   12f4c:	c9                   	leave  
   12f4d:	c3                   	ret    

00012f4e <ck_pr_md_load_uint>:
CK_PR_LOAD_S(uint, unsigned int, "movl")
   12f4e:	55                   	push   %ebp
   12f4f:	89 e5                	mov    %esp,%ebp
   12f51:	83 ec 10             	sub    $0x10,%esp
   12f54:	8b 45 08             	mov    0x8(%ebp),%eax
   12f57:	8b 00                	mov    (%eax),%eax
   12f59:	89 45 fc             	mov    %eax,-0x4(%ebp)
   12f5c:	8b 45 fc             	mov    -0x4(%ebp),%eax
   12f5f:	c9                   	leave  
   12f60:	c3                   	ret    

00012f61 <ck_pr_md_load_int>:
CK_PR_LOAD_S(int, int, "movl")
   12f61:	55                   	push   %ebp
   12f62:	89 e5                	mov    %esp,%ebp
   12f64:	83 ec 10             	sub    $0x10,%esp
   12f67:	8b 45 08             	mov    0x8(%ebp),%eax
   12f6a:	8b 00                	mov    (%eax),%eax
   12f6c:	89 45 fc             	mov    %eax,-0x4(%ebp)
   12f6f:	8b 45 fc             	mov    -0x4(%ebp),%eax
   12f72:	c9                   	leave  
   12f73:	c3                   	ret    

00012f74 <ck_pr_md_load_32>:
CK_PR_LOAD_S(32, uint32_t, "movl")
   12f74:	55                   	push   %ebp
   12f75:	89 e5                	mov    %esp,%ebp
   12f77:	83 ec 10             	sub    $0x10,%esp
   12f7a:	8b 45 08             	mov    0x8(%ebp),%eax
   12f7d:	8b 00                	mov    (%eax),%eax
   12f7f:	89 45 fc             	mov    %eax,-0x4(%ebp)
   12f82:	8b 45 fc             	mov    -0x4(%ebp),%eax
   12f85:	c9                   	leave  
   12f86:	c3                   	ret    

00012f87 <ck_pr_md_load_16>:
CK_PR_LOAD_S(16, uint16_t, "movw")
   12f87:	55                   	push   %ebp
   12f88:	89 e5                	mov    %esp,%ebp
   12f8a:	83 ec 10             	sub    $0x10,%esp
   12f8d:	8b 45 08             	mov    0x8(%ebp),%eax
   12f90:	66 8b 00             	mov    (%eax),%ax
   12f93:	66 89 45 fe          	mov    %ax,-0x2(%ebp)
   12f97:	0f b7 45 fe          	movzwl -0x2(%ebp),%eax
   12f9b:	c9                   	leave  
   12f9c:	c3                   	ret    

00012f9d <ck_pr_md_load_8>:
CK_PR_LOAD_S(8,  uint8_t,  "movb")
   12f9d:	55                   	push   %ebp
   12f9e:	89 e5                	mov    %esp,%ebp
   12fa0:	83 ec 10             	sub    $0x10,%esp
   12fa3:	8b 45 08             	mov    0x8(%ebp),%eax
   12fa6:	8a 00                	mov    (%eax),%al
   12fa8:	88 45 ff             	mov    %al,-0x1(%ebp)
   12fab:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   12faf:	c9                   	leave  
   12fb0:	c3                   	ret    

00012fb1 <ck_pr_md_store_ptr>:
					: CK_CC_IMM "q" (v)	\
					: "memory");		\
		return;						\
	}

CK_PR_STORE(ptr, void, const void *, char, "movl")
   12fb1:	55                   	push   %ebp
   12fb2:	89 e5                	mov    %esp,%ebp
   12fb4:	8b 45 08             	mov    0x8(%ebp),%eax
   12fb7:	8b 55 0c             	mov    0xc(%ebp),%edx
   12fba:	89 10                	mov    %edx,(%eax)
   12fbc:	90                   	nop
   12fbd:	5d                   	pop    %ebp
   12fbe:	c3                   	ret    

00012fbf <ck_pr_md_store_char>:

#define CK_PR_STORE_S(S, T, I) CK_PR_STORE(S, T, T, T, I)

CK_PR_STORE_S(char, char, "movb")
   12fbf:	55                   	push   %ebp
   12fc0:	89 e5                	mov    %esp,%ebp
   12fc2:	83 ec 04             	sub    $0x4,%esp
   12fc5:	8b 45 0c             	mov    0xc(%ebp),%eax
   12fc8:	88 45 fc             	mov    %al,-0x4(%ebp)
   12fcb:	8b 45 08             	mov    0x8(%ebp),%eax
   12fce:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   12fd2:	88 10                	mov    %dl,(%eax)
   12fd4:	90                   	nop
   12fd5:	c9                   	leave  
   12fd6:	c3                   	ret    

00012fd7 <ck_pr_md_store_uint>:
CK_PR_STORE_S(uint, unsigned int, "movl")
   12fd7:	55                   	push   %ebp
   12fd8:	89 e5                	mov    %esp,%ebp
   12fda:	8b 45 08             	mov    0x8(%ebp),%eax
   12fdd:	8b 55 0c             	mov    0xc(%ebp),%edx
   12fe0:	89 10                	mov    %edx,(%eax)
   12fe2:	90                   	nop
   12fe3:	5d                   	pop    %ebp
   12fe4:	c3                   	ret    

00012fe5 <ck_pr_md_store_int>:
CK_PR_STORE_S(int, int, "movl")
   12fe5:	55                   	push   %ebp
   12fe6:	89 e5                	mov    %esp,%ebp
   12fe8:	8b 45 08             	mov    0x8(%ebp),%eax
   12feb:	8b 55 0c             	mov    0xc(%ebp),%edx
   12fee:	89 10                	mov    %edx,(%eax)
   12ff0:	90                   	nop
   12ff1:	5d                   	pop    %ebp
   12ff2:	c3                   	ret    

00012ff3 <ck_pr_md_store_32>:
CK_PR_STORE_S(32, uint32_t, "movl")
   12ff3:	55                   	push   %ebp
   12ff4:	89 e5                	mov    %esp,%ebp
   12ff6:	8b 45 08             	mov    0x8(%ebp),%eax
   12ff9:	8b 55 0c             	mov    0xc(%ebp),%edx
   12ffc:	89 10                	mov    %edx,(%eax)
   12ffe:	90                   	nop
   12fff:	5d                   	pop    %ebp
   13000:	c3                   	ret    

00013001 <ck_pr_md_store_16>:
CK_PR_STORE_S(16, uint16_t, "movw")
   13001:	55                   	push   %ebp
   13002:	89 e5                	mov    %esp,%ebp
   13004:	83 ec 04             	sub    $0x4,%esp
   13007:	8b 45 0c             	mov    0xc(%ebp),%eax
   1300a:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1300e:	8b 45 08             	mov    0x8(%ebp),%eax
   13011:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   13015:	66 89 10             	mov    %dx,(%eax)
   13018:	90                   	nop
   13019:	c9                   	leave  
   1301a:	c3                   	ret    

0001301b <ck_pr_md_store_8>:
CK_PR_STORE_S(8,  uint8_t, "movb")
   1301b:	55                   	push   %ebp
   1301c:	89 e5                	mov    %esp,%ebp
   1301e:	83 ec 04             	sub    $0x4,%esp
   13021:	8b 45 0c             	mov    0xc(%ebp),%eax
   13024:	88 45 fc             	mov    %al,-0x4(%ebp)
   13027:	8b 45 08             	mov    0x8(%ebp),%eax
   1302a:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1302e:	88 10                	mov    %dl,(%eax)
   13030:	90                   	nop
   13031:	c9                   	leave  
   13032:	c3                   	ret    

00013033 <ck_pr_faa_ptr>:
					:				\
					: "memory", "cc");		\
		return (d);						\
	}

CK_PR_FAA(ptr, void, uintptr_t, char, "xaddl")
   13033:	55                   	push   %ebp
   13034:	89 e5                	mov    %esp,%ebp
   13036:	8b 55 08             	mov    0x8(%ebp),%edx
   13039:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1303c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1303f:	f0 0f c1 02          	lock xadd %eax,(%edx)
   13043:	89 45 0c             	mov    %eax,0xc(%ebp)
   13046:	8b 45 0c             	mov    0xc(%ebp),%eax
   13049:	5d                   	pop    %ebp
   1304a:	c3                   	ret    

0001304b <ck_pr_faa_char>:

#define CK_PR_FAA_S(S, T, I) CK_PR_FAA(S, T, T, T, I)

CK_PR_FAA_S(char, char, "xaddb")
   1304b:	55                   	push   %ebp
   1304c:	89 e5                	mov    %esp,%ebp
   1304e:	83 ec 04             	sub    $0x4,%esp
   13051:	8b 45 0c             	mov    0xc(%ebp),%eax
   13054:	88 45 fc             	mov    %al,-0x4(%ebp)
   13057:	8b 55 08             	mov    0x8(%ebp),%edx
   1305a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1305d:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   13061:	f0 0f c0 02          	lock xadd %al,(%edx)
   13065:	88 45 fc             	mov    %al,-0x4(%ebp)
   13068:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1306c:	c9                   	leave  
   1306d:	c3                   	ret    

0001306e <ck_pr_faa_uint>:
CK_PR_FAA_S(uint, unsigned int, "xaddl")
   1306e:	55                   	push   %ebp
   1306f:	89 e5                	mov    %esp,%ebp
   13071:	8b 55 08             	mov    0x8(%ebp),%edx
   13074:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13077:	8b 45 0c             	mov    0xc(%ebp),%eax
   1307a:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1307e:	89 45 0c             	mov    %eax,0xc(%ebp)
   13081:	8b 45 0c             	mov    0xc(%ebp),%eax
   13084:	5d                   	pop    %ebp
   13085:	c3                   	ret    

00013086 <ck_pr_faa_int>:
CK_PR_FAA_S(int, int, "xaddl")
   13086:	55                   	push   %ebp
   13087:	89 e5                	mov    %esp,%ebp
   13089:	8b 55 08             	mov    0x8(%ebp),%edx
   1308c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1308f:	8b 45 0c             	mov    0xc(%ebp),%eax
   13092:	f0 0f c1 02          	lock xadd %eax,(%edx)
   13096:	89 45 0c             	mov    %eax,0xc(%ebp)
   13099:	8b 45 0c             	mov    0xc(%ebp),%eax
   1309c:	5d                   	pop    %ebp
   1309d:	c3                   	ret    

0001309e <ck_pr_faa_32>:
CK_PR_FAA_S(32, uint32_t, "xaddl")
   1309e:	55                   	push   %ebp
   1309f:	89 e5                	mov    %esp,%ebp
   130a1:	8b 55 08             	mov    0x8(%ebp),%edx
   130a4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   130a7:	8b 45 0c             	mov    0xc(%ebp),%eax
   130aa:	f0 0f c1 02          	lock xadd %eax,(%edx)
   130ae:	89 45 0c             	mov    %eax,0xc(%ebp)
   130b1:	8b 45 0c             	mov    0xc(%ebp),%eax
   130b4:	5d                   	pop    %ebp
   130b5:	c3                   	ret    

000130b6 <ck_pr_faa_16>:
CK_PR_FAA_S(16, uint16_t, "xaddw")
   130b6:	55                   	push   %ebp
   130b7:	89 e5                	mov    %esp,%ebp
   130b9:	83 ec 04             	sub    $0x4,%esp
   130bc:	8b 45 0c             	mov    0xc(%ebp),%eax
   130bf:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   130c3:	8b 55 08             	mov    0x8(%ebp),%edx
   130c6:	8b 4d 08             	mov    0x8(%ebp),%ecx
   130c9:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   130cd:	66 f0 0f c1 02       	lock xadd %ax,(%edx)
   130d2:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   130d6:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   130da:	c9                   	leave  
   130db:	c3                   	ret    

000130dc <ck_pr_faa_8>:
CK_PR_FAA_S(8,  uint8_t,  "xaddb")
   130dc:	55                   	push   %ebp
   130dd:	89 e5                	mov    %esp,%ebp
   130df:	83 ec 04             	sub    $0x4,%esp
   130e2:	8b 45 0c             	mov    0xc(%ebp),%eax
   130e5:	88 45 fc             	mov    %al,-0x4(%ebp)
   130e8:	8b 55 08             	mov    0x8(%ebp),%edx
   130eb:	8b 4d 08             	mov    0x8(%ebp),%ecx
   130ee:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   130f2:	f0 0f c0 02          	lock xadd %al,(%edx)
   130f6:	88 45 fc             	mov    %al,-0x4(%ebp)
   130f9:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   130fd:	c9                   	leave  
   130fe:	c3                   	ret    

000130ff <ck_pr_inc_ptr>:
	CK_PR_UNARY_S(K, uint, unsigned int, #K "l")	\
	CK_PR_UNARY_S(K, 32, uint32_t, #K "l")		\
	CK_PR_UNARY_S(K, 16, uint16_t, #K "w")		\
	CK_PR_UNARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(inc)
   130ff:	55                   	push   %ebp
   13100:	89 e5                	mov    %esp,%ebp
   13102:	8b 45 08             	mov    0x8(%ebp),%eax
   13105:	8b 55 08             	mov    0x8(%ebp),%edx
   13108:	f0 ff 00             	lock incl (%eax)
   1310b:	90                   	nop
   1310c:	5d                   	pop    %ebp
   1310d:	c3                   	ret    

0001310e <ck_pr_inc_ptr_zero>:
   1310e:	55                   	push   %ebp
   1310f:	89 e5                	mov    %esp,%ebp
   13111:	8b 45 08             	mov    0x8(%ebp),%eax
   13114:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   13117:	8b 55 08             	mov    0x8(%ebp),%edx
   1311a:	f0 ff 00             	lock incl (%eax)
   1311d:	0f 94 01             	sete   (%ecx)
   13120:	90                   	nop
   13121:	5d                   	pop    %ebp
   13122:	c3                   	ret    

00013123 <ck_pr_inc_char>:
   13123:	55                   	push   %ebp
   13124:	89 e5                	mov    %esp,%ebp
   13126:	8b 45 08             	mov    0x8(%ebp),%eax
   13129:	8b 55 08             	mov    0x8(%ebp),%edx
   1312c:	f0 fe 00             	lock incb (%eax)
   1312f:	90                   	nop
   13130:	5d                   	pop    %ebp
   13131:	c3                   	ret    

00013132 <ck_pr_inc_char_zero>:
   13132:	55                   	push   %ebp
   13133:	89 e5                	mov    %esp,%ebp
   13135:	8b 45 08             	mov    0x8(%ebp),%eax
   13138:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1313b:	8b 55 08             	mov    0x8(%ebp),%edx
   1313e:	f0 fe 00             	lock incb (%eax)
   13141:	0f 94 01             	sete   (%ecx)
   13144:	90                   	nop
   13145:	5d                   	pop    %ebp
   13146:	c3                   	ret    

00013147 <ck_pr_inc_int>:
   13147:	55                   	push   %ebp
   13148:	89 e5                	mov    %esp,%ebp
   1314a:	8b 45 08             	mov    0x8(%ebp),%eax
   1314d:	8b 55 08             	mov    0x8(%ebp),%edx
   13150:	f0 ff 00             	lock incl (%eax)
   13153:	90                   	nop
   13154:	5d                   	pop    %ebp
   13155:	c3                   	ret    

00013156 <ck_pr_inc_int_zero>:
   13156:	55                   	push   %ebp
   13157:	89 e5                	mov    %esp,%ebp
   13159:	8b 45 08             	mov    0x8(%ebp),%eax
   1315c:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1315f:	8b 55 08             	mov    0x8(%ebp),%edx
   13162:	f0 ff 00             	lock incl (%eax)
   13165:	0f 94 01             	sete   (%ecx)
   13168:	90                   	nop
   13169:	5d                   	pop    %ebp
   1316a:	c3                   	ret    

0001316b <ck_pr_inc_uint>:
   1316b:	55                   	push   %ebp
   1316c:	89 e5                	mov    %esp,%ebp
   1316e:	8b 45 08             	mov    0x8(%ebp),%eax
   13171:	8b 55 08             	mov    0x8(%ebp),%edx
   13174:	f0 ff 00             	lock incl (%eax)
   13177:	90                   	nop
   13178:	5d                   	pop    %ebp
   13179:	c3                   	ret    

0001317a <ck_pr_inc_uint_zero>:
   1317a:	55                   	push   %ebp
   1317b:	89 e5                	mov    %esp,%ebp
   1317d:	8b 45 08             	mov    0x8(%ebp),%eax
   13180:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   13183:	8b 55 08             	mov    0x8(%ebp),%edx
   13186:	f0 ff 00             	lock incl (%eax)
   13189:	0f 94 01             	sete   (%ecx)
   1318c:	90                   	nop
   1318d:	5d                   	pop    %ebp
   1318e:	c3                   	ret    

0001318f <ck_pr_inc_32>:
   1318f:	55                   	push   %ebp
   13190:	89 e5                	mov    %esp,%ebp
   13192:	8b 45 08             	mov    0x8(%ebp),%eax
   13195:	8b 55 08             	mov    0x8(%ebp),%edx
   13198:	f0 ff 00             	lock incl (%eax)
   1319b:	90                   	nop
   1319c:	5d                   	pop    %ebp
   1319d:	c3                   	ret    

0001319e <ck_pr_inc_32_zero>:
   1319e:	55                   	push   %ebp
   1319f:	89 e5                	mov    %esp,%ebp
   131a1:	8b 45 08             	mov    0x8(%ebp),%eax
   131a4:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   131a7:	8b 55 08             	mov    0x8(%ebp),%edx
   131aa:	f0 ff 00             	lock incl (%eax)
   131ad:	0f 94 01             	sete   (%ecx)
   131b0:	90                   	nop
   131b1:	5d                   	pop    %ebp
   131b2:	c3                   	ret    

000131b3 <ck_pr_inc_16>:
   131b3:	55                   	push   %ebp
   131b4:	89 e5                	mov    %esp,%ebp
   131b6:	8b 45 08             	mov    0x8(%ebp),%eax
   131b9:	8b 55 08             	mov    0x8(%ebp),%edx
   131bc:	66 f0 ff 00          	lock incw (%eax)
   131c0:	90                   	nop
   131c1:	5d                   	pop    %ebp
   131c2:	c3                   	ret    

000131c3 <ck_pr_inc_16_zero>:
   131c3:	55                   	push   %ebp
   131c4:	89 e5                	mov    %esp,%ebp
   131c6:	8b 45 08             	mov    0x8(%ebp),%eax
   131c9:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   131cc:	8b 55 08             	mov    0x8(%ebp),%edx
   131cf:	66 f0 ff 00          	lock incw (%eax)
   131d3:	0f 94 01             	sete   (%ecx)
   131d6:	90                   	nop
   131d7:	5d                   	pop    %ebp
   131d8:	c3                   	ret    

000131d9 <ck_pr_inc_8>:
   131d9:	55                   	push   %ebp
   131da:	89 e5                	mov    %esp,%ebp
   131dc:	8b 45 08             	mov    0x8(%ebp),%eax
   131df:	8b 55 08             	mov    0x8(%ebp),%edx
   131e2:	f0 fe 00             	lock incb (%eax)
   131e5:	90                   	nop
   131e6:	5d                   	pop    %ebp
   131e7:	c3                   	ret    

000131e8 <ck_pr_inc_8_zero>:
   131e8:	55                   	push   %ebp
   131e9:	89 e5                	mov    %esp,%ebp
   131eb:	8b 45 08             	mov    0x8(%ebp),%eax
   131ee:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   131f1:	8b 55 08             	mov    0x8(%ebp),%edx
   131f4:	f0 fe 00             	lock incb (%eax)
   131f7:	0f 94 01             	sete   (%ecx)
   131fa:	90                   	nop
   131fb:	5d                   	pop    %ebp
   131fc:	c3                   	ret    

000131fd <ck_pr_dec_ptr>:
CK_PR_GENERATE(dec)
   131fd:	55                   	push   %ebp
   131fe:	89 e5                	mov    %esp,%ebp
   13200:	8b 45 08             	mov    0x8(%ebp),%eax
   13203:	8b 55 08             	mov    0x8(%ebp),%edx
   13206:	f0 ff 08             	lock decl (%eax)
   13209:	90                   	nop
   1320a:	5d                   	pop    %ebp
   1320b:	c3                   	ret    

0001320c <ck_pr_dec_ptr_zero>:
   1320c:	55                   	push   %ebp
   1320d:	89 e5                	mov    %esp,%ebp
   1320f:	8b 45 08             	mov    0x8(%ebp),%eax
   13212:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   13215:	8b 55 08             	mov    0x8(%ebp),%edx
   13218:	f0 ff 08             	lock decl (%eax)
   1321b:	0f 94 01             	sete   (%ecx)
   1321e:	90                   	nop
   1321f:	5d                   	pop    %ebp
   13220:	c3                   	ret    

00013221 <ck_pr_dec_char>:
   13221:	55                   	push   %ebp
   13222:	89 e5                	mov    %esp,%ebp
   13224:	8b 45 08             	mov    0x8(%ebp),%eax
   13227:	8b 55 08             	mov    0x8(%ebp),%edx
   1322a:	f0 fe 08             	lock decb (%eax)
   1322d:	90                   	nop
   1322e:	5d                   	pop    %ebp
   1322f:	c3                   	ret    

00013230 <ck_pr_dec_char_zero>:
   13230:	55                   	push   %ebp
   13231:	89 e5                	mov    %esp,%ebp
   13233:	8b 45 08             	mov    0x8(%ebp),%eax
   13236:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   13239:	8b 55 08             	mov    0x8(%ebp),%edx
   1323c:	f0 fe 08             	lock decb (%eax)
   1323f:	0f 94 01             	sete   (%ecx)
   13242:	90                   	nop
   13243:	5d                   	pop    %ebp
   13244:	c3                   	ret    

00013245 <ck_pr_dec_int>:
   13245:	55                   	push   %ebp
   13246:	89 e5                	mov    %esp,%ebp
   13248:	8b 45 08             	mov    0x8(%ebp),%eax
   1324b:	8b 55 08             	mov    0x8(%ebp),%edx
   1324e:	f0 ff 08             	lock decl (%eax)
   13251:	90                   	nop
   13252:	5d                   	pop    %ebp
   13253:	c3                   	ret    

00013254 <ck_pr_dec_int_zero>:
   13254:	55                   	push   %ebp
   13255:	89 e5                	mov    %esp,%ebp
   13257:	8b 45 08             	mov    0x8(%ebp),%eax
   1325a:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1325d:	8b 55 08             	mov    0x8(%ebp),%edx
   13260:	f0 ff 08             	lock decl (%eax)
   13263:	0f 94 01             	sete   (%ecx)
   13266:	90                   	nop
   13267:	5d                   	pop    %ebp
   13268:	c3                   	ret    

00013269 <ck_pr_dec_uint>:
   13269:	55                   	push   %ebp
   1326a:	89 e5                	mov    %esp,%ebp
   1326c:	8b 45 08             	mov    0x8(%ebp),%eax
   1326f:	8b 55 08             	mov    0x8(%ebp),%edx
   13272:	f0 ff 08             	lock decl (%eax)
   13275:	90                   	nop
   13276:	5d                   	pop    %ebp
   13277:	c3                   	ret    

00013278 <ck_pr_dec_uint_zero>:
   13278:	55                   	push   %ebp
   13279:	89 e5                	mov    %esp,%ebp
   1327b:	8b 45 08             	mov    0x8(%ebp),%eax
   1327e:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   13281:	8b 55 08             	mov    0x8(%ebp),%edx
   13284:	f0 ff 08             	lock decl (%eax)
   13287:	0f 94 01             	sete   (%ecx)
   1328a:	90                   	nop
   1328b:	5d                   	pop    %ebp
   1328c:	c3                   	ret    

0001328d <ck_pr_dec_32>:
   1328d:	55                   	push   %ebp
   1328e:	89 e5                	mov    %esp,%ebp
   13290:	8b 45 08             	mov    0x8(%ebp),%eax
   13293:	8b 55 08             	mov    0x8(%ebp),%edx
   13296:	f0 ff 08             	lock decl (%eax)
   13299:	90                   	nop
   1329a:	5d                   	pop    %ebp
   1329b:	c3                   	ret    

0001329c <ck_pr_dec_32_zero>:
   1329c:	55                   	push   %ebp
   1329d:	89 e5                	mov    %esp,%ebp
   1329f:	8b 45 08             	mov    0x8(%ebp),%eax
   132a2:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   132a5:	8b 55 08             	mov    0x8(%ebp),%edx
   132a8:	f0 ff 08             	lock decl (%eax)
   132ab:	0f 94 01             	sete   (%ecx)
   132ae:	90                   	nop
   132af:	5d                   	pop    %ebp
   132b0:	c3                   	ret    

000132b1 <ck_pr_dec_16>:
   132b1:	55                   	push   %ebp
   132b2:	89 e5                	mov    %esp,%ebp
   132b4:	8b 45 08             	mov    0x8(%ebp),%eax
   132b7:	8b 55 08             	mov    0x8(%ebp),%edx
   132ba:	66 f0 ff 08          	lock decw (%eax)
   132be:	90                   	nop
   132bf:	5d                   	pop    %ebp
   132c0:	c3                   	ret    

000132c1 <ck_pr_dec_16_zero>:
   132c1:	55                   	push   %ebp
   132c2:	89 e5                	mov    %esp,%ebp
   132c4:	8b 45 08             	mov    0x8(%ebp),%eax
   132c7:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   132ca:	8b 55 08             	mov    0x8(%ebp),%edx
   132cd:	66 f0 ff 08          	lock decw (%eax)
   132d1:	0f 94 01             	sete   (%ecx)
   132d4:	90                   	nop
   132d5:	5d                   	pop    %ebp
   132d6:	c3                   	ret    

000132d7 <ck_pr_dec_8>:
   132d7:	55                   	push   %ebp
   132d8:	89 e5                	mov    %esp,%ebp
   132da:	8b 45 08             	mov    0x8(%ebp),%eax
   132dd:	8b 55 08             	mov    0x8(%ebp),%edx
   132e0:	f0 fe 08             	lock decb (%eax)
   132e3:	90                   	nop
   132e4:	5d                   	pop    %ebp
   132e5:	c3                   	ret    

000132e6 <ck_pr_dec_8_zero>:
   132e6:	55                   	push   %ebp
   132e7:	89 e5                	mov    %esp,%ebp
   132e9:	8b 45 08             	mov    0x8(%ebp),%eax
   132ec:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   132ef:	8b 55 08             	mov    0x8(%ebp),%edx
   132f2:	f0 fe 08             	lock decb (%eax)
   132f5:	0f 94 01             	sete   (%ecx)
   132f8:	90                   	nop
   132f9:	5d                   	pop    %ebp
   132fa:	c3                   	ret    

000132fb <ck_pr_neg_ptr>:
CK_PR_GENERATE(neg)
   132fb:	55                   	push   %ebp
   132fc:	89 e5                	mov    %esp,%ebp
   132fe:	8b 45 08             	mov    0x8(%ebp),%eax
   13301:	8b 55 08             	mov    0x8(%ebp),%edx
   13304:	f0 f7 18             	lock negl (%eax)
   13307:	90                   	nop
   13308:	5d                   	pop    %ebp
   13309:	c3                   	ret    

0001330a <ck_pr_neg_ptr_zero>:
   1330a:	55                   	push   %ebp
   1330b:	89 e5                	mov    %esp,%ebp
   1330d:	8b 45 08             	mov    0x8(%ebp),%eax
   13310:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   13313:	8b 55 08             	mov    0x8(%ebp),%edx
   13316:	f0 f7 18             	lock negl (%eax)
   13319:	0f 94 01             	sete   (%ecx)
   1331c:	90                   	nop
   1331d:	5d                   	pop    %ebp
   1331e:	c3                   	ret    

0001331f <ck_pr_neg_char>:
   1331f:	55                   	push   %ebp
   13320:	89 e5                	mov    %esp,%ebp
   13322:	8b 45 08             	mov    0x8(%ebp),%eax
   13325:	8b 55 08             	mov    0x8(%ebp),%edx
   13328:	f0 f6 18             	lock negb (%eax)
   1332b:	90                   	nop
   1332c:	5d                   	pop    %ebp
   1332d:	c3                   	ret    

0001332e <ck_pr_neg_char_zero>:
   1332e:	55                   	push   %ebp
   1332f:	89 e5                	mov    %esp,%ebp
   13331:	8b 45 08             	mov    0x8(%ebp),%eax
   13334:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   13337:	8b 55 08             	mov    0x8(%ebp),%edx
   1333a:	f0 f6 18             	lock negb (%eax)
   1333d:	0f 94 01             	sete   (%ecx)
   13340:	90                   	nop
   13341:	5d                   	pop    %ebp
   13342:	c3                   	ret    

00013343 <ck_pr_neg_int>:
   13343:	55                   	push   %ebp
   13344:	89 e5                	mov    %esp,%ebp
   13346:	8b 45 08             	mov    0x8(%ebp),%eax
   13349:	8b 55 08             	mov    0x8(%ebp),%edx
   1334c:	f0 f7 18             	lock negl (%eax)
   1334f:	90                   	nop
   13350:	5d                   	pop    %ebp
   13351:	c3                   	ret    

00013352 <ck_pr_neg_int_zero>:
   13352:	55                   	push   %ebp
   13353:	89 e5                	mov    %esp,%ebp
   13355:	8b 45 08             	mov    0x8(%ebp),%eax
   13358:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1335b:	8b 55 08             	mov    0x8(%ebp),%edx
   1335e:	f0 f7 18             	lock negl (%eax)
   13361:	0f 94 01             	sete   (%ecx)
   13364:	90                   	nop
   13365:	5d                   	pop    %ebp
   13366:	c3                   	ret    

00013367 <ck_pr_neg_uint>:
   13367:	55                   	push   %ebp
   13368:	89 e5                	mov    %esp,%ebp
   1336a:	8b 45 08             	mov    0x8(%ebp),%eax
   1336d:	8b 55 08             	mov    0x8(%ebp),%edx
   13370:	f0 f7 18             	lock negl (%eax)
   13373:	90                   	nop
   13374:	5d                   	pop    %ebp
   13375:	c3                   	ret    

00013376 <ck_pr_neg_uint_zero>:
   13376:	55                   	push   %ebp
   13377:	89 e5                	mov    %esp,%ebp
   13379:	8b 45 08             	mov    0x8(%ebp),%eax
   1337c:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1337f:	8b 55 08             	mov    0x8(%ebp),%edx
   13382:	f0 f7 18             	lock negl (%eax)
   13385:	0f 94 01             	sete   (%ecx)
   13388:	90                   	nop
   13389:	5d                   	pop    %ebp
   1338a:	c3                   	ret    

0001338b <ck_pr_neg_32>:
   1338b:	55                   	push   %ebp
   1338c:	89 e5                	mov    %esp,%ebp
   1338e:	8b 45 08             	mov    0x8(%ebp),%eax
   13391:	8b 55 08             	mov    0x8(%ebp),%edx
   13394:	f0 f7 18             	lock negl (%eax)
   13397:	90                   	nop
   13398:	5d                   	pop    %ebp
   13399:	c3                   	ret    

0001339a <ck_pr_neg_32_zero>:
   1339a:	55                   	push   %ebp
   1339b:	89 e5                	mov    %esp,%ebp
   1339d:	8b 45 08             	mov    0x8(%ebp),%eax
   133a0:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   133a3:	8b 55 08             	mov    0x8(%ebp),%edx
   133a6:	f0 f7 18             	lock negl (%eax)
   133a9:	0f 94 01             	sete   (%ecx)
   133ac:	90                   	nop
   133ad:	5d                   	pop    %ebp
   133ae:	c3                   	ret    

000133af <ck_pr_neg_16>:
   133af:	55                   	push   %ebp
   133b0:	89 e5                	mov    %esp,%ebp
   133b2:	8b 45 08             	mov    0x8(%ebp),%eax
   133b5:	8b 55 08             	mov    0x8(%ebp),%edx
   133b8:	66 f0 f7 18          	lock negw (%eax)
   133bc:	90                   	nop
   133bd:	5d                   	pop    %ebp
   133be:	c3                   	ret    

000133bf <ck_pr_neg_16_zero>:
   133bf:	55                   	push   %ebp
   133c0:	89 e5                	mov    %esp,%ebp
   133c2:	8b 45 08             	mov    0x8(%ebp),%eax
   133c5:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   133c8:	8b 55 08             	mov    0x8(%ebp),%edx
   133cb:	66 f0 f7 18          	lock negw (%eax)
   133cf:	0f 94 01             	sete   (%ecx)
   133d2:	90                   	nop
   133d3:	5d                   	pop    %ebp
   133d4:	c3                   	ret    

000133d5 <ck_pr_neg_8>:
   133d5:	55                   	push   %ebp
   133d6:	89 e5                	mov    %esp,%ebp
   133d8:	8b 45 08             	mov    0x8(%ebp),%eax
   133db:	8b 55 08             	mov    0x8(%ebp),%edx
   133de:	f0 f6 18             	lock negb (%eax)
   133e1:	90                   	nop
   133e2:	5d                   	pop    %ebp
   133e3:	c3                   	ret    

000133e4 <ck_pr_neg_8_zero>:
   133e4:	55                   	push   %ebp
   133e5:	89 e5                	mov    %esp,%ebp
   133e7:	8b 45 08             	mov    0x8(%ebp),%eax
   133ea:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   133ed:	8b 55 08             	mov    0x8(%ebp),%edx
   133f0:	f0 f6 18             	lock negb (%eax)
   133f3:	0f 94 01             	sete   (%ecx)
   133f6:	90                   	nop
   133f7:	5d                   	pop    %ebp
   133f8:	c3                   	ret    

000133f9 <ck_pr_not_ptr>:

/* not does not affect condition flags. */
#undef CK_PR_UNARY_V
#define CK_PR_UNARY_V(a, b, c, d, e)
CK_PR_GENERATE(not)
   133f9:	55                   	push   %ebp
   133fa:	89 e5                	mov    %esp,%ebp
   133fc:	8b 45 08             	mov    0x8(%ebp),%eax
   133ff:	8b 55 08             	mov    0x8(%ebp),%edx
   13402:	f0 f7 10             	lock notl (%eax)
   13405:	90                   	nop
   13406:	5d                   	pop    %ebp
   13407:	c3                   	ret    

00013408 <ck_pr_not_char>:
   13408:	55                   	push   %ebp
   13409:	89 e5                	mov    %esp,%ebp
   1340b:	8b 45 08             	mov    0x8(%ebp),%eax
   1340e:	8b 55 08             	mov    0x8(%ebp),%edx
   13411:	f0 f6 10             	lock notb (%eax)
   13414:	90                   	nop
   13415:	5d                   	pop    %ebp
   13416:	c3                   	ret    

00013417 <ck_pr_not_int>:
   13417:	55                   	push   %ebp
   13418:	89 e5                	mov    %esp,%ebp
   1341a:	8b 45 08             	mov    0x8(%ebp),%eax
   1341d:	8b 55 08             	mov    0x8(%ebp),%edx
   13420:	f0 f7 10             	lock notl (%eax)
   13423:	90                   	nop
   13424:	5d                   	pop    %ebp
   13425:	c3                   	ret    

00013426 <ck_pr_not_uint>:
   13426:	55                   	push   %ebp
   13427:	89 e5                	mov    %esp,%ebp
   13429:	8b 45 08             	mov    0x8(%ebp),%eax
   1342c:	8b 55 08             	mov    0x8(%ebp),%edx
   1342f:	f0 f7 10             	lock notl (%eax)
   13432:	90                   	nop
   13433:	5d                   	pop    %ebp
   13434:	c3                   	ret    

00013435 <ck_pr_not_32>:
   13435:	55                   	push   %ebp
   13436:	89 e5                	mov    %esp,%ebp
   13438:	8b 45 08             	mov    0x8(%ebp),%eax
   1343b:	8b 55 08             	mov    0x8(%ebp),%edx
   1343e:	f0 f7 10             	lock notl (%eax)
   13441:	90                   	nop
   13442:	5d                   	pop    %ebp
   13443:	c3                   	ret    

00013444 <ck_pr_not_16>:
   13444:	55                   	push   %ebp
   13445:	89 e5                	mov    %esp,%ebp
   13447:	8b 45 08             	mov    0x8(%ebp),%eax
   1344a:	8b 55 08             	mov    0x8(%ebp),%edx
   1344d:	66 f0 f7 10          	lock notw (%eax)
   13451:	90                   	nop
   13452:	5d                   	pop    %ebp
   13453:	c3                   	ret    

00013454 <ck_pr_not_8>:
   13454:	55                   	push   %ebp
   13455:	89 e5                	mov    %esp,%ebp
   13457:	8b 45 08             	mov    0x8(%ebp),%eax
   1345a:	8b 55 08             	mov    0x8(%ebp),%edx
   1345d:	f0 f6 10             	lock notb (%eax)
   13460:	90                   	nop
   13461:	5d                   	pop    %ebp
   13462:	c3                   	ret    

00013463 <ck_pr_add_ptr>:
	CK_PR_BINARY_S(K, uint, unsigned int, #K "l")		\
	CK_PR_BINARY_S(K, 32, uint32_t, #K "l")			\
	CK_PR_BINARY_S(K, 16, uint16_t, #K "w")			\
	CK_PR_BINARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(add)
   13463:	55                   	push   %ebp
   13464:	89 e5                	mov    %esp,%ebp
   13466:	8b 45 08             	mov    0x8(%ebp),%eax
   13469:	8b 55 0c             	mov    0xc(%ebp),%edx
   1346c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1346f:	f0 01 10             	lock add %edx,(%eax)
   13472:	90                   	nop
   13473:	5d                   	pop    %ebp
   13474:	c3                   	ret    

00013475 <ck_pr_add_char>:
   13475:	55                   	push   %ebp
   13476:	89 e5                	mov    %esp,%ebp
   13478:	83 ec 04             	sub    $0x4,%esp
   1347b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1347e:	88 45 fc             	mov    %al,-0x4(%ebp)
   13481:	8b 45 08             	mov    0x8(%ebp),%eax
   13484:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   13488:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1348b:	f0 00 10             	lock add %dl,(%eax)
   1348e:	90                   	nop
   1348f:	c9                   	leave  
   13490:	c3                   	ret    

00013491 <ck_pr_add_int>:
   13491:	55                   	push   %ebp
   13492:	89 e5                	mov    %esp,%ebp
   13494:	8b 45 08             	mov    0x8(%ebp),%eax
   13497:	8b 55 0c             	mov    0xc(%ebp),%edx
   1349a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1349d:	f0 01 10             	lock add %edx,(%eax)
   134a0:	90                   	nop
   134a1:	5d                   	pop    %ebp
   134a2:	c3                   	ret    

000134a3 <ck_pr_add_uint>:
   134a3:	55                   	push   %ebp
   134a4:	89 e5                	mov    %esp,%ebp
   134a6:	8b 45 08             	mov    0x8(%ebp),%eax
   134a9:	8b 55 0c             	mov    0xc(%ebp),%edx
   134ac:	8b 4d 08             	mov    0x8(%ebp),%ecx
   134af:	f0 01 10             	lock add %edx,(%eax)
   134b2:	90                   	nop
   134b3:	5d                   	pop    %ebp
   134b4:	c3                   	ret    

000134b5 <ck_pr_add_32>:
   134b5:	55                   	push   %ebp
   134b6:	89 e5                	mov    %esp,%ebp
   134b8:	8b 45 08             	mov    0x8(%ebp),%eax
   134bb:	8b 55 0c             	mov    0xc(%ebp),%edx
   134be:	8b 4d 08             	mov    0x8(%ebp),%ecx
   134c1:	f0 01 10             	lock add %edx,(%eax)
   134c4:	90                   	nop
   134c5:	5d                   	pop    %ebp
   134c6:	c3                   	ret    

000134c7 <ck_pr_add_16>:
   134c7:	55                   	push   %ebp
   134c8:	89 e5                	mov    %esp,%ebp
   134ca:	83 ec 04             	sub    $0x4,%esp
   134cd:	8b 45 0c             	mov    0xc(%ebp),%eax
   134d0:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   134d4:	8b 45 08             	mov    0x8(%ebp),%eax
   134d7:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   134db:	8b 4d 08             	mov    0x8(%ebp),%ecx
   134de:	66 f0 01 10          	lock add %dx,(%eax)
   134e2:	90                   	nop
   134e3:	c9                   	leave  
   134e4:	c3                   	ret    

000134e5 <ck_pr_add_8>:
   134e5:	55                   	push   %ebp
   134e6:	89 e5                	mov    %esp,%ebp
   134e8:	83 ec 04             	sub    $0x4,%esp
   134eb:	8b 45 0c             	mov    0xc(%ebp),%eax
   134ee:	88 45 fc             	mov    %al,-0x4(%ebp)
   134f1:	8b 45 08             	mov    0x8(%ebp),%eax
   134f4:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   134f8:	8b 4d 08             	mov    0x8(%ebp),%ecx
   134fb:	f0 00 10             	lock add %dl,(%eax)
   134fe:	90                   	nop
   134ff:	c9                   	leave  
   13500:	c3                   	ret    

00013501 <ck_pr_sub_ptr>:
CK_PR_GENERATE(sub)
   13501:	55                   	push   %ebp
   13502:	89 e5                	mov    %esp,%ebp
   13504:	8b 45 08             	mov    0x8(%ebp),%eax
   13507:	8b 55 0c             	mov    0xc(%ebp),%edx
   1350a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1350d:	f0 29 10             	lock sub %edx,(%eax)
   13510:	90                   	nop
   13511:	5d                   	pop    %ebp
   13512:	c3                   	ret    

00013513 <ck_pr_sub_char>:
   13513:	55                   	push   %ebp
   13514:	89 e5                	mov    %esp,%ebp
   13516:	83 ec 04             	sub    $0x4,%esp
   13519:	8b 45 0c             	mov    0xc(%ebp),%eax
   1351c:	88 45 fc             	mov    %al,-0x4(%ebp)
   1351f:	8b 45 08             	mov    0x8(%ebp),%eax
   13522:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   13526:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13529:	f0 28 10             	lock sub %dl,(%eax)
   1352c:	90                   	nop
   1352d:	c9                   	leave  
   1352e:	c3                   	ret    

0001352f <ck_pr_sub_int>:
   1352f:	55                   	push   %ebp
   13530:	89 e5                	mov    %esp,%ebp
   13532:	8b 45 08             	mov    0x8(%ebp),%eax
   13535:	8b 55 0c             	mov    0xc(%ebp),%edx
   13538:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1353b:	f0 29 10             	lock sub %edx,(%eax)
   1353e:	90                   	nop
   1353f:	5d                   	pop    %ebp
   13540:	c3                   	ret    

00013541 <ck_pr_sub_uint>:
   13541:	55                   	push   %ebp
   13542:	89 e5                	mov    %esp,%ebp
   13544:	8b 45 08             	mov    0x8(%ebp),%eax
   13547:	8b 55 0c             	mov    0xc(%ebp),%edx
   1354a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1354d:	f0 29 10             	lock sub %edx,(%eax)
   13550:	90                   	nop
   13551:	5d                   	pop    %ebp
   13552:	c3                   	ret    

00013553 <ck_pr_sub_32>:
   13553:	55                   	push   %ebp
   13554:	89 e5                	mov    %esp,%ebp
   13556:	8b 45 08             	mov    0x8(%ebp),%eax
   13559:	8b 55 0c             	mov    0xc(%ebp),%edx
   1355c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1355f:	f0 29 10             	lock sub %edx,(%eax)
   13562:	90                   	nop
   13563:	5d                   	pop    %ebp
   13564:	c3                   	ret    

00013565 <ck_pr_sub_16>:
   13565:	55                   	push   %ebp
   13566:	89 e5                	mov    %esp,%ebp
   13568:	83 ec 04             	sub    $0x4,%esp
   1356b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1356e:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   13572:	8b 45 08             	mov    0x8(%ebp),%eax
   13575:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   13579:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1357c:	66 f0 29 10          	lock sub %dx,(%eax)
   13580:	90                   	nop
   13581:	c9                   	leave  
   13582:	c3                   	ret    

00013583 <ck_pr_sub_8>:
   13583:	55                   	push   %ebp
   13584:	89 e5                	mov    %esp,%ebp
   13586:	83 ec 04             	sub    $0x4,%esp
   13589:	8b 45 0c             	mov    0xc(%ebp),%eax
   1358c:	88 45 fc             	mov    %al,-0x4(%ebp)
   1358f:	8b 45 08             	mov    0x8(%ebp),%eax
   13592:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   13596:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13599:	f0 28 10             	lock sub %dl,(%eax)
   1359c:	90                   	nop
   1359d:	c9                   	leave  
   1359e:	c3                   	ret    

0001359f <ck_pr_and_ptr>:
CK_PR_GENERATE(and)
   1359f:	55                   	push   %ebp
   135a0:	89 e5                	mov    %esp,%ebp
   135a2:	8b 45 08             	mov    0x8(%ebp),%eax
   135a5:	8b 55 0c             	mov    0xc(%ebp),%edx
   135a8:	8b 4d 08             	mov    0x8(%ebp),%ecx
   135ab:	f0 21 10             	lock and %edx,(%eax)
   135ae:	90                   	nop
   135af:	5d                   	pop    %ebp
   135b0:	c3                   	ret    

000135b1 <ck_pr_and_char>:
   135b1:	55                   	push   %ebp
   135b2:	89 e5                	mov    %esp,%ebp
   135b4:	83 ec 04             	sub    $0x4,%esp
   135b7:	8b 45 0c             	mov    0xc(%ebp),%eax
   135ba:	88 45 fc             	mov    %al,-0x4(%ebp)
   135bd:	8b 45 08             	mov    0x8(%ebp),%eax
   135c0:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   135c4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   135c7:	f0 20 10             	lock and %dl,(%eax)
   135ca:	90                   	nop
   135cb:	c9                   	leave  
   135cc:	c3                   	ret    

000135cd <ck_pr_and_int>:
   135cd:	55                   	push   %ebp
   135ce:	89 e5                	mov    %esp,%ebp
   135d0:	8b 45 08             	mov    0x8(%ebp),%eax
   135d3:	8b 55 0c             	mov    0xc(%ebp),%edx
   135d6:	8b 4d 08             	mov    0x8(%ebp),%ecx
   135d9:	f0 21 10             	lock and %edx,(%eax)
   135dc:	90                   	nop
   135dd:	5d                   	pop    %ebp
   135de:	c3                   	ret    

000135df <ck_pr_and_uint>:
   135df:	55                   	push   %ebp
   135e0:	89 e5                	mov    %esp,%ebp
   135e2:	8b 45 08             	mov    0x8(%ebp),%eax
   135e5:	8b 55 0c             	mov    0xc(%ebp),%edx
   135e8:	8b 4d 08             	mov    0x8(%ebp),%ecx
   135eb:	f0 21 10             	lock and %edx,(%eax)
   135ee:	90                   	nop
   135ef:	5d                   	pop    %ebp
   135f0:	c3                   	ret    

000135f1 <ck_pr_and_32>:
   135f1:	55                   	push   %ebp
   135f2:	89 e5                	mov    %esp,%ebp
   135f4:	8b 45 08             	mov    0x8(%ebp),%eax
   135f7:	8b 55 0c             	mov    0xc(%ebp),%edx
   135fa:	8b 4d 08             	mov    0x8(%ebp),%ecx
   135fd:	f0 21 10             	lock and %edx,(%eax)
   13600:	90                   	nop
   13601:	5d                   	pop    %ebp
   13602:	c3                   	ret    

00013603 <ck_pr_and_16>:
   13603:	55                   	push   %ebp
   13604:	89 e5                	mov    %esp,%ebp
   13606:	83 ec 04             	sub    $0x4,%esp
   13609:	8b 45 0c             	mov    0xc(%ebp),%eax
   1360c:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   13610:	8b 45 08             	mov    0x8(%ebp),%eax
   13613:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   13617:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1361a:	66 f0 21 10          	lock and %dx,(%eax)
   1361e:	90                   	nop
   1361f:	c9                   	leave  
   13620:	c3                   	ret    

00013621 <ck_pr_and_8>:
   13621:	55                   	push   %ebp
   13622:	89 e5                	mov    %esp,%ebp
   13624:	83 ec 04             	sub    $0x4,%esp
   13627:	8b 45 0c             	mov    0xc(%ebp),%eax
   1362a:	88 45 fc             	mov    %al,-0x4(%ebp)
   1362d:	8b 45 08             	mov    0x8(%ebp),%eax
   13630:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   13634:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13637:	f0 20 10             	lock and %dl,(%eax)
   1363a:	90                   	nop
   1363b:	c9                   	leave  
   1363c:	c3                   	ret    

0001363d <ck_pr_or_ptr>:
CK_PR_GENERATE(or)
   1363d:	55                   	push   %ebp
   1363e:	89 e5                	mov    %esp,%ebp
   13640:	8b 45 08             	mov    0x8(%ebp),%eax
   13643:	8b 55 0c             	mov    0xc(%ebp),%edx
   13646:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13649:	f0 09 10             	lock or %edx,(%eax)
   1364c:	90                   	nop
   1364d:	5d                   	pop    %ebp
   1364e:	c3                   	ret    

0001364f <ck_pr_or_char>:
   1364f:	55                   	push   %ebp
   13650:	89 e5                	mov    %esp,%ebp
   13652:	83 ec 04             	sub    $0x4,%esp
   13655:	8b 45 0c             	mov    0xc(%ebp),%eax
   13658:	88 45 fc             	mov    %al,-0x4(%ebp)
   1365b:	8b 45 08             	mov    0x8(%ebp),%eax
   1365e:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   13662:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13665:	f0 08 10             	lock or %dl,(%eax)
   13668:	90                   	nop
   13669:	c9                   	leave  
   1366a:	c3                   	ret    

0001366b <ck_pr_or_int>:
   1366b:	55                   	push   %ebp
   1366c:	89 e5                	mov    %esp,%ebp
   1366e:	8b 45 08             	mov    0x8(%ebp),%eax
   13671:	8b 55 0c             	mov    0xc(%ebp),%edx
   13674:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13677:	f0 09 10             	lock or %edx,(%eax)
   1367a:	90                   	nop
   1367b:	5d                   	pop    %ebp
   1367c:	c3                   	ret    

0001367d <ck_pr_or_uint>:
   1367d:	55                   	push   %ebp
   1367e:	89 e5                	mov    %esp,%ebp
   13680:	8b 45 08             	mov    0x8(%ebp),%eax
   13683:	8b 55 0c             	mov    0xc(%ebp),%edx
   13686:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13689:	f0 09 10             	lock or %edx,(%eax)
   1368c:	90                   	nop
   1368d:	5d                   	pop    %ebp
   1368e:	c3                   	ret    

0001368f <ck_pr_or_32>:
   1368f:	55                   	push   %ebp
   13690:	89 e5                	mov    %esp,%ebp
   13692:	8b 45 08             	mov    0x8(%ebp),%eax
   13695:	8b 55 0c             	mov    0xc(%ebp),%edx
   13698:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1369b:	f0 09 10             	lock or %edx,(%eax)
   1369e:	90                   	nop
   1369f:	5d                   	pop    %ebp
   136a0:	c3                   	ret    

000136a1 <ck_pr_or_16>:
   136a1:	55                   	push   %ebp
   136a2:	89 e5                	mov    %esp,%ebp
   136a4:	83 ec 04             	sub    $0x4,%esp
   136a7:	8b 45 0c             	mov    0xc(%ebp),%eax
   136aa:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   136ae:	8b 45 08             	mov    0x8(%ebp),%eax
   136b1:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   136b5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   136b8:	66 f0 09 10          	lock or %dx,(%eax)
   136bc:	90                   	nop
   136bd:	c9                   	leave  
   136be:	c3                   	ret    

000136bf <ck_pr_or_8>:
   136bf:	55                   	push   %ebp
   136c0:	89 e5                	mov    %esp,%ebp
   136c2:	83 ec 04             	sub    $0x4,%esp
   136c5:	8b 45 0c             	mov    0xc(%ebp),%eax
   136c8:	88 45 fc             	mov    %al,-0x4(%ebp)
   136cb:	8b 45 08             	mov    0x8(%ebp),%eax
   136ce:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   136d2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   136d5:	f0 08 10             	lock or %dl,(%eax)
   136d8:	90                   	nop
   136d9:	c9                   	leave  
   136da:	c3                   	ret    

000136db <ck_pr_xor_ptr>:
CK_PR_GENERATE(xor)
   136db:	55                   	push   %ebp
   136dc:	89 e5                	mov    %esp,%ebp
   136de:	8b 45 08             	mov    0x8(%ebp),%eax
   136e1:	8b 55 0c             	mov    0xc(%ebp),%edx
   136e4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   136e7:	f0 31 10             	lock xor %edx,(%eax)
   136ea:	90                   	nop
   136eb:	5d                   	pop    %ebp
   136ec:	c3                   	ret    

000136ed <ck_pr_xor_char>:
   136ed:	55                   	push   %ebp
   136ee:	89 e5                	mov    %esp,%ebp
   136f0:	83 ec 04             	sub    $0x4,%esp
   136f3:	8b 45 0c             	mov    0xc(%ebp),%eax
   136f6:	88 45 fc             	mov    %al,-0x4(%ebp)
   136f9:	8b 45 08             	mov    0x8(%ebp),%eax
   136fc:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   13700:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13703:	f0 30 10             	lock xor %dl,(%eax)
   13706:	90                   	nop
   13707:	c9                   	leave  
   13708:	c3                   	ret    

00013709 <ck_pr_xor_int>:
   13709:	55                   	push   %ebp
   1370a:	89 e5                	mov    %esp,%ebp
   1370c:	8b 45 08             	mov    0x8(%ebp),%eax
   1370f:	8b 55 0c             	mov    0xc(%ebp),%edx
   13712:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13715:	f0 31 10             	lock xor %edx,(%eax)
   13718:	90                   	nop
   13719:	5d                   	pop    %ebp
   1371a:	c3                   	ret    

0001371b <ck_pr_xor_uint>:
   1371b:	55                   	push   %ebp
   1371c:	89 e5                	mov    %esp,%ebp
   1371e:	8b 45 08             	mov    0x8(%ebp),%eax
   13721:	8b 55 0c             	mov    0xc(%ebp),%edx
   13724:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13727:	f0 31 10             	lock xor %edx,(%eax)
   1372a:	90                   	nop
   1372b:	5d                   	pop    %ebp
   1372c:	c3                   	ret    

0001372d <ck_pr_xor_32>:
   1372d:	55                   	push   %ebp
   1372e:	89 e5                	mov    %esp,%ebp
   13730:	8b 45 08             	mov    0x8(%ebp),%eax
   13733:	8b 55 0c             	mov    0xc(%ebp),%edx
   13736:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13739:	f0 31 10             	lock xor %edx,(%eax)
   1373c:	90                   	nop
   1373d:	5d                   	pop    %ebp
   1373e:	c3                   	ret    

0001373f <ck_pr_xor_16>:
   1373f:	55                   	push   %ebp
   13740:	89 e5                	mov    %esp,%ebp
   13742:	83 ec 04             	sub    $0x4,%esp
   13745:	8b 45 0c             	mov    0xc(%ebp),%eax
   13748:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1374c:	8b 45 08             	mov    0x8(%ebp),%eax
   1374f:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   13753:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13756:	66 f0 31 10          	lock xor %dx,(%eax)
   1375a:	90                   	nop
   1375b:	c9                   	leave  
   1375c:	c3                   	ret    

0001375d <ck_pr_xor_8>:
   1375d:	55                   	push   %ebp
   1375e:	89 e5                	mov    %esp,%ebp
   13760:	83 ec 04             	sub    $0x4,%esp
   13763:	8b 45 0c             	mov    0xc(%ebp),%eax
   13766:	88 45 fc             	mov    %al,-0x4(%ebp)
   13769:	8b 45 08             	mov    0x8(%ebp),%eax
   1376c:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   13770:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13773:	f0 30 10             	lock xor %dl,(%eax)
   13776:	90                   	nop
   13777:	c9                   	leave  
   13778:	c3                   	ret    

00013779 <ck_pr_cas_ptr>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return z;							\
	}

CK_PR_CAS(ptr, void, void *, char, "cmpxchgl")
   13779:	55                   	push   %ebp
   1377a:	89 e5                	mov    %esp,%ebp
   1377c:	53                   	push   %ebx
   1377d:	83 ec 10             	sub    $0x10,%esp
   13780:	8b 55 08             	mov    0x8(%ebp),%edx
   13783:	8b 4d 10             	mov    0x10(%ebp),%ecx
   13786:	8b 45 0c             	mov    0xc(%ebp),%eax
   13789:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1378c:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   13790:	0f 94 c0             	sete   %al
   13793:	88 45 fb             	mov    %al,-0x5(%ebp)
   13796:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1379a:	83 c4 10             	add    $0x10,%esp
   1379d:	5b                   	pop    %ebx
   1379e:	5d                   	pop    %ebp
   1379f:	c3                   	ret    

000137a0 <ck_pr_cas_char>:

#define CK_PR_CAS_S(S, T, I) CK_PR_CAS(S, T, T, T, I)

CK_PR_CAS_S(char, char, "cmpxchgb")
   137a0:	55                   	push   %ebp
   137a1:	89 e5                	mov    %esp,%ebp
   137a3:	53                   	push   %ebx
   137a4:	83 ec 18             	sub    $0x18,%esp
   137a7:	8b 55 0c             	mov    0xc(%ebp),%edx
   137aa:	8b 45 10             	mov    0x10(%ebp),%eax
   137ad:	88 55 e8             	mov    %dl,-0x18(%ebp)
   137b0:	88 45 e4             	mov    %al,-0x1c(%ebp)
   137b3:	8b 55 08             	mov    0x8(%ebp),%edx
   137b6:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   137ba:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   137be:	8b 5d 08             	mov    0x8(%ebp),%ebx
   137c1:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   137c5:	0f 94 c0             	sete   %al
   137c8:	88 45 fb             	mov    %al,-0x5(%ebp)
   137cb:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   137cf:	83 c4 18             	add    $0x18,%esp
   137d2:	5b                   	pop    %ebx
   137d3:	5d                   	pop    %ebp
   137d4:	c3                   	ret    

000137d5 <ck_pr_cas_int>:
CK_PR_CAS_S(int, int, "cmpxchgl")
   137d5:	55                   	push   %ebp
   137d6:	89 e5                	mov    %esp,%ebp
   137d8:	53                   	push   %ebx
   137d9:	83 ec 10             	sub    $0x10,%esp
   137dc:	8b 55 08             	mov    0x8(%ebp),%edx
   137df:	8b 4d 10             	mov    0x10(%ebp),%ecx
   137e2:	8b 45 0c             	mov    0xc(%ebp),%eax
   137e5:	8b 5d 08             	mov    0x8(%ebp),%ebx
   137e8:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   137ec:	0f 94 c0             	sete   %al
   137ef:	88 45 fb             	mov    %al,-0x5(%ebp)
   137f2:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   137f6:	83 c4 10             	add    $0x10,%esp
   137f9:	5b                   	pop    %ebx
   137fa:	5d                   	pop    %ebp
   137fb:	c3                   	ret    

000137fc <ck_pr_cas_uint>:
CK_PR_CAS_S(uint, unsigned int, "cmpxchgl")
   137fc:	55                   	push   %ebp
   137fd:	89 e5                	mov    %esp,%ebp
   137ff:	53                   	push   %ebx
   13800:	83 ec 10             	sub    $0x10,%esp
   13803:	8b 55 08             	mov    0x8(%ebp),%edx
   13806:	8b 4d 10             	mov    0x10(%ebp),%ecx
   13809:	8b 45 0c             	mov    0xc(%ebp),%eax
   1380c:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1380f:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   13813:	0f 94 c0             	sete   %al
   13816:	88 45 fb             	mov    %al,-0x5(%ebp)
   13819:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1381d:	83 c4 10             	add    $0x10,%esp
   13820:	5b                   	pop    %ebx
   13821:	5d                   	pop    %ebp
   13822:	c3                   	ret    

00013823 <ck_pr_cas_32>:
CK_PR_CAS_S(32, uint32_t, "cmpxchgl")
   13823:	55                   	push   %ebp
   13824:	89 e5                	mov    %esp,%ebp
   13826:	53                   	push   %ebx
   13827:	83 ec 10             	sub    $0x10,%esp
   1382a:	8b 55 08             	mov    0x8(%ebp),%edx
   1382d:	8b 4d 10             	mov    0x10(%ebp),%ecx
   13830:	8b 45 0c             	mov    0xc(%ebp),%eax
   13833:	8b 5d 08             	mov    0x8(%ebp),%ebx
   13836:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1383a:	0f 94 c0             	sete   %al
   1383d:	88 45 fb             	mov    %al,-0x5(%ebp)
   13840:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   13844:	83 c4 10             	add    $0x10,%esp
   13847:	5b                   	pop    %ebx
   13848:	5d                   	pop    %ebp
   13849:	c3                   	ret    

0001384a <ck_pr_cas_16>:
CK_PR_CAS_S(16, uint16_t, "cmpxchgw")
   1384a:	55                   	push   %ebp
   1384b:	89 e5                	mov    %esp,%ebp
   1384d:	53                   	push   %ebx
   1384e:	83 ec 18             	sub    $0x18,%esp
   13851:	8b 55 0c             	mov    0xc(%ebp),%edx
   13854:	8b 45 10             	mov    0x10(%ebp),%eax
   13857:	66 89 55 e8          	mov    %dx,-0x18(%ebp)
   1385b:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   1385f:	8b 55 08             	mov    0x8(%ebp),%edx
   13862:	0f b7 4d e4          	movzwl -0x1c(%ebp),%ecx
   13866:	0f b7 45 e8          	movzwl -0x18(%ebp),%eax
   1386a:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1386d:	66 f0 0f b1 0a       	lock cmpxchg %cx,(%edx)
   13872:	0f 94 c0             	sete   %al
   13875:	88 45 fb             	mov    %al,-0x5(%ebp)
   13878:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1387c:	83 c4 18             	add    $0x18,%esp
   1387f:	5b                   	pop    %ebx
   13880:	5d                   	pop    %ebp
   13881:	c3                   	ret    

00013882 <ck_pr_cas_8>:
CK_PR_CAS_S(8,  uint8_t,  "cmpxchgb")
   13882:	55                   	push   %ebp
   13883:	89 e5                	mov    %esp,%ebp
   13885:	53                   	push   %ebx
   13886:	83 ec 18             	sub    $0x18,%esp
   13889:	8b 55 0c             	mov    0xc(%ebp),%edx
   1388c:	8b 45 10             	mov    0x10(%ebp),%eax
   1388f:	88 55 e8             	mov    %dl,-0x18(%ebp)
   13892:	88 45 e4             	mov    %al,-0x1c(%ebp)
   13895:	8b 55 08             	mov    0x8(%ebp),%edx
   13898:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   1389c:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   138a0:	8b 5d 08             	mov    0x8(%ebp),%ebx
   138a3:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   138a7:	0f 94 c0             	sete   %al
   138aa:	88 45 fb             	mov    %al,-0x5(%ebp)
   138ad:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   138b1:	83 c4 18             	add    $0x18,%esp
   138b4:	5b                   	pop    %ebx
   138b5:	5d                   	pop    %ebp
   138b6:	c3                   	ret    

000138b7 <ck_pr_cas_ptr_value>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return (bool)z;							\
	}

CK_PR_CAS_O(ptr, void, void *, char, "l", "eax")
   138b7:	55                   	push   %ebp
   138b8:	89 e5                	mov    %esp,%ebp
   138ba:	56                   	push   %esi
   138bb:	53                   	push   %ebx
   138bc:	83 ec 10             	sub    $0x10,%esp
   138bf:	8b 5d 08             	mov    0x8(%ebp),%ebx
   138c2:	8b 75 14             	mov    0x14(%ebp),%esi
   138c5:	8b 55 10             	mov    0x10(%ebp),%edx
   138c8:	8b 45 0c             	mov    0xc(%ebp),%eax
   138cb:	8b 4d 08             	mov    0x8(%ebp),%ecx
   138ce:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   138d2:	89 06                	mov    %eax,(%esi)
   138d4:	0f 94 c0             	sete   %al
   138d7:	88 45 f7             	mov    %al,-0x9(%ebp)
   138da:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   138de:	83 c4 10             	add    $0x10,%esp
   138e1:	5b                   	pop    %ebx
   138e2:	5e                   	pop    %esi
   138e3:	5d                   	pop    %ebp
   138e4:	c3                   	ret    

000138e5 <ck_pr_cas_char_value>:

#define CK_PR_CAS_O_S(S, T, I, R)	\
	CK_PR_CAS_O(S, T, T, T, I, R)

CK_PR_CAS_O_S(char, char, "b", "al")
   138e5:	55                   	push   %ebp
   138e6:	89 e5                	mov    %esp,%ebp
   138e8:	56                   	push   %esi
   138e9:	53                   	push   %ebx
   138ea:	83 ec 18             	sub    $0x18,%esp
   138ed:	8b 55 0c             	mov    0xc(%ebp),%edx
   138f0:	8b 45 10             	mov    0x10(%ebp),%eax
   138f3:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   138f6:	88 45 e0             	mov    %al,-0x20(%ebp)
   138f9:	8b 5d 08             	mov    0x8(%ebp),%ebx
   138fc:	8b 75 14             	mov    0x14(%ebp),%esi
   138ff:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   13903:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   13907:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1390a:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   1390e:	88 06                	mov    %al,(%esi)
   13910:	0f 94 c0             	sete   %al
   13913:	88 45 f7             	mov    %al,-0x9(%ebp)
   13916:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1391a:	83 c4 18             	add    $0x18,%esp
   1391d:	5b                   	pop    %ebx
   1391e:	5e                   	pop    %esi
   1391f:	5d                   	pop    %ebp
   13920:	c3                   	ret    

00013921 <ck_pr_cas_int_value>:
CK_PR_CAS_O_S(int, int, "l", "eax")
   13921:	55                   	push   %ebp
   13922:	89 e5                	mov    %esp,%ebp
   13924:	56                   	push   %esi
   13925:	53                   	push   %ebx
   13926:	83 ec 10             	sub    $0x10,%esp
   13929:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1392c:	8b 75 14             	mov    0x14(%ebp),%esi
   1392f:	8b 55 10             	mov    0x10(%ebp),%edx
   13932:	8b 45 0c             	mov    0xc(%ebp),%eax
   13935:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13938:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1393c:	89 06                	mov    %eax,(%esi)
   1393e:	0f 94 c0             	sete   %al
   13941:	88 45 f7             	mov    %al,-0x9(%ebp)
   13944:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   13948:	83 c4 10             	add    $0x10,%esp
   1394b:	5b                   	pop    %ebx
   1394c:	5e                   	pop    %esi
   1394d:	5d                   	pop    %ebp
   1394e:	c3                   	ret    

0001394f <ck_pr_cas_uint_value>:
CK_PR_CAS_O_S(uint, unsigned int, "l", "eax")
   1394f:	55                   	push   %ebp
   13950:	89 e5                	mov    %esp,%ebp
   13952:	56                   	push   %esi
   13953:	53                   	push   %ebx
   13954:	83 ec 10             	sub    $0x10,%esp
   13957:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1395a:	8b 75 14             	mov    0x14(%ebp),%esi
   1395d:	8b 55 10             	mov    0x10(%ebp),%edx
   13960:	8b 45 0c             	mov    0xc(%ebp),%eax
   13963:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13966:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1396a:	89 06                	mov    %eax,(%esi)
   1396c:	0f 94 c0             	sete   %al
   1396f:	88 45 f7             	mov    %al,-0x9(%ebp)
   13972:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   13976:	83 c4 10             	add    $0x10,%esp
   13979:	5b                   	pop    %ebx
   1397a:	5e                   	pop    %esi
   1397b:	5d                   	pop    %ebp
   1397c:	c3                   	ret    

0001397d <ck_pr_cas_32_value>:
CK_PR_CAS_O_S(32, uint32_t, "l", "eax")
   1397d:	55                   	push   %ebp
   1397e:	89 e5                	mov    %esp,%ebp
   13980:	56                   	push   %esi
   13981:	53                   	push   %ebx
   13982:	83 ec 10             	sub    $0x10,%esp
   13985:	8b 5d 08             	mov    0x8(%ebp),%ebx
   13988:	8b 75 14             	mov    0x14(%ebp),%esi
   1398b:	8b 55 10             	mov    0x10(%ebp),%edx
   1398e:	8b 45 0c             	mov    0xc(%ebp),%eax
   13991:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13994:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   13998:	89 06                	mov    %eax,(%esi)
   1399a:	0f 94 c0             	sete   %al
   1399d:	88 45 f7             	mov    %al,-0x9(%ebp)
   139a0:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   139a4:	83 c4 10             	add    $0x10,%esp
   139a7:	5b                   	pop    %ebx
   139a8:	5e                   	pop    %esi
   139a9:	5d                   	pop    %ebp
   139aa:	c3                   	ret    

000139ab <ck_pr_cas_16_value>:
CK_PR_CAS_O_S(16, uint16_t, "w", "ax")
   139ab:	55                   	push   %ebp
   139ac:	89 e5                	mov    %esp,%ebp
   139ae:	56                   	push   %esi
   139af:	53                   	push   %ebx
   139b0:	83 ec 18             	sub    $0x18,%esp
   139b3:	8b 55 0c             	mov    0xc(%ebp),%edx
   139b6:	8b 45 10             	mov    0x10(%ebp),%eax
   139b9:	66 89 55 e4          	mov    %dx,-0x1c(%ebp)
   139bd:	66 89 45 e0          	mov    %ax,-0x20(%ebp)
   139c1:	8b 5d 08             	mov    0x8(%ebp),%ebx
   139c4:	8b 75 14             	mov    0x14(%ebp),%esi
   139c7:	0f b7 55 e0          	movzwl -0x20(%ebp),%edx
   139cb:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
   139cf:	8b 4d 08             	mov    0x8(%ebp),%ecx
   139d2:	66 f0 0f b1 13       	lock cmpxchg %dx,(%ebx)
   139d7:	66 89 06             	mov    %ax,(%esi)
   139da:	0f 94 c0             	sete   %al
   139dd:	88 45 f7             	mov    %al,-0x9(%ebp)
   139e0:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   139e4:	83 c4 18             	add    $0x18,%esp
   139e7:	5b                   	pop    %ebx
   139e8:	5e                   	pop    %esi
   139e9:	5d                   	pop    %ebp
   139ea:	c3                   	ret    

000139eb <ck_pr_cas_8_value>:
CK_PR_CAS_O_S(8,  uint8_t,  "b", "al")
   139eb:	55                   	push   %ebp
   139ec:	89 e5                	mov    %esp,%ebp
   139ee:	56                   	push   %esi
   139ef:	53                   	push   %ebx
   139f0:	83 ec 18             	sub    $0x18,%esp
   139f3:	8b 55 0c             	mov    0xc(%ebp),%edx
   139f6:	8b 45 10             	mov    0x10(%ebp),%eax
   139f9:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   139fc:	88 45 e0             	mov    %al,-0x20(%ebp)
   139ff:	8b 5d 08             	mov    0x8(%ebp),%ebx
   13a02:	8b 75 14             	mov    0x14(%ebp),%esi
   13a05:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   13a09:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   13a0d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13a10:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   13a14:	88 06                	mov    %al,(%esi)
   13a16:	0f 94 c0             	sete   %al
   13a19:	88 45 f7             	mov    %al,-0x9(%ebp)
   13a1c:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   13a20:	83 c4 18             	add    $0x18,%esp
   13a23:	5b                   	pop    %ebx
   13a24:	5e                   	pop    %esi
   13a25:	5d                   	pop    %ebp
   13a26:	c3                   	ret    

00013a27 <ck_pr_btc_ptr>:
	CK_PR_BT_S(K, uint, unsigned int, #K "l %2, %0")	\
	CK_PR_BT_S(K, int, int, #K "l %2, %0")			\
	CK_PR_BT_S(K, 32, uint32_t, #K "l %2, %0")		\
	CK_PR_BT_S(K, 16, uint16_t, #K "w %w2, %0")

CK_PR_GENERATE(btc)
   13a27:	55                   	push   %ebp
   13a28:	89 e5                	mov    %esp,%ebp
   13a2a:	83 ec 10             	sub    $0x10,%esp
   13a2d:	8b 55 08             	mov    0x8(%ebp),%edx
   13a30:	8b 45 0c             	mov    0xc(%ebp),%eax
   13a33:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13a36:	f0 0f bb 02          	lock btc %eax,(%edx)
   13a3a:	0f 92 c0             	setb   %al
   13a3d:	88 45 ff             	mov    %al,-0x1(%ebp)
   13a40:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13a44:	c9                   	leave  
   13a45:	c3                   	ret    

00013a46 <ck_pr_btc_uint>:
   13a46:	55                   	push   %ebp
   13a47:	89 e5                	mov    %esp,%ebp
   13a49:	83 ec 10             	sub    $0x10,%esp
   13a4c:	8b 55 08             	mov    0x8(%ebp),%edx
   13a4f:	8b 45 0c             	mov    0xc(%ebp),%eax
   13a52:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13a55:	f0 0f bb 02          	lock btc %eax,(%edx)
   13a59:	0f 92 c0             	setb   %al
   13a5c:	88 45 ff             	mov    %al,-0x1(%ebp)
   13a5f:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13a63:	c9                   	leave  
   13a64:	c3                   	ret    

00013a65 <ck_pr_btc_int>:
   13a65:	55                   	push   %ebp
   13a66:	89 e5                	mov    %esp,%ebp
   13a68:	83 ec 10             	sub    $0x10,%esp
   13a6b:	8b 45 0c             	mov    0xc(%ebp),%eax
   13a6e:	8b 55 08             	mov    0x8(%ebp),%edx
   13a71:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13a74:	f0 0f bb 02          	lock btc %eax,(%edx)
   13a78:	0f 92 c0             	setb   %al
   13a7b:	88 45 ff             	mov    %al,-0x1(%ebp)
   13a7e:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13a82:	c9                   	leave  
   13a83:	c3                   	ret    

00013a84 <ck_pr_btc_32>:
   13a84:	55                   	push   %ebp
   13a85:	89 e5                	mov    %esp,%ebp
   13a87:	83 ec 10             	sub    $0x10,%esp
   13a8a:	8b 55 08             	mov    0x8(%ebp),%edx
   13a8d:	8b 45 0c             	mov    0xc(%ebp),%eax
   13a90:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13a93:	f0 0f bb 02          	lock btc %eax,(%edx)
   13a97:	0f 92 c0             	setb   %al
   13a9a:	88 45 ff             	mov    %al,-0x1(%ebp)
   13a9d:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13aa1:	c9                   	leave  
   13aa2:	c3                   	ret    

00013aa3 <ck_pr_btc_16>:
   13aa3:	55                   	push   %ebp
   13aa4:	89 e5                	mov    %esp,%ebp
   13aa6:	83 ec 10             	sub    $0x10,%esp
   13aa9:	8b 45 0c             	mov    0xc(%ebp),%eax
   13aac:	8b 55 08             	mov    0x8(%ebp),%edx
   13aaf:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13ab2:	66 f0 0f bb 02       	lock btc %ax,(%edx)
   13ab7:	0f 92 c0             	setb   %al
   13aba:	88 45 ff             	mov    %al,-0x1(%ebp)
   13abd:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13ac1:	c9                   	leave  
   13ac2:	c3                   	ret    

00013ac3 <ck_pr_bts_ptr>:
CK_PR_GENERATE(bts)
   13ac3:	55                   	push   %ebp
   13ac4:	89 e5                	mov    %esp,%ebp
   13ac6:	83 ec 10             	sub    $0x10,%esp
   13ac9:	8b 55 08             	mov    0x8(%ebp),%edx
   13acc:	8b 45 0c             	mov    0xc(%ebp),%eax
   13acf:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13ad2:	f0 0f ab 02          	lock bts %eax,(%edx)
   13ad6:	0f 92 c0             	setb   %al
   13ad9:	88 45 ff             	mov    %al,-0x1(%ebp)
   13adc:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13ae0:	c9                   	leave  
   13ae1:	c3                   	ret    

00013ae2 <ck_pr_bts_uint>:
   13ae2:	55                   	push   %ebp
   13ae3:	89 e5                	mov    %esp,%ebp
   13ae5:	83 ec 10             	sub    $0x10,%esp
   13ae8:	8b 55 08             	mov    0x8(%ebp),%edx
   13aeb:	8b 45 0c             	mov    0xc(%ebp),%eax
   13aee:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13af1:	f0 0f ab 02          	lock bts %eax,(%edx)
   13af5:	0f 92 c0             	setb   %al
   13af8:	88 45 ff             	mov    %al,-0x1(%ebp)
   13afb:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13aff:	c9                   	leave  
   13b00:	c3                   	ret    

00013b01 <ck_pr_bts_int>:
   13b01:	55                   	push   %ebp
   13b02:	89 e5                	mov    %esp,%ebp
   13b04:	83 ec 10             	sub    $0x10,%esp
   13b07:	8b 45 0c             	mov    0xc(%ebp),%eax
   13b0a:	8b 55 08             	mov    0x8(%ebp),%edx
   13b0d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13b10:	f0 0f ab 02          	lock bts %eax,(%edx)
   13b14:	0f 92 c0             	setb   %al
   13b17:	88 45 ff             	mov    %al,-0x1(%ebp)
   13b1a:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13b1e:	c9                   	leave  
   13b1f:	c3                   	ret    

00013b20 <ck_pr_bts_32>:
   13b20:	55                   	push   %ebp
   13b21:	89 e5                	mov    %esp,%ebp
   13b23:	83 ec 10             	sub    $0x10,%esp
   13b26:	8b 55 08             	mov    0x8(%ebp),%edx
   13b29:	8b 45 0c             	mov    0xc(%ebp),%eax
   13b2c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13b2f:	f0 0f ab 02          	lock bts %eax,(%edx)
   13b33:	0f 92 c0             	setb   %al
   13b36:	88 45 ff             	mov    %al,-0x1(%ebp)
   13b39:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13b3d:	c9                   	leave  
   13b3e:	c3                   	ret    

00013b3f <ck_pr_bts_16>:
   13b3f:	55                   	push   %ebp
   13b40:	89 e5                	mov    %esp,%ebp
   13b42:	83 ec 10             	sub    $0x10,%esp
   13b45:	8b 45 0c             	mov    0xc(%ebp),%eax
   13b48:	8b 55 08             	mov    0x8(%ebp),%edx
   13b4b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13b4e:	66 f0 0f ab 02       	lock bts %ax,(%edx)
   13b53:	0f 92 c0             	setb   %al
   13b56:	88 45 ff             	mov    %al,-0x1(%ebp)
   13b59:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13b5d:	c9                   	leave  
   13b5e:	c3                   	ret    

00013b5f <ck_pr_btr_ptr>:
CK_PR_GENERATE(btr)
   13b5f:	55                   	push   %ebp
   13b60:	89 e5                	mov    %esp,%ebp
   13b62:	83 ec 10             	sub    $0x10,%esp
   13b65:	8b 55 08             	mov    0x8(%ebp),%edx
   13b68:	8b 45 0c             	mov    0xc(%ebp),%eax
   13b6b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13b6e:	f0 0f b3 02          	lock btr %eax,(%edx)
   13b72:	0f 92 c0             	setb   %al
   13b75:	88 45 ff             	mov    %al,-0x1(%ebp)
   13b78:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13b7c:	c9                   	leave  
   13b7d:	c3                   	ret    

00013b7e <ck_pr_btr_uint>:
   13b7e:	55                   	push   %ebp
   13b7f:	89 e5                	mov    %esp,%ebp
   13b81:	83 ec 10             	sub    $0x10,%esp
   13b84:	8b 55 08             	mov    0x8(%ebp),%edx
   13b87:	8b 45 0c             	mov    0xc(%ebp),%eax
   13b8a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13b8d:	f0 0f b3 02          	lock btr %eax,(%edx)
   13b91:	0f 92 c0             	setb   %al
   13b94:	88 45 ff             	mov    %al,-0x1(%ebp)
   13b97:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13b9b:	c9                   	leave  
   13b9c:	c3                   	ret    

00013b9d <ck_pr_btr_int>:
   13b9d:	55                   	push   %ebp
   13b9e:	89 e5                	mov    %esp,%ebp
   13ba0:	83 ec 10             	sub    $0x10,%esp
   13ba3:	8b 45 0c             	mov    0xc(%ebp),%eax
   13ba6:	8b 55 08             	mov    0x8(%ebp),%edx
   13ba9:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13bac:	f0 0f b3 02          	lock btr %eax,(%edx)
   13bb0:	0f 92 c0             	setb   %al
   13bb3:	88 45 ff             	mov    %al,-0x1(%ebp)
   13bb6:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13bba:	c9                   	leave  
   13bbb:	c3                   	ret    

00013bbc <ck_pr_btr_32>:
   13bbc:	55                   	push   %ebp
   13bbd:	89 e5                	mov    %esp,%ebp
   13bbf:	83 ec 10             	sub    $0x10,%esp
   13bc2:	8b 55 08             	mov    0x8(%ebp),%edx
   13bc5:	8b 45 0c             	mov    0xc(%ebp),%eax
   13bc8:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13bcb:	f0 0f b3 02          	lock btr %eax,(%edx)
   13bcf:	0f 92 c0             	setb   %al
   13bd2:	88 45 ff             	mov    %al,-0x1(%ebp)
   13bd5:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13bd9:	c9                   	leave  
   13bda:	c3                   	ret    

00013bdb <ck_pr_btr_16>:
   13bdb:	55                   	push   %ebp
   13bdc:	89 e5                	mov    %esp,%ebp
   13bde:	83 ec 10             	sub    $0x10,%esp
   13be1:	8b 45 0c             	mov    0xc(%ebp),%eax
   13be4:	8b 55 08             	mov    0x8(%ebp),%edx
   13be7:	8b 4d 08             	mov    0x8(%ebp),%ecx
   13bea:	66 f0 0f b3 02       	lock btr %ax,(%edx)
   13bef:	0f 92 c0             	setb   %al
   13bf2:	88 45 ff             	mov    %al,-0x1(%ebp)
   13bf5:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   13bf9:	c9                   	leave  
   13bfa:	c3                   	ret    

00013bfb <ck_pr_barrier>:

#include <ck_cc.h>

CK_CC_INLINE static void
ck_pr_barrier(void)
{
   13bfb:	55                   	push   %ebp
   13bfc:	89 e5                	mov    %esp,%ebp

	__asm__ __volatile__("" ::: "memory");
	return;
   13bfe:	90                   	nop
}
   13bff:	5d                   	pop    %ebp
   13c00:	c3                   	ret    

00013c01 <ck_pr_fence_load_depends>:

/*
 * None of the currently supported platforms allow for data-dependent
 * load ordering.
 */
CK_PR_FENCE_NOOP(load_depends)
   13c01:	55                   	push   %ebp
   13c02:	89 e5                	mov    %esp,%ebp
   13c04:	e8 f2 ff ff ff       	call   13bfb <ck_pr_barrier>
   13c09:	90                   	nop
   13c0a:	5d                   	pop    %ebp
   13c0b:	c3                   	ret    

00013c0c <ck_pr_fence_atomic>:
#elif defined(CK_MD_TSO)
/*
 * Only loads are re-ordered and only with respect to
 * prior stores. Atomic operations are serializing.
 */
CK_PR_FENCE_NOOP(atomic)
   13c0c:	55                   	push   %ebp
   13c0d:	89 e5                	mov    %esp,%ebp
   13c0f:	e8 e7 ff ff ff       	call   13bfb <ck_pr_barrier>
   13c14:	90                   	nop
   13c15:	5d                   	pop    %ebp
   13c16:	c3                   	ret    

00013c17 <ck_pr_fence_atomic_load>:
CK_PR_FENCE_NOOP(atomic_load)
   13c17:	55                   	push   %ebp
   13c18:	89 e5                	mov    %esp,%ebp
   13c1a:	e8 dc ff ff ff       	call   13bfb <ck_pr_barrier>
   13c1f:	90                   	nop
   13c20:	5d                   	pop    %ebp
   13c21:	c3                   	ret    

00013c22 <ck_pr_fence_atomic_store>:
CK_PR_FENCE_NOOP(atomic_store)
   13c22:	55                   	push   %ebp
   13c23:	89 e5                	mov    %esp,%ebp
   13c25:	e8 d1 ff ff ff       	call   13bfb <ck_pr_barrier>
   13c2a:	90                   	nop
   13c2b:	5d                   	pop    %ebp
   13c2c:	c3                   	ret    

00013c2d <ck_pr_fence_store_atomic>:
CK_PR_FENCE_NOOP(store_atomic)
   13c2d:	55                   	push   %ebp
   13c2e:	89 e5                	mov    %esp,%ebp
   13c30:	e8 c6 ff ff ff       	call   13bfb <ck_pr_barrier>
   13c35:	90                   	nop
   13c36:	5d                   	pop    %ebp
   13c37:	c3                   	ret    

00013c38 <ck_pr_fence_load_atomic>:
CK_PR_FENCE_NOOP(load_atomic)
   13c38:	55                   	push   %ebp
   13c39:	89 e5                	mov    %esp,%ebp
   13c3b:	e8 bb ff ff ff       	call   13bfb <ck_pr_barrier>
   13c40:	90                   	nop
   13c41:	5d                   	pop    %ebp
   13c42:	c3                   	ret    

00013c43 <ck_pr_fence_load_store>:
CK_PR_FENCE_NOOP(load_store)
   13c43:	55                   	push   %ebp
   13c44:	89 e5                	mov    %esp,%ebp
   13c46:	e8 b0 ff ff ff       	call   13bfb <ck_pr_barrier>
   13c4b:	90                   	nop
   13c4c:	5d                   	pop    %ebp
   13c4d:	c3                   	ret    

00013c4e <ck_pr_fence_store_load>:
CK_PR_FENCE_EMIT(store_load)
   13c4e:	55                   	push   %ebp
   13c4f:	89 e5                	mov    %esp,%ebp
   13c51:	e8 d4 f1 ff ff       	call   12e2a <ck_pr_fence_strict_store_load>
   13c56:	90                   	nop
   13c57:	5d                   	pop    %ebp
   13c58:	c3                   	ret    

00013c59 <ck_pr_fence_load>:
CK_PR_FENCE_NOOP(load)
   13c59:	55                   	push   %ebp
   13c5a:	89 e5                	mov    %esp,%ebp
   13c5c:	e8 9a ff ff ff       	call   13bfb <ck_pr_barrier>
   13c61:	90                   	nop
   13c62:	5d                   	pop    %ebp
   13c63:	c3                   	ret    

00013c64 <ck_pr_fence_store>:
CK_PR_FENCE_NOOP(store)
   13c64:	55                   	push   %ebp
   13c65:	89 e5                	mov    %esp,%ebp
   13c67:	e8 8f ff ff ff       	call   13bfb <ck_pr_barrier>
   13c6c:	90                   	nop
   13c6d:	5d                   	pop    %ebp
   13c6e:	c3                   	ret    

00013c6f <ck_pr_fence_memory>:
CK_PR_FENCE_EMIT(memory)
   13c6f:	55                   	push   %ebp
   13c70:	89 e5                	mov    %esp,%ebp
   13c72:	e8 bc f1 ff ff       	call   12e33 <ck_pr_fence_strict_memory>
   13c77:	90                   	nop
   13c78:	5d                   	pop    %ebp
   13c79:	c3                   	ret    

00013c7a <ck_pr_fence_acquire>:
CK_PR_FENCE_NOOP(acquire)
   13c7a:	55                   	push   %ebp
   13c7b:	89 e5                	mov    %esp,%ebp
   13c7d:	e8 79 ff ff ff       	call   13bfb <ck_pr_barrier>
   13c82:	90                   	nop
   13c83:	5d                   	pop    %ebp
   13c84:	c3                   	ret    

00013c85 <ck_pr_fence_release>:
CK_PR_FENCE_NOOP(release)
   13c85:	55                   	push   %ebp
   13c86:	89 e5                	mov    %esp,%ebp
   13c88:	e8 6e ff ff ff       	call   13bfb <ck_pr_barrier>
   13c8d:	90                   	nop
   13c8e:	5d                   	pop    %ebp
   13c8f:	c3                   	ret    

00013c90 <ck_pr_fence_acqrel>:
CK_PR_FENCE_NOOP(acqrel)
   13c90:	55                   	push   %ebp
   13c91:	89 e5                	mov    %esp,%ebp
   13c93:	e8 63 ff ff ff       	call   13bfb <ck_pr_barrier>
   13c98:	90                   	nop
   13c99:	5d                   	pop    %ebp
   13c9a:	c3                   	ret    

00013c9b <ck_pr_fence_lock>:
CK_PR_FENCE_NOOP(lock)
   13c9b:	55                   	push   %ebp
   13c9c:	89 e5                	mov    %esp,%ebp
   13c9e:	e8 58 ff ff ff       	call   13bfb <ck_pr_barrier>
   13ca3:	90                   	nop
   13ca4:	5d                   	pop    %ebp
   13ca5:	c3                   	ret    

00013ca6 <ck_pr_fence_unlock>:
CK_PR_FENCE_NOOP(unlock)
   13ca6:	55                   	push   %ebp
   13ca7:	89 e5                	mov    %esp,%ebp
   13ca9:	e8 4d ff ff ff       	call   13bfb <ck_pr_barrier>
   13cae:	90                   	nop
   13caf:	5d                   	pop    %ebp
   13cb0:	c3                   	ret    

00013cb1 <ck_pr_rfo>:

#ifndef CK_F_PR_RFO
#define CK_F_PR_RFO
CK_CC_INLINE static void
ck_pr_rfo(const void *m)
{
   13cb1:	55                   	push   %ebp
   13cb2:	89 e5                	mov    %esp,%ebp

	(void)m;
	return;
   13cb4:	90                   	nop
}
   13cb5:	5d                   	pop    %ebp
   13cb6:	c3                   	ret    

00013cb7 <ck_ring_size>:
};
typedef struct ck_ring_buffer ck_ring_buffer_t;

CK_CC_INLINE static unsigned int
ck_ring_size(const struct ck_ring *ring)
{
   13cb7:	55                   	push   %ebp
   13cb8:	89 e5                	mov    %esp,%ebp
   13cba:	83 ec 14             	sub    $0x14,%esp
	unsigned int c, p;

	c = ck_pr_load_uint(&ring->c_head);
   13cbd:	8b 45 08             	mov    0x8(%ebp),%eax
   13cc0:	89 04 24             	mov    %eax,(%esp)
   13cc3:	e8 86 f2 ff ff       	call   12f4e <ck_pr_md_load_uint>
   13cc8:	89 45 fc             	mov    %eax,-0x4(%ebp)
	p = ck_pr_load_uint(&ring->p_tail);
   13ccb:	8b 45 08             	mov    0x8(%ebp),%eax
   13cce:	83 c0 40             	add    $0x40,%eax
   13cd1:	89 04 24             	mov    %eax,(%esp)
   13cd4:	e8 75 f2 ff ff       	call   12f4e <ck_pr_md_load_uint>
   13cd9:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return (p - c) & ring->mask;
   13cdc:	8b 45 fc             	mov    -0x4(%ebp),%eax
   13cdf:	8b 55 f8             	mov    -0x8(%ebp),%edx
   13ce2:	29 c2                	sub    %eax,%edx
   13ce4:	8b 45 08             	mov    0x8(%ebp),%eax
   13ce7:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   13ced:	21 d0                	and    %edx,%eax
}
   13cef:	c9                   	leave  
   13cf0:	c3                   	ret    

00013cf1 <ck_ring_capacity>:

CK_CC_INLINE static unsigned int
ck_ring_capacity(const struct ck_ring *ring)
{
   13cf1:	55                   	push   %ebp
   13cf2:	89 e5                	mov    %esp,%ebp
	return ring->size;
   13cf4:	8b 45 08             	mov    0x8(%ebp),%eax
   13cf7:	8b 80 80 00 00 00    	mov    0x80(%eax),%eax
}
   13cfd:	5d                   	pop    %ebp
   13cfe:	c3                   	ret    

00013cff <ck_ring_init>:

CK_CC_INLINE static void
ck_ring_init(struct ck_ring *ring, unsigned int size)
{
   13cff:	55                   	push   %ebp
   13d00:	89 e5                	mov    %esp,%ebp

	ring->size = size;
   13d02:	8b 45 08             	mov    0x8(%ebp),%eax
   13d05:	8b 55 0c             	mov    0xc(%ebp),%edx
   13d08:	89 90 80 00 00 00    	mov    %edx,0x80(%eax)
	ring->mask = size - 1;
   13d0e:	8b 45 0c             	mov    0xc(%ebp),%eax
   13d11:	8d 50 ff             	lea    -0x1(%eax),%edx
   13d14:	8b 45 08             	mov    0x8(%ebp),%eax
   13d17:	89 90 84 00 00 00    	mov    %edx,0x84(%eax)
	ring->p_tail = 0;
   13d1d:	8b 45 08             	mov    0x8(%ebp),%eax
   13d20:	c7 40 40 00 00 00 00 	movl   $0x0,0x40(%eax)
	ring->p_head = 0;
   13d27:	8b 45 08             	mov    0x8(%ebp),%eax
   13d2a:	c7 40 44 00 00 00 00 	movl   $0x0,0x44(%eax)
	ring->c_head = 0;
   13d31:	8b 45 08             	mov    0x8(%ebp),%eax
   13d34:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
	return;
   13d3a:	90                   	nop
}
   13d3b:	5d                   	pop    %ebp
   13d3c:	c3                   	ret    

00013d3d <ck_ring_enqueue_spsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   13d3d:	55                   	push   %ebp
   13d3e:	89 e5                	mov    %esp,%ebp
   13d40:	83 ec 58             	sub    $0x58,%esp
   13d43:	8b 45 08             	mov    0x8(%ebp),%eax
   13d46:	89 45 f4             	mov    %eax,-0xc(%ebp)
   13d49:	8b 45 0c             	mov    0xc(%ebp),%eax
   13d4c:	89 45 f0             	mov    %eax,-0x10(%ebp)
   13d4f:	8d 45 10             	lea    0x10(%ebp),%eax
   13d52:	89 45 ec             	mov    %eax,-0x14(%ebp)
   13d55:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   13d5c:	8b 45 14             	mov    0x14(%ebp),%eax
   13d5f:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   13d62:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13d65:	89 45 e0             	mov    %eax,-0x20(%ebp)
   13d68:	8b 45 f0             	mov    -0x10(%ebp),%eax
   13d6b:	89 45 dc             	mov    %eax,-0x24(%ebp)
   13d6e:	8b 45 ec             	mov    -0x14(%ebp),%eax
   13d71:	89 45 d8             	mov    %eax,-0x28(%ebp)
   13d74:	8b 45 e8             	mov    -0x18(%ebp),%eax
   13d77:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   13d7a:	8d 45 b8             	lea    -0x48(%ebp),%eax
   13d7d:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   13d80:	8b 45 e0             	mov    -0x20(%ebp),%eax
   13d83:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   13d89:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   13d8c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   13d8f:	89 04 24             	mov    %eax,(%esp)
   13d92:	e8 b7 f1 ff ff       	call   12f4e <ck_pr_md_load_uint>
   13d97:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   13d9a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   13d9d:	8b 40 40             	mov    0x40(%eax),%eax
   13da0:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   13da3:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   13da6:	83 c0 01             	add    $0x1,%eax
   13da9:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   13dac:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   13db0:	74 14                	je     13dc6 <ck_ring_enqueue_spsc_size+0x89>
		*size = (producer - consumer) & mask;
   13db2:	8b 45 c8             	mov    -0x38(%ebp),%eax
   13db5:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   13db8:	29 c2                	sub    %eax,%edx
   13dba:	89 d0                	mov    %edx,%eax
   13dbc:	23 45 cc             	and    -0x34(%ebp),%eax
   13dbf:	89 c2                	mov    %eax,%edx
   13dc1:	8b 45 d0             	mov    -0x30(%ebp),%eax
   13dc4:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   13dc6:	8b 45 c0             	mov    -0x40(%ebp),%eax
   13dc9:	8b 55 c8             	mov    -0x38(%ebp),%edx
   13dcc:	31 d0                	xor    %edx,%eax
   13dce:	23 45 cc             	and    -0x34(%ebp),%eax
   13dd1:	85 c0                	test   %eax,%eax
   13dd3:	0f 94 c0             	sete   %al
   13dd6:	0f b6 c0             	movzbl %al,%eax
   13dd9:	85 c0                	test   %eax,%eax
   13ddb:	74 07                	je     13de4 <ck_ring_enqueue_spsc_size+0xa7>
		return false;
   13ddd:	b8 00 00 00 00       	mov    $0x0,%eax
   13de2:	eb 47                	jmp    13e2b <ck_ring_enqueue_spsc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   13de4:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   13de7:	8b 55 cc             	mov    -0x34(%ebp),%edx
   13dea:	21 d0                	and    %edx,%eax
   13dec:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   13df0:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   13df3:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   13df6:	89 44 24 08          	mov    %eax,0x8(%esp)
   13dfa:	8b 45 d8             	mov    -0x28(%ebp),%eax
   13dfd:	89 44 24 04          	mov    %eax,0x4(%esp)
   13e01:	8b 45 dc             	mov    -0x24(%ebp),%eax
   13e04:	89 04 24             	mov    %eax,(%esp)
   13e07:	e8 fc ff ff ff       	call   13e08 <ck_ring_enqueue_spsc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   13e0c:	e8 53 fe ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   13e11:	8b 45 e0             	mov    -0x20(%ebp),%eax
   13e14:	8d 50 40             	lea    0x40(%eax),%edx
   13e17:	8b 45 c0             	mov    -0x40(%ebp),%eax
   13e1a:	89 44 24 04          	mov    %eax,0x4(%esp)
   13e1e:	89 14 24             	mov    %edx,(%esp)
   13e21:	e8 b1 f1 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   13e26:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   13e2b:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   13e2e:	8b 55 b8             	mov    -0x48(%ebp),%edx
   13e31:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   13e34:	89 10                	mov    %edx,(%eax)
	return r;
   13e36:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   13e3a:	c9                   	leave  
   13e3b:	c3                   	ret    

00013e3c <ck_ring_enqueue_spsc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   13e3c:	55                   	push   %ebp
   13e3d:	89 e5                	mov    %esp,%ebp
   13e3f:	83 ec 48             	sub    $0x48,%esp
   13e42:	8b 45 08             	mov    0x8(%ebp),%eax
   13e45:	89 45 f4             	mov    %eax,-0xc(%ebp)
   13e48:	8b 45 0c             	mov    0xc(%ebp),%eax
   13e4b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   13e4e:	8d 45 10             	lea    0x10(%ebp),%eax
   13e51:	89 45 ec             	mov    %eax,-0x14(%ebp)
   13e54:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   13e5b:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   13e62:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13e65:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   13e6b:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   13e6e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13e71:	89 04 24             	mov    %eax,(%esp)
   13e74:	e8 d5 f0 ff ff       	call   12f4e <ck_pr_md_load_uint>
   13e79:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   13e7c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13e7f:	8b 40 40             	mov    0x40(%eax),%eax
   13e82:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   13e85:	8b 45 d8             	mov    -0x28(%ebp),%eax
   13e88:	83 c0 01             	add    $0x1,%eax
   13e8b:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   13e8e:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   13e92:	74 14                	je     13ea8 <ck_ring_enqueue_spsc+0x6c>
		*size = (producer - consumer) & mask;
   13e94:	8b 45 dc             	mov    -0x24(%ebp),%eax
   13e97:	8b 55 d8             	mov    -0x28(%ebp),%edx
   13e9a:	29 c2                	sub    %eax,%edx
   13e9c:	89 d0                	mov    %edx,%eax
   13e9e:	23 45 e0             	and    -0x20(%ebp),%eax
   13ea1:	89 c2                	mov    %eax,%edx
   13ea3:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   13ea6:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   13ea8:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   13eab:	8b 55 dc             	mov    -0x24(%ebp),%edx
   13eae:	31 d0                	xor    %edx,%eax
   13eb0:	23 45 e0             	and    -0x20(%ebp),%eax
   13eb3:	85 c0                	test   %eax,%eax
   13eb5:	0f 94 c0             	sete   %al
   13eb8:	0f b6 c0             	movzbl %al,%eax
   13ebb:	85 c0                	test   %eax,%eax
   13ebd:	74 07                	je     13ec6 <ck_ring_enqueue_spsc+0x8a>
		return false;
   13ebf:	b8 00 00 00 00       	mov    $0x0,%eax
   13ec4:	eb 47                	jmp    13f0d <ck_ring_enqueue_spsc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   13ec6:	8b 45 d8             	mov    -0x28(%ebp),%eax
   13ec9:	8b 55 e0             	mov    -0x20(%ebp),%edx
   13ecc:	21 d0                	and    %edx,%eax
   13ece:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   13ed2:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   13ed5:	8b 45 e8             	mov    -0x18(%ebp),%eax
   13ed8:	89 44 24 08          	mov    %eax,0x8(%esp)
   13edc:	8b 45 ec             	mov    -0x14(%ebp),%eax
   13edf:	89 44 24 04          	mov    %eax,0x4(%esp)
   13ee3:	8b 45 f0             	mov    -0x10(%ebp),%eax
   13ee6:	89 04 24             	mov    %eax,(%esp)
   13ee9:	e8 fc ff ff ff       	call   13eea <ck_ring_enqueue_spsc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   13eee:	e8 71 fd ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   13ef3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13ef6:	8d 50 40             	lea    0x40(%eax),%edx
   13ef9:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   13efc:	89 44 24 04          	mov    %eax,0x4(%esp)
   13f00:	89 14 24             	mov    %edx,(%esp)
   13f03:	e8 cf f0 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   13f08:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer,
	    &entry, sizeof(entry), NULL);
}
   13f0d:	c9                   	leave  
   13f0e:	c3                   	ret    

00013f0f <ck_ring_dequeue_spsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   13f0f:	55                   	push   %ebp
   13f10:	89 e5                	mov    %esp,%ebp
   13f12:	83 ec 38             	sub    $0x38,%esp
   13f15:	8b 45 08             	mov    0x8(%ebp),%eax
   13f18:	89 45 f4             	mov    %eax,-0xc(%ebp)
   13f1b:	8b 45 0c             	mov    0xc(%ebp),%eax
   13f1e:	89 45 f0             	mov    %eax,-0x10(%ebp)
   13f21:	8b 45 10             	mov    0x10(%ebp),%eax
   13f24:	89 45 ec             	mov    %eax,-0x14(%ebp)
   13f27:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   13f2e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13f31:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   13f37:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   13f3a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13f3d:	8b 00                	mov    (%eax),%eax
   13f3f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   13f42:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13f45:	83 c0 40             	add    $0x40,%eax
   13f48:	89 04 24             	mov    %eax,(%esp)
   13f4b:	e8 fe ef ff ff       	call   12f4e <ck_pr_md_load_uint>
   13f50:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   13f53:	8b 45 e0             	mov    -0x20(%ebp),%eax
   13f56:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   13f59:	0f 94 c0             	sete   %al
   13f5c:	0f b6 c0             	movzbl %al,%eax
   13f5f:	85 c0                	test   %eax,%eax
   13f61:	74 07                	je     13f6a <ck_ring_dequeue_spsc+0x5b>
		return false;
   13f63:	b8 00 00 00 00       	mov    $0x0,%eax
   13f68:	eb 4c                	jmp    13fb6 <ck_ring_dequeue_spsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   13f6a:	e8 ea fc ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   13f6f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   13f72:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   13f75:	21 d0                	and    %edx,%eax
   13f77:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   13f7b:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   13f7e:	8b 45 e8             	mov    -0x18(%ebp),%eax
   13f81:	89 44 24 08          	mov    %eax,0x8(%esp)
   13f85:	8b 45 f0             	mov    -0x10(%ebp),%eax
   13f88:	89 44 24 04          	mov    %eax,0x4(%esp)
   13f8c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   13f8f:	89 04 24             	mov    %eax,(%esp)
   13f92:	e8 fc ff ff ff       	call   13f93 <ck_ring_dequeue_spsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   13f97:	e8 c8 fc ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   13f9c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   13f9f:	8d 50 01             	lea    0x1(%eax),%edx
   13fa2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13fa5:	89 54 24 04          	mov    %edx,0x4(%esp)
   13fa9:	89 04 24             	mov    %eax,(%esp)
   13fac:	e8 26 f0 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   13fb1:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer,
	    (void **)data, sizeof(void *));
}
   13fb6:	c9                   	leave  
   13fb7:	c3                   	ret    

00013fb8 <ck_ring_enqueue_mpmc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   13fb8:	55                   	push   %ebp
   13fb9:	89 e5                	mov    %esp,%ebp
   13fbb:	83 ec 48             	sub    $0x48,%esp
   13fbe:	8b 45 08             	mov    0x8(%ebp),%eax
   13fc1:	89 45 f4             	mov    %eax,-0xc(%ebp)
   13fc4:	8b 45 0c             	mov    0xc(%ebp),%eax
   13fc7:	89 45 f0             	mov    %eax,-0x10(%ebp)
   13fca:	8d 45 10             	lea    0x10(%ebp),%eax
   13fcd:	89 45 ec             	mov    %eax,-0x14(%ebp)
   13fd0:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   13fd7:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   13fde:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13fe1:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   13fe7:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   13fea:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   13fee:	8b 45 f4             	mov    -0xc(%ebp),%eax
   13ff1:	83 c0 44             	add    $0x44,%eax
   13ff4:	89 04 24             	mov    %eax,(%esp)
   13ff7:	e8 52 ef ff ff       	call   12f4e <ck_pr_md_load_uint>
   13ffc:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   13fff:	e8 55 fc ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   14004:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14007:	89 04 24             	mov    %eax,(%esp)
   1400a:	e8 3f ef ff ff       	call   12f4e <ck_pr_md_load_uint>
   1400f:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   14012:	8b 45 cc             	mov    -0x34(%ebp),%eax
   14015:	83 c0 01             	add    $0x1,%eax
   14018:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1401b:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1401e:	2b 45 d8             	sub    -0x28(%ebp),%eax
   14021:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   14024:	0f 97 c0             	seta   %al
   14027:	0f b6 c0             	movzbl %al,%eax
   1402a:	85 c0                	test   %eax,%eax
   1402c:	74 29                	je     14057 <ck_ring_enqueue_mpmc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1402e:	8b 45 cc             	mov    -0x34(%ebp),%eax
   14031:	8b 55 f4             	mov    -0xc(%ebp),%edx
   14034:	8d 4a 44             	lea    0x44(%edx),%ecx
   14037:	8d 55 cc             	lea    -0x34(%ebp),%edx
   1403a:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1403e:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   14041:	89 54 24 08          	mov    %edx,0x8(%esp)
   14045:	89 44 24 04          	mov    %eax,0x4(%esp)
   14049:	89 0c 24             	mov    %ecx,(%esp)
   1404c:	e8 fe f8 ff ff       	call   1394f <ck_pr_cas_uint_value>
   14051:	84 c0                	test   %al,%al
   14053:	75 31                	jne    14086 <ck_ring_enqueue_mpmc+0xce>
   14055:	eb a8                	jmp    13fff <ck_ring_enqueue_mpmc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   14057:	e8 fd fb ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1405c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1405f:	83 c0 44             	add    $0x44,%eax
   14062:	89 04 24             	mov    %eax,(%esp)
   14065:	e8 e4 ee ff ff       	call   12f4e <ck_pr_md_load_uint>
   1406a:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1406d:	8b 45 cc             	mov    -0x34(%ebp),%eax
   14070:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   14073:	75 06                	jne    1407b <ck_ring_enqueue_mpmc+0xc3>
				r = false;
   14075:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   14079:	eb 67                	jmp    140e2 <ck_ring_enqueue_mpmc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1407b:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1407e:	89 45 cc             	mov    %eax,-0x34(%ebp)
   14081:	e9 79 ff ff ff       	jmp    13fff <ck_ring_enqueue_mpmc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   14086:	8b 45 cc             	mov    -0x34(%ebp),%eax
   14089:	23 45 e0             	and    -0x20(%ebp),%eax
   1408c:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14090:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   14093:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14096:	89 44 24 08          	mov    %eax,0x8(%esp)
   1409a:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1409d:	89 44 24 04          	mov    %eax,0x4(%esp)
   140a1:	8b 45 f0             	mov    -0x10(%ebp),%eax
   140a4:	89 04 24             	mov    %eax,(%esp)
   140a7:	e8 fc ff ff ff       	call   140a8 <ck_ring_enqueue_mpmc+0xf0>
   140ac:	eb 05                	jmp    140b3 <ck_ring_enqueue_mpmc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   140ae:	e8 36 ed ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   140b3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   140b6:	83 c0 40             	add    $0x40,%eax
   140b9:	89 04 24             	mov    %eax,(%esp)
   140bc:	e8 8d ee ff ff       	call   12f4e <ck_pr_md_load_uint>
   140c1:	8b 55 cc             	mov    -0x34(%ebp),%edx
   140c4:	39 d0                	cmp    %edx,%eax
   140c6:	75 e6                	jne    140ae <ck_ring_enqueue_mpmc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   140c8:	e8 97 fb ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   140cd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   140d0:	8d 50 40             	lea    0x40(%eax),%edx
   140d3:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   140d6:	89 44 24 04          	mov    %eax,0x4(%esp)
   140da:	89 14 24             	mov    %edx,(%esp)
   140dd:	e8 f5 ee ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   140e2:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   140e6:	74 10                	je     140f8 <ck_ring_enqueue_mpmc+0x140>
		*size = (producer - consumer) & mask;
   140e8:	8b 45 cc             	mov    -0x34(%ebp),%eax
   140eb:	2b 45 d8             	sub    -0x28(%ebp),%eax
   140ee:	23 45 e0             	and    -0x20(%ebp),%eax
   140f1:	89 c2                	mov    %eax,%edx
   140f3:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   140f6:	89 10                	mov    %edx,(%eax)

	return r;
   140f8:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   140fc:	c9                   	leave  
   140fd:	c3                   	ret    

000140fe <ck_ring_enqueue_mpmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   140fe:	55                   	push   %ebp
   140ff:	89 e5                	mov    %esp,%ebp
   14101:	83 ec 68             	sub    $0x68,%esp
   14104:	8b 45 08             	mov    0x8(%ebp),%eax
   14107:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1410a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1410d:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14110:	8d 45 10             	lea    0x10(%ebp),%eax
   14113:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14116:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1411d:	8b 45 14             	mov    0x14(%ebp),%eax
   14120:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   14123:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14126:	89 45 e0             	mov    %eax,-0x20(%ebp)
   14129:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1412c:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1412f:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14132:	89 45 d8             	mov    %eax,-0x28(%ebp)
   14135:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14138:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1413b:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1413e:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   14141:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14144:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1414a:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1414d:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   14151:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14154:	83 c0 44             	add    $0x44,%eax
   14157:	89 04 24             	mov    %eax,(%esp)
   1415a:	e8 ef ed ff ff       	call   12f4e <ck_pr_md_load_uint>
   1415f:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   14162:	e8 f2 fa ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   14167:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1416a:	89 04 24             	mov    %eax,(%esp)
   1416d:	e8 dc ed ff ff       	call   12f4e <ck_pr_md_load_uint>
   14172:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   14175:	8b 45 b0             	mov    -0x50(%ebp),%eax
   14178:	83 c0 01             	add    $0x1,%eax
   1417b:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1417e:	8b 45 b0             	mov    -0x50(%ebp),%eax
   14181:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   14184:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   14187:	0f 97 c0             	seta   %al
   1418a:	0f b6 c0             	movzbl %al,%eax
   1418d:	85 c0                	test   %eax,%eax
   1418f:	74 29                	je     141ba <ck_ring_enqueue_mpmc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   14191:	8b 45 b0             	mov    -0x50(%ebp),%eax
   14194:	8b 55 e0             	mov    -0x20(%ebp),%edx
   14197:	8d 4a 44             	lea    0x44(%edx),%ecx
   1419a:	8d 55 b0             	lea    -0x50(%ebp),%edx
   1419d:	89 54 24 0c          	mov    %edx,0xc(%esp)
   141a1:	8b 55 c0             	mov    -0x40(%ebp),%edx
   141a4:	89 54 24 08          	mov    %edx,0x8(%esp)
   141a8:	89 44 24 04          	mov    %eax,0x4(%esp)
   141ac:	89 0c 24             	mov    %ecx,(%esp)
   141af:	e8 9b f7 ff ff       	call   1394f <ck_pr_cas_uint_value>
   141b4:	84 c0                	test   %al,%al
   141b6:	75 31                	jne    141e9 <ck_ring_enqueue_mpmc_size+0xeb>
   141b8:	eb a8                	jmp    14162 <ck_ring_enqueue_mpmc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   141ba:	e8 9a fa ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   141bf:	8b 45 e0             	mov    -0x20(%ebp),%eax
   141c2:	83 c0 44             	add    $0x44,%eax
   141c5:	89 04 24             	mov    %eax,(%esp)
   141c8:	e8 81 ed ff ff       	call   12f4e <ck_pr_md_load_uint>
   141cd:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   141d0:	8b 45 b0             	mov    -0x50(%ebp),%eax
   141d3:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   141d6:	75 06                	jne    141de <ck_ring_enqueue_mpmc_size+0xe0>
				r = false;
   141d8:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   141dc:	eb 67                	jmp    14245 <ck_ring_enqueue_mpmc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   141de:	8b 45 bc             	mov    -0x44(%ebp),%eax
   141e1:	89 45 b0             	mov    %eax,-0x50(%ebp)
   141e4:	e9 79 ff ff ff       	jmp    14162 <ck_ring_enqueue_mpmc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   141e9:	8b 45 b0             	mov    -0x50(%ebp),%eax
   141ec:	23 45 cc             	and    -0x34(%ebp),%eax
   141ef:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   141f3:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   141f6:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   141f9:	89 44 24 08          	mov    %eax,0x8(%esp)
   141fd:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14200:	89 44 24 04          	mov    %eax,0x4(%esp)
   14204:	8b 45 dc             	mov    -0x24(%ebp),%eax
   14207:	89 04 24             	mov    %eax,(%esp)
   1420a:	e8 fc ff ff ff       	call   1420b <ck_ring_enqueue_mpmc_size+0x10d>
   1420f:	eb 05                	jmp    14216 <ck_ring_enqueue_mpmc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   14211:	e8 d3 eb ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   14216:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14219:	83 c0 40             	add    $0x40,%eax
   1421c:	89 04 24             	mov    %eax,(%esp)
   1421f:	e8 2a ed ff ff       	call   12f4e <ck_pr_md_load_uint>
   14224:	8b 55 b0             	mov    -0x50(%ebp),%edx
   14227:	39 d0                	cmp    %edx,%eax
   14229:	75 e6                	jne    14211 <ck_ring_enqueue_mpmc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1422b:	e8 34 fa ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   14230:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14233:	8d 50 40             	lea    0x40(%eax),%edx
   14236:	8b 45 c0             	mov    -0x40(%ebp),%eax
   14239:	89 44 24 04          	mov    %eax,0x4(%esp)
   1423d:	89 14 24             	mov    %edx,(%esp)
   14240:	e8 92 ed ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   14245:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   14249:	74 10                	je     1425b <ck_ring_enqueue_mpmc_size+0x15d>
		*size = (producer - consumer) & mask;
   1424b:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1424e:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   14251:	23 45 cc             	and    -0x34(%ebp),%eax
   14254:	89 c2                	mov    %eax,%edx
   14256:	8b 45 d0             	mov    -0x30(%ebp),%eax
   14259:	89 10                	mov    %edx,(%eax)

	return r;
   1425b:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   1425f:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   14262:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   14265:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   14268:	89 10                	mov    %edx,(%eax)
	return r;
   1426a:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   1426e:	c9                   	leave  
   1426f:	c3                   	ret    

00014270 <ck_ring_trydequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   14270:	55                   	push   %ebp
   14271:	89 e5                	mov    %esp,%ebp
   14273:	83 ec 38             	sub    $0x38,%esp
   14276:	8b 45 08             	mov    0x8(%ebp),%eax
   14279:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1427c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1427f:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14282:	8b 45 10             	mov    0x10(%ebp),%eax
   14285:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14288:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1428f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14292:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14298:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1429b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1429e:	89 04 24             	mov    %eax,(%esp)
   142a1:	e8 a8 ec ff ff       	call   12f4e <ck_pr_md_load_uint>
   142a6:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   142a9:	e8 ab f9 ff ff       	call   13c59 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   142ae:	8b 45 f4             	mov    -0xc(%ebp),%eax
   142b1:	83 c0 40             	add    $0x40,%eax
   142b4:	89 04 24             	mov    %eax,(%esp)
   142b7:	e8 92 ec ff ff       	call   12f4e <ck_pr_md_load_uint>
   142bc:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   142bf:	8b 45 e0             	mov    -0x20(%ebp),%eax
   142c2:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   142c5:	0f 94 c0             	sete   %al
   142c8:	0f b6 c0             	movzbl %al,%eax
   142cb:	85 c0                	test   %eax,%eax
   142cd:	74 07                	je     142d6 <ck_ring_trydequeue_mpmc+0x66>
		return false;
   142cf:	b8 00 00 00 00       	mov    $0x0,%eax
   142d4:	eb 4e                	jmp    14324 <ck_ring_trydequeue_mpmc+0xb4>

	ck_pr_fence_load();
   142d6:	e8 7e f9 ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   142db:	8b 45 e0             	mov    -0x20(%ebp),%eax
   142de:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   142e1:	21 d0                	and    %edx,%eax
   142e3:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   142e7:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   142ea:	8b 45 e8             	mov    -0x18(%ebp),%eax
   142ed:	89 44 24 08          	mov    %eax,0x8(%esp)
   142f1:	8b 45 f0             	mov    -0x10(%ebp),%eax
   142f4:	89 44 24 04          	mov    %eax,0x4(%esp)
   142f8:	8b 45 ec             	mov    -0x14(%ebp),%eax
   142fb:	89 04 24             	mov    %eax,(%esp)
   142fe:	e8 fc ff ff ff       	call   142ff <ck_ring_trydequeue_mpmc+0x8f>

	ck_pr_fence_store_atomic();
   14303:	e8 25 f9 ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   14308:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1430b:	8d 50 01             	lea    0x1(%eax),%edx
   1430e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14311:	89 54 24 08          	mov    %edx,0x8(%esp)
   14315:	8b 55 e0             	mov    -0x20(%ebp),%edx
   14318:	89 54 24 04          	mov    %edx,0x4(%esp)
   1431c:	89 04 24             	mov    %eax,(%esp)
   1431f:	e8 d8 f4 ff ff       	call   137fc <ck_pr_cas_uint>
    void *data)
{

	return _ck_ring_trydequeue_mc(ring,
	    buffer, (void **)data, sizeof(void *));
}
   14324:	c9                   	leave  
   14325:	c3                   	ret    

00014326 <ck_ring_dequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   14326:	55                   	push   %ebp
   14327:	89 e5                	mov    %esp,%ebp
   14329:	53                   	push   %ebx
   1432a:	83 ec 34             	sub    $0x34,%esp
   1432d:	8b 45 08             	mov    0x8(%ebp),%eax
   14330:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14333:	8b 45 0c             	mov    0xc(%ebp),%eax
   14336:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14339:	8b 45 10             	mov    0x10(%ebp),%eax
   1433c:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1433f:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   14346:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14349:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1434f:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   14352:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14355:	89 04 24             	mov    %eax,(%esp)
   14358:	e8 f1 eb ff ff       	call   12f4e <ck_pr_md_load_uint>
   1435d:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   14360:	e8 f4 f8 ff ff       	call   13c59 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   14365:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14368:	83 c0 40             	add    $0x40,%eax
   1436b:	89 04 24             	mov    %eax,(%esp)
   1436e:	e8 db eb ff ff       	call   12f4e <ck_pr_md_load_uint>
   14373:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   14376:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14379:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1437c:	0f 94 c0             	sete   %al
   1437f:	0f b6 c0             	movzbl %al,%eax
   14382:	85 c0                	test   %eax,%eax
   14384:	74 07                	je     1438d <ck_ring_dequeue_mpmc+0x67>
			return false;
   14386:	b8 00 00 00 00       	mov    $0x0,%eax
   1438b:	eb 6a                	jmp    143f7 <ck_ring_dequeue_mpmc+0xd1>

		ck_pr_fence_load();
   1438d:	e8 c7 f8 ff ff       	call   13c59 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   14392:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14395:	23 45 e4             	and    -0x1c(%ebp),%eax
   14398:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1439c:	89 c2                	mov    %eax,%edx
   1439e:	8b 45 f0             	mov    -0x10(%ebp),%eax
   143a1:	01 d0                	add    %edx,%eax
   143a3:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   143a6:	8b 45 e8             	mov    -0x18(%ebp),%eax
   143a9:	89 44 24 08          	mov    %eax,0x8(%esp)
   143ad:	8b 45 dc             	mov    -0x24(%ebp),%eax
   143b0:	89 44 24 04          	mov    %eax,0x4(%esp)
   143b4:	8b 45 ec             	mov    -0x14(%ebp),%eax
   143b7:	89 04 24             	mov    %eax,(%esp)
   143ba:	e8 fc ff ff ff       	call   143bb <ck_ring_dequeue_mpmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   143bf:	e8 69 f8 ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   143c4:	8b 45 d8             	mov    -0x28(%ebp),%eax
   143c7:	8d 58 01             	lea    0x1(%eax),%ebx
   143ca:	8b 55 d8             	mov    -0x28(%ebp),%edx
   143cd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   143d0:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   143d3:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   143d7:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   143db:	89 54 24 04          	mov    %edx,0x4(%esp)
   143df:	89 04 24             	mov    %eax,(%esp)
   143e2:	e8 68 f5 ff ff       	call   1394f <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   143e7:	83 f0 01             	xor    $0x1,%eax
   143ea:	84 c0                	test   %al,%al
   143ec:	0f 85 6e ff ff ff    	jne    14360 <ck_ring_dequeue_mpmc+0x3a>

	return true;
   143f2:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   143f7:	83 c4 34             	add    $0x34,%esp
   143fa:	5b                   	pop    %ebx
   143fb:	5d                   	pop    %ebp
   143fc:	c3                   	ret    

000143fd <ck_ring_enqueue_spmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   143fd:	55                   	push   %ebp
   143fe:	89 e5                	mov    %esp,%ebp
   14400:	83 ec 58             	sub    $0x58,%esp
   14403:	8b 45 08             	mov    0x8(%ebp),%eax
   14406:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14409:	8b 45 0c             	mov    0xc(%ebp),%eax
   1440c:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1440f:	8d 45 10             	lea    0x10(%ebp),%eax
   14412:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14415:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1441c:	8b 45 14             	mov    0x14(%ebp),%eax
   1441f:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   14422:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14425:	89 45 e0             	mov    %eax,-0x20(%ebp)
   14428:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1442b:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1442e:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14431:	89 45 d8             	mov    %eax,-0x28(%ebp)
   14434:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14437:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1443a:	8d 45 b8             	lea    -0x48(%ebp),%eax
   1443d:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   14440:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14443:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14449:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1444c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1444f:	89 04 24             	mov    %eax,(%esp)
   14452:	e8 f7 ea ff ff       	call   12f4e <ck_pr_md_load_uint>
   14457:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   1445a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1445d:	8b 40 40             	mov    0x40(%eax),%eax
   14460:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   14463:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   14466:	83 c0 01             	add    $0x1,%eax
   14469:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   1446c:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   14470:	74 14                	je     14486 <ck_ring_enqueue_spmc_size+0x89>
		*size = (producer - consumer) & mask;
   14472:	8b 45 c8             	mov    -0x38(%ebp),%eax
   14475:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   14478:	29 c2                	sub    %eax,%edx
   1447a:	89 d0                	mov    %edx,%eax
   1447c:	23 45 cc             	and    -0x34(%ebp),%eax
   1447f:	89 c2                	mov    %eax,%edx
   14481:	8b 45 d0             	mov    -0x30(%ebp),%eax
   14484:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   14486:	8b 45 c0             	mov    -0x40(%ebp),%eax
   14489:	8b 55 c8             	mov    -0x38(%ebp),%edx
   1448c:	31 d0                	xor    %edx,%eax
   1448e:	23 45 cc             	and    -0x34(%ebp),%eax
   14491:	85 c0                	test   %eax,%eax
   14493:	0f 94 c0             	sete   %al
   14496:	0f b6 c0             	movzbl %al,%eax
   14499:	85 c0                	test   %eax,%eax
   1449b:	74 07                	je     144a4 <ck_ring_enqueue_spmc_size+0xa7>
		return false;
   1449d:	b8 00 00 00 00       	mov    $0x0,%eax
   144a2:	eb 47                	jmp    144eb <ck_ring_enqueue_spmc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   144a4:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   144a7:	8b 55 cc             	mov    -0x34(%ebp),%edx
   144aa:	21 d0                	and    %edx,%eax
   144ac:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   144b0:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   144b3:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   144b6:	89 44 24 08          	mov    %eax,0x8(%esp)
   144ba:	8b 45 d8             	mov    -0x28(%ebp),%eax
   144bd:	89 44 24 04          	mov    %eax,0x4(%esp)
   144c1:	8b 45 dc             	mov    -0x24(%ebp),%eax
   144c4:	89 04 24             	mov    %eax,(%esp)
   144c7:	e8 fc ff ff ff       	call   144c8 <ck_ring_enqueue_spmc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   144cc:	e8 93 f7 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   144d1:	8b 45 e0             	mov    -0x20(%ebp),%eax
   144d4:	8d 50 40             	lea    0x40(%eax),%edx
   144d7:	8b 45 c0             	mov    -0x40(%ebp),%eax
   144da:	89 44 24 04          	mov    %eax,0x4(%esp)
   144de:	89 14 24             	mov    %edx,(%esp)
   144e1:	e8 f1 ea ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   144e6:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   144eb:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   144ee:	8b 55 b8             	mov    -0x48(%ebp),%edx
   144f1:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   144f4:	89 10                	mov    %edx,(%eax)
	return r;
   144f6:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   144fa:	c9                   	leave  
   144fb:	c3                   	ret    

000144fc <ck_ring_enqueue_spmc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   144fc:	55                   	push   %ebp
   144fd:	89 e5                	mov    %esp,%ebp
   144ff:	83 ec 48             	sub    $0x48,%esp
   14502:	8b 45 08             	mov    0x8(%ebp),%eax
   14505:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14508:	8b 45 0c             	mov    0xc(%ebp),%eax
   1450b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1450e:	8d 45 10             	lea    0x10(%ebp),%eax
   14511:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14514:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1451b:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   14522:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14525:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1452b:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1452e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14531:	89 04 24             	mov    %eax,(%esp)
   14534:	e8 15 ea ff ff       	call   12f4e <ck_pr_md_load_uint>
   14539:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   1453c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1453f:	8b 40 40             	mov    0x40(%eax),%eax
   14542:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   14545:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14548:	83 c0 01             	add    $0x1,%eax
   1454b:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   1454e:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   14552:	74 14                	je     14568 <ck_ring_enqueue_spmc+0x6c>
		*size = (producer - consumer) & mask;
   14554:	8b 45 dc             	mov    -0x24(%ebp),%eax
   14557:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1455a:	29 c2                	sub    %eax,%edx
   1455c:	89 d0                	mov    %edx,%eax
   1455e:	23 45 e0             	and    -0x20(%ebp),%eax
   14561:	89 c2                	mov    %eax,%edx
   14563:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   14566:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   14568:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1456b:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1456e:	31 d0                	xor    %edx,%eax
   14570:	23 45 e0             	and    -0x20(%ebp),%eax
   14573:	85 c0                	test   %eax,%eax
   14575:	0f 94 c0             	sete   %al
   14578:	0f b6 c0             	movzbl %al,%eax
   1457b:	85 c0                	test   %eax,%eax
   1457d:	74 07                	je     14586 <ck_ring_enqueue_spmc+0x8a>
		return false;
   1457f:	b8 00 00 00 00       	mov    $0x0,%eax
   14584:	eb 47                	jmp    145cd <ck_ring_enqueue_spmc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   14586:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14589:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1458c:	21 d0                	and    %edx,%eax
   1458e:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14592:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   14595:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14598:	89 44 24 08          	mov    %eax,0x8(%esp)
   1459c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1459f:	89 44 24 04          	mov    %eax,0x4(%esp)
   145a3:	8b 45 f0             	mov    -0x10(%ebp),%eax
   145a6:	89 04 24             	mov    %eax,(%esp)
   145a9:	e8 fc ff ff ff       	call   145aa <ck_ring_enqueue_spmc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   145ae:	e8 b1 f6 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   145b3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   145b6:	8d 50 40             	lea    0x40(%eax),%edx
   145b9:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   145bc:	89 44 24 04          	mov    %eax,0x4(%esp)
   145c0:	89 14 24             	mov    %edx,(%esp)
   145c3:	e8 0f ea ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   145c8:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   145cd:	c9                   	leave  
   145ce:	c3                   	ret    

000145cf <ck_ring_trydequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   145cf:	55                   	push   %ebp
   145d0:	89 e5                	mov    %esp,%ebp
   145d2:	83 ec 38             	sub    $0x38,%esp
   145d5:	8b 45 08             	mov    0x8(%ebp),%eax
   145d8:	89 45 f4             	mov    %eax,-0xc(%ebp)
   145db:	8b 45 0c             	mov    0xc(%ebp),%eax
   145de:	89 45 f0             	mov    %eax,-0x10(%ebp)
   145e1:	8b 45 10             	mov    0x10(%ebp),%eax
   145e4:	89 45 ec             	mov    %eax,-0x14(%ebp)
   145e7:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   145ee:	8b 45 f4             	mov    -0xc(%ebp),%eax
   145f1:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   145f7:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   145fa:	8b 45 f4             	mov    -0xc(%ebp),%eax
   145fd:	89 04 24             	mov    %eax,(%esp)
   14600:	e8 49 e9 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14605:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   14608:	e8 4c f6 ff ff       	call   13c59 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   1460d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14610:	83 c0 40             	add    $0x40,%eax
   14613:	89 04 24             	mov    %eax,(%esp)
   14616:	e8 33 e9 ff ff       	call   12f4e <ck_pr_md_load_uint>
   1461b:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1461e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14621:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   14624:	0f 94 c0             	sete   %al
   14627:	0f b6 c0             	movzbl %al,%eax
   1462a:	85 c0                	test   %eax,%eax
   1462c:	74 07                	je     14635 <ck_ring_trydequeue_spmc+0x66>
		return false;
   1462e:	b8 00 00 00 00       	mov    $0x0,%eax
   14633:	eb 4e                	jmp    14683 <ck_ring_trydequeue_spmc+0xb4>

	ck_pr_fence_load();
   14635:	e8 1f f6 ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1463a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1463d:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   14640:	21 d0                	and    %edx,%eax
   14642:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14646:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   14649:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1464c:	89 44 24 08          	mov    %eax,0x8(%esp)
   14650:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14653:	89 44 24 04          	mov    %eax,0x4(%esp)
   14657:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1465a:	89 04 24             	mov    %eax,(%esp)
   1465d:	e8 fc ff ff ff       	call   1465e <ck_ring_trydequeue_spmc+0x8f>

	ck_pr_fence_store_atomic();
   14662:	e8 c6 f5 ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   14667:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1466a:	8d 50 01             	lea    0x1(%eax),%edx
   1466d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14670:	89 54 24 08          	mov    %edx,0x8(%esp)
   14674:	8b 55 e0             	mov    -0x20(%ebp),%edx
   14677:	89 54 24 04          	mov    %edx,0x4(%esp)
   1467b:	89 04 24             	mov    %eax,(%esp)
   1467e:	e8 79 f1 ff ff       	call   137fc <ck_pr_cas_uint>
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_trydequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   14683:	c9                   	leave  
   14684:	c3                   	ret    

00014685 <ck_ring_dequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   14685:	55                   	push   %ebp
   14686:	89 e5                	mov    %esp,%ebp
   14688:	53                   	push   %ebx
   14689:	83 ec 34             	sub    $0x34,%esp
   1468c:	8b 45 08             	mov    0x8(%ebp),%eax
   1468f:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14692:	8b 45 0c             	mov    0xc(%ebp),%eax
   14695:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14698:	8b 45 10             	mov    0x10(%ebp),%eax
   1469b:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1469e:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   146a5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   146a8:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   146ae:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   146b1:	8b 45 f4             	mov    -0xc(%ebp),%eax
   146b4:	89 04 24             	mov    %eax,(%esp)
   146b7:	e8 92 e8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   146bc:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   146bf:	e8 95 f5 ff ff       	call   13c59 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   146c4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   146c7:	83 c0 40             	add    $0x40,%eax
   146ca:	89 04 24             	mov    %eax,(%esp)
   146cd:	e8 7c e8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   146d2:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   146d5:	8b 45 d8             	mov    -0x28(%ebp),%eax
   146d8:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   146db:	0f 94 c0             	sete   %al
   146de:	0f b6 c0             	movzbl %al,%eax
   146e1:	85 c0                	test   %eax,%eax
   146e3:	74 07                	je     146ec <ck_ring_dequeue_spmc+0x67>
			return false;
   146e5:	b8 00 00 00 00       	mov    $0x0,%eax
   146ea:	eb 6a                	jmp    14756 <ck_ring_dequeue_spmc+0xd1>

		ck_pr_fence_load();
   146ec:	e8 68 f5 ff ff       	call   13c59 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   146f1:	8b 45 d8             	mov    -0x28(%ebp),%eax
   146f4:	23 45 e4             	and    -0x1c(%ebp),%eax
   146f7:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   146fb:	89 c2                	mov    %eax,%edx
   146fd:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14700:	01 d0                	add    %edx,%eax
   14702:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   14705:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14708:	89 44 24 08          	mov    %eax,0x8(%esp)
   1470c:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1470f:	89 44 24 04          	mov    %eax,0x4(%esp)
   14713:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14716:	89 04 24             	mov    %eax,(%esp)
   14719:	e8 fc ff ff ff       	call   1471a <ck_ring_dequeue_spmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   1471e:	e8 0a f5 ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   14723:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14726:	8d 58 01             	lea    0x1(%eax),%ebx
   14729:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1472c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1472f:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   14732:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   14736:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1473a:	89 54 24 04          	mov    %edx,0x4(%esp)
   1473e:	89 04 24             	mov    %eax,(%esp)
   14741:	e8 09 f2 ff ff       	call   1394f <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   14746:	83 f0 01             	xor    $0x1,%eax
   14749:	84 c0                	test   %al,%al
   1474b:	0f 85 6e ff ff ff    	jne    146bf <ck_ring_dequeue_spmc+0x3a>

	return true;
   14751:	b8 01 00 00 00       	mov    $0x1,%eax
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   14756:	83 c4 34             	add    $0x34,%esp
   14759:	5b                   	pop    %ebx
   1475a:	5d                   	pop    %ebp
   1475b:	c3                   	ret    

0001475c <ck_ring_enqueue_mpsc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1475c:	55                   	push   %ebp
   1475d:	89 e5                	mov    %esp,%ebp
   1475f:	83 ec 48             	sub    $0x48,%esp
   14762:	8b 45 08             	mov    0x8(%ebp),%eax
   14765:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14768:	8b 45 0c             	mov    0xc(%ebp),%eax
   1476b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1476e:	8d 45 10             	lea    0x10(%ebp),%eax
   14771:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14774:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1477b:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   14782:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14785:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1478b:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1478e:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   14792:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14795:	83 c0 44             	add    $0x44,%eax
   14798:	89 04 24             	mov    %eax,(%esp)
   1479b:	e8 ae e7 ff ff       	call   12f4e <ck_pr_md_load_uint>
   147a0:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   147a3:	e8 b1 f4 ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   147a8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   147ab:	89 04 24             	mov    %eax,(%esp)
   147ae:	e8 9b e7 ff ff       	call   12f4e <ck_pr_md_load_uint>
   147b3:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   147b6:	8b 45 cc             	mov    -0x34(%ebp),%eax
   147b9:	83 c0 01             	add    $0x1,%eax
   147bc:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   147bf:	8b 45 cc             	mov    -0x34(%ebp),%eax
   147c2:	2b 45 d8             	sub    -0x28(%ebp),%eax
   147c5:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   147c8:	0f 97 c0             	seta   %al
   147cb:	0f b6 c0             	movzbl %al,%eax
   147ce:	85 c0                	test   %eax,%eax
   147d0:	74 29                	je     147fb <ck_ring_enqueue_mpsc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   147d2:	8b 45 cc             	mov    -0x34(%ebp),%eax
   147d5:	8b 55 f4             	mov    -0xc(%ebp),%edx
   147d8:	8d 4a 44             	lea    0x44(%edx),%ecx
   147db:	8d 55 cc             	lea    -0x34(%ebp),%edx
   147de:	89 54 24 0c          	mov    %edx,0xc(%esp)
   147e2:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   147e5:	89 54 24 08          	mov    %edx,0x8(%esp)
   147e9:	89 44 24 04          	mov    %eax,0x4(%esp)
   147ed:	89 0c 24             	mov    %ecx,(%esp)
   147f0:	e8 5a f1 ff ff       	call   1394f <ck_pr_cas_uint_value>
   147f5:	84 c0                	test   %al,%al
   147f7:	75 31                	jne    1482a <ck_ring_enqueue_mpsc+0xce>
   147f9:	eb a8                	jmp    147a3 <ck_ring_enqueue_mpsc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   147fb:	e8 59 f4 ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   14800:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14803:	83 c0 44             	add    $0x44,%eax
   14806:	89 04 24             	mov    %eax,(%esp)
   14809:	e8 40 e7 ff ff       	call   12f4e <ck_pr_md_load_uint>
   1480e:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   14811:	8b 45 cc             	mov    -0x34(%ebp),%eax
   14814:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   14817:	75 06                	jne    1481f <ck_ring_enqueue_mpsc+0xc3>
				r = false;
   14819:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1481d:	eb 67                	jmp    14886 <ck_ring_enqueue_mpsc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1481f:	8b 45 d0             	mov    -0x30(%ebp),%eax
   14822:	89 45 cc             	mov    %eax,-0x34(%ebp)
   14825:	e9 79 ff ff ff       	jmp    147a3 <ck_ring_enqueue_mpsc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1482a:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1482d:	23 45 e0             	and    -0x20(%ebp),%eax
   14830:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14834:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   14837:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1483a:	89 44 24 08          	mov    %eax,0x8(%esp)
   1483e:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14841:	89 44 24 04          	mov    %eax,0x4(%esp)
   14845:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14848:	89 04 24             	mov    %eax,(%esp)
   1484b:	e8 fc ff ff ff       	call   1484c <ck_ring_enqueue_mpsc+0xf0>
   14850:	eb 05                	jmp    14857 <ck_ring_enqueue_mpsc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   14852:	e8 92 e5 ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   14857:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1485a:	83 c0 40             	add    $0x40,%eax
   1485d:	89 04 24             	mov    %eax,(%esp)
   14860:	e8 e9 e6 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14865:	8b 55 cc             	mov    -0x34(%ebp),%edx
   14868:	39 d0                	cmp    %edx,%eax
   1486a:	75 e6                	jne    14852 <ck_ring_enqueue_mpsc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1486c:	e8 f3 f3 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   14871:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14874:	8d 50 40             	lea    0x40(%eax),%edx
   14877:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1487a:	89 44 24 04          	mov    %eax,0x4(%esp)
   1487e:	89 14 24             	mov    %edx,(%esp)
   14881:	e8 51 e7 ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   14886:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1488a:	74 10                	je     1489c <ck_ring_enqueue_mpsc+0x140>
		*size = (producer - consumer) & mask;
   1488c:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1488f:	2b 45 d8             	sub    -0x28(%ebp),%eax
   14892:	23 45 e0             	and    -0x20(%ebp),%eax
   14895:	89 c2                	mov    %eax,%edx
   14897:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1489a:	89 10                	mov    %edx,(%eax)

	return r;
   1489c:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   148a0:	c9                   	leave  
   148a1:	c3                   	ret    

000148a2 <ck_ring_enqueue_mpsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   148a2:	55                   	push   %ebp
   148a3:	89 e5                	mov    %esp,%ebp
   148a5:	83 ec 68             	sub    $0x68,%esp
   148a8:	8b 45 08             	mov    0x8(%ebp),%eax
   148ab:	89 45 f4             	mov    %eax,-0xc(%ebp)
   148ae:	8b 45 0c             	mov    0xc(%ebp),%eax
   148b1:	89 45 f0             	mov    %eax,-0x10(%ebp)
   148b4:	8d 45 10             	lea    0x10(%ebp),%eax
   148b7:	89 45 ec             	mov    %eax,-0x14(%ebp)
   148ba:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   148c1:	8b 45 14             	mov    0x14(%ebp),%eax
   148c4:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   148c7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   148ca:	89 45 e0             	mov    %eax,-0x20(%ebp)
   148cd:	8b 45 f0             	mov    -0x10(%ebp),%eax
   148d0:	89 45 dc             	mov    %eax,-0x24(%ebp)
   148d3:	8b 45 ec             	mov    -0x14(%ebp),%eax
   148d6:	89 45 d8             	mov    %eax,-0x28(%ebp)
   148d9:	8b 45 e8             	mov    -0x18(%ebp),%eax
   148dc:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   148df:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   148e2:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   148e5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   148e8:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   148ee:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   148f1:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   148f5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   148f8:	83 c0 44             	add    $0x44,%eax
   148fb:	89 04 24             	mov    %eax,(%esp)
   148fe:	e8 4b e6 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14903:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   14906:	e8 4e f3 ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1490b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1490e:	89 04 24             	mov    %eax,(%esp)
   14911:	e8 38 e6 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14916:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   14919:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1491c:	83 c0 01             	add    $0x1,%eax
   1491f:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   14922:	8b 45 b0             	mov    -0x50(%ebp),%eax
   14925:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   14928:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   1492b:	0f 97 c0             	seta   %al
   1492e:	0f b6 c0             	movzbl %al,%eax
   14931:	85 c0                	test   %eax,%eax
   14933:	74 29                	je     1495e <ck_ring_enqueue_mpsc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   14935:	8b 45 b0             	mov    -0x50(%ebp),%eax
   14938:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1493b:	8d 4a 44             	lea    0x44(%edx),%ecx
   1493e:	8d 55 b0             	lea    -0x50(%ebp),%edx
   14941:	89 54 24 0c          	mov    %edx,0xc(%esp)
   14945:	8b 55 c0             	mov    -0x40(%ebp),%edx
   14948:	89 54 24 08          	mov    %edx,0x8(%esp)
   1494c:	89 44 24 04          	mov    %eax,0x4(%esp)
   14950:	89 0c 24             	mov    %ecx,(%esp)
   14953:	e8 f7 ef ff ff       	call   1394f <ck_pr_cas_uint_value>
   14958:	84 c0                	test   %al,%al
   1495a:	75 31                	jne    1498d <ck_ring_enqueue_mpsc_size+0xeb>
   1495c:	eb a8                	jmp    14906 <ck_ring_enqueue_mpsc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1495e:	e8 f6 f2 ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   14963:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14966:	83 c0 44             	add    $0x44,%eax
   14969:	89 04 24             	mov    %eax,(%esp)
   1496c:	e8 dd e5 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14971:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   14974:	8b 45 b0             	mov    -0x50(%ebp),%eax
   14977:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   1497a:	75 06                	jne    14982 <ck_ring_enqueue_mpsc_size+0xe0>
				r = false;
   1497c:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   14980:	eb 67                	jmp    149e9 <ck_ring_enqueue_mpsc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   14982:	8b 45 bc             	mov    -0x44(%ebp),%eax
   14985:	89 45 b0             	mov    %eax,-0x50(%ebp)
   14988:	e9 79 ff ff ff       	jmp    14906 <ck_ring_enqueue_mpsc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1498d:	8b 45 b0             	mov    -0x50(%ebp),%eax
   14990:	23 45 cc             	and    -0x34(%ebp),%eax
   14993:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   14997:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1499a:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1499d:	89 44 24 08          	mov    %eax,0x8(%esp)
   149a1:	8b 45 d8             	mov    -0x28(%ebp),%eax
   149a4:	89 44 24 04          	mov    %eax,0x4(%esp)
   149a8:	8b 45 dc             	mov    -0x24(%ebp),%eax
   149ab:	89 04 24             	mov    %eax,(%esp)
   149ae:	e8 fc ff ff ff       	call   149af <ck_ring_enqueue_mpsc_size+0x10d>
   149b3:	eb 05                	jmp    149ba <ck_ring_enqueue_mpsc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   149b5:	e8 2f e4 ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   149ba:	8b 45 e0             	mov    -0x20(%ebp),%eax
   149bd:	83 c0 40             	add    $0x40,%eax
   149c0:	89 04 24             	mov    %eax,(%esp)
   149c3:	e8 86 e5 ff ff       	call   12f4e <ck_pr_md_load_uint>
   149c8:	8b 55 b0             	mov    -0x50(%ebp),%edx
   149cb:	39 d0                	cmp    %edx,%eax
   149cd:	75 e6                	jne    149b5 <ck_ring_enqueue_mpsc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   149cf:	e8 90 f2 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   149d4:	8b 45 e0             	mov    -0x20(%ebp),%eax
   149d7:	8d 50 40             	lea    0x40(%eax),%edx
   149da:	8b 45 c0             	mov    -0x40(%ebp),%eax
   149dd:	89 44 24 04          	mov    %eax,0x4(%esp)
   149e1:	89 14 24             	mov    %edx,(%esp)
   149e4:	e8 ee e5 ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   149e9:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   149ed:	74 10                	je     149ff <ck_ring_enqueue_mpsc_size+0x15d>
		*size = (producer - consumer) & mask;
   149ef:	8b 45 b0             	mov    -0x50(%ebp),%eax
   149f2:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   149f5:	23 45 cc             	and    -0x34(%ebp),%eax
   149f8:	89 c2                	mov    %eax,%edx
   149fa:	8b 45 d0             	mov    -0x30(%ebp),%eax
   149fd:	89 10                	mov    %edx,(%eax)

	return r;
   149ff:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   14a03:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   14a06:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   14a09:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   14a0c:	89 10                	mov    %edx,(%eax)
	return r;
   14a0e:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   14a12:	c9                   	leave  
   14a13:	c3                   	ret    

00014a14 <ck_ring_dequeue_mpsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   14a14:	55                   	push   %ebp
   14a15:	89 e5                	mov    %esp,%ebp
   14a17:	83 ec 38             	sub    $0x38,%esp
   14a1a:	8b 45 08             	mov    0x8(%ebp),%eax
   14a1d:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14a20:	8b 45 0c             	mov    0xc(%ebp),%eax
   14a23:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14a26:	8b 45 10             	mov    0x10(%ebp),%eax
   14a29:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14a2c:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   14a33:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14a36:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14a3c:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   14a3f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14a42:	8b 00                	mov    (%eax),%eax
   14a44:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   14a47:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14a4a:	83 c0 40             	add    $0x40,%eax
   14a4d:	89 04 24             	mov    %eax,(%esp)
   14a50:	e8 f9 e4 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14a55:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   14a58:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14a5b:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   14a5e:	0f 94 c0             	sete   %al
   14a61:	0f b6 c0             	movzbl %al,%eax
   14a64:	85 c0                	test   %eax,%eax
   14a66:	74 07                	je     14a6f <ck_ring_dequeue_mpsc+0x5b>
		return false;
   14a68:	b8 00 00 00 00       	mov    $0x0,%eax
   14a6d:	eb 4c                	jmp    14abb <ck_ring_dequeue_mpsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   14a6f:	e8 e5 f1 ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   14a74:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14a77:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   14a7a:	21 d0                	and    %edx,%eax
   14a7c:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14a80:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   14a83:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14a86:	89 44 24 08          	mov    %eax,0x8(%esp)
   14a8a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14a8d:	89 44 24 04          	mov    %eax,0x4(%esp)
   14a91:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14a94:	89 04 24             	mov    %eax,(%esp)
   14a97:	e8 fc ff ff ff       	call   14a98 <ck_ring_dequeue_mpsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   14a9c:	e8 c3 f1 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   14aa1:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14aa4:	8d 50 01             	lea    0x1(%eax),%edx
   14aa7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14aaa:	89 54 24 04          	mov    %edx,0x4(%esp)
   14aae:	89 04 24             	mov    %eax,(%esp)
   14ab1:	e8 21 e5 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   14ab6:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   14abb:	c9                   	leave  
   14abc:	c3                   	ret    

00014abd <ck_ring_enqueue_spsc_size_xcpu>:
			struct cos_defcompinfo *dci, *sched;
		} sl_xcpu_req_initaep_alloc;
	};
};

CK_RING_PROTOTYPE(xcpu, sl_xcpu_request);
   14abd:	55                   	push   %ebp
   14abe:	89 e5                	mov    %esp,%ebp
   14ac0:	83 ec 58             	sub    $0x58,%esp
   14ac3:	8b 45 08             	mov    0x8(%ebp),%eax
   14ac6:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14ac9:	8b 45 0c             	mov    0xc(%ebp),%eax
   14acc:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14acf:	8b 45 10             	mov    0x10(%ebp),%eax
   14ad2:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14ad5:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   14adc:	8b 45 14             	mov    0x14(%ebp),%eax
   14adf:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   14ae2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14ae5:	89 45 e0             	mov    %eax,-0x20(%ebp)
   14ae8:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14aeb:	89 45 dc             	mov    %eax,-0x24(%ebp)
   14aee:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14af1:	89 45 d8             	mov    %eax,-0x28(%ebp)
   14af4:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14af7:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   14afa:	8d 45 b8             	lea    -0x48(%ebp),%eax
   14afd:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   14b00:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14b03:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14b09:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   14b0c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14b0f:	89 04 24             	mov    %eax,(%esp)
   14b12:	e8 37 e4 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14b17:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   14b1a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14b1d:	8b 40 40             	mov    0x40(%eax),%eax
   14b20:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   14b23:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   14b26:	83 c0 01             	add    $0x1,%eax
   14b29:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   14b2c:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   14b30:	74 14                	je     14b46 <ck_ring_enqueue_spsc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   14b32:	8b 45 c8             	mov    -0x38(%ebp),%eax
   14b35:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   14b38:	29 c2                	sub    %eax,%edx
   14b3a:	89 d0                	mov    %edx,%eax
   14b3c:	23 45 cc             	and    -0x34(%ebp),%eax
   14b3f:	89 c2                	mov    %eax,%edx
   14b41:	8b 45 d0             	mov    -0x30(%ebp),%eax
   14b44:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   14b46:	8b 45 c0             	mov    -0x40(%ebp),%eax
   14b49:	8b 55 c8             	mov    -0x38(%ebp),%edx
   14b4c:	31 d0                	xor    %edx,%eax
   14b4e:	23 45 cc             	and    -0x34(%ebp),%eax
   14b51:	85 c0                	test   %eax,%eax
   14b53:	0f 94 c0             	sete   %al
   14b56:	0f b6 c0             	movzbl %al,%eax
   14b59:	85 c0                	test   %eax,%eax
   14b5b:	74 07                	je     14b64 <ck_ring_enqueue_spsc_size_xcpu+0xa7>
		return false;
   14b5d:	b8 00 00 00 00       	mov    $0x0,%eax
   14b62:	eb 47                	jmp    14bab <ck_ring_enqueue_spsc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   14b64:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   14b67:	8b 55 cc             	mov    -0x34(%ebp),%edx
   14b6a:	21 d0                	and    %edx,%eax
   14b6c:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   14b70:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   14b73:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   14b76:	89 44 24 08          	mov    %eax,0x8(%esp)
   14b7a:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14b7d:	89 44 24 04          	mov    %eax,0x4(%esp)
   14b81:	8b 45 dc             	mov    -0x24(%ebp),%eax
   14b84:	89 04 24             	mov    %eax,(%esp)
   14b87:	e8 fc ff ff ff       	call   14b88 <ck_ring_enqueue_spsc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   14b8c:	e8 d3 f0 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   14b91:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14b94:	8d 50 40             	lea    0x40(%eax),%edx
   14b97:	8b 45 c0             	mov    -0x40(%ebp),%eax
   14b9a:	89 44 24 04          	mov    %eax,0x4(%esp)
   14b9e:	89 14 24             	mov    %edx,(%esp)
   14ba1:	e8 31 e4 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   14ba6:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   14bab:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   14bae:	8b 55 b8             	mov    -0x48(%ebp),%edx
   14bb1:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   14bb4:	89 10                	mov    %edx,(%eax)
	return r;
   14bb6:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   14bba:	c9                   	leave  
   14bbb:	c3                   	ret    

00014bbc <ck_ring_enqueue_spsc_xcpu>:
   14bbc:	55                   	push   %ebp
   14bbd:	89 e5                	mov    %esp,%ebp
   14bbf:	83 ec 48             	sub    $0x48,%esp
   14bc2:	8b 45 08             	mov    0x8(%ebp),%eax
   14bc5:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14bc8:	8b 45 0c             	mov    0xc(%ebp),%eax
   14bcb:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14bce:	8b 45 10             	mov    0x10(%ebp),%eax
   14bd1:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14bd4:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   14bdb:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   14be2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14be5:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14beb:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   14bee:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14bf1:	89 04 24             	mov    %eax,(%esp)
   14bf4:	e8 55 e3 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14bf9:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   14bfc:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14bff:	8b 40 40             	mov    0x40(%eax),%eax
   14c02:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   14c05:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14c08:	83 c0 01             	add    $0x1,%eax
   14c0b:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   14c0e:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   14c12:	74 14                	je     14c28 <ck_ring_enqueue_spsc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   14c14:	8b 45 dc             	mov    -0x24(%ebp),%eax
   14c17:	8b 55 d8             	mov    -0x28(%ebp),%edx
   14c1a:	29 c2                	sub    %eax,%edx
   14c1c:	89 d0                	mov    %edx,%eax
   14c1e:	23 45 e0             	and    -0x20(%ebp),%eax
   14c21:	89 c2                	mov    %eax,%edx
   14c23:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   14c26:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   14c28:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   14c2b:	8b 55 dc             	mov    -0x24(%ebp),%edx
   14c2e:	31 d0                	xor    %edx,%eax
   14c30:	23 45 e0             	and    -0x20(%ebp),%eax
   14c33:	85 c0                	test   %eax,%eax
   14c35:	0f 94 c0             	sete   %al
   14c38:	0f b6 c0             	movzbl %al,%eax
   14c3b:	85 c0                	test   %eax,%eax
   14c3d:	74 07                	je     14c46 <ck_ring_enqueue_spsc_xcpu+0x8a>
		return false;
   14c3f:	b8 00 00 00 00       	mov    $0x0,%eax
   14c44:	eb 47                	jmp    14c8d <ck_ring_enqueue_spsc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   14c46:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14c49:	8b 55 e0             	mov    -0x20(%ebp),%edx
   14c4c:	21 d0                	and    %edx,%eax
   14c4e:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14c52:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   14c55:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14c58:	89 44 24 08          	mov    %eax,0x8(%esp)
   14c5c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14c5f:	89 44 24 04          	mov    %eax,0x4(%esp)
   14c63:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14c66:	89 04 24             	mov    %eax,(%esp)
   14c69:	e8 fc ff ff ff       	call   14c6a <ck_ring_enqueue_spsc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   14c6e:	e8 f1 ef ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   14c73:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14c76:	8d 50 40             	lea    0x40(%eax),%edx
   14c79:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   14c7c:	89 44 24 04          	mov    %eax,0x4(%esp)
   14c80:	89 14 24             	mov    %edx,(%esp)
   14c83:	e8 4f e3 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   14c88:	b8 01 00 00 00       	mov    $0x1,%eax
   14c8d:	c9                   	leave  
   14c8e:	c3                   	ret    

00014c8f <ck_ring_dequeue_spsc_xcpu>:
   14c8f:	55                   	push   %ebp
   14c90:	89 e5                	mov    %esp,%ebp
   14c92:	83 ec 38             	sub    $0x38,%esp
   14c95:	8b 45 08             	mov    0x8(%ebp),%eax
   14c98:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14c9b:	8b 45 0c             	mov    0xc(%ebp),%eax
   14c9e:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14ca1:	8b 45 10             	mov    0x10(%ebp),%eax
   14ca4:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14ca7:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   14cae:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14cb1:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14cb7:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   14cba:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14cbd:	8b 00                	mov    (%eax),%eax
   14cbf:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   14cc2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14cc5:	83 c0 40             	add    $0x40,%eax
   14cc8:	89 04 24             	mov    %eax,(%esp)
   14ccb:	e8 7e e2 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14cd0:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   14cd3:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14cd6:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   14cd9:	0f 94 c0             	sete   %al
   14cdc:	0f b6 c0             	movzbl %al,%eax
   14cdf:	85 c0                	test   %eax,%eax
   14ce1:	74 07                	je     14cea <ck_ring_dequeue_spsc_xcpu+0x5b>
		return false;
   14ce3:	b8 00 00 00 00       	mov    $0x0,%eax
   14ce8:	eb 4c                	jmp    14d36 <ck_ring_dequeue_spsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   14cea:	e8 6a ef ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   14cef:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14cf2:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   14cf5:	21 d0                	and    %edx,%eax
   14cf7:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14cfb:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   14cfe:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14d01:	89 44 24 08          	mov    %eax,0x8(%esp)
   14d05:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14d08:	89 44 24 04          	mov    %eax,0x4(%esp)
   14d0c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14d0f:	89 04 24             	mov    %eax,(%esp)
   14d12:	e8 fc ff ff ff       	call   14d13 <ck_ring_dequeue_spsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   14d17:	e8 48 ef ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   14d1c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14d1f:	8d 50 01             	lea    0x1(%eax),%edx
   14d22:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14d25:	89 54 24 04          	mov    %edx,0x4(%esp)
   14d29:	89 04 24             	mov    %eax,(%esp)
   14d2c:	e8 a6 e2 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   14d31:	b8 01 00 00 00       	mov    $0x1,%eax
   14d36:	c9                   	leave  
   14d37:	c3                   	ret    

00014d38 <ck_ring_enqueue_spmc_size_xcpu>:
   14d38:	55                   	push   %ebp
   14d39:	89 e5                	mov    %esp,%ebp
   14d3b:	83 ec 58             	sub    $0x58,%esp
   14d3e:	8b 45 08             	mov    0x8(%ebp),%eax
   14d41:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14d44:	8b 45 0c             	mov    0xc(%ebp),%eax
   14d47:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14d4a:	8b 45 10             	mov    0x10(%ebp),%eax
   14d4d:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14d50:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   14d57:	8b 45 14             	mov    0x14(%ebp),%eax
   14d5a:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   14d5d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14d60:	89 45 e0             	mov    %eax,-0x20(%ebp)
   14d63:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14d66:	89 45 dc             	mov    %eax,-0x24(%ebp)
   14d69:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14d6c:	89 45 d8             	mov    %eax,-0x28(%ebp)
   14d6f:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14d72:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   14d75:	8d 45 b8             	lea    -0x48(%ebp),%eax
   14d78:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   14d7b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14d7e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14d84:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   14d87:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14d8a:	89 04 24             	mov    %eax,(%esp)
   14d8d:	e8 bc e1 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14d92:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   14d95:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14d98:	8b 40 40             	mov    0x40(%eax),%eax
   14d9b:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   14d9e:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   14da1:	83 c0 01             	add    $0x1,%eax
   14da4:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   14da7:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   14dab:	74 14                	je     14dc1 <ck_ring_enqueue_spmc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   14dad:	8b 45 c8             	mov    -0x38(%ebp),%eax
   14db0:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   14db3:	29 c2                	sub    %eax,%edx
   14db5:	89 d0                	mov    %edx,%eax
   14db7:	23 45 cc             	and    -0x34(%ebp),%eax
   14dba:	89 c2                	mov    %eax,%edx
   14dbc:	8b 45 d0             	mov    -0x30(%ebp),%eax
   14dbf:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   14dc1:	8b 45 c0             	mov    -0x40(%ebp),%eax
   14dc4:	8b 55 c8             	mov    -0x38(%ebp),%edx
   14dc7:	31 d0                	xor    %edx,%eax
   14dc9:	23 45 cc             	and    -0x34(%ebp),%eax
   14dcc:	85 c0                	test   %eax,%eax
   14dce:	0f 94 c0             	sete   %al
   14dd1:	0f b6 c0             	movzbl %al,%eax
   14dd4:	85 c0                	test   %eax,%eax
   14dd6:	74 07                	je     14ddf <ck_ring_enqueue_spmc_size_xcpu+0xa7>
		return false;
   14dd8:	b8 00 00 00 00       	mov    $0x0,%eax
   14ddd:	eb 47                	jmp    14e26 <ck_ring_enqueue_spmc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   14ddf:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   14de2:	8b 55 cc             	mov    -0x34(%ebp),%edx
   14de5:	21 d0                	and    %edx,%eax
   14de7:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   14deb:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   14dee:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   14df1:	89 44 24 08          	mov    %eax,0x8(%esp)
   14df5:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14df8:	89 44 24 04          	mov    %eax,0x4(%esp)
   14dfc:	8b 45 dc             	mov    -0x24(%ebp),%eax
   14dff:	89 04 24             	mov    %eax,(%esp)
   14e02:	e8 fc ff ff ff       	call   14e03 <ck_ring_enqueue_spmc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   14e07:	e8 58 ee ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   14e0c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14e0f:	8d 50 40             	lea    0x40(%eax),%edx
   14e12:	8b 45 c0             	mov    -0x40(%ebp),%eax
   14e15:	89 44 24 04          	mov    %eax,0x4(%esp)
   14e19:	89 14 24             	mov    %edx,(%esp)
   14e1c:	e8 b6 e1 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   14e21:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   14e26:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   14e29:	8b 55 b8             	mov    -0x48(%ebp),%edx
   14e2c:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   14e2f:	89 10                	mov    %edx,(%eax)
	return r;
   14e31:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   14e35:	c9                   	leave  
   14e36:	c3                   	ret    

00014e37 <ck_ring_enqueue_spmc_xcpu>:
   14e37:	55                   	push   %ebp
   14e38:	89 e5                	mov    %esp,%ebp
   14e3a:	83 ec 48             	sub    $0x48,%esp
   14e3d:	8b 45 08             	mov    0x8(%ebp),%eax
   14e40:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14e43:	8b 45 0c             	mov    0xc(%ebp),%eax
   14e46:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14e49:	8b 45 10             	mov    0x10(%ebp),%eax
   14e4c:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14e4f:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   14e56:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   14e5d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14e60:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14e66:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   14e69:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14e6c:	89 04 24             	mov    %eax,(%esp)
   14e6f:	e8 da e0 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14e74:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   14e77:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14e7a:	8b 40 40             	mov    0x40(%eax),%eax
   14e7d:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   14e80:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14e83:	83 c0 01             	add    $0x1,%eax
   14e86:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   14e89:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   14e8d:	74 14                	je     14ea3 <ck_ring_enqueue_spmc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   14e8f:	8b 45 dc             	mov    -0x24(%ebp),%eax
   14e92:	8b 55 d8             	mov    -0x28(%ebp),%edx
   14e95:	29 c2                	sub    %eax,%edx
   14e97:	89 d0                	mov    %edx,%eax
   14e99:	23 45 e0             	and    -0x20(%ebp),%eax
   14e9c:	89 c2                	mov    %eax,%edx
   14e9e:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   14ea1:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   14ea3:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   14ea6:	8b 55 dc             	mov    -0x24(%ebp),%edx
   14ea9:	31 d0                	xor    %edx,%eax
   14eab:	23 45 e0             	and    -0x20(%ebp),%eax
   14eae:	85 c0                	test   %eax,%eax
   14eb0:	0f 94 c0             	sete   %al
   14eb3:	0f b6 c0             	movzbl %al,%eax
   14eb6:	85 c0                	test   %eax,%eax
   14eb8:	74 07                	je     14ec1 <ck_ring_enqueue_spmc_xcpu+0x8a>
		return false;
   14eba:	b8 00 00 00 00       	mov    $0x0,%eax
   14ebf:	eb 47                	jmp    14f08 <ck_ring_enqueue_spmc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   14ec1:	8b 45 d8             	mov    -0x28(%ebp),%eax
   14ec4:	8b 55 e0             	mov    -0x20(%ebp),%edx
   14ec7:	21 d0                	and    %edx,%eax
   14ec9:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14ecd:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   14ed0:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14ed3:	89 44 24 08          	mov    %eax,0x8(%esp)
   14ed7:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14eda:	89 44 24 04          	mov    %eax,0x4(%esp)
   14ede:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14ee1:	89 04 24             	mov    %eax,(%esp)
   14ee4:	e8 fc ff ff ff       	call   14ee5 <ck_ring_enqueue_spmc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   14ee9:	e8 76 ed ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   14eee:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14ef1:	8d 50 40             	lea    0x40(%eax),%edx
   14ef4:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   14ef7:	89 44 24 04          	mov    %eax,0x4(%esp)
   14efb:	89 14 24             	mov    %edx,(%esp)
   14efe:	e8 d4 e0 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   14f03:	b8 01 00 00 00       	mov    $0x1,%eax
   14f08:	c9                   	leave  
   14f09:	c3                   	ret    

00014f0a <ck_ring_trydequeue_spmc_xcpu>:
   14f0a:	55                   	push   %ebp
   14f0b:	89 e5                	mov    %esp,%ebp
   14f0d:	83 ec 38             	sub    $0x38,%esp
   14f10:	8b 45 08             	mov    0x8(%ebp),%eax
   14f13:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14f16:	8b 45 0c             	mov    0xc(%ebp),%eax
   14f19:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14f1c:	8b 45 10             	mov    0x10(%ebp),%eax
   14f1f:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14f22:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   14f29:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14f2c:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14f32:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   14f35:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14f38:	89 04 24             	mov    %eax,(%esp)
   14f3b:	e8 0e e0 ff ff       	call   12f4e <ck_pr_md_load_uint>
   14f40:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   14f43:	e8 11 ed ff ff       	call   13c59 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   14f48:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14f4b:	83 c0 40             	add    $0x40,%eax
   14f4e:	89 04 24             	mov    %eax,(%esp)
   14f51:	e8 f8 df ff ff       	call   12f4e <ck_pr_md_load_uint>
   14f56:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   14f59:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14f5c:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   14f5f:	0f 94 c0             	sete   %al
   14f62:	0f b6 c0             	movzbl %al,%eax
   14f65:	85 c0                	test   %eax,%eax
   14f67:	74 07                	je     14f70 <ck_ring_trydequeue_spmc_xcpu+0x66>
		return false;
   14f69:	b8 00 00 00 00       	mov    $0x0,%eax
   14f6e:	eb 4e                	jmp    14fbe <ck_ring_trydequeue_spmc_xcpu+0xb4>

	ck_pr_fence_load();
   14f70:	e8 e4 ec ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   14f75:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14f78:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   14f7b:	21 d0                	and    %edx,%eax
   14f7d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   14f81:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   14f84:	8b 45 e8             	mov    -0x18(%ebp),%eax
   14f87:	89 44 24 08          	mov    %eax,0x8(%esp)
   14f8b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   14f8e:	89 44 24 04          	mov    %eax,0x4(%esp)
   14f92:	8b 45 ec             	mov    -0x14(%ebp),%eax
   14f95:	89 04 24             	mov    %eax,(%esp)
   14f98:	e8 fc ff ff ff       	call   14f99 <ck_ring_trydequeue_spmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   14f9d:	e8 8b ec ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   14fa2:	8b 45 e0             	mov    -0x20(%ebp),%eax
   14fa5:	8d 50 01             	lea    0x1(%eax),%edx
   14fa8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14fab:	89 54 24 08          	mov    %edx,0x8(%esp)
   14faf:	8b 55 e0             	mov    -0x20(%ebp),%edx
   14fb2:	89 54 24 04          	mov    %edx,0x4(%esp)
   14fb6:	89 04 24             	mov    %eax,(%esp)
   14fb9:	e8 3e e8 ff ff       	call   137fc <ck_pr_cas_uint>
   14fbe:	c9                   	leave  
   14fbf:	c3                   	ret    

00014fc0 <ck_ring_dequeue_spmc_xcpu>:
   14fc0:	55                   	push   %ebp
   14fc1:	89 e5                	mov    %esp,%ebp
   14fc3:	53                   	push   %ebx
   14fc4:	83 ec 34             	sub    $0x34,%esp
   14fc7:	8b 45 08             	mov    0x8(%ebp),%eax
   14fca:	89 45 f4             	mov    %eax,-0xc(%ebp)
   14fcd:	8b 45 0c             	mov    0xc(%ebp),%eax
   14fd0:	89 45 f0             	mov    %eax,-0x10(%ebp)
   14fd3:	8b 45 10             	mov    0x10(%ebp),%eax
   14fd6:	89 45 ec             	mov    %eax,-0x14(%ebp)
   14fd9:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   14fe0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14fe3:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   14fe9:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   14fec:	8b 45 f4             	mov    -0xc(%ebp),%eax
   14fef:	89 04 24             	mov    %eax,(%esp)
   14ff2:	e8 57 df ff ff       	call   12f4e <ck_pr_md_load_uint>
   14ff7:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   14ffa:	e8 5a ec ff ff       	call   13c59 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   14fff:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15002:	83 c0 40             	add    $0x40,%eax
   15005:	89 04 24             	mov    %eax,(%esp)
   15008:	e8 41 df ff ff       	call   12f4e <ck_pr_md_load_uint>
   1500d:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   15010:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15013:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   15016:	0f 94 c0             	sete   %al
   15019:	0f b6 c0             	movzbl %al,%eax
   1501c:	85 c0                	test   %eax,%eax
   1501e:	74 07                	je     15027 <ck_ring_dequeue_spmc_xcpu+0x67>
			return false;
   15020:	b8 00 00 00 00       	mov    $0x0,%eax
   15025:	eb 6a                	jmp    15091 <ck_ring_dequeue_spmc_xcpu+0xd1>

		ck_pr_fence_load();
   15027:	e8 2d ec ff ff       	call   13c59 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   1502c:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1502f:	23 45 e4             	and    -0x1c(%ebp),%eax
   15032:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   15036:	89 c2                	mov    %eax,%edx
   15038:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1503b:	01 d0                	add    %edx,%eax
   1503d:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   15040:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15043:	89 44 24 08          	mov    %eax,0x8(%esp)
   15047:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1504a:	89 44 24 04          	mov    %eax,0x4(%esp)
   1504e:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15051:	89 04 24             	mov    %eax,(%esp)
   15054:	e8 fc ff ff ff       	call   15055 <ck_ring_dequeue_spmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   15059:	e8 cf eb ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1505e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15061:	8d 58 01             	lea    0x1(%eax),%ebx
   15064:	8b 55 d8             	mov    -0x28(%ebp),%edx
   15067:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1506a:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1506d:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   15071:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   15075:	89 54 24 04          	mov    %edx,0x4(%esp)
   15079:	89 04 24             	mov    %eax,(%esp)
   1507c:	e8 ce e8 ff ff       	call   1394f <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   15081:	83 f0 01             	xor    $0x1,%eax
   15084:	84 c0                	test   %al,%al
   15086:	0f 85 6e ff ff ff    	jne    14ffa <ck_ring_dequeue_spmc_xcpu+0x3a>

	return true;
   1508c:	b8 01 00 00 00       	mov    $0x1,%eax
   15091:	83 c4 34             	add    $0x34,%esp
   15094:	5b                   	pop    %ebx
   15095:	5d                   	pop    %ebp
   15096:	c3                   	ret    

00015097 <ck_ring_enqueue_mpsc_xcpu>:
   15097:	55                   	push   %ebp
   15098:	89 e5                	mov    %esp,%ebp
   1509a:	83 ec 48             	sub    $0x48,%esp
   1509d:	8b 45 08             	mov    0x8(%ebp),%eax
   150a0:	89 45 f4             	mov    %eax,-0xc(%ebp)
   150a3:	8b 45 0c             	mov    0xc(%ebp),%eax
   150a6:	89 45 f0             	mov    %eax,-0x10(%ebp)
   150a9:	8b 45 10             	mov    0x10(%ebp),%eax
   150ac:	89 45 ec             	mov    %eax,-0x14(%ebp)
   150af:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   150b6:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   150bd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   150c0:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   150c6:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   150c9:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   150cd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   150d0:	83 c0 44             	add    $0x44,%eax
   150d3:	89 04 24             	mov    %eax,(%esp)
   150d6:	e8 73 de ff ff       	call   12f4e <ck_pr_md_load_uint>
   150db:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   150de:	e8 76 eb ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   150e3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   150e6:	89 04 24             	mov    %eax,(%esp)
   150e9:	e8 60 de ff ff       	call   12f4e <ck_pr_md_load_uint>
   150ee:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   150f1:	8b 45 cc             	mov    -0x34(%ebp),%eax
   150f4:	83 c0 01             	add    $0x1,%eax
   150f7:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   150fa:	8b 45 cc             	mov    -0x34(%ebp),%eax
   150fd:	2b 45 d8             	sub    -0x28(%ebp),%eax
   15100:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   15103:	0f 97 c0             	seta   %al
   15106:	0f b6 c0             	movzbl %al,%eax
   15109:	85 c0                	test   %eax,%eax
   1510b:	74 29                	je     15136 <ck_ring_enqueue_mpsc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1510d:	8b 45 cc             	mov    -0x34(%ebp),%eax
   15110:	8b 55 f4             	mov    -0xc(%ebp),%edx
   15113:	8d 4a 44             	lea    0x44(%edx),%ecx
   15116:	8d 55 cc             	lea    -0x34(%ebp),%edx
   15119:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1511d:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   15120:	89 54 24 08          	mov    %edx,0x8(%esp)
   15124:	89 44 24 04          	mov    %eax,0x4(%esp)
   15128:	89 0c 24             	mov    %ecx,(%esp)
   1512b:	e8 1f e8 ff ff       	call   1394f <ck_pr_cas_uint_value>
   15130:	84 c0                	test   %al,%al
   15132:	75 31                	jne    15165 <ck_ring_enqueue_mpsc_xcpu+0xce>
   15134:	eb a8                	jmp    150de <ck_ring_enqueue_mpsc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   15136:	e8 1e eb ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1513b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1513e:	83 c0 44             	add    $0x44,%eax
   15141:	89 04 24             	mov    %eax,(%esp)
   15144:	e8 05 de ff ff       	call   12f4e <ck_pr_md_load_uint>
   15149:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1514c:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1514f:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   15152:	75 06                	jne    1515a <ck_ring_enqueue_mpsc_xcpu+0xc3>
				r = false;
   15154:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   15158:	eb 67                	jmp    151c1 <ck_ring_enqueue_mpsc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1515a:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1515d:	89 45 cc             	mov    %eax,-0x34(%ebp)
   15160:	e9 79 ff ff ff       	jmp    150de <ck_ring_enqueue_mpsc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   15165:	8b 45 cc             	mov    -0x34(%ebp),%eax
   15168:	23 45 e0             	and    -0x20(%ebp),%eax
   1516b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1516f:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   15172:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15175:	89 44 24 08          	mov    %eax,0x8(%esp)
   15179:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1517c:	89 44 24 04          	mov    %eax,0x4(%esp)
   15180:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15183:	89 04 24             	mov    %eax,(%esp)
   15186:	e8 fc ff ff ff       	call   15187 <ck_ring_enqueue_mpsc_xcpu+0xf0>
   1518b:	eb 05                	jmp    15192 <ck_ring_enqueue_mpsc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1518d:	e8 57 dc ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   15192:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15195:	83 c0 40             	add    $0x40,%eax
   15198:	89 04 24             	mov    %eax,(%esp)
   1519b:	e8 ae dd ff ff       	call   12f4e <ck_pr_md_load_uint>
   151a0:	8b 55 cc             	mov    -0x34(%ebp),%edx
   151a3:	39 d0                	cmp    %edx,%eax
   151a5:	75 e6                	jne    1518d <ck_ring_enqueue_mpsc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   151a7:	e8 b8 ea ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   151ac:	8b 45 f4             	mov    -0xc(%ebp),%eax
   151af:	8d 50 40             	lea    0x40(%eax),%edx
   151b2:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   151b5:	89 44 24 04          	mov    %eax,0x4(%esp)
   151b9:	89 14 24             	mov    %edx,(%esp)
   151bc:	e8 16 de ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   151c1:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   151c5:	74 10                	je     151d7 <ck_ring_enqueue_mpsc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   151c7:	8b 45 cc             	mov    -0x34(%ebp),%eax
   151ca:	2b 45 d8             	sub    -0x28(%ebp),%eax
   151cd:	23 45 e0             	and    -0x20(%ebp),%eax
   151d0:	89 c2                	mov    %eax,%edx
   151d2:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   151d5:	89 10                	mov    %edx,(%eax)

	return r;
   151d7:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   151db:	c9                   	leave  
   151dc:	c3                   	ret    

000151dd <ck_ring_enqueue_mpsc_size_xcpu>:
   151dd:	55                   	push   %ebp
   151de:	89 e5                	mov    %esp,%ebp
   151e0:	83 ec 68             	sub    $0x68,%esp
   151e3:	8b 45 08             	mov    0x8(%ebp),%eax
   151e6:	89 45 f4             	mov    %eax,-0xc(%ebp)
   151e9:	8b 45 0c             	mov    0xc(%ebp),%eax
   151ec:	89 45 f0             	mov    %eax,-0x10(%ebp)
   151ef:	8b 45 10             	mov    0x10(%ebp),%eax
   151f2:	89 45 ec             	mov    %eax,-0x14(%ebp)
   151f5:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   151fc:	8b 45 14             	mov    0x14(%ebp),%eax
   151ff:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   15202:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15205:	89 45 e0             	mov    %eax,-0x20(%ebp)
   15208:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1520b:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1520e:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15211:	89 45 d8             	mov    %eax,-0x28(%ebp)
   15214:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15217:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1521a:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1521d:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   15220:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15223:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15229:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1522c:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   15230:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15233:	83 c0 44             	add    $0x44,%eax
   15236:	89 04 24             	mov    %eax,(%esp)
   15239:	e8 10 dd ff ff       	call   12f4e <ck_pr_md_load_uint>
   1523e:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   15241:	e8 13 ea ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   15246:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15249:	89 04 24             	mov    %eax,(%esp)
   1524c:	e8 fd dc ff ff       	call   12f4e <ck_pr_md_load_uint>
   15251:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   15254:	8b 45 b0             	mov    -0x50(%ebp),%eax
   15257:	83 c0 01             	add    $0x1,%eax
   1525a:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1525d:	8b 45 b0             	mov    -0x50(%ebp),%eax
   15260:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   15263:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   15266:	0f 97 c0             	seta   %al
   15269:	0f b6 c0             	movzbl %al,%eax
   1526c:	85 c0                	test   %eax,%eax
   1526e:	74 29                	je     15299 <ck_ring_enqueue_mpsc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   15270:	8b 45 b0             	mov    -0x50(%ebp),%eax
   15273:	8b 55 e0             	mov    -0x20(%ebp),%edx
   15276:	8d 4a 44             	lea    0x44(%edx),%ecx
   15279:	8d 55 b0             	lea    -0x50(%ebp),%edx
   1527c:	89 54 24 0c          	mov    %edx,0xc(%esp)
   15280:	8b 55 c0             	mov    -0x40(%ebp),%edx
   15283:	89 54 24 08          	mov    %edx,0x8(%esp)
   15287:	89 44 24 04          	mov    %eax,0x4(%esp)
   1528b:	89 0c 24             	mov    %ecx,(%esp)
   1528e:	e8 bc e6 ff ff       	call   1394f <ck_pr_cas_uint_value>
   15293:	84 c0                	test   %al,%al
   15295:	75 31                	jne    152c8 <ck_ring_enqueue_mpsc_size_xcpu+0xeb>
   15297:	eb a8                	jmp    15241 <ck_ring_enqueue_mpsc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   15299:	e8 bb e9 ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1529e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   152a1:	83 c0 44             	add    $0x44,%eax
   152a4:	89 04 24             	mov    %eax,(%esp)
   152a7:	e8 a2 dc ff ff       	call   12f4e <ck_pr_md_load_uint>
   152ac:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   152af:	8b 45 b0             	mov    -0x50(%ebp),%eax
   152b2:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   152b5:	75 06                	jne    152bd <ck_ring_enqueue_mpsc_size_xcpu+0xe0>
				r = false;
   152b7:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   152bb:	eb 67                	jmp    15324 <ck_ring_enqueue_mpsc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   152bd:	8b 45 bc             	mov    -0x44(%ebp),%eax
   152c0:	89 45 b0             	mov    %eax,-0x50(%ebp)
   152c3:	e9 79 ff ff ff       	jmp    15241 <ck_ring_enqueue_mpsc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   152c8:	8b 45 b0             	mov    -0x50(%ebp),%eax
   152cb:	23 45 cc             	and    -0x34(%ebp),%eax
   152ce:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   152d2:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   152d5:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   152d8:	89 44 24 08          	mov    %eax,0x8(%esp)
   152dc:	8b 45 d8             	mov    -0x28(%ebp),%eax
   152df:	89 44 24 04          	mov    %eax,0x4(%esp)
   152e3:	8b 45 dc             	mov    -0x24(%ebp),%eax
   152e6:	89 04 24             	mov    %eax,(%esp)
   152e9:	e8 fc ff ff ff       	call   152ea <ck_ring_enqueue_mpsc_size_xcpu+0x10d>
   152ee:	eb 05                	jmp    152f5 <ck_ring_enqueue_mpsc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   152f0:	e8 f4 da ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   152f5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   152f8:	83 c0 40             	add    $0x40,%eax
   152fb:	89 04 24             	mov    %eax,(%esp)
   152fe:	e8 4b dc ff ff       	call   12f4e <ck_pr_md_load_uint>
   15303:	8b 55 b0             	mov    -0x50(%ebp),%edx
   15306:	39 d0                	cmp    %edx,%eax
   15308:	75 e6                	jne    152f0 <ck_ring_enqueue_mpsc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1530a:	e8 55 e9 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1530f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15312:	8d 50 40             	lea    0x40(%eax),%edx
   15315:	8b 45 c0             	mov    -0x40(%ebp),%eax
   15318:	89 44 24 04          	mov    %eax,0x4(%esp)
   1531c:	89 14 24             	mov    %edx,(%esp)
   1531f:	e8 b3 dc ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   15324:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   15328:	74 10                	je     1533a <ck_ring_enqueue_mpsc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   1532a:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1532d:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   15330:	23 45 cc             	and    -0x34(%ebp),%eax
   15333:	89 c2                	mov    %eax,%edx
   15335:	8b 45 d0             	mov    -0x30(%ebp),%eax
   15338:	89 10                	mov    %edx,(%eax)

	return r;
   1533a:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   1533e:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   15341:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   15344:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   15347:	89 10                	mov    %edx,(%eax)
	return r;
   15349:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   1534d:	c9                   	leave  
   1534e:	c3                   	ret    

0001534f <ck_ring_dequeue_mpsc_xcpu>:
   1534f:	55                   	push   %ebp
   15350:	89 e5                	mov    %esp,%ebp
   15352:	83 ec 38             	sub    $0x38,%esp
   15355:	8b 45 08             	mov    0x8(%ebp),%eax
   15358:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1535b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1535e:	89 45 f0             	mov    %eax,-0x10(%ebp)
   15361:	8b 45 10             	mov    0x10(%ebp),%eax
   15364:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15367:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1536e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15371:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15377:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   1537a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1537d:	8b 00                	mov    (%eax),%eax
   1537f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   15382:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15385:	83 c0 40             	add    $0x40,%eax
   15388:	89 04 24             	mov    %eax,(%esp)
   1538b:	e8 be db ff ff       	call   12f4e <ck_pr_md_load_uint>
   15390:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   15393:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15396:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   15399:	0f 94 c0             	sete   %al
   1539c:	0f b6 c0             	movzbl %al,%eax
   1539f:	85 c0                	test   %eax,%eax
   153a1:	74 07                	je     153aa <ck_ring_dequeue_mpsc_xcpu+0x5b>
		return false;
   153a3:	b8 00 00 00 00       	mov    $0x0,%eax
   153a8:	eb 4c                	jmp    153f6 <ck_ring_dequeue_mpsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   153aa:	e8 aa e8 ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   153af:	8b 45 e0             	mov    -0x20(%ebp),%eax
   153b2:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   153b5:	21 d0                	and    %edx,%eax
   153b7:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   153bb:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   153be:	8b 45 e8             	mov    -0x18(%ebp),%eax
   153c1:	89 44 24 08          	mov    %eax,0x8(%esp)
   153c5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   153c8:	89 44 24 04          	mov    %eax,0x4(%esp)
   153cc:	8b 45 ec             	mov    -0x14(%ebp),%eax
   153cf:	89 04 24             	mov    %eax,(%esp)
   153d2:	e8 fc ff ff ff       	call   153d3 <ck_ring_dequeue_mpsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   153d7:	e8 88 e8 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   153dc:	8b 45 e0             	mov    -0x20(%ebp),%eax
   153df:	8d 50 01             	lea    0x1(%eax),%edx
   153e2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   153e5:	89 54 24 04          	mov    %edx,0x4(%esp)
   153e9:	89 04 24             	mov    %eax,(%esp)
   153ec:	e8 e6 db ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   153f1:	b8 01 00 00 00       	mov    $0x1,%eax
   153f6:	c9                   	leave  
   153f7:	c3                   	ret    

000153f8 <ck_ring_enqueue_mpmc_size_xcpu>:
   153f8:	55                   	push   %ebp
   153f9:	89 e5                	mov    %esp,%ebp
   153fb:	83 ec 68             	sub    $0x68,%esp
   153fe:	8b 45 08             	mov    0x8(%ebp),%eax
   15401:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15404:	8b 45 0c             	mov    0xc(%ebp),%eax
   15407:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1540a:	8b 45 10             	mov    0x10(%ebp),%eax
   1540d:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15410:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   15417:	8b 45 14             	mov    0x14(%ebp),%eax
   1541a:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1541d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15420:	89 45 e0             	mov    %eax,-0x20(%ebp)
   15423:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15426:	89 45 dc             	mov    %eax,-0x24(%ebp)
   15429:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1542c:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1542f:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15432:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   15435:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   15438:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1543b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1543e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15444:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   15447:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1544b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1544e:	83 c0 44             	add    $0x44,%eax
   15451:	89 04 24             	mov    %eax,(%esp)
   15454:	e8 f5 da ff ff       	call   12f4e <ck_pr_md_load_uint>
   15459:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1545c:	e8 f8 e7 ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   15461:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15464:	89 04 24             	mov    %eax,(%esp)
   15467:	e8 e2 da ff ff       	call   12f4e <ck_pr_md_load_uint>
   1546c:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   1546f:	8b 45 b0             	mov    -0x50(%ebp),%eax
   15472:	83 c0 01             	add    $0x1,%eax
   15475:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   15478:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1547b:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1547e:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   15481:	0f 97 c0             	seta   %al
   15484:	0f b6 c0             	movzbl %al,%eax
   15487:	85 c0                	test   %eax,%eax
   15489:	74 29                	je     154b4 <ck_ring_enqueue_mpmc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1548b:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1548e:	8b 55 e0             	mov    -0x20(%ebp),%edx
   15491:	8d 4a 44             	lea    0x44(%edx),%ecx
   15494:	8d 55 b0             	lea    -0x50(%ebp),%edx
   15497:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1549b:	8b 55 c0             	mov    -0x40(%ebp),%edx
   1549e:	89 54 24 08          	mov    %edx,0x8(%esp)
   154a2:	89 44 24 04          	mov    %eax,0x4(%esp)
   154a6:	89 0c 24             	mov    %ecx,(%esp)
   154a9:	e8 a1 e4 ff ff       	call   1394f <ck_pr_cas_uint_value>
   154ae:	84 c0                	test   %al,%al
   154b0:	75 31                	jne    154e3 <ck_ring_enqueue_mpmc_size_xcpu+0xeb>
   154b2:	eb a8                	jmp    1545c <ck_ring_enqueue_mpmc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   154b4:	e8 a0 e7 ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   154b9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   154bc:	83 c0 44             	add    $0x44,%eax
   154bf:	89 04 24             	mov    %eax,(%esp)
   154c2:	e8 87 da ff ff       	call   12f4e <ck_pr_md_load_uint>
   154c7:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   154ca:	8b 45 b0             	mov    -0x50(%ebp),%eax
   154cd:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   154d0:	75 06                	jne    154d8 <ck_ring_enqueue_mpmc_size_xcpu+0xe0>
				r = false;
   154d2:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   154d6:	eb 67                	jmp    1553f <ck_ring_enqueue_mpmc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   154d8:	8b 45 bc             	mov    -0x44(%ebp),%eax
   154db:	89 45 b0             	mov    %eax,-0x50(%ebp)
   154de:	e9 79 ff ff ff       	jmp    1545c <ck_ring_enqueue_mpmc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   154e3:	8b 45 b0             	mov    -0x50(%ebp),%eax
   154e6:	23 45 cc             	and    -0x34(%ebp),%eax
   154e9:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   154ed:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   154f0:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   154f3:	89 44 24 08          	mov    %eax,0x8(%esp)
   154f7:	8b 45 d8             	mov    -0x28(%ebp),%eax
   154fa:	89 44 24 04          	mov    %eax,0x4(%esp)
   154fe:	8b 45 dc             	mov    -0x24(%ebp),%eax
   15501:	89 04 24             	mov    %eax,(%esp)
   15504:	e8 fc ff ff ff       	call   15505 <ck_ring_enqueue_mpmc_size_xcpu+0x10d>
   15509:	eb 05                	jmp    15510 <ck_ring_enqueue_mpmc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1550b:	e8 d9 d8 ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   15510:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15513:	83 c0 40             	add    $0x40,%eax
   15516:	89 04 24             	mov    %eax,(%esp)
   15519:	e8 30 da ff ff       	call   12f4e <ck_pr_md_load_uint>
   1551e:	8b 55 b0             	mov    -0x50(%ebp),%edx
   15521:	39 d0                	cmp    %edx,%eax
   15523:	75 e6                	jne    1550b <ck_ring_enqueue_mpmc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   15525:	e8 3a e7 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1552a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1552d:	8d 50 40             	lea    0x40(%eax),%edx
   15530:	8b 45 c0             	mov    -0x40(%ebp),%eax
   15533:	89 44 24 04          	mov    %eax,0x4(%esp)
   15537:	89 14 24             	mov    %edx,(%esp)
   1553a:	e8 98 da ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1553f:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   15543:	74 10                	je     15555 <ck_ring_enqueue_mpmc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   15545:	8b 45 b0             	mov    -0x50(%ebp),%eax
   15548:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1554b:	23 45 cc             	and    -0x34(%ebp),%eax
   1554e:	89 c2                	mov    %eax,%edx
   15550:	8b 45 d0             	mov    -0x30(%ebp),%eax
   15553:	89 10                	mov    %edx,(%eax)

	return r;
   15555:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   15559:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   1555c:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   1555f:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   15562:	89 10                	mov    %edx,(%eax)
	return r;
   15564:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   15568:	c9                   	leave  
   15569:	c3                   	ret    

0001556a <ck_ring_enqueue_mpmc_xcpu>:
   1556a:	55                   	push   %ebp
   1556b:	89 e5                	mov    %esp,%ebp
   1556d:	83 ec 48             	sub    $0x48,%esp
   15570:	8b 45 08             	mov    0x8(%ebp),%eax
   15573:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15576:	8b 45 0c             	mov    0xc(%ebp),%eax
   15579:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1557c:	8b 45 10             	mov    0x10(%ebp),%eax
   1557f:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15582:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   15589:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   15590:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15593:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15599:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1559c:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   155a0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   155a3:	83 c0 44             	add    $0x44,%eax
   155a6:	89 04 24             	mov    %eax,(%esp)
   155a9:	e8 a0 d9 ff ff       	call   12f4e <ck_pr_md_load_uint>
   155ae:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   155b1:	e8 a3 e6 ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   155b6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   155b9:	89 04 24             	mov    %eax,(%esp)
   155bc:	e8 8d d9 ff ff       	call   12f4e <ck_pr_md_load_uint>
   155c1:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   155c4:	8b 45 cc             	mov    -0x34(%ebp),%eax
   155c7:	83 c0 01             	add    $0x1,%eax
   155ca:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   155cd:	8b 45 cc             	mov    -0x34(%ebp),%eax
   155d0:	2b 45 d8             	sub    -0x28(%ebp),%eax
   155d3:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   155d6:	0f 97 c0             	seta   %al
   155d9:	0f b6 c0             	movzbl %al,%eax
   155dc:	85 c0                	test   %eax,%eax
   155de:	74 29                	je     15609 <ck_ring_enqueue_mpmc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   155e0:	8b 45 cc             	mov    -0x34(%ebp),%eax
   155e3:	8b 55 f4             	mov    -0xc(%ebp),%edx
   155e6:	8d 4a 44             	lea    0x44(%edx),%ecx
   155e9:	8d 55 cc             	lea    -0x34(%ebp),%edx
   155ec:	89 54 24 0c          	mov    %edx,0xc(%esp)
   155f0:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   155f3:	89 54 24 08          	mov    %edx,0x8(%esp)
   155f7:	89 44 24 04          	mov    %eax,0x4(%esp)
   155fb:	89 0c 24             	mov    %ecx,(%esp)
   155fe:	e8 4c e3 ff ff       	call   1394f <ck_pr_cas_uint_value>
   15603:	84 c0                	test   %al,%al
   15605:	75 31                	jne    15638 <ck_ring_enqueue_mpmc_xcpu+0xce>
   15607:	eb a8                	jmp    155b1 <ck_ring_enqueue_mpmc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   15609:	e8 4b e6 ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1560e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15611:	83 c0 44             	add    $0x44,%eax
   15614:	89 04 24             	mov    %eax,(%esp)
   15617:	e8 32 d9 ff ff       	call   12f4e <ck_pr_md_load_uint>
   1561c:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1561f:	8b 45 cc             	mov    -0x34(%ebp),%eax
   15622:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   15625:	75 06                	jne    1562d <ck_ring_enqueue_mpmc_xcpu+0xc3>
				r = false;
   15627:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1562b:	eb 67                	jmp    15694 <ck_ring_enqueue_mpmc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1562d:	8b 45 d0             	mov    -0x30(%ebp),%eax
   15630:	89 45 cc             	mov    %eax,-0x34(%ebp)
   15633:	e9 79 ff ff ff       	jmp    155b1 <ck_ring_enqueue_mpmc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   15638:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1563b:	23 45 e0             	and    -0x20(%ebp),%eax
   1563e:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   15642:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   15645:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15648:	89 44 24 08          	mov    %eax,0x8(%esp)
   1564c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1564f:	89 44 24 04          	mov    %eax,0x4(%esp)
   15653:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15656:	89 04 24             	mov    %eax,(%esp)
   15659:	e8 fc ff ff ff       	call   1565a <ck_ring_enqueue_mpmc_xcpu+0xf0>
   1565e:	eb 05                	jmp    15665 <ck_ring_enqueue_mpmc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   15660:	e8 84 d7 ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   15665:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15668:	83 c0 40             	add    $0x40,%eax
   1566b:	89 04 24             	mov    %eax,(%esp)
   1566e:	e8 db d8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   15673:	8b 55 cc             	mov    -0x34(%ebp),%edx
   15676:	39 d0                	cmp    %edx,%eax
   15678:	75 e6                	jne    15660 <ck_ring_enqueue_mpmc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1567a:	e8 e5 e5 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1567f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15682:	8d 50 40             	lea    0x40(%eax),%edx
   15685:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   15688:	89 44 24 04          	mov    %eax,0x4(%esp)
   1568c:	89 14 24             	mov    %edx,(%esp)
   1568f:	e8 43 d9 ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   15694:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   15698:	74 10                	je     156aa <ck_ring_enqueue_mpmc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   1569a:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1569d:	2b 45 d8             	sub    -0x28(%ebp),%eax
   156a0:	23 45 e0             	and    -0x20(%ebp),%eax
   156a3:	89 c2                	mov    %eax,%edx
   156a5:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   156a8:	89 10                	mov    %edx,(%eax)

	return r;
   156aa:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   156ae:	c9                   	leave  
   156af:	c3                   	ret    

000156b0 <ck_ring_trydequeue_mpmc_xcpu>:
   156b0:	55                   	push   %ebp
   156b1:	89 e5                	mov    %esp,%ebp
   156b3:	83 ec 38             	sub    $0x38,%esp
   156b6:	8b 45 08             	mov    0x8(%ebp),%eax
   156b9:	89 45 f4             	mov    %eax,-0xc(%ebp)
   156bc:	8b 45 0c             	mov    0xc(%ebp),%eax
   156bf:	89 45 f0             	mov    %eax,-0x10(%ebp)
   156c2:	8b 45 10             	mov    0x10(%ebp),%eax
   156c5:	89 45 ec             	mov    %eax,-0x14(%ebp)
   156c8:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   156cf:	8b 45 f4             	mov    -0xc(%ebp),%eax
   156d2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   156d8:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   156db:	8b 45 f4             	mov    -0xc(%ebp),%eax
   156de:	89 04 24             	mov    %eax,(%esp)
   156e1:	e8 68 d8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   156e6:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   156e9:	e8 6b e5 ff ff       	call   13c59 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   156ee:	8b 45 f4             	mov    -0xc(%ebp),%eax
   156f1:	83 c0 40             	add    $0x40,%eax
   156f4:	89 04 24             	mov    %eax,(%esp)
   156f7:	e8 52 d8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   156fc:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   156ff:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15702:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   15705:	0f 94 c0             	sete   %al
   15708:	0f b6 c0             	movzbl %al,%eax
   1570b:	85 c0                	test   %eax,%eax
   1570d:	74 07                	je     15716 <ck_ring_trydequeue_mpmc_xcpu+0x66>
		return false;
   1570f:	b8 00 00 00 00       	mov    $0x0,%eax
   15714:	eb 4e                	jmp    15764 <ck_ring_trydequeue_mpmc_xcpu+0xb4>

	ck_pr_fence_load();
   15716:	e8 3e e5 ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1571b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1571e:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   15721:	21 d0                	and    %edx,%eax
   15723:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   15727:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1572a:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1572d:	89 44 24 08          	mov    %eax,0x8(%esp)
   15731:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15734:	89 44 24 04          	mov    %eax,0x4(%esp)
   15738:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1573b:	89 04 24             	mov    %eax,(%esp)
   1573e:	e8 fc ff ff ff       	call   1573f <ck_ring_trydequeue_mpmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   15743:	e8 e5 e4 ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   15748:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1574b:	8d 50 01             	lea    0x1(%eax),%edx
   1574e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15751:	89 54 24 08          	mov    %edx,0x8(%esp)
   15755:	8b 55 e0             	mov    -0x20(%ebp),%edx
   15758:	89 54 24 04          	mov    %edx,0x4(%esp)
   1575c:	89 04 24             	mov    %eax,(%esp)
   1575f:	e8 98 e0 ff ff       	call   137fc <ck_pr_cas_uint>
   15764:	c9                   	leave  
   15765:	c3                   	ret    

00015766 <ck_ring_dequeue_mpmc_xcpu>:
   15766:	55                   	push   %ebp
   15767:	89 e5                	mov    %esp,%ebp
   15769:	53                   	push   %ebx
   1576a:	83 ec 34             	sub    $0x34,%esp
   1576d:	8b 45 08             	mov    0x8(%ebp),%eax
   15770:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15773:	8b 45 0c             	mov    0xc(%ebp),%eax
   15776:	89 45 f0             	mov    %eax,-0x10(%ebp)
   15779:	8b 45 10             	mov    0x10(%ebp),%eax
   1577c:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1577f:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   15786:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15789:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1578f:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   15792:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15795:	89 04 24             	mov    %eax,(%esp)
   15798:	e8 b1 d7 ff ff       	call   12f4e <ck_pr_md_load_uint>
   1579d:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   157a0:	e8 b4 e4 ff ff       	call   13c59 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   157a5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   157a8:	83 c0 40             	add    $0x40,%eax
   157ab:	89 04 24             	mov    %eax,(%esp)
   157ae:	e8 9b d7 ff ff       	call   12f4e <ck_pr_md_load_uint>
   157b3:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   157b6:	8b 45 d8             	mov    -0x28(%ebp),%eax
   157b9:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   157bc:	0f 94 c0             	sete   %al
   157bf:	0f b6 c0             	movzbl %al,%eax
   157c2:	85 c0                	test   %eax,%eax
   157c4:	74 07                	je     157cd <ck_ring_dequeue_mpmc_xcpu+0x67>
			return false;
   157c6:	b8 00 00 00 00       	mov    $0x0,%eax
   157cb:	eb 6a                	jmp    15837 <ck_ring_dequeue_mpmc_xcpu+0xd1>

		ck_pr_fence_load();
   157cd:	e8 87 e4 ff ff       	call   13c59 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   157d2:	8b 45 d8             	mov    -0x28(%ebp),%eax
   157d5:	23 45 e4             	and    -0x1c(%ebp),%eax
   157d8:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   157dc:	89 c2                	mov    %eax,%edx
   157de:	8b 45 f0             	mov    -0x10(%ebp),%eax
   157e1:	01 d0                	add    %edx,%eax
   157e3:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   157e6:	8b 45 e8             	mov    -0x18(%ebp),%eax
   157e9:	89 44 24 08          	mov    %eax,0x8(%esp)
   157ed:	8b 45 dc             	mov    -0x24(%ebp),%eax
   157f0:	89 44 24 04          	mov    %eax,0x4(%esp)
   157f4:	8b 45 ec             	mov    -0x14(%ebp),%eax
   157f7:	89 04 24             	mov    %eax,(%esp)
   157fa:	e8 fc ff ff ff       	call   157fb <ck_ring_dequeue_mpmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   157ff:	e8 29 e4 ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   15804:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15807:	8d 58 01             	lea    0x1(%eax),%ebx
   1580a:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1580d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15810:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   15813:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   15817:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1581b:	89 54 24 04          	mov    %edx,0x4(%esp)
   1581f:	89 04 24             	mov    %eax,(%esp)
   15822:	e8 28 e1 ff ff       	call   1394f <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   15827:	83 f0 01             	xor    $0x1,%eax
   1582a:	84 c0                	test   %al,%al
   1582c:	0f 85 6e ff ff ff    	jne    157a0 <ck_ring_dequeue_mpmc_xcpu+0x3a>

	return true;
   15832:	b8 01 00 00 00       	mov    $0x1,%eax
   15837:	83 c4 34             	add    $0x34,%esp
   1583a:	5b                   	pop    %ebx
   1583b:	5d                   	pop    %ebp
   1583c:	c3                   	ret    

0001583d <sl__globals_cpu>:

extern struct sl_global_cpu sl_global_cpu_data[];

static inline struct sl_global_cpu *
sl__globals_cpu(void)
{
   1583d:	55                   	push   %ebp
   1583e:	89 e5                	mov    %esp,%ebp
	return &(sl_global_cpu_data[cos_cpuid()]);
   15840:	e8 6c d0 ff ff       	call   128b1 <cos_cpuid>
   15845:	c1 e0 03             	shl    $0x3,%eax
   15848:	8d 14 c5 00 00 00 00 	lea    0x0(,%eax,8),%edx
   1584f:	29 c2                	sub    %eax,%edx
   15851:	8d 82 00 00 00 00    	lea    0x0(%edx),%eax
}
   15857:	5d                   	pop    %ebp
   15858:	c3                   	ret    

00015859 <sl_thd_lkup>:
/* for lazy retrieval of a child component thread in the parent */
extern struct sl_thd *sl_thd_retrieve(thdid_t tid);

static inline struct sl_thd *
sl_thd_lkup(thdid_t tid)
{
   15859:	55                   	push   %ebp
   1585a:	89 e5                	mov    %esp,%ebp
   1585c:	83 ec 18             	sub    $0x18,%esp
   1585f:	8b 45 08             	mov    0x8(%ebp),%eax
   15862:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	assert(tid != 0);
   15866:	66 83 7d f4 00       	cmpw   $0x0,-0xc(%ebp)
   1586b:	0f 94 c0             	sete   %al
   1586e:	0f b6 c0             	movzbl %al,%eax
   15871:	85 c0                	test   %eax,%eax
   15873:	74 1c                	je     15891 <sl_thd_lkup+0x38>
   15875:	c7 04 24 dc 2c 00 00 	movl   $0x2cdc,(%esp)
   1587c:	e8 ab d1 ff ff       	call   12a2c <prints>
   15881:	a1 a0 02 00 00       	mov    0x2a0,%eax
   15886:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1588c:	e8 22 d2 ff ff       	call   12ab3 <__cos_noret>
	if (unlikely(tid > MAX_NUM_THREADS)) return NULL;
   15891:	66 83 7d f4 40       	cmpw   $0x40,-0xc(%ebp)
   15896:	0f 97 c0             	seta   %al
   15899:	0f b6 c0             	movzbl %al,%eax
   1589c:	85 c0                	test   %eax,%eax
   1589e:	74 07                	je     158a7 <sl_thd_lkup+0x4e>
   158a0:	b8 00 00 00 00       	mov    $0x0,%eax
   158a5:	eb 0c                	jmp    158b3 <sl_thd_lkup+0x5a>

	return sl_thd_retrieve(tid);
   158a7:	0f b7 45 f4          	movzwl -0xc(%ebp),%eax
   158ab:	89 04 24             	mov    %eax,(%esp)
   158ae:	e8 fc ff ff ff       	call   158af <sl_thd_lkup+0x56>
}
   158b3:	c9                   	leave  
   158b4:	c3                   	ret    

000158b5 <sl_thdid>:
	return t;
}

static inline thdid_t
sl_thdid(void)
{
   158b5:	55                   	push   %ebp
   158b6:	89 e5                	mov    %esp,%ebp
   158b8:	83 ec 28             	sub    $0x28,%esp
	thdid_t tid = cos_thdid();
   158bb:	e8 0f d0 ff ff       	call   128cf <cos_thdid>
   158c0:	66 89 45 f6          	mov    %ax,-0xa(%ebp)

	assert(tid != 0);
   158c4:	66 83 7d f6 00       	cmpw   $0x0,-0xa(%ebp)
   158c9:	0f 94 c0             	sete   %al
   158cc:	0f b6 c0             	movzbl %al,%eax
   158cf:	85 c0                	test   %eax,%eax
   158d1:	74 1c                	je     158ef <sl_thdid+0x3a>
   158d3:	c7 04 24 30 2d 00 00 	movl   $0x2d30,(%esp)
   158da:	e8 4d d1 ff ff       	call   12a2c <prints>
   158df:	a1 a0 02 00 00       	mov    0x2a0,%eax
   158e4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   158ea:	e8 c4 d1 ff ff       	call   12ab3 <__cos_noret>
	assert(tid < MAX_NUM_THREADS);
   158ef:	66 83 7d f6 3f       	cmpw   $0x3f,-0xa(%ebp)
   158f4:	0f 97 c0             	seta   %al
   158f7:	0f b6 c0             	movzbl %al,%eax
   158fa:	85 c0                	test   %eax,%eax
   158fc:	74 1c                	je     1591a <sl_thdid+0x65>
   158fe:	c7 04 24 84 2d 00 00 	movl   $0x2d84,(%esp)
   15905:	e8 22 d1 ff ff       	call   12a2c <prints>
   1590a:	a1 a0 02 00 00       	mov    0x2a0,%eax
   1590f:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   15915:	e8 99 d1 ff ff       	call   12ab3 <__cos_noret>

	return tid;
   1591a:	0f b7 45 f6          	movzwl -0xa(%ebp),%eax
}
   1591e:	c9                   	leave  
   1591f:	c3                   	ret    

00015920 <sl_thd_curr>:


static inline struct sl_thd *
sl_thd_curr(void)
{
   15920:	55                   	push   %ebp
   15921:	89 e5                	mov    %esp,%ebp
   15923:	83 ec 18             	sub    $0x18,%esp
	return sl_thd_lkup(sl_thdid());
   15926:	e8 8a ff ff ff       	call   158b5 <sl_thdid>
   1592b:	0f b7 c0             	movzwl %ax,%eax
   1592e:	89 04 24             	mov    %eax,(%esp)
   15931:	e8 23 ff ff ff       	call   15859 <sl_thd_lkup>
}
   15936:	c9                   	leave  
   15937:	c3                   	ret    

00015938 <sl_cs_owner>:

/* are we the owner of the critical section? */
static inline int
sl_cs_owner(void)
{
   15938:	55                   	push   %ebp
   15939:	89 e5                	mov    %esp,%ebp
   1593b:	53                   	push   %ebx
   1593c:	83 ec 14             	sub    $0x14,%esp
	return sl__globals_cpu()->lock.u.s.owner == sl_thd_thdcap(sl_thd_curr());
   1593f:	e8 f9 fe ff ff       	call   1583d <sl__globals_cpu>
   15944:	8b 00                	mov    (%eax),%eax
   15946:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   1594b:	89 c3                	mov    %eax,%ebx
   1594d:	e8 ce ff ff ff       	call   15920 <sl_thd_curr>
   15952:	89 04 24             	mov    %eax,(%esp)
   15955:	e8 a2 d3 ff ff       	call   12cfc <sl_thd_thdcap>
   1595a:	39 c3                	cmp    %eax,%ebx
   1595c:	0f 94 c0             	sete   %al
   1595f:	0f b6 c0             	movzbl %al,%eax
}
   15962:	83 c4 14             	add    $0x14,%esp
   15965:	5b                   	pop    %ebx
   15966:	5d                   	pop    %ebp
   15967:	c3                   	ret    

00015968 <sl_cs_enter_nospin>:
int sl_cs_exit_contention(union sl_cs_intern *csi, union sl_cs_intern *cached, sched_tok_t tok);

/* Enter into the scheduler critical section */
static inline int
sl_cs_enter_nospin(void)
{
   15968:	55                   	push   %ebp
   15969:	89 e5                	mov    %esp,%ebp
   1596b:	56                   	push   %esi
   1596c:	53                   	push   %ebx
   1596d:	83 ec 20             	sub    $0x20,%esp
	union sl_cs_intern csi, cached;
	struct sl_thd *    t = sl_thd_curr();
   15970:	e8 ab ff ff ff       	call   15920 <sl_thd_curr>
   15975:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sched_tok_t        tok;

	assert(t);
   15978:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
   1597c:	0f 94 c0             	sete   %al
   1597f:	0f b6 c0             	movzbl %al,%eax
   15982:	85 c0                	test   %eax,%eax
   15984:	74 1c                	je     159a2 <sl_cs_enter_nospin+0x3a>
   15986:	c7 04 24 d8 2d 00 00 	movl   $0x2dd8,(%esp)
   1598d:	e8 9a d0 ff ff       	call   12a2c <prints>
   15992:	a1 a0 02 00 00       	mov    0x2a0,%eax
   15997:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1599d:	e8 11 d1 ff ff       	call   12ab3 <__cos_noret>
	tok      = cos_sched_sync();
   159a2:	e8 fc ff ff ff       	call   159a3 <sl_cs_enter_nospin+0x3b>
   159a7:	89 45 f0             	mov    %eax,-0x10(%ebp)
	csi.v    = sl__globals_cpu()->lock.u.v;
   159aa:	e8 8e fe ff ff       	call   1583d <sl__globals_cpu>
   159af:	8b 00                	mov    (%eax),%eax
   159b1:	89 45 ec             	mov    %eax,-0x14(%ebp)
	cached.v = csi.v;
   159b4:	8b 45 ec             	mov    -0x14(%ebp),%eax
   159b7:	89 45 e8             	mov    %eax,-0x18(%ebp)

	if (unlikely(csi.s.owner)) {
   159ba:	8b 45 ec             	mov    -0x14(%ebp),%eax
   159bd:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   159c2:	85 c0                	test   %eax,%eax
   159c4:	0f 95 c0             	setne  %al
   159c7:	0f b6 c0             	movzbl %al,%eax
   159ca:	85 c0                	test   %eax,%eax
   159cc:	74 2a                	je     159f8 <sl_cs_enter_nospin+0x90>
		return sl_cs_enter_contention(&csi, &cached, sl_thd_thdcap(t), tok);
   159ce:	8b 45 f4             	mov    -0xc(%ebp),%eax
   159d1:	89 04 24             	mov    %eax,(%esp)
   159d4:	e8 23 d3 ff ff       	call   12cfc <sl_thd_thdcap>
   159d9:	8b 55 f0             	mov    -0x10(%ebp),%edx
   159dc:	89 54 24 0c          	mov    %edx,0xc(%esp)
   159e0:	89 44 24 08          	mov    %eax,0x8(%esp)
   159e4:	8d 45 e8             	lea    -0x18(%ebp),%eax
   159e7:	89 44 24 04          	mov    %eax,0x4(%esp)
   159eb:	8d 45 ec             	lea    -0x14(%ebp),%eax
   159ee:	89 04 24             	mov    %eax,(%esp)
   159f1:	e8 fc ff ff ff       	call   159f2 <sl_cs_enter_nospin+0x8a>
   159f6:	eb 4f                	jmp    15a47 <sl_cs_enter_nospin+0xdf>
	}

	csi.s.owner = sl_thd_thdcap(t);
   159f8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   159fb:	89 04 24             	mov    %eax,(%esp)
   159fe:	e8 f9 d2 ff ff       	call   12cfc <sl_thd_thdcap>
   15a03:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   15a08:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   15a0d:	89 c2                	mov    %eax,%edx
   15a0f:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15a12:	25 00 00 00 80       	and    $0x80000000,%eax
   15a17:	09 d0                	or     %edx,%eax
   15a19:	89 45 ec             	mov    %eax,-0x14(%ebp)
	if (!ps_cas(&sl__globals_cpu()->lock.u.v, cached.v, csi.v)) return 1;
   15a1c:	8b 75 ec             	mov    -0x14(%ebp),%esi
   15a1f:	8b 5d e8             	mov    -0x18(%ebp),%ebx
   15a22:	e8 16 fe ff ff       	call   1583d <sl__globals_cpu>
   15a27:	89 74 24 08          	mov    %esi,0x8(%esp)
   15a2b:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   15a2f:	89 04 24             	mov    %eax,(%esp)
   15a32:	e8 81 d0 ff ff       	call   12ab8 <ps_cas>
   15a37:	85 c0                	test   %eax,%eax
   15a39:	75 07                	jne    15a42 <sl_cs_enter_nospin+0xda>
   15a3b:	b8 01 00 00 00       	mov    $0x1,%eax
   15a40:	eb 05                	jmp    15a47 <sl_cs_enter_nospin+0xdf>

	return 0;
   15a42:	b8 00 00 00 00       	mov    $0x0,%eax
}
   15a47:	83 c4 20             	add    $0x20,%esp
   15a4a:	5b                   	pop    %ebx
   15a4b:	5e                   	pop    %esi
   15a4c:	5d                   	pop    %ebp
   15a4d:	c3                   	ret    

00015a4e <sl_cs_enter>:

/* Enter into scheduler cs from a non-sched thread context */
static inline void
sl_cs_enter(void)
{
   15a4e:	55                   	push   %ebp
   15a4f:	89 e5                	mov    %esp,%ebp
   15a51:	83 ec 08             	sub    $0x8,%esp
	while (sl_cs_enter_nospin())
   15a54:	90                   	nop
   15a55:	e8 0e ff ff ff       	call   15968 <sl_cs_enter_nospin>
   15a5a:	85 c0                	test   %eax,%eax
   15a5c:	75 f7                	jne    15a55 <sl_cs_enter+0x7>
		;
}
   15a5e:	c9                   	leave  
   15a5f:	c3                   	ret    

00015a60 <sl_cs_exit>:
 * Release the scheduler critical section, switch to the scheduler
 * thread if there is pending contention
 */
static inline void
sl_cs_exit(void)
{
   15a60:	55                   	push   %ebp
   15a61:	89 e5                	mov    %esp,%ebp
   15a63:	53                   	push   %ebx
   15a64:	83 ec 24             	sub    $0x24,%esp
	union sl_cs_intern csi, cached;
	sched_tok_t        tok;

	assert(sl_cs_owner());
   15a67:	e8 cc fe ff ff       	call   15938 <sl_cs_owner>
   15a6c:	85 c0                	test   %eax,%eax
   15a6e:	0f 94 c0             	sete   %al
   15a71:	0f b6 c0             	movzbl %al,%eax
   15a74:	85 c0                	test   %eax,%eax
   15a76:	74 1c                	je     15a94 <sl_cs_exit+0x34>
   15a78:	c7 04 24 2c 2e 00 00 	movl   $0x2e2c,(%esp)
   15a7f:	e8 a8 cf ff ff       	call   12a2c <prints>
   15a84:	a1 a0 02 00 00       	mov    0x2a0,%eax
   15a89:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   15a8f:	e8 1f d0 ff ff       	call   12ab3 <__cos_noret>

retry:
	tok      = cos_sched_sync();
   15a94:	e8 fc ff ff ff       	call   15a95 <sl_cs_exit+0x35>
   15a99:	89 45 f4             	mov    %eax,-0xc(%ebp)
	csi.v    = sl__globals_cpu()->lock.u.v;
   15a9c:	e8 9c fd ff ff       	call   1583d <sl__globals_cpu>
   15aa1:	8b 00                	mov    (%eax),%eax
   15aa3:	89 45 f0             	mov    %eax,-0x10(%ebp)
	cached.v = csi.v;
   15aa6:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15aa9:	89 45 ec             	mov    %eax,-0x14(%ebp)

	if (unlikely(csi.s.contention)) {
   15aac:	0f b6 45 f3          	movzbl -0xd(%ebp),%eax
   15ab0:	c0 e8 07             	shr    $0x7,%al
   15ab3:	0f b6 c0             	movzbl %al,%eax
   15ab6:	85 c0                	test   %eax,%eax
   15ab8:	74 1f                	je     15ad9 <sl_cs_exit+0x79>
		if (sl_cs_exit_contention(&csi, &cached, tok)) goto retry;
   15aba:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15abd:	89 44 24 08          	mov    %eax,0x8(%esp)
   15ac1:	8d 45 ec             	lea    -0x14(%ebp),%eax
   15ac4:	89 44 24 04          	mov    %eax,0x4(%esp)
   15ac8:	8d 45 f0             	lea    -0x10(%ebp),%eax
   15acb:	89 04 24             	mov    %eax,(%esp)
   15ace:	e8 fc ff ff ff       	call   15acf <sl_cs_exit+0x6f>
   15ad3:	85 c0                	test   %eax,%eax
   15ad5:	74 24                	je     15afb <sl_cs_exit+0x9b>
   15ad7:	eb bb                	jmp    15a94 <sl_cs_exit+0x34>
		return;
	}

	if (!ps_cas(&sl__globals_cpu()->lock.u.v, cached.v, 0)) goto retry;
   15ad9:	8b 5d ec             	mov    -0x14(%ebp),%ebx
   15adc:	e8 5c fd ff ff       	call   1583d <sl__globals_cpu>
   15ae1:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   15ae8:	00 
   15ae9:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   15aed:	89 04 24             	mov    %eax,(%esp)
   15af0:	e8 c3 cf ff ff       	call   12ab8 <ps_cas>
   15af5:	85 c0                	test   %eax,%eax
   15af7:	75 02                	jne    15afb <sl_cs_exit+0x9b>
   15af9:	eb 99                	jmp    15a94 <sl_cs_exit+0x34>
}
   15afb:	83 c4 24             	add    $0x24,%esp
   15afe:	5b                   	pop    %ebx
   15aff:	5d                   	pop    %ebp
   15b00:	c3                   	ret    

00015b01 <ck_ring_enqueue_spsc_size_child>:
   15b01:	55                   	push   %ebp
   15b02:	89 e5                	mov    %esp,%ebp
   15b04:	83 ec 58             	sub    $0x58,%esp
   15b07:	8b 45 08             	mov    0x8(%ebp),%eax
   15b0a:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15b0d:	8b 45 0c             	mov    0xc(%ebp),%eax
   15b10:	89 45 f0             	mov    %eax,-0x10(%ebp)
   15b13:	8b 45 10             	mov    0x10(%ebp),%eax
   15b16:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15b19:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
   15b20:	8b 45 14             	mov    0x14(%ebp),%eax
   15b23:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   15b26:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15b29:	89 45 e0             	mov    %eax,-0x20(%ebp)
   15b2c:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15b2f:	89 45 dc             	mov    %eax,-0x24(%ebp)
   15b32:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15b35:	89 45 d8             	mov    %eax,-0x28(%ebp)
   15b38:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15b3b:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   15b3e:	8d 45 b8             	lea    -0x48(%ebp),%eax
   15b41:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   15b44:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15b47:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15b4d:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   15b50:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15b53:	89 04 24             	mov    %eax,(%esp)
   15b56:	e8 f3 d3 ff ff       	call   12f4e <ck_pr_md_load_uint>
   15b5b:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   15b5e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15b61:	8b 40 40             	mov    0x40(%eax),%eax
   15b64:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   15b67:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   15b6a:	83 c0 01             	add    $0x1,%eax
   15b6d:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   15b70:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   15b74:	74 14                	je     15b8a <ck_ring_enqueue_spsc_size_child+0x89>
		*size = (producer - consumer) & mask;
   15b76:	8b 45 c8             	mov    -0x38(%ebp),%eax
   15b79:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   15b7c:	29 c2                	sub    %eax,%edx
   15b7e:	89 d0                	mov    %edx,%eax
   15b80:	23 45 cc             	and    -0x34(%ebp),%eax
   15b83:	89 c2                	mov    %eax,%edx
   15b85:	8b 45 d0             	mov    -0x30(%ebp),%eax
   15b88:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   15b8a:	8b 45 c0             	mov    -0x40(%ebp),%eax
   15b8d:	8b 55 c8             	mov    -0x38(%ebp),%edx
   15b90:	31 d0                	xor    %edx,%eax
   15b92:	23 45 cc             	and    -0x34(%ebp),%eax
   15b95:	85 c0                	test   %eax,%eax
   15b97:	0f 94 c0             	sete   %al
   15b9a:	0f b6 c0             	movzbl %al,%eax
   15b9d:	85 c0                	test   %eax,%eax
   15b9f:	74 07                	je     15ba8 <ck_ring_enqueue_spsc_size_child+0xa7>
		return false;
   15ba1:	b8 00 00 00 00       	mov    $0x0,%eax
   15ba6:	eb 47                	jmp    15bef <ck_ring_enqueue_spsc_size_child+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   15ba8:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   15bab:	8b 55 cc             	mov    -0x34(%ebp),%edx
   15bae:	21 d0                	and    %edx,%eax
   15bb0:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   15bb4:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   15bb7:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   15bba:	89 44 24 08          	mov    %eax,0x8(%esp)
   15bbe:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15bc1:	89 44 24 04          	mov    %eax,0x4(%esp)
   15bc5:	8b 45 dc             	mov    -0x24(%ebp),%eax
   15bc8:	89 04 24             	mov    %eax,(%esp)
   15bcb:	e8 fc ff ff ff       	call   15bcc <ck_ring_enqueue_spsc_size_child+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   15bd0:	e8 8f e0 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   15bd5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15bd8:	8d 50 40             	lea    0x40(%eax),%edx
   15bdb:	8b 45 c0             	mov    -0x40(%ebp),%eax
   15bde:	89 44 24 04          	mov    %eax,0x4(%esp)
   15be2:	89 14 24             	mov    %edx,(%esp)
   15be5:	e8 ed d3 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   15bea:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   15bef:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   15bf2:	8b 55 b8             	mov    -0x48(%ebp),%edx
   15bf5:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   15bf8:	89 10                	mov    %edx,(%eax)
	return r;
   15bfa:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   15bfe:	c9                   	leave  
   15bff:	c3                   	ret    

00015c00 <ck_ring_enqueue_spsc_child>:
   15c00:	55                   	push   %ebp
   15c01:	89 e5                	mov    %esp,%ebp
   15c03:	83 ec 48             	sub    $0x48,%esp
   15c06:	8b 45 08             	mov    0x8(%ebp),%eax
   15c09:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15c0c:	8b 45 0c             	mov    0xc(%ebp),%eax
   15c0f:	89 45 f0             	mov    %eax,-0x10(%ebp)
   15c12:	8b 45 10             	mov    0x10(%ebp),%eax
   15c15:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15c18:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
   15c1f:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   15c26:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15c29:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15c2f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   15c32:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15c35:	89 04 24             	mov    %eax,(%esp)
   15c38:	e8 11 d3 ff ff       	call   12f4e <ck_pr_md_load_uint>
   15c3d:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   15c40:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15c43:	8b 40 40             	mov    0x40(%eax),%eax
   15c46:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   15c49:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15c4c:	83 c0 01             	add    $0x1,%eax
   15c4f:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   15c52:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   15c56:	74 14                	je     15c6c <ck_ring_enqueue_spsc_child+0x6c>
		*size = (producer - consumer) & mask;
   15c58:	8b 45 dc             	mov    -0x24(%ebp),%eax
   15c5b:	8b 55 d8             	mov    -0x28(%ebp),%edx
   15c5e:	29 c2                	sub    %eax,%edx
   15c60:	89 d0                	mov    %edx,%eax
   15c62:	23 45 e0             	and    -0x20(%ebp),%eax
   15c65:	89 c2                	mov    %eax,%edx
   15c67:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   15c6a:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   15c6c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   15c6f:	8b 55 dc             	mov    -0x24(%ebp),%edx
   15c72:	31 d0                	xor    %edx,%eax
   15c74:	23 45 e0             	and    -0x20(%ebp),%eax
   15c77:	85 c0                	test   %eax,%eax
   15c79:	0f 94 c0             	sete   %al
   15c7c:	0f b6 c0             	movzbl %al,%eax
   15c7f:	85 c0                	test   %eax,%eax
   15c81:	74 07                	je     15c8a <ck_ring_enqueue_spsc_child+0x8a>
		return false;
   15c83:	b8 00 00 00 00       	mov    $0x0,%eax
   15c88:	eb 47                	jmp    15cd1 <ck_ring_enqueue_spsc_child+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   15c8a:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15c8d:	8b 55 e0             	mov    -0x20(%ebp),%edx
   15c90:	21 d0                	and    %edx,%eax
   15c92:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   15c96:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   15c99:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15c9c:	89 44 24 08          	mov    %eax,0x8(%esp)
   15ca0:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15ca3:	89 44 24 04          	mov    %eax,0x4(%esp)
   15ca7:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15caa:	89 04 24             	mov    %eax,(%esp)
   15cad:	e8 fc ff ff ff       	call   15cae <ck_ring_enqueue_spsc_child+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   15cb2:	e8 ad df ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   15cb7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15cba:	8d 50 40             	lea    0x40(%eax),%edx
   15cbd:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   15cc0:	89 44 24 04          	mov    %eax,0x4(%esp)
   15cc4:	89 14 24             	mov    %edx,(%esp)
   15cc7:	e8 0b d3 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   15ccc:	b8 01 00 00 00       	mov    $0x1,%eax
   15cd1:	c9                   	leave  
   15cd2:	c3                   	ret    

00015cd3 <ck_ring_dequeue_spsc_child>:
   15cd3:	55                   	push   %ebp
   15cd4:	89 e5                	mov    %esp,%ebp
   15cd6:	83 ec 38             	sub    $0x38,%esp
   15cd9:	8b 45 08             	mov    0x8(%ebp),%eax
   15cdc:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15cdf:	8b 45 0c             	mov    0xc(%ebp),%eax
   15ce2:	89 45 f0             	mov    %eax,-0x10(%ebp)
   15ce5:	8b 45 10             	mov    0x10(%ebp),%eax
   15ce8:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15ceb:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   15cf2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15cf5:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15cfb:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   15cfe:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15d01:	8b 00                	mov    (%eax),%eax
   15d03:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   15d06:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15d09:	83 c0 40             	add    $0x40,%eax
   15d0c:	89 04 24             	mov    %eax,(%esp)
   15d0f:	e8 3a d2 ff ff       	call   12f4e <ck_pr_md_load_uint>
   15d14:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   15d17:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15d1a:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   15d1d:	0f 94 c0             	sete   %al
   15d20:	0f b6 c0             	movzbl %al,%eax
   15d23:	85 c0                	test   %eax,%eax
   15d25:	74 07                	je     15d2e <ck_ring_dequeue_spsc_child+0x5b>
		return false;
   15d27:	b8 00 00 00 00       	mov    $0x0,%eax
   15d2c:	eb 4c                	jmp    15d7a <ck_ring_dequeue_spsc_child+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   15d2e:	e8 26 df ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   15d33:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15d36:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   15d39:	21 d0                	and    %edx,%eax
   15d3b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   15d3f:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   15d42:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15d45:	89 44 24 08          	mov    %eax,0x8(%esp)
   15d49:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15d4c:	89 44 24 04          	mov    %eax,0x4(%esp)
   15d50:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15d53:	89 04 24             	mov    %eax,(%esp)
   15d56:	e8 fc ff ff ff       	call   15d57 <ck_ring_dequeue_spsc_child+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   15d5b:	e8 04 df ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   15d60:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15d63:	8d 50 01             	lea    0x1(%eax),%edx
   15d66:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15d69:	89 54 24 04          	mov    %edx,0x4(%esp)
   15d6d:	89 04 24             	mov    %eax,(%esp)
   15d70:	e8 62 d2 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   15d75:	b8 01 00 00 00       	mov    $0x1,%eax
   15d7a:	c9                   	leave  
   15d7b:	c3                   	ret    

00015d7c <ck_ring_enqueue_spmc_size_child>:
   15d7c:	55                   	push   %ebp
   15d7d:	89 e5                	mov    %esp,%ebp
   15d7f:	83 ec 58             	sub    $0x58,%esp
   15d82:	8b 45 08             	mov    0x8(%ebp),%eax
   15d85:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15d88:	8b 45 0c             	mov    0xc(%ebp),%eax
   15d8b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   15d8e:	8b 45 10             	mov    0x10(%ebp),%eax
   15d91:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15d94:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
   15d9b:	8b 45 14             	mov    0x14(%ebp),%eax
   15d9e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   15da1:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15da4:	89 45 e0             	mov    %eax,-0x20(%ebp)
   15da7:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15daa:	89 45 dc             	mov    %eax,-0x24(%ebp)
   15dad:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15db0:	89 45 d8             	mov    %eax,-0x28(%ebp)
   15db3:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15db6:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   15db9:	8d 45 b8             	lea    -0x48(%ebp),%eax
   15dbc:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   15dbf:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15dc2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15dc8:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   15dcb:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15dce:	89 04 24             	mov    %eax,(%esp)
   15dd1:	e8 78 d1 ff ff       	call   12f4e <ck_pr_md_load_uint>
   15dd6:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   15dd9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15ddc:	8b 40 40             	mov    0x40(%eax),%eax
   15ddf:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   15de2:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   15de5:	83 c0 01             	add    $0x1,%eax
   15de8:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   15deb:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   15def:	74 14                	je     15e05 <ck_ring_enqueue_spmc_size_child+0x89>
		*size = (producer - consumer) & mask;
   15df1:	8b 45 c8             	mov    -0x38(%ebp),%eax
   15df4:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   15df7:	29 c2                	sub    %eax,%edx
   15df9:	89 d0                	mov    %edx,%eax
   15dfb:	23 45 cc             	and    -0x34(%ebp),%eax
   15dfe:	89 c2                	mov    %eax,%edx
   15e00:	8b 45 d0             	mov    -0x30(%ebp),%eax
   15e03:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   15e05:	8b 45 c0             	mov    -0x40(%ebp),%eax
   15e08:	8b 55 c8             	mov    -0x38(%ebp),%edx
   15e0b:	31 d0                	xor    %edx,%eax
   15e0d:	23 45 cc             	and    -0x34(%ebp),%eax
   15e10:	85 c0                	test   %eax,%eax
   15e12:	0f 94 c0             	sete   %al
   15e15:	0f b6 c0             	movzbl %al,%eax
   15e18:	85 c0                	test   %eax,%eax
   15e1a:	74 07                	je     15e23 <ck_ring_enqueue_spmc_size_child+0xa7>
		return false;
   15e1c:	b8 00 00 00 00       	mov    $0x0,%eax
   15e21:	eb 47                	jmp    15e6a <ck_ring_enqueue_spmc_size_child+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   15e23:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   15e26:	8b 55 cc             	mov    -0x34(%ebp),%edx
   15e29:	21 d0                	and    %edx,%eax
   15e2b:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   15e2f:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   15e32:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   15e35:	89 44 24 08          	mov    %eax,0x8(%esp)
   15e39:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15e3c:	89 44 24 04          	mov    %eax,0x4(%esp)
   15e40:	8b 45 dc             	mov    -0x24(%ebp),%eax
   15e43:	89 04 24             	mov    %eax,(%esp)
   15e46:	e8 fc ff ff ff       	call   15e47 <ck_ring_enqueue_spmc_size_child+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   15e4b:	e8 14 de ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   15e50:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15e53:	8d 50 40             	lea    0x40(%eax),%edx
   15e56:	8b 45 c0             	mov    -0x40(%ebp),%eax
   15e59:	89 44 24 04          	mov    %eax,0x4(%esp)
   15e5d:	89 14 24             	mov    %edx,(%esp)
   15e60:	e8 72 d1 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   15e65:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   15e6a:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   15e6d:	8b 55 b8             	mov    -0x48(%ebp),%edx
   15e70:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   15e73:	89 10                	mov    %edx,(%eax)
	return r;
   15e75:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   15e79:	c9                   	leave  
   15e7a:	c3                   	ret    

00015e7b <ck_ring_enqueue_spmc_child>:
   15e7b:	55                   	push   %ebp
   15e7c:	89 e5                	mov    %esp,%ebp
   15e7e:	83 ec 48             	sub    $0x48,%esp
   15e81:	8b 45 08             	mov    0x8(%ebp),%eax
   15e84:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15e87:	8b 45 0c             	mov    0xc(%ebp),%eax
   15e8a:	89 45 f0             	mov    %eax,-0x10(%ebp)
   15e8d:	8b 45 10             	mov    0x10(%ebp),%eax
   15e90:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15e93:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
   15e9a:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   15ea1:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15ea4:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15eaa:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   15ead:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15eb0:	89 04 24             	mov    %eax,(%esp)
   15eb3:	e8 96 d0 ff ff       	call   12f4e <ck_pr_md_load_uint>
   15eb8:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   15ebb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15ebe:	8b 40 40             	mov    0x40(%eax),%eax
   15ec1:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   15ec4:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15ec7:	83 c0 01             	add    $0x1,%eax
   15eca:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   15ecd:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   15ed1:	74 14                	je     15ee7 <ck_ring_enqueue_spmc_child+0x6c>
		*size = (producer - consumer) & mask;
   15ed3:	8b 45 dc             	mov    -0x24(%ebp),%eax
   15ed6:	8b 55 d8             	mov    -0x28(%ebp),%edx
   15ed9:	29 c2                	sub    %eax,%edx
   15edb:	89 d0                	mov    %edx,%eax
   15edd:	23 45 e0             	and    -0x20(%ebp),%eax
   15ee0:	89 c2                	mov    %eax,%edx
   15ee2:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   15ee5:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   15ee7:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   15eea:	8b 55 dc             	mov    -0x24(%ebp),%edx
   15eed:	31 d0                	xor    %edx,%eax
   15eef:	23 45 e0             	and    -0x20(%ebp),%eax
   15ef2:	85 c0                	test   %eax,%eax
   15ef4:	0f 94 c0             	sete   %al
   15ef7:	0f b6 c0             	movzbl %al,%eax
   15efa:	85 c0                	test   %eax,%eax
   15efc:	74 07                	je     15f05 <ck_ring_enqueue_spmc_child+0x8a>
		return false;
   15efe:	b8 00 00 00 00       	mov    $0x0,%eax
   15f03:	eb 47                	jmp    15f4c <ck_ring_enqueue_spmc_child+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   15f05:	8b 45 d8             	mov    -0x28(%ebp),%eax
   15f08:	8b 55 e0             	mov    -0x20(%ebp),%edx
   15f0b:	21 d0                	and    %edx,%eax
   15f0d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   15f11:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   15f14:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15f17:	89 44 24 08          	mov    %eax,0x8(%esp)
   15f1b:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15f1e:	89 44 24 04          	mov    %eax,0x4(%esp)
   15f22:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15f25:	89 04 24             	mov    %eax,(%esp)
   15f28:	e8 fc ff ff ff       	call   15f29 <ck_ring_enqueue_spmc_child+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   15f2d:	e8 32 dd ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   15f32:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15f35:	8d 50 40             	lea    0x40(%eax),%edx
   15f38:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   15f3b:	89 44 24 04          	mov    %eax,0x4(%esp)
   15f3f:	89 14 24             	mov    %edx,(%esp)
   15f42:	e8 90 d0 ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   15f47:	b8 01 00 00 00       	mov    $0x1,%eax
   15f4c:	c9                   	leave  
   15f4d:	c3                   	ret    

00015f4e <ck_ring_trydequeue_spmc_child>:
   15f4e:	55                   	push   %ebp
   15f4f:	89 e5                	mov    %esp,%ebp
   15f51:	83 ec 38             	sub    $0x38,%esp
   15f54:	8b 45 08             	mov    0x8(%ebp),%eax
   15f57:	89 45 f4             	mov    %eax,-0xc(%ebp)
   15f5a:	8b 45 0c             	mov    0xc(%ebp),%eax
   15f5d:	89 45 f0             	mov    %eax,-0x10(%ebp)
   15f60:	8b 45 10             	mov    0x10(%ebp),%eax
   15f63:	89 45 ec             	mov    %eax,-0x14(%ebp)
   15f66:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   15f6d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15f70:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   15f76:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   15f79:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15f7c:	89 04 24             	mov    %eax,(%esp)
   15f7f:	e8 ca cf ff ff       	call   12f4e <ck_pr_md_load_uint>
   15f84:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   15f87:	e8 cd dc ff ff       	call   13c59 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   15f8c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15f8f:	83 c0 40             	add    $0x40,%eax
   15f92:	89 04 24             	mov    %eax,(%esp)
   15f95:	e8 b4 cf ff ff       	call   12f4e <ck_pr_md_load_uint>
   15f9a:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   15f9d:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15fa0:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   15fa3:	0f 94 c0             	sete   %al
   15fa6:	0f b6 c0             	movzbl %al,%eax
   15fa9:	85 c0                	test   %eax,%eax
   15fab:	74 07                	je     15fb4 <ck_ring_trydequeue_spmc_child+0x66>
		return false;
   15fad:	b8 00 00 00 00       	mov    $0x0,%eax
   15fb2:	eb 4e                	jmp    16002 <ck_ring_trydequeue_spmc_child+0xb4>

	ck_pr_fence_load();
   15fb4:	e8 a0 dc ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   15fb9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15fbc:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   15fbf:	21 d0                	and    %edx,%eax
   15fc1:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   15fc5:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   15fc8:	8b 45 e8             	mov    -0x18(%ebp),%eax
   15fcb:	89 44 24 08          	mov    %eax,0x8(%esp)
   15fcf:	8b 45 f0             	mov    -0x10(%ebp),%eax
   15fd2:	89 44 24 04          	mov    %eax,0x4(%esp)
   15fd6:	8b 45 ec             	mov    -0x14(%ebp),%eax
   15fd9:	89 04 24             	mov    %eax,(%esp)
   15fdc:	e8 fc ff ff ff       	call   15fdd <ck_ring_trydequeue_spmc_child+0x8f>

	ck_pr_fence_store_atomic();
   15fe1:	e8 47 dc ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   15fe6:	8b 45 e0             	mov    -0x20(%ebp),%eax
   15fe9:	8d 50 01             	lea    0x1(%eax),%edx
   15fec:	8b 45 f4             	mov    -0xc(%ebp),%eax
   15fef:	89 54 24 08          	mov    %edx,0x8(%esp)
   15ff3:	8b 55 e0             	mov    -0x20(%ebp),%edx
   15ff6:	89 54 24 04          	mov    %edx,0x4(%esp)
   15ffa:	89 04 24             	mov    %eax,(%esp)
   15ffd:	e8 fa d7 ff ff       	call   137fc <ck_pr_cas_uint>
   16002:	c9                   	leave  
   16003:	c3                   	ret    

00016004 <ck_ring_dequeue_spmc_child>:
   16004:	55                   	push   %ebp
   16005:	89 e5                	mov    %esp,%ebp
   16007:	53                   	push   %ebx
   16008:	83 ec 34             	sub    $0x34,%esp
   1600b:	8b 45 08             	mov    0x8(%ebp),%eax
   1600e:	89 45 f4             	mov    %eax,-0xc(%ebp)
   16011:	8b 45 0c             	mov    0xc(%ebp),%eax
   16014:	89 45 f0             	mov    %eax,-0x10(%ebp)
   16017:	8b 45 10             	mov    0x10(%ebp),%eax
   1601a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1601d:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   16024:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16027:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1602d:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   16030:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16033:	89 04 24             	mov    %eax,(%esp)
   16036:	e8 13 cf ff ff       	call   12f4e <ck_pr_md_load_uint>
   1603b:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   1603e:	e8 16 dc ff ff       	call   13c59 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   16043:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16046:	83 c0 40             	add    $0x40,%eax
   16049:	89 04 24             	mov    %eax,(%esp)
   1604c:	e8 fd ce ff ff       	call   12f4e <ck_pr_md_load_uint>
   16051:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   16054:	8b 45 d8             	mov    -0x28(%ebp),%eax
   16057:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1605a:	0f 94 c0             	sete   %al
   1605d:	0f b6 c0             	movzbl %al,%eax
   16060:	85 c0                	test   %eax,%eax
   16062:	74 07                	je     1606b <ck_ring_dequeue_spmc_child+0x67>
			return false;
   16064:	b8 00 00 00 00       	mov    $0x0,%eax
   16069:	eb 6a                	jmp    160d5 <ck_ring_dequeue_spmc_child+0xd1>

		ck_pr_fence_load();
   1606b:	e8 e9 db ff ff       	call   13c59 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   16070:	8b 45 d8             	mov    -0x28(%ebp),%eax
   16073:	23 45 e4             	and    -0x1c(%ebp),%eax
   16076:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1607a:	89 c2                	mov    %eax,%edx
   1607c:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1607f:	01 d0                	add    %edx,%eax
   16081:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   16084:	8b 45 e8             	mov    -0x18(%ebp),%eax
   16087:	89 44 24 08          	mov    %eax,0x8(%esp)
   1608b:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1608e:	89 44 24 04          	mov    %eax,0x4(%esp)
   16092:	8b 45 ec             	mov    -0x14(%ebp),%eax
   16095:	89 04 24             	mov    %eax,(%esp)
   16098:	e8 fc ff ff ff       	call   16099 <ck_ring_dequeue_spmc_child+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   1609d:	e8 8b db ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   160a2:	8b 45 d8             	mov    -0x28(%ebp),%eax
   160a5:	8d 58 01             	lea    0x1(%eax),%ebx
   160a8:	8b 55 d8             	mov    -0x28(%ebp),%edx
   160ab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   160ae:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   160b1:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   160b5:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   160b9:	89 54 24 04          	mov    %edx,0x4(%esp)
   160bd:	89 04 24             	mov    %eax,(%esp)
   160c0:	e8 8a d8 ff ff       	call   1394f <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   160c5:	83 f0 01             	xor    $0x1,%eax
   160c8:	84 c0                	test   %al,%al
   160ca:	0f 85 6e ff ff ff    	jne    1603e <ck_ring_dequeue_spmc_child+0x3a>

	return true;
   160d0:	b8 01 00 00 00       	mov    $0x1,%eax
   160d5:	83 c4 34             	add    $0x34,%esp
   160d8:	5b                   	pop    %ebx
   160d9:	5d                   	pop    %ebp
   160da:	c3                   	ret    

000160db <ck_ring_enqueue_mpsc_child>:
   160db:	55                   	push   %ebp
   160dc:	89 e5                	mov    %esp,%ebp
   160de:	83 ec 48             	sub    $0x48,%esp
   160e1:	8b 45 08             	mov    0x8(%ebp),%eax
   160e4:	89 45 f4             	mov    %eax,-0xc(%ebp)
   160e7:	8b 45 0c             	mov    0xc(%ebp),%eax
   160ea:	89 45 f0             	mov    %eax,-0x10(%ebp)
   160ed:	8b 45 10             	mov    0x10(%ebp),%eax
   160f0:	89 45 ec             	mov    %eax,-0x14(%ebp)
   160f3:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
   160fa:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   16101:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16104:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1610a:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1610d:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   16111:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16114:	83 c0 44             	add    $0x44,%eax
   16117:	89 04 24             	mov    %eax,(%esp)
   1611a:	e8 2f ce ff ff       	call   12f4e <ck_pr_md_load_uint>
   1611f:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   16122:	e8 32 db ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   16127:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1612a:	89 04 24             	mov    %eax,(%esp)
   1612d:	e8 1c ce ff ff       	call   12f4e <ck_pr_md_load_uint>
   16132:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   16135:	8b 45 cc             	mov    -0x34(%ebp),%eax
   16138:	83 c0 01             	add    $0x1,%eax
   1613b:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1613e:	8b 45 cc             	mov    -0x34(%ebp),%eax
   16141:	2b 45 d8             	sub    -0x28(%ebp),%eax
   16144:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   16147:	0f 97 c0             	seta   %al
   1614a:	0f b6 c0             	movzbl %al,%eax
   1614d:	85 c0                	test   %eax,%eax
   1614f:	74 29                	je     1617a <ck_ring_enqueue_mpsc_child+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   16151:	8b 45 cc             	mov    -0x34(%ebp),%eax
   16154:	8b 55 f4             	mov    -0xc(%ebp),%edx
   16157:	8d 4a 44             	lea    0x44(%edx),%ecx
   1615a:	8d 55 cc             	lea    -0x34(%ebp),%edx
   1615d:	89 54 24 0c          	mov    %edx,0xc(%esp)
   16161:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   16164:	89 54 24 08          	mov    %edx,0x8(%esp)
   16168:	89 44 24 04          	mov    %eax,0x4(%esp)
   1616c:	89 0c 24             	mov    %ecx,(%esp)
   1616f:	e8 db d7 ff ff       	call   1394f <ck_pr_cas_uint_value>
   16174:	84 c0                	test   %al,%al
   16176:	75 31                	jne    161a9 <ck_ring_enqueue_mpsc_child+0xce>
   16178:	eb a8                	jmp    16122 <ck_ring_enqueue_mpsc_child+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1617a:	e8 da da ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1617f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16182:	83 c0 44             	add    $0x44,%eax
   16185:	89 04 24             	mov    %eax,(%esp)
   16188:	e8 c1 cd ff ff       	call   12f4e <ck_pr_md_load_uint>
   1618d:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   16190:	8b 45 cc             	mov    -0x34(%ebp),%eax
   16193:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   16196:	75 06                	jne    1619e <ck_ring_enqueue_mpsc_child+0xc3>
				r = false;
   16198:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1619c:	eb 67                	jmp    16205 <ck_ring_enqueue_mpsc_child+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1619e:	8b 45 d0             	mov    -0x30(%ebp),%eax
   161a1:	89 45 cc             	mov    %eax,-0x34(%ebp)
   161a4:	e9 79 ff ff ff       	jmp    16122 <ck_ring_enqueue_mpsc_child+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   161a9:	8b 45 cc             	mov    -0x34(%ebp),%eax
   161ac:	23 45 e0             	and    -0x20(%ebp),%eax
   161af:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   161b3:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   161b6:	8b 45 e8             	mov    -0x18(%ebp),%eax
   161b9:	89 44 24 08          	mov    %eax,0x8(%esp)
   161bd:	8b 45 ec             	mov    -0x14(%ebp),%eax
   161c0:	89 44 24 04          	mov    %eax,0x4(%esp)
   161c4:	8b 45 f0             	mov    -0x10(%ebp),%eax
   161c7:	89 04 24             	mov    %eax,(%esp)
   161ca:	e8 fc ff ff ff       	call   161cb <ck_ring_enqueue_mpsc_child+0xf0>
   161cf:	eb 05                	jmp    161d6 <ck_ring_enqueue_mpsc_child+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   161d1:	e8 13 cc ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   161d6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   161d9:	83 c0 40             	add    $0x40,%eax
   161dc:	89 04 24             	mov    %eax,(%esp)
   161df:	e8 6a cd ff ff       	call   12f4e <ck_pr_md_load_uint>
   161e4:	8b 55 cc             	mov    -0x34(%ebp),%edx
   161e7:	39 d0                	cmp    %edx,%eax
   161e9:	75 e6                	jne    161d1 <ck_ring_enqueue_mpsc_child+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   161eb:	e8 74 da ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   161f0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   161f3:	8d 50 40             	lea    0x40(%eax),%edx
   161f6:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   161f9:	89 44 24 04          	mov    %eax,0x4(%esp)
   161fd:	89 14 24             	mov    %edx,(%esp)
   16200:	e8 d2 cd ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   16205:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   16209:	74 10                	je     1621b <ck_ring_enqueue_mpsc_child+0x140>
		*size = (producer - consumer) & mask;
   1620b:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1620e:	2b 45 d8             	sub    -0x28(%ebp),%eax
   16211:	23 45 e0             	and    -0x20(%ebp),%eax
   16214:	89 c2                	mov    %eax,%edx
   16216:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   16219:	89 10                	mov    %edx,(%eax)

	return r;
   1621b:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   1621f:	c9                   	leave  
   16220:	c3                   	ret    

00016221 <ck_ring_enqueue_mpsc_size_child>:
   16221:	55                   	push   %ebp
   16222:	89 e5                	mov    %esp,%ebp
   16224:	83 ec 68             	sub    $0x68,%esp
   16227:	8b 45 08             	mov    0x8(%ebp),%eax
   1622a:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1622d:	8b 45 0c             	mov    0xc(%ebp),%eax
   16230:	89 45 f0             	mov    %eax,-0x10(%ebp)
   16233:	8b 45 10             	mov    0x10(%ebp),%eax
   16236:	89 45 ec             	mov    %eax,-0x14(%ebp)
   16239:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
   16240:	8b 45 14             	mov    0x14(%ebp),%eax
   16243:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   16246:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16249:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1624c:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1624f:	89 45 dc             	mov    %eax,-0x24(%ebp)
   16252:	8b 45 ec             	mov    -0x14(%ebp),%eax
   16255:	89 45 d8             	mov    %eax,-0x28(%ebp)
   16258:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1625b:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1625e:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   16261:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   16264:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16267:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1626d:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   16270:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   16274:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16277:	83 c0 44             	add    $0x44,%eax
   1627a:	89 04 24             	mov    %eax,(%esp)
   1627d:	e8 cc cc ff ff       	call   12f4e <ck_pr_md_load_uint>
   16282:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   16285:	e8 cf d9 ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1628a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1628d:	89 04 24             	mov    %eax,(%esp)
   16290:	e8 b9 cc ff ff       	call   12f4e <ck_pr_md_load_uint>
   16295:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   16298:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1629b:	83 c0 01             	add    $0x1,%eax
   1629e:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   162a1:	8b 45 b0             	mov    -0x50(%ebp),%eax
   162a4:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   162a7:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   162aa:	0f 97 c0             	seta   %al
   162ad:	0f b6 c0             	movzbl %al,%eax
   162b0:	85 c0                	test   %eax,%eax
   162b2:	74 29                	je     162dd <ck_ring_enqueue_mpsc_size_child+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   162b4:	8b 45 b0             	mov    -0x50(%ebp),%eax
   162b7:	8b 55 e0             	mov    -0x20(%ebp),%edx
   162ba:	8d 4a 44             	lea    0x44(%edx),%ecx
   162bd:	8d 55 b0             	lea    -0x50(%ebp),%edx
   162c0:	89 54 24 0c          	mov    %edx,0xc(%esp)
   162c4:	8b 55 c0             	mov    -0x40(%ebp),%edx
   162c7:	89 54 24 08          	mov    %edx,0x8(%esp)
   162cb:	89 44 24 04          	mov    %eax,0x4(%esp)
   162cf:	89 0c 24             	mov    %ecx,(%esp)
   162d2:	e8 78 d6 ff ff       	call   1394f <ck_pr_cas_uint_value>
   162d7:	84 c0                	test   %al,%al
   162d9:	75 31                	jne    1630c <ck_ring_enqueue_mpsc_size_child+0xeb>
   162db:	eb a8                	jmp    16285 <ck_ring_enqueue_mpsc_size_child+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   162dd:	e8 77 d9 ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   162e2:	8b 45 e0             	mov    -0x20(%ebp),%eax
   162e5:	83 c0 44             	add    $0x44,%eax
   162e8:	89 04 24             	mov    %eax,(%esp)
   162eb:	e8 5e cc ff ff       	call   12f4e <ck_pr_md_load_uint>
   162f0:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   162f3:	8b 45 b0             	mov    -0x50(%ebp),%eax
   162f6:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   162f9:	75 06                	jne    16301 <ck_ring_enqueue_mpsc_size_child+0xe0>
				r = false;
   162fb:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   162ff:	eb 67                	jmp    16368 <ck_ring_enqueue_mpsc_size_child+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   16301:	8b 45 bc             	mov    -0x44(%ebp),%eax
   16304:	89 45 b0             	mov    %eax,-0x50(%ebp)
   16307:	e9 79 ff ff ff       	jmp    16285 <ck_ring_enqueue_mpsc_size_child+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1630c:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1630f:	23 45 cc             	and    -0x34(%ebp),%eax
   16312:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   16316:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   16319:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1631c:	89 44 24 08          	mov    %eax,0x8(%esp)
   16320:	8b 45 d8             	mov    -0x28(%ebp),%eax
   16323:	89 44 24 04          	mov    %eax,0x4(%esp)
   16327:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1632a:	89 04 24             	mov    %eax,(%esp)
   1632d:	e8 fc ff ff ff       	call   1632e <ck_ring_enqueue_mpsc_size_child+0x10d>
   16332:	eb 05                	jmp    16339 <ck_ring_enqueue_mpsc_size_child+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   16334:	e8 b0 ca ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   16339:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1633c:	83 c0 40             	add    $0x40,%eax
   1633f:	89 04 24             	mov    %eax,(%esp)
   16342:	e8 07 cc ff ff       	call   12f4e <ck_pr_md_load_uint>
   16347:	8b 55 b0             	mov    -0x50(%ebp),%edx
   1634a:	39 d0                	cmp    %edx,%eax
   1634c:	75 e6                	jne    16334 <ck_ring_enqueue_mpsc_size_child+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1634e:	e8 11 d9 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   16353:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16356:	8d 50 40             	lea    0x40(%eax),%edx
   16359:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1635c:	89 44 24 04          	mov    %eax,0x4(%esp)
   16360:	89 14 24             	mov    %edx,(%esp)
   16363:	e8 6f cc ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   16368:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1636c:	74 10                	je     1637e <ck_ring_enqueue_mpsc_size_child+0x15d>
		*size = (producer - consumer) & mask;
   1636e:	8b 45 b0             	mov    -0x50(%ebp),%eax
   16371:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   16374:	23 45 cc             	and    -0x34(%ebp),%eax
   16377:	89 c2                	mov    %eax,%edx
   16379:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1637c:	89 10                	mov    %edx,(%eax)

	return r;
   1637e:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   16382:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   16385:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   16388:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1638b:	89 10                	mov    %edx,(%eax)
	return r;
   1638d:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   16391:	c9                   	leave  
   16392:	c3                   	ret    

00016393 <ck_ring_dequeue_mpsc_child>:
   16393:	55                   	push   %ebp
   16394:	89 e5                	mov    %esp,%ebp
   16396:	83 ec 38             	sub    $0x38,%esp
   16399:	8b 45 08             	mov    0x8(%ebp),%eax
   1639c:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1639f:	8b 45 0c             	mov    0xc(%ebp),%eax
   163a2:	89 45 f0             	mov    %eax,-0x10(%ebp)
   163a5:	8b 45 10             	mov    0x10(%ebp),%eax
   163a8:	89 45 ec             	mov    %eax,-0x14(%ebp)
   163ab:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   163b2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   163b5:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   163bb:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   163be:	8b 45 f4             	mov    -0xc(%ebp),%eax
   163c1:	8b 00                	mov    (%eax),%eax
   163c3:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   163c6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   163c9:	83 c0 40             	add    $0x40,%eax
   163cc:	89 04 24             	mov    %eax,(%esp)
   163cf:	e8 7a cb ff ff       	call   12f4e <ck_pr_md_load_uint>
   163d4:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   163d7:	8b 45 e0             	mov    -0x20(%ebp),%eax
   163da:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   163dd:	0f 94 c0             	sete   %al
   163e0:	0f b6 c0             	movzbl %al,%eax
   163e3:	85 c0                	test   %eax,%eax
   163e5:	74 07                	je     163ee <ck_ring_dequeue_mpsc_child+0x5b>
		return false;
   163e7:	b8 00 00 00 00       	mov    $0x0,%eax
   163ec:	eb 4c                	jmp    1643a <ck_ring_dequeue_mpsc_child+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   163ee:	e8 66 d8 ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   163f3:	8b 45 e0             	mov    -0x20(%ebp),%eax
   163f6:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   163f9:	21 d0                	and    %edx,%eax
   163fb:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   163ff:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   16402:	8b 45 e8             	mov    -0x18(%ebp),%eax
   16405:	89 44 24 08          	mov    %eax,0x8(%esp)
   16409:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1640c:	89 44 24 04          	mov    %eax,0x4(%esp)
   16410:	8b 45 ec             	mov    -0x14(%ebp),%eax
   16413:	89 04 24             	mov    %eax,(%esp)
   16416:	e8 fc ff ff ff       	call   16417 <ck_ring_dequeue_mpsc_child+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   1641b:	e8 44 d8 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   16420:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16423:	8d 50 01             	lea    0x1(%eax),%edx
   16426:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16429:	89 54 24 04          	mov    %edx,0x4(%esp)
   1642d:	89 04 24             	mov    %eax,(%esp)
   16430:	e8 a2 cb ff ff       	call   12fd7 <ck_pr_md_store_uint>
	return true;
   16435:	b8 01 00 00 00       	mov    $0x1,%eax
   1643a:	c9                   	leave  
   1643b:	c3                   	ret    

0001643c <ck_ring_enqueue_mpmc_size_child>:
   1643c:	55                   	push   %ebp
   1643d:	89 e5                	mov    %esp,%ebp
   1643f:	83 ec 68             	sub    $0x68,%esp
   16442:	8b 45 08             	mov    0x8(%ebp),%eax
   16445:	89 45 f4             	mov    %eax,-0xc(%ebp)
   16448:	8b 45 0c             	mov    0xc(%ebp),%eax
   1644b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1644e:	8b 45 10             	mov    0x10(%ebp),%eax
   16451:	89 45 ec             	mov    %eax,-0x14(%ebp)
   16454:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
   1645b:	8b 45 14             	mov    0x14(%ebp),%eax
   1645e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   16461:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16464:	89 45 e0             	mov    %eax,-0x20(%ebp)
   16467:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1646a:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1646d:	8b 45 ec             	mov    -0x14(%ebp),%eax
   16470:	89 45 d8             	mov    %eax,-0x28(%ebp)
   16473:	8b 45 e8             	mov    -0x18(%ebp),%eax
   16476:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   16479:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1647c:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1647f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16482:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   16488:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1648b:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1648f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16492:	83 c0 44             	add    $0x44,%eax
   16495:	89 04 24             	mov    %eax,(%esp)
   16498:	e8 b1 ca ff ff       	call   12f4e <ck_pr_md_load_uint>
   1649d:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   164a0:	e8 b4 d7 ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   164a5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   164a8:	89 04 24             	mov    %eax,(%esp)
   164ab:	e8 9e ca ff ff       	call   12f4e <ck_pr_md_load_uint>
   164b0:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   164b3:	8b 45 b0             	mov    -0x50(%ebp),%eax
   164b6:	83 c0 01             	add    $0x1,%eax
   164b9:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   164bc:	8b 45 b0             	mov    -0x50(%ebp),%eax
   164bf:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   164c2:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   164c5:	0f 97 c0             	seta   %al
   164c8:	0f b6 c0             	movzbl %al,%eax
   164cb:	85 c0                	test   %eax,%eax
   164cd:	74 29                	je     164f8 <ck_ring_enqueue_mpmc_size_child+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   164cf:	8b 45 b0             	mov    -0x50(%ebp),%eax
   164d2:	8b 55 e0             	mov    -0x20(%ebp),%edx
   164d5:	8d 4a 44             	lea    0x44(%edx),%ecx
   164d8:	8d 55 b0             	lea    -0x50(%ebp),%edx
   164db:	89 54 24 0c          	mov    %edx,0xc(%esp)
   164df:	8b 55 c0             	mov    -0x40(%ebp),%edx
   164e2:	89 54 24 08          	mov    %edx,0x8(%esp)
   164e6:	89 44 24 04          	mov    %eax,0x4(%esp)
   164ea:	89 0c 24             	mov    %ecx,(%esp)
   164ed:	e8 5d d4 ff ff       	call   1394f <ck_pr_cas_uint_value>
   164f2:	84 c0                	test   %al,%al
   164f4:	75 31                	jne    16527 <ck_ring_enqueue_mpmc_size_child+0xeb>
   164f6:	eb a8                	jmp    164a0 <ck_ring_enqueue_mpmc_size_child+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   164f8:	e8 5c d7 ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   164fd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16500:	83 c0 44             	add    $0x44,%eax
   16503:	89 04 24             	mov    %eax,(%esp)
   16506:	e8 43 ca ff ff       	call   12f4e <ck_pr_md_load_uint>
   1650b:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1650e:	8b 45 b0             	mov    -0x50(%ebp),%eax
   16511:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   16514:	75 06                	jne    1651c <ck_ring_enqueue_mpmc_size_child+0xe0>
				r = false;
   16516:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   1651a:	eb 67                	jmp    16583 <ck_ring_enqueue_mpmc_size_child+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1651c:	8b 45 bc             	mov    -0x44(%ebp),%eax
   1651f:	89 45 b0             	mov    %eax,-0x50(%ebp)
   16522:	e9 79 ff ff ff       	jmp    164a0 <ck_ring_enqueue_mpmc_size_child+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   16527:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1652a:	23 45 cc             	and    -0x34(%ebp),%eax
   1652d:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   16531:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   16534:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   16537:	89 44 24 08          	mov    %eax,0x8(%esp)
   1653b:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1653e:	89 44 24 04          	mov    %eax,0x4(%esp)
   16542:	8b 45 dc             	mov    -0x24(%ebp),%eax
   16545:	89 04 24             	mov    %eax,(%esp)
   16548:	e8 fc ff ff ff       	call   16549 <ck_ring_enqueue_mpmc_size_child+0x10d>
   1654d:	eb 05                	jmp    16554 <ck_ring_enqueue_mpmc_size_child+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1654f:	e8 95 c8 ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   16554:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16557:	83 c0 40             	add    $0x40,%eax
   1655a:	89 04 24             	mov    %eax,(%esp)
   1655d:	e8 ec c9 ff ff       	call   12f4e <ck_pr_md_load_uint>
   16562:	8b 55 b0             	mov    -0x50(%ebp),%edx
   16565:	39 d0                	cmp    %edx,%eax
   16567:	75 e6                	jne    1654f <ck_ring_enqueue_mpmc_size_child+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   16569:	e8 f6 d6 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1656e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16571:	8d 50 40             	lea    0x40(%eax),%edx
   16574:	8b 45 c0             	mov    -0x40(%ebp),%eax
   16577:	89 44 24 04          	mov    %eax,0x4(%esp)
   1657b:	89 14 24             	mov    %edx,(%esp)
   1657e:	e8 54 ca ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   16583:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   16587:	74 10                	je     16599 <ck_ring_enqueue_mpmc_size_child+0x15d>
		*size = (producer - consumer) & mask;
   16589:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1658c:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1658f:	23 45 cc             	and    -0x34(%ebp),%eax
   16592:	89 c2                	mov    %eax,%edx
   16594:	8b 45 d0             	mov    -0x30(%ebp),%eax
   16597:	89 10                	mov    %edx,(%eax)

	return r;
   16599:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   1659d:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   165a0:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   165a3:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   165a6:	89 10                	mov    %edx,(%eax)
	return r;
   165a8:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   165ac:	c9                   	leave  
   165ad:	c3                   	ret    

000165ae <ck_ring_enqueue_mpmc_child>:
   165ae:	55                   	push   %ebp
   165af:	89 e5                	mov    %esp,%ebp
   165b1:	83 ec 48             	sub    $0x48,%esp
   165b4:	8b 45 08             	mov    0x8(%ebp),%eax
   165b7:	89 45 f4             	mov    %eax,-0xc(%ebp)
   165ba:	8b 45 0c             	mov    0xc(%ebp),%eax
   165bd:	89 45 f0             	mov    %eax,-0x10(%ebp)
   165c0:	8b 45 10             	mov    0x10(%ebp),%eax
   165c3:	89 45 ec             	mov    %eax,-0x14(%ebp)
   165c6:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
   165cd:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   165d4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   165d7:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   165dd:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   165e0:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   165e4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   165e7:	83 c0 44             	add    $0x44,%eax
   165ea:	89 04 24             	mov    %eax,(%esp)
   165ed:	e8 5c c9 ff ff       	call   12f4e <ck_pr_md_load_uint>
   165f2:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   165f5:	e8 5f d6 ff ff       	call   13c59 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   165fa:	8b 45 f4             	mov    -0xc(%ebp),%eax
   165fd:	89 04 24             	mov    %eax,(%esp)
   16600:	e8 49 c9 ff ff       	call   12f4e <ck_pr_md_load_uint>
   16605:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   16608:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1660b:	83 c0 01             	add    $0x1,%eax
   1660e:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   16611:	8b 45 cc             	mov    -0x34(%ebp),%eax
   16614:	2b 45 d8             	sub    -0x28(%ebp),%eax
   16617:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1661a:	0f 97 c0             	seta   %al
   1661d:	0f b6 c0             	movzbl %al,%eax
   16620:	85 c0                	test   %eax,%eax
   16622:	74 29                	je     1664d <ck_ring_enqueue_mpmc_child+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   16624:	8b 45 cc             	mov    -0x34(%ebp),%eax
   16627:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1662a:	8d 4a 44             	lea    0x44(%edx),%ecx
   1662d:	8d 55 cc             	lea    -0x34(%ebp),%edx
   16630:	89 54 24 0c          	mov    %edx,0xc(%esp)
   16634:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   16637:	89 54 24 08          	mov    %edx,0x8(%esp)
   1663b:	89 44 24 04          	mov    %eax,0x4(%esp)
   1663f:	89 0c 24             	mov    %ecx,(%esp)
   16642:	e8 08 d3 ff ff       	call   1394f <ck_pr_cas_uint_value>
   16647:	84 c0                	test   %al,%al
   16649:	75 31                	jne    1667c <ck_ring_enqueue_mpmc_child+0xce>
   1664b:	eb a8                	jmp    165f5 <ck_ring_enqueue_mpmc_child+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1664d:	e8 07 d6 ff ff       	call   13c59 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   16652:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16655:	83 c0 44             	add    $0x44,%eax
   16658:	89 04 24             	mov    %eax,(%esp)
   1665b:	e8 ee c8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   16660:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   16663:	8b 45 cc             	mov    -0x34(%ebp),%eax
   16666:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   16669:	75 06                	jne    16671 <ck_ring_enqueue_mpmc_child+0xc3>
				r = false;
   1666b:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1666f:	eb 67                	jmp    166d8 <ck_ring_enqueue_mpmc_child+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   16671:	8b 45 d0             	mov    -0x30(%ebp),%eax
   16674:	89 45 cc             	mov    %eax,-0x34(%ebp)
   16677:	e9 79 ff ff ff       	jmp    165f5 <ck_ring_enqueue_mpmc_child+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1667c:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1667f:	23 45 e0             	and    -0x20(%ebp),%eax
   16682:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   16686:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   16689:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1668c:	89 44 24 08          	mov    %eax,0x8(%esp)
   16690:	8b 45 ec             	mov    -0x14(%ebp),%eax
   16693:	89 44 24 04          	mov    %eax,0x4(%esp)
   16697:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1669a:	89 04 24             	mov    %eax,(%esp)
   1669d:	e8 fc ff ff ff       	call   1669e <ck_ring_enqueue_mpmc_child+0xf0>
   166a2:	eb 05                	jmp    166a9 <ck_ring_enqueue_mpmc_child+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   166a4:	e8 40 c7 ff ff       	call   12de9 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   166a9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   166ac:	83 c0 40             	add    $0x40,%eax
   166af:	89 04 24             	mov    %eax,(%esp)
   166b2:	e8 97 c8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   166b7:	8b 55 cc             	mov    -0x34(%ebp),%edx
   166ba:	39 d0                	cmp    %edx,%eax
   166bc:	75 e6                	jne    166a4 <ck_ring_enqueue_mpmc_child+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   166be:	e8 a1 d5 ff ff       	call   13c64 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   166c3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   166c6:	8d 50 40             	lea    0x40(%eax),%edx
   166c9:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   166cc:	89 44 24 04          	mov    %eax,0x4(%esp)
   166d0:	89 14 24             	mov    %edx,(%esp)
   166d3:	e8 ff c8 ff ff       	call   12fd7 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   166d8:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   166dc:	74 10                	je     166ee <ck_ring_enqueue_mpmc_child+0x140>
		*size = (producer - consumer) & mask;
   166de:	8b 45 cc             	mov    -0x34(%ebp),%eax
   166e1:	2b 45 d8             	sub    -0x28(%ebp),%eax
   166e4:	23 45 e0             	and    -0x20(%ebp),%eax
   166e7:	89 c2                	mov    %eax,%edx
   166e9:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   166ec:	89 10                	mov    %edx,(%eax)

	return r;
   166ee:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   166f2:	c9                   	leave  
   166f3:	c3                   	ret    

000166f4 <ck_ring_trydequeue_mpmc_child>:
   166f4:	55                   	push   %ebp
   166f5:	89 e5                	mov    %esp,%ebp
   166f7:	83 ec 38             	sub    $0x38,%esp
   166fa:	8b 45 08             	mov    0x8(%ebp),%eax
   166fd:	89 45 f4             	mov    %eax,-0xc(%ebp)
   16700:	8b 45 0c             	mov    0xc(%ebp),%eax
   16703:	89 45 f0             	mov    %eax,-0x10(%ebp)
   16706:	8b 45 10             	mov    0x10(%ebp),%eax
   16709:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1670c:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   16713:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16716:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1671c:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1671f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16722:	89 04 24             	mov    %eax,(%esp)
   16725:	e8 24 c8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   1672a:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   1672d:	e8 27 d5 ff ff       	call   13c59 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   16732:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16735:	83 c0 40             	add    $0x40,%eax
   16738:	89 04 24             	mov    %eax,(%esp)
   1673b:	e8 0e c8 ff ff       	call   12f4e <ck_pr_md_load_uint>
   16740:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   16743:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16746:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   16749:	0f 94 c0             	sete   %al
   1674c:	0f b6 c0             	movzbl %al,%eax
   1674f:	85 c0                	test   %eax,%eax
   16751:	74 07                	je     1675a <ck_ring_trydequeue_mpmc_child+0x66>
		return false;
   16753:	b8 00 00 00 00       	mov    $0x0,%eax
   16758:	eb 4e                	jmp    167a8 <ck_ring_trydequeue_mpmc_child+0xb4>

	ck_pr_fence_load();
   1675a:	e8 fa d4 ff ff       	call   13c59 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1675f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   16762:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   16765:	21 d0                	and    %edx,%eax
   16767:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1676b:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1676e:	8b 45 e8             	mov    -0x18(%ebp),%eax
   16771:	89 44 24 08          	mov    %eax,0x8(%esp)
   16775:	8b 45 f0             	mov    -0x10(%ebp),%eax
   16778:	89 44 24 04          	mov    %eax,0x4(%esp)
   1677c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1677f:	89 04 24             	mov    %eax,(%esp)
   16782:	e8 fc ff ff ff       	call   16783 <ck_ring_trydequeue_mpmc_child+0x8f>

	ck_pr_fence_store_atomic();
   16787:	e8 a1 d4 ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1678c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1678f:	8d 50 01             	lea    0x1(%eax),%edx
   16792:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16795:	89 54 24 08          	mov    %edx,0x8(%esp)
   16799:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1679c:	89 54 24 04          	mov    %edx,0x4(%esp)
   167a0:	89 04 24             	mov    %eax,(%esp)
   167a3:	e8 54 d0 ff ff       	call   137fc <ck_pr_cas_uint>
   167a8:	c9                   	leave  
   167a9:	c3                   	ret    

000167aa <ck_ring_dequeue_mpmc_child>:
   167aa:	55                   	push   %ebp
   167ab:	89 e5                	mov    %esp,%ebp
   167ad:	53                   	push   %ebx
   167ae:	83 ec 34             	sub    $0x34,%esp
   167b1:	8b 45 08             	mov    0x8(%ebp),%eax
   167b4:	89 45 f4             	mov    %eax,-0xc(%ebp)
   167b7:	8b 45 0c             	mov    0xc(%ebp),%eax
   167ba:	89 45 f0             	mov    %eax,-0x10(%ebp)
   167bd:	8b 45 10             	mov    0x10(%ebp),%eax
   167c0:	89 45 ec             	mov    %eax,-0x14(%ebp)
   167c3:	c7 45 e8 08 00 00 00 	movl   $0x8,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   167ca:	8b 45 f4             	mov    -0xc(%ebp),%eax
   167cd:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   167d3:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   167d6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   167d9:	89 04 24             	mov    %eax,(%esp)
   167dc:	e8 6d c7 ff ff       	call   12f4e <ck_pr_md_load_uint>
   167e1:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   167e4:	e8 70 d4 ff ff       	call   13c59 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   167e9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   167ec:	83 c0 40             	add    $0x40,%eax
   167ef:	89 04 24             	mov    %eax,(%esp)
   167f2:	e8 57 c7 ff ff       	call   12f4e <ck_pr_md_load_uint>
   167f7:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   167fa:	8b 45 d8             	mov    -0x28(%ebp),%eax
   167fd:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   16800:	0f 94 c0             	sete   %al
   16803:	0f b6 c0             	movzbl %al,%eax
   16806:	85 c0                	test   %eax,%eax
   16808:	74 07                	je     16811 <ck_ring_dequeue_mpmc_child+0x67>
			return false;
   1680a:	b8 00 00 00 00       	mov    $0x0,%eax
   1680f:	eb 6a                	jmp    1687b <ck_ring_dequeue_mpmc_child+0xd1>

		ck_pr_fence_load();
   16811:	e8 43 d4 ff ff       	call   13c59 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   16816:	8b 45 d8             	mov    -0x28(%ebp),%eax
   16819:	23 45 e4             	and    -0x1c(%ebp),%eax
   1681c:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   16820:	89 c2                	mov    %eax,%edx
   16822:	8b 45 f0             	mov    -0x10(%ebp),%eax
   16825:	01 d0                	add    %edx,%eax
   16827:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   1682a:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1682d:	89 44 24 08          	mov    %eax,0x8(%esp)
   16831:	8b 45 dc             	mov    -0x24(%ebp),%eax
   16834:	89 44 24 04          	mov    %eax,0x4(%esp)
   16838:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1683b:	89 04 24             	mov    %eax,(%esp)
   1683e:	e8 fc ff ff ff       	call   1683f <ck_ring_dequeue_mpmc_child+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   16843:	e8 e5 d3 ff ff       	call   13c2d <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   16848:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1684b:	8d 58 01             	lea    0x1(%eax),%ebx
   1684e:	8b 55 d8             	mov    -0x28(%ebp),%edx
   16851:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16854:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   16857:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1685b:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1685f:	89 54 24 04          	mov    %edx,0x4(%esp)
   16863:	89 04 24             	mov    %eax,(%esp)
   16866:	e8 e4 d0 ff ff       	call   1394f <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   1686b:	83 f0 01             	xor    $0x1,%eax
   1686e:	84 c0                	test   %al,%al
   16870:	0f 85 6e ff ff ff    	jne    167e4 <ck_ring_dequeue_mpmc_child+0x3a>

	return true;
   16876:	b8 01 00 00 00       	mov    $0x1,%eax
   1687b:	83 c4 34             	add    $0x34,%esp
   1687e:	5b                   	pop    %ebx
   1687f:	5d                   	pop    %ebp
   16880:	c3                   	ret    

00016881 <sl_child_ring>:

/* in-place ring-buff! NO POINTER PASSING!! */
static inline struct ck_ring *
sl_child_ring(vaddr_t vaddr)
{
   16881:	55                   	push   %ebp
   16882:	89 e5                	mov    %esp,%ebp
	return (struct ck_ring *)(vaddr);
   16884:	8b 45 08             	mov    0x8(%ebp),%eax
}
   16887:	5d                   	pop    %ebp
   16888:	c3                   	ret    

00016889 <sl_child_notif_buffer>:

static inline struct sl_child_notification *
sl_child_notif_buffer(vaddr_t vaddr)
{
   16889:	55                   	push   %ebp
   1688a:	89 e5                	mov    %esp,%ebp
	return (struct sl_child_notification *)(vaddr + sizeof(struct ck_ring));
   1688c:	8b 45 08             	mov    0x8(%ebp),%eax
   1688f:	05 88 00 00 00       	add    $0x88,%eax
}
   16894:	5d                   	pop    %ebp
   16895:	c3                   	ret    

00016896 <sl_parent_notif_alloc>:
extern cbuf_t  sl_shm_alloc(vaddr_t *addr);
extern vaddr_t sl_shm_map(cbuf_t id);

cbuf_t
sl_parent_notif_alloc(struct sl_thd *childthd)
{
   16896:	55                   	push   %ebp
   16897:	89 e5                	mov    %esp,%ebp
   16899:	83 ec 28             	sub    $0x28,%esp
	vaddr_t shmaddr = 0;
   1689c:	c7 45 e8 00 00 00 00 	movl   $0x0,-0x18(%ebp)
	cbuf_t id = 0;
   168a3:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct ck_ring *cring = NULL;
   168aa:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	struct sl_child_notification *crbuf = NULL;
   168b1:	c7 45 ec 00 00 00 00 	movl   $0x0,-0x14(%ebp)

	assert(childthd && (childthd->properties & SL_THD_PROPERTY_SEND));
   168b8:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   168bc:	0f 94 c0             	sete   %al
   168bf:	0f b6 c0             	movzbl %al,%eax
   168c2:	85 c0                	test   %eax,%eax
   168c4:	75 15                	jne    168db <sl_parent_notif_alloc+0x45>
   168c6:	8b 45 08             	mov    0x8(%ebp),%eax
   168c9:	8b 40 08             	mov    0x8(%eax),%eax
   168cc:	83 e0 02             	and    $0x2,%eax
   168cf:	85 c0                	test   %eax,%eax
   168d1:	0f 94 c0             	sete   %al
   168d4:	0f b6 c0             	movzbl %al,%eax
   168d7:	85 c0                	test   %eax,%eax
   168d9:	74 1c                	je     168f7 <sl_parent_notif_alloc+0x61>
   168db:	c7 04 24 80 2e 00 00 	movl   $0x2e80,(%esp)
   168e2:	e8 45 c1 ff ff       	call   12a2c <prints>
   168e7:	a1 a0 02 00 00       	mov    0x2a0,%eax
   168ec:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   168f2:	e8 bc c1 ff ff       	call   12ab3 <__cos_noret>

	sl_cs_enter();
   168f7:	e8 52 f1 ff ff       	call   15a4e <sl_cs_enter>

	id = sl_shm_alloc(&shmaddr);
   168fc:	8d 45 e8             	lea    -0x18(%ebp),%eax
   168ff:	89 04 24             	mov    %eax,(%esp)
   16902:	e8 fc ff ff ff       	call   16903 <sl_parent_notif_alloc+0x6d>
   16907:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (!id) goto done;
   1690a:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
   1690e:	75 02                	jne    16912 <sl_parent_notif_alloc+0x7c>
   16910:	eb 75                	jmp    16987 <sl_parent_notif_alloc+0xf1>

	assert(shmaddr);
   16912:	8b 45 e8             	mov    -0x18(%ebp),%eax
   16915:	85 c0                	test   %eax,%eax
   16917:	0f 94 c0             	sete   %al
   1691a:	0f b6 c0             	movzbl %al,%eax
   1691d:	85 c0                	test   %eax,%eax
   1691f:	74 1c                	je     1693d <sl_parent_notif_alloc+0xa7>
   16921:	c7 04 24 ac 2e 00 00 	movl   $0x2eac,(%esp)
   16928:	e8 ff c0 ff ff       	call   12a2c <prints>
   1692d:	a1 a0 02 00 00       	mov    0x2a0,%eax
   16932:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   16938:	e8 76 c1 ff ff       	call   12ab3 <__cos_noret>
	cring = sl_child_ring(shmaddr);
   1693d:	8b 45 e8             	mov    -0x18(%ebp),%eax
   16940:	89 04 24             	mov    %eax,(%esp)
   16943:	e8 39 ff ff ff       	call   16881 <sl_child_ring>
   16948:	89 45 f0             	mov    %eax,-0x10(%ebp)
	crbuf = sl_child_notif_buffer(shmaddr);
   1694b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1694e:	89 04 24             	mov    %eax,(%esp)
   16951:	e8 33 ff ff ff       	call   16889 <sl_child_notif_buffer>
   16956:	89 45 ec             	mov    %eax,-0x14(%ebp)

	ck_ring_init(cring, SL_CHILD_RBUF_SZ);
   16959:	c7 44 24 04 00 02 00 	movl   $0x200,0x4(%esp)
   16960:	00 
   16961:	8b 45 f0             	mov    -0x10(%ebp),%eax
   16964:	89 04 24             	mov    %eax,(%esp)
   16967:	e8 93 d3 ff ff       	call   13cff <ck_ring_init>
	childthd->shmid      = id;
   1696c:	8b 45 08             	mov    0x8(%ebp),%eax
   1696f:	8b 55 f4             	mov    -0xc(%ebp),%edx
   16972:	89 50 1c             	mov    %edx,0x1c(%eax)
	childthd->ch_ringbuf = crbuf;
   16975:	8b 45 08             	mov    0x8(%ebp),%eax
   16978:	8b 55 ec             	mov    -0x14(%ebp),%edx
   1697b:	89 50 24             	mov    %edx,0x24(%eax)
	childthd->ch_ring    = cring;
   1697e:	8b 45 08             	mov    0x8(%ebp),%eax
   16981:	8b 55 f0             	mov    -0x10(%ebp),%edx
   16984:	89 50 20             	mov    %edx,0x20(%eax)

done:
	sl_cs_exit();
   16987:	e8 d4 f0 ff ff       	call   15a60 <sl_cs_exit>

	return id;
   1698c:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1698f:	c9                   	leave  
   16990:	c3                   	ret    

00016991 <sl_parent_notif_enqueue>:

int
sl_parent_notif_enqueue(struct sl_thd *thd, struct sl_child_notification *notif)
{
   16991:	55                   	push   %ebp
   16992:	89 e5                	mov    %esp,%ebp
   16994:	83 ec 18             	sub    $0x18,%esp
	assert(thd && notif);
   16997:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1699b:	0f 94 c0             	sete   %al
   1699e:	0f b6 c0             	movzbl %al,%eax
   169a1:	85 c0                	test   %eax,%eax
   169a3:	75 0e                	jne    169b3 <sl_parent_notif_enqueue+0x22>
   169a5:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   169a9:	0f 94 c0             	sete   %al
   169ac:	0f b6 c0             	movzbl %al,%eax
   169af:	85 c0                	test   %eax,%eax
   169b1:	74 1c                	je     169cf <sl_parent_notif_enqueue+0x3e>
   169b3:	c7 04 24 d8 2e 00 00 	movl   $0x2ed8,(%esp)
   169ba:	e8 6d c0 ff ff       	call   12a2c <prints>
   169bf:	a1 a0 02 00 00       	mov    0x2a0,%eax
   169c4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   169ca:	e8 e4 c0 ff ff       	call   12ab3 <__cos_noret>
	assert(thd->properties & SL_THD_PROPERTY_SEND);
   169cf:	8b 45 08             	mov    0x8(%ebp),%eax
   169d2:	8b 40 08             	mov    0x8(%eax),%eax
   169d5:	83 e0 02             	and    $0x2,%eax
   169d8:	85 c0                	test   %eax,%eax
   169da:	0f 94 c0             	sete   %al
   169dd:	0f b6 c0             	movzbl %al,%eax
   169e0:	85 c0                	test   %eax,%eax
   169e2:	74 1c                	je     16a00 <sl_parent_notif_enqueue+0x6f>
   169e4:	c7 04 24 04 2f 00 00 	movl   $0x2f04,(%esp)
   169eb:	e8 3c c0 ff ff       	call   12a2c <prints>
   169f0:	a1 a0 02 00 00       	mov    0x2a0,%eax
   169f5:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   169fb:	e8 b3 c0 ff ff       	call   12ab3 <__cos_noret>

	if (!thd->ch_ring) return -1;
   16a00:	8b 45 08             	mov    0x8(%ebp),%eax
   16a03:	8b 40 20             	mov    0x20(%eax),%eax
   16a06:	85 c0                	test   %eax,%eax
   16a08:	75 0a                	jne    16a14 <sl_parent_notif_enqueue+0x83>
   16a0a:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
   16a0f:	e9 86 00 00 00       	jmp    16a9a <sl_parent_notif_enqueue+0x109>
	assert(thd->ch_ringbuf);
   16a14:	8b 45 08             	mov    0x8(%ebp),%eax
   16a17:	8b 40 24             	mov    0x24(%eax),%eax
   16a1a:	85 c0                	test   %eax,%eax
   16a1c:	0f 94 c0             	sete   %al
   16a1f:	0f b6 c0             	movzbl %al,%eax
   16a22:	85 c0                	test   %eax,%eax
   16a24:	74 1c                	je     16a42 <sl_parent_notif_enqueue+0xb1>
   16a26:	c7 04 24 30 2f 00 00 	movl   $0x2f30,(%esp)
   16a2d:	e8 fa bf ff ff       	call   12a2c <prints>
   16a32:	a1 a0 02 00 00       	mov    0x2a0,%eax
   16a37:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   16a3d:	e8 71 c0 ff ff       	call   12ab3 <__cos_noret>

	if (ck_ring_enqueue_spsc_child(thd->ch_ring, thd->ch_ringbuf, notif) == false) return -1;
   16a42:	8b 45 08             	mov    0x8(%ebp),%eax
   16a45:	8b 50 24             	mov    0x24(%eax),%edx
   16a48:	8b 45 08             	mov    0x8(%ebp),%eax
   16a4b:	8b 40 20             	mov    0x20(%eax),%eax
   16a4e:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   16a51:	89 4c 24 08          	mov    %ecx,0x8(%esp)
   16a55:	89 54 24 04          	mov    %edx,0x4(%esp)
   16a59:	89 04 24             	mov    %eax,(%esp)
   16a5c:	e8 9f f1 ff ff       	call   15c00 <ck_ring_enqueue_spsc_child>
   16a61:	83 f0 01             	xor    $0x1,%eax
   16a64:	84 c0                	test   %al,%al
   16a66:	74 07                	je     16a6f <sl_parent_notif_enqueue+0xde>
   16a68:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
   16a6d:	eb 2b                	jmp    16a9a <sl_parent_notif_enqueue+0x109>
	if (cos_asnd(sl_thd_asndcap(thd), 0)) return -1;
   16a6f:	8b 45 08             	mov    0x8(%ebp),%eax
   16a72:	89 04 24             	mov    %eax,(%esp)
   16a75:	e8 98 c2 ff ff       	call   12d12 <sl_thd_asndcap>
   16a7a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   16a81:	00 
   16a82:	89 04 24             	mov    %eax,(%esp)
   16a85:	e8 fc ff ff ff       	call   16a86 <sl_parent_notif_enqueue+0xf5>
   16a8a:	85 c0                	test   %eax,%eax
   16a8c:	74 07                	je     16a95 <sl_parent_notif_enqueue+0x104>
   16a8e:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
   16a93:	eb 05                	jmp    16a9a <sl_parent_notif_enqueue+0x109>

	return 0;
   16a95:	b8 00 00 00 00       	mov    $0x0,%eax
}
   16a9a:	c9                   	leave  
   16a9b:	c3                   	ret    

00016a9c <sl_child_notif_map>:

/* there is only 1 parent per scheduler per cpu */
int
sl_child_notif_map(cbuf_t id)
{
   16a9c:	55                   	push   %ebp
   16a9d:	89 e5                	mov    %esp,%ebp
   16a9f:	53                   	push   %ebx
   16aa0:	83 ec 24             	sub    $0x24,%esp
	vaddr_t shmaddr = 0;
   16aa3:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	assert(id);
   16aaa:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   16aae:	0f 94 c0             	sete   %al
   16ab1:	0f b6 c0             	movzbl %al,%eax
   16ab4:	85 c0                	test   %eax,%eax
   16ab6:	74 1c                	je     16ad4 <sl_child_notif_map+0x38>
   16ab8:	c7 04 24 5c 2f 00 00 	movl   $0x2f5c,(%esp)
   16abf:	e8 68 bf ff ff       	call   12a2c <prints>
   16ac4:	a1 a0 02 00 00       	mov    0x2a0,%eax
   16ac9:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   16acf:	e8 df bf ff ff       	call   12ab3 <__cos_noret>

	sl_cs_enter();
   16ad4:	e8 75 ef ff ff       	call   15a4e <sl_cs_enter>
	shmaddr = sl_shm_map(id);
   16ad9:	8b 45 08             	mov    0x8(%ebp),%eax
   16adc:	89 04 24             	mov    %eax,(%esp)
   16adf:	e8 fc ff ff ff       	call   16ae0 <sl_child_notif_map+0x44>
   16ae4:	89 45 f4             	mov    %eax,-0xc(%ebp)
	if (!shmaddr) {
   16ae7:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
   16aeb:	75 0c                	jne    16af9 <sl_child_notif_map+0x5d>
		sl_cs_exit();
   16aed:	e8 6e ef ff ff       	call   15a60 <sl_cs_exit>
		return -1;
   16af2:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
   16af7:	eb 70                	jmp    16b69 <sl_child_notif_map+0xcd>
	}
	assert(!child_ring[cos_cpuid()]);
   16af9:	e8 b3 bd ff ff       	call   128b1 <cos_cpuid>
   16afe:	8b 04 85 a4 02 00 00 	mov    0x2a4(,%eax,4),%eax
   16b05:	85 c0                	test   %eax,%eax
   16b07:	0f 95 c0             	setne  %al
   16b0a:	0f b6 c0             	movzbl %al,%eax
   16b0d:	85 c0                	test   %eax,%eax
   16b0f:	74 1c                	je     16b2d <sl_child_notif_map+0x91>
   16b11:	c7 04 24 88 2f 00 00 	movl   $0x2f88,(%esp)
   16b18:	e8 0f bf ff ff       	call   12a2c <prints>
   16b1d:	a1 a0 02 00 00       	mov    0x2a0,%eax
   16b22:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   16b28:	e8 86 bf ff ff       	call   12ab3 <__cos_noret>

	child_ring[cos_cpuid()]    = sl_child_ring(shmaddr);
   16b2d:	e8 7f bd ff ff       	call   128b1 <cos_cpuid>
   16b32:	89 c3                	mov    %eax,%ebx
   16b34:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16b37:	89 04 24             	mov    %eax,(%esp)
   16b3a:	e8 42 fd ff ff       	call   16881 <sl_child_ring>
   16b3f:	89 04 9d a4 02 00 00 	mov    %eax,0x2a4(,%ebx,4)
	child_ringbuf[cos_cpuid()] = sl_child_notif_buffer(shmaddr);
   16b46:	e8 66 bd ff ff       	call   128b1 <cos_cpuid>
   16b4b:	89 c3                	mov    %eax,%ebx
   16b4d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16b50:	89 04 24             	mov    %eax,(%esp)
   16b53:	e8 31 fd ff ff       	call   16889 <sl_child_notif_buffer>
   16b58:	89 04 9d a8 02 00 00 	mov    %eax,0x2a8(,%ebx,4)
	sl_cs_exit();
   16b5f:	e8 fc ee ff ff       	call   15a60 <sl_cs_exit>

	return 0;
   16b64:	b8 00 00 00 00       	mov    $0x0,%eax
}
   16b69:	83 c4 24             	add    $0x24,%esp
   16b6c:	5b                   	pop    %ebx
   16b6d:	5d                   	pop    %ebp
   16b6e:	c3                   	ret    

00016b6f <sl_child_notif_dequeue>:

int
sl_child_notif_dequeue(struct sl_child_notification *notif)
{
   16b6f:	55                   	push   %ebp
   16b70:	89 e5                	mov    %esp,%ebp
   16b72:	83 ec 28             	sub    $0x28,%esp
	struct ck_ring *cring = child_ring[cos_cpuid()];
   16b75:	e8 37 bd ff ff       	call   128b1 <cos_cpuid>
   16b7a:	8b 04 85 a4 02 00 00 	mov    0x2a4(,%eax,4),%eax
   16b81:	89 45 f4             	mov    %eax,-0xc(%ebp)
	struct sl_child_notification *crbuf = child_ringbuf[cos_cpuid()];
   16b84:	e8 28 bd ff ff       	call   128b1 <cos_cpuid>
   16b89:	8b 04 85 a8 02 00 00 	mov    0x2a8(,%eax,4),%eax
   16b90:	89 45 f0             	mov    %eax,-0x10(%ebp)

	assert(notif);
   16b93:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   16b97:	0f 94 c0             	sete   %al
   16b9a:	0f b6 c0             	movzbl %al,%eax
   16b9d:	85 c0                	test   %eax,%eax
   16b9f:	74 1c                	je     16bbd <sl_child_notif_dequeue+0x4e>
   16ba1:	c7 04 24 b4 2f 00 00 	movl   $0x2fb4,(%esp)
   16ba8:	e8 7f be ff ff       	call   12a2c <prints>
   16bad:	a1 a0 02 00 00       	mov    0x2a0,%eax
   16bb2:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   16bb8:	e8 f6 be ff ff       	call   12ab3 <__cos_noret>
	if (!cring || !crbuf) return 0;
   16bbd:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
   16bc1:	74 06                	je     16bc9 <sl_child_notif_dequeue+0x5a>
   16bc3:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
   16bc7:	75 07                	jne    16bd0 <sl_child_notif_dequeue+0x61>
   16bc9:	b8 00 00 00 00       	mov    $0x0,%eax
   16bce:	eb 29                	jmp    16bf9 <sl_child_notif_dequeue+0x8a>

	if (ck_ring_dequeue_spsc_child(cring, crbuf, notif) == true) return 1;
   16bd0:	8b 45 08             	mov    0x8(%ebp),%eax
   16bd3:	89 44 24 08          	mov    %eax,0x8(%esp)
   16bd7:	8b 45 f0             	mov    -0x10(%ebp),%eax
   16bda:	89 44 24 04          	mov    %eax,0x4(%esp)
   16bde:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16be1:	89 04 24             	mov    %eax,(%esp)
   16be4:	e8 ea f0 ff ff       	call   15cd3 <ck_ring_dequeue_spsc_child>
   16be9:	84 c0                	test   %al,%al
   16beb:	74 07                	je     16bf4 <sl_child_notif_dequeue+0x85>
   16bed:	b8 01 00 00 00       	mov    $0x1,%eax
   16bf2:	eb 05                	jmp    16bf9 <sl_child_notif_dequeue+0x8a>

	return 0;
   16bf4:	b8 00 00 00 00       	mov    $0x0,%eax
}
   16bf9:	c9                   	leave  
   16bfa:	c3                   	ret    

00016bfb <sl_child_notif_empty>:

int
sl_child_notif_empty(void)
{
   16bfb:	55                   	push   %ebp
   16bfc:	89 e5                	mov    %esp,%ebp
   16bfe:	83 ec 14             	sub    $0x14,%esp
	struct ck_ring *cring = child_ring[cos_cpuid()];
   16c01:	e8 ab bc ff ff       	call   128b1 <cos_cpuid>
   16c06:	8b 04 85 a4 02 00 00 	mov    0x2a4(,%eax,4),%eax
   16c0d:	89 45 fc             	mov    %eax,-0x4(%ebp)

	if (!cring) return 1;
   16c10:	83 7d fc 00          	cmpl   $0x0,-0x4(%ebp)
   16c14:	75 07                	jne    16c1d <sl_child_notif_empty+0x22>
   16c16:	b8 01 00 00 00       	mov    $0x1,%eax
   16c1b:	eb 13                	jmp    16c30 <sl_child_notif_empty+0x35>

	return (!ck_ring_size(cring));
   16c1d:	8b 45 fc             	mov    -0x4(%ebp),%eax
   16c20:	89 04 24             	mov    %eax,(%esp)
   16c23:	e8 8f d0 ff ff       	call   13cb7 <ck_ring_size>
   16c28:	85 c0                	test   %eax,%eax
   16c2a:	0f 94 c0             	sete   %al
   16c2d:	0f b6 c0             	movzbl %al,%eax
}
   16c30:	c9                   	leave  
   16c31:	c3                   	ret    

00016c32 <sl_parent_notif_block_no_cs>:

int
sl_parent_notif_block_no_cs(struct sl_thd *child, struct sl_thd *thd)
{
   16c32:	55                   	push   %ebp
   16c33:	89 e5                	mov    %esp,%ebp
   16c35:	83 ec 28             	sub    $0x28,%esp
	struct sl_child_notification notif;

	notif.type = SL_CHILD_THD_BLOCK;
   16c38:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	notif.tid  = sl_thd_thdid(thd);
   16c3f:	8b 45 0c             	mov    0xc(%ebp),%eax
   16c42:	89 04 24             	mov    %eax,(%esp)
   16c45:	e8 d3 c0 ff ff       	call   12d1d <sl_thd_thdid>
   16c4a:	66 89 45 f4          	mov    %ax,-0xc(%ebp)

	return sl_parent_notif_enqueue(child, &notif);
   16c4e:	8d 45 f0             	lea    -0x10(%ebp),%eax
   16c51:	89 44 24 04          	mov    %eax,0x4(%esp)
   16c55:	8b 45 08             	mov    0x8(%ebp),%eax
   16c58:	89 04 24             	mov    %eax,(%esp)
   16c5b:	e8 fc ff ff ff       	call   16c5c <sl_parent_notif_block_no_cs+0x2a>
}
   16c60:	c9                   	leave  
   16c61:	c3                   	ret    

00016c62 <sl_parent_notif_wakeup_no_cs>:

int
sl_parent_notif_wakeup_no_cs(struct sl_thd *child, struct sl_thd *thd)
{
   16c62:	55                   	push   %ebp
   16c63:	89 e5                	mov    %esp,%ebp
   16c65:	83 ec 28             	sub    $0x28,%esp
	struct sl_child_notification notif;

	notif.type = SL_CHILD_THD_WAKEUP;
   16c68:	c7 45 f0 01 00 00 00 	movl   $0x1,-0x10(%ebp)
	notif.tid  = sl_thd_thdid(thd);
   16c6f:	8b 45 0c             	mov    0xc(%ebp),%eax
   16c72:	89 04 24             	mov    %eax,(%esp)
   16c75:	e8 a3 c0 ff ff       	call   12d1d <sl_thd_thdid>
   16c7a:	66 89 45 f4          	mov    %ax,-0xc(%ebp)

	return sl_parent_notif_enqueue(child, &notif);
   16c7e:	8d 45 f0             	lea    -0x10(%ebp),%eax
   16c81:	89 44 24 04          	mov    %eax,0x4(%esp)
   16c85:	8b 45 08             	mov    0x8(%ebp),%eax
   16c88:	89 04 24             	mov    %eax,(%esp)
   16c8b:	e8 fc ff ff ff       	call   16c8c <sl_parent_notif_wakeup_no_cs+0x2a>
}
   16c90:	c9                   	leave  
   16c91:	c3                   	ret    
   16c92:	66 90                	xchg   %ax,%ax
   16c94:	66 90                	xchg   %ax,%ax
   16c96:	66 90                	xchg   %ax,%ax

00016c98 <ps_list_ll_init>:

#define PS_LIST_DEF_NAME list

static inline void
ps_list_ll_init(struct ps_list *l)
{ l->n = l->p = l; }
   16c98:	55                   	push   %ebp
   16c99:	89 e5                	mov    %esp,%ebp
   16c9b:	8b 45 08             	mov    0x8(%ebp),%eax
   16c9e:	8b 55 08             	mov    0x8(%ebp),%edx
   16ca1:	89 50 04             	mov    %edx,0x4(%eax)
   16ca4:	8b 45 08             	mov    0x8(%ebp),%eax
   16ca7:	8b 50 04             	mov    0x4(%eax),%edx
   16caa:	8b 45 08             	mov    0x8(%ebp),%eax
   16cad:	89 10                	mov    %edx,(%eax)
   16caf:	5d                   	pop    %ebp
   16cb0:	c3                   	ret    

00016cb1 <ps_list_ll_empty>:
ps_list_head_init(struct ps_list_head *lh)
{ ps_list_ll_init(&lh->l); }

static inline int
ps_list_ll_empty(struct ps_list *l)
{ return l->n == l; }
   16cb1:	55                   	push   %ebp
   16cb2:	89 e5                	mov    %esp,%ebp
   16cb4:	8b 45 08             	mov    0x8(%ebp),%eax
   16cb7:	8b 00                	mov    (%eax),%eax
   16cb9:	3b 45 08             	cmp    0x8(%ebp),%eax
   16cbc:	0f 94 c0             	sete   %al
   16cbf:	0f b6 c0             	movzbl %al,%eax
   16cc2:	5d                   	pop    %ebp
   16cc3:	c3                   	ret    

00016cc4 <ps_list_ll_add>:
ps_list_head_empty(struct ps_list_head *lh)
{ return ps_list_ll_empty(&lh->l); }

static inline void
ps_list_ll_add(struct ps_list *l, struct ps_list *new)
{
   16cc4:	55                   	push   %ebp
   16cc5:	89 e5                	mov    %esp,%ebp
	new->n    = l->n;
   16cc7:	8b 45 08             	mov    0x8(%ebp),%eax
   16cca:	8b 10                	mov    (%eax),%edx
   16ccc:	8b 45 0c             	mov    0xc(%ebp),%eax
   16ccf:	89 10                	mov    %edx,(%eax)
	new->p    = l;
   16cd1:	8b 45 0c             	mov    0xc(%ebp),%eax
   16cd4:	8b 55 08             	mov    0x8(%ebp),%edx
   16cd7:	89 50 04             	mov    %edx,0x4(%eax)
	l->n      = new;
   16cda:	8b 45 08             	mov    0x8(%ebp),%eax
   16cdd:	8b 55 0c             	mov    0xc(%ebp),%edx
   16ce0:	89 10                	mov    %edx,(%eax)
	new->n->p = new;
   16ce2:	8b 45 0c             	mov    0xc(%ebp),%eax
   16ce5:	8b 00                	mov    (%eax),%eax
   16ce7:	8b 55 0c             	mov    0xc(%ebp),%edx
   16cea:	89 50 04             	mov    %edx,0x4(%eax)
}
   16ced:	5d                   	pop    %ebp
   16cee:	c3                   	ret    

00016cef <ps_list_ll_rem>:

static inline void
ps_list_ll_rem(struct ps_list *l)
{
   16cef:	55                   	push   %ebp
   16cf0:	89 e5                	mov    %esp,%ebp
	l->n->p = l->p;
   16cf2:	8b 45 08             	mov    0x8(%ebp),%eax
   16cf5:	8b 00                	mov    (%eax),%eax
   16cf7:	8b 55 08             	mov    0x8(%ebp),%edx
   16cfa:	8b 52 04             	mov    0x4(%edx),%edx
   16cfd:	89 50 04             	mov    %edx,0x4(%eax)
	l->p->n = l->n;
   16d00:	8b 45 08             	mov    0x8(%ebp),%eax
   16d03:	8b 40 04             	mov    0x4(%eax),%eax
   16d06:	8b 55 08             	mov    0x8(%ebp),%edx
   16d09:	8b 12                	mov    (%edx),%edx
   16d0b:	89 10                	mov    %edx,(%eax)
	l->p = l->n = l;
   16d0d:	8b 45 08             	mov    0x8(%ebp),%eax
   16d10:	8b 55 08             	mov    0x8(%ebp),%edx
   16d13:	89 10                	mov    %edx,(%eax)
   16d15:	8b 45 08             	mov    0x8(%ebp),%eax
   16d18:	8b 10                	mov    (%eax),%edx
   16d1a:	8b 45 08             	mov    0x8(%ebp),%eax
   16d1d:	89 50 04             	mov    %edx,0x4(%eax)
}
   16d20:	5d                   	pop    %ebp
   16d21:	c3                   	ret    

00016d22 <ps_cas>:
 * 0 on failure due to contention (*target != old)
 * 1 otherwise (*target == old -> *target = updated)
 */
static inline int
ps_cas(unsigned long *target, unsigned long old, unsigned long updated)
{
   16d22:	55                   	push   %ebp
   16d23:	89 e5                	mov    %esp,%ebp
   16d25:	53                   	push   %ebx
   16d26:	83 ec 10             	sub    $0x10,%esp
        char z;
        __asm__ __volatile__("lock " PS_CAS_STR
   16d29:	8b 55 08             	mov    0x8(%ebp),%edx
   16d2c:	8b 4d 10             	mov    0x10(%ebp),%ecx
   16d2f:	8b 45 0c             	mov    0xc(%ebp),%eax
   16d32:	8b 5d 08             	mov    0x8(%ebp),%ebx
   16d35:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   16d39:	0f 94 c0             	sete   %al
   16d3c:	88 45 fb             	mov    %al,-0x5(%ebp)
                             : "+m" (*target), "=a" (z)
                             : "q"  (updated), "a"  (old)
                             : "memory", "cc");
        return (int)z;
   16d3f:	0f be 45 fb          	movsbl -0x5(%ebp),%eax
}
   16d43:	83 c4 10             	add    $0x10,%esp
   16d46:	5b                   	pop    %ebx
   16d47:	5d                   	pop    %ebp
   16d48:	c3                   	ret    

00016d49 <__bitmap_check>:
	return x | (1 << v);
}

static inline int
__bitmap_check(u32_t x, int v)
{
   16d49:	55                   	push   %ebp
   16d4a:	89 e5                	mov    %esp,%ebp
	return x & (1 << v);
   16d4c:	8b 45 0c             	mov    0xc(%ebp),%eax
   16d4f:	ba 01 00 00 00       	mov    $0x1,%edx
   16d54:	89 c1                	mov    %eax,%ecx
   16d56:	d3 e2                	shl    %cl,%edx
   16d58:	89 d0                	mov    %edx,%eax
   16d5a:	23 45 08             	and    0x8(%ebp),%eax
}
   16d5d:	5d                   	pop    %ebp
   16d5e:	c3                   	ret    

00016d5f <bitmap_check>:
	x[idx] = __bitmap_set(x[idx], off);
}

static inline int
bitmap_check(u32_t *x, int v)
{
   16d5f:	55                   	push   %ebp
   16d60:	89 e5                	mov    %esp,%ebp
   16d62:	83 ec 18             	sub    $0x18,%esp
	int idx, off;
	idx = v / WORD_SIZE; /* WORD_SIZE = sizeof(u32_t) */
   16d65:	8b 45 0c             	mov    0xc(%ebp),%eax
   16d68:	8d 50 1f             	lea    0x1f(%eax),%edx
   16d6b:	85 c0                	test   %eax,%eax
   16d6d:	0f 48 c2             	cmovs  %edx,%eax
   16d70:	c1 f8 05             	sar    $0x5,%eax
   16d73:	89 45 fc             	mov    %eax,-0x4(%ebp)
	off = v & (WORD_SIZE - 1);
   16d76:	8b 45 0c             	mov    0xc(%ebp),%eax
   16d79:	83 e0 1f             	and    $0x1f,%eax
   16d7c:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return __bitmap_check(x[idx], off);
   16d7f:	8b 45 fc             	mov    -0x4(%ebp),%eax
   16d82:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
   16d89:	8b 45 08             	mov    0x8(%ebp),%eax
   16d8c:	01 d0                	add    %edx,%eax
   16d8e:	8b 00                	mov    (%eax),%eax
   16d90:	8b 55 f8             	mov    -0x8(%ebp),%edx
   16d93:	89 54 24 04          	mov    %edx,0x4(%esp)
   16d97:	89 04 24             	mov    %eax,(%esp)
   16d9a:	e8 aa ff ff ff       	call   16d49 <__bitmap_check>
}
   16d9f:	c9                   	leave  
   16da0:	c3                   	ret    

00016da1 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
   16da1:	55                   	push   %ebp
   16da2:	89 e5                	mov    %esp,%ebp
   16da4:	57                   	push   %edi
   16da5:	56                   	push   %esi
   16da6:	53                   	push   %ebx
   16da7:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
   16daa:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
   16db1:	8b 45 08             	mov    0x8(%ebp),%eax
   16db4:	83 c0 01             	add    $0x1,%eax
   16db7:	c1 e0 10             	shl    $0x10,%eax
   16dba:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
   16dbd:	8b 45 0c             	mov    0xc(%ebp),%eax
   16dc0:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
   16dc3:	8b 45 08             	mov    0x8(%ebp),%eax
   16dc6:	8b 4d 10             	mov    0x10(%ebp),%ecx
   16dc9:	8b 75 14             	mov    0x14(%ebp),%esi
   16dcc:	8b 7d 18             	mov    0x18(%ebp),%edi
   16dcf:	8b 55 1c             	mov    0x1c(%ebp),%edx
   16dd2:	89 cb                	mov    %ecx,%ebx
   16dd4:	55                   	push   %ebp
   16dd5:	89 e5                	mov    %esp,%ebp
   16dd7:	b9 e8 6d 01 00       	mov    $0x16de8,%ecx
   16ddc:	0f 34                	sysenter 
   16dde:	66 90                	xchg   %ax,%ax
   16de0:	eb 0d                	jmp    16def <call_cap_asm+0x4e>
   16de2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   16de8:	b9 00 00 00 00       	mov    $0x0,%ecx
   16ded:	eb 05                	jmp    16df4 <call_cap_asm+0x53>
   16def:	b9 01 00 00 00       	mov    $0x1,%ecx
   16df4:	5d                   	pop    %ebp
   16df5:	89 ca                	mov    %ecx,%edx
   16df7:	89 45 ec             	mov    %eax,-0x14(%ebp)
   16dfa:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
   16dfd:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
   16e00:	83 c4 10             	add    $0x10,%esp
   16e03:	5b                   	pop    %ebx
   16e04:	5e                   	pop    %esi
   16e05:	5f                   	pop    %edi
   16e06:	5d                   	pop    %ebp
   16e07:	c3                   	ret    

00016e08 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
   16e08:	55                   	push   %ebp
   16e09:	89 e5                	mov    %esp,%ebp
   16e0b:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
   16e0e:	8b 45 18             	mov    0x18(%ebp),%eax
   16e11:	89 44 24 14          	mov    %eax,0x14(%esp)
   16e15:	8b 45 14             	mov    0x14(%ebp),%eax
   16e18:	89 44 24 10          	mov    %eax,0x10(%esp)
   16e1c:	8b 45 10             	mov    0x10(%ebp),%eax
   16e1f:	89 44 24 0c          	mov    %eax,0xc(%esp)
   16e23:	8b 45 0c             	mov    0xc(%ebp),%eax
   16e26:	89 44 24 08          	mov    %eax,0x8(%esp)
   16e2a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   16e31:	00 
   16e32:	8b 45 08             	mov    0x8(%ebp),%eax
   16e35:	89 04 24             	mov    %eax,(%esp)
   16e38:	e8 64 ff ff ff       	call   16da1 <call_cap_asm>
}
   16e3d:	c9                   	leave  
   16e3e:	c3                   	ret    

00016e3f <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
   16e3f:	55                   	push   %ebp
   16e40:	89 e5                	mov    %esp,%ebp
   16e42:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
   16e45:	8b 45 08             	mov    0x8(%ebp),%eax
   16e48:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   16e4f:	00 
   16e50:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   16e57:	00 
   16e58:	8b 55 0c             	mov    0xc(%ebp),%edx
   16e5b:	89 54 24 08          	mov    %edx,0x8(%esp)
   16e5f:	89 44 24 04          	mov    %eax,0x4(%esp)
   16e63:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
   16e6a:	e8 99 ff ff ff       	call   16e08 <call_cap>
}
   16e6f:	c9                   	leave  
   16e70:	c3                   	ret    

00016e71 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
   16e71:	55                   	push   %ebp
   16e72:	89 e5                	mov    %esp,%ebp
   16e74:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
   16e77:	89 e0                	mov    %esp,%eax
   16e79:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
   16e7c:	8b 45 fc             	mov    -0x4(%ebp),%eax
   16e7f:	25 00 f0 ff ff       	and    $0xfffff000,%eax
   16e84:	89 c2                	mov    %eax,%edx
   16e86:	8b 45 08             	mov    0x8(%ebp),%eax
   16e89:	c1 e0 02             	shl    $0x2,%eax
   16e8c:	29 c2                	sub    %eax,%edx
   16e8e:	89 d0                	mov    %edx,%eax
   16e90:	05 00 10 00 00       	add    $0x1000,%eax
   16e95:	8b 00                	mov    (%eax),%eax
}
   16e97:	c9                   	leave  
   16e98:	c3                   	ret    

00016e99 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
   16e99:	55                   	push   %ebp
   16e9a:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
   16e9c:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
   16ea1:	5d                   	pop    %ebp
   16ea2:	c3                   	ret    

00016ea3 <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
   16ea3:	55                   	push   %ebp
   16ea4:	89 e5                	mov    %esp,%ebp
   16ea6:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
   16ea9:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
   16eb0:	e8 bc ff ff ff       	call   16e71 <get_stk_data>
}
   16eb5:	c9                   	leave  
   16eb6:	c3                   	ret    

00016eb7 <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
   16eb7:	55                   	push   %ebp
   16eb8:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
   16eba:	e8 e4 ff ff ff       	call   16ea3 <cos_get_thd_id>
}
   16ebf:	5d                   	pop    %ebp
   16ec0:	c3                   	ret    

00016ec1 <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
   16ec1:	55                   	push   %ebp
   16ec2:	89 e5                	mov    %esp,%ebp
   16ec4:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
   16ec7:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
   16ece:	eb 20                	jmp    16ef0 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
   16ed0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   16ed3:	83 c0 01             	add    $0x1,%eax
   16ed6:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
   16edd:	8b 45 08             	mov    0x8(%ebp),%eax
   16ee0:	01 d0                	add    %edx,%eax
   16ee2:	8b 00                	mov    (%eax),%eax
   16ee4:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
   16ee7:	8b 45 f0             	mov    -0x10(%ebp),%eax
   16eea:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
   16eec:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   16ef0:	8b 45 08             	mov    0x8(%ebp),%eax
   16ef3:	8b 00                	mov    (%eax),%eax
   16ef5:	3b 45 f4             	cmp    -0xc(%ebp),%eax
   16ef8:	7f d6                	jg     16ed0 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
   16efa:	c9                   	leave  
   16efb:	c3                   	ret    

00016efc <constructors_execute>:

static void
constructors_execute(void)
{
   16efc:	55                   	push   %ebp
   16efd:	89 e5                	mov    %esp,%ebp
   16eff:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
   16f02:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   16f09:	e8 b3 ff ff ff       	call   16ec1 <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
   16f0e:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   16f15:	e8 a7 ff ff ff       	call   16ec1 <section_fnptrs_execute>
}
   16f1a:	c9                   	leave  
   16f1b:	c3                   	ret    

00016f1c <destructors_execute>:
static void
destructors_execute(void)
{
   16f1c:	55                   	push   %ebp
   16f1d:	89 e5                	mov    %esp,%ebp
   16f1f:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
   16f22:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   16f29:	e8 93 ff ff ff       	call   16ec1 <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
   16f2e:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   16f35:	e8 87 ff ff ff       	call   16ec1 <section_fnptrs_execute>
}
   16f3a:	c9                   	leave  
   16f3b:	c3                   	ret    

00016f3c <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
   16f3c:	55                   	push   %ebp
   16f3d:	89 e5                	mov    %esp,%ebp
   16f3f:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
   16f42:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   16f49:	e8 73 ff ff ff       	call   16ec1 <section_fnptrs_execute>
}
   16f4e:	c9                   	leave  
   16f4f:	c3                   	ret    

00016f50 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
   16f50:	55                   	push   %ebp
   16f51:	89 e5                	mov    %esp,%ebp
   16f53:	83 ec 08             	sub    $0x8,%esp
   16f56:	8b 55 08             	mov    0x8(%ebp),%edx
   16f59:	8b 45 0c             	mov    0xc(%ebp),%eax
   16f5c:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
   16f60:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
   16f63:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   16f67:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
   16f6b:	ee                   	out    %al,(%dx)
}
   16f6c:	c9                   	leave  
   16f6d:	c3                   	ret    

00016f6e <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
   16f6e:	55                   	push   %ebp
   16f6f:	89 e5                	mov    %esp,%ebp
   16f71:	83 ec 14             	sub    $0x14,%esp
   16f74:	8b 45 08             	mov    0x8(%ebp),%eax
   16f77:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
   16f7b:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
   16f7f:	89 c2                	mov    %eax,%edx
   16f81:	ec                   	in     (%dx),%al
   16f82:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
   16f85:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
   16f89:	c9                   	leave  
   16f8a:	c3                   	ret    

00016f8b <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
   16f8b:	55                   	push   %ebp
   16f8c:	89 e5                	mov    %esp,%ebp
   16f8e:	83 ec 0c             	sub    $0xc,%esp
   16f91:	8b 45 08             	mov    0x8(%ebp),%eax
   16f94:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
   16f97:	90                   	nop
   16f98:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
   16f9f:	e8 ca ff ff ff       	call   16f6e <inb>
   16fa4:	0f b6 c0             	movzbl %al,%eax
   16fa7:	83 e0 20             	and    $0x20,%eax
   16faa:	85 c0                	test   %eax,%eax
   16fac:	74 ea                	je     16f98 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
   16fae:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   16fb2:	0f b6 c0             	movzbl %al,%eax
   16fb5:	89 44 24 04          	mov    %eax,0x4(%esp)
   16fb9:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
   16fc0:	e8 8b ff ff ff       	call   16f50 <outb>
}
   16fc5:	c9                   	leave  
   16fc6:	c3                   	ret    

00016fc7 <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
   16fc7:	55                   	push   %ebp
   16fc8:	89 e5                	mov    %esp,%ebp
   16fca:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
   16fcd:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
   16fd4:	eb 1a                	jmp    16ff0 <cos_serial_putb+0x29>
   16fd6:	8b 45 fc             	mov    -0x4(%ebp),%eax
   16fd9:	8b 55 08             	mov    0x8(%ebp),%edx
   16fdc:	01 d0                	add    %edx,%eax
   16fde:	0f b6 00             	movzbl (%eax),%eax
   16fe1:	0f be c0             	movsbl %al,%eax
   16fe4:	89 04 24             	mov    %eax,(%esp)
   16fe7:	e8 9f ff ff ff       	call   16f8b <cos_serial_putc>
   16fec:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
   16ff0:	8b 45 fc             	mov    -0x4(%ebp),%eax
   16ff3:	3b 45 0c             	cmp    0xc(%ebp),%eax
   16ff6:	72 de                	jb     16fd6 <cos_serial_putb+0xf>
}
   16ff8:	c9                   	leave  
   16ff9:	c3                   	ret    

00016ffa <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
   16ffa:	55                   	push   %ebp
   16ffb:	89 e5                	mov    %esp,%ebp
   16ffd:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
   17000:	8b 45 0c             	mov    0xc(%ebp),%eax
   17003:	89 44 24 04          	mov    %eax,0x4(%esp)
   17007:	8b 45 08             	mov    0x8(%ebp),%eax
   1700a:	89 04 24             	mov    %eax,(%esp)
   1700d:	e8 b5 ff ff ff       	call   16fc7 <cos_serial_putb>
}
   17012:	c9                   	leave  
   17013:	c3                   	ret    

00017014 <prints>:

static int
prints(char *s)
{
   17014:	55                   	push   %ebp
   17015:	89 e5                	mov    %esp,%ebp
   17017:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
   1701a:	8b 45 08             	mov    0x8(%ebp),%eax
   1701d:	89 04 24             	mov    %eax,(%esp)
   17020:	e8 fc ff ff ff       	call   17021 <prints+0xd>
   17025:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
   17028:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1702b:	89 44 24 04          	mov    %eax,0x4(%esp)
   1702f:	8b 45 08             	mov    0x8(%ebp),%eax
   17032:	89 04 24             	mov    %eax,(%esp)
   17035:	e8 05 fe ff ff       	call   16e3f <cos_print>

	return len;
   1703a:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1703d:	c9                   	leave  
   1703e:	c3                   	ret    

0001703f <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
   1703f:	55                   	push   %ebp
   17040:	89 e5                	mov    %esp,%ebp
   17042:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
   17048:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
   1704f:	8d 45 0c             	lea    0xc(%ebp),%eax
   17052:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
   17058:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
   1705e:	89 44 24 0c          	mov    %eax,0xc(%esp)
   17062:	8b 45 08             	mov    0x8(%ebp),%eax
   17065:	89 44 24 08          	mov    %eax,0x8(%esp)
   17069:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1706c:	89 44 24 04          	mov    %eax,0x4(%esp)
   17070:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
   17076:	89 04 24             	mov    %eax,(%esp)
   17079:	e8 fc ff ff ff       	call   1707a <printc+0x3b>
   1707e:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
   17081:	8b 45 f0             	mov    -0x10(%ebp),%eax
   17084:	89 44 24 04          	mov    %eax,0x4(%esp)
   17088:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
   1708e:	89 04 24             	mov    %eax,(%esp)
   17091:	e8 64 ff ff ff       	call   16ffa <cos_llprint>

	return ret;
   17096:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
   17099:	c9                   	leave  
   1709a:	c3                   	ret    

0001709b <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
   1709b:	55                   	push   %ebp
   1709c:	89 e5                	mov    %esp,%ebp
	while (1)
		;
   1709e:	eb fe                	jmp    1709e <__cos_noret+0x3>

000170a0 <__slab_freelist_rem>:
static inline void __ps_slab_freelist_check(struct ps_slab_freelist *fl) { (void)fl; }
#endif /* PS_SLAB_DEBUG */

static void
__slab_freelist_rem(struct ps_slab_freelist *fl, struct ps_slab *s)
{
   170a0:	55                   	push   %ebp
   170a1:	89 e5                	mov    %esp,%ebp
   170a3:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
   170a6:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   170aa:	0f 94 c0             	sete   %al
   170ad:	0f b6 c0             	movzbl %al,%eax
   170b0:	85 c0                	test   %eax,%eax
   170b2:	75 0e                	jne    170c2 <__slab_freelist_rem+0x22>
   170b4:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   170b8:	0f 94 c0             	sete   %al
   170bb:	0f b6 c0             	movzbl %al,%eax
   170be:	85 c0                	test   %eax,%eax
   170c0:	74 1c                	je     170de <__slab_freelist_rem+0x3e>
   170c2:	c7 04 24 e0 2f 00 00 	movl   $0x2fe0,(%esp)
   170c9:	e8 46 ff ff ff       	call   17014 <prints>
   170ce:	a1 ac 02 00 00       	mov    0x2ac,%eax
   170d3:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   170d9:	e8 bd ff ff ff       	call   1709b <__cos_noret>
	if (fl->list == s) {
   170de:	8b 45 08             	mov    0x8(%ebp),%eax
   170e1:	8b 00                	mov    (%eax),%eax
   170e3:	3b 45 0c             	cmp    0xc(%ebp),%eax
   170e6:	75 2b                	jne    17113 <__slab_freelist_rem+0x73>
		if (ps_list_singleton(s, list)) fl->list = NULL;
   170e8:	8b 45 0c             	mov    0xc(%ebp),%eax
   170eb:	83 c0 44             	add    $0x44,%eax
   170ee:	89 04 24             	mov    %eax,(%esp)
   170f1:	e8 bb fb ff ff       	call   16cb1 <ps_list_ll_empty>
   170f6:	85 c0                	test   %eax,%eax
   170f8:	74 0b                	je     17105 <__slab_freelist_rem+0x65>
   170fa:	8b 45 08             	mov    0x8(%ebp),%eax
   170fd:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   17103:	eb 0e                	jmp    17113 <__slab_freelist_rem+0x73>
		else                            fl->list = ps_list_next(s, list);
   17105:	8b 45 0c             	mov    0xc(%ebp),%eax
   17108:	8b 40 44             	mov    0x44(%eax),%eax
   1710b:	8d 50 bc             	lea    -0x44(%eax),%edx
   1710e:	8b 45 08             	mov    0x8(%ebp),%eax
   17111:	89 10                	mov    %edx,(%eax)
	}
	ps_list_rem(s, list);
   17113:	8b 45 0c             	mov    0xc(%ebp),%eax
   17116:	83 c0 44             	add    $0x44,%eax
   17119:	89 04 24             	mov    %eax,(%esp)
   1711c:	e8 ce fb ff ff       	call   16cef <ps_list_ll_rem>
}
   17121:	c9                   	leave  
   17122:	c3                   	ret    

00017123 <__slab_freelist_add>:

static void
__slab_freelist_add(struct ps_slab_freelist *fl, struct ps_slab *s)
{
   17123:	55                   	push   %ebp
   17124:	89 e5                	mov    %esp,%ebp
   17126:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
   17129:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1712d:	0f 94 c0             	sete   %al
   17130:	0f b6 c0             	movzbl %al,%eax
   17133:	85 c0                	test   %eax,%eax
   17135:	75 0e                	jne    17145 <__slab_freelist_add+0x22>
   17137:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1713b:	0f 94 c0             	sete   %al
   1713e:	0f b6 c0             	movzbl %al,%eax
   17141:	85 c0                	test   %eax,%eax
   17143:	74 1c                	je     17161 <__slab_freelist_add+0x3e>
   17145:	c7 04 24 38 30 00 00 	movl   $0x3038,(%esp)
   1714c:	e8 c3 fe ff ff       	call   17014 <prints>
   17151:	a1 ac 02 00 00       	mov    0x2ac,%eax
   17156:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1715c:	e8 3a ff ff ff       	call   1709b <__cos_noret>
	assert(ps_list_singleton(s, list));
   17161:	8b 45 0c             	mov    0xc(%ebp),%eax
   17164:	83 c0 44             	add    $0x44,%eax
   17167:	89 04 24             	mov    %eax,(%esp)
   1716a:	e8 42 fb ff ff       	call   16cb1 <ps_list_ll_empty>
   1716f:	85 c0                	test   %eax,%eax
   17171:	0f 94 c0             	sete   %al
   17174:	0f b6 c0             	movzbl %al,%eax
   17177:	85 c0                	test   %eax,%eax
   17179:	74 1c                	je     17197 <__slab_freelist_add+0x74>
   1717b:	c7 04 24 90 30 00 00 	movl   $0x3090,(%esp)
   17182:	e8 8d fe ff ff       	call   17014 <prints>
   17187:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1718c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   17192:	e8 04 ff ff ff       	call   1709b <__cos_noret>
	assert(s != fl->list);
   17197:	8b 45 08             	mov    0x8(%ebp),%eax
   1719a:	8b 00                	mov    (%eax),%eax
   1719c:	3b 45 0c             	cmp    0xc(%ebp),%eax
   1719f:	0f 94 c0             	sete   %al
   171a2:	0f b6 c0             	movzbl %al,%eax
   171a5:	85 c0                	test   %eax,%eax
   171a7:	74 1c                	je     171c5 <__slab_freelist_add+0xa2>
   171a9:	c7 04 24 e8 30 00 00 	movl   $0x30e8,(%esp)
   171b0:	e8 5f fe ff ff       	call   17014 <prints>
   171b5:	a1 ac 02 00 00       	mov    0x2ac,%eax
   171ba:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   171c0:	e8 d6 fe ff ff       	call   1709b <__cos_noret>
	if (fl->list) ps_list_add(fl->list, s, list);
   171c5:	8b 45 08             	mov    0x8(%ebp),%eax
   171c8:	8b 00                	mov    (%eax),%eax
   171ca:	85 c0                	test   %eax,%eax
   171cc:	74 1a                	je     171e8 <__slab_freelist_add+0xc5>
   171ce:	8b 45 0c             	mov    0xc(%ebp),%eax
   171d1:	8d 50 44             	lea    0x44(%eax),%edx
   171d4:	8b 45 08             	mov    0x8(%ebp),%eax
   171d7:	8b 00                	mov    (%eax),%eax
   171d9:	83 c0 44             	add    $0x44,%eax
   171dc:	89 54 24 04          	mov    %edx,0x4(%esp)
   171e0:	89 04 24             	mov    %eax,(%esp)
   171e3:	e8 dc fa ff ff       	call   16cc4 <ps_list_ll_add>
	fl->list = s;
   171e8:	8b 45 08             	mov    0x8(%ebp),%eax
   171eb:	8b 55 0c             	mov    0xc(%ebp),%edx
   171ee:	89 10                	mov    %edx,(%eax)
	/* TODO: sort based on emptiness...just use N bins */
}
   171f0:	c9                   	leave  
   171f1:	c3                   	ret    

000171f2 <cos_aepthd_fn>:
	struct cos_aep_info sched_aep[NUM_CPU];
};

static void
cos_aepthd_fn(void *data)
{
   171f2:	55                   	push   %ebp
   171f3:	89 e5                	mov    %esp,%ebp
   171f5:	83 ec 28             	sub    $0x28,%esp
	struct cos_aep_info *aep_info = (struct cos_aep_info *)data;
   171f8:	8b 45 08             	mov    0x8(%ebp),%eax
   171fb:	89 45 f4             	mov    %eax,-0xc(%ebp)
	cos_aepthd_fn_t      aep_fn   = aep_info->fn;
   171fe:	8b 45 f4             	mov    -0xc(%ebp),%eax
   17201:	8b 40 10             	mov    0x10(%eax),%eax
   17204:	89 45 f0             	mov    %eax,-0x10(%ebp)
	void *               fn_data  = aep_info->data;
   17207:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1720a:	8b 40 14             	mov    0x14(%eax),%eax
   1720d:	89 45 ec             	mov    %eax,-0x14(%ebp)

	(aep_fn)(aep_info->rcv, fn_data);
   17210:	8b 45 f4             	mov    -0xc(%ebp),%eax
   17213:	8b 40 0c             	mov    0xc(%eax),%eax
   17216:	8b 55 ec             	mov    -0x14(%ebp),%edx
   17219:	89 54 24 04          	mov    %edx,0x4(%esp)
   1721d:	89 04 24             	mov    %eax,(%esp)
   17220:	8b 45 f0             	mov    -0x10(%ebp),%eax
   17223:	ff d0                	call   *%eax

	/* TODO: handling destruction */
	assert(0);
   17225:	c7 04 24 40 31 00 00 	movl   $0x3140,(%esp)
   1722c:	e8 e3 fd ff ff       	call   17014 <prints>
   17231:	a1 ac 02 00 00       	mov    0x2ac,%eax
   17236:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1723c:	e8 5a fe ff ff       	call   1709b <__cos_noret>

00017241 <sl_thd_aepinfo>:
	struct ps_list    SL_THD_EVENT_LIST; /* list of events for the scheduler end-point */
};

static inline struct cos_aep_info *
sl_thd_aepinfo(struct sl_thd *t)
{ return (t->aepinfo); }
   17241:	55                   	push   %ebp
   17242:	89 e5                	mov    %esp,%ebp
   17244:	8b 45 08             	mov    0x8(%ebp),%eax
   17247:	8b 40 0c             	mov    0xc(%eax),%eax
   1724a:	5d                   	pop    %ebp
   1724b:	c3                   	ret    

0001724c <sl_thd_thdcap>:

static inline thdcap_t
sl_thd_thdcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->thd; }
   1724c:	55                   	push   %ebp
   1724d:	89 e5                	mov    %esp,%ebp
   1724f:	83 ec 04             	sub    $0x4,%esp
   17252:	8b 45 08             	mov    0x8(%ebp),%eax
   17255:	89 04 24             	mov    %eax,(%esp)
   17258:	e8 e4 ff ff ff       	call   17241 <sl_thd_aepinfo>
   1725d:	8b 40 04             	mov    0x4(%eax),%eax
   17260:	c9                   	leave  
   17261:	c3                   	ret    

00017262 <sl_thd_tcap>:

static inline tcap_t
sl_thd_tcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->tc; }
   17262:	55                   	push   %ebp
   17263:	89 e5                	mov    %esp,%ebp
   17265:	83 ec 04             	sub    $0x4,%esp
   17268:	8b 45 08             	mov    0x8(%ebp),%eax
   1726b:	89 04 24             	mov    %eax,(%esp)
   1726e:	e8 ce ff ff ff       	call   17241 <sl_thd_aepinfo>
   17273:	8b 00                	mov    (%eax),%eax
   17275:	c9                   	leave  
   17276:	c3                   	ret    

00017277 <sl_thd_rcvcap>:

static inline arcvcap_t
sl_thd_rcvcap(struct sl_thd *t)
{ return sl_thd_aepinfo(t)->rcv; }
   17277:	55                   	push   %ebp
   17278:	89 e5                	mov    %esp,%ebp
   1727a:	83 ec 04             	sub    $0x4,%esp
   1727d:	8b 45 08             	mov    0x8(%ebp),%eax
   17280:	89 04 24             	mov    %eax,(%esp)
   17283:	e8 b9 ff ff ff       	call   17241 <sl_thd_aepinfo>
   17288:	8b 40 0c             	mov    0xc(%eax),%eax
   1728b:	c9                   	leave  
   1728c:	c3                   	ret    

0001728d <sl_mod_thd_get>:
	struct ps_list list;
} CACHE_ALIGNED;

static inline struct sl_thd *
sl_mod_thd_get(struct sl_thd_policy *tp)
{
   1728d:	55                   	push   %ebp
   1728e:	89 e5                	mov    %esp,%ebp
	return &tp->thd;
   17290:	8b 45 08             	mov    0x8(%ebp),%eax
}
   17293:	5d                   	pop    %ebp
   17294:	c3                   	ret    

00017295 <sl_mod_thd_policy_get>:

static inline struct sl_thd_policy *
sl_mod_thd_policy_get(struct sl_thd *t)
{
   17295:	55                   	push   %ebp
   17296:	89 e5                	mov    %esp,%ebp
	return ps_container(t, struct sl_thd_policy, thd);
   17298:	8b 45 08             	mov    0x8(%ebp),%eax
}
   1729b:	5d                   	pop    %ebp
   1729c:	c3                   	ret    

0001729d <ck_cc_ffs>:
 */
#ifndef CK_MD_CC_BUILTIN_DISABLE
#define CK_F_CC_FFS
CK_CC_INLINE static int
ck_cc_ffs(unsigned int x)
{
   1729d:	55                   	push   %ebp
   1729e:	89 e5                	mov    %esp,%ebp

	return __builtin_ffsl(x);
   172a0:	8b 45 08             	mov    0x8(%ebp),%eax
   172a3:	ba ff ff ff ff       	mov    $0xffffffff,%edx
   172a8:	0f bc c0             	bsf    %eax,%eax
   172ab:	0f 44 c2             	cmove  %edx,%eax
   172ae:	83 c0 01             	add    $0x1,%eax
}
   172b1:	5d                   	pop    %ebp
   172b2:	c3                   	ret    

000172b3 <ck_cc_ffsl>:

#define CK_F_CC_FFSL
CK_CC_INLINE static int
ck_cc_ffsl(unsigned long x)
{
   172b3:	55                   	push   %ebp
   172b4:	89 e5                	mov    %esp,%ebp
   172b6:	83 ec 18             	sub    $0x18,%esp

	return __builtin_ffsll(x);
   172b9:	8b 45 08             	mov    0x8(%ebp),%eax
   172bc:	ba 00 00 00 00       	mov    $0x0,%edx
   172c1:	89 04 24             	mov    %eax,(%esp)
   172c4:	89 54 24 04          	mov    %edx,0x4(%esp)
   172c8:	e8 fc ff ff ff       	call   172c9 <ck_cc_ffsl+0x16>
}
   172cd:	c9                   	leave  
   172ce:	c3                   	ret    

000172cf <ck_cc_ctz>:

#define CK_F_CC_CTZ
CK_CC_INLINE static int
ck_cc_ctz(unsigned int x)
{
   172cf:	55                   	push   %ebp
   172d0:	89 e5                	mov    %esp,%ebp

	return __builtin_ctz(x);
   172d2:	f3 0f bc 45 08       	tzcnt  0x8(%ebp),%eax
}
   172d7:	5d                   	pop    %ebp
   172d8:	c3                   	ret    

000172d9 <ck_cc_popcount>:

#define CK_F_CC_POPCOUNT
CK_CC_INLINE static int
ck_cc_popcount(unsigned int x)
{
   172d9:	55                   	push   %ebp
   172da:	89 e5                	mov    %esp,%ebp
   172dc:	83 ec 18             	sub    $0x18,%esp

	return __builtin_popcount(x);
   172df:	8b 45 08             	mov    0x8(%ebp),%eax
   172e2:	89 04 24             	mov    %eax,(%esp)
   172e5:	e8 fc ff ff ff       	call   172e6 <ck_cc_popcount+0xd>
}
   172ea:	c9                   	leave  
   172eb:	c3                   	ret    

000172ec <ck_cc_ffsll>:
   172ec:	55                   	push   %ebp
   172ed:	89 e5                	mov    %esp,%ebp
   172ef:	53                   	push   %ebx
   172f0:	83 ec 1c             	sub    $0x1c,%esp
   172f3:	8b 4d 08             	mov    0x8(%ebp),%ecx
   172f6:	89 4d e0             	mov    %ecx,-0x20(%ebp)
   172f9:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   172fc:	89 4d e4             	mov    %ecx,-0x1c(%ebp)
   172ff:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   17302:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
   17305:	09 d9                	or     %ebx,%ecx
   17307:	85 c9                	test   %ecx,%ecx
   17309:	75 07                	jne    17312 <ck_cc_ffsll+0x26>
   1730b:	b8 00 00 00 00       	mov    $0x0,%eax
   17310:	eb 3a                	jmp    1734c <ck_cc_ffsll+0x60>
   17312:	c7 45 f4 01 00 00 00 	movl   $0x1,-0xc(%ebp)
   17319:	eb 16                	jmp    17331 <ck_cc_ffsll+0x45>
   1731b:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   1731f:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   17322:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
   17325:	0f ac d9 01          	shrd   $0x1,%ebx,%ecx
   17329:	d1 eb                	shr    %ebx
   1732b:	89 4d e0             	mov    %ecx,-0x20(%ebp)
   1732e:	89 5d e4             	mov    %ebx,-0x1c(%ebp)
   17331:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   17334:	83 e1 01             	and    $0x1,%ecx
   17337:	89 c8                	mov    %ecx,%eax
   17339:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
   1733c:	83 e1 00             	and    $0x0,%ecx
   1733f:	89 ca                	mov    %ecx,%edx
   17341:	89 d1                	mov    %edx,%ecx
   17343:	09 c1                	or     %eax,%ecx
   17345:	85 c9                	test   %ecx,%ecx
   17347:	74 d2                	je     1731b <ck_cc_ffsll+0x2f>
   17349:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1734c:	83 c4 1c             	add    $0x1c,%esp
   1734f:	5b                   	pop    %ebx
   17350:	5d                   	pop    %ebp
   17351:	c3                   	ret    

00017352 <ck_pr_stall>:
 * Prevent speculative execution in busy-wait loops (P4 <=) or "predefined
 * delay".
 */
CK_CC_INLINE static void
ck_pr_stall(void)
{
   17352:	55                   	push   %ebp
   17353:	89 e5                	mov    %esp,%ebp
	__asm__ __volatile__("pause" ::: "memory");
   17355:	f3 90                	pause  
	return;
   17357:	90                   	nop
}
   17358:	5d                   	pop    %ebp
   17359:	c3                   	ret    

0001735a <ck_pr_fence_strict_atomic>:
#define CK_MD_X86_SFENCE "sfence"
#define CK_MD_X86_LFENCE "lfence"
#define CK_MD_X86_MFENCE "mfence"
#endif /* !CK_MD_SSE_DISABLE */

CK_PR_FENCE(atomic, "")
   1735a:	55                   	push   %ebp
   1735b:	89 e5                	mov    %esp,%ebp
   1735d:	90                   	nop
   1735e:	5d                   	pop    %ebp
   1735f:	c3                   	ret    

00017360 <ck_pr_fence_strict_atomic_store>:
CK_PR_FENCE(atomic_store, "")
   17360:	55                   	push   %ebp
   17361:	89 e5                	mov    %esp,%ebp
   17363:	90                   	nop
   17364:	5d                   	pop    %ebp
   17365:	c3                   	ret    

00017366 <ck_pr_fence_strict_atomic_load>:
CK_PR_FENCE(atomic_load, "")
   17366:	55                   	push   %ebp
   17367:	89 e5                	mov    %esp,%ebp
   17369:	90                   	nop
   1736a:	5d                   	pop    %ebp
   1736b:	c3                   	ret    

0001736c <ck_pr_fence_strict_store_atomic>:
CK_PR_FENCE(store_atomic, "")
   1736c:	55                   	push   %ebp
   1736d:	89 e5                	mov    %esp,%ebp
   1736f:	90                   	nop
   17370:	5d                   	pop    %ebp
   17371:	c3                   	ret    

00017372 <ck_pr_fence_strict_load_atomic>:
CK_PR_FENCE(load_atomic, "")
   17372:	55                   	push   %ebp
   17373:	89 e5                	mov    %esp,%ebp
   17375:	90                   	nop
   17376:	5d                   	pop    %ebp
   17377:	c3                   	ret    

00017378 <ck_pr_fence_strict_load>:
CK_PR_FENCE(load, CK_MD_X86_LFENCE)
   17378:	55                   	push   %ebp
   17379:	89 e5                	mov    %esp,%ebp
   1737b:	0f ae e8             	lfence 
   1737e:	90                   	nop
   1737f:	5d                   	pop    %ebp
   17380:	c3                   	ret    

00017381 <ck_pr_fence_strict_load_store>:
CK_PR_FENCE(load_store, CK_MD_X86_MFENCE)
   17381:	55                   	push   %ebp
   17382:	89 e5                	mov    %esp,%ebp
   17384:	0f ae f0             	mfence 
   17387:	90                   	nop
   17388:	5d                   	pop    %ebp
   17389:	c3                   	ret    

0001738a <ck_pr_fence_strict_store>:
CK_PR_FENCE(store, CK_MD_X86_SFENCE)
   1738a:	55                   	push   %ebp
   1738b:	89 e5                	mov    %esp,%ebp
   1738d:	0f ae f8             	sfence 
   17390:	90                   	nop
   17391:	5d                   	pop    %ebp
   17392:	c3                   	ret    

00017393 <ck_pr_fence_strict_store_load>:
CK_PR_FENCE(store_load, CK_MD_X86_MFENCE)
   17393:	55                   	push   %ebp
   17394:	89 e5                	mov    %esp,%ebp
   17396:	0f ae f0             	mfence 
   17399:	90                   	nop
   1739a:	5d                   	pop    %ebp
   1739b:	c3                   	ret    

0001739c <ck_pr_fence_strict_memory>:
CK_PR_FENCE(memory, CK_MD_X86_MFENCE)
   1739c:	55                   	push   %ebp
   1739d:	89 e5                	mov    %esp,%ebp
   1739f:	0f ae f0             	mfence 
   173a2:	90                   	nop
   173a3:	5d                   	pop    %ebp
   173a4:	c3                   	ret    

000173a5 <ck_pr_fence_strict_release>:
CK_PR_FENCE(release, CK_MD_X86_MFENCE)
   173a5:	55                   	push   %ebp
   173a6:	89 e5                	mov    %esp,%ebp
   173a8:	0f ae f0             	mfence 
   173ab:	90                   	nop
   173ac:	5d                   	pop    %ebp
   173ad:	c3                   	ret    

000173ae <ck_pr_fence_strict_acquire>:
CK_PR_FENCE(acquire, CK_MD_X86_MFENCE)
   173ae:	55                   	push   %ebp
   173af:	89 e5                	mov    %esp,%ebp
   173b1:	0f ae f0             	mfence 
   173b4:	90                   	nop
   173b5:	5d                   	pop    %ebp
   173b6:	c3                   	ret    

000173b7 <ck_pr_fence_strict_acqrel>:
CK_PR_FENCE(acqrel, CK_MD_X86_MFENCE)
   173b7:	55                   	push   %ebp
   173b8:	89 e5                	mov    %esp,%ebp
   173ba:	0f ae f0             	mfence 
   173bd:	90                   	nop
   173be:	5d                   	pop    %ebp
   173bf:	c3                   	ret    

000173c0 <ck_pr_fence_strict_lock>:
CK_PR_FENCE(lock, CK_MD_X86_MFENCE)
   173c0:	55                   	push   %ebp
   173c1:	89 e5                	mov    %esp,%ebp
   173c3:	0f ae f0             	mfence 
   173c6:	90                   	nop
   173c7:	5d                   	pop    %ebp
   173c8:	c3                   	ret    

000173c9 <ck_pr_fence_strict_unlock>:
CK_PR_FENCE(unlock, CK_MD_X86_MFENCE)
   173c9:	55                   	push   %ebp
   173ca:	89 e5                	mov    %esp,%ebp
   173cc:	0f ae f0             	mfence 
   173cf:	90                   	nop
   173d0:	5d                   	pop    %ebp
   173d1:	c3                   	ret    

000173d2 <ck_pr_fas_ptr>:
					:			\
					: "memory");		\
		return v;					\
	}

CK_PR_FAS(ptr, void, void *, char, "xchgl")
   173d2:	55                   	push   %ebp
   173d3:	89 e5                	mov    %esp,%ebp
   173d5:	8b 55 08             	mov    0x8(%ebp),%edx
   173d8:	8b 4d 08             	mov    0x8(%ebp),%ecx
   173db:	8b 45 0c             	mov    0xc(%ebp),%eax
   173de:	87 02                	xchg   %eax,(%edx)
   173e0:	89 45 0c             	mov    %eax,0xc(%ebp)
   173e3:	8b 45 0c             	mov    0xc(%ebp),%eax
   173e6:	5d                   	pop    %ebp
   173e7:	c3                   	ret    

000173e8 <ck_pr_fas_char>:

#define CK_PR_FAS_S(S, T, I) CK_PR_FAS(S, T, T, T, I)

CK_PR_FAS_S(char, char, "xchgb")
   173e8:	55                   	push   %ebp
   173e9:	89 e5                	mov    %esp,%ebp
   173eb:	83 ec 04             	sub    $0x4,%esp
   173ee:	8b 45 0c             	mov    0xc(%ebp),%eax
   173f1:	88 45 fc             	mov    %al,-0x4(%ebp)
   173f4:	8b 55 08             	mov    0x8(%ebp),%edx
   173f7:	8b 4d 08             	mov    0x8(%ebp),%ecx
   173fa:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   173fe:	86 02                	xchg   %al,(%edx)
   17400:	88 45 fc             	mov    %al,-0x4(%ebp)
   17403:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   17407:	c9                   	leave  
   17408:	c3                   	ret    

00017409 <ck_pr_fas_uint>:
CK_PR_FAS_S(uint, unsigned int, "xchgl")
   17409:	55                   	push   %ebp
   1740a:	89 e5                	mov    %esp,%ebp
   1740c:	8b 55 08             	mov    0x8(%ebp),%edx
   1740f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17412:	8b 45 0c             	mov    0xc(%ebp),%eax
   17415:	87 02                	xchg   %eax,(%edx)
   17417:	89 45 0c             	mov    %eax,0xc(%ebp)
   1741a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1741d:	5d                   	pop    %ebp
   1741e:	c3                   	ret    

0001741f <ck_pr_fas_int>:
CK_PR_FAS_S(int, int, "xchgl")
   1741f:	55                   	push   %ebp
   17420:	89 e5                	mov    %esp,%ebp
   17422:	8b 55 08             	mov    0x8(%ebp),%edx
   17425:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17428:	8b 45 0c             	mov    0xc(%ebp),%eax
   1742b:	87 02                	xchg   %eax,(%edx)
   1742d:	89 45 0c             	mov    %eax,0xc(%ebp)
   17430:	8b 45 0c             	mov    0xc(%ebp),%eax
   17433:	5d                   	pop    %ebp
   17434:	c3                   	ret    

00017435 <ck_pr_fas_32>:
CK_PR_FAS_S(32, uint32_t, "xchgl")
   17435:	55                   	push   %ebp
   17436:	89 e5                	mov    %esp,%ebp
   17438:	8b 55 08             	mov    0x8(%ebp),%edx
   1743b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1743e:	8b 45 0c             	mov    0xc(%ebp),%eax
   17441:	87 02                	xchg   %eax,(%edx)
   17443:	89 45 0c             	mov    %eax,0xc(%ebp)
   17446:	8b 45 0c             	mov    0xc(%ebp),%eax
   17449:	5d                   	pop    %ebp
   1744a:	c3                   	ret    

0001744b <ck_pr_fas_16>:
CK_PR_FAS_S(16, uint16_t, "xchgw")
   1744b:	55                   	push   %ebp
   1744c:	89 e5                	mov    %esp,%ebp
   1744e:	83 ec 04             	sub    $0x4,%esp
   17451:	8b 45 0c             	mov    0xc(%ebp),%eax
   17454:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   17458:	8b 55 08             	mov    0x8(%ebp),%edx
   1745b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1745e:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   17462:	66 87 02             	xchg   %ax,(%edx)
   17465:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   17469:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1746d:	c9                   	leave  
   1746e:	c3                   	ret    

0001746f <ck_pr_fas_8>:
CK_PR_FAS_S(8,  uint8_t,  "xchgb")
   1746f:	55                   	push   %ebp
   17470:	89 e5                	mov    %esp,%ebp
   17472:	83 ec 04             	sub    $0x4,%esp
   17475:	8b 45 0c             	mov    0xc(%ebp),%eax
   17478:	88 45 fc             	mov    %al,-0x4(%ebp)
   1747b:	8b 55 08             	mov    0x8(%ebp),%edx
   1747e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17481:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   17485:	86 02                	xchg   %al,(%edx)
   17487:	88 45 fc             	mov    %al,-0x4(%ebp)
   1748a:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1748e:	c9                   	leave  
   1748f:	c3                   	ret    

00017490 <ck_pr_md_load_ptr>:
					: "m"  (*(const C *)target)	\
					: "memory");			\
		return (r);						\
	}

CK_PR_LOAD(ptr, void, void *, char, "movl")
   17490:	55                   	push   %ebp
   17491:	89 e5                	mov    %esp,%ebp
   17493:	83 ec 10             	sub    $0x10,%esp
   17496:	8b 45 08             	mov    0x8(%ebp),%eax
   17499:	8b 00                	mov    (%eax),%eax
   1749b:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1749e:	8b 45 fc             	mov    -0x4(%ebp),%eax
   174a1:	c9                   	leave  
   174a2:	c3                   	ret    

000174a3 <ck_pr_md_load_char>:

#define CK_PR_LOAD_S(S, T, I) CK_PR_LOAD(S, T, T, T, I)

CK_PR_LOAD_S(char, char, "movb")
   174a3:	55                   	push   %ebp
   174a4:	89 e5                	mov    %esp,%ebp
   174a6:	83 ec 10             	sub    $0x10,%esp
   174a9:	8b 45 08             	mov    0x8(%ebp),%eax
   174ac:	8a 00                	mov    (%eax),%al
   174ae:	88 45 ff             	mov    %al,-0x1(%ebp)
   174b1:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   174b5:	c9                   	leave  
   174b6:	c3                   	ret    

000174b7 <ck_pr_md_load_uint>:
CK_PR_LOAD_S(uint, unsigned int, "movl")
   174b7:	55                   	push   %ebp
   174b8:	89 e5                	mov    %esp,%ebp
   174ba:	83 ec 10             	sub    $0x10,%esp
   174bd:	8b 45 08             	mov    0x8(%ebp),%eax
   174c0:	8b 00                	mov    (%eax),%eax
   174c2:	89 45 fc             	mov    %eax,-0x4(%ebp)
   174c5:	8b 45 fc             	mov    -0x4(%ebp),%eax
   174c8:	c9                   	leave  
   174c9:	c3                   	ret    

000174ca <ck_pr_md_load_int>:
CK_PR_LOAD_S(int, int, "movl")
   174ca:	55                   	push   %ebp
   174cb:	89 e5                	mov    %esp,%ebp
   174cd:	83 ec 10             	sub    $0x10,%esp
   174d0:	8b 45 08             	mov    0x8(%ebp),%eax
   174d3:	8b 00                	mov    (%eax),%eax
   174d5:	89 45 fc             	mov    %eax,-0x4(%ebp)
   174d8:	8b 45 fc             	mov    -0x4(%ebp),%eax
   174db:	c9                   	leave  
   174dc:	c3                   	ret    

000174dd <ck_pr_md_load_32>:
CK_PR_LOAD_S(32, uint32_t, "movl")
   174dd:	55                   	push   %ebp
   174de:	89 e5                	mov    %esp,%ebp
   174e0:	83 ec 10             	sub    $0x10,%esp
   174e3:	8b 45 08             	mov    0x8(%ebp),%eax
   174e6:	8b 00                	mov    (%eax),%eax
   174e8:	89 45 fc             	mov    %eax,-0x4(%ebp)
   174eb:	8b 45 fc             	mov    -0x4(%ebp),%eax
   174ee:	c9                   	leave  
   174ef:	c3                   	ret    

000174f0 <ck_pr_md_load_16>:
CK_PR_LOAD_S(16, uint16_t, "movw")
   174f0:	55                   	push   %ebp
   174f1:	89 e5                	mov    %esp,%ebp
   174f3:	83 ec 10             	sub    $0x10,%esp
   174f6:	8b 45 08             	mov    0x8(%ebp),%eax
   174f9:	66 8b 00             	mov    (%eax),%ax
   174fc:	66 89 45 fe          	mov    %ax,-0x2(%ebp)
   17500:	0f b7 45 fe          	movzwl -0x2(%ebp),%eax
   17504:	c9                   	leave  
   17505:	c3                   	ret    

00017506 <ck_pr_md_load_8>:
CK_PR_LOAD_S(8,  uint8_t,  "movb")
   17506:	55                   	push   %ebp
   17507:	89 e5                	mov    %esp,%ebp
   17509:	83 ec 10             	sub    $0x10,%esp
   1750c:	8b 45 08             	mov    0x8(%ebp),%eax
   1750f:	8a 00                	mov    (%eax),%al
   17511:	88 45 ff             	mov    %al,-0x1(%ebp)
   17514:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   17518:	c9                   	leave  
   17519:	c3                   	ret    

0001751a <ck_pr_md_store_ptr>:
					: CK_CC_IMM "q" (v)	\
					: "memory");		\
		return;						\
	}

CK_PR_STORE(ptr, void, const void *, char, "movl")
   1751a:	55                   	push   %ebp
   1751b:	89 e5                	mov    %esp,%ebp
   1751d:	8b 45 08             	mov    0x8(%ebp),%eax
   17520:	8b 55 0c             	mov    0xc(%ebp),%edx
   17523:	89 10                	mov    %edx,(%eax)
   17525:	90                   	nop
   17526:	5d                   	pop    %ebp
   17527:	c3                   	ret    

00017528 <ck_pr_md_store_char>:

#define CK_PR_STORE_S(S, T, I) CK_PR_STORE(S, T, T, T, I)

CK_PR_STORE_S(char, char, "movb")
   17528:	55                   	push   %ebp
   17529:	89 e5                	mov    %esp,%ebp
   1752b:	83 ec 04             	sub    $0x4,%esp
   1752e:	8b 45 0c             	mov    0xc(%ebp),%eax
   17531:	88 45 fc             	mov    %al,-0x4(%ebp)
   17534:	8b 45 08             	mov    0x8(%ebp),%eax
   17537:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1753b:	88 10                	mov    %dl,(%eax)
   1753d:	90                   	nop
   1753e:	c9                   	leave  
   1753f:	c3                   	ret    

00017540 <ck_pr_md_store_uint>:
CK_PR_STORE_S(uint, unsigned int, "movl")
   17540:	55                   	push   %ebp
   17541:	89 e5                	mov    %esp,%ebp
   17543:	8b 45 08             	mov    0x8(%ebp),%eax
   17546:	8b 55 0c             	mov    0xc(%ebp),%edx
   17549:	89 10                	mov    %edx,(%eax)
   1754b:	90                   	nop
   1754c:	5d                   	pop    %ebp
   1754d:	c3                   	ret    

0001754e <ck_pr_md_store_int>:
CK_PR_STORE_S(int, int, "movl")
   1754e:	55                   	push   %ebp
   1754f:	89 e5                	mov    %esp,%ebp
   17551:	8b 45 08             	mov    0x8(%ebp),%eax
   17554:	8b 55 0c             	mov    0xc(%ebp),%edx
   17557:	89 10                	mov    %edx,(%eax)
   17559:	90                   	nop
   1755a:	5d                   	pop    %ebp
   1755b:	c3                   	ret    

0001755c <ck_pr_md_store_32>:
CK_PR_STORE_S(32, uint32_t, "movl")
   1755c:	55                   	push   %ebp
   1755d:	89 e5                	mov    %esp,%ebp
   1755f:	8b 45 08             	mov    0x8(%ebp),%eax
   17562:	8b 55 0c             	mov    0xc(%ebp),%edx
   17565:	89 10                	mov    %edx,(%eax)
   17567:	90                   	nop
   17568:	5d                   	pop    %ebp
   17569:	c3                   	ret    

0001756a <ck_pr_md_store_16>:
CK_PR_STORE_S(16, uint16_t, "movw")
   1756a:	55                   	push   %ebp
   1756b:	89 e5                	mov    %esp,%ebp
   1756d:	83 ec 04             	sub    $0x4,%esp
   17570:	8b 45 0c             	mov    0xc(%ebp),%eax
   17573:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   17577:	8b 45 08             	mov    0x8(%ebp),%eax
   1757a:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1757e:	66 89 10             	mov    %dx,(%eax)
   17581:	90                   	nop
   17582:	c9                   	leave  
   17583:	c3                   	ret    

00017584 <ck_pr_md_store_8>:
CK_PR_STORE_S(8,  uint8_t, "movb")
   17584:	55                   	push   %ebp
   17585:	89 e5                	mov    %esp,%ebp
   17587:	83 ec 04             	sub    $0x4,%esp
   1758a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1758d:	88 45 fc             	mov    %al,-0x4(%ebp)
   17590:	8b 45 08             	mov    0x8(%ebp),%eax
   17593:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17597:	88 10                	mov    %dl,(%eax)
   17599:	90                   	nop
   1759a:	c9                   	leave  
   1759b:	c3                   	ret    

0001759c <ck_pr_faa_ptr>:
					:				\
					: "memory", "cc");		\
		return (d);						\
	}

CK_PR_FAA(ptr, void, uintptr_t, char, "xaddl")
   1759c:	55                   	push   %ebp
   1759d:	89 e5                	mov    %esp,%ebp
   1759f:	8b 55 08             	mov    0x8(%ebp),%edx
   175a2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   175a5:	8b 45 0c             	mov    0xc(%ebp),%eax
   175a8:	f0 0f c1 02          	lock xadd %eax,(%edx)
   175ac:	89 45 0c             	mov    %eax,0xc(%ebp)
   175af:	8b 45 0c             	mov    0xc(%ebp),%eax
   175b2:	5d                   	pop    %ebp
   175b3:	c3                   	ret    

000175b4 <ck_pr_faa_char>:

#define CK_PR_FAA_S(S, T, I) CK_PR_FAA(S, T, T, T, I)

CK_PR_FAA_S(char, char, "xaddb")
   175b4:	55                   	push   %ebp
   175b5:	89 e5                	mov    %esp,%ebp
   175b7:	83 ec 04             	sub    $0x4,%esp
   175ba:	8b 45 0c             	mov    0xc(%ebp),%eax
   175bd:	88 45 fc             	mov    %al,-0x4(%ebp)
   175c0:	8b 55 08             	mov    0x8(%ebp),%edx
   175c3:	8b 4d 08             	mov    0x8(%ebp),%ecx
   175c6:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   175ca:	f0 0f c0 02          	lock xadd %al,(%edx)
   175ce:	88 45 fc             	mov    %al,-0x4(%ebp)
   175d1:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   175d5:	c9                   	leave  
   175d6:	c3                   	ret    

000175d7 <ck_pr_faa_uint>:
CK_PR_FAA_S(uint, unsigned int, "xaddl")
   175d7:	55                   	push   %ebp
   175d8:	89 e5                	mov    %esp,%ebp
   175da:	8b 55 08             	mov    0x8(%ebp),%edx
   175dd:	8b 4d 08             	mov    0x8(%ebp),%ecx
   175e0:	8b 45 0c             	mov    0xc(%ebp),%eax
   175e3:	f0 0f c1 02          	lock xadd %eax,(%edx)
   175e7:	89 45 0c             	mov    %eax,0xc(%ebp)
   175ea:	8b 45 0c             	mov    0xc(%ebp),%eax
   175ed:	5d                   	pop    %ebp
   175ee:	c3                   	ret    

000175ef <ck_pr_faa_int>:
CK_PR_FAA_S(int, int, "xaddl")
   175ef:	55                   	push   %ebp
   175f0:	89 e5                	mov    %esp,%ebp
   175f2:	8b 55 08             	mov    0x8(%ebp),%edx
   175f5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   175f8:	8b 45 0c             	mov    0xc(%ebp),%eax
   175fb:	f0 0f c1 02          	lock xadd %eax,(%edx)
   175ff:	89 45 0c             	mov    %eax,0xc(%ebp)
   17602:	8b 45 0c             	mov    0xc(%ebp),%eax
   17605:	5d                   	pop    %ebp
   17606:	c3                   	ret    

00017607 <ck_pr_faa_32>:
CK_PR_FAA_S(32, uint32_t, "xaddl")
   17607:	55                   	push   %ebp
   17608:	89 e5                	mov    %esp,%ebp
   1760a:	8b 55 08             	mov    0x8(%ebp),%edx
   1760d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17610:	8b 45 0c             	mov    0xc(%ebp),%eax
   17613:	f0 0f c1 02          	lock xadd %eax,(%edx)
   17617:	89 45 0c             	mov    %eax,0xc(%ebp)
   1761a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1761d:	5d                   	pop    %ebp
   1761e:	c3                   	ret    

0001761f <ck_pr_faa_16>:
CK_PR_FAA_S(16, uint16_t, "xaddw")
   1761f:	55                   	push   %ebp
   17620:	89 e5                	mov    %esp,%ebp
   17622:	83 ec 04             	sub    $0x4,%esp
   17625:	8b 45 0c             	mov    0xc(%ebp),%eax
   17628:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1762c:	8b 55 08             	mov    0x8(%ebp),%edx
   1762f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17632:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   17636:	66 f0 0f c1 02       	lock xadd %ax,(%edx)
   1763b:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1763f:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   17643:	c9                   	leave  
   17644:	c3                   	ret    

00017645 <ck_pr_faa_8>:
CK_PR_FAA_S(8,  uint8_t,  "xaddb")
   17645:	55                   	push   %ebp
   17646:	89 e5                	mov    %esp,%ebp
   17648:	83 ec 04             	sub    $0x4,%esp
   1764b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1764e:	88 45 fc             	mov    %al,-0x4(%ebp)
   17651:	8b 55 08             	mov    0x8(%ebp),%edx
   17654:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17657:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1765b:	f0 0f c0 02          	lock xadd %al,(%edx)
   1765f:	88 45 fc             	mov    %al,-0x4(%ebp)
   17662:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   17666:	c9                   	leave  
   17667:	c3                   	ret    

00017668 <ck_pr_inc_ptr>:
	CK_PR_UNARY_S(K, uint, unsigned int, #K "l")	\
	CK_PR_UNARY_S(K, 32, uint32_t, #K "l")		\
	CK_PR_UNARY_S(K, 16, uint16_t, #K "w")		\
	CK_PR_UNARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(inc)
   17668:	55                   	push   %ebp
   17669:	89 e5                	mov    %esp,%ebp
   1766b:	8b 45 08             	mov    0x8(%ebp),%eax
   1766e:	8b 55 08             	mov    0x8(%ebp),%edx
   17671:	f0 ff 00             	lock incl (%eax)
   17674:	90                   	nop
   17675:	5d                   	pop    %ebp
   17676:	c3                   	ret    

00017677 <ck_pr_inc_ptr_zero>:
   17677:	55                   	push   %ebp
   17678:	89 e5                	mov    %esp,%ebp
   1767a:	8b 45 08             	mov    0x8(%ebp),%eax
   1767d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   17680:	8b 55 08             	mov    0x8(%ebp),%edx
   17683:	f0 ff 00             	lock incl (%eax)
   17686:	0f 94 01             	sete   (%ecx)
   17689:	90                   	nop
   1768a:	5d                   	pop    %ebp
   1768b:	c3                   	ret    

0001768c <ck_pr_inc_char>:
   1768c:	55                   	push   %ebp
   1768d:	89 e5                	mov    %esp,%ebp
   1768f:	8b 45 08             	mov    0x8(%ebp),%eax
   17692:	8b 55 08             	mov    0x8(%ebp),%edx
   17695:	f0 fe 00             	lock incb (%eax)
   17698:	90                   	nop
   17699:	5d                   	pop    %ebp
   1769a:	c3                   	ret    

0001769b <ck_pr_inc_char_zero>:
   1769b:	55                   	push   %ebp
   1769c:	89 e5                	mov    %esp,%ebp
   1769e:	8b 45 08             	mov    0x8(%ebp),%eax
   176a1:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   176a4:	8b 55 08             	mov    0x8(%ebp),%edx
   176a7:	f0 fe 00             	lock incb (%eax)
   176aa:	0f 94 01             	sete   (%ecx)
   176ad:	90                   	nop
   176ae:	5d                   	pop    %ebp
   176af:	c3                   	ret    

000176b0 <ck_pr_inc_int>:
   176b0:	55                   	push   %ebp
   176b1:	89 e5                	mov    %esp,%ebp
   176b3:	8b 45 08             	mov    0x8(%ebp),%eax
   176b6:	8b 55 08             	mov    0x8(%ebp),%edx
   176b9:	f0 ff 00             	lock incl (%eax)
   176bc:	90                   	nop
   176bd:	5d                   	pop    %ebp
   176be:	c3                   	ret    

000176bf <ck_pr_inc_int_zero>:
   176bf:	55                   	push   %ebp
   176c0:	89 e5                	mov    %esp,%ebp
   176c2:	8b 45 08             	mov    0x8(%ebp),%eax
   176c5:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   176c8:	8b 55 08             	mov    0x8(%ebp),%edx
   176cb:	f0 ff 00             	lock incl (%eax)
   176ce:	0f 94 01             	sete   (%ecx)
   176d1:	90                   	nop
   176d2:	5d                   	pop    %ebp
   176d3:	c3                   	ret    

000176d4 <ck_pr_inc_uint>:
   176d4:	55                   	push   %ebp
   176d5:	89 e5                	mov    %esp,%ebp
   176d7:	8b 45 08             	mov    0x8(%ebp),%eax
   176da:	8b 55 08             	mov    0x8(%ebp),%edx
   176dd:	f0 ff 00             	lock incl (%eax)
   176e0:	90                   	nop
   176e1:	5d                   	pop    %ebp
   176e2:	c3                   	ret    

000176e3 <ck_pr_inc_uint_zero>:
   176e3:	55                   	push   %ebp
   176e4:	89 e5                	mov    %esp,%ebp
   176e6:	8b 45 08             	mov    0x8(%ebp),%eax
   176e9:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   176ec:	8b 55 08             	mov    0x8(%ebp),%edx
   176ef:	f0 ff 00             	lock incl (%eax)
   176f2:	0f 94 01             	sete   (%ecx)
   176f5:	90                   	nop
   176f6:	5d                   	pop    %ebp
   176f7:	c3                   	ret    

000176f8 <ck_pr_inc_32>:
   176f8:	55                   	push   %ebp
   176f9:	89 e5                	mov    %esp,%ebp
   176fb:	8b 45 08             	mov    0x8(%ebp),%eax
   176fe:	8b 55 08             	mov    0x8(%ebp),%edx
   17701:	f0 ff 00             	lock incl (%eax)
   17704:	90                   	nop
   17705:	5d                   	pop    %ebp
   17706:	c3                   	ret    

00017707 <ck_pr_inc_32_zero>:
   17707:	55                   	push   %ebp
   17708:	89 e5                	mov    %esp,%ebp
   1770a:	8b 45 08             	mov    0x8(%ebp),%eax
   1770d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   17710:	8b 55 08             	mov    0x8(%ebp),%edx
   17713:	f0 ff 00             	lock incl (%eax)
   17716:	0f 94 01             	sete   (%ecx)
   17719:	90                   	nop
   1771a:	5d                   	pop    %ebp
   1771b:	c3                   	ret    

0001771c <ck_pr_inc_16>:
   1771c:	55                   	push   %ebp
   1771d:	89 e5                	mov    %esp,%ebp
   1771f:	8b 45 08             	mov    0x8(%ebp),%eax
   17722:	8b 55 08             	mov    0x8(%ebp),%edx
   17725:	66 f0 ff 00          	lock incw (%eax)
   17729:	90                   	nop
   1772a:	5d                   	pop    %ebp
   1772b:	c3                   	ret    

0001772c <ck_pr_inc_16_zero>:
   1772c:	55                   	push   %ebp
   1772d:	89 e5                	mov    %esp,%ebp
   1772f:	8b 45 08             	mov    0x8(%ebp),%eax
   17732:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   17735:	8b 55 08             	mov    0x8(%ebp),%edx
   17738:	66 f0 ff 00          	lock incw (%eax)
   1773c:	0f 94 01             	sete   (%ecx)
   1773f:	90                   	nop
   17740:	5d                   	pop    %ebp
   17741:	c3                   	ret    

00017742 <ck_pr_inc_8>:
   17742:	55                   	push   %ebp
   17743:	89 e5                	mov    %esp,%ebp
   17745:	8b 45 08             	mov    0x8(%ebp),%eax
   17748:	8b 55 08             	mov    0x8(%ebp),%edx
   1774b:	f0 fe 00             	lock incb (%eax)
   1774e:	90                   	nop
   1774f:	5d                   	pop    %ebp
   17750:	c3                   	ret    

00017751 <ck_pr_inc_8_zero>:
   17751:	55                   	push   %ebp
   17752:	89 e5                	mov    %esp,%ebp
   17754:	8b 45 08             	mov    0x8(%ebp),%eax
   17757:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1775a:	8b 55 08             	mov    0x8(%ebp),%edx
   1775d:	f0 fe 00             	lock incb (%eax)
   17760:	0f 94 01             	sete   (%ecx)
   17763:	90                   	nop
   17764:	5d                   	pop    %ebp
   17765:	c3                   	ret    

00017766 <ck_pr_dec_ptr>:
CK_PR_GENERATE(dec)
   17766:	55                   	push   %ebp
   17767:	89 e5                	mov    %esp,%ebp
   17769:	8b 45 08             	mov    0x8(%ebp),%eax
   1776c:	8b 55 08             	mov    0x8(%ebp),%edx
   1776f:	f0 ff 08             	lock decl (%eax)
   17772:	90                   	nop
   17773:	5d                   	pop    %ebp
   17774:	c3                   	ret    

00017775 <ck_pr_dec_ptr_zero>:
   17775:	55                   	push   %ebp
   17776:	89 e5                	mov    %esp,%ebp
   17778:	8b 45 08             	mov    0x8(%ebp),%eax
   1777b:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1777e:	8b 55 08             	mov    0x8(%ebp),%edx
   17781:	f0 ff 08             	lock decl (%eax)
   17784:	0f 94 01             	sete   (%ecx)
   17787:	90                   	nop
   17788:	5d                   	pop    %ebp
   17789:	c3                   	ret    

0001778a <ck_pr_dec_char>:
   1778a:	55                   	push   %ebp
   1778b:	89 e5                	mov    %esp,%ebp
   1778d:	8b 45 08             	mov    0x8(%ebp),%eax
   17790:	8b 55 08             	mov    0x8(%ebp),%edx
   17793:	f0 fe 08             	lock decb (%eax)
   17796:	90                   	nop
   17797:	5d                   	pop    %ebp
   17798:	c3                   	ret    

00017799 <ck_pr_dec_char_zero>:
   17799:	55                   	push   %ebp
   1779a:	89 e5                	mov    %esp,%ebp
   1779c:	8b 45 08             	mov    0x8(%ebp),%eax
   1779f:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   177a2:	8b 55 08             	mov    0x8(%ebp),%edx
   177a5:	f0 fe 08             	lock decb (%eax)
   177a8:	0f 94 01             	sete   (%ecx)
   177ab:	90                   	nop
   177ac:	5d                   	pop    %ebp
   177ad:	c3                   	ret    

000177ae <ck_pr_dec_int>:
   177ae:	55                   	push   %ebp
   177af:	89 e5                	mov    %esp,%ebp
   177b1:	8b 45 08             	mov    0x8(%ebp),%eax
   177b4:	8b 55 08             	mov    0x8(%ebp),%edx
   177b7:	f0 ff 08             	lock decl (%eax)
   177ba:	90                   	nop
   177bb:	5d                   	pop    %ebp
   177bc:	c3                   	ret    

000177bd <ck_pr_dec_int_zero>:
   177bd:	55                   	push   %ebp
   177be:	89 e5                	mov    %esp,%ebp
   177c0:	8b 45 08             	mov    0x8(%ebp),%eax
   177c3:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   177c6:	8b 55 08             	mov    0x8(%ebp),%edx
   177c9:	f0 ff 08             	lock decl (%eax)
   177cc:	0f 94 01             	sete   (%ecx)
   177cf:	90                   	nop
   177d0:	5d                   	pop    %ebp
   177d1:	c3                   	ret    

000177d2 <ck_pr_dec_uint>:
   177d2:	55                   	push   %ebp
   177d3:	89 e5                	mov    %esp,%ebp
   177d5:	8b 45 08             	mov    0x8(%ebp),%eax
   177d8:	8b 55 08             	mov    0x8(%ebp),%edx
   177db:	f0 ff 08             	lock decl (%eax)
   177de:	90                   	nop
   177df:	5d                   	pop    %ebp
   177e0:	c3                   	ret    

000177e1 <ck_pr_dec_uint_zero>:
   177e1:	55                   	push   %ebp
   177e2:	89 e5                	mov    %esp,%ebp
   177e4:	8b 45 08             	mov    0x8(%ebp),%eax
   177e7:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   177ea:	8b 55 08             	mov    0x8(%ebp),%edx
   177ed:	f0 ff 08             	lock decl (%eax)
   177f0:	0f 94 01             	sete   (%ecx)
   177f3:	90                   	nop
   177f4:	5d                   	pop    %ebp
   177f5:	c3                   	ret    

000177f6 <ck_pr_dec_32>:
   177f6:	55                   	push   %ebp
   177f7:	89 e5                	mov    %esp,%ebp
   177f9:	8b 45 08             	mov    0x8(%ebp),%eax
   177fc:	8b 55 08             	mov    0x8(%ebp),%edx
   177ff:	f0 ff 08             	lock decl (%eax)
   17802:	90                   	nop
   17803:	5d                   	pop    %ebp
   17804:	c3                   	ret    

00017805 <ck_pr_dec_32_zero>:
   17805:	55                   	push   %ebp
   17806:	89 e5                	mov    %esp,%ebp
   17808:	8b 45 08             	mov    0x8(%ebp),%eax
   1780b:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1780e:	8b 55 08             	mov    0x8(%ebp),%edx
   17811:	f0 ff 08             	lock decl (%eax)
   17814:	0f 94 01             	sete   (%ecx)
   17817:	90                   	nop
   17818:	5d                   	pop    %ebp
   17819:	c3                   	ret    

0001781a <ck_pr_dec_16>:
   1781a:	55                   	push   %ebp
   1781b:	89 e5                	mov    %esp,%ebp
   1781d:	8b 45 08             	mov    0x8(%ebp),%eax
   17820:	8b 55 08             	mov    0x8(%ebp),%edx
   17823:	66 f0 ff 08          	lock decw (%eax)
   17827:	90                   	nop
   17828:	5d                   	pop    %ebp
   17829:	c3                   	ret    

0001782a <ck_pr_dec_16_zero>:
   1782a:	55                   	push   %ebp
   1782b:	89 e5                	mov    %esp,%ebp
   1782d:	8b 45 08             	mov    0x8(%ebp),%eax
   17830:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   17833:	8b 55 08             	mov    0x8(%ebp),%edx
   17836:	66 f0 ff 08          	lock decw (%eax)
   1783a:	0f 94 01             	sete   (%ecx)
   1783d:	90                   	nop
   1783e:	5d                   	pop    %ebp
   1783f:	c3                   	ret    

00017840 <ck_pr_dec_8>:
   17840:	55                   	push   %ebp
   17841:	89 e5                	mov    %esp,%ebp
   17843:	8b 45 08             	mov    0x8(%ebp),%eax
   17846:	8b 55 08             	mov    0x8(%ebp),%edx
   17849:	f0 fe 08             	lock decb (%eax)
   1784c:	90                   	nop
   1784d:	5d                   	pop    %ebp
   1784e:	c3                   	ret    

0001784f <ck_pr_dec_8_zero>:
   1784f:	55                   	push   %ebp
   17850:	89 e5                	mov    %esp,%ebp
   17852:	8b 45 08             	mov    0x8(%ebp),%eax
   17855:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   17858:	8b 55 08             	mov    0x8(%ebp),%edx
   1785b:	f0 fe 08             	lock decb (%eax)
   1785e:	0f 94 01             	sete   (%ecx)
   17861:	90                   	nop
   17862:	5d                   	pop    %ebp
   17863:	c3                   	ret    

00017864 <ck_pr_neg_ptr>:
CK_PR_GENERATE(neg)
   17864:	55                   	push   %ebp
   17865:	89 e5                	mov    %esp,%ebp
   17867:	8b 45 08             	mov    0x8(%ebp),%eax
   1786a:	8b 55 08             	mov    0x8(%ebp),%edx
   1786d:	f0 f7 18             	lock negl (%eax)
   17870:	90                   	nop
   17871:	5d                   	pop    %ebp
   17872:	c3                   	ret    

00017873 <ck_pr_neg_ptr_zero>:
   17873:	55                   	push   %ebp
   17874:	89 e5                	mov    %esp,%ebp
   17876:	8b 45 08             	mov    0x8(%ebp),%eax
   17879:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1787c:	8b 55 08             	mov    0x8(%ebp),%edx
   1787f:	f0 f7 18             	lock negl (%eax)
   17882:	0f 94 01             	sete   (%ecx)
   17885:	90                   	nop
   17886:	5d                   	pop    %ebp
   17887:	c3                   	ret    

00017888 <ck_pr_neg_char>:
   17888:	55                   	push   %ebp
   17889:	89 e5                	mov    %esp,%ebp
   1788b:	8b 45 08             	mov    0x8(%ebp),%eax
   1788e:	8b 55 08             	mov    0x8(%ebp),%edx
   17891:	f0 f6 18             	lock negb (%eax)
   17894:	90                   	nop
   17895:	5d                   	pop    %ebp
   17896:	c3                   	ret    

00017897 <ck_pr_neg_char_zero>:
   17897:	55                   	push   %ebp
   17898:	89 e5                	mov    %esp,%ebp
   1789a:	8b 45 08             	mov    0x8(%ebp),%eax
   1789d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   178a0:	8b 55 08             	mov    0x8(%ebp),%edx
   178a3:	f0 f6 18             	lock negb (%eax)
   178a6:	0f 94 01             	sete   (%ecx)
   178a9:	90                   	nop
   178aa:	5d                   	pop    %ebp
   178ab:	c3                   	ret    

000178ac <ck_pr_neg_int>:
   178ac:	55                   	push   %ebp
   178ad:	89 e5                	mov    %esp,%ebp
   178af:	8b 45 08             	mov    0x8(%ebp),%eax
   178b2:	8b 55 08             	mov    0x8(%ebp),%edx
   178b5:	f0 f7 18             	lock negl (%eax)
   178b8:	90                   	nop
   178b9:	5d                   	pop    %ebp
   178ba:	c3                   	ret    

000178bb <ck_pr_neg_int_zero>:
   178bb:	55                   	push   %ebp
   178bc:	89 e5                	mov    %esp,%ebp
   178be:	8b 45 08             	mov    0x8(%ebp),%eax
   178c1:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   178c4:	8b 55 08             	mov    0x8(%ebp),%edx
   178c7:	f0 f7 18             	lock negl (%eax)
   178ca:	0f 94 01             	sete   (%ecx)
   178cd:	90                   	nop
   178ce:	5d                   	pop    %ebp
   178cf:	c3                   	ret    

000178d0 <ck_pr_neg_uint>:
   178d0:	55                   	push   %ebp
   178d1:	89 e5                	mov    %esp,%ebp
   178d3:	8b 45 08             	mov    0x8(%ebp),%eax
   178d6:	8b 55 08             	mov    0x8(%ebp),%edx
   178d9:	f0 f7 18             	lock negl (%eax)
   178dc:	90                   	nop
   178dd:	5d                   	pop    %ebp
   178de:	c3                   	ret    

000178df <ck_pr_neg_uint_zero>:
   178df:	55                   	push   %ebp
   178e0:	89 e5                	mov    %esp,%ebp
   178e2:	8b 45 08             	mov    0x8(%ebp),%eax
   178e5:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   178e8:	8b 55 08             	mov    0x8(%ebp),%edx
   178eb:	f0 f7 18             	lock negl (%eax)
   178ee:	0f 94 01             	sete   (%ecx)
   178f1:	90                   	nop
   178f2:	5d                   	pop    %ebp
   178f3:	c3                   	ret    

000178f4 <ck_pr_neg_32>:
   178f4:	55                   	push   %ebp
   178f5:	89 e5                	mov    %esp,%ebp
   178f7:	8b 45 08             	mov    0x8(%ebp),%eax
   178fa:	8b 55 08             	mov    0x8(%ebp),%edx
   178fd:	f0 f7 18             	lock negl (%eax)
   17900:	90                   	nop
   17901:	5d                   	pop    %ebp
   17902:	c3                   	ret    

00017903 <ck_pr_neg_32_zero>:
   17903:	55                   	push   %ebp
   17904:	89 e5                	mov    %esp,%ebp
   17906:	8b 45 08             	mov    0x8(%ebp),%eax
   17909:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1790c:	8b 55 08             	mov    0x8(%ebp),%edx
   1790f:	f0 f7 18             	lock negl (%eax)
   17912:	0f 94 01             	sete   (%ecx)
   17915:	90                   	nop
   17916:	5d                   	pop    %ebp
   17917:	c3                   	ret    

00017918 <ck_pr_neg_16>:
   17918:	55                   	push   %ebp
   17919:	89 e5                	mov    %esp,%ebp
   1791b:	8b 45 08             	mov    0x8(%ebp),%eax
   1791e:	8b 55 08             	mov    0x8(%ebp),%edx
   17921:	66 f0 f7 18          	lock negw (%eax)
   17925:	90                   	nop
   17926:	5d                   	pop    %ebp
   17927:	c3                   	ret    

00017928 <ck_pr_neg_16_zero>:
   17928:	55                   	push   %ebp
   17929:	89 e5                	mov    %esp,%ebp
   1792b:	8b 45 08             	mov    0x8(%ebp),%eax
   1792e:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   17931:	8b 55 08             	mov    0x8(%ebp),%edx
   17934:	66 f0 f7 18          	lock negw (%eax)
   17938:	0f 94 01             	sete   (%ecx)
   1793b:	90                   	nop
   1793c:	5d                   	pop    %ebp
   1793d:	c3                   	ret    

0001793e <ck_pr_neg_8>:
   1793e:	55                   	push   %ebp
   1793f:	89 e5                	mov    %esp,%ebp
   17941:	8b 45 08             	mov    0x8(%ebp),%eax
   17944:	8b 55 08             	mov    0x8(%ebp),%edx
   17947:	f0 f6 18             	lock negb (%eax)
   1794a:	90                   	nop
   1794b:	5d                   	pop    %ebp
   1794c:	c3                   	ret    

0001794d <ck_pr_neg_8_zero>:
   1794d:	55                   	push   %ebp
   1794e:	89 e5                	mov    %esp,%ebp
   17950:	8b 45 08             	mov    0x8(%ebp),%eax
   17953:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   17956:	8b 55 08             	mov    0x8(%ebp),%edx
   17959:	f0 f6 18             	lock negb (%eax)
   1795c:	0f 94 01             	sete   (%ecx)
   1795f:	90                   	nop
   17960:	5d                   	pop    %ebp
   17961:	c3                   	ret    

00017962 <ck_pr_not_ptr>:

/* not does not affect condition flags. */
#undef CK_PR_UNARY_V
#define CK_PR_UNARY_V(a, b, c, d, e)
CK_PR_GENERATE(not)
   17962:	55                   	push   %ebp
   17963:	89 e5                	mov    %esp,%ebp
   17965:	8b 45 08             	mov    0x8(%ebp),%eax
   17968:	8b 55 08             	mov    0x8(%ebp),%edx
   1796b:	f0 f7 10             	lock notl (%eax)
   1796e:	90                   	nop
   1796f:	5d                   	pop    %ebp
   17970:	c3                   	ret    

00017971 <ck_pr_not_char>:
   17971:	55                   	push   %ebp
   17972:	89 e5                	mov    %esp,%ebp
   17974:	8b 45 08             	mov    0x8(%ebp),%eax
   17977:	8b 55 08             	mov    0x8(%ebp),%edx
   1797a:	f0 f6 10             	lock notb (%eax)
   1797d:	90                   	nop
   1797e:	5d                   	pop    %ebp
   1797f:	c3                   	ret    

00017980 <ck_pr_not_int>:
   17980:	55                   	push   %ebp
   17981:	89 e5                	mov    %esp,%ebp
   17983:	8b 45 08             	mov    0x8(%ebp),%eax
   17986:	8b 55 08             	mov    0x8(%ebp),%edx
   17989:	f0 f7 10             	lock notl (%eax)
   1798c:	90                   	nop
   1798d:	5d                   	pop    %ebp
   1798e:	c3                   	ret    

0001798f <ck_pr_not_uint>:
   1798f:	55                   	push   %ebp
   17990:	89 e5                	mov    %esp,%ebp
   17992:	8b 45 08             	mov    0x8(%ebp),%eax
   17995:	8b 55 08             	mov    0x8(%ebp),%edx
   17998:	f0 f7 10             	lock notl (%eax)
   1799b:	90                   	nop
   1799c:	5d                   	pop    %ebp
   1799d:	c3                   	ret    

0001799e <ck_pr_not_32>:
   1799e:	55                   	push   %ebp
   1799f:	89 e5                	mov    %esp,%ebp
   179a1:	8b 45 08             	mov    0x8(%ebp),%eax
   179a4:	8b 55 08             	mov    0x8(%ebp),%edx
   179a7:	f0 f7 10             	lock notl (%eax)
   179aa:	90                   	nop
   179ab:	5d                   	pop    %ebp
   179ac:	c3                   	ret    

000179ad <ck_pr_not_16>:
   179ad:	55                   	push   %ebp
   179ae:	89 e5                	mov    %esp,%ebp
   179b0:	8b 45 08             	mov    0x8(%ebp),%eax
   179b3:	8b 55 08             	mov    0x8(%ebp),%edx
   179b6:	66 f0 f7 10          	lock notw (%eax)
   179ba:	90                   	nop
   179bb:	5d                   	pop    %ebp
   179bc:	c3                   	ret    

000179bd <ck_pr_not_8>:
   179bd:	55                   	push   %ebp
   179be:	89 e5                	mov    %esp,%ebp
   179c0:	8b 45 08             	mov    0x8(%ebp),%eax
   179c3:	8b 55 08             	mov    0x8(%ebp),%edx
   179c6:	f0 f6 10             	lock notb (%eax)
   179c9:	90                   	nop
   179ca:	5d                   	pop    %ebp
   179cb:	c3                   	ret    

000179cc <ck_pr_add_ptr>:
	CK_PR_BINARY_S(K, uint, unsigned int, #K "l")		\
	CK_PR_BINARY_S(K, 32, uint32_t, #K "l")			\
	CK_PR_BINARY_S(K, 16, uint16_t, #K "w")			\
	CK_PR_BINARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(add)
   179cc:	55                   	push   %ebp
   179cd:	89 e5                	mov    %esp,%ebp
   179cf:	8b 45 08             	mov    0x8(%ebp),%eax
   179d2:	8b 55 0c             	mov    0xc(%ebp),%edx
   179d5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   179d8:	f0 01 10             	lock add %edx,(%eax)
   179db:	90                   	nop
   179dc:	5d                   	pop    %ebp
   179dd:	c3                   	ret    

000179de <ck_pr_add_char>:
   179de:	55                   	push   %ebp
   179df:	89 e5                	mov    %esp,%ebp
   179e1:	83 ec 04             	sub    $0x4,%esp
   179e4:	8b 45 0c             	mov    0xc(%ebp),%eax
   179e7:	88 45 fc             	mov    %al,-0x4(%ebp)
   179ea:	8b 45 08             	mov    0x8(%ebp),%eax
   179ed:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   179f1:	8b 4d 08             	mov    0x8(%ebp),%ecx
   179f4:	f0 00 10             	lock add %dl,(%eax)
   179f7:	90                   	nop
   179f8:	c9                   	leave  
   179f9:	c3                   	ret    

000179fa <ck_pr_add_int>:
   179fa:	55                   	push   %ebp
   179fb:	89 e5                	mov    %esp,%ebp
   179fd:	8b 45 08             	mov    0x8(%ebp),%eax
   17a00:	8b 55 0c             	mov    0xc(%ebp),%edx
   17a03:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17a06:	f0 01 10             	lock add %edx,(%eax)
   17a09:	90                   	nop
   17a0a:	5d                   	pop    %ebp
   17a0b:	c3                   	ret    

00017a0c <ck_pr_add_uint>:
   17a0c:	55                   	push   %ebp
   17a0d:	89 e5                	mov    %esp,%ebp
   17a0f:	8b 45 08             	mov    0x8(%ebp),%eax
   17a12:	8b 55 0c             	mov    0xc(%ebp),%edx
   17a15:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17a18:	f0 01 10             	lock add %edx,(%eax)
   17a1b:	90                   	nop
   17a1c:	5d                   	pop    %ebp
   17a1d:	c3                   	ret    

00017a1e <ck_pr_add_32>:
   17a1e:	55                   	push   %ebp
   17a1f:	89 e5                	mov    %esp,%ebp
   17a21:	8b 45 08             	mov    0x8(%ebp),%eax
   17a24:	8b 55 0c             	mov    0xc(%ebp),%edx
   17a27:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17a2a:	f0 01 10             	lock add %edx,(%eax)
   17a2d:	90                   	nop
   17a2e:	5d                   	pop    %ebp
   17a2f:	c3                   	ret    

00017a30 <ck_pr_add_16>:
   17a30:	55                   	push   %ebp
   17a31:	89 e5                	mov    %esp,%ebp
   17a33:	83 ec 04             	sub    $0x4,%esp
   17a36:	8b 45 0c             	mov    0xc(%ebp),%eax
   17a39:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   17a3d:	8b 45 08             	mov    0x8(%ebp),%eax
   17a40:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   17a44:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17a47:	66 f0 01 10          	lock add %dx,(%eax)
   17a4b:	90                   	nop
   17a4c:	c9                   	leave  
   17a4d:	c3                   	ret    

00017a4e <ck_pr_add_8>:
   17a4e:	55                   	push   %ebp
   17a4f:	89 e5                	mov    %esp,%ebp
   17a51:	83 ec 04             	sub    $0x4,%esp
   17a54:	8b 45 0c             	mov    0xc(%ebp),%eax
   17a57:	88 45 fc             	mov    %al,-0x4(%ebp)
   17a5a:	8b 45 08             	mov    0x8(%ebp),%eax
   17a5d:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17a61:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17a64:	f0 00 10             	lock add %dl,(%eax)
   17a67:	90                   	nop
   17a68:	c9                   	leave  
   17a69:	c3                   	ret    

00017a6a <ck_pr_sub_ptr>:
CK_PR_GENERATE(sub)
   17a6a:	55                   	push   %ebp
   17a6b:	89 e5                	mov    %esp,%ebp
   17a6d:	8b 45 08             	mov    0x8(%ebp),%eax
   17a70:	8b 55 0c             	mov    0xc(%ebp),%edx
   17a73:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17a76:	f0 29 10             	lock sub %edx,(%eax)
   17a79:	90                   	nop
   17a7a:	5d                   	pop    %ebp
   17a7b:	c3                   	ret    

00017a7c <ck_pr_sub_char>:
   17a7c:	55                   	push   %ebp
   17a7d:	89 e5                	mov    %esp,%ebp
   17a7f:	83 ec 04             	sub    $0x4,%esp
   17a82:	8b 45 0c             	mov    0xc(%ebp),%eax
   17a85:	88 45 fc             	mov    %al,-0x4(%ebp)
   17a88:	8b 45 08             	mov    0x8(%ebp),%eax
   17a8b:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17a8f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17a92:	f0 28 10             	lock sub %dl,(%eax)
   17a95:	90                   	nop
   17a96:	c9                   	leave  
   17a97:	c3                   	ret    

00017a98 <ck_pr_sub_int>:
   17a98:	55                   	push   %ebp
   17a99:	89 e5                	mov    %esp,%ebp
   17a9b:	8b 45 08             	mov    0x8(%ebp),%eax
   17a9e:	8b 55 0c             	mov    0xc(%ebp),%edx
   17aa1:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17aa4:	f0 29 10             	lock sub %edx,(%eax)
   17aa7:	90                   	nop
   17aa8:	5d                   	pop    %ebp
   17aa9:	c3                   	ret    

00017aaa <ck_pr_sub_uint>:
   17aaa:	55                   	push   %ebp
   17aab:	89 e5                	mov    %esp,%ebp
   17aad:	8b 45 08             	mov    0x8(%ebp),%eax
   17ab0:	8b 55 0c             	mov    0xc(%ebp),%edx
   17ab3:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17ab6:	f0 29 10             	lock sub %edx,(%eax)
   17ab9:	90                   	nop
   17aba:	5d                   	pop    %ebp
   17abb:	c3                   	ret    

00017abc <ck_pr_sub_32>:
   17abc:	55                   	push   %ebp
   17abd:	89 e5                	mov    %esp,%ebp
   17abf:	8b 45 08             	mov    0x8(%ebp),%eax
   17ac2:	8b 55 0c             	mov    0xc(%ebp),%edx
   17ac5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17ac8:	f0 29 10             	lock sub %edx,(%eax)
   17acb:	90                   	nop
   17acc:	5d                   	pop    %ebp
   17acd:	c3                   	ret    

00017ace <ck_pr_sub_16>:
   17ace:	55                   	push   %ebp
   17acf:	89 e5                	mov    %esp,%ebp
   17ad1:	83 ec 04             	sub    $0x4,%esp
   17ad4:	8b 45 0c             	mov    0xc(%ebp),%eax
   17ad7:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   17adb:	8b 45 08             	mov    0x8(%ebp),%eax
   17ade:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   17ae2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17ae5:	66 f0 29 10          	lock sub %dx,(%eax)
   17ae9:	90                   	nop
   17aea:	c9                   	leave  
   17aeb:	c3                   	ret    

00017aec <ck_pr_sub_8>:
   17aec:	55                   	push   %ebp
   17aed:	89 e5                	mov    %esp,%ebp
   17aef:	83 ec 04             	sub    $0x4,%esp
   17af2:	8b 45 0c             	mov    0xc(%ebp),%eax
   17af5:	88 45 fc             	mov    %al,-0x4(%ebp)
   17af8:	8b 45 08             	mov    0x8(%ebp),%eax
   17afb:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17aff:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17b02:	f0 28 10             	lock sub %dl,(%eax)
   17b05:	90                   	nop
   17b06:	c9                   	leave  
   17b07:	c3                   	ret    

00017b08 <ck_pr_and_ptr>:
CK_PR_GENERATE(and)
   17b08:	55                   	push   %ebp
   17b09:	89 e5                	mov    %esp,%ebp
   17b0b:	8b 45 08             	mov    0x8(%ebp),%eax
   17b0e:	8b 55 0c             	mov    0xc(%ebp),%edx
   17b11:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17b14:	f0 21 10             	lock and %edx,(%eax)
   17b17:	90                   	nop
   17b18:	5d                   	pop    %ebp
   17b19:	c3                   	ret    

00017b1a <ck_pr_and_char>:
   17b1a:	55                   	push   %ebp
   17b1b:	89 e5                	mov    %esp,%ebp
   17b1d:	83 ec 04             	sub    $0x4,%esp
   17b20:	8b 45 0c             	mov    0xc(%ebp),%eax
   17b23:	88 45 fc             	mov    %al,-0x4(%ebp)
   17b26:	8b 45 08             	mov    0x8(%ebp),%eax
   17b29:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17b2d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17b30:	f0 20 10             	lock and %dl,(%eax)
   17b33:	90                   	nop
   17b34:	c9                   	leave  
   17b35:	c3                   	ret    

00017b36 <ck_pr_and_int>:
   17b36:	55                   	push   %ebp
   17b37:	89 e5                	mov    %esp,%ebp
   17b39:	8b 45 08             	mov    0x8(%ebp),%eax
   17b3c:	8b 55 0c             	mov    0xc(%ebp),%edx
   17b3f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17b42:	f0 21 10             	lock and %edx,(%eax)
   17b45:	90                   	nop
   17b46:	5d                   	pop    %ebp
   17b47:	c3                   	ret    

00017b48 <ck_pr_and_uint>:
   17b48:	55                   	push   %ebp
   17b49:	89 e5                	mov    %esp,%ebp
   17b4b:	8b 45 08             	mov    0x8(%ebp),%eax
   17b4e:	8b 55 0c             	mov    0xc(%ebp),%edx
   17b51:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17b54:	f0 21 10             	lock and %edx,(%eax)
   17b57:	90                   	nop
   17b58:	5d                   	pop    %ebp
   17b59:	c3                   	ret    

00017b5a <ck_pr_and_32>:
   17b5a:	55                   	push   %ebp
   17b5b:	89 e5                	mov    %esp,%ebp
   17b5d:	8b 45 08             	mov    0x8(%ebp),%eax
   17b60:	8b 55 0c             	mov    0xc(%ebp),%edx
   17b63:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17b66:	f0 21 10             	lock and %edx,(%eax)
   17b69:	90                   	nop
   17b6a:	5d                   	pop    %ebp
   17b6b:	c3                   	ret    

00017b6c <ck_pr_and_16>:
   17b6c:	55                   	push   %ebp
   17b6d:	89 e5                	mov    %esp,%ebp
   17b6f:	83 ec 04             	sub    $0x4,%esp
   17b72:	8b 45 0c             	mov    0xc(%ebp),%eax
   17b75:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   17b79:	8b 45 08             	mov    0x8(%ebp),%eax
   17b7c:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   17b80:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17b83:	66 f0 21 10          	lock and %dx,(%eax)
   17b87:	90                   	nop
   17b88:	c9                   	leave  
   17b89:	c3                   	ret    

00017b8a <ck_pr_and_8>:
   17b8a:	55                   	push   %ebp
   17b8b:	89 e5                	mov    %esp,%ebp
   17b8d:	83 ec 04             	sub    $0x4,%esp
   17b90:	8b 45 0c             	mov    0xc(%ebp),%eax
   17b93:	88 45 fc             	mov    %al,-0x4(%ebp)
   17b96:	8b 45 08             	mov    0x8(%ebp),%eax
   17b99:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17b9d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17ba0:	f0 20 10             	lock and %dl,(%eax)
   17ba3:	90                   	nop
   17ba4:	c9                   	leave  
   17ba5:	c3                   	ret    

00017ba6 <ck_pr_or_ptr>:
CK_PR_GENERATE(or)
   17ba6:	55                   	push   %ebp
   17ba7:	89 e5                	mov    %esp,%ebp
   17ba9:	8b 45 08             	mov    0x8(%ebp),%eax
   17bac:	8b 55 0c             	mov    0xc(%ebp),%edx
   17baf:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17bb2:	f0 09 10             	lock or %edx,(%eax)
   17bb5:	90                   	nop
   17bb6:	5d                   	pop    %ebp
   17bb7:	c3                   	ret    

00017bb8 <ck_pr_or_char>:
   17bb8:	55                   	push   %ebp
   17bb9:	89 e5                	mov    %esp,%ebp
   17bbb:	83 ec 04             	sub    $0x4,%esp
   17bbe:	8b 45 0c             	mov    0xc(%ebp),%eax
   17bc1:	88 45 fc             	mov    %al,-0x4(%ebp)
   17bc4:	8b 45 08             	mov    0x8(%ebp),%eax
   17bc7:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17bcb:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17bce:	f0 08 10             	lock or %dl,(%eax)
   17bd1:	90                   	nop
   17bd2:	c9                   	leave  
   17bd3:	c3                   	ret    

00017bd4 <ck_pr_or_int>:
   17bd4:	55                   	push   %ebp
   17bd5:	89 e5                	mov    %esp,%ebp
   17bd7:	8b 45 08             	mov    0x8(%ebp),%eax
   17bda:	8b 55 0c             	mov    0xc(%ebp),%edx
   17bdd:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17be0:	f0 09 10             	lock or %edx,(%eax)
   17be3:	90                   	nop
   17be4:	5d                   	pop    %ebp
   17be5:	c3                   	ret    

00017be6 <ck_pr_or_uint>:
   17be6:	55                   	push   %ebp
   17be7:	89 e5                	mov    %esp,%ebp
   17be9:	8b 45 08             	mov    0x8(%ebp),%eax
   17bec:	8b 55 0c             	mov    0xc(%ebp),%edx
   17bef:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17bf2:	f0 09 10             	lock or %edx,(%eax)
   17bf5:	90                   	nop
   17bf6:	5d                   	pop    %ebp
   17bf7:	c3                   	ret    

00017bf8 <ck_pr_or_32>:
   17bf8:	55                   	push   %ebp
   17bf9:	89 e5                	mov    %esp,%ebp
   17bfb:	8b 45 08             	mov    0x8(%ebp),%eax
   17bfe:	8b 55 0c             	mov    0xc(%ebp),%edx
   17c01:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17c04:	f0 09 10             	lock or %edx,(%eax)
   17c07:	90                   	nop
   17c08:	5d                   	pop    %ebp
   17c09:	c3                   	ret    

00017c0a <ck_pr_or_16>:
   17c0a:	55                   	push   %ebp
   17c0b:	89 e5                	mov    %esp,%ebp
   17c0d:	83 ec 04             	sub    $0x4,%esp
   17c10:	8b 45 0c             	mov    0xc(%ebp),%eax
   17c13:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   17c17:	8b 45 08             	mov    0x8(%ebp),%eax
   17c1a:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   17c1e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17c21:	66 f0 09 10          	lock or %dx,(%eax)
   17c25:	90                   	nop
   17c26:	c9                   	leave  
   17c27:	c3                   	ret    

00017c28 <ck_pr_or_8>:
   17c28:	55                   	push   %ebp
   17c29:	89 e5                	mov    %esp,%ebp
   17c2b:	83 ec 04             	sub    $0x4,%esp
   17c2e:	8b 45 0c             	mov    0xc(%ebp),%eax
   17c31:	88 45 fc             	mov    %al,-0x4(%ebp)
   17c34:	8b 45 08             	mov    0x8(%ebp),%eax
   17c37:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17c3b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17c3e:	f0 08 10             	lock or %dl,(%eax)
   17c41:	90                   	nop
   17c42:	c9                   	leave  
   17c43:	c3                   	ret    

00017c44 <ck_pr_xor_ptr>:
CK_PR_GENERATE(xor)
   17c44:	55                   	push   %ebp
   17c45:	89 e5                	mov    %esp,%ebp
   17c47:	8b 45 08             	mov    0x8(%ebp),%eax
   17c4a:	8b 55 0c             	mov    0xc(%ebp),%edx
   17c4d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17c50:	f0 31 10             	lock xor %edx,(%eax)
   17c53:	90                   	nop
   17c54:	5d                   	pop    %ebp
   17c55:	c3                   	ret    

00017c56 <ck_pr_xor_char>:
   17c56:	55                   	push   %ebp
   17c57:	89 e5                	mov    %esp,%ebp
   17c59:	83 ec 04             	sub    $0x4,%esp
   17c5c:	8b 45 0c             	mov    0xc(%ebp),%eax
   17c5f:	88 45 fc             	mov    %al,-0x4(%ebp)
   17c62:	8b 45 08             	mov    0x8(%ebp),%eax
   17c65:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17c69:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17c6c:	f0 30 10             	lock xor %dl,(%eax)
   17c6f:	90                   	nop
   17c70:	c9                   	leave  
   17c71:	c3                   	ret    

00017c72 <ck_pr_xor_int>:
   17c72:	55                   	push   %ebp
   17c73:	89 e5                	mov    %esp,%ebp
   17c75:	8b 45 08             	mov    0x8(%ebp),%eax
   17c78:	8b 55 0c             	mov    0xc(%ebp),%edx
   17c7b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17c7e:	f0 31 10             	lock xor %edx,(%eax)
   17c81:	90                   	nop
   17c82:	5d                   	pop    %ebp
   17c83:	c3                   	ret    

00017c84 <ck_pr_xor_uint>:
   17c84:	55                   	push   %ebp
   17c85:	89 e5                	mov    %esp,%ebp
   17c87:	8b 45 08             	mov    0x8(%ebp),%eax
   17c8a:	8b 55 0c             	mov    0xc(%ebp),%edx
   17c8d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17c90:	f0 31 10             	lock xor %edx,(%eax)
   17c93:	90                   	nop
   17c94:	5d                   	pop    %ebp
   17c95:	c3                   	ret    

00017c96 <ck_pr_xor_32>:
   17c96:	55                   	push   %ebp
   17c97:	89 e5                	mov    %esp,%ebp
   17c99:	8b 45 08             	mov    0x8(%ebp),%eax
   17c9c:	8b 55 0c             	mov    0xc(%ebp),%edx
   17c9f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17ca2:	f0 31 10             	lock xor %edx,(%eax)
   17ca5:	90                   	nop
   17ca6:	5d                   	pop    %ebp
   17ca7:	c3                   	ret    

00017ca8 <ck_pr_xor_16>:
   17ca8:	55                   	push   %ebp
   17ca9:	89 e5                	mov    %esp,%ebp
   17cab:	83 ec 04             	sub    $0x4,%esp
   17cae:	8b 45 0c             	mov    0xc(%ebp),%eax
   17cb1:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   17cb5:	8b 45 08             	mov    0x8(%ebp),%eax
   17cb8:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   17cbc:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17cbf:	66 f0 31 10          	lock xor %dx,(%eax)
   17cc3:	90                   	nop
   17cc4:	c9                   	leave  
   17cc5:	c3                   	ret    

00017cc6 <ck_pr_xor_8>:
   17cc6:	55                   	push   %ebp
   17cc7:	89 e5                	mov    %esp,%ebp
   17cc9:	83 ec 04             	sub    $0x4,%esp
   17ccc:	8b 45 0c             	mov    0xc(%ebp),%eax
   17ccf:	88 45 fc             	mov    %al,-0x4(%ebp)
   17cd2:	8b 45 08             	mov    0x8(%ebp),%eax
   17cd5:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   17cd9:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17cdc:	f0 30 10             	lock xor %dl,(%eax)
   17cdf:	90                   	nop
   17ce0:	c9                   	leave  
   17ce1:	c3                   	ret    

00017ce2 <ck_pr_cas_ptr>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return z;							\
	}

CK_PR_CAS(ptr, void, void *, char, "cmpxchgl")
   17ce2:	55                   	push   %ebp
   17ce3:	89 e5                	mov    %esp,%ebp
   17ce5:	53                   	push   %ebx
   17ce6:	83 ec 10             	sub    $0x10,%esp
   17ce9:	8b 55 08             	mov    0x8(%ebp),%edx
   17cec:	8b 4d 10             	mov    0x10(%ebp),%ecx
   17cef:	8b 45 0c             	mov    0xc(%ebp),%eax
   17cf2:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17cf5:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   17cf9:	0f 94 c0             	sete   %al
   17cfc:	88 45 fb             	mov    %al,-0x5(%ebp)
   17cff:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   17d03:	83 c4 10             	add    $0x10,%esp
   17d06:	5b                   	pop    %ebx
   17d07:	5d                   	pop    %ebp
   17d08:	c3                   	ret    

00017d09 <ck_pr_cas_char>:

#define CK_PR_CAS_S(S, T, I) CK_PR_CAS(S, T, T, T, I)

CK_PR_CAS_S(char, char, "cmpxchgb")
   17d09:	55                   	push   %ebp
   17d0a:	89 e5                	mov    %esp,%ebp
   17d0c:	53                   	push   %ebx
   17d0d:	83 ec 18             	sub    $0x18,%esp
   17d10:	8b 55 0c             	mov    0xc(%ebp),%edx
   17d13:	8b 45 10             	mov    0x10(%ebp),%eax
   17d16:	88 55 e8             	mov    %dl,-0x18(%ebp)
   17d19:	88 45 e4             	mov    %al,-0x1c(%ebp)
   17d1c:	8b 55 08             	mov    0x8(%ebp),%edx
   17d1f:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   17d23:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   17d27:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17d2a:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   17d2e:	0f 94 c0             	sete   %al
   17d31:	88 45 fb             	mov    %al,-0x5(%ebp)
   17d34:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   17d38:	83 c4 18             	add    $0x18,%esp
   17d3b:	5b                   	pop    %ebx
   17d3c:	5d                   	pop    %ebp
   17d3d:	c3                   	ret    

00017d3e <ck_pr_cas_int>:
CK_PR_CAS_S(int, int, "cmpxchgl")
   17d3e:	55                   	push   %ebp
   17d3f:	89 e5                	mov    %esp,%ebp
   17d41:	53                   	push   %ebx
   17d42:	83 ec 10             	sub    $0x10,%esp
   17d45:	8b 55 08             	mov    0x8(%ebp),%edx
   17d48:	8b 4d 10             	mov    0x10(%ebp),%ecx
   17d4b:	8b 45 0c             	mov    0xc(%ebp),%eax
   17d4e:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17d51:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   17d55:	0f 94 c0             	sete   %al
   17d58:	88 45 fb             	mov    %al,-0x5(%ebp)
   17d5b:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   17d5f:	83 c4 10             	add    $0x10,%esp
   17d62:	5b                   	pop    %ebx
   17d63:	5d                   	pop    %ebp
   17d64:	c3                   	ret    

00017d65 <ck_pr_cas_uint>:
CK_PR_CAS_S(uint, unsigned int, "cmpxchgl")
   17d65:	55                   	push   %ebp
   17d66:	89 e5                	mov    %esp,%ebp
   17d68:	53                   	push   %ebx
   17d69:	83 ec 10             	sub    $0x10,%esp
   17d6c:	8b 55 08             	mov    0x8(%ebp),%edx
   17d6f:	8b 4d 10             	mov    0x10(%ebp),%ecx
   17d72:	8b 45 0c             	mov    0xc(%ebp),%eax
   17d75:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17d78:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   17d7c:	0f 94 c0             	sete   %al
   17d7f:	88 45 fb             	mov    %al,-0x5(%ebp)
   17d82:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   17d86:	83 c4 10             	add    $0x10,%esp
   17d89:	5b                   	pop    %ebx
   17d8a:	5d                   	pop    %ebp
   17d8b:	c3                   	ret    

00017d8c <ck_pr_cas_32>:
CK_PR_CAS_S(32, uint32_t, "cmpxchgl")
   17d8c:	55                   	push   %ebp
   17d8d:	89 e5                	mov    %esp,%ebp
   17d8f:	53                   	push   %ebx
   17d90:	83 ec 10             	sub    $0x10,%esp
   17d93:	8b 55 08             	mov    0x8(%ebp),%edx
   17d96:	8b 4d 10             	mov    0x10(%ebp),%ecx
   17d99:	8b 45 0c             	mov    0xc(%ebp),%eax
   17d9c:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17d9f:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   17da3:	0f 94 c0             	sete   %al
   17da6:	88 45 fb             	mov    %al,-0x5(%ebp)
   17da9:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   17dad:	83 c4 10             	add    $0x10,%esp
   17db0:	5b                   	pop    %ebx
   17db1:	5d                   	pop    %ebp
   17db2:	c3                   	ret    

00017db3 <ck_pr_cas_16>:
CK_PR_CAS_S(16, uint16_t, "cmpxchgw")
   17db3:	55                   	push   %ebp
   17db4:	89 e5                	mov    %esp,%ebp
   17db6:	53                   	push   %ebx
   17db7:	83 ec 18             	sub    $0x18,%esp
   17dba:	8b 55 0c             	mov    0xc(%ebp),%edx
   17dbd:	8b 45 10             	mov    0x10(%ebp),%eax
   17dc0:	66 89 55 e8          	mov    %dx,-0x18(%ebp)
   17dc4:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   17dc8:	8b 55 08             	mov    0x8(%ebp),%edx
   17dcb:	0f b7 4d e4          	movzwl -0x1c(%ebp),%ecx
   17dcf:	0f b7 45 e8          	movzwl -0x18(%ebp),%eax
   17dd3:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17dd6:	66 f0 0f b1 0a       	lock cmpxchg %cx,(%edx)
   17ddb:	0f 94 c0             	sete   %al
   17dde:	88 45 fb             	mov    %al,-0x5(%ebp)
   17de1:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   17de5:	83 c4 18             	add    $0x18,%esp
   17de8:	5b                   	pop    %ebx
   17de9:	5d                   	pop    %ebp
   17dea:	c3                   	ret    

00017deb <ck_pr_cas_8>:
CK_PR_CAS_S(8,  uint8_t,  "cmpxchgb")
   17deb:	55                   	push   %ebp
   17dec:	89 e5                	mov    %esp,%ebp
   17dee:	53                   	push   %ebx
   17def:	83 ec 18             	sub    $0x18,%esp
   17df2:	8b 55 0c             	mov    0xc(%ebp),%edx
   17df5:	8b 45 10             	mov    0x10(%ebp),%eax
   17df8:	88 55 e8             	mov    %dl,-0x18(%ebp)
   17dfb:	88 45 e4             	mov    %al,-0x1c(%ebp)
   17dfe:	8b 55 08             	mov    0x8(%ebp),%edx
   17e01:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   17e05:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   17e09:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17e0c:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   17e10:	0f 94 c0             	sete   %al
   17e13:	88 45 fb             	mov    %al,-0x5(%ebp)
   17e16:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   17e1a:	83 c4 18             	add    $0x18,%esp
   17e1d:	5b                   	pop    %ebx
   17e1e:	5d                   	pop    %ebp
   17e1f:	c3                   	ret    

00017e20 <ck_pr_cas_ptr_value>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return (bool)z;							\
	}

CK_PR_CAS_O(ptr, void, void *, char, "l", "eax")
   17e20:	55                   	push   %ebp
   17e21:	89 e5                	mov    %esp,%ebp
   17e23:	56                   	push   %esi
   17e24:	53                   	push   %ebx
   17e25:	83 ec 10             	sub    $0x10,%esp
   17e28:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17e2b:	8b 75 14             	mov    0x14(%ebp),%esi
   17e2e:	8b 55 10             	mov    0x10(%ebp),%edx
   17e31:	8b 45 0c             	mov    0xc(%ebp),%eax
   17e34:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17e37:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   17e3b:	89 06                	mov    %eax,(%esi)
   17e3d:	0f 94 c0             	sete   %al
   17e40:	88 45 f7             	mov    %al,-0x9(%ebp)
   17e43:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   17e47:	83 c4 10             	add    $0x10,%esp
   17e4a:	5b                   	pop    %ebx
   17e4b:	5e                   	pop    %esi
   17e4c:	5d                   	pop    %ebp
   17e4d:	c3                   	ret    

00017e4e <ck_pr_cas_char_value>:

#define CK_PR_CAS_O_S(S, T, I, R)	\
	CK_PR_CAS_O(S, T, T, T, I, R)

CK_PR_CAS_O_S(char, char, "b", "al")
   17e4e:	55                   	push   %ebp
   17e4f:	89 e5                	mov    %esp,%ebp
   17e51:	56                   	push   %esi
   17e52:	53                   	push   %ebx
   17e53:	83 ec 18             	sub    $0x18,%esp
   17e56:	8b 55 0c             	mov    0xc(%ebp),%edx
   17e59:	8b 45 10             	mov    0x10(%ebp),%eax
   17e5c:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   17e5f:	88 45 e0             	mov    %al,-0x20(%ebp)
   17e62:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17e65:	8b 75 14             	mov    0x14(%ebp),%esi
   17e68:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   17e6c:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   17e70:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17e73:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   17e77:	88 06                	mov    %al,(%esi)
   17e79:	0f 94 c0             	sete   %al
   17e7c:	88 45 f7             	mov    %al,-0x9(%ebp)
   17e7f:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   17e83:	83 c4 18             	add    $0x18,%esp
   17e86:	5b                   	pop    %ebx
   17e87:	5e                   	pop    %esi
   17e88:	5d                   	pop    %ebp
   17e89:	c3                   	ret    

00017e8a <ck_pr_cas_int_value>:
CK_PR_CAS_O_S(int, int, "l", "eax")
   17e8a:	55                   	push   %ebp
   17e8b:	89 e5                	mov    %esp,%ebp
   17e8d:	56                   	push   %esi
   17e8e:	53                   	push   %ebx
   17e8f:	83 ec 10             	sub    $0x10,%esp
   17e92:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17e95:	8b 75 14             	mov    0x14(%ebp),%esi
   17e98:	8b 55 10             	mov    0x10(%ebp),%edx
   17e9b:	8b 45 0c             	mov    0xc(%ebp),%eax
   17e9e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17ea1:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   17ea5:	89 06                	mov    %eax,(%esi)
   17ea7:	0f 94 c0             	sete   %al
   17eaa:	88 45 f7             	mov    %al,-0x9(%ebp)
   17ead:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   17eb1:	83 c4 10             	add    $0x10,%esp
   17eb4:	5b                   	pop    %ebx
   17eb5:	5e                   	pop    %esi
   17eb6:	5d                   	pop    %ebp
   17eb7:	c3                   	ret    

00017eb8 <ck_pr_cas_uint_value>:
CK_PR_CAS_O_S(uint, unsigned int, "l", "eax")
   17eb8:	55                   	push   %ebp
   17eb9:	89 e5                	mov    %esp,%ebp
   17ebb:	56                   	push   %esi
   17ebc:	53                   	push   %ebx
   17ebd:	83 ec 10             	sub    $0x10,%esp
   17ec0:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17ec3:	8b 75 14             	mov    0x14(%ebp),%esi
   17ec6:	8b 55 10             	mov    0x10(%ebp),%edx
   17ec9:	8b 45 0c             	mov    0xc(%ebp),%eax
   17ecc:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17ecf:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   17ed3:	89 06                	mov    %eax,(%esi)
   17ed5:	0f 94 c0             	sete   %al
   17ed8:	88 45 f7             	mov    %al,-0x9(%ebp)
   17edb:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   17edf:	83 c4 10             	add    $0x10,%esp
   17ee2:	5b                   	pop    %ebx
   17ee3:	5e                   	pop    %esi
   17ee4:	5d                   	pop    %ebp
   17ee5:	c3                   	ret    

00017ee6 <ck_pr_cas_32_value>:
CK_PR_CAS_O_S(32, uint32_t, "l", "eax")
   17ee6:	55                   	push   %ebp
   17ee7:	89 e5                	mov    %esp,%ebp
   17ee9:	56                   	push   %esi
   17eea:	53                   	push   %ebx
   17eeb:	83 ec 10             	sub    $0x10,%esp
   17eee:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17ef1:	8b 75 14             	mov    0x14(%ebp),%esi
   17ef4:	8b 55 10             	mov    0x10(%ebp),%edx
   17ef7:	8b 45 0c             	mov    0xc(%ebp),%eax
   17efa:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17efd:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   17f01:	89 06                	mov    %eax,(%esi)
   17f03:	0f 94 c0             	sete   %al
   17f06:	88 45 f7             	mov    %al,-0x9(%ebp)
   17f09:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   17f0d:	83 c4 10             	add    $0x10,%esp
   17f10:	5b                   	pop    %ebx
   17f11:	5e                   	pop    %esi
   17f12:	5d                   	pop    %ebp
   17f13:	c3                   	ret    

00017f14 <ck_pr_cas_16_value>:
CK_PR_CAS_O_S(16, uint16_t, "w", "ax")
   17f14:	55                   	push   %ebp
   17f15:	89 e5                	mov    %esp,%ebp
   17f17:	56                   	push   %esi
   17f18:	53                   	push   %ebx
   17f19:	83 ec 18             	sub    $0x18,%esp
   17f1c:	8b 55 0c             	mov    0xc(%ebp),%edx
   17f1f:	8b 45 10             	mov    0x10(%ebp),%eax
   17f22:	66 89 55 e4          	mov    %dx,-0x1c(%ebp)
   17f26:	66 89 45 e0          	mov    %ax,-0x20(%ebp)
   17f2a:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17f2d:	8b 75 14             	mov    0x14(%ebp),%esi
   17f30:	0f b7 55 e0          	movzwl -0x20(%ebp),%edx
   17f34:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
   17f38:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17f3b:	66 f0 0f b1 13       	lock cmpxchg %dx,(%ebx)
   17f40:	66 89 06             	mov    %ax,(%esi)
   17f43:	0f 94 c0             	sete   %al
   17f46:	88 45 f7             	mov    %al,-0x9(%ebp)
   17f49:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   17f4d:	83 c4 18             	add    $0x18,%esp
   17f50:	5b                   	pop    %ebx
   17f51:	5e                   	pop    %esi
   17f52:	5d                   	pop    %ebp
   17f53:	c3                   	ret    

00017f54 <ck_pr_cas_8_value>:
CK_PR_CAS_O_S(8,  uint8_t,  "b", "al")
   17f54:	55                   	push   %ebp
   17f55:	89 e5                	mov    %esp,%ebp
   17f57:	56                   	push   %esi
   17f58:	53                   	push   %ebx
   17f59:	83 ec 18             	sub    $0x18,%esp
   17f5c:	8b 55 0c             	mov    0xc(%ebp),%edx
   17f5f:	8b 45 10             	mov    0x10(%ebp),%eax
   17f62:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   17f65:	88 45 e0             	mov    %al,-0x20(%ebp)
   17f68:	8b 5d 08             	mov    0x8(%ebp),%ebx
   17f6b:	8b 75 14             	mov    0x14(%ebp),%esi
   17f6e:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   17f72:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   17f76:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17f79:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   17f7d:	88 06                	mov    %al,(%esi)
   17f7f:	0f 94 c0             	sete   %al
   17f82:	88 45 f7             	mov    %al,-0x9(%ebp)
   17f85:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   17f89:	83 c4 18             	add    $0x18,%esp
   17f8c:	5b                   	pop    %ebx
   17f8d:	5e                   	pop    %esi
   17f8e:	5d                   	pop    %ebp
   17f8f:	c3                   	ret    

00017f90 <ck_pr_btc_ptr>:
	CK_PR_BT_S(K, uint, unsigned int, #K "l %2, %0")	\
	CK_PR_BT_S(K, int, int, #K "l %2, %0")			\
	CK_PR_BT_S(K, 32, uint32_t, #K "l %2, %0")		\
	CK_PR_BT_S(K, 16, uint16_t, #K "w %w2, %0")

CK_PR_GENERATE(btc)
   17f90:	55                   	push   %ebp
   17f91:	89 e5                	mov    %esp,%ebp
   17f93:	83 ec 10             	sub    $0x10,%esp
   17f96:	8b 55 08             	mov    0x8(%ebp),%edx
   17f99:	8b 45 0c             	mov    0xc(%ebp),%eax
   17f9c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17f9f:	f0 0f bb 02          	lock btc %eax,(%edx)
   17fa3:	0f 92 c0             	setb   %al
   17fa6:	88 45 ff             	mov    %al,-0x1(%ebp)
   17fa9:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   17fad:	c9                   	leave  
   17fae:	c3                   	ret    

00017faf <ck_pr_btc_uint>:
   17faf:	55                   	push   %ebp
   17fb0:	89 e5                	mov    %esp,%ebp
   17fb2:	83 ec 10             	sub    $0x10,%esp
   17fb5:	8b 55 08             	mov    0x8(%ebp),%edx
   17fb8:	8b 45 0c             	mov    0xc(%ebp),%eax
   17fbb:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17fbe:	f0 0f bb 02          	lock btc %eax,(%edx)
   17fc2:	0f 92 c0             	setb   %al
   17fc5:	88 45 ff             	mov    %al,-0x1(%ebp)
   17fc8:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   17fcc:	c9                   	leave  
   17fcd:	c3                   	ret    

00017fce <ck_pr_btc_int>:
   17fce:	55                   	push   %ebp
   17fcf:	89 e5                	mov    %esp,%ebp
   17fd1:	83 ec 10             	sub    $0x10,%esp
   17fd4:	8b 45 0c             	mov    0xc(%ebp),%eax
   17fd7:	8b 55 08             	mov    0x8(%ebp),%edx
   17fda:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17fdd:	f0 0f bb 02          	lock btc %eax,(%edx)
   17fe1:	0f 92 c0             	setb   %al
   17fe4:	88 45 ff             	mov    %al,-0x1(%ebp)
   17fe7:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   17feb:	c9                   	leave  
   17fec:	c3                   	ret    

00017fed <ck_pr_btc_32>:
   17fed:	55                   	push   %ebp
   17fee:	89 e5                	mov    %esp,%ebp
   17ff0:	83 ec 10             	sub    $0x10,%esp
   17ff3:	8b 55 08             	mov    0x8(%ebp),%edx
   17ff6:	8b 45 0c             	mov    0xc(%ebp),%eax
   17ff9:	8b 4d 08             	mov    0x8(%ebp),%ecx
   17ffc:	f0 0f bb 02          	lock btc %eax,(%edx)
   18000:	0f 92 c0             	setb   %al
   18003:	88 45 ff             	mov    %al,-0x1(%ebp)
   18006:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1800a:	c9                   	leave  
   1800b:	c3                   	ret    

0001800c <ck_pr_btc_16>:
   1800c:	55                   	push   %ebp
   1800d:	89 e5                	mov    %esp,%ebp
   1800f:	83 ec 10             	sub    $0x10,%esp
   18012:	8b 45 0c             	mov    0xc(%ebp),%eax
   18015:	8b 55 08             	mov    0x8(%ebp),%edx
   18018:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1801b:	66 f0 0f bb 02       	lock btc %ax,(%edx)
   18020:	0f 92 c0             	setb   %al
   18023:	88 45 ff             	mov    %al,-0x1(%ebp)
   18026:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1802a:	c9                   	leave  
   1802b:	c3                   	ret    

0001802c <ck_pr_bts_ptr>:
CK_PR_GENERATE(bts)
   1802c:	55                   	push   %ebp
   1802d:	89 e5                	mov    %esp,%ebp
   1802f:	83 ec 10             	sub    $0x10,%esp
   18032:	8b 55 08             	mov    0x8(%ebp),%edx
   18035:	8b 45 0c             	mov    0xc(%ebp),%eax
   18038:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1803b:	f0 0f ab 02          	lock bts %eax,(%edx)
   1803f:	0f 92 c0             	setb   %al
   18042:	88 45 ff             	mov    %al,-0x1(%ebp)
   18045:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   18049:	c9                   	leave  
   1804a:	c3                   	ret    

0001804b <ck_pr_bts_uint>:
   1804b:	55                   	push   %ebp
   1804c:	89 e5                	mov    %esp,%ebp
   1804e:	83 ec 10             	sub    $0x10,%esp
   18051:	8b 55 08             	mov    0x8(%ebp),%edx
   18054:	8b 45 0c             	mov    0xc(%ebp),%eax
   18057:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1805a:	f0 0f ab 02          	lock bts %eax,(%edx)
   1805e:	0f 92 c0             	setb   %al
   18061:	88 45 ff             	mov    %al,-0x1(%ebp)
   18064:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   18068:	c9                   	leave  
   18069:	c3                   	ret    

0001806a <ck_pr_bts_int>:
   1806a:	55                   	push   %ebp
   1806b:	89 e5                	mov    %esp,%ebp
   1806d:	83 ec 10             	sub    $0x10,%esp
   18070:	8b 45 0c             	mov    0xc(%ebp),%eax
   18073:	8b 55 08             	mov    0x8(%ebp),%edx
   18076:	8b 4d 08             	mov    0x8(%ebp),%ecx
   18079:	f0 0f ab 02          	lock bts %eax,(%edx)
   1807d:	0f 92 c0             	setb   %al
   18080:	88 45 ff             	mov    %al,-0x1(%ebp)
   18083:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   18087:	c9                   	leave  
   18088:	c3                   	ret    

00018089 <ck_pr_bts_32>:
   18089:	55                   	push   %ebp
   1808a:	89 e5                	mov    %esp,%ebp
   1808c:	83 ec 10             	sub    $0x10,%esp
   1808f:	8b 55 08             	mov    0x8(%ebp),%edx
   18092:	8b 45 0c             	mov    0xc(%ebp),%eax
   18095:	8b 4d 08             	mov    0x8(%ebp),%ecx
   18098:	f0 0f ab 02          	lock bts %eax,(%edx)
   1809c:	0f 92 c0             	setb   %al
   1809f:	88 45 ff             	mov    %al,-0x1(%ebp)
   180a2:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   180a6:	c9                   	leave  
   180a7:	c3                   	ret    

000180a8 <ck_pr_bts_16>:
   180a8:	55                   	push   %ebp
   180a9:	89 e5                	mov    %esp,%ebp
   180ab:	83 ec 10             	sub    $0x10,%esp
   180ae:	8b 45 0c             	mov    0xc(%ebp),%eax
   180b1:	8b 55 08             	mov    0x8(%ebp),%edx
   180b4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   180b7:	66 f0 0f ab 02       	lock bts %ax,(%edx)
   180bc:	0f 92 c0             	setb   %al
   180bf:	88 45 ff             	mov    %al,-0x1(%ebp)
   180c2:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   180c6:	c9                   	leave  
   180c7:	c3                   	ret    

000180c8 <ck_pr_btr_ptr>:
CK_PR_GENERATE(btr)
   180c8:	55                   	push   %ebp
   180c9:	89 e5                	mov    %esp,%ebp
   180cb:	83 ec 10             	sub    $0x10,%esp
   180ce:	8b 55 08             	mov    0x8(%ebp),%edx
   180d1:	8b 45 0c             	mov    0xc(%ebp),%eax
   180d4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   180d7:	f0 0f b3 02          	lock btr %eax,(%edx)
   180db:	0f 92 c0             	setb   %al
   180de:	88 45 ff             	mov    %al,-0x1(%ebp)
   180e1:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   180e5:	c9                   	leave  
   180e6:	c3                   	ret    

000180e7 <ck_pr_btr_uint>:
   180e7:	55                   	push   %ebp
   180e8:	89 e5                	mov    %esp,%ebp
   180ea:	83 ec 10             	sub    $0x10,%esp
   180ed:	8b 55 08             	mov    0x8(%ebp),%edx
   180f0:	8b 45 0c             	mov    0xc(%ebp),%eax
   180f3:	8b 4d 08             	mov    0x8(%ebp),%ecx
   180f6:	f0 0f b3 02          	lock btr %eax,(%edx)
   180fa:	0f 92 c0             	setb   %al
   180fd:	88 45 ff             	mov    %al,-0x1(%ebp)
   18100:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   18104:	c9                   	leave  
   18105:	c3                   	ret    

00018106 <ck_pr_btr_int>:
   18106:	55                   	push   %ebp
   18107:	89 e5                	mov    %esp,%ebp
   18109:	83 ec 10             	sub    $0x10,%esp
   1810c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1810f:	8b 55 08             	mov    0x8(%ebp),%edx
   18112:	8b 4d 08             	mov    0x8(%ebp),%ecx
   18115:	f0 0f b3 02          	lock btr %eax,(%edx)
   18119:	0f 92 c0             	setb   %al
   1811c:	88 45 ff             	mov    %al,-0x1(%ebp)
   1811f:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   18123:	c9                   	leave  
   18124:	c3                   	ret    

00018125 <ck_pr_btr_32>:
   18125:	55                   	push   %ebp
   18126:	89 e5                	mov    %esp,%ebp
   18128:	83 ec 10             	sub    $0x10,%esp
   1812b:	8b 55 08             	mov    0x8(%ebp),%edx
   1812e:	8b 45 0c             	mov    0xc(%ebp),%eax
   18131:	8b 4d 08             	mov    0x8(%ebp),%ecx
   18134:	f0 0f b3 02          	lock btr %eax,(%edx)
   18138:	0f 92 c0             	setb   %al
   1813b:	88 45 ff             	mov    %al,-0x1(%ebp)
   1813e:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   18142:	c9                   	leave  
   18143:	c3                   	ret    

00018144 <ck_pr_btr_16>:
   18144:	55                   	push   %ebp
   18145:	89 e5                	mov    %esp,%ebp
   18147:	83 ec 10             	sub    $0x10,%esp
   1814a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1814d:	8b 55 08             	mov    0x8(%ebp),%edx
   18150:	8b 4d 08             	mov    0x8(%ebp),%ecx
   18153:	66 f0 0f b3 02       	lock btr %ax,(%edx)
   18158:	0f 92 c0             	setb   %al
   1815b:	88 45 ff             	mov    %al,-0x1(%ebp)
   1815e:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   18162:	c9                   	leave  
   18163:	c3                   	ret    

00018164 <ck_pr_barrier>:

#include <ck_cc.h>

CK_CC_INLINE static void
ck_pr_barrier(void)
{
   18164:	55                   	push   %ebp
   18165:	89 e5                	mov    %esp,%ebp

	__asm__ __volatile__("" ::: "memory");
	return;
   18167:	90                   	nop
}
   18168:	5d                   	pop    %ebp
   18169:	c3                   	ret    

0001816a <ck_pr_fence_load_depends>:

/*
 * None of the currently supported platforms allow for data-dependent
 * load ordering.
 */
CK_PR_FENCE_NOOP(load_depends)
   1816a:	55                   	push   %ebp
   1816b:	89 e5                	mov    %esp,%ebp
   1816d:	e8 f2 ff ff ff       	call   18164 <ck_pr_barrier>
   18172:	90                   	nop
   18173:	5d                   	pop    %ebp
   18174:	c3                   	ret    

00018175 <ck_pr_fence_atomic>:
#elif defined(CK_MD_TSO)
/*
 * Only loads are re-ordered and only with respect to
 * prior stores. Atomic operations are serializing.
 */
CK_PR_FENCE_NOOP(atomic)
   18175:	55                   	push   %ebp
   18176:	89 e5                	mov    %esp,%ebp
   18178:	e8 e7 ff ff ff       	call   18164 <ck_pr_barrier>
   1817d:	90                   	nop
   1817e:	5d                   	pop    %ebp
   1817f:	c3                   	ret    

00018180 <ck_pr_fence_atomic_load>:
CK_PR_FENCE_NOOP(atomic_load)
   18180:	55                   	push   %ebp
   18181:	89 e5                	mov    %esp,%ebp
   18183:	e8 dc ff ff ff       	call   18164 <ck_pr_barrier>
   18188:	90                   	nop
   18189:	5d                   	pop    %ebp
   1818a:	c3                   	ret    

0001818b <ck_pr_fence_atomic_store>:
CK_PR_FENCE_NOOP(atomic_store)
   1818b:	55                   	push   %ebp
   1818c:	89 e5                	mov    %esp,%ebp
   1818e:	e8 d1 ff ff ff       	call   18164 <ck_pr_barrier>
   18193:	90                   	nop
   18194:	5d                   	pop    %ebp
   18195:	c3                   	ret    

00018196 <ck_pr_fence_store_atomic>:
CK_PR_FENCE_NOOP(store_atomic)
   18196:	55                   	push   %ebp
   18197:	89 e5                	mov    %esp,%ebp
   18199:	e8 c6 ff ff ff       	call   18164 <ck_pr_barrier>
   1819e:	90                   	nop
   1819f:	5d                   	pop    %ebp
   181a0:	c3                   	ret    

000181a1 <ck_pr_fence_load_atomic>:
CK_PR_FENCE_NOOP(load_atomic)
   181a1:	55                   	push   %ebp
   181a2:	89 e5                	mov    %esp,%ebp
   181a4:	e8 bb ff ff ff       	call   18164 <ck_pr_barrier>
   181a9:	90                   	nop
   181aa:	5d                   	pop    %ebp
   181ab:	c3                   	ret    

000181ac <ck_pr_fence_load_store>:
CK_PR_FENCE_NOOP(load_store)
   181ac:	55                   	push   %ebp
   181ad:	89 e5                	mov    %esp,%ebp
   181af:	e8 b0 ff ff ff       	call   18164 <ck_pr_barrier>
   181b4:	90                   	nop
   181b5:	5d                   	pop    %ebp
   181b6:	c3                   	ret    

000181b7 <ck_pr_fence_store_load>:
CK_PR_FENCE_EMIT(store_load)
   181b7:	55                   	push   %ebp
   181b8:	89 e5                	mov    %esp,%ebp
   181ba:	e8 d4 f1 ff ff       	call   17393 <ck_pr_fence_strict_store_load>
   181bf:	90                   	nop
   181c0:	5d                   	pop    %ebp
   181c1:	c3                   	ret    

000181c2 <ck_pr_fence_load>:
CK_PR_FENCE_NOOP(load)
   181c2:	55                   	push   %ebp
   181c3:	89 e5                	mov    %esp,%ebp
   181c5:	e8 9a ff ff ff       	call   18164 <ck_pr_barrier>
   181ca:	90                   	nop
   181cb:	5d                   	pop    %ebp
   181cc:	c3                   	ret    

000181cd <ck_pr_fence_store>:
CK_PR_FENCE_NOOP(store)
   181cd:	55                   	push   %ebp
   181ce:	89 e5                	mov    %esp,%ebp
   181d0:	e8 8f ff ff ff       	call   18164 <ck_pr_barrier>
   181d5:	90                   	nop
   181d6:	5d                   	pop    %ebp
   181d7:	c3                   	ret    

000181d8 <ck_pr_fence_memory>:
CK_PR_FENCE_EMIT(memory)
   181d8:	55                   	push   %ebp
   181d9:	89 e5                	mov    %esp,%ebp
   181db:	e8 bc f1 ff ff       	call   1739c <ck_pr_fence_strict_memory>
   181e0:	90                   	nop
   181e1:	5d                   	pop    %ebp
   181e2:	c3                   	ret    

000181e3 <ck_pr_fence_acquire>:
CK_PR_FENCE_NOOP(acquire)
   181e3:	55                   	push   %ebp
   181e4:	89 e5                	mov    %esp,%ebp
   181e6:	e8 79 ff ff ff       	call   18164 <ck_pr_barrier>
   181eb:	90                   	nop
   181ec:	5d                   	pop    %ebp
   181ed:	c3                   	ret    

000181ee <ck_pr_fence_release>:
CK_PR_FENCE_NOOP(release)
   181ee:	55                   	push   %ebp
   181ef:	89 e5                	mov    %esp,%ebp
   181f1:	e8 6e ff ff ff       	call   18164 <ck_pr_barrier>
   181f6:	90                   	nop
   181f7:	5d                   	pop    %ebp
   181f8:	c3                   	ret    

000181f9 <ck_pr_fence_acqrel>:
CK_PR_FENCE_NOOP(acqrel)
   181f9:	55                   	push   %ebp
   181fa:	89 e5                	mov    %esp,%ebp
   181fc:	e8 63 ff ff ff       	call   18164 <ck_pr_barrier>
   18201:	90                   	nop
   18202:	5d                   	pop    %ebp
   18203:	c3                   	ret    

00018204 <ck_pr_fence_lock>:
CK_PR_FENCE_NOOP(lock)
   18204:	55                   	push   %ebp
   18205:	89 e5                	mov    %esp,%ebp
   18207:	e8 58 ff ff ff       	call   18164 <ck_pr_barrier>
   1820c:	90                   	nop
   1820d:	5d                   	pop    %ebp
   1820e:	c3                   	ret    

0001820f <ck_pr_fence_unlock>:
CK_PR_FENCE_NOOP(unlock)
   1820f:	55                   	push   %ebp
   18210:	89 e5                	mov    %esp,%ebp
   18212:	e8 4d ff ff ff       	call   18164 <ck_pr_barrier>
   18217:	90                   	nop
   18218:	5d                   	pop    %ebp
   18219:	c3                   	ret    

0001821a <ck_pr_rfo>:

#ifndef CK_F_PR_RFO
#define CK_F_PR_RFO
CK_CC_INLINE static void
ck_pr_rfo(const void *m)
{
   1821a:	55                   	push   %ebp
   1821b:	89 e5                	mov    %esp,%ebp

	(void)m;
	return;
   1821d:	90                   	nop
}
   1821e:	5d                   	pop    %ebp
   1821f:	c3                   	ret    

00018220 <ck_ring_size>:
};
typedef struct ck_ring_buffer ck_ring_buffer_t;

CK_CC_INLINE static unsigned int
ck_ring_size(const struct ck_ring *ring)
{
   18220:	55                   	push   %ebp
   18221:	89 e5                	mov    %esp,%ebp
   18223:	83 ec 14             	sub    $0x14,%esp
	unsigned int c, p;

	c = ck_pr_load_uint(&ring->c_head);
   18226:	8b 45 08             	mov    0x8(%ebp),%eax
   18229:	89 04 24             	mov    %eax,(%esp)
   1822c:	e8 86 f2 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18231:	89 45 fc             	mov    %eax,-0x4(%ebp)
	p = ck_pr_load_uint(&ring->p_tail);
   18234:	8b 45 08             	mov    0x8(%ebp),%eax
   18237:	83 c0 40             	add    $0x40,%eax
   1823a:	89 04 24             	mov    %eax,(%esp)
   1823d:	e8 75 f2 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18242:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return (p - c) & ring->mask;
   18245:	8b 45 fc             	mov    -0x4(%ebp),%eax
   18248:	8b 55 f8             	mov    -0x8(%ebp),%edx
   1824b:	29 c2                	sub    %eax,%edx
   1824d:	8b 45 08             	mov    0x8(%ebp),%eax
   18250:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18256:	21 d0                	and    %edx,%eax
}
   18258:	c9                   	leave  
   18259:	c3                   	ret    

0001825a <ck_ring_capacity>:

CK_CC_INLINE static unsigned int
ck_ring_capacity(const struct ck_ring *ring)
{
   1825a:	55                   	push   %ebp
   1825b:	89 e5                	mov    %esp,%ebp
	return ring->size;
   1825d:	8b 45 08             	mov    0x8(%ebp),%eax
   18260:	8b 80 80 00 00 00    	mov    0x80(%eax),%eax
}
   18266:	5d                   	pop    %ebp
   18267:	c3                   	ret    

00018268 <ck_ring_init>:

CK_CC_INLINE static void
ck_ring_init(struct ck_ring *ring, unsigned int size)
{
   18268:	55                   	push   %ebp
   18269:	89 e5                	mov    %esp,%ebp

	ring->size = size;
   1826b:	8b 45 08             	mov    0x8(%ebp),%eax
   1826e:	8b 55 0c             	mov    0xc(%ebp),%edx
   18271:	89 90 80 00 00 00    	mov    %edx,0x80(%eax)
	ring->mask = size - 1;
   18277:	8b 45 0c             	mov    0xc(%ebp),%eax
   1827a:	8d 50 ff             	lea    -0x1(%eax),%edx
   1827d:	8b 45 08             	mov    0x8(%ebp),%eax
   18280:	89 90 84 00 00 00    	mov    %edx,0x84(%eax)
	ring->p_tail = 0;
   18286:	8b 45 08             	mov    0x8(%ebp),%eax
   18289:	c7 40 40 00 00 00 00 	movl   $0x0,0x40(%eax)
	ring->p_head = 0;
   18290:	8b 45 08             	mov    0x8(%ebp),%eax
   18293:	c7 40 44 00 00 00 00 	movl   $0x0,0x44(%eax)
	ring->c_head = 0;
   1829a:	8b 45 08             	mov    0x8(%ebp),%eax
   1829d:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
	return;
   182a3:	90                   	nop
}
   182a4:	5d                   	pop    %ebp
   182a5:	c3                   	ret    

000182a6 <ck_ring_enqueue_spsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   182a6:	55                   	push   %ebp
   182a7:	89 e5                	mov    %esp,%ebp
   182a9:	83 ec 58             	sub    $0x58,%esp
   182ac:	8b 45 08             	mov    0x8(%ebp),%eax
   182af:	89 45 f4             	mov    %eax,-0xc(%ebp)
   182b2:	8b 45 0c             	mov    0xc(%ebp),%eax
   182b5:	89 45 f0             	mov    %eax,-0x10(%ebp)
   182b8:	8d 45 10             	lea    0x10(%ebp),%eax
   182bb:	89 45 ec             	mov    %eax,-0x14(%ebp)
   182be:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   182c5:	8b 45 14             	mov    0x14(%ebp),%eax
   182c8:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   182cb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   182ce:	89 45 e0             	mov    %eax,-0x20(%ebp)
   182d1:	8b 45 f0             	mov    -0x10(%ebp),%eax
   182d4:	89 45 dc             	mov    %eax,-0x24(%ebp)
   182d7:	8b 45 ec             	mov    -0x14(%ebp),%eax
   182da:	89 45 d8             	mov    %eax,-0x28(%ebp)
   182dd:	8b 45 e8             	mov    -0x18(%ebp),%eax
   182e0:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   182e3:	8d 45 b8             	lea    -0x48(%ebp),%eax
   182e6:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   182e9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   182ec:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   182f2:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   182f5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   182f8:	89 04 24             	mov    %eax,(%esp)
   182fb:	e8 b7 f1 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18300:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   18303:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18306:	8b 40 40             	mov    0x40(%eax),%eax
   18309:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1830c:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1830f:	83 c0 01             	add    $0x1,%eax
   18312:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   18315:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   18319:	74 14                	je     1832f <ck_ring_enqueue_spsc_size+0x89>
		*size = (producer - consumer) & mask;
   1831b:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1831e:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   18321:	29 c2                	sub    %eax,%edx
   18323:	89 d0                	mov    %edx,%eax
   18325:	23 45 cc             	and    -0x34(%ebp),%eax
   18328:	89 c2                	mov    %eax,%edx
   1832a:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1832d:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1832f:	8b 45 c0             	mov    -0x40(%ebp),%eax
   18332:	8b 55 c8             	mov    -0x38(%ebp),%edx
   18335:	31 d0                	xor    %edx,%eax
   18337:	23 45 cc             	and    -0x34(%ebp),%eax
   1833a:	85 c0                	test   %eax,%eax
   1833c:	0f 94 c0             	sete   %al
   1833f:	0f b6 c0             	movzbl %al,%eax
   18342:	85 c0                	test   %eax,%eax
   18344:	74 07                	je     1834d <ck_ring_enqueue_spsc_size+0xa7>
		return false;
   18346:	b8 00 00 00 00       	mov    $0x0,%eax
   1834b:	eb 47                	jmp    18394 <ck_ring_enqueue_spsc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1834d:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   18350:	8b 55 cc             	mov    -0x34(%ebp),%edx
   18353:	21 d0                	and    %edx,%eax
   18355:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   18359:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1835c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1835f:	89 44 24 08          	mov    %eax,0x8(%esp)
   18363:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18366:	89 44 24 04          	mov    %eax,0x4(%esp)
   1836a:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1836d:	89 04 24             	mov    %eax,(%esp)
   18370:	e8 fc ff ff ff       	call   18371 <ck_ring_enqueue_spsc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   18375:	e8 53 fe ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1837a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1837d:	8d 50 40             	lea    0x40(%eax),%edx
   18380:	8b 45 c0             	mov    -0x40(%ebp),%eax
   18383:	89 44 24 04          	mov    %eax,0x4(%esp)
   18387:	89 14 24             	mov    %edx,(%esp)
   1838a:	e8 b1 f1 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   1838f:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   18394:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   18397:	8b 55 b8             	mov    -0x48(%ebp),%edx
   1839a:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1839d:	89 10                	mov    %edx,(%eax)
	return r;
   1839f:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   183a3:	c9                   	leave  
   183a4:	c3                   	ret    

000183a5 <ck_ring_enqueue_spsc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   183a5:	55                   	push   %ebp
   183a6:	89 e5                	mov    %esp,%ebp
   183a8:	83 ec 48             	sub    $0x48,%esp
   183ab:	8b 45 08             	mov    0x8(%ebp),%eax
   183ae:	89 45 f4             	mov    %eax,-0xc(%ebp)
   183b1:	8b 45 0c             	mov    0xc(%ebp),%eax
   183b4:	89 45 f0             	mov    %eax,-0x10(%ebp)
   183b7:	8d 45 10             	lea    0x10(%ebp),%eax
   183ba:	89 45 ec             	mov    %eax,-0x14(%ebp)
   183bd:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   183c4:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   183cb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   183ce:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   183d4:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   183d7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   183da:	89 04 24             	mov    %eax,(%esp)
   183dd:	e8 d5 f0 ff ff       	call   174b7 <ck_pr_md_load_uint>
   183e2:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   183e5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   183e8:	8b 40 40             	mov    0x40(%eax),%eax
   183eb:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   183ee:	8b 45 d8             	mov    -0x28(%ebp),%eax
   183f1:	83 c0 01             	add    $0x1,%eax
   183f4:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   183f7:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   183fb:	74 14                	je     18411 <ck_ring_enqueue_spsc+0x6c>
		*size = (producer - consumer) & mask;
   183fd:	8b 45 dc             	mov    -0x24(%ebp),%eax
   18400:	8b 55 d8             	mov    -0x28(%ebp),%edx
   18403:	29 c2                	sub    %eax,%edx
   18405:	89 d0                	mov    %edx,%eax
   18407:	23 45 e0             	and    -0x20(%ebp),%eax
   1840a:	89 c2                	mov    %eax,%edx
   1840c:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1840f:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   18411:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   18414:	8b 55 dc             	mov    -0x24(%ebp),%edx
   18417:	31 d0                	xor    %edx,%eax
   18419:	23 45 e0             	and    -0x20(%ebp),%eax
   1841c:	85 c0                	test   %eax,%eax
   1841e:	0f 94 c0             	sete   %al
   18421:	0f b6 c0             	movzbl %al,%eax
   18424:	85 c0                	test   %eax,%eax
   18426:	74 07                	je     1842f <ck_ring_enqueue_spsc+0x8a>
		return false;
   18428:	b8 00 00 00 00       	mov    $0x0,%eax
   1842d:	eb 47                	jmp    18476 <ck_ring_enqueue_spsc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1842f:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18432:	8b 55 e0             	mov    -0x20(%ebp),%edx
   18435:	21 d0                	and    %edx,%eax
   18437:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1843b:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1843e:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18441:	89 44 24 08          	mov    %eax,0x8(%esp)
   18445:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18448:	89 44 24 04          	mov    %eax,0x4(%esp)
   1844c:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1844f:	89 04 24             	mov    %eax,(%esp)
   18452:	e8 fc ff ff ff       	call   18453 <ck_ring_enqueue_spsc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   18457:	e8 71 fd ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1845c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1845f:	8d 50 40             	lea    0x40(%eax),%edx
   18462:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   18465:	89 44 24 04          	mov    %eax,0x4(%esp)
   18469:	89 14 24             	mov    %edx,(%esp)
   1846c:	e8 cf f0 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   18471:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer,
	    &entry, sizeof(entry), NULL);
}
   18476:	c9                   	leave  
   18477:	c3                   	ret    

00018478 <ck_ring_dequeue_spsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   18478:	55                   	push   %ebp
   18479:	89 e5                	mov    %esp,%ebp
   1847b:	83 ec 38             	sub    $0x38,%esp
   1847e:	8b 45 08             	mov    0x8(%ebp),%eax
   18481:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18484:	8b 45 0c             	mov    0xc(%ebp),%eax
   18487:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1848a:	8b 45 10             	mov    0x10(%ebp),%eax
   1848d:	89 45 ec             	mov    %eax,-0x14(%ebp)
   18490:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   18497:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1849a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   184a0:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   184a3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   184a6:	8b 00                	mov    (%eax),%eax
   184a8:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   184ab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   184ae:	83 c0 40             	add    $0x40,%eax
   184b1:	89 04 24             	mov    %eax,(%esp)
   184b4:	e8 fe ef ff ff       	call   174b7 <ck_pr_md_load_uint>
   184b9:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   184bc:	8b 45 e0             	mov    -0x20(%ebp),%eax
   184bf:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   184c2:	0f 94 c0             	sete   %al
   184c5:	0f b6 c0             	movzbl %al,%eax
   184c8:	85 c0                	test   %eax,%eax
   184ca:	74 07                	je     184d3 <ck_ring_dequeue_spsc+0x5b>
		return false;
   184cc:	b8 00 00 00 00       	mov    $0x0,%eax
   184d1:	eb 4c                	jmp    1851f <ck_ring_dequeue_spsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   184d3:	e8 ea fc ff ff       	call   181c2 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   184d8:	8b 45 e0             	mov    -0x20(%ebp),%eax
   184db:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   184de:	21 d0                	and    %edx,%eax
   184e0:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   184e4:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   184e7:	8b 45 e8             	mov    -0x18(%ebp),%eax
   184ea:	89 44 24 08          	mov    %eax,0x8(%esp)
   184ee:	8b 45 f0             	mov    -0x10(%ebp),%eax
   184f1:	89 44 24 04          	mov    %eax,0x4(%esp)
   184f5:	8b 45 ec             	mov    -0x14(%ebp),%eax
   184f8:	89 04 24             	mov    %eax,(%esp)
   184fb:	e8 fc ff ff ff       	call   184fc <ck_ring_dequeue_spsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   18500:	e8 c8 fc ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   18505:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18508:	8d 50 01             	lea    0x1(%eax),%edx
   1850b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1850e:	89 54 24 04          	mov    %edx,0x4(%esp)
   18512:	89 04 24             	mov    %eax,(%esp)
   18515:	e8 26 f0 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   1851a:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer,
	    (void **)data, sizeof(void *));
}
   1851f:	c9                   	leave  
   18520:	c3                   	ret    

00018521 <ck_ring_enqueue_mpmc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   18521:	55                   	push   %ebp
   18522:	89 e5                	mov    %esp,%ebp
   18524:	83 ec 48             	sub    $0x48,%esp
   18527:	8b 45 08             	mov    0x8(%ebp),%eax
   1852a:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1852d:	8b 45 0c             	mov    0xc(%ebp),%eax
   18530:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18533:	8d 45 10             	lea    0x10(%ebp),%eax
   18536:	89 45 ec             	mov    %eax,-0x14(%ebp)
   18539:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   18540:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   18547:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1854a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18550:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   18553:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   18557:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1855a:	83 c0 44             	add    $0x44,%eax
   1855d:	89 04 24             	mov    %eax,(%esp)
   18560:	e8 52 ef ff ff       	call   174b7 <ck_pr_md_load_uint>
   18565:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   18568:	e8 55 fc ff ff       	call   181c2 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1856d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18570:	89 04 24             	mov    %eax,(%esp)
   18573:	e8 3f ef ff ff       	call   174b7 <ck_pr_md_load_uint>
   18578:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1857b:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1857e:	83 c0 01             	add    $0x1,%eax
   18581:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   18584:	8b 45 cc             	mov    -0x34(%ebp),%eax
   18587:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1858a:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1858d:	0f 97 c0             	seta   %al
   18590:	0f b6 c0             	movzbl %al,%eax
   18593:	85 c0                	test   %eax,%eax
   18595:	74 29                	je     185c0 <ck_ring_enqueue_mpmc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   18597:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1859a:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1859d:	8d 4a 44             	lea    0x44(%edx),%ecx
   185a0:	8d 55 cc             	lea    -0x34(%ebp),%edx
   185a3:	89 54 24 0c          	mov    %edx,0xc(%esp)
   185a7:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   185aa:	89 54 24 08          	mov    %edx,0x8(%esp)
   185ae:	89 44 24 04          	mov    %eax,0x4(%esp)
   185b2:	89 0c 24             	mov    %ecx,(%esp)
   185b5:	e8 fe f8 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
   185ba:	84 c0                	test   %al,%al
   185bc:	75 31                	jne    185ef <ck_ring_enqueue_mpmc+0xce>
   185be:	eb a8                	jmp    18568 <ck_ring_enqueue_mpmc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   185c0:	e8 fd fb ff ff       	call   181c2 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   185c5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   185c8:	83 c0 44             	add    $0x44,%eax
   185cb:	89 04 24             	mov    %eax,(%esp)
   185ce:	e8 e4 ee ff ff       	call   174b7 <ck_pr_md_load_uint>
   185d3:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   185d6:	8b 45 cc             	mov    -0x34(%ebp),%eax
   185d9:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   185dc:	75 06                	jne    185e4 <ck_ring_enqueue_mpmc+0xc3>
				r = false;
   185de:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   185e2:	eb 67                	jmp    1864b <ck_ring_enqueue_mpmc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   185e4:	8b 45 d0             	mov    -0x30(%ebp),%eax
   185e7:	89 45 cc             	mov    %eax,-0x34(%ebp)
   185ea:	e9 79 ff ff ff       	jmp    18568 <ck_ring_enqueue_mpmc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   185ef:	8b 45 cc             	mov    -0x34(%ebp),%eax
   185f2:	23 45 e0             	and    -0x20(%ebp),%eax
   185f5:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   185f9:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   185fc:	8b 45 e8             	mov    -0x18(%ebp),%eax
   185ff:	89 44 24 08          	mov    %eax,0x8(%esp)
   18603:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18606:	89 44 24 04          	mov    %eax,0x4(%esp)
   1860a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1860d:	89 04 24             	mov    %eax,(%esp)
   18610:	e8 fc ff ff ff       	call   18611 <ck_ring_enqueue_mpmc+0xf0>
   18615:	eb 05                	jmp    1861c <ck_ring_enqueue_mpmc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   18617:	e8 36 ed ff ff       	call   17352 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1861c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1861f:	83 c0 40             	add    $0x40,%eax
   18622:	89 04 24             	mov    %eax,(%esp)
   18625:	e8 8d ee ff ff       	call   174b7 <ck_pr_md_load_uint>
   1862a:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1862d:	39 d0                	cmp    %edx,%eax
   1862f:	75 e6                	jne    18617 <ck_ring_enqueue_mpmc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   18631:	e8 97 fb ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   18636:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18639:	8d 50 40             	lea    0x40(%eax),%edx
   1863c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1863f:	89 44 24 04          	mov    %eax,0x4(%esp)
   18643:	89 14 24             	mov    %edx,(%esp)
   18646:	e8 f5 ee ff ff       	call   17540 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1864b:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1864f:	74 10                	je     18661 <ck_ring_enqueue_mpmc+0x140>
		*size = (producer - consumer) & mask;
   18651:	8b 45 cc             	mov    -0x34(%ebp),%eax
   18654:	2b 45 d8             	sub    -0x28(%ebp),%eax
   18657:	23 45 e0             	and    -0x20(%ebp),%eax
   1865a:	89 c2                	mov    %eax,%edx
   1865c:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1865f:	89 10                	mov    %edx,(%eax)

	return r;
   18661:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   18665:	c9                   	leave  
   18666:	c3                   	ret    

00018667 <ck_ring_enqueue_mpmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   18667:	55                   	push   %ebp
   18668:	89 e5                	mov    %esp,%ebp
   1866a:	83 ec 68             	sub    $0x68,%esp
   1866d:	8b 45 08             	mov    0x8(%ebp),%eax
   18670:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18673:	8b 45 0c             	mov    0xc(%ebp),%eax
   18676:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18679:	8d 45 10             	lea    0x10(%ebp),%eax
   1867c:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1867f:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   18686:	8b 45 14             	mov    0x14(%ebp),%eax
   18689:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1868c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1868f:	89 45 e0             	mov    %eax,-0x20(%ebp)
   18692:	8b 45 f0             	mov    -0x10(%ebp),%eax
   18695:	89 45 dc             	mov    %eax,-0x24(%ebp)
   18698:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1869b:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1869e:	8b 45 e8             	mov    -0x18(%ebp),%eax
   186a1:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   186a4:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   186a7:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   186aa:	8b 45 e0             	mov    -0x20(%ebp),%eax
   186ad:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   186b3:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   186b6:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   186ba:	8b 45 e0             	mov    -0x20(%ebp),%eax
   186bd:	83 c0 44             	add    $0x44,%eax
   186c0:	89 04 24             	mov    %eax,(%esp)
   186c3:	e8 ef ed ff ff       	call   174b7 <ck_pr_md_load_uint>
   186c8:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   186cb:	e8 f2 fa ff ff       	call   181c2 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   186d0:	8b 45 e0             	mov    -0x20(%ebp),%eax
   186d3:	89 04 24             	mov    %eax,(%esp)
   186d6:	e8 dc ed ff ff       	call   174b7 <ck_pr_md_load_uint>
   186db:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   186de:	8b 45 b0             	mov    -0x50(%ebp),%eax
   186e1:	83 c0 01             	add    $0x1,%eax
   186e4:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   186e7:	8b 45 b0             	mov    -0x50(%ebp),%eax
   186ea:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   186ed:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   186f0:	0f 97 c0             	seta   %al
   186f3:	0f b6 c0             	movzbl %al,%eax
   186f6:	85 c0                	test   %eax,%eax
   186f8:	74 29                	je     18723 <ck_ring_enqueue_mpmc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   186fa:	8b 45 b0             	mov    -0x50(%ebp),%eax
   186fd:	8b 55 e0             	mov    -0x20(%ebp),%edx
   18700:	8d 4a 44             	lea    0x44(%edx),%ecx
   18703:	8d 55 b0             	lea    -0x50(%ebp),%edx
   18706:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1870a:	8b 55 c0             	mov    -0x40(%ebp),%edx
   1870d:	89 54 24 08          	mov    %edx,0x8(%esp)
   18711:	89 44 24 04          	mov    %eax,0x4(%esp)
   18715:	89 0c 24             	mov    %ecx,(%esp)
   18718:	e8 9b f7 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
   1871d:	84 c0                	test   %al,%al
   1871f:	75 31                	jne    18752 <ck_ring_enqueue_mpmc_size+0xeb>
   18721:	eb a8                	jmp    186cb <ck_ring_enqueue_mpmc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   18723:	e8 9a fa ff ff       	call   181c2 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   18728:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1872b:	83 c0 44             	add    $0x44,%eax
   1872e:	89 04 24             	mov    %eax,(%esp)
   18731:	e8 81 ed ff ff       	call   174b7 <ck_pr_md_load_uint>
   18736:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   18739:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1873c:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   1873f:	75 06                	jne    18747 <ck_ring_enqueue_mpmc_size+0xe0>
				r = false;
   18741:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   18745:	eb 67                	jmp    187ae <ck_ring_enqueue_mpmc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   18747:	8b 45 bc             	mov    -0x44(%ebp),%eax
   1874a:	89 45 b0             	mov    %eax,-0x50(%ebp)
   1874d:	e9 79 ff ff ff       	jmp    186cb <ck_ring_enqueue_mpmc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   18752:	8b 45 b0             	mov    -0x50(%ebp),%eax
   18755:	23 45 cc             	and    -0x34(%ebp),%eax
   18758:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1875c:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1875f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   18762:	89 44 24 08          	mov    %eax,0x8(%esp)
   18766:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18769:	89 44 24 04          	mov    %eax,0x4(%esp)
   1876d:	8b 45 dc             	mov    -0x24(%ebp),%eax
   18770:	89 04 24             	mov    %eax,(%esp)
   18773:	e8 fc ff ff ff       	call   18774 <ck_ring_enqueue_mpmc_size+0x10d>
   18778:	eb 05                	jmp    1877f <ck_ring_enqueue_mpmc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1877a:	e8 d3 eb ff ff       	call   17352 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1877f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18782:	83 c0 40             	add    $0x40,%eax
   18785:	89 04 24             	mov    %eax,(%esp)
   18788:	e8 2a ed ff ff       	call   174b7 <ck_pr_md_load_uint>
   1878d:	8b 55 b0             	mov    -0x50(%ebp),%edx
   18790:	39 d0                	cmp    %edx,%eax
   18792:	75 e6                	jne    1877a <ck_ring_enqueue_mpmc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   18794:	e8 34 fa ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   18799:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1879c:	8d 50 40             	lea    0x40(%eax),%edx
   1879f:	8b 45 c0             	mov    -0x40(%ebp),%eax
   187a2:	89 44 24 04          	mov    %eax,0x4(%esp)
   187a6:	89 14 24             	mov    %edx,(%esp)
   187a9:	e8 92 ed ff ff       	call   17540 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   187ae:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   187b2:	74 10                	je     187c4 <ck_ring_enqueue_mpmc_size+0x15d>
		*size = (producer - consumer) & mask;
   187b4:	8b 45 b0             	mov    -0x50(%ebp),%eax
   187b7:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   187ba:	23 45 cc             	and    -0x34(%ebp),%eax
   187bd:	89 c2                	mov    %eax,%edx
   187bf:	8b 45 d0             	mov    -0x30(%ebp),%eax
   187c2:	89 10                	mov    %edx,(%eax)

	return r;
   187c4:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   187c8:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   187cb:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   187ce:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   187d1:	89 10                	mov    %edx,(%eax)
	return r;
   187d3:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   187d7:	c9                   	leave  
   187d8:	c3                   	ret    

000187d9 <ck_ring_trydequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   187d9:	55                   	push   %ebp
   187da:	89 e5                	mov    %esp,%ebp
   187dc:	83 ec 38             	sub    $0x38,%esp
   187df:	8b 45 08             	mov    0x8(%ebp),%eax
   187e2:	89 45 f4             	mov    %eax,-0xc(%ebp)
   187e5:	8b 45 0c             	mov    0xc(%ebp),%eax
   187e8:	89 45 f0             	mov    %eax,-0x10(%ebp)
   187eb:	8b 45 10             	mov    0x10(%ebp),%eax
   187ee:	89 45 ec             	mov    %eax,-0x14(%ebp)
   187f1:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   187f8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   187fb:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18801:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   18804:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18807:	89 04 24             	mov    %eax,(%esp)
   1880a:	e8 a8 ec ff ff       	call   174b7 <ck_pr_md_load_uint>
   1880f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   18812:	e8 ab f9 ff ff       	call   181c2 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   18817:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1881a:	83 c0 40             	add    $0x40,%eax
   1881d:	89 04 24             	mov    %eax,(%esp)
   18820:	e8 92 ec ff ff       	call   174b7 <ck_pr_md_load_uint>
   18825:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   18828:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1882b:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1882e:	0f 94 c0             	sete   %al
   18831:	0f b6 c0             	movzbl %al,%eax
   18834:	85 c0                	test   %eax,%eax
   18836:	74 07                	je     1883f <ck_ring_trydequeue_mpmc+0x66>
		return false;
   18838:	b8 00 00 00 00       	mov    $0x0,%eax
   1883d:	eb 4e                	jmp    1888d <ck_ring_trydequeue_mpmc+0xb4>

	ck_pr_fence_load();
   1883f:	e8 7e f9 ff ff       	call   181c2 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   18844:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18847:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1884a:	21 d0                	and    %edx,%eax
   1884c:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   18850:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   18853:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18856:	89 44 24 08          	mov    %eax,0x8(%esp)
   1885a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1885d:	89 44 24 04          	mov    %eax,0x4(%esp)
   18861:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18864:	89 04 24             	mov    %eax,(%esp)
   18867:	e8 fc ff ff ff       	call   18868 <ck_ring_trydequeue_mpmc+0x8f>

	ck_pr_fence_store_atomic();
   1886c:	e8 25 f9 ff ff       	call   18196 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   18871:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18874:	8d 50 01             	lea    0x1(%eax),%edx
   18877:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1887a:	89 54 24 08          	mov    %edx,0x8(%esp)
   1887e:	8b 55 e0             	mov    -0x20(%ebp),%edx
   18881:	89 54 24 04          	mov    %edx,0x4(%esp)
   18885:	89 04 24             	mov    %eax,(%esp)
   18888:	e8 d8 f4 ff ff       	call   17d65 <ck_pr_cas_uint>
    void *data)
{

	return _ck_ring_trydequeue_mc(ring,
	    buffer, (void **)data, sizeof(void *));
}
   1888d:	c9                   	leave  
   1888e:	c3                   	ret    

0001888f <ck_ring_dequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1888f:	55                   	push   %ebp
   18890:	89 e5                	mov    %esp,%ebp
   18892:	53                   	push   %ebx
   18893:	83 ec 34             	sub    $0x34,%esp
   18896:	8b 45 08             	mov    0x8(%ebp),%eax
   18899:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1889c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1889f:	89 45 f0             	mov    %eax,-0x10(%ebp)
   188a2:	8b 45 10             	mov    0x10(%ebp),%eax
   188a5:	89 45 ec             	mov    %eax,-0x14(%ebp)
   188a8:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   188af:	8b 45 f4             	mov    -0xc(%ebp),%eax
   188b2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   188b8:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   188bb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   188be:	89 04 24             	mov    %eax,(%esp)
   188c1:	e8 f1 eb ff ff       	call   174b7 <ck_pr_md_load_uint>
   188c6:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   188c9:	e8 f4 f8 ff ff       	call   181c2 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   188ce:	8b 45 f4             	mov    -0xc(%ebp),%eax
   188d1:	83 c0 40             	add    $0x40,%eax
   188d4:	89 04 24             	mov    %eax,(%esp)
   188d7:	e8 db eb ff ff       	call   174b7 <ck_pr_md_load_uint>
   188dc:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   188df:	8b 45 d8             	mov    -0x28(%ebp),%eax
   188e2:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   188e5:	0f 94 c0             	sete   %al
   188e8:	0f b6 c0             	movzbl %al,%eax
   188eb:	85 c0                	test   %eax,%eax
   188ed:	74 07                	je     188f6 <ck_ring_dequeue_mpmc+0x67>
			return false;
   188ef:	b8 00 00 00 00       	mov    $0x0,%eax
   188f4:	eb 6a                	jmp    18960 <ck_ring_dequeue_mpmc+0xd1>

		ck_pr_fence_load();
   188f6:	e8 c7 f8 ff ff       	call   181c2 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   188fb:	8b 45 d8             	mov    -0x28(%ebp),%eax
   188fe:	23 45 e4             	and    -0x1c(%ebp),%eax
   18901:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   18905:	89 c2                	mov    %eax,%edx
   18907:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1890a:	01 d0                	add    %edx,%eax
   1890c:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   1890f:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18912:	89 44 24 08          	mov    %eax,0x8(%esp)
   18916:	8b 45 dc             	mov    -0x24(%ebp),%eax
   18919:	89 44 24 04          	mov    %eax,0x4(%esp)
   1891d:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18920:	89 04 24             	mov    %eax,(%esp)
   18923:	e8 fc ff ff ff       	call   18924 <ck_ring_dequeue_mpmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   18928:	e8 69 f8 ff ff       	call   18196 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1892d:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18930:	8d 58 01             	lea    0x1(%eax),%ebx
   18933:	8b 55 d8             	mov    -0x28(%ebp),%edx
   18936:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18939:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1893c:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   18940:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   18944:	89 54 24 04          	mov    %edx,0x4(%esp)
   18948:	89 04 24             	mov    %eax,(%esp)
   1894b:	e8 68 f5 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   18950:	83 f0 01             	xor    $0x1,%eax
   18953:	84 c0                	test   %al,%al
   18955:	0f 85 6e ff ff ff    	jne    188c9 <ck_ring_dequeue_mpmc+0x3a>

	return true;
   1895b:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   18960:	83 c4 34             	add    $0x34,%esp
   18963:	5b                   	pop    %ebx
   18964:	5d                   	pop    %ebp
   18965:	c3                   	ret    

00018966 <ck_ring_enqueue_spmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   18966:	55                   	push   %ebp
   18967:	89 e5                	mov    %esp,%ebp
   18969:	83 ec 58             	sub    $0x58,%esp
   1896c:	8b 45 08             	mov    0x8(%ebp),%eax
   1896f:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18972:	8b 45 0c             	mov    0xc(%ebp),%eax
   18975:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18978:	8d 45 10             	lea    0x10(%ebp),%eax
   1897b:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1897e:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   18985:	8b 45 14             	mov    0x14(%ebp),%eax
   18988:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1898b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1898e:	89 45 e0             	mov    %eax,-0x20(%ebp)
   18991:	8b 45 f0             	mov    -0x10(%ebp),%eax
   18994:	89 45 dc             	mov    %eax,-0x24(%ebp)
   18997:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1899a:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1899d:	8b 45 e8             	mov    -0x18(%ebp),%eax
   189a0:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   189a3:	8d 45 b8             	lea    -0x48(%ebp),%eax
   189a6:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   189a9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   189ac:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   189b2:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   189b5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   189b8:	89 04 24             	mov    %eax,(%esp)
   189bb:	e8 f7 ea ff ff       	call   174b7 <ck_pr_md_load_uint>
   189c0:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   189c3:	8b 45 e0             	mov    -0x20(%ebp),%eax
   189c6:	8b 40 40             	mov    0x40(%eax),%eax
   189c9:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   189cc:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   189cf:	83 c0 01             	add    $0x1,%eax
   189d2:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   189d5:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   189d9:	74 14                	je     189ef <ck_ring_enqueue_spmc_size+0x89>
		*size = (producer - consumer) & mask;
   189db:	8b 45 c8             	mov    -0x38(%ebp),%eax
   189de:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   189e1:	29 c2                	sub    %eax,%edx
   189e3:	89 d0                	mov    %edx,%eax
   189e5:	23 45 cc             	and    -0x34(%ebp),%eax
   189e8:	89 c2                	mov    %eax,%edx
   189ea:	8b 45 d0             	mov    -0x30(%ebp),%eax
   189ed:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   189ef:	8b 45 c0             	mov    -0x40(%ebp),%eax
   189f2:	8b 55 c8             	mov    -0x38(%ebp),%edx
   189f5:	31 d0                	xor    %edx,%eax
   189f7:	23 45 cc             	and    -0x34(%ebp),%eax
   189fa:	85 c0                	test   %eax,%eax
   189fc:	0f 94 c0             	sete   %al
   189ff:	0f b6 c0             	movzbl %al,%eax
   18a02:	85 c0                	test   %eax,%eax
   18a04:	74 07                	je     18a0d <ck_ring_enqueue_spmc_size+0xa7>
		return false;
   18a06:	b8 00 00 00 00       	mov    $0x0,%eax
   18a0b:	eb 47                	jmp    18a54 <ck_ring_enqueue_spmc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   18a0d:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   18a10:	8b 55 cc             	mov    -0x34(%ebp),%edx
   18a13:	21 d0                	and    %edx,%eax
   18a15:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   18a19:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   18a1c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   18a1f:	89 44 24 08          	mov    %eax,0x8(%esp)
   18a23:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18a26:	89 44 24 04          	mov    %eax,0x4(%esp)
   18a2a:	8b 45 dc             	mov    -0x24(%ebp),%eax
   18a2d:	89 04 24             	mov    %eax,(%esp)
   18a30:	e8 fc ff ff ff       	call   18a31 <ck_ring_enqueue_spmc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   18a35:	e8 93 f7 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   18a3a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18a3d:	8d 50 40             	lea    0x40(%eax),%edx
   18a40:	8b 45 c0             	mov    -0x40(%ebp),%eax
   18a43:	89 44 24 04          	mov    %eax,0x4(%esp)
   18a47:	89 14 24             	mov    %edx,(%esp)
   18a4a:	e8 f1 ea ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   18a4f:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   18a54:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   18a57:	8b 55 b8             	mov    -0x48(%ebp),%edx
   18a5a:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   18a5d:	89 10                	mov    %edx,(%eax)
	return r;
   18a5f:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   18a63:	c9                   	leave  
   18a64:	c3                   	ret    

00018a65 <ck_ring_enqueue_spmc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   18a65:	55                   	push   %ebp
   18a66:	89 e5                	mov    %esp,%ebp
   18a68:	83 ec 48             	sub    $0x48,%esp
   18a6b:	8b 45 08             	mov    0x8(%ebp),%eax
   18a6e:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18a71:	8b 45 0c             	mov    0xc(%ebp),%eax
   18a74:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18a77:	8d 45 10             	lea    0x10(%ebp),%eax
   18a7a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   18a7d:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   18a84:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   18a8b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18a8e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18a94:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   18a97:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18a9a:	89 04 24             	mov    %eax,(%esp)
   18a9d:	e8 15 ea ff ff       	call   174b7 <ck_pr_md_load_uint>
   18aa2:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   18aa5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18aa8:	8b 40 40             	mov    0x40(%eax),%eax
   18aab:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   18aae:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18ab1:	83 c0 01             	add    $0x1,%eax
   18ab4:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   18ab7:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   18abb:	74 14                	je     18ad1 <ck_ring_enqueue_spmc+0x6c>
		*size = (producer - consumer) & mask;
   18abd:	8b 45 dc             	mov    -0x24(%ebp),%eax
   18ac0:	8b 55 d8             	mov    -0x28(%ebp),%edx
   18ac3:	29 c2                	sub    %eax,%edx
   18ac5:	89 d0                	mov    %edx,%eax
   18ac7:	23 45 e0             	and    -0x20(%ebp),%eax
   18aca:	89 c2                	mov    %eax,%edx
   18acc:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   18acf:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   18ad1:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   18ad4:	8b 55 dc             	mov    -0x24(%ebp),%edx
   18ad7:	31 d0                	xor    %edx,%eax
   18ad9:	23 45 e0             	and    -0x20(%ebp),%eax
   18adc:	85 c0                	test   %eax,%eax
   18ade:	0f 94 c0             	sete   %al
   18ae1:	0f b6 c0             	movzbl %al,%eax
   18ae4:	85 c0                	test   %eax,%eax
   18ae6:	74 07                	je     18aef <ck_ring_enqueue_spmc+0x8a>
		return false;
   18ae8:	b8 00 00 00 00       	mov    $0x0,%eax
   18aed:	eb 47                	jmp    18b36 <ck_ring_enqueue_spmc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   18aef:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18af2:	8b 55 e0             	mov    -0x20(%ebp),%edx
   18af5:	21 d0                	and    %edx,%eax
   18af7:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   18afb:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   18afe:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18b01:	89 44 24 08          	mov    %eax,0x8(%esp)
   18b05:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18b08:	89 44 24 04          	mov    %eax,0x4(%esp)
   18b0c:	8b 45 f0             	mov    -0x10(%ebp),%eax
   18b0f:	89 04 24             	mov    %eax,(%esp)
   18b12:	e8 fc ff ff ff       	call   18b13 <ck_ring_enqueue_spmc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   18b17:	e8 b1 f6 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   18b1c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18b1f:	8d 50 40             	lea    0x40(%eax),%edx
   18b22:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   18b25:	89 44 24 04          	mov    %eax,0x4(%esp)
   18b29:	89 14 24             	mov    %edx,(%esp)
   18b2c:	e8 0f ea ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   18b31:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   18b36:	c9                   	leave  
   18b37:	c3                   	ret    

00018b38 <ck_ring_trydequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   18b38:	55                   	push   %ebp
   18b39:	89 e5                	mov    %esp,%ebp
   18b3b:	83 ec 38             	sub    $0x38,%esp
   18b3e:	8b 45 08             	mov    0x8(%ebp),%eax
   18b41:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18b44:	8b 45 0c             	mov    0xc(%ebp),%eax
   18b47:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18b4a:	8b 45 10             	mov    0x10(%ebp),%eax
   18b4d:	89 45 ec             	mov    %eax,-0x14(%ebp)
   18b50:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   18b57:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18b5a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18b60:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   18b63:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18b66:	89 04 24             	mov    %eax,(%esp)
   18b69:	e8 49 e9 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18b6e:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   18b71:	e8 4c f6 ff ff       	call   181c2 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   18b76:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18b79:	83 c0 40             	add    $0x40,%eax
   18b7c:	89 04 24             	mov    %eax,(%esp)
   18b7f:	e8 33 e9 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18b84:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   18b87:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18b8a:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   18b8d:	0f 94 c0             	sete   %al
   18b90:	0f b6 c0             	movzbl %al,%eax
   18b93:	85 c0                	test   %eax,%eax
   18b95:	74 07                	je     18b9e <ck_ring_trydequeue_spmc+0x66>
		return false;
   18b97:	b8 00 00 00 00       	mov    $0x0,%eax
   18b9c:	eb 4e                	jmp    18bec <ck_ring_trydequeue_spmc+0xb4>

	ck_pr_fence_load();
   18b9e:	e8 1f f6 ff ff       	call   181c2 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   18ba3:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18ba6:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   18ba9:	21 d0                	and    %edx,%eax
   18bab:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   18baf:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   18bb2:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18bb5:	89 44 24 08          	mov    %eax,0x8(%esp)
   18bb9:	8b 45 f0             	mov    -0x10(%ebp),%eax
   18bbc:	89 44 24 04          	mov    %eax,0x4(%esp)
   18bc0:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18bc3:	89 04 24             	mov    %eax,(%esp)
   18bc6:	e8 fc ff ff ff       	call   18bc7 <ck_ring_trydequeue_spmc+0x8f>

	ck_pr_fence_store_atomic();
   18bcb:	e8 c6 f5 ff ff       	call   18196 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   18bd0:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18bd3:	8d 50 01             	lea    0x1(%eax),%edx
   18bd6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18bd9:	89 54 24 08          	mov    %edx,0x8(%esp)
   18bdd:	8b 55 e0             	mov    -0x20(%ebp),%edx
   18be0:	89 54 24 04          	mov    %edx,0x4(%esp)
   18be4:	89 04 24             	mov    %eax,(%esp)
   18be7:	e8 79 f1 ff ff       	call   17d65 <ck_pr_cas_uint>
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_trydequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   18bec:	c9                   	leave  
   18bed:	c3                   	ret    

00018bee <ck_ring_dequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   18bee:	55                   	push   %ebp
   18bef:	89 e5                	mov    %esp,%ebp
   18bf1:	53                   	push   %ebx
   18bf2:	83 ec 34             	sub    $0x34,%esp
   18bf5:	8b 45 08             	mov    0x8(%ebp),%eax
   18bf8:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18bfb:	8b 45 0c             	mov    0xc(%ebp),%eax
   18bfe:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18c01:	8b 45 10             	mov    0x10(%ebp),%eax
   18c04:	89 45 ec             	mov    %eax,-0x14(%ebp)
   18c07:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   18c0e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18c11:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18c17:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   18c1a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18c1d:	89 04 24             	mov    %eax,(%esp)
   18c20:	e8 92 e8 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18c25:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   18c28:	e8 95 f5 ff ff       	call   181c2 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   18c2d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18c30:	83 c0 40             	add    $0x40,%eax
   18c33:	89 04 24             	mov    %eax,(%esp)
   18c36:	e8 7c e8 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18c3b:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   18c3e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18c41:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   18c44:	0f 94 c0             	sete   %al
   18c47:	0f b6 c0             	movzbl %al,%eax
   18c4a:	85 c0                	test   %eax,%eax
   18c4c:	74 07                	je     18c55 <ck_ring_dequeue_spmc+0x67>
			return false;
   18c4e:	b8 00 00 00 00       	mov    $0x0,%eax
   18c53:	eb 6a                	jmp    18cbf <ck_ring_dequeue_spmc+0xd1>

		ck_pr_fence_load();
   18c55:	e8 68 f5 ff ff       	call   181c2 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   18c5a:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18c5d:	23 45 e4             	and    -0x1c(%ebp),%eax
   18c60:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   18c64:	89 c2                	mov    %eax,%edx
   18c66:	8b 45 f0             	mov    -0x10(%ebp),%eax
   18c69:	01 d0                	add    %edx,%eax
   18c6b:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   18c6e:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18c71:	89 44 24 08          	mov    %eax,0x8(%esp)
   18c75:	8b 45 dc             	mov    -0x24(%ebp),%eax
   18c78:	89 44 24 04          	mov    %eax,0x4(%esp)
   18c7c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18c7f:	89 04 24             	mov    %eax,(%esp)
   18c82:	e8 fc ff ff ff       	call   18c83 <ck_ring_dequeue_spmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   18c87:	e8 0a f5 ff ff       	call   18196 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   18c8c:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18c8f:	8d 58 01             	lea    0x1(%eax),%ebx
   18c92:	8b 55 d8             	mov    -0x28(%ebp),%edx
   18c95:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18c98:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   18c9b:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   18c9f:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   18ca3:	89 54 24 04          	mov    %edx,0x4(%esp)
   18ca7:	89 04 24             	mov    %eax,(%esp)
   18caa:	e8 09 f2 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   18caf:	83 f0 01             	xor    $0x1,%eax
   18cb2:	84 c0                	test   %al,%al
   18cb4:	0f 85 6e ff ff ff    	jne    18c28 <ck_ring_dequeue_spmc+0x3a>

	return true;
   18cba:	b8 01 00 00 00       	mov    $0x1,%eax
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   18cbf:	83 c4 34             	add    $0x34,%esp
   18cc2:	5b                   	pop    %ebx
   18cc3:	5d                   	pop    %ebp
   18cc4:	c3                   	ret    

00018cc5 <ck_ring_enqueue_mpsc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   18cc5:	55                   	push   %ebp
   18cc6:	89 e5                	mov    %esp,%ebp
   18cc8:	83 ec 48             	sub    $0x48,%esp
   18ccb:	8b 45 08             	mov    0x8(%ebp),%eax
   18cce:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18cd1:	8b 45 0c             	mov    0xc(%ebp),%eax
   18cd4:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18cd7:	8d 45 10             	lea    0x10(%ebp),%eax
   18cda:	89 45 ec             	mov    %eax,-0x14(%ebp)
   18cdd:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   18ce4:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   18ceb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18cee:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18cf4:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   18cf7:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   18cfb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18cfe:	83 c0 44             	add    $0x44,%eax
   18d01:	89 04 24             	mov    %eax,(%esp)
   18d04:	e8 ae e7 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18d09:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   18d0c:	e8 b1 f4 ff ff       	call   181c2 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   18d11:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18d14:	89 04 24             	mov    %eax,(%esp)
   18d17:	e8 9b e7 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18d1c:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   18d1f:	8b 45 cc             	mov    -0x34(%ebp),%eax
   18d22:	83 c0 01             	add    $0x1,%eax
   18d25:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   18d28:	8b 45 cc             	mov    -0x34(%ebp),%eax
   18d2b:	2b 45 d8             	sub    -0x28(%ebp),%eax
   18d2e:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   18d31:	0f 97 c0             	seta   %al
   18d34:	0f b6 c0             	movzbl %al,%eax
   18d37:	85 c0                	test   %eax,%eax
   18d39:	74 29                	je     18d64 <ck_ring_enqueue_mpsc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   18d3b:	8b 45 cc             	mov    -0x34(%ebp),%eax
   18d3e:	8b 55 f4             	mov    -0xc(%ebp),%edx
   18d41:	8d 4a 44             	lea    0x44(%edx),%ecx
   18d44:	8d 55 cc             	lea    -0x34(%ebp),%edx
   18d47:	89 54 24 0c          	mov    %edx,0xc(%esp)
   18d4b:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   18d4e:	89 54 24 08          	mov    %edx,0x8(%esp)
   18d52:	89 44 24 04          	mov    %eax,0x4(%esp)
   18d56:	89 0c 24             	mov    %ecx,(%esp)
   18d59:	e8 5a f1 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
   18d5e:	84 c0                	test   %al,%al
   18d60:	75 31                	jne    18d93 <ck_ring_enqueue_mpsc+0xce>
   18d62:	eb a8                	jmp    18d0c <ck_ring_enqueue_mpsc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   18d64:	e8 59 f4 ff ff       	call   181c2 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   18d69:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18d6c:	83 c0 44             	add    $0x44,%eax
   18d6f:	89 04 24             	mov    %eax,(%esp)
   18d72:	e8 40 e7 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18d77:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   18d7a:	8b 45 cc             	mov    -0x34(%ebp),%eax
   18d7d:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   18d80:	75 06                	jne    18d88 <ck_ring_enqueue_mpsc+0xc3>
				r = false;
   18d82:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   18d86:	eb 67                	jmp    18def <ck_ring_enqueue_mpsc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   18d88:	8b 45 d0             	mov    -0x30(%ebp),%eax
   18d8b:	89 45 cc             	mov    %eax,-0x34(%ebp)
   18d8e:	e9 79 ff ff ff       	jmp    18d0c <ck_ring_enqueue_mpsc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   18d93:	8b 45 cc             	mov    -0x34(%ebp),%eax
   18d96:	23 45 e0             	and    -0x20(%ebp),%eax
   18d99:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   18d9d:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   18da0:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18da3:	89 44 24 08          	mov    %eax,0x8(%esp)
   18da7:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18daa:	89 44 24 04          	mov    %eax,0x4(%esp)
   18dae:	8b 45 f0             	mov    -0x10(%ebp),%eax
   18db1:	89 04 24             	mov    %eax,(%esp)
   18db4:	e8 fc ff ff ff       	call   18db5 <ck_ring_enqueue_mpsc+0xf0>
   18db9:	eb 05                	jmp    18dc0 <ck_ring_enqueue_mpsc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   18dbb:	e8 92 e5 ff ff       	call   17352 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   18dc0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18dc3:	83 c0 40             	add    $0x40,%eax
   18dc6:	89 04 24             	mov    %eax,(%esp)
   18dc9:	e8 e9 e6 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18dce:	8b 55 cc             	mov    -0x34(%ebp),%edx
   18dd1:	39 d0                	cmp    %edx,%eax
   18dd3:	75 e6                	jne    18dbb <ck_ring_enqueue_mpsc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   18dd5:	e8 f3 f3 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   18dda:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18ddd:	8d 50 40             	lea    0x40(%eax),%edx
   18de0:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   18de3:	89 44 24 04          	mov    %eax,0x4(%esp)
   18de7:	89 14 24             	mov    %edx,(%esp)
   18dea:	e8 51 e7 ff ff       	call   17540 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   18def:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   18df3:	74 10                	je     18e05 <ck_ring_enqueue_mpsc+0x140>
		*size = (producer - consumer) & mask;
   18df5:	8b 45 cc             	mov    -0x34(%ebp),%eax
   18df8:	2b 45 d8             	sub    -0x28(%ebp),%eax
   18dfb:	23 45 e0             	and    -0x20(%ebp),%eax
   18dfe:	89 c2                	mov    %eax,%edx
   18e00:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   18e03:	89 10                	mov    %edx,(%eax)

	return r;
   18e05:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   18e09:	c9                   	leave  
   18e0a:	c3                   	ret    

00018e0b <ck_ring_enqueue_mpsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   18e0b:	55                   	push   %ebp
   18e0c:	89 e5                	mov    %esp,%ebp
   18e0e:	83 ec 68             	sub    $0x68,%esp
   18e11:	8b 45 08             	mov    0x8(%ebp),%eax
   18e14:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18e17:	8b 45 0c             	mov    0xc(%ebp),%eax
   18e1a:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18e1d:	8d 45 10             	lea    0x10(%ebp),%eax
   18e20:	89 45 ec             	mov    %eax,-0x14(%ebp)
   18e23:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   18e2a:	8b 45 14             	mov    0x14(%ebp),%eax
   18e2d:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   18e30:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18e33:	89 45 e0             	mov    %eax,-0x20(%ebp)
   18e36:	8b 45 f0             	mov    -0x10(%ebp),%eax
   18e39:	89 45 dc             	mov    %eax,-0x24(%ebp)
   18e3c:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18e3f:	89 45 d8             	mov    %eax,-0x28(%ebp)
   18e42:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18e45:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   18e48:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   18e4b:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   18e4e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18e51:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18e57:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   18e5a:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   18e5e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18e61:	83 c0 44             	add    $0x44,%eax
   18e64:	89 04 24             	mov    %eax,(%esp)
   18e67:	e8 4b e6 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18e6c:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   18e6f:	e8 4e f3 ff ff       	call   181c2 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   18e74:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18e77:	89 04 24             	mov    %eax,(%esp)
   18e7a:	e8 38 e6 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18e7f:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   18e82:	8b 45 b0             	mov    -0x50(%ebp),%eax
   18e85:	83 c0 01             	add    $0x1,%eax
   18e88:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   18e8b:	8b 45 b0             	mov    -0x50(%ebp),%eax
   18e8e:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   18e91:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   18e94:	0f 97 c0             	seta   %al
   18e97:	0f b6 c0             	movzbl %al,%eax
   18e9a:	85 c0                	test   %eax,%eax
   18e9c:	74 29                	je     18ec7 <ck_ring_enqueue_mpsc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   18e9e:	8b 45 b0             	mov    -0x50(%ebp),%eax
   18ea1:	8b 55 e0             	mov    -0x20(%ebp),%edx
   18ea4:	8d 4a 44             	lea    0x44(%edx),%ecx
   18ea7:	8d 55 b0             	lea    -0x50(%ebp),%edx
   18eaa:	89 54 24 0c          	mov    %edx,0xc(%esp)
   18eae:	8b 55 c0             	mov    -0x40(%ebp),%edx
   18eb1:	89 54 24 08          	mov    %edx,0x8(%esp)
   18eb5:	89 44 24 04          	mov    %eax,0x4(%esp)
   18eb9:	89 0c 24             	mov    %ecx,(%esp)
   18ebc:	e8 f7 ef ff ff       	call   17eb8 <ck_pr_cas_uint_value>
   18ec1:	84 c0                	test   %al,%al
   18ec3:	75 31                	jne    18ef6 <ck_ring_enqueue_mpsc_size+0xeb>
   18ec5:	eb a8                	jmp    18e6f <ck_ring_enqueue_mpsc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   18ec7:	e8 f6 f2 ff ff       	call   181c2 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   18ecc:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18ecf:	83 c0 44             	add    $0x44,%eax
   18ed2:	89 04 24             	mov    %eax,(%esp)
   18ed5:	e8 dd e5 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18eda:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   18edd:	8b 45 b0             	mov    -0x50(%ebp),%eax
   18ee0:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   18ee3:	75 06                	jne    18eeb <ck_ring_enqueue_mpsc_size+0xe0>
				r = false;
   18ee5:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   18ee9:	eb 67                	jmp    18f52 <ck_ring_enqueue_mpsc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   18eeb:	8b 45 bc             	mov    -0x44(%ebp),%eax
   18eee:	89 45 b0             	mov    %eax,-0x50(%ebp)
   18ef1:	e9 79 ff ff ff       	jmp    18e6f <ck_ring_enqueue_mpsc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   18ef6:	8b 45 b0             	mov    -0x50(%ebp),%eax
   18ef9:	23 45 cc             	and    -0x34(%ebp),%eax
   18efc:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   18f00:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   18f03:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   18f06:	89 44 24 08          	mov    %eax,0x8(%esp)
   18f0a:	8b 45 d8             	mov    -0x28(%ebp),%eax
   18f0d:	89 44 24 04          	mov    %eax,0x4(%esp)
   18f11:	8b 45 dc             	mov    -0x24(%ebp),%eax
   18f14:	89 04 24             	mov    %eax,(%esp)
   18f17:	e8 fc ff ff ff       	call   18f18 <ck_ring_enqueue_mpsc_size+0x10d>
   18f1c:	eb 05                	jmp    18f23 <ck_ring_enqueue_mpsc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   18f1e:	e8 2f e4 ff ff       	call   17352 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   18f23:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18f26:	83 c0 40             	add    $0x40,%eax
   18f29:	89 04 24             	mov    %eax,(%esp)
   18f2c:	e8 86 e5 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18f31:	8b 55 b0             	mov    -0x50(%ebp),%edx
   18f34:	39 d0                	cmp    %edx,%eax
   18f36:	75 e6                	jne    18f1e <ck_ring_enqueue_mpsc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   18f38:	e8 90 f2 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   18f3d:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18f40:	8d 50 40             	lea    0x40(%eax),%edx
   18f43:	8b 45 c0             	mov    -0x40(%ebp),%eax
   18f46:	89 44 24 04          	mov    %eax,0x4(%esp)
   18f4a:	89 14 24             	mov    %edx,(%esp)
   18f4d:	e8 ee e5 ff ff       	call   17540 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   18f52:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   18f56:	74 10                	je     18f68 <ck_ring_enqueue_mpsc_size+0x15d>
		*size = (producer - consumer) & mask;
   18f58:	8b 45 b0             	mov    -0x50(%ebp),%eax
   18f5b:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   18f5e:	23 45 cc             	and    -0x34(%ebp),%eax
   18f61:	89 c2                	mov    %eax,%edx
   18f63:	8b 45 d0             	mov    -0x30(%ebp),%eax
   18f66:	89 10                	mov    %edx,(%eax)

	return r;
   18f68:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   18f6c:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   18f6f:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   18f72:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   18f75:	89 10                	mov    %edx,(%eax)
	return r;
   18f77:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   18f7b:	c9                   	leave  
   18f7c:	c3                   	ret    

00018f7d <ck_ring_dequeue_mpsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   18f7d:	55                   	push   %ebp
   18f7e:	89 e5                	mov    %esp,%ebp
   18f80:	83 ec 38             	sub    $0x38,%esp
   18f83:	8b 45 08             	mov    0x8(%ebp),%eax
   18f86:	89 45 f4             	mov    %eax,-0xc(%ebp)
   18f89:	8b 45 0c             	mov    0xc(%ebp),%eax
   18f8c:	89 45 f0             	mov    %eax,-0x10(%ebp)
   18f8f:	8b 45 10             	mov    0x10(%ebp),%eax
   18f92:	89 45 ec             	mov    %eax,-0x14(%ebp)
   18f95:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   18f9c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18f9f:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   18fa5:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   18fa8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18fab:	8b 00                	mov    (%eax),%eax
   18fad:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   18fb0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   18fb3:	83 c0 40             	add    $0x40,%eax
   18fb6:	89 04 24             	mov    %eax,(%esp)
   18fb9:	e8 f9 e4 ff ff       	call   174b7 <ck_pr_md_load_uint>
   18fbe:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   18fc1:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18fc4:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   18fc7:	0f 94 c0             	sete   %al
   18fca:	0f b6 c0             	movzbl %al,%eax
   18fcd:	85 c0                	test   %eax,%eax
   18fcf:	74 07                	je     18fd8 <ck_ring_dequeue_mpsc+0x5b>
		return false;
   18fd1:	b8 00 00 00 00       	mov    $0x0,%eax
   18fd6:	eb 4c                	jmp    19024 <ck_ring_dequeue_mpsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   18fd8:	e8 e5 f1 ff ff       	call   181c2 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   18fdd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   18fe0:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   18fe3:	21 d0                	and    %edx,%eax
   18fe5:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   18fe9:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   18fec:	8b 45 e8             	mov    -0x18(%ebp),%eax
   18fef:	89 44 24 08          	mov    %eax,0x8(%esp)
   18ff3:	8b 45 f0             	mov    -0x10(%ebp),%eax
   18ff6:	89 44 24 04          	mov    %eax,0x4(%esp)
   18ffa:	8b 45 ec             	mov    -0x14(%ebp),%eax
   18ffd:	89 04 24             	mov    %eax,(%esp)
   19000:	e8 fc ff ff ff       	call   19001 <ck_ring_dequeue_mpsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   19005:	e8 c3 f1 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   1900a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1900d:	8d 50 01             	lea    0x1(%eax),%edx
   19010:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19013:	89 54 24 04          	mov    %edx,0x4(%esp)
   19017:	89 04 24             	mov    %eax,(%esp)
   1901a:	e8 21 e5 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   1901f:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   19024:	c9                   	leave  
   19025:	c3                   	ret    

00019026 <ck_ring_enqueue_spsc_size_xcpu>:
   19026:	55                   	push   %ebp
   19027:	89 e5                	mov    %esp,%ebp
   19029:	83 ec 58             	sub    $0x58,%esp
   1902c:	8b 45 08             	mov    0x8(%ebp),%eax
   1902f:	89 45 f4             	mov    %eax,-0xc(%ebp)
   19032:	8b 45 0c             	mov    0xc(%ebp),%eax
   19035:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19038:	8b 45 10             	mov    0x10(%ebp),%eax
   1903b:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1903e:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   19045:	8b 45 14             	mov    0x14(%ebp),%eax
   19048:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1904b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1904e:	89 45 e0             	mov    %eax,-0x20(%ebp)
   19051:	8b 45 f0             	mov    -0x10(%ebp),%eax
   19054:	89 45 dc             	mov    %eax,-0x24(%ebp)
   19057:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1905a:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1905d:	8b 45 e8             	mov    -0x18(%ebp),%eax
   19060:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   19063:	8d 45 b8             	lea    -0x48(%ebp),%eax
   19066:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   19069:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1906c:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   19072:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   19075:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19078:	89 04 24             	mov    %eax,(%esp)
   1907b:	e8 37 e4 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19080:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   19083:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19086:	8b 40 40             	mov    0x40(%eax),%eax
   19089:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1908c:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1908f:	83 c0 01             	add    $0x1,%eax
   19092:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   19095:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   19099:	74 14                	je     190af <ck_ring_enqueue_spsc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   1909b:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1909e:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   190a1:	29 c2                	sub    %eax,%edx
   190a3:	89 d0                	mov    %edx,%eax
   190a5:	23 45 cc             	and    -0x34(%ebp),%eax
   190a8:	89 c2                	mov    %eax,%edx
   190aa:	8b 45 d0             	mov    -0x30(%ebp),%eax
   190ad:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   190af:	8b 45 c0             	mov    -0x40(%ebp),%eax
   190b2:	8b 55 c8             	mov    -0x38(%ebp),%edx
   190b5:	31 d0                	xor    %edx,%eax
   190b7:	23 45 cc             	and    -0x34(%ebp),%eax
   190ba:	85 c0                	test   %eax,%eax
   190bc:	0f 94 c0             	sete   %al
   190bf:	0f b6 c0             	movzbl %al,%eax
   190c2:	85 c0                	test   %eax,%eax
   190c4:	74 07                	je     190cd <ck_ring_enqueue_spsc_size_xcpu+0xa7>
		return false;
   190c6:	b8 00 00 00 00       	mov    $0x0,%eax
   190cb:	eb 47                	jmp    19114 <ck_ring_enqueue_spsc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   190cd:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   190d0:	8b 55 cc             	mov    -0x34(%ebp),%edx
   190d3:	21 d0                	and    %edx,%eax
   190d5:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   190d9:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   190dc:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   190df:	89 44 24 08          	mov    %eax,0x8(%esp)
   190e3:	8b 45 d8             	mov    -0x28(%ebp),%eax
   190e6:	89 44 24 04          	mov    %eax,0x4(%esp)
   190ea:	8b 45 dc             	mov    -0x24(%ebp),%eax
   190ed:	89 04 24             	mov    %eax,(%esp)
   190f0:	e8 fc ff ff ff       	call   190f1 <ck_ring_enqueue_spsc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   190f5:	e8 d3 f0 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   190fa:	8b 45 e0             	mov    -0x20(%ebp),%eax
   190fd:	8d 50 40             	lea    0x40(%eax),%edx
   19100:	8b 45 c0             	mov    -0x40(%ebp),%eax
   19103:	89 44 24 04          	mov    %eax,0x4(%esp)
   19107:	89 14 24             	mov    %edx,(%esp)
   1910a:	e8 31 e4 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   1910f:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   19114:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   19117:	8b 55 b8             	mov    -0x48(%ebp),%edx
   1911a:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1911d:	89 10                	mov    %edx,(%eax)
	return r;
   1911f:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   19123:	c9                   	leave  
   19124:	c3                   	ret    

00019125 <ck_ring_enqueue_spsc_xcpu>:
   19125:	55                   	push   %ebp
   19126:	89 e5                	mov    %esp,%ebp
   19128:	83 ec 48             	sub    $0x48,%esp
   1912b:	8b 45 08             	mov    0x8(%ebp),%eax
   1912e:	89 45 f4             	mov    %eax,-0xc(%ebp)
   19131:	8b 45 0c             	mov    0xc(%ebp),%eax
   19134:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19137:	8b 45 10             	mov    0x10(%ebp),%eax
   1913a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1913d:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   19144:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1914b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1914e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   19154:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   19157:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1915a:	89 04 24             	mov    %eax,(%esp)
   1915d:	e8 55 e3 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19162:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   19165:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19168:	8b 40 40             	mov    0x40(%eax),%eax
   1916b:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1916e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   19171:	83 c0 01             	add    $0x1,%eax
   19174:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   19177:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1917b:	74 14                	je     19191 <ck_ring_enqueue_spsc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   1917d:	8b 45 dc             	mov    -0x24(%ebp),%eax
   19180:	8b 55 d8             	mov    -0x28(%ebp),%edx
   19183:	29 c2                	sub    %eax,%edx
   19185:	89 d0                	mov    %edx,%eax
   19187:	23 45 e0             	and    -0x20(%ebp),%eax
   1918a:	89 c2                	mov    %eax,%edx
   1918c:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1918f:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   19191:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   19194:	8b 55 dc             	mov    -0x24(%ebp),%edx
   19197:	31 d0                	xor    %edx,%eax
   19199:	23 45 e0             	and    -0x20(%ebp),%eax
   1919c:	85 c0                	test   %eax,%eax
   1919e:	0f 94 c0             	sete   %al
   191a1:	0f b6 c0             	movzbl %al,%eax
   191a4:	85 c0                	test   %eax,%eax
   191a6:	74 07                	je     191af <ck_ring_enqueue_spsc_xcpu+0x8a>
		return false;
   191a8:	b8 00 00 00 00       	mov    $0x0,%eax
   191ad:	eb 47                	jmp    191f6 <ck_ring_enqueue_spsc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   191af:	8b 45 d8             	mov    -0x28(%ebp),%eax
   191b2:	8b 55 e0             	mov    -0x20(%ebp),%edx
   191b5:	21 d0                	and    %edx,%eax
   191b7:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   191bb:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   191be:	8b 45 e8             	mov    -0x18(%ebp),%eax
   191c1:	89 44 24 08          	mov    %eax,0x8(%esp)
   191c5:	8b 45 ec             	mov    -0x14(%ebp),%eax
   191c8:	89 44 24 04          	mov    %eax,0x4(%esp)
   191cc:	8b 45 f0             	mov    -0x10(%ebp),%eax
   191cf:	89 04 24             	mov    %eax,(%esp)
   191d2:	e8 fc ff ff ff       	call   191d3 <ck_ring_enqueue_spsc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   191d7:	e8 f1 ef ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   191dc:	8b 45 f4             	mov    -0xc(%ebp),%eax
   191df:	8d 50 40             	lea    0x40(%eax),%edx
   191e2:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   191e5:	89 44 24 04          	mov    %eax,0x4(%esp)
   191e9:	89 14 24             	mov    %edx,(%esp)
   191ec:	e8 4f e3 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   191f1:	b8 01 00 00 00       	mov    $0x1,%eax
   191f6:	c9                   	leave  
   191f7:	c3                   	ret    

000191f8 <ck_ring_dequeue_spsc_xcpu>:
   191f8:	55                   	push   %ebp
   191f9:	89 e5                	mov    %esp,%ebp
   191fb:	83 ec 38             	sub    $0x38,%esp
   191fe:	8b 45 08             	mov    0x8(%ebp),%eax
   19201:	89 45 f4             	mov    %eax,-0xc(%ebp)
   19204:	8b 45 0c             	mov    0xc(%ebp),%eax
   19207:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1920a:	8b 45 10             	mov    0x10(%ebp),%eax
   1920d:	89 45 ec             	mov    %eax,-0x14(%ebp)
   19210:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   19217:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1921a:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   19220:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   19223:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19226:	8b 00                	mov    (%eax),%eax
   19228:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   1922b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1922e:	83 c0 40             	add    $0x40,%eax
   19231:	89 04 24             	mov    %eax,(%esp)
   19234:	e8 7e e2 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19239:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1923c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1923f:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   19242:	0f 94 c0             	sete   %al
   19245:	0f b6 c0             	movzbl %al,%eax
   19248:	85 c0                	test   %eax,%eax
   1924a:	74 07                	je     19253 <ck_ring_dequeue_spsc_xcpu+0x5b>
		return false;
   1924c:	b8 00 00 00 00       	mov    $0x0,%eax
   19251:	eb 4c                	jmp    1929f <ck_ring_dequeue_spsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   19253:	e8 6a ef ff ff       	call   181c2 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   19258:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1925b:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1925e:	21 d0                	and    %edx,%eax
   19260:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   19264:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   19267:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1926a:	89 44 24 08          	mov    %eax,0x8(%esp)
   1926e:	8b 45 f0             	mov    -0x10(%ebp),%eax
   19271:	89 44 24 04          	mov    %eax,0x4(%esp)
   19275:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19278:	89 04 24             	mov    %eax,(%esp)
   1927b:	e8 fc ff ff ff       	call   1927c <ck_ring_dequeue_spsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   19280:	e8 48 ef ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   19285:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19288:	8d 50 01             	lea    0x1(%eax),%edx
   1928b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1928e:	89 54 24 04          	mov    %edx,0x4(%esp)
   19292:	89 04 24             	mov    %eax,(%esp)
   19295:	e8 a6 e2 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   1929a:	b8 01 00 00 00       	mov    $0x1,%eax
   1929f:	c9                   	leave  
   192a0:	c3                   	ret    

000192a1 <ck_ring_enqueue_spmc_size_xcpu>:
   192a1:	55                   	push   %ebp
   192a2:	89 e5                	mov    %esp,%ebp
   192a4:	83 ec 58             	sub    $0x58,%esp
   192a7:	8b 45 08             	mov    0x8(%ebp),%eax
   192aa:	89 45 f4             	mov    %eax,-0xc(%ebp)
   192ad:	8b 45 0c             	mov    0xc(%ebp),%eax
   192b0:	89 45 f0             	mov    %eax,-0x10(%ebp)
   192b3:	8b 45 10             	mov    0x10(%ebp),%eax
   192b6:	89 45 ec             	mov    %eax,-0x14(%ebp)
   192b9:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   192c0:	8b 45 14             	mov    0x14(%ebp),%eax
   192c3:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   192c6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   192c9:	89 45 e0             	mov    %eax,-0x20(%ebp)
   192cc:	8b 45 f0             	mov    -0x10(%ebp),%eax
   192cf:	89 45 dc             	mov    %eax,-0x24(%ebp)
   192d2:	8b 45 ec             	mov    -0x14(%ebp),%eax
   192d5:	89 45 d8             	mov    %eax,-0x28(%ebp)
   192d8:	8b 45 e8             	mov    -0x18(%ebp),%eax
   192db:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   192de:	8d 45 b8             	lea    -0x48(%ebp),%eax
   192e1:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   192e4:	8b 45 e0             	mov    -0x20(%ebp),%eax
   192e7:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   192ed:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   192f0:	8b 45 e0             	mov    -0x20(%ebp),%eax
   192f3:	89 04 24             	mov    %eax,(%esp)
   192f6:	e8 bc e1 ff ff       	call   174b7 <ck_pr_md_load_uint>
   192fb:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   192fe:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19301:	8b 40 40             	mov    0x40(%eax),%eax
   19304:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   19307:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1930a:	83 c0 01             	add    $0x1,%eax
   1930d:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   19310:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   19314:	74 14                	je     1932a <ck_ring_enqueue_spmc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   19316:	8b 45 c8             	mov    -0x38(%ebp),%eax
   19319:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   1931c:	29 c2                	sub    %eax,%edx
   1931e:	89 d0                	mov    %edx,%eax
   19320:	23 45 cc             	and    -0x34(%ebp),%eax
   19323:	89 c2                	mov    %eax,%edx
   19325:	8b 45 d0             	mov    -0x30(%ebp),%eax
   19328:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1932a:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1932d:	8b 55 c8             	mov    -0x38(%ebp),%edx
   19330:	31 d0                	xor    %edx,%eax
   19332:	23 45 cc             	and    -0x34(%ebp),%eax
   19335:	85 c0                	test   %eax,%eax
   19337:	0f 94 c0             	sete   %al
   1933a:	0f b6 c0             	movzbl %al,%eax
   1933d:	85 c0                	test   %eax,%eax
   1933f:	74 07                	je     19348 <ck_ring_enqueue_spmc_size_xcpu+0xa7>
		return false;
   19341:	b8 00 00 00 00       	mov    $0x0,%eax
   19346:	eb 47                	jmp    1938f <ck_ring_enqueue_spmc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   19348:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1934b:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1934e:	21 d0                	and    %edx,%eax
   19350:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   19354:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   19357:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1935a:	89 44 24 08          	mov    %eax,0x8(%esp)
   1935e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   19361:	89 44 24 04          	mov    %eax,0x4(%esp)
   19365:	8b 45 dc             	mov    -0x24(%ebp),%eax
   19368:	89 04 24             	mov    %eax,(%esp)
   1936b:	e8 fc ff ff ff       	call   1936c <ck_ring_enqueue_spmc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   19370:	e8 58 ee ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   19375:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19378:	8d 50 40             	lea    0x40(%eax),%edx
   1937b:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1937e:	89 44 24 04          	mov    %eax,0x4(%esp)
   19382:	89 14 24             	mov    %edx,(%esp)
   19385:	e8 b6 e1 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   1938a:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   1938f:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   19392:	8b 55 b8             	mov    -0x48(%ebp),%edx
   19395:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   19398:	89 10                	mov    %edx,(%eax)
	return r;
   1939a:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   1939e:	c9                   	leave  
   1939f:	c3                   	ret    

000193a0 <ck_ring_enqueue_spmc_xcpu>:
   193a0:	55                   	push   %ebp
   193a1:	89 e5                	mov    %esp,%ebp
   193a3:	83 ec 48             	sub    $0x48,%esp
   193a6:	8b 45 08             	mov    0x8(%ebp),%eax
   193a9:	89 45 f4             	mov    %eax,-0xc(%ebp)
   193ac:	8b 45 0c             	mov    0xc(%ebp),%eax
   193af:	89 45 f0             	mov    %eax,-0x10(%ebp)
   193b2:	8b 45 10             	mov    0x10(%ebp),%eax
   193b5:	89 45 ec             	mov    %eax,-0x14(%ebp)
   193b8:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   193bf:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   193c6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   193c9:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   193cf:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   193d2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   193d5:	89 04 24             	mov    %eax,(%esp)
   193d8:	e8 da e0 ff ff       	call   174b7 <ck_pr_md_load_uint>
   193dd:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   193e0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   193e3:	8b 40 40             	mov    0x40(%eax),%eax
   193e6:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   193e9:	8b 45 d8             	mov    -0x28(%ebp),%eax
   193ec:	83 c0 01             	add    $0x1,%eax
   193ef:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   193f2:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   193f6:	74 14                	je     1940c <ck_ring_enqueue_spmc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   193f8:	8b 45 dc             	mov    -0x24(%ebp),%eax
   193fb:	8b 55 d8             	mov    -0x28(%ebp),%edx
   193fe:	29 c2                	sub    %eax,%edx
   19400:	89 d0                	mov    %edx,%eax
   19402:	23 45 e0             	and    -0x20(%ebp),%eax
   19405:	89 c2                	mov    %eax,%edx
   19407:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1940a:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1940c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1940f:	8b 55 dc             	mov    -0x24(%ebp),%edx
   19412:	31 d0                	xor    %edx,%eax
   19414:	23 45 e0             	and    -0x20(%ebp),%eax
   19417:	85 c0                	test   %eax,%eax
   19419:	0f 94 c0             	sete   %al
   1941c:	0f b6 c0             	movzbl %al,%eax
   1941f:	85 c0                	test   %eax,%eax
   19421:	74 07                	je     1942a <ck_ring_enqueue_spmc_xcpu+0x8a>
		return false;
   19423:	b8 00 00 00 00       	mov    $0x0,%eax
   19428:	eb 47                	jmp    19471 <ck_ring_enqueue_spmc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1942a:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1942d:	8b 55 e0             	mov    -0x20(%ebp),%edx
   19430:	21 d0                	and    %edx,%eax
   19432:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   19436:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   19439:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1943c:	89 44 24 08          	mov    %eax,0x8(%esp)
   19440:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19443:	89 44 24 04          	mov    %eax,0x4(%esp)
   19447:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1944a:	89 04 24             	mov    %eax,(%esp)
   1944d:	e8 fc ff ff ff       	call   1944e <ck_ring_enqueue_spmc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   19452:	e8 76 ed ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   19457:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1945a:	8d 50 40             	lea    0x40(%eax),%edx
   1945d:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   19460:	89 44 24 04          	mov    %eax,0x4(%esp)
   19464:	89 14 24             	mov    %edx,(%esp)
   19467:	e8 d4 e0 ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   1946c:	b8 01 00 00 00       	mov    $0x1,%eax
   19471:	c9                   	leave  
   19472:	c3                   	ret    

00019473 <ck_ring_trydequeue_spmc_xcpu>:
   19473:	55                   	push   %ebp
   19474:	89 e5                	mov    %esp,%ebp
   19476:	83 ec 38             	sub    $0x38,%esp
   19479:	8b 45 08             	mov    0x8(%ebp),%eax
   1947c:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1947f:	8b 45 0c             	mov    0xc(%ebp),%eax
   19482:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19485:	8b 45 10             	mov    0x10(%ebp),%eax
   19488:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1948b:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   19492:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19495:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1949b:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1949e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   194a1:	89 04 24             	mov    %eax,(%esp)
   194a4:	e8 0e e0 ff ff       	call   174b7 <ck_pr_md_load_uint>
   194a9:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   194ac:	e8 11 ed ff ff       	call   181c2 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   194b1:	8b 45 f4             	mov    -0xc(%ebp),%eax
   194b4:	83 c0 40             	add    $0x40,%eax
   194b7:	89 04 24             	mov    %eax,(%esp)
   194ba:	e8 f8 df ff ff       	call   174b7 <ck_pr_md_load_uint>
   194bf:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   194c2:	8b 45 e0             	mov    -0x20(%ebp),%eax
   194c5:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   194c8:	0f 94 c0             	sete   %al
   194cb:	0f b6 c0             	movzbl %al,%eax
   194ce:	85 c0                	test   %eax,%eax
   194d0:	74 07                	je     194d9 <ck_ring_trydequeue_spmc_xcpu+0x66>
		return false;
   194d2:	b8 00 00 00 00       	mov    $0x0,%eax
   194d7:	eb 4e                	jmp    19527 <ck_ring_trydequeue_spmc_xcpu+0xb4>

	ck_pr_fence_load();
   194d9:	e8 e4 ec ff ff       	call   181c2 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   194de:	8b 45 e0             	mov    -0x20(%ebp),%eax
   194e1:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   194e4:	21 d0                	and    %edx,%eax
   194e6:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   194ea:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   194ed:	8b 45 e8             	mov    -0x18(%ebp),%eax
   194f0:	89 44 24 08          	mov    %eax,0x8(%esp)
   194f4:	8b 45 f0             	mov    -0x10(%ebp),%eax
   194f7:	89 44 24 04          	mov    %eax,0x4(%esp)
   194fb:	8b 45 ec             	mov    -0x14(%ebp),%eax
   194fe:	89 04 24             	mov    %eax,(%esp)
   19501:	e8 fc ff ff ff       	call   19502 <ck_ring_trydequeue_spmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   19506:	e8 8b ec ff ff       	call   18196 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1950b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1950e:	8d 50 01             	lea    0x1(%eax),%edx
   19511:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19514:	89 54 24 08          	mov    %edx,0x8(%esp)
   19518:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1951b:	89 54 24 04          	mov    %edx,0x4(%esp)
   1951f:	89 04 24             	mov    %eax,(%esp)
   19522:	e8 3e e8 ff ff       	call   17d65 <ck_pr_cas_uint>
   19527:	c9                   	leave  
   19528:	c3                   	ret    

00019529 <ck_ring_dequeue_spmc_xcpu>:
   19529:	55                   	push   %ebp
   1952a:	89 e5                	mov    %esp,%ebp
   1952c:	53                   	push   %ebx
   1952d:	83 ec 34             	sub    $0x34,%esp
   19530:	8b 45 08             	mov    0x8(%ebp),%eax
   19533:	89 45 f4             	mov    %eax,-0xc(%ebp)
   19536:	8b 45 0c             	mov    0xc(%ebp),%eax
   19539:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1953c:	8b 45 10             	mov    0x10(%ebp),%eax
   1953f:	89 45 ec             	mov    %eax,-0x14(%ebp)
   19542:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   19549:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1954c:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   19552:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   19555:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19558:	89 04 24             	mov    %eax,(%esp)
   1955b:	e8 57 df ff ff       	call   174b7 <ck_pr_md_load_uint>
   19560:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   19563:	e8 5a ec ff ff       	call   181c2 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   19568:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1956b:	83 c0 40             	add    $0x40,%eax
   1956e:	89 04 24             	mov    %eax,(%esp)
   19571:	e8 41 df ff ff       	call   174b7 <ck_pr_md_load_uint>
   19576:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   19579:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1957c:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1957f:	0f 94 c0             	sete   %al
   19582:	0f b6 c0             	movzbl %al,%eax
   19585:	85 c0                	test   %eax,%eax
   19587:	74 07                	je     19590 <ck_ring_dequeue_spmc_xcpu+0x67>
			return false;
   19589:	b8 00 00 00 00       	mov    $0x0,%eax
   1958e:	eb 6a                	jmp    195fa <ck_ring_dequeue_spmc_xcpu+0xd1>

		ck_pr_fence_load();
   19590:	e8 2d ec ff ff       	call   181c2 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   19595:	8b 45 d8             	mov    -0x28(%ebp),%eax
   19598:	23 45 e4             	and    -0x1c(%ebp),%eax
   1959b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1959f:	89 c2                	mov    %eax,%edx
   195a1:	8b 45 f0             	mov    -0x10(%ebp),%eax
   195a4:	01 d0                	add    %edx,%eax
   195a6:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   195a9:	8b 45 e8             	mov    -0x18(%ebp),%eax
   195ac:	89 44 24 08          	mov    %eax,0x8(%esp)
   195b0:	8b 45 dc             	mov    -0x24(%ebp),%eax
   195b3:	89 44 24 04          	mov    %eax,0x4(%esp)
   195b7:	8b 45 ec             	mov    -0x14(%ebp),%eax
   195ba:	89 04 24             	mov    %eax,(%esp)
   195bd:	e8 fc ff ff ff       	call   195be <ck_ring_dequeue_spmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   195c2:	e8 cf eb ff ff       	call   18196 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   195c7:	8b 45 d8             	mov    -0x28(%ebp),%eax
   195ca:	8d 58 01             	lea    0x1(%eax),%ebx
   195cd:	8b 55 d8             	mov    -0x28(%ebp),%edx
   195d0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   195d3:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   195d6:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   195da:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   195de:	89 54 24 04          	mov    %edx,0x4(%esp)
   195e2:	89 04 24             	mov    %eax,(%esp)
   195e5:	e8 ce e8 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   195ea:	83 f0 01             	xor    $0x1,%eax
   195ed:	84 c0                	test   %al,%al
   195ef:	0f 85 6e ff ff ff    	jne    19563 <ck_ring_dequeue_spmc_xcpu+0x3a>

	return true;
   195f5:	b8 01 00 00 00       	mov    $0x1,%eax
   195fa:	83 c4 34             	add    $0x34,%esp
   195fd:	5b                   	pop    %ebx
   195fe:	5d                   	pop    %ebp
   195ff:	c3                   	ret    

00019600 <ck_ring_enqueue_mpsc_xcpu>:
   19600:	55                   	push   %ebp
   19601:	89 e5                	mov    %esp,%ebp
   19603:	83 ec 48             	sub    $0x48,%esp
   19606:	8b 45 08             	mov    0x8(%ebp),%eax
   19609:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1960c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1960f:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19612:	8b 45 10             	mov    0x10(%ebp),%eax
   19615:	89 45 ec             	mov    %eax,-0x14(%ebp)
   19618:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1961f:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   19626:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19629:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1962f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   19632:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   19636:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19639:	83 c0 44             	add    $0x44,%eax
   1963c:	89 04 24             	mov    %eax,(%esp)
   1963f:	e8 73 de ff ff       	call   174b7 <ck_pr_md_load_uint>
   19644:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   19647:	e8 76 eb ff ff       	call   181c2 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1964c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1964f:	89 04 24             	mov    %eax,(%esp)
   19652:	e8 60 de ff ff       	call   174b7 <ck_pr_md_load_uint>
   19657:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1965a:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1965d:	83 c0 01             	add    $0x1,%eax
   19660:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   19663:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19666:	2b 45 d8             	sub    -0x28(%ebp),%eax
   19669:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1966c:	0f 97 c0             	seta   %al
   1966f:	0f b6 c0             	movzbl %al,%eax
   19672:	85 c0                	test   %eax,%eax
   19674:	74 29                	je     1969f <ck_ring_enqueue_mpsc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   19676:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19679:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1967c:	8d 4a 44             	lea    0x44(%edx),%ecx
   1967f:	8d 55 cc             	lea    -0x34(%ebp),%edx
   19682:	89 54 24 0c          	mov    %edx,0xc(%esp)
   19686:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   19689:	89 54 24 08          	mov    %edx,0x8(%esp)
   1968d:	89 44 24 04          	mov    %eax,0x4(%esp)
   19691:	89 0c 24             	mov    %ecx,(%esp)
   19694:	e8 1f e8 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
   19699:	84 c0                	test   %al,%al
   1969b:	75 31                	jne    196ce <ck_ring_enqueue_mpsc_xcpu+0xce>
   1969d:	eb a8                	jmp    19647 <ck_ring_enqueue_mpsc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1969f:	e8 1e eb ff ff       	call   181c2 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   196a4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   196a7:	83 c0 44             	add    $0x44,%eax
   196aa:	89 04 24             	mov    %eax,(%esp)
   196ad:	e8 05 de ff ff       	call   174b7 <ck_pr_md_load_uint>
   196b2:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   196b5:	8b 45 cc             	mov    -0x34(%ebp),%eax
   196b8:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   196bb:	75 06                	jne    196c3 <ck_ring_enqueue_mpsc_xcpu+0xc3>
				r = false;
   196bd:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   196c1:	eb 67                	jmp    1972a <ck_ring_enqueue_mpsc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   196c3:	8b 45 d0             	mov    -0x30(%ebp),%eax
   196c6:	89 45 cc             	mov    %eax,-0x34(%ebp)
   196c9:	e9 79 ff ff ff       	jmp    19647 <ck_ring_enqueue_mpsc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   196ce:	8b 45 cc             	mov    -0x34(%ebp),%eax
   196d1:	23 45 e0             	and    -0x20(%ebp),%eax
   196d4:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   196d8:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   196db:	8b 45 e8             	mov    -0x18(%ebp),%eax
   196de:	89 44 24 08          	mov    %eax,0x8(%esp)
   196e2:	8b 45 ec             	mov    -0x14(%ebp),%eax
   196e5:	89 44 24 04          	mov    %eax,0x4(%esp)
   196e9:	8b 45 f0             	mov    -0x10(%ebp),%eax
   196ec:	89 04 24             	mov    %eax,(%esp)
   196ef:	e8 fc ff ff ff       	call   196f0 <ck_ring_enqueue_mpsc_xcpu+0xf0>
   196f4:	eb 05                	jmp    196fb <ck_ring_enqueue_mpsc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   196f6:	e8 57 dc ff ff       	call   17352 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   196fb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   196fe:	83 c0 40             	add    $0x40,%eax
   19701:	89 04 24             	mov    %eax,(%esp)
   19704:	e8 ae dd ff ff       	call   174b7 <ck_pr_md_load_uint>
   19709:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1970c:	39 d0                	cmp    %edx,%eax
   1970e:	75 e6                	jne    196f6 <ck_ring_enqueue_mpsc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   19710:	e8 b8 ea ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   19715:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19718:	8d 50 40             	lea    0x40(%eax),%edx
   1971b:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1971e:	89 44 24 04          	mov    %eax,0x4(%esp)
   19722:	89 14 24             	mov    %edx,(%esp)
   19725:	e8 16 de ff ff       	call   17540 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1972a:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1972e:	74 10                	je     19740 <ck_ring_enqueue_mpsc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   19730:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19733:	2b 45 d8             	sub    -0x28(%ebp),%eax
   19736:	23 45 e0             	and    -0x20(%ebp),%eax
   19739:	89 c2                	mov    %eax,%edx
   1973b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1973e:	89 10                	mov    %edx,(%eax)

	return r;
   19740:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   19744:	c9                   	leave  
   19745:	c3                   	ret    

00019746 <ck_ring_enqueue_mpsc_size_xcpu>:
   19746:	55                   	push   %ebp
   19747:	89 e5                	mov    %esp,%ebp
   19749:	83 ec 68             	sub    $0x68,%esp
   1974c:	8b 45 08             	mov    0x8(%ebp),%eax
   1974f:	89 45 f4             	mov    %eax,-0xc(%ebp)
   19752:	8b 45 0c             	mov    0xc(%ebp),%eax
   19755:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19758:	8b 45 10             	mov    0x10(%ebp),%eax
   1975b:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1975e:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   19765:	8b 45 14             	mov    0x14(%ebp),%eax
   19768:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1976b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1976e:	89 45 e0             	mov    %eax,-0x20(%ebp)
   19771:	8b 45 f0             	mov    -0x10(%ebp),%eax
   19774:	89 45 dc             	mov    %eax,-0x24(%ebp)
   19777:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1977a:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1977d:	8b 45 e8             	mov    -0x18(%ebp),%eax
   19780:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   19783:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   19786:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   19789:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1978c:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   19792:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   19795:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   19799:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1979c:	83 c0 44             	add    $0x44,%eax
   1979f:	89 04 24             	mov    %eax,(%esp)
   197a2:	e8 10 dd ff ff       	call   174b7 <ck_pr_md_load_uint>
   197a7:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   197aa:	e8 13 ea ff ff       	call   181c2 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   197af:	8b 45 e0             	mov    -0x20(%ebp),%eax
   197b2:	89 04 24             	mov    %eax,(%esp)
   197b5:	e8 fd dc ff ff       	call   174b7 <ck_pr_md_load_uint>
   197ba:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   197bd:	8b 45 b0             	mov    -0x50(%ebp),%eax
   197c0:	83 c0 01             	add    $0x1,%eax
   197c3:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   197c6:	8b 45 b0             	mov    -0x50(%ebp),%eax
   197c9:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   197cc:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   197cf:	0f 97 c0             	seta   %al
   197d2:	0f b6 c0             	movzbl %al,%eax
   197d5:	85 c0                	test   %eax,%eax
   197d7:	74 29                	je     19802 <ck_ring_enqueue_mpsc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   197d9:	8b 45 b0             	mov    -0x50(%ebp),%eax
   197dc:	8b 55 e0             	mov    -0x20(%ebp),%edx
   197df:	8d 4a 44             	lea    0x44(%edx),%ecx
   197e2:	8d 55 b0             	lea    -0x50(%ebp),%edx
   197e5:	89 54 24 0c          	mov    %edx,0xc(%esp)
   197e9:	8b 55 c0             	mov    -0x40(%ebp),%edx
   197ec:	89 54 24 08          	mov    %edx,0x8(%esp)
   197f0:	89 44 24 04          	mov    %eax,0x4(%esp)
   197f4:	89 0c 24             	mov    %ecx,(%esp)
   197f7:	e8 bc e6 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
   197fc:	84 c0                	test   %al,%al
   197fe:	75 31                	jne    19831 <ck_ring_enqueue_mpsc_size_xcpu+0xeb>
   19800:	eb a8                	jmp    197aa <ck_ring_enqueue_mpsc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   19802:	e8 bb e9 ff ff       	call   181c2 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   19807:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1980a:	83 c0 44             	add    $0x44,%eax
   1980d:	89 04 24             	mov    %eax,(%esp)
   19810:	e8 a2 dc ff ff       	call   174b7 <ck_pr_md_load_uint>
   19815:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   19818:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1981b:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   1981e:	75 06                	jne    19826 <ck_ring_enqueue_mpsc_size_xcpu+0xe0>
				r = false;
   19820:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   19824:	eb 67                	jmp    1988d <ck_ring_enqueue_mpsc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   19826:	8b 45 bc             	mov    -0x44(%ebp),%eax
   19829:	89 45 b0             	mov    %eax,-0x50(%ebp)
   1982c:	e9 79 ff ff ff       	jmp    197aa <ck_ring_enqueue_mpsc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   19831:	8b 45 b0             	mov    -0x50(%ebp),%eax
   19834:	23 45 cc             	and    -0x34(%ebp),%eax
   19837:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1983b:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1983e:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   19841:	89 44 24 08          	mov    %eax,0x8(%esp)
   19845:	8b 45 d8             	mov    -0x28(%ebp),%eax
   19848:	89 44 24 04          	mov    %eax,0x4(%esp)
   1984c:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1984f:	89 04 24             	mov    %eax,(%esp)
   19852:	e8 fc ff ff ff       	call   19853 <ck_ring_enqueue_mpsc_size_xcpu+0x10d>
   19857:	eb 05                	jmp    1985e <ck_ring_enqueue_mpsc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   19859:	e8 f4 da ff ff       	call   17352 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1985e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19861:	83 c0 40             	add    $0x40,%eax
   19864:	89 04 24             	mov    %eax,(%esp)
   19867:	e8 4b dc ff ff       	call   174b7 <ck_pr_md_load_uint>
   1986c:	8b 55 b0             	mov    -0x50(%ebp),%edx
   1986f:	39 d0                	cmp    %edx,%eax
   19871:	75 e6                	jne    19859 <ck_ring_enqueue_mpsc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   19873:	e8 55 e9 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   19878:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1987b:	8d 50 40             	lea    0x40(%eax),%edx
   1987e:	8b 45 c0             	mov    -0x40(%ebp),%eax
   19881:	89 44 24 04          	mov    %eax,0x4(%esp)
   19885:	89 14 24             	mov    %edx,(%esp)
   19888:	e8 b3 dc ff ff       	call   17540 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1988d:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   19891:	74 10                	je     198a3 <ck_ring_enqueue_mpsc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   19893:	8b 45 b0             	mov    -0x50(%ebp),%eax
   19896:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   19899:	23 45 cc             	and    -0x34(%ebp),%eax
   1989c:	89 c2                	mov    %eax,%edx
   1989e:	8b 45 d0             	mov    -0x30(%ebp),%eax
   198a1:	89 10                	mov    %edx,(%eax)

	return r;
   198a3:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   198a7:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   198aa:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   198ad:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   198b0:	89 10                	mov    %edx,(%eax)
	return r;
   198b2:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   198b6:	c9                   	leave  
   198b7:	c3                   	ret    

000198b8 <ck_ring_dequeue_mpsc_xcpu>:
   198b8:	55                   	push   %ebp
   198b9:	89 e5                	mov    %esp,%ebp
   198bb:	83 ec 38             	sub    $0x38,%esp
   198be:	8b 45 08             	mov    0x8(%ebp),%eax
   198c1:	89 45 f4             	mov    %eax,-0xc(%ebp)
   198c4:	8b 45 0c             	mov    0xc(%ebp),%eax
   198c7:	89 45 f0             	mov    %eax,-0x10(%ebp)
   198ca:	8b 45 10             	mov    0x10(%ebp),%eax
   198cd:	89 45 ec             	mov    %eax,-0x14(%ebp)
   198d0:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   198d7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   198da:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   198e0:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   198e3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   198e6:	8b 00                	mov    (%eax),%eax
   198e8:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   198eb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   198ee:	83 c0 40             	add    $0x40,%eax
   198f1:	89 04 24             	mov    %eax,(%esp)
   198f4:	e8 be db ff ff       	call   174b7 <ck_pr_md_load_uint>
   198f9:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   198fc:	8b 45 e0             	mov    -0x20(%ebp),%eax
   198ff:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   19902:	0f 94 c0             	sete   %al
   19905:	0f b6 c0             	movzbl %al,%eax
   19908:	85 c0                	test   %eax,%eax
   1990a:	74 07                	je     19913 <ck_ring_dequeue_mpsc_xcpu+0x5b>
		return false;
   1990c:	b8 00 00 00 00       	mov    $0x0,%eax
   19911:	eb 4c                	jmp    1995f <ck_ring_dequeue_mpsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   19913:	e8 aa e8 ff ff       	call   181c2 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   19918:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1991b:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1991e:	21 d0                	and    %edx,%eax
   19920:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   19924:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   19927:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1992a:	89 44 24 08          	mov    %eax,0x8(%esp)
   1992e:	8b 45 f0             	mov    -0x10(%ebp),%eax
   19931:	89 44 24 04          	mov    %eax,0x4(%esp)
   19935:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19938:	89 04 24             	mov    %eax,(%esp)
   1993b:	e8 fc ff ff ff       	call   1993c <ck_ring_dequeue_mpsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   19940:	e8 88 e8 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   19945:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19948:	8d 50 01             	lea    0x1(%eax),%edx
   1994b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1994e:	89 54 24 04          	mov    %edx,0x4(%esp)
   19952:	89 04 24             	mov    %eax,(%esp)
   19955:	e8 e6 db ff ff       	call   17540 <ck_pr_md_store_uint>
	return true;
   1995a:	b8 01 00 00 00       	mov    $0x1,%eax
   1995f:	c9                   	leave  
   19960:	c3                   	ret    

00019961 <ck_ring_enqueue_mpmc_size_xcpu>:
   19961:	55                   	push   %ebp
   19962:	89 e5                	mov    %esp,%ebp
   19964:	83 ec 68             	sub    $0x68,%esp
   19967:	8b 45 08             	mov    0x8(%ebp),%eax
   1996a:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1996d:	8b 45 0c             	mov    0xc(%ebp),%eax
   19970:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19973:	8b 45 10             	mov    0x10(%ebp),%eax
   19976:	89 45 ec             	mov    %eax,-0x14(%ebp)
   19979:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   19980:	8b 45 14             	mov    0x14(%ebp),%eax
   19983:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   19986:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19989:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1998c:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1998f:	89 45 dc             	mov    %eax,-0x24(%ebp)
   19992:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19995:	89 45 d8             	mov    %eax,-0x28(%ebp)
   19998:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1999b:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1999e:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   199a1:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   199a4:	8b 45 e0             	mov    -0x20(%ebp),%eax
   199a7:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   199ad:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   199b0:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   199b4:	8b 45 e0             	mov    -0x20(%ebp),%eax
   199b7:	83 c0 44             	add    $0x44,%eax
   199ba:	89 04 24             	mov    %eax,(%esp)
   199bd:	e8 f5 da ff ff       	call   174b7 <ck_pr_md_load_uint>
   199c2:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   199c5:	e8 f8 e7 ff ff       	call   181c2 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   199ca:	8b 45 e0             	mov    -0x20(%ebp),%eax
   199cd:	89 04 24             	mov    %eax,(%esp)
   199d0:	e8 e2 da ff ff       	call   174b7 <ck_pr_md_load_uint>
   199d5:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   199d8:	8b 45 b0             	mov    -0x50(%ebp),%eax
   199db:	83 c0 01             	add    $0x1,%eax
   199de:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   199e1:	8b 45 b0             	mov    -0x50(%ebp),%eax
   199e4:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   199e7:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   199ea:	0f 97 c0             	seta   %al
   199ed:	0f b6 c0             	movzbl %al,%eax
   199f0:	85 c0                	test   %eax,%eax
   199f2:	74 29                	je     19a1d <ck_ring_enqueue_mpmc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   199f4:	8b 45 b0             	mov    -0x50(%ebp),%eax
   199f7:	8b 55 e0             	mov    -0x20(%ebp),%edx
   199fa:	8d 4a 44             	lea    0x44(%edx),%ecx
   199fd:	8d 55 b0             	lea    -0x50(%ebp),%edx
   19a00:	89 54 24 0c          	mov    %edx,0xc(%esp)
   19a04:	8b 55 c0             	mov    -0x40(%ebp),%edx
   19a07:	89 54 24 08          	mov    %edx,0x8(%esp)
   19a0b:	89 44 24 04          	mov    %eax,0x4(%esp)
   19a0f:	89 0c 24             	mov    %ecx,(%esp)
   19a12:	e8 a1 e4 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
   19a17:	84 c0                	test   %al,%al
   19a19:	75 31                	jne    19a4c <ck_ring_enqueue_mpmc_size_xcpu+0xeb>
   19a1b:	eb a8                	jmp    199c5 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   19a1d:	e8 a0 e7 ff ff       	call   181c2 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   19a22:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19a25:	83 c0 44             	add    $0x44,%eax
   19a28:	89 04 24             	mov    %eax,(%esp)
   19a2b:	e8 87 da ff ff       	call   174b7 <ck_pr_md_load_uint>
   19a30:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   19a33:	8b 45 b0             	mov    -0x50(%ebp),%eax
   19a36:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   19a39:	75 06                	jne    19a41 <ck_ring_enqueue_mpmc_size_xcpu+0xe0>
				r = false;
   19a3b:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   19a3f:	eb 67                	jmp    19aa8 <ck_ring_enqueue_mpmc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   19a41:	8b 45 bc             	mov    -0x44(%ebp),%eax
   19a44:	89 45 b0             	mov    %eax,-0x50(%ebp)
   19a47:	e9 79 ff ff ff       	jmp    199c5 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   19a4c:	8b 45 b0             	mov    -0x50(%ebp),%eax
   19a4f:	23 45 cc             	and    -0x34(%ebp),%eax
   19a52:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   19a56:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   19a59:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   19a5c:	89 44 24 08          	mov    %eax,0x8(%esp)
   19a60:	8b 45 d8             	mov    -0x28(%ebp),%eax
   19a63:	89 44 24 04          	mov    %eax,0x4(%esp)
   19a67:	8b 45 dc             	mov    -0x24(%ebp),%eax
   19a6a:	89 04 24             	mov    %eax,(%esp)
   19a6d:	e8 fc ff ff ff       	call   19a6e <ck_ring_enqueue_mpmc_size_xcpu+0x10d>
   19a72:	eb 05                	jmp    19a79 <ck_ring_enqueue_mpmc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   19a74:	e8 d9 d8 ff ff       	call   17352 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   19a79:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19a7c:	83 c0 40             	add    $0x40,%eax
   19a7f:	89 04 24             	mov    %eax,(%esp)
   19a82:	e8 30 da ff ff       	call   174b7 <ck_pr_md_load_uint>
   19a87:	8b 55 b0             	mov    -0x50(%ebp),%edx
   19a8a:	39 d0                	cmp    %edx,%eax
   19a8c:	75 e6                	jne    19a74 <ck_ring_enqueue_mpmc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   19a8e:	e8 3a e7 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   19a93:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19a96:	8d 50 40             	lea    0x40(%eax),%edx
   19a99:	8b 45 c0             	mov    -0x40(%ebp),%eax
   19a9c:	89 44 24 04          	mov    %eax,0x4(%esp)
   19aa0:	89 14 24             	mov    %edx,(%esp)
   19aa3:	e8 98 da ff ff       	call   17540 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   19aa8:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   19aac:	74 10                	je     19abe <ck_ring_enqueue_mpmc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   19aae:	8b 45 b0             	mov    -0x50(%ebp),%eax
   19ab1:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   19ab4:	23 45 cc             	and    -0x34(%ebp),%eax
   19ab7:	89 c2                	mov    %eax,%edx
   19ab9:	8b 45 d0             	mov    -0x30(%ebp),%eax
   19abc:	89 10                	mov    %edx,(%eax)

	return r;
   19abe:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   19ac2:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   19ac5:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   19ac8:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   19acb:	89 10                	mov    %edx,(%eax)
	return r;
   19acd:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   19ad1:	c9                   	leave  
   19ad2:	c3                   	ret    

00019ad3 <ck_ring_enqueue_mpmc_xcpu>:
   19ad3:	55                   	push   %ebp
   19ad4:	89 e5                	mov    %esp,%ebp
   19ad6:	83 ec 48             	sub    $0x48,%esp
   19ad9:	8b 45 08             	mov    0x8(%ebp),%eax
   19adc:	89 45 f4             	mov    %eax,-0xc(%ebp)
   19adf:	8b 45 0c             	mov    0xc(%ebp),%eax
   19ae2:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19ae5:	8b 45 10             	mov    0x10(%ebp),%eax
   19ae8:	89 45 ec             	mov    %eax,-0x14(%ebp)
   19aeb:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   19af2:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   19af9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19afc:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   19b02:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   19b05:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   19b09:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19b0c:	83 c0 44             	add    $0x44,%eax
   19b0f:	89 04 24             	mov    %eax,(%esp)
   19b12:	e8 a0 d9 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19b17:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   19b1a:	e8 a3 e6 ff ff       	call   181c2 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   19b1f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19b22:	89 04 24             	mov    %eax,(%esp)
   19b25:	e8 8d d9 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19b2a:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   19b2d:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19b30:	83 c0 01             	add    $0x1,%eax
   19b33:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   19b36:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19b39:	2b 45 d8             	sub    -0x28(%ebp),%eax
   19b3c:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   19b3f:	0f 97 c0             	seta   %al
   19b42:	0f b6 c0             	movzbl %al,%eax
   19b45:	85 c0                	test   %eax,%eax
   19b47:	74 29                	je     19b72 <ck_ring_enqueue_mpmc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   19b49:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19b4c:	8b 55 f4             	mov    -0xc(%ebp),%edx
   19b4f:	8d 4a 44             	lea    0x44(%edx),%ecx
   19b52:	8d 55 cc             	lea    -0x34(%ebp),%edx
   19b55:	89 54 24 0c          	mov    %edx,0xc(%esp)
   19b59:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   19b5c:	89 54 24 08          	mov    %edx,0x8(%esp)
   19b60:	89 44 24 04          	mov    %eax,0x4(%esp)
   19b64:	89 0c 24             	mov    %ecx,(%esp)
   19b67:	e8 4c e3 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
   19b6c:	84 c0                	test   %al,%al
   19b6e:	75 31                	jne    19ba1 <ck_ring_enqueue_mpmc_xcpu+0xce>
   19b70:	eb a8                	jmp    19b1a <ck_ring_enqueue_mpmc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   19b72:	e8 4b e6 ff ff       	call   181c2 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   19b77:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19b7a:	83 c0 44             	add    $0x44,%eax
   19b7d:	89 04 24             	mov    %eax,(%esp)
   19b80:	e8 32 d9 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19b85:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   19b88:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19b8b:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   19b8e:	75 06                	jne    19b96 <ck_ring_enqueue_mpmc_xcpu+0xc3>
				r = false;
   19b90:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   19b94:	eb 67                	jmp    19bfd <ck_ring_enqueue_mpmc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   19b96:	8b 45 d0             	mov    -0x30(%ebp),%eax
   19b99:	89 45 cc             	mov    %eax,-0x34(%ebp)
   19b9c:	e9 79 ff ff ff       	jmp    19b1a <ck_ring_enqueue_mpmc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   19ba1:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19ba4:	23 45 e0             	and    -0x20(%ebp),%eax
   19ba7:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   19bab:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   19bae:	8b 45 e8             	mov    -0x18(%ebp),%eax
   19bb1:	89 44 24 08          	mov    %eax,0x8(%esp)
   19bb5:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19bb8:	89 44 24 04          	mov    %eax,0x4(%esp)
   19bbc:	8b 45 f0             	mov    -0x10(%ebp),%eax
   19bbf:	89 04 24             	mov    %eax,(%esp)
   19bc2:	e8 fc ff ff ff       	call   19bc3 <ck_ring_enqueue_mpmc_xcpu+0xf0>
   19bc7:	eb 05                	jmp    19bce <ck_ring_enqueue_mpmc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   19bc9:	e8 84 d7 ff ff       	call   17352 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   19bce:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19bd1:	83 c0 40             	add    $0x40,%eax
   19bd4:	89 04 24             	mov    %eax,(%esp)
   19bd7:	e8 db d8 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19bdc:	8b 55 cc             	mov    -0x34(%ebp),%edx
   19bdf:	39 d0                	cmp    %edx,%eax
   19be1:	75 e6                	jne    19bc9 <ck_ring_enqueue_mpmc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   19be3:	e8 e5 e5 ff ff       	call   181cd <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   19be8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19beb:	8d 50 40             	lea    0x40(%eax),%edx
   19bee:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   19bf1:	89 44 24 04          	mov    %eax,0x4(%esp)
   19bf5:	89 14 24             	mov    %edx,(%esp)
   19bf8:	e8 43 d9 ff ff       	call   17540 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   19bfd:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   19c01:	74 10                	je     19c13 <ck_ring_enqueue_mpmc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   19c03:	8b 45 cc             	mov    -0x34(%ebp),%eax
   19c06:	2b 45 d8             	sub    -0x28(%ebp),%eax
   19c09:	23 45 e0             	and    -0x20(%ebp),%eax
   19c0c:	89 c2                	mov    %eax,%edx
   19c0e:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   19c11:	89 10                	mov    %edx,(%eax)

	return r;
   19c13:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   19c17:	c9                   	leave  
   19c18:	c3                   	ret    

00019c19 <ck_ring_trydequeue_mpmc_xcpu>:
   19c19:	55                   	push   %ebp
   19c1a:	89 e5                	mov    %esp,%ebp
   19c1c:	83 ec 38             	sub    $0x38,%esp
   19c1f:	8b 45 08             	mov    0x8(%ebp),%eax
   19c22:	89 45 f4             	mov    %eax,-0xc(%ebp)
   19c25:	8b 45 0c             	mov    0xc(%ebp),%eax
   19c28:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19c2b:	8b 45 10             	mov    0x10(%ebp),%eax
   19c2e:	89 45 ec             	mov    %eax,-0x14(%ebp)
   19c31:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   19c38:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19c3b:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   19c41:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   19c44:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19c47:	89 04 24             	mov    %eax,(%esp)
   19c4a:	e8 68 d8 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19c4f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   19c52:	e8 6b e5 ff ff       	call   181c2 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   19c57:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19c5a:	83 c0 40             	add    $0x40,%eax
   19c5d:	89 04 24             	mov    %eax,(%esp)
   19c60:	e8 52 d8 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19c65:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   19c68:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19c6b:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   19c6e:	0f 94 c0             	sete   %al
   19c71:	0f b6 c0             	movzbl %al,%eax
   19c74:	85 c0                	test   %eax,%eax
   19c76:	74 07                	je     19c7f <ck_ring_trydequeue_mpmc_xcpu+0x66>
		return false;
   19c78:	b8 00 00 00 00       	mov    $0x0,%eax
   19c7d:	eb 4e                	jmp    19ccd <ck_ring_trydequeue_mpmc_xcpu+0xb4>

	ck_pr_fence_load();
   19c7f:	e8 3e e5 ff ff       	call   181c2 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   19c84:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19c87:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   19c8a:	21 d0                	and    %edx,%eax
   19c8c:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   19c90:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   19c93:	8b 45 e8             	mov    -0x18(%ebp),%eax
   19c96:	89 44 24 08          	mov    %eax,0x8(%esp)
   19c9a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   19c9d:	89 44 24 04          	mov    %eax,0x4(%esp)
   19ca1:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19ca4:	89 04 24             	mov    %eax,(%esp)
   19ca7:	e8 fc ff ff ff       	call   19ca8 <ck_ring_trydequeue_mpmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   19cac:	e8 e5 e4 ff ff       	call   18196 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   19cb1:	8b 45 e0             	mov    -0x20(%ebp),%eax
   19cb4:	8d 50 01             	lea    0x1(%eax),%edx
   19cb7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19cba:	89 54 24 08          	mov    %edx,0x8(%esp)
   19cbe:	8b 55 e0             	mov    -0x20(%ebp),%edx
   19cc1:	89 54 24 04          	mov    %edx,0x4(%esp)
   19cc5:	89 04 24             	mov    %eax,(%esp)
   19cc8:	e8 98 e0 ff ff       	call   17d65 <ck_pr_cas_uint>
   19ccd:	c9                   	leave  
   19cce:	c3                   	ret    

00019ccf <ck_ring_dequeue_mpmc_xcpu>:
   19ccf:	55                   	push   %ebp
   19cd0:	89 e5                	mov    %esp,%ebp
   19cd2:	53                   	push   %ebx
   19cd3:	83 ec 34             	sub    $0x34,%esp
   19cd6:	8b 45 08             	mov    0x8(%ebp),%eax
   19cd9:	89 45 f4             	mov    %eax,-0xc(%ebp)
   19cdc:	8b 45 0c             	mov    0xc(%ebp),%eax
   19cdf:	89 45 f0             	mov    %eax,-0x10(%ebp)
   19ce2:	8b 45 10             	mov    0x10(%ebp),%eax
   19ce5:	89 45 ec             	mov    %eax,-0x14(%ebp)
   19ce8:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   19cef:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19cf2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   19cf8:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   19cfb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19cfe:	89 04 24             	mov    %eax,(%esp)
   19d01:	e8 b1 d7 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19d06:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   19d09:	e8 b4 e4 ff ff       	call   181c2 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   19d0e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19d11:	83 c0 40             	add    $0x40,%eax
   19d14:	89 04 24             	mov    %eax,(%esp)
   19d17:	e8 9b d7 ff ff       	call   174b7 <ck_pr_md_load_uint>
   19d1c:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   19d1f:	8b 45 d8             	mov    -0x28(%ebp),%eax
   19d22:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   19d25:	0f 94 c0             	sete   %al
   19d28:	0f b6 c0             	movzbl %al,%eax
   19d2b:	85 c0                	test   %eax,%eax
   19d2d:	74 07                	je     19d36 <ck_ring_dequeue_mpmc_xcpu+0x67>
			return false;
   19d2f:	b8 00 00 00 00       	mov    $0x0,%eax
   19d34:	eb 6a                	jmp    19da0 <ck_ring_dequeue_mpmc_xcpu+0xd1>

		ck_pr_fence_load();
   19d36:	e8 87 e4 ff ff       	call   181c2 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   19d3b:	8b 45 d8             	mov    -0x28(%ebp),%eax
   19d3e:	23 45 e4             	and    -0x1c(%ebp),%eax
   19d41:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   19d45:	89 c2                	mov    %eax,%edx
   19d47:	8b 45 f0             	mov    -0x10(%ebp),%eax
   19d4a:	01 d0                	add    %edx,%eax
   19d4c:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   19d4f:	8b 45 e8             	mov    -0x18(%ebp),%eax
   19d52:	89 44 24 08          	mov    %eax,0x8(%esp)
   19d56:	8b 45 dc             	mov    -0x24(%ebp),%eax
   19d59:	89 44 24 04          	mov    %eax,0x4(%esp)
   19d5d:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19d60:	89 04 24             	mov    %eax,(%esp)
   19d63:	e8 fc ff ff ff       	call   19d64 <ck_ring_dequeue_mpmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   19d68:	e8 29 e4 ff ff       	call   18196 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   19d6d:	8b 45 d8             	mov    -0x28(%ebp),%eax
   19d70:	8d 58 01             	lea    0x1(%eax),%ebx
   19d73:	8b 55 d8             	mov    -0x28(%ebp),%edx
   19d76:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19d79:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   19d7c:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   19d80:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   19d84:	89 54 24 04          	mov    %edx,0x4(%esp)
   19d88:	89 04 24             	mov    %eax,(%esp)
   19d8b:	e8 28 e1 ff ff       	call   17eb8 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   19d90:	83 f0 01             	xor    $0x1,%eax
   19d93:	84 c0                	test   %al,%al
   19d95:	0f 85 6e ff ff ff    	jne    19d09 <ck_ring_dequeue_mpmc_xcpu+0x3a>

	return true;
   19d9b:	b8 01 00 00 00       	mov    $0x1,%eax
   19da0:	83 c4 34             	add    $0x34,%esp
   19da3:	5b                   	pop    %ebx
   19da4:	5d                   	pop    %ebp
   19da5:	c3                   	ret    

00019da6 <sl__globals>:

extern struct sl_global sl_global_data;

static inline struct sl_global *
sl__globals(void)
{
   19da6:	55                   	push   %ebp
   19da7:	89 e5                	mov    %esp,%ebp
	return &sl_global_data;
   19da9:	b8 00 00 00 00       	mov    $0x0,%eax
}
   19dae:	5d                   	pop    %ebp
   19daf:	c3                   	ret    

00019db0 <sl__globals_cpu>:

extern struct sl_global_cpu sl_global_cpu_data[];

static inline struct sl_global_cpu *
sl__globals_cpu(void)
{
   19db0:	55                   	push   %ebp
   19db1:	89 e5                	mov    %esp,%ebp
	return &(sl_global_cpu_data[cos_cpuid()]);
   19db3:	e8 e1 d0 ff ff       	call   16e99 <cos_cpuid>
   19db8:	c1 e0 03             	shl    $0x3,%eax
   19dbb:	8d 14 c5 00 00 00 00 	lea    0x0(,%eax,8),%edx
   19dc2:	29 c2                	sub    %eax,%edx
   19dc4:	8d 82 00 00 00 00    	lea    0x0(%edx),%eax
}
   19dca:	5d                   	pop    %ebp
   19dcb:	c3                   	ret    

00019dcc <sl_thd_lkup>:
/* for lazy retrieval of a child component thread in the parent */
extern struct sl_thd *sl_thd_retrieve(thdid_t tid);

static inline struct sl_thd *
sl_thd_lkup(thdid_t tid)
{
   19dcc:	55                   	push   %ebp
   19dcd:	89 e5                	mov    %esp,%ebp
   19dcf:	83 ec 18             	sub    $0x18,%esp
   19dd2:	8b 45 08             	mov    0x8(%ebp),%eax
   19dd5:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	assert(tid != 0);
   19dd9:	66 83 7d f4 00       	cmpw   $0x0,-0xc(%ebp)
   19dde:	0f 94 c0             	sete   %al
   19de1:	0f b6 c0             	movzbl %al,%eax
   19de4:	85 c0                	test   %eax,%eax
   19de6:	74 1c                	je     19e04 <sl_thd_lkup+0x38>
   19de8:	c7 04 24 a4 31 00 00 	movl   $0x31a4,(%esp)
   19def:	e8 20 d2 ff ff       	call   17014 <prints>
   19df4:	a1 ac 02 00 00       	mov    0x2ac,%eax
   19df9:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   19dff:	e8 97 d2 ff ff       	call   1709b <__cos_noret>
	if (unlikely(tid > MAX_NUM_THREADS)) return NULL;
   19e04:	66 83 7d f4 40       	cmpw   $0x40,-0xc(%ebp)
   19e09:	0f 97 c0             	seta   %al
   19e0c:	0f b6 c0             	movzbl %al,%eax
   19e0f:	85 c0                	test   %eax,%eax
   19e11:	74 07                	je     19e1a <sl_thd_lkup+0x4e>
   19e13:	b8 00 00 00 00       	mov    $0x0,%eax
   19e18:	eb 0c                	jmp    19e26 <sl_thd_lkup+0x5a>

	return sl_thd_retrieve(tid);
   19e1a:	0f b7 45 f4          	movzwl -0xc(%ebp),%eax
   19e1e:	89 04 24             	mov    %eax,(%esp)
   19e21:	e8 fc ff ff ff       	call   19e22 <sl_thd_lkup+0x56>
}
   19e26:	c9                   	leave  
   19e27:	c3                   	ret    

00019e28 <sl_thdid>:
	return t;
}

static inline thdid_t
sl_thdid(void)
{
   19e28:	55                   	push   %ebp
   19e29:	89 e5                	mov    %esp,%ebp
   19e2b:	83 ec 28             	sub    $0x28,%esp
	thdid_t tid = cos_thdid();
   19e2e:	e8 84 d0 ff ff       	call   16eb7 <cos_thdid>
   19e33:	66 89 45 f6          	mov    %ax,-0xa(%ebp)

	assert(tid != 0);
   19e37:	66 83 7d f6 00       	cmpw   $0x0,-0xa(%ebp)
   19e3c:	0f 94 c0             	sete   %al
   19e3f:	0f b6 c0             	movzbl %al,%eax
   19e42:	85 c0                	test   %eax,%eax
   19e44:	74 1c                	je     19e62 <sl_thdid+0x3a>
   19e46:	c7 04 24 f8 31 00 00 	movl   $0x31f8,(%esp)
   19e4d:	e8 c2 d1 ff ff       	call   17014 <prints>
   19e52:	a1 ac 02 00 00       	mov    0x2ac,%eax
   19e57:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   19e5d:	e8 39 d2 ff ff       	call   1709b <__cos_noret>
	assert(tid < MAX_NUM_THREADS);
   19e62:	66 83 7d f6 3f       	cmpw   $0x3f,-0xa(%ebp)
   19e67:	0f 97 c0             	seta   %al
   19e6a:	0f b6 c0             	movzbl %al,%eax
   19e6d:	85 c0                	test   %eax,%eax
   19e6f:	74 1c                	je     19e8d <sl_thdid+0x65>
   19e71:	c7 04 24 4c 32 00 00 	movl   $0x324c,(%esp)
   19e78:	e8 97 d1 ff ff       	call   17014 <prints>
   19e7d:	a1 ac 02 00 00       	mov    0x2ac,%eax
   19e82:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   19e88:	e8 0e d2 ff ff       	call   1709b <__cos_noret>

	return tid;
   19e8d:	0f b7 45 f6          	movzwl -0xa(%ebp),%eax
}
   19e91:	c9                   	leave  
   19e92:	c3                   	ret    

00019e93 <sl_thd_curr>:


static inline struct sl_thd *
sl_thd_curr(void)
{
   19e93:	55                   	push   %ebp
   19e94:	89 e5                	mov    %esp,%ebp
   19e96:	83 ec 18             	sub    $0x18,%esp
	return sl_thd_lkup(sl_thdid());
   19e99:	e8 8a ff ff ff       	call   19e28 <sl_thdid>
   19e9e:	0f b7 c0             	movzwl %ax,%eax
   19ea1:	89 04 24             	mov    %eax,(%esp)
   19ea4:	e8 23 ff ff ff       	call   19dcc <sl_thd_lkup>
}
   19ea9:	c9                   	leave  
   19eaa:	c3                   	ret    

00019eab <sl_cs_owner>:

/* are we the owner of the critical section? */
static inline int
sl_cs_owner(void)
{
   19eab:	55                   	push   %ebp
   19eac:	89 e5                	mov    %esp,%ebp
   19eae:	53                   	push   %ebx
   19eaf:	83 ec 14             	sub    $0x14,%esp
	return sl__globals_cpu()->lock.u.s.owner == sl_thd_thdcap(sl_thd_curr());
   19eb2:	e8 f9 fe ff ff       	call   19db0 <sl__globals_cpu>
   19eb7:	8b 00                	mov    (%eax),%eax
   19eb9:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   19ebe:	89 c3                	mov    %eax,%ebx
   19ec0:	e8 ce ff ff ff       	call   19e93 <sl_thd_curr>
   19ec5:	89 04 24             	mov    %eax,(%esp)
   19ec8:	e8 7f d3 ff ff       	call   1724c <sl_thd_thdcap>
   19ecd:	39 c3                	cmp    %eax,%ebx
   19ecf:	0f 94 c0             	sete   %al
   19ed2:	0f b6 c0             	movzbl %al,%eax
}
   19ed5:	83 c4 14             	add    $0x14,%esp
   19ed8:	5b                   	pop    %ebx
   19ed9:	5d                   	pop    %ebp
   19eda:	c3                   	ret    

00019edb <sl_cs_enter_nospin>:
int sl_cs_exit_contention(union sl_cs_intern *csi, union sl_cs_intern *cached, sched_tok_t tok);

/* Enter into the scheduler critical section */
static inline int
sl_cs_enter_nospin(void)
{
   19edb:	55                   	push   %ebp
   19edc:	89 e5                	mov    %esp,%ebp
   19ede:	56                   	push   %esi
   19edf:	53                   	push   %ebx
   19ee0:	83 ec 20             	sub    $0x20,%esp
	union sl_cs_intern csi, cached;
	struct sl_thd *    t = sl_thd_curr();
   19ee3:	e8 ab ff ff ff       	call   19e93 <sl_thd_curr>
   19ee8:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sched_tok_t        tok;

	assert(t);
   19eeb:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
   19eef:	0f 94 c0             	sete   %al
   19ef2:	0f b6 c0             	movzbl %al,%eax
   19ef5:	85 c0                	test   %eax,%eax
   19ef7:	74 1c                	je     19f15 <sl_cs_enter_nospin+0x3a>
   19ef9:	c7 04 24 a0 32 00 00 	movl   $0x32a0,(%esp)
   19f00:	e8 0f d1 ff ff       	call   17014 <prints>
   19f05:	a1 ac 02 00 00       	mov    0x2ac,%eax
   19f0a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   19f10:	e8 86 d1 ff ff       	call   1709b <__cos_noret>
	tok      = cos_sched_sync();
   19f15:	e8 fc ff ff ff       	call   19f16 <sl_cs_enter_nospin+0x3b>
   19f1a:	89 45 f0             	mov    %eax,-0x10(%ebp)
	csi.v    = sl__globals_cpu()->lock.u.v;
   19f1d:	e8 8e fe ff ff       	call   19db0 <sl__globals_cpu>
   19f22:	8b 00                	mov    (%eax),%eax
   19f24:	89 45 ec             	mov    %eax,-0x14(%ebp)
	cached.v = csi.v;
   19f27:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19f2a:	89 45 e8             	mov    %eax,-0x18(%ebp)

	if (unlikely(csi.s.owner)) {
   19f2d:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19f30:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   19f35:	85 c0                	test   %eax,%eax
   19f37:	0f 95 c0             	setne  %al
   19f3a:	0f b6 c0             	movzbl %al,%eax
   19f3d:	85 c0                	test   %eax,%eax
   19f3f:	74 2a                	je     19f6b <sl_cs_enter_nospin+0x90>
		return sl_cs_enter_contention(&csi, &cached, sl_thd_thdcap(t), tok);
   19f41:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19f44:	89 04 24             	mov    %eax,(%esp)
   19f47:	e8 00 d3 ff ff       	call   1724c <sl_thd_thdcap>
   19f4c:	8b 55 f0             	mov    -0x10(%ebp),%edx
   19f4f:	89 54 24 0c          	mov    %edx,0xc(%esp)
   19f53:	89 44 24 08          	mov    %eax,0x8(%esp)
   19f57:	8d 45 e8             	lea    -0x18(%ebp),%eax
   19f5a:	89 44 24 04          	mov    %eax,0x4(%esp)
   19f5e:	8d 45 ec             	lea    -0x14(%ebp),%eax
   19f61:	89 04 24             	mov    %eax,(%esp)
   19f64:	e8 fc ff ff ff       	call   19f65 <sl_cs_enter_nospin+0x8a>
   19f69:	eb 4f                	jmp    19fba <sl_cs_enter_nospin+0xdf>
	}

	csi.s.owner = sl_thd_thdcap(t);
   19f6b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   19f6e:	89 04 24             	mov    %eax,(%esp)
   19f71:	e8 d6 d2 ff ff       	call   1724c <sl_thd_thdcap>
   19f76:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   19f7b:	25 ff ff ff 7f       	and    $0x7fffffff,%eax
   19f80:	89 c2                	mov    %eax,%edx
   19f82:	8b 45 ec             	mov    -0x14(%ebp),%eax
   19f85:	25 00 00 00 80       	and    $0x80000000,%eax
   19f8a:	09 d0                	or     %edx,%eax
   19f8c:	89 45 ec             	mov    %eax,-0x14(%ebp)
	if (!ps_cas(&sl__globals_cpu()->lock.u.v, cached.v, csi.v)) return 1;
   19f8f:	8b 75 ec             	mov    -0x14(%ebp),%esi
   19f92:	8b 5d e8             	mov    -0x18(%ebp),%ebx
   19f95:	e8 16 fe ff ff       	call   19db0 <sl__globals_cpu>
   19f9a:	89 74 24 08          	mov    %esi,0x8(%esp)
   19f9e:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   19fa2:	89 04 24             	mov    %eax,(%esp)
   19fa5:	e8 78 cd ff ff       	call   16d22 <ps_cas>
   19faa:	85 c0                	test   %eax,%eax
   19fac:	75 07                	jne    19fb5 <sl_cs_enter_nospin+0xda>
   19fae:	b8 01 00 00 00       	mov    $0x1,%eax
   19fb3:	eb 05                	jmp    19fba <sl_cs_enter_nospin+0xdf>

	return 0;
   19fb5:	b8 00 00 00 00       	mov    $0x0,%eax
}
   19fba:	83 c4 20             	add    $0x20,%esp
   19fbd:	5b                   	pop    %ebx
   19fbe:	5e                   	pop    %esi
   19fbf:	5d                   	pop    %ebp
   19fc0:	c3                   	ret    

00019fc1 <sl_cs_enter>:

/* Enter into scheduler cs from a non-sched thread context */
static inline void
sl_cs_enter(void)
{
   19fc1:	55                   	push   %ebp
   19fc2:	89 e5                	mov    %esp,%ebp
   19fc4:	83 ec 08             	sub    $0x8,%esp
	while (sl_cs_enter_nospin())
   19fc7:	90                   	nop
   19fc8:	e8 0e ff ff ff       	call   19edb <sl_cs_enter_nospin>
   19fcd:	85 c0                	test   %eax,%eax
   19fcf:	75 f7                	jne    19fc8 <sl_cs_enter+0x7>
		;
}
   19fd1:	c9                   	leave  
   19fd2:	c3                   	ret    

00019fd3 <sl_cs_exit>:
 * Release the scheduler critical section, switch to the scheduler
 * thread if there is pending contention
 */
static inline void
sl_cs_exit(void)
{
   19fd3:	55                   	push   %ebp
   19fd4:	89 e5                	mov    %esp,%ebp
   19fd6:	53                   	push   %ebx
   19fd7:	83 ec 24             	sub    $0x24,%esp
	union sl_cs_intern csi, cached;
	sched_tok_t        tok;

	assert(sl_cs_owner());
   19fda:	e8 cc fe ff ff       	call   19eab <sl_cs_owner>
   19fdf:	85 c0                	test   %eax,%eax
   19fe1:	0f 94 c0             	sete   %al
   19fe4:	0f b6 c0             	movzbl %al,%eax
   19fe7:	85 c0                	test   %eax,%eax
   19fe9:	74 1c                	je     1a007 <sl_cs_exit+0x34>
   19feb:	c7 04 24 f4 32 00 00 	movl   $0x32f4,(%esp)
   19ff2:	e8 1d d0 ff ff       	call   17014 <prints>
   19ff7:	a1 ac 02 00 00       	mov    0x2ac,%eax
   19ffc:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1a002:	e8 94 d0 ff ff       	call   1709b <__cos_noret>

retry:
	tok      = cos_sched_sync();
   1a007:	e8 fc ff ff ff       	call   1a008 <sl_cs_exit+0x35>
   1a00c:	89 45 f4             	mov    %eax,-0xc(%ebp)
	csi.v    = sl__globals_cpu()->lock.u.v;
   1a00f:	e8 9c fd ff ff       	call   19db0 <sl__globals_cpu>
   1a014:	8b 00                	mov    (%eax),%eax
   1a016:	89 45 f0             	mov    %eax,-0x10(%ebp)
	cached.v = csi.v;
   1a019:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1a01c:	89 45 ec             	mov    %eax,-0x14(%ebp)

	if (unlikely(csi.s.contention)) {
   1a01f:	0f b6 45 f3          	movzbl -0xd(%ebp),%eax
   1a023:	c0 e8 07             	shr    $0x7,%al
   1a026:	0f b6 c0             	movzbl %al,%eax
   1a029:	85 c0                	test   %eax,%eax
   1a02b:	74 1f                	je     1a04c <sl_cs_exit+0x79>
		if (sl_cs_exit_contention(&csi, &cached, tok)) goto retry;
   1a02d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a030:	89 44 24 08          	mov    %eax,0x8(%esp)
   1a034:	8d 45 ec             	lea    -0x14(%ebp),%eax
   1a037:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a03b:	8d 45 f0             	lea    -0x10(%ebp),%eax
   1a03e:	89 04 24             	mov    %eax,(%esp)
   1a041:	e8 fc ff ff ff       	call   1a042 <sl_cs_exit+0x6f>
   1a046:	85 c0                	test   %eax,%eax
   1a048:	74 24                	je     1a06e <sl_cs_exit+0x9b>
   1a04a:	eb bb                	jmp    1a007 <sl_cs_exit+0x34>
		return;
	}

	if (!ps_cas(&sl__globals_cpu()->lock.u.v, cached.v, 0)) goto retry;
   1a04c:	8b 5d ec             	mov    -0x14(%ebp),%ebx
   1a04f:	e8 5c fd ff ff       	call   19db0 <sl__globals_cpu>
   1a054:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a05b:	00 
   1a05c:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   1a060:	89 04 24             	mov    %eax,(%esp)
   1a063:	e8 ba cc ff ff       	call   16d22 <ps_cas>
   1a068:	85 c0                	test   %eax,%eax
   1a06a:	75 02                	jne    1a06e <sl_cs_exit+0x9b>
   1a06c:	eb 99                	jmp    1a007 <sl_cs_exit+0x34>
}
   1a06e:	83 c4 24             	add    $0x24,%esp
   1a071:	5b                   	pop    %ebx
   1a072:	5d                   	pop    %ebp
   1a073:	c3                   	ret    

0001a074 <sl_shm_alloc>:
extern void sl_thd_event_info_reset(struct sl_thd *t);
extern void sl_thd_free_no_cs(struct sl_thd *t);

cbuf_t
sl_shm_alloc(vaddr_t *addr)
{
   1a074:	55                   	push   %ebp
   1a075:	89 e5                	mov    %esp,%ebp
	return 0;
   1a077:	b8 00 00 00 00       	mov    $0x0,%eax
}
   1a07c:	5d                   	pop    %ebp
   1a07d:	c3                   	ret    

0001a07e <sl_shm_map>:

vaddr_t
sl_shm_map(cbuf_t id)
{
   1a07e:	55                   	push   %ebp
   1a07f:	89 e5                	mov    %esp,%ebp
        return 0;
   1a081:	b8 00 00 00 00       	mov    $0x0,%eax
}
   1a086:	5d                   	pop    %ebp
   1a087:	c3                   	ret    

0001a088 <sl_xcpu_asnd_alloc>:

void
sl_xcpu_asnd_alloc(void)
{
   1a088:	55                   	push   %ebp
   1a089:	89 e5                	mov    %esp,%ebp
   1a08b:	53                   	push   %ebx
   1a08c:	83 ec 24             	sub    $0x24,%esp
        struct cos_defcompinfo *dci = cos_defcompinfo_curr_get();
   1a08f:	e8 fc ff ff ff       	call   1a090 <sl_xcpu_asnd_alloc+0x8>
   1a094:	89 45 f0             	mov    %eax,-0x10(%ebp)
        struct cos_compinfo    *ci  = cos_compinfo_get(dci);
   1a097:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1a09a:	89 04 24             	mov    %eax,(%esp)
   1a09d:	e8 fc ff ff ff       	call   1a09e <sl_xcpu_asnd_alloc+0x16>
   1a0a2:	89 45 ec             	mov    %eax,-0x14(%ebp)
	int i;

	for (i = 0; i < NUM_CPU; i++) {
   1a0a5:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
   1a0ac:	e9 a0 00 00 00       	jmp    1a151 <sl_xcpu_asnd_alloc+0xc9>
		asndcap_t snd;

		if (i == cos_cpuid()) continue;
   1a0b1:	e8 e3 cd ff ff       	call   16e99 <cos_cpuid>
   1a0b6:	3b 45 f4             	cmp    -0xc(%ebp),%eax
   1a0b9:	75 05                	jne    1a0c0 <sl_xcpu_asnd_alloc+0x38>
   1a0bb:	e9 8d 00 00 00       	jmp    1a14d <sl_xcpu_asnd_alloc+0xc5>
		if (!bitmap_check(sl__globals()->cpu_bmp, i)) continue;
   1a0c0:	e8 e1 fc ff ff       	call   19da6 <sl__globals>
   1a0c5:	8d 90 88 40 02 00    	lea    0x24088(%eax),%edx
   1a0cb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a0ce:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a0d2:	89 14 24             	mov    %edx,(%esp)
   1a0d5:	e8 85 cc ff ff       	call   16d5f <bitmap_check>
   1a0da:	85 c0                	test   %eax,%eax
   1a0dc:	75 02                	jne    1a0e0 <sl_xcpu_asnd_alloc+0x58>
   1a0de:	eb 6d                	jmp    1a14d <sl_xcpu_asnd_alloc+0xc5>

		snd = cos_asnd_alloc(ci, BOOT_CAPTBL_SELF_INITRCV_BASE_CPU(i), ci->captbl_cap);
   1a0e0:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a0e3:	8b 50 04             	mov    0x4(%eax),%edx
   1a0e6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a0e9:	83 c0 08             	add    $0x8,%eax
   1a0ec:	c1 e0 02             	shl    $0x2,%eax
   1a0ef:	89 54 24 08          	mov    %edx,0x8(%esp)
   1a0f3:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a0f7:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a0fa:	89 04 24             	mov    %eax,(%esp)
   1a0fd:	e8 fc ff ff ff       	call   1a0fe <sl_xcpu_asnd_alloc+0x76>
   1a102:	89 45 e8             	mov    %eax,-0x18(%ebp)
		assert(snd);
   1a105:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
   1a109:	0f 94 c0             	sete   %al
   1a10c:	0f b6 c0             	movzbl %al,%eax
   1a10f:	85 c0                	test   %eax,%eax
   1a111:	74 1c                	je     1a12f <sl_xcpu_asnd_alloc+0xa7>
   1a113:	c7 04 24 48 33 00 00 	movl   $0x3348,(%esp)
   1a11a:	e8 f5 ce ff ff       	call   17014 <prints>
   1a11f:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1a124:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1a12a:	e8 6c cf ff ff       	call   1709b <__cos_noret>
		sl__globals()->xcpu_asnd[cos_cpuid()][i] = snd;
   1a12f:	e8 72 fc ff ff       	call   19da6 <sl__globals>
   1a134:	89 c3                	mov    %eax,%ebx
   1a136:	e8 5e cd ff ff       	call   16e99 <cos_cpuid>
   1a13b:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1a13e:	01 d0                	add    %edx,%eax
   1a140:	8d 90 20 90 00 00    	lea    0x9020(%eax),%edx
   1a146:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a149:	89 44 93 0c          	mov    %eax,0xc(%ebx,%edx,4)
{
        struct cos_defcompinfo *dci = cos_defcompinfo_curr_get();
        struct cos_compinfo    *ci  = cos_compinfo_get(dci);
	int i;

	for (i = 0; i < NUM_CPU; i++) {
   1a14d:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   1a151:	83 7d f4 00          	cmpl   $0x0,-0xc(%ebp)
   1a155:	0f 8e 56 ff ff ff    	jle    1a0b1 <sl_xcpu_asnd_alloc+0x29>

		snd = cos_asnd_alloc(ci, BOOT_CAPTBL_SELF_INITRCV_BASE_CPU(i), ci->captbl_cap);
		assert(snd);
		sl__globals()->xcpu_asnd[cos_cpuid()][i] = snd;
	}
}
   1a15b:	83 c4 24             	add    $0x24,%esp
   1a15e:	5b                   	pop    %ebx
   1a15f:	5d                   	pop    %ebp
   1a160:	c3                   	ret    

0001a161 <sl_thd_alloc_init>:

struct sl_thd *
sl_thd_alloc_init(struct cos_aep_info *aep, asndcap_t sndcap, sl_thd_property_t prps)
{
   1a161:	55                   	push   %ebp
   1a162:	89 e5                	mov    %esp,%ebp
   1a164:	83 ec 28             	sub    $0x28,%esp
	struct sl_thd_policy *tp = NULL;
   1a167:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	struct sl_thd        *t  = NULL;
   1a16e:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	assert(aep->tid);
   1a175:	8b 45 08             	mov    0x8(%ebp),%eax
   1a178:	0f b7 40 08          	movzwl 0x8(%eax),%eax
   1a17c:	66 85 c0             	test   %ax,%ax
   1a17f:	0f 94 c0             	sete   %al
   1a182:	0f b6 c0             	movzbl %al,%eax
   1a185:	85 c0                	test   %eax,%eax
   1a187:	74 1c                	je     1a1a5 <sl_thd_alloc_init+0x44>
   1a189:	c7 04 24 70 33 00 00 	movl   $0x3370,(%esp)
   1a190:	e8 7f ce ff ff       	call   17014 <prints>
   1a195:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1a19a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1a1a0:	e8 f6 ce ff ff       	call   1709b <__cos_noret>
	tp = sl_thd_alloc_backend(aep->tid);
   1a1a5:	8b 45 08             	mov    0x8(%ebp),%eax
   1a1a8:	0f b7 40 08          	movzwl 0x8(%eax),%eax
   1a1ac:	0f b7 c0             	movzwl %ax,%eax
   1a1af:	89 04 24             	mov    %eax,(%esp)
   1a1b2:	e8 fc ff ff ff       	call   1a1b3 <sl_thd_alloc_init+0x52>
   1a1b7:	89 45 f0             	mov    %eax,-0x10(%ebp)
	if (!tp) goto done;
   1a1ba:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
   1a1be:	75 05                	jne    1a1c5 <sl_thd_alloc_init+0x64>
   1a1c0:	e9 e4 00 00 00       	jmp    1a2a9 <sl_thd_alloc_init+0x148>
	t  = sl_mod_thd_get(tp);
   1a1c5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1a1c8:	89 04 24             	mov    %eax,(%esp)
   1a1cb:	e8 bd d0 ff ff       	call   1728d <sl_mod_thd_get>
   1a1d0:	89 45 f4             	mov    %eax,-0xc(%ebp)

	t->properties     = prps;
   1a1d3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a1d6:	8b 55 10             	mov    0x10(%ebp),%edx
   1a1d9:	89 50 08             	mov    %edx,0x8(%eax)
	t->aepinfo        = aep;
   1a1dc:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a1df:	8b 55 08             	mov    0x8(%ebp),%edx
   1a1e2:	89 50 0c             	mov    %edx,0xc(%eax)
	t->sndcap         = sndcap;
   1a1e5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a1e8:	8b 55 0c             	mov    0xc(%ebp),%edx
   1a1eb:	89 50 10             	mov    %edx,0x10(%eax)
	t->state          = SL_THD_RUNNABLE;
   1a1ee:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a1f1:	c7 00 04 00 00 00    	movl   $0x4,(%eax)
	sl_thd_index_add_backend(sl_mod_thd_policy_get(t));
   1a1f7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a1fa:	89 04 24             	mov    %eax,(%esp)
   1a1fd:	e8 93 d0 ff ff       	call   17295 <sl_mod_thd_policy_get>
   1a202:	89 04 24             	mov    %eax,(%esp)
   1a205:	e8 fc ff ff ff       	call   1a206 <sl_thd_alloc_init+0xa5>

	t->rcv_suspended  = 0;
   1a20a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a20d:	c7 40 04 00 00 00 00 	movl   $0x0,0x4(%eax)
	t->budget         = 0;
   1a214:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a217:	c7 40 30 00 00 00 00 	movl   $0x0,0x30(%eax)
	t->last_replenish = 0;
   1a21e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a221:	c7 40 34 00 00 00 00 	movl   $0x0,0x34(%eax)
   1a228:	c7 40 38 00 00 00 00 	movl   $0x0,0x38(%eax)
	t->period         = t->timeout_cycs = t->periodic_cycs = 0;
   1a22f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a232:	c7 40 44 00 00 00 00 	movl   $0x0,0x44(%eax)
   1a239:	c7 40 48 00 00 00 00 	movl   $0x0,0x48(%eax)
   1a240:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a243:	8b 50 48             	mov    0x48(%eax),%edx
   1a246:	8b 40 44             	mov    0x44(%eax),%eax
   1a249:	8b 4d f4             	mov    -0xc(%ebp),%ecx
   1a24c:	89 41 4c             	mov    %eax,0x4c(%ecx)
   1a24f:	89 51 50             	mov    %edx,0x50(%ecx)
   1a252:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a255:	8b 50 50             	mov    0x50(%eax),%edx
   1a258:	8b 40 4c             	mov    0x4c(%eax),%eax
   1a25b:	8b 4d f4             	mov    -0xc(%ebp),%ecx
   1a25e:	89 41 3c             	mov    %eax,0x3c(%ecx)
   1a261:	89 51 40             	mov    %edx,0x40(%ecx)
	t->wakeup_cycs    = 0;
   1a264:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a267:	c7 40 54 00 00 00 00 	movl   $0x0,0x54(%eax)
   1a26e:	c7 40 58 00 00 00 00 	movl   $0x0,0x58(%eax)
	t->timeout_idx    = -1;
   1a275:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a278:	c7 40 5c ff ff ff ff 	movl   $0xffffffff,0x5c(%eax)
	t->prio           = TCAP_PRIO_MIN;
   1a27f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a282:	c7 40 28 ff ff ff ff 	movl   $0xffffffff,0x28(%eax)
   1a289:	c7 40 2c ff ff 00 00 	movl   $0xffff,0x2c(%eax)
	ps_list_init(t, SL_THD_EVENT_LIST);
   1a290:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a293:	83 c0 70             	add    $0x70,%eax
   1a296:	89 04 24             	mov    %eax,(%esp)
   1a299:	e8 fa c9 ff ff       	call   16c98 <ps_list_ll_init>
	sl_thd_event_info_reset(t);
   1a29e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a2a1:	89 04 24             	mov    %eax,(%esp)
   1a2a4:	e8 fc ff ff ff       	call   1a2a5 <sl_thd_alloc_init+0x144>

done:
	return t;
   1a2a9:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a2ac:	c9                   	leave  
   1a2ad:	c3                   	ret    

0001a2ae <sl_thd_alloc_no_cs>:

struct sl_thd *
sl_thd_alloc_no_cs(cos_thd_fn_t fn, void *data)
{
   1a2ae:	55                   	push   %ebp
   1a2af:	89 e5                	mov    %esp,%ebp
   1a2b1:	83 ec 28             	sub    $0x28,%esp
	struct cos_defcompinfo *dci = cos_defcompinfo_curr_get();
   1a2b4:	e8 fc ff ff ff       	call   1a2b5 <sl_thd_alloc_no_cs+0x7>
   1a2b9:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_compinfo    *ci  = cos_compinfo_get(dci);
   1a2bc:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1a2bf:	89 04 24             	mov    %eax,(%esp)
   1a2c2:	e8 fc ff ff ff       	call   1a2c3 <sl_thd_alloc_no_cs+0x15>
   1a2c7:	89 45 ec             	mov    %eax,-0x14(%ebp)
	struct sl_thd          *t   = NULL;
   1a2ca:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct cos_aep_info    *aep = NULL;
   1a2d1:	c7 45 e8 00 00 00 00 	movl   $0x0,-0x18(%ebp)

	aep = sl_thd_alloc_aep_backend();
   1a2d8:	e8 fc ff ff ff       	call   1a2d9 <sl_thd_alloc_no_cs+0x2b>
   1a2dd:	89 45 e8             	mov    %eax,-0x18(%ebp)
	if (!aep) goto done;
   1a2e0:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
   1a2e4:	75 05                	jne    1a2eb <sl_thd_alloc_no_cs+0x3d>
   1a2e6:	e9 9a 00 00 00       	jmp    1a385 <sl_thd_alloc_no_cs+0xd7>

	aep->thd = cos_thd_alloc(ci, ci->comp_cap, fn, data);
   1a2eb:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a2ee:	8b 40 08             	mov    0x8(%eax),%eax
   1a2f1:	8b 55 0c             	mov    0xc(%ebp),%edx
   1a2f4:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1a2f8:	8b 55 08             	mov    0x8(%ebp),%edx
   1a2fb:	89 54 24 08          	mov    %edx,0x8(%esp)
   1a2ff:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a303:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a306:	89 04 24             	mov    %eax,(%esp)
   1a309:	e8 fc ff ff ff       	call   1a30a <sl_thd_alloc_no_cs+0x5c>
   1a30e:	8b 55 e8             	mov    -0x18(%ebp),%edx
   1a311:	89 42 04             	mov    %eax,0x4(%edx)
	if (!aep->thd) goto done;
   1a314:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a317:	8b 40 04             	mov    0x4(%eax),%eax
   1a31a:	85 c0                	test   %eax,%eax
   1a31c:	75 02                	jne    1a320 <sl_thd_alloc_no_cs+0x72>
   1a31e:	eb 65                	jmp    1a385 <sl_thd_alloc_no_cs+0xd7>
	aep->tid = cos_introspect(ci, aep->thd, THD_GET_TID);
   1a320:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a323:	8b 40 04             	mov    0x4(%eax),%eax
   1a326:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a32d:	00 
   1a32e:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a332:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a335:	89 04 24             	mov    %eax,(%esp)
   1a338:	e8 fc ff ff ff       	call   1a339 <sl_thd_alloc_no_cs+0x8b>
   1a33d:	89 c2                	mov    %eax,%edx
   1a33f:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a342:	66 89 50 08          	mov    %dx,0x8(%eax)
	if (!aep->tid) goto done;
   1a346:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a349:	0f b7 40 08          	movzwl 0x8(%eax),%eax
   1a34d:	66 85 c0             	test   %ax,%ax
   1a350:	75 02                	jne    1a354 <sl_thd_alloc_no_cs+0xa6>
   1a352:	eb 31                	jmp    1a385 <sl_thd_alloc_no_cs+0xd7>

	t = sl_thd_alloc_init(aep, 0, 0);
   1a354:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a35b:	00 
   1a35c:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1a363:	00 
   1a364:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a367:	89 04 24             	mov    %eax,(%esp)
   1a36a:	e8 fc ff ff ff       	call   1a36b <sl_thd_alloc_no_cs+0xbd>
   1a36f:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_mod_thd_create(sl_mod_thd_policy_get(t));
   1a372:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a375:	89 04 24             	mov    %eax,(%esp)
   1a378:	e8 18 cf ff ff       	call   17295 <sl_mod_thd_policy_get>
   1a37d:	89 04 24             	mov    %eax,(%esp)
   1a380:	e8 fc ff ff ff       	call   1a381 <sl_thd_alloc_no_cs+0xd3>

done:
	return t;
   1a385:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a388:	c9                   	leave  
   1a389:	c3                   	ret    

0001a38a <sl_thd_comp_init_no_cs>:

static struct sl_thd *
sl_thd_comp_init_no_cs(struct cos_defcompinfo *comp, sl_thd_property_t prps, asndcap_t snd)
{
   1a38a:	55                   	push   %ebp
   1a38b:	89 e5                	mov    %esp,%ebp
   1a38d:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *dci = cos_defcompinfo_curr_get();
   1a390:	e8 fc ff ff ff       	call   1a391 <sl_thd_comp_init_no_cs+0x7>
   1a395:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_compinfo    *ci  = cos_compinfo_get(dci);
   1a398:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1a39b:	89 04 24             	mov    %eax,(%esp)
   1a39e:	e8 fc ff ff ff       	call   1a39f <sl_thd_comp_init_no_cs+0x15>
   1a3a3:	89 45 ec             	mov    %eax,-0x14(%ebp)
	struct cos_aep_info    *sa  = cos_sched_aep_get(comp);
   1a3a6:	8b 45 08             	mov    0x8(%ebp),%eax
   1a3a9:	89 04 24             	mov    %eax,(%esp)
   1a3ac:	e8 fc ff ff ff       	call   1a3ad <sl_thd_comp_init_no_cs+0x23>
   1a3b1:	89 45 e8             	mov    %eax,-0x18(%ebp)
	struct cos_aep_info    *aep = NULL;
   1a3b4:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
	struct sl_thd          *t   = NULL;
   1a3bb:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	aep = sl_thd_alloc_aep_backend();
   1a3c2:	e8 fc ff ff ff       	call   1a3c3 <sl_thd_comp_init_no_cs+0x39>
   1a3c7:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	if (!aep) goto done;
   1a3ca:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1a3ce:	75 05                	jne    1a3d5 <sl_thd_comp_init_no_cs+0x4b>
   1a3d0:	e9 b3 00 00 00       	jmp    1a488 <sl_thd_comp_init_no_cs+0xfe>

	/* copying cos_aep_info is fine here as cos_thd_alloc() is not done using this aep */
	*aep = *sa;
   1a3d5:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1a3d8:	8b 55 e8             	mov    -0x18(%ebp),%edx
   1a3db:	8b 0a                	mov    (%edx),%ecx
   1a3dd:	89 08                	mov    %ecx,(%eax)
   1a3df:	8b 4a 04             	mov    0x4(%edx),%ecx
   1a3e2:	89 48 04             	mov    %ecx,0x4(%eax)
   1a3e5:	8b 4a 08             	mov    0x8(%edx),%ecx
   1a3e8:	89 48 08             	mov    %ecx,0x8(%eax)
   1a3eb:	8b 4a 0c             	mov    0xc(%edx),%ecx
   1a3ee:	89 48 0c             	mov    %ecx,0xc(%eax)
   1a3f1:	8b 4a 10             	mov    0x10(%edx),%ecx
   1a3f4:	89 48 10             	mov    %ecx,0x10(%eax)
   1a3f7:	8b 52 14             	mov    0x14(%edx),%edx
   1a3fa:	89 50 14             	mov    %edx,0x14(%eax)
	if (!snd && (prps & SL_THD_PROPERTY_SEND)) {
   1a3fd:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
   1a401:	75 56                	jne    1a459 <sl_thd_comp_init_no_cs+0xcf>
   1a403:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a406:	83 e0 02             	and    $0x2,%eax
   1a409:	85 c0                	test   %eax,%eax
   1a40b:	74 4c                	je     1a459 <sl_thd_comp_init_no_cs+0xcf>
		snd = cos_asnd_alloc(ci, aep->rcv, ci->captbl_cap);
   1a40d:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a410:	8b 50 04             	mov    0x4(%eax),%edx
   1a413:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1a416:	8b 40 0c             	mov    0xc(%eax),%eax
   1a419:	89 54 24 08          	mov    %edx,0x8(%esp)
   1a41d:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a421:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a424:	89 04 24             	mov    %eax,(%esp)
   1a427:	e8 fc ff ff ff       	call   1a428 <sl_thd_comp_init_no_cs+0x9e>
   1a42c:	89 45 10             	mov    %eax,0x10(%ebp)
		assert(snd);
   1a42f:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
   1a433:	0f 94 c0             	sete   %al
   1a436:	0f b6 c0             	movzbl %al,%eax
   1a439:	85 c0                	test   %eax,%eax
   1a43b:	74 1c                	je     1a459 <sl_thd_comp_init_no_cs+0xcf>
   1a43d:	c7 04 24 98 33 00 00 	movl   $0x3398,(%esp)
   1a444:	e8 cb cb ff ff       	call   17014 <prints>
   1a449:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1a44e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1a454:	e8 42 cc ff ff       	call   1709b <__cos_noret>
	}

	t = sl_thd_alloc_init(aep, snd, prps);
   1a459:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a45c:	89 44 24 08          	mov    %eax,0x8(%esp)
   1a460:	8b 45 10             	mov    0x10(%ebp),%eax
   1a463:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a467:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1a46a:	89 04 24             	mov    %eax,(%esp)
   1a46d:	e8 fc ff ff ff       	call   1a46e <sl_thd_comp_init_no_cs+0xe4>
   1a472:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_mod_thd_create(sl_mod_thd_policy_get(t));
   1a475:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a478:	89 04 24             	mov    %eax,(%esp)
   1a47b:	e8 15 ce ff ff       	call   17295 <sl_mod_thd_policy_get>
   1a480:	89 04 24             	mov    %eax,(%esp)
   1a483:	e8 fc ff ff ff       	call   1a484 <sl_thd_comp_init_no_cs+0xfa>

done:
	return t;
   1a488:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a48b:	c9                   	leave  
   1a48c:	c3                   	ret    

0001a48d <sl_thd_alloc_ext_no_cs>:

static struct sl_thd *
sl_thd_alloc_ext_no_cs(struct cos_defcompinfo *comp, thdclosure_index_t idx)
{
   1a48d:	55                   	push   %ebp
   1a48e:	89 e5                	mov    %esp,%ebp
   1a490:	83 ec 38             	sub    $0x38,%esp
	struct cos_defcompinfo *dci    = cos_defcompinfo_curr_get();
   1a493:	e8 fc ff ff ff       	call   1a494 <sl_thd_alloc_ext_no_cs+0x7>
   1a498:	89 45 f0             	mov    %eax,-0x10(%ebp)
	struct cos_compinfo    *ci     = cos_compinfo_get(dci);
   1a49b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1a49e:	89 04 24             	mov    %eax,(%esp)
   1a4a1:	e8 fc ff ff ff       	call   1a4a2 <sl_thd_alloc_ext_no_cs+0x15>
   1a4a6:	89 45 ec             	mov    %eax,-0x14(%ebp)
	struct cos_compinfo    *compci = cos_compinfo_get(comp);
   1a4a9:	8b 45 08             	mov    0x8(%ebp),%eax
   1a4ac:	89 04 24             	mov    %eax,(%esp)
   1a4af:	e8 fc ff ff ff       	call   1a4b0 <sl_thd_alloc_ext_no_cs+0x23>
   1a4b4:	89 45 e8             	mov    %eax,-0x18(%ebp)
	struct sl_thd          *t      = NULL;
   1a4b7:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct cos_aep_info    *aep    = NULL;
   1a4be:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
	int                     ret;

	if (idx) {
   1a4c5:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1a4c9:	0f 84 ae 00 00 00    	je     1a57d <sl_thd_alloc_ext_no_cs+0xf0>
		aep = sl_thd_alloc_aep_backend();
   1a4cf:	e8 fc ff ff ff       	call   1a4d0 <sl_thd_alloc_ext_no_cs+0x43>
   1a4d4:	89 45 e4             	mov    %eax,-0x1c(%ebp)
		if (!aep) goto done;
   1a4d7:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1a4db:	75 05                	jne    1a4e2 <sl_thd_alloc_ext_no_cs+0x55>
   1a4dd:	e9 09 01 00 00       	jmp    1a5eb <sl_thd_alloc_ext_no_cs+0x15e>

		aep->thd = cos_thd_alloc_ext(ci, compci->comp_cap, idx);
   1a4e2:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a4e5:	8b 40 08             	mov    0x8(%eax),%eax
   1a4e8:	8b 55 0c             	mov    0xc(%ebp),%edx
   1a4eb:	89 54 24 08          	mov    %edx,0x8(%esp)
   1a4ef:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a4f3:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a4f6:	89 04 24             	mov    %eax,(%esp)
   1a4f9:	e8 fc ff ff ff       	call   1a4fa <sl_thd_alloc_ext_no_cs+0x6d>
   1a4fe:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1a501:	89 42 04             	mov    %eax,0x4(%edx)
		if (!aep->thd) goto done;
   1a504:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1a507:	8b 40 04             	mov    0x4(%eax),%eax
   1a50a:	85 c0                	test   %eax,%eax
   1a50c:	75 05                	jne    1a513 <sl_thd_alloc_ext_no_cs+0x86>
   1a50e:	e9 d8 00 00 00       	jmp    1a5eb <sl_thd_alloc_ext_no_cs+0x15e>
		aep->tid = cos_introspect(ci, aep->thd, THD_GET_TID);
   1a513:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1a516:	8b 40 04             	mov    0x4(%eax),%eax
   1a519:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a520:	00 
   1a521:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a525:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a528:	89 04 24             	mov    %eax,(%esp)
   1a52b:	e8 fc ff ff ff       	call   1a52c <sl_thd_alloc_ext_no_cs+0x9f>
   1a530:	89 c2                	mov    %eax,%edx
   1a532:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1a535:	66 89 50 08          	mov    %dx,0x8(%eax)
		if (!aep->tid) goto done;
   1a539:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1a53c:	0f b7 40 08          	movzwl 0x8(%eax),%eax
   1a540:	66 85 c0             	test   %ax,%ax
   1a543:	75 05                	jne    1a54a <sl_thd_alloc_ext_no_cs+0xbd>
   1a545:	e9 a1 00 00 00       	jmp    1a5eb <sl_thd_alloc_ext_no_cs+0x15e>

		t = sl_thd_alloc_init(aep, 0, 0);
   1a54a:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a551:	00 
   1a552:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1a559:	00 
   1a55a:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1a55d:	89 04 24             	mov    %eax,(%esp)
   1a560:	e8 fc ff ff ff       	call   1a561 <sl_thd_alloc_ext_no_cs+0xd4>
   1a565:	89 45 f4             	mov    %eax,-0xc(%ebp)
		sl_mod_thd_create(sl_mod_thd_policy_get(t));
   1a568:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a56b:	89 04 24             	mov    %eax,(%esp)
   1a56e:	e8 22 cd ff ff       	call   17295 <sl_mod_thd_policy_get>
   1a573:	89 04 24             	mov    %eax,(%esp)
   1a576:	e8 fc ff ff ff       	call   1a577 <sl_thd_alloc_ext_no_cs+0xea>
   1a57b:	eb 6e                	jmp    1a5eb <sl_thd_alloc_ext_no_cs+0x15e>
	} else {
		assert(idx == 0);
   1a57d:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1a581:	0f 95 c0             	setne  %al
   1a584:	0f b6 c0             	movzbl %al,%eax
   1a587:	85 c0                	test   %eax,%eax
   1a589:	74 1c                	je     1a5a7 <sl_thd_alloc_ext_no_cs+0x11a>
   1a58b:	c7 04 24 c0 33 00 00 	movl   $0x33c0,(%esp)
   1a592:	e8 7d ca ff ff       	call   17014 <prints>
   1a597:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1a59c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1a5a2:	e8 f4 ca ff ff       	call   1709b <__cos_noret>
		ret = cos_initaep_alloc(comp, NULL, 0);
   1a5a7:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a5ae:	00 
   1a5af:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1a5b6:	00 
   1a5b7:	8b 45 08             	mov    0x8(%ebp),%eax
   1a5ba:	89 04 24             	mov    %eax,(%esp)
   1a5bd:	e8 fc ff ff ff       	call   1a5be <sl_thd_alloc_ext_no_cs+0x131>
   1a5c2:	89 45 e0             	mov    %eax,-0x20(%ebp)
		if (ret) goto done;
   1a5c5:	83 7d e0 00          	cmpl   $0x0,-0x20(%ebp)
   1a5c9:	74 02                	je     1a5cd <sl_thd_alloc_ext_no_cs+0x140>
   1a5cb:	eb 1e                	jmp    1a5eb <sl_thd_alloc_ext_no_cs+0x15e>

		t = sl_thd_comp_init_no_cs(comp, 0, 0);
   1a5cd:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a5d4:	00 
   1a5d5:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1a5dc:	00 
   1a5dd:	8b 45 08             	mov    0x8(%ebp),%eax
   1a5e0:	89 04 24             	mov    %eax,(%esp)
   1a5e3:	e8 a2 fd ff ff       	call   1a38a <sl_thd_comp_init_no_cs>
   1a5e8:	89 45 f4             	mov    %eax,-0xc(%ebp)
	}

done:
	return t;
   1a5eb:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a5ee:	c9                   	leave  
   1a5ef:	c3                   	ret    

0001a5f0 <sl_thd_aep_alloc_no_cs>:

static struct sl_thd *
sl_thd_aep_alloc_no_cs(cos_aepthd_fn_t fn, void *data, sl_thd_property_t prps, cos_channelkey_t key, microsec_t ipiwin, u32_t ipimax)
{
   1a5f0:	55                   	push   %ebp
   1a5f1:	89 e5                	mov    %esp,%ebp
   1a5f3:	83 ec 38             	sub    $0x38,%esp
   1a5f6:	8b 45 14             	mov    0x14(%ebp),%eax
   1a5f9:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   1a5fd:	8b 45 18             	mov    0x18(%ebp),%eax
   1a600:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1a603:	8b 45 1c             	mov    0x1c(%ebp),%eax
   1a606:	89 45 dc             	mov    %eax,-0x24(%ebp)
	struct cos_defcompinfo *dci = cos_defcompinfo_curr_get();
   1a609:	e8 fc ff ff ff       	call   1a60a <sl_thd_aep_alloc_no_cs+0x1a>
   1a60e:	89 45 ec             	mov    %eax,-0x14(%ebp)
	struct sl_thd          *t   = NULL;
   1a611:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct cos_aep_info    *aep = NULL;
   1a618:	c7 45 e8 00 00 00 00 	movl   $0x0,-0x18(%ebp)
	int                     ret;

	aep = sl_thd_alloc_aep_backend();
   1a61f:	e8 fc ff ff ff       	call   1a620 <sl_thd_aep_alloc_no_cs+0x30>
   1a624:	89 45 e8             	mov    %eax,-0x18(%ebp)
	if (!aep) goto done;
   1a627:	83 7d e8 00          	cmpl   $0x0,-0x18(%ebp)
   1a62b:	75 05                	jne    1a632 <sl_thd_aep_alloc_no_cs+0x42>
   1a62d:	e9 92 00 00 00       	jmp    1a6c4 <sl_thd_aep_alloc_no_cs+0xd4>

	/* NOTE: Cannot use stack-allocated cos_aep_info struct here */
	if (prps & SL_THD_PROPERTY_OWN_TCAP) ret = cos_aep_alloc(aep, fn, data);
   1a632:	8b 45 10             	mov    0x10(%ebp),%eax
   1a635:	83 e0 01             	and    $0x1,%eax
   1a638:	85 c0                	test   %eax,%eax
   1a63a:	74 1e                	je     1a65a <sl_thd_aep_alloc_no_cs+0x6a>
   1a63c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a63f:	89 44 24 08          	mov    %eax,0x8(%esp)
   1a643:	8b 45 08             	mov    0x8(%ebp),%eax
   1a646:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a64a:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a64d:	89 04 24             	mov    %eax,(%esp)
   1a650:	e8 fc ff ff ff       	call   1a651 <sl_thd_aep_alloc_no_cs+0x61>
   1a655:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1a658:	eb 32                	jmp    1a68c <sl_thd_aep_alloc_no_cs+0x9c>
	else                                 ret = cos_aep_tcap_alloc(aep, sl_thd_aepinfo(sl__globals_cpu()->sched_thd)->tc,
   1a65a:	e8 51 f7 ff ff       	call   19db0 <sl__globals_cpu>
   1a65f:	8b 40 10             	mov    0x10(%eax),%eax
   1a662:	89 04 24             	mov    %eax,(%esp)
   1a665:	e8 d7 cb ff ff       	call   17241 <sl_thd_aepinfo>
   1a66a:	8b 00                	mov    (%eax),%eax
   1a66c:	8b 55 0c             	mov    0xc(%ebp),%edx
   1a66f:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1a673:	8b 55 08             	mov    0x8(%ebp),%edx
   1a676:	89 54 24 08          	mov    %edx,0x8(%esp)
   1a67a:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a67e:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a681:	89 04 24             	mov    %eax,(%esp)
   1a684:	e8 fc ff ff ff       	call   1a685 <sl_thd_aep_alloc_no_cs+0x95>
   1a689:	89 45 f0             	mov    %eax,-0x10(%ebp)
			                                              fn, data);
	if (ret) goto done;
   1a68c:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
   1a690:	74 02                	je     1a694 <sl_thd_aep_alloc_no_cs+0xa4>
   1a692:	eb 30                	jmp    1a6c4 <sl_thd_aep_alloc_no_cs+0xd4>

	t = sl_thd_alloc_init(aep, 0, prps);
   1a694:	8b 45 10             	mov    0x10(%ebp),%eax
   1a697:	89 44 24 08          	mov    %eax,0x8(%esp)
   1a69b:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1a6a2:	00 
   1a6a3:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1a6a6:	89 04 24             	mov    %eax,(%esp)
   1a6a9:	e8 fc ff ff ff       	call   1a6aa <sl_thd_aep_alloc_no_cs+0xba>
   1a6ae:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_mod_thd_create(sl_mod_thd_policy_get(t));
   1a6b1:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a6b4:	89 04 24             	mov    %eax,(%esp)
   1a6b7:	e8 d9 cb ff ff       	call   17295 <sl_mod_thd_policy_get>
   1a6bc:	89 04 24             	mov    %eax,(%esp)
   1a6bf:	e8 fc ff ff ff       	call   1a6c0 <sl_thd_aep_alloc_no_cs+0xd0>

done:
	return t;
   1a6c4:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a6c7:	c9                   	leave  
   1a6c8:	c3                   	ret    

0001a6c9 <sl_thd_aep_alloc_ext_no_cs>:

static struct sl_thd *
sl_thd_aep_alloc_ext_no_cs(struct cos_defcompinfo *comp, struct sl_thd *sched, thdclosure_index_t idx, sl_thd_property_t prps, cos_channelkey_t key, microsec_t ipiwin, u32_t ipimax, arcvcap_t *extrcv)
{
   1a6c9:	55                   	push   %ebp
   1a6ca:	89 e5                	mov    %esp,%ebp
   1a6cc:	53                   	push   %ebx
   1a6cd:	83 ec 44             	sub    $0x44,%esp
   1a6d0:	8b 45 18             	mov    0x18(%ebp),%eax
   1a6d3:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   1a6d7:	8b 45 1c             	mov    0x1c(%ebp),%eax
   1a6da:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1a6dd:	8b 45 20             	mov    0x20(%ebp),%eax
   1a6e0:	89 45 dc             	mov    %eax,-0x24(%ebp)
	struct cos_aep_info *aep = NULL;
   1a6e3:	c7 45 ec 00 00 00 00 	movl   $0x0,-0x14(%ebp)
	struct sl_thd       *t   = NULL;
   1a6ea:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	asndcap_t            snd = 0;
   1a6f1:	c7 45 e8 00 00 00 00 	movl   $0x0,-0x18(%ebp)
	int                  ret = 0;
   1a6f8:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)

	if (prps & SL_THD_PROPERTY_SEND) {
   1a6ff:	8b 45 14             	mov    0x14(%ebp),%eax
   1a702:	83 e0 02             	and    $0x2,%eax
   1a705:	85 c0                	test   %eax,%eax
   1a707:	0f 84 ba 00 00 00    	je     1a7c7 <sl_thd_aep_alloc_ext_no_cs+0xfe>
		assert(sched);
   1a70d:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1a711:	0f 94 c0             	sete   %al
   1a714:	0f b6 c0             	movzbl %al,%eax
   1a717:	85 c0                	test   %eax,%eax
   1a719:	74 1c                	je     1a737 <sl_thd_aep_alloc_ext_no_cs+0x6e>
   1a71b:	c7 04 24 e8 33 00 00 	movl   $0x33e8,(%esp)
   1a722:	e8 ed c8 ff ff       	call   17014 <prints>
   1a727:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1a72c:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1a732:	e8 64 c9 ff ff       	call   1709b <__cos_noret>
		if (prps & SL_THD_PROPERTY_OWN_TCAP) {
   1a737:	8b 45 14             	mov    0x14(%ebp),%eax
   1a73a:	83 e0 01             	and    $0x1,%eax
   1a73d:	85 c0                	test   %eax,%eax
   1a73f:	74 2b                	je     1a76c <sl_thd_aep_alloc_ext_no_cs+0xa3>
			ret = cos_initaep_alloc(comp, sl_thd_aepinfo(sched), prps & SL_THD_PROPERTY_SEND);
   1a741:	8b 45 14             	mov    0x14(%ebp),%eax
   1a744:	83 e0 02             	and    $0x2,%eax
   1a747:	89 c3                	mov    %eax,%ebx
   1a749:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a74c:	89 04 24             	mov    %eax,(%esp)
   1a74f:	e8 ed ca ff ff       	call   17241 <sl_thd_aepinfo>
   1a754:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1a758:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a75c:	8b 45 08             	mov    0x8(%ebp),%eax
   1a75f:	89 04 24             	mov    %eax,(%esp)
   1a762:	e8 fc ff ff ff       	call   1a763 <sl_thd_aep_alloc_ext_no_cs+0x9a>
   1a767:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1a76a:	eb 2e                	jmp    1a79a <sl_thd_aep_alloc_ext_no_cs+0xd1>
		} else {
			ret = cos_initaep_tcap_alloc(comp, sl_thd_tcap(sched), sl_thd_aepinfo(sched));
   1a76c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a76f:	89 04 24             	mov    %eax,(%esp)
   1a772:	e8 ca ca ff ff       	call   17241 <sl_thd_aepinfo>
   1a777:	89 c3                	mov    %eax,%ebx
   1a779:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a77c:	89 04 24             	mov    %eax,(%esp)
   1a77f:	e8 de ca ff ff       	call   17262 <sl_thd_tcap>
   1a784:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1a788:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a78c:	8b 45 08             	mov    0x8(%ebp),%eax
   1a78f:	89 04 24             	mov    %eax,(%esp)
   1a792:	e8 fc ff ff ff       	call   1a793 <sl_thd_aep_alloc_ext_no_cs+0xca>
   1a797:	89 45 f0             	mov    %eax,-0x10(%ebp)
		}
		if (ret) goto done;
   1a79a:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
   1a79e:	74 05                	je     1a7a5 <sl_thd_aep_alloc_ext_no_cs+0xdc>
   1a7a0:	e9 4a 01 00 00       	jmp    1a8ef <sl_thd_aep_alloc_ext_no_cs+0x226>

		t = sl_thd_comp_init_no_cs(comp, prps, 0);
   1a7a5:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a7ac:	00 
   1a7ad:	8b 45 14             	mov    0x14(%ebp),%eax
   1a7b0:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a7b4:	8b 45 08             	mov    0x8(%ebp),%eax
   1a7b7:	89 04 24             	mov    %eax,(%esp)
   1a7ba:	e8 cb fb ff ff       	call   1a38a <sl_thd_comp_init_no_cs>
   1a7bf:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1a7c2:	e9 28 01 00 00       	jmp    1a8ef <sl_thd_aep_alloc_ext_no_cs+0x226>
	} else {
		assert(idx > 0);
   1a7c7:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
   1a7cb:	0f 9e c0             	setle  %al
   1a7ce:	0f b6 c0             	movzbl %al,%eax
   1a7d1:	85 c0                	test   %eax,%eax
   1a7d3:	74 1c                	je     1a7f1 <sl_thd_aep_alloc_ext_no_cs+0x128>
   1a7d5:	c7 04 24 10 34 00 00 	movl   $0x3410,(%esp)
   1a7dc:	e8 33 c8 ff ff       	call   17014 <prints>
   1a7e1:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1a7e6:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1a7ec:	e8 aa c8 ff ff       	call   1709b <__cos_noret>
		assert(sched);
   1a7f1:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1a7f5:	0f 94 c0             	sete   %al
   1a7f8:	0f b6 c0             	movzbl %al,%eax
   1a7fb:	85 c0                	test   %eax,%eax
   1a7fd:	74 1c                	je     1a81b <sl_thd_aep_alloc_ext_no_cs+0x152>
   1a7ff:	c7 04 24 38 34 00 00 	movl   $0x3438,(%esp)
   1a806:	e8 09 c8 ff ff       	call   17014 <prints>
   1a80b:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1a810:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1a816:	e8 80 c8 ff ff       	call   1709b <__cos_noret>
		aep = sl_thd_alloc_aep_backend();
   1a81b:	e8 fc ff ff ff       	call   1a81c <sl_thd_aep_alloc_ext_no_cs+0x153>
   1a820:	89 45 ec             	mov    %eax,-0x14(%ebp)
		if (!aep) goto done;
   1a823:	83 7d ec 00          	cmpl   $0x0,-0x14(%ebp)
   1a827:	75 05                	jne    1a82e <sl_thd_aep_alloc_ext_no_cs+0x165>
   1a829:	e9 c1 00 00 00       	jmp    1a8ef <sl_thd_aep_alloc_ext_no_cs+0x226>

		if (prps & SL_THD_PROPERTY_OWN_TCAP) {
   1a82e:	8b 45 14             	mov    0x14(%ebp),%eax
   1a831:	83 e0 01             	and    $0x1,%eax
   1a834:	85 c0                	test   %eax,%eax
   1a836:	74 2d                	je     1a865 <sl_thd_aep_alloc_ext_no_cs+0x19c>
			ret = cos_aep_alloc_ext(aep, comp, sl_thd_aepinfo(sched), idx);
   1a838:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a83b:	89 04 24             	mov    %eax,(%esp)
   1a83e:	e8 fe c9 ff ff       	call   17241 <sl_thd_aepinfo>
   1a843:	8b 55 10             	mov    0x10(%ebp),%edx
   1a846:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1a84a:	89 44 24 08          	mov    %eax,0x8(%esp)
   1a84e:	8b 45 08             	mov    0x8(%ebp),%eax
   1a851:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a855:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a858:	89 04 24             	mov    %eax,(%esp)
   1a85b:	e8 fc ff ff ff       	call   1a85c <sl_thd_aep_alloc_ext_no_cs+0x193>
   1a860:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1a863:	eb 3c                	jmp    1a8a1 <sl_thd_aep_alloc_ext_no_cs+0x1d8>
		} else {
			ret = cos_aep_tcap_alloc_ext(aep, comp, sl_thd_aepinfo(sched), sl_thd_tcap(sched), idx);
   1a865:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a868:	89 04 24             	mov    %eax,(%esp)
   1a86b:	e8 f2 c9 ff ff       	call   17262 <sl_thd_tcap>
   1a870:	89 c3                	mov    %eax,%ebx
   1a872:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a875:	89 04 24             	mov    %eax,(%esp)
   1a878:	e8 c4 c9 ff ff       	call   17241 <sl_thd_aepinfo>
   1a87d:	8b 55 10             	mov    0x10(%ebp),%edx
   1a880:	89 54 24 10          	mov    %edx,0x10(%esp)
   1a884:	89 5c 24 0c          	mov    %ebx,0xc(%esp)
   1a888:	89 44 24 08          	mov    %eax,0x8(%esp)
   1a88c:	8b 45 08             	mov    0x8(%ebp),%eax
   1a88f:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a893:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a896:	89 04 24             	mov    %eax,(%esp)
   1a899:	e8 fc ff ff ff       	call   1a89a <sl_thd_aep_alloc_ext_no_cs+0x1d1>
   1a89e:	89 45 f0             	mov    %eax,-0x10(%ebp)
		}
		if (ret) goto done;
   1a8a1:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
   1a8a5:	74 02                	je     1a8a9 <sl_thd_aep_alloc_ext_no_cs+0x1e0>
   1a8a7:	eb 46                	jmp    1a8ef <sl_thd_aep_alloc_ext_no_cs+0x226>

		t = sl_thd_alloc_init(aep, 0, prps);
   1a8a9:	8b 45 14             	mov    0x14(%ebp),%eax
   1a8ac:	89 44 24 08          	mov    %eax,0x8(%esp)
   1a8b0:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1a8b7:	00 
   1a8b8:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1a8bb:	89 04 24             	mov    %eax,(%esp)
   1a8be:	e8 fc ff ff ff       	call   1a8bf <sl_thd_aep_alloc_ext_no_cs+0x1f6>
   1a8c3:	89 45 f4             	mov    %eax,-0xc(%ebp)
		sl_mod_thd_create(sl_mod_thd_policy_get(t));
   1a8c6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a8c9:	89 04 24             	mov    %eax,(%esp)
   1a8cc:	e8 c4 c9 ff ff       	call   17295 <sl_mod_thd_policy_get>
   1a8d1:	89 04 24             	mov    %eax,(%esp)
   1a8d4:	e8 fc ff ff ff       	call   1a8d5 <sl_thd_aep_alloc_ext_no_cs+0x20c>

		if (extrcv) *extrcv = sl_thd_rcvcap(t);
   1a8d9:	83 7d 28 00          	cmpl   $0x0,0x28(%ebp)
   1a8dd:	74 10                	je     1a8ef <sl_thd_aep_alloc_ext_no_cs+0x226>
   1a8df:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1a8e2:	89 04 24             	mov    %eax,(%esp)
   1a8e5:	e8 8d c9 ff ff       	call   17277 <sl_thd_rcvcap>
   1a8ea:	8b 55 28             	mov    0x28(%ebp),%edx
   1a8ed:	89 02                	mov    %eax,(%edx)
	}

done:
	return t;
   1a8ef:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a8f2:	83 c4 44             	add    $0x44,%esp
   1a8f5:	5b                   	pop    %ebx
   1a8f6:	5d                   	pop    %ebp
   1a8f7:	c3                   	ret    

0001a8f8 <sl_thd_alloc>:

struct sl_thd *
sl_thd_alloc(cos_thd_fn_t fn, void *data)
{
   1a8f8:	55                   	push   %ebp
   1a8f9:	89 e5                	mov    %esp,%ebp
   1a8fb:	83 ec 28             	sub    $0x28,%esp
	struct sl_thd *t = NULL;
   1a8fe:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	sl_cs_enter();
   1a905:	e8 b7 f6 ff ff       	call   19fc1 <sl_cs_enter>
	t = sl_thd_alloc_no_cs(fn, data);
   1a90a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a90d:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a911:	8b 45 08             	mov    0x8(%ebp),%eax
   1a914:	89 04 24             	mov    %eax,(%esp)
   1a917:	e8 fc ff ff ff       	call   1a918 <sl_thd_alloc+0x20>
   1a91c:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_cs_exit();
   1a91f:	e8 af f6 ff ff       	call   19fd3 <sl_cs_exit>

	return t;
   1a924:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a927:	c9                   	leave  
   1a928:	c3                   	ret    

0001a929 <sl_thd_aep_alloc>:

struct sl_thd *
sl_thd_aep_alloc(cos_aepthd_fn_t fn, void *data, int own_tcap, cos_channelkey_t key, microsec_t ipiwin, u32_t ipimax)
{
   1a929:	55                   	push   %ebp
   1a92a:	89 e5                	mov    %esp,%ebp
   1a92c:	83 ec 48             	sub    $0x48,%esp
   1a92f:	8b 45 14             	mov    0x14(%ebp),%eax
   1a932:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   1a936:	8b 45 18             	mov    0x18(%ebp),%eax
   1a939:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1a93c:	8b 45 1c             	mov    0x1c(%ebp),%eax
   1a93f:	89 45 dc             	mov    %eax,-0x24(%ebp)
	struct sl_thd *t = NULL;
   1a942:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	sl_cs_enter();
   1a949:	e8 73 f6 ff ff       	call   19fc1 <sl_cs_enter>
	t = sl_thd_aep_alloc_no_cs(fn, data, own_tcap ? SL_THD_PROPERTY_OWN_TCAP : 0, 0, ipiwin, ipimax);
   1a94e:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
   1a952:	0f 95 c0             	setne  %al
   1a955:	0f b6 c8             	movzbl %al,%ecx
   1a958:	8b 45 20             	mov    0x20(%ebp),%eax
   1a95b:	89 44 24 18          	mov    %eax,0x18(%esp)
   1a95f:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1a962:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1a965:	89 44 24 10          	mov    %eax,0x10(%esp)
   1a969:	89 54 24 14          	mov    %edx,0x14(%esp)
   1a96d:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   1a974:	00 
   1a975:	89 4c 24 08          	mov    %ecx,0x8(%esp)
   1a979:	8b 45 0c             	mov    0xc(%ebp),%eax
   1a97c:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a980:	8b 45 08             	mov    0x8(%ebp),%eax
   1a983:	89 04 24             	mov    %eax,(%esp)
   1a986:	e8 65 fc ff ff       	call   1a5f0 <sl_thd_aep_alloc_no_cs>
   1a98b:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_cs_exit();
   1a98e:	e8 40 f6 ff ff       	call   19fd3 <sl_cs_exit>

	return t;
   1a993:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a996:	c9                   	leave  
   1a997:	c3                   	ret    

0001a998 <sl_thd_comp_init>:

/* sl object for inithd in the child comp */
struct sl_thd *
sl_thd_comp_init(struct cos_defcompinfo *comp, int is_sched)
{
   1a998:	55                   	push   %ebp
   1a999:	89 e5                	mov    %esp,%ebp
   1a99b:	83 ec 28             	sub    $0x28,%esp
	struct sl_thd *t = NULL;
   1a99e:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	if (!comp) return NULL;
   1a9a5:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1a9a9:	75 07                	jne    1a9b2 <sl_thd_comp_init+0x1a>
   1a9ab:	b8 00 00 00 00       	mov    $0x0,%eax
   1a9b0:	eb 39                	jmp    1a9eb <sl_thd_comp_init+0x53>

	sl_cs_enter();
   1a9b2:	e8 0a f6 ff ff       	call   19fc1 <sl_cs_enter>
	t = sl_thd_comp_init_no_cs(comp, is_sched ? SL_THD_PROPERTY_OWN_TCAP | SL_THD_PROPERTY_SEND : 0, 0);
   1a9b7:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1a9bb:	74 07                	je     1a9c4 <sl_thd_comp_init+0x2c>
   1a9bd:	b8 03 00 00 00       	mov    $0x3,%eax
   1a9c2:	eb 05                	jmp    1a9c9 <sl_thd_comp_init+0x31>
   1a9c4:	b8 00 00 00 00       	mov    $0x0,%eax
   1a9c9:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1a9d0:	00 
   1a9d1:	89 44 24 04          	mov    %eax,0x4(%esp)
   1a9d5:	8b 45 08             	mov    0x8(%ebp),%eax
   1a9d8:	89 04 24             	mov    %eax,(%esp)
   1a9db:	e8 aa f9 ff ff       	call   1a38a <sl_thd_comp_init_no_cs>
   1a9e0:	89 45 f4             	mov    %eax,-0xc(%ebp)
	sl_cs_exit();
   1a9e3:	e8 eb f5 ff ff       	call   19fd3 <sl_cs_exit>

	return t;
   1a9e8:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1a9eb:	c9                   	leave  
   1a9ec:	c3                   	ret    

0001a9ed <sl_thd_initaep_alloc>:

struct sl_thd *
sl_thd_initaep_alloc(struct cos_defcompinfo *comp, struct sl_thd *sched_thd, int is_sched, int own_tcap, cos_channelkey_t key, microsec_t ipiwin, u32_t ipimax)
{
   1a9ed:	55                   	push   %ebp
   1a9ee:	89 e5                	mov    %esp,%ebp
   1a9f0:	53                   	push   %ebx
   1a9f1:	83 ec 54             	sub    $0x54,%esp
   1a9f4:	8b 45 18             	mov    0x18(%ebp),%eax
   1a9f7:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   1a9fb:	8b 45 1c             	mov    0x1c(%ebp),%eax
   1a9fe:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1aa01:	8b 45 20             	mov    0x20(%ebp),%eax
   1aa04:	89 45 dc             	mov    %eax,-0x24(%ebp)
	struct sl_thd *t = NULL;
   1aa07:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	if (!comp) return NULL;
   1aa0e:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1aa12:	75 0a                	jne    1aa1e <sl_thd_initaep_alloc+0x31>
   1aa14:	b8 00 00 00 00       	mov    $0x0,%eax
   1aa19:	e9 91 00 00 00       	jmp    1aaaf <sl_thd_initaep_alloc+0xc2>

	sl_cs_enter();
   1aa1e:	e8 9e f5 ff ff       	call   19fc1 <sl_cs_enter>
	if (!is_sched) t = sl_thd_alloc_ext_no_cs(comp, 0);
   1aa23:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
   1aa27:	75 18                	jne    1aa41 <sl_thd_initaep_alloc+0x54>
   1aa29:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1aa30:	00 
   1aa31:	8b 45 08             	mov    0x8(%ebp),%eax
   1aa34:	89 04 24             	mov    %eax,(%esp)
   1aa37:	e8 51 fa ff ff       	call   1a48d <sl_thd_alloc_ext_no_cs>
   1aa3c:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1aa3f:	eb 66                	jmp    1aaa7 <sl_thd_initaep_alloc+0xba>
	else           t = sl_thd_aep_alloc_ext_no_cs(comp, sched_thd, 0, (is_sched ? SL_THD_PROPERTY_SEND : 0)
   1aa41:	0f b7 5d e4          	movzwl -0x1c(%ebp),%ebx
   1aa45:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
   1aa49:	74 07                	je     1aa52 <sl_thd_initaep_alloc+0x65>
   1aa4b:	b8 02 00 00 00       	mov    $0x2,%eax
   1aa50:	eb 05                	jmp    1aa57 <sl_thd_initaep_alloc+0x6a>
   1aa52:	b8 00 00 00 00       	mov    $0x0,%eax
						      | (own_tcap ? SL_THD_PROPERTY_OWN_TCAP : 0), key, ipiwin, ipimax, NULL);
   1aa57:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
   1aa5b:	0f 95 c2             	setne  %dl
   1aa5e:	0f b6 d2             	movzbl %dl,%edx
   1aa61:	09 d0                	or     %edx,%eax

	if (!comp) return NULL;

	sl_cs_enter();
	if (!is_sched) t = sl_thd_alloc_ext_no_cs(comp, 0);
	else           t = sl_thd_aep_alloc_ext_no_cs(comp, sched_thd, 0, (is_sched ? SL_THD_PROPERTY_SEND : 0)
   1aa63:	89 c1                	mov    %eax,%ecx
   1aa65:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   1aa6c:	00 
   1aa6d:	8b 45 24             	mov    0x24(%ebp),%eax
   1aa70:	89 44 24 1c          	mov    %eax,0x1c(%esp)
   1aa74:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1aa77:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1aa7a:	89 44 24 14          	mov    %eax,0x14(%esp)
   1aa7e:	89 54 24 18          	mov    %edx,0x18(%esp)
   1aa82:	89 5c 24 10          	mov    %ebx,0x10(%esp)
   1aa86:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1aa8a:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1aa91:	00 
   1aa92:	8b 45 0c             	mov    0xc(%ebp),%eax
   1aa95:	89 44 24 04          	mov    %eax,0x4(%esp)
   1aa99:	8b 45 08             	mov    0x8(%ebp),%eax
   1aa9c:	89 04 24             	mov    %eax,(%esp)
   1aa9f:	e8 25 fc ff ff       	call   1a6c9 <sl_thd_aep_alloc_ext_no_cs>
   1aaa4:	89 45 f4             	mov    %eax,-0xc(%ebp)
						      | (own_tcap ? SL_THD_PROPERTY_OWN_TCAP : 0), key, ipiwin, ipimax, NULL);
	sl_cs_exit();
   1aaa7:	e8 27 f5 ff ff       	call   19fd3 <sl_cs_exit>

	return t;
   1aaac:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1aaaf:	83 c4 54             	add    $0x54,%esp
   1aab2:	5b                   	pop    %ebx
   1aab3:	5d                   	pop    %ebp
   1aab4:	c3                   	ret    

0001aab5 <sl_thd_aep_alloc_ext>:

struct sl_thd *
sl_thd_aep_alloc_ext(struct cos_defcompinfo *comp, struct sl_thd *sched_thd, thdclosure_index_t idx, int is_aep, int own_tcap, cos_channelkey_t key, microsec_t ipiwin, u32_t ipimax, arcvcap_t *extrcv)
{
   1aab5:	55                   	push   %ebp
   1aab6:	89 e5                	mov    %esp,%ebp
   1aab8:	53                   	push   %ebx
   1aab9:	83 ec 54             	sub    $0x54,%esp
   1aabc:	8b 45 1c             	mov    0x1c(%ebp),%eax
   1aabf:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   1aac3:	8b 45 20             	mov    0x20(%ebp),%eax
   1aac6:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1aac9:	8b 45 24             	mov    0x24(%ebp),%eax
   1aacc:	89 45 dc             	mov    %eax,-0x24(%ebp)
	struct sl_thd *t = NULL;
   1aacf:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	if (!comp || idx <= 0) return NULL;
   1aad6:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1aada:	74 06                	je     1aae2 <sl_thd_aep_alloc_ext+0x2d>
   1aadc:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
   1aae0:	7f 0a                	jg     1aaec <sl_thd_aep_alloc_ext+0x37>
   1aae2:	b8 00 00 00 00       	mov    $0x0,%eax
   1aae7:	e9 85 00 00 00       	jmp    1ab71 <sl_thd_aep_alloc_ext+0xbc>
	sl_cs_enter();
   1aaec:	e8 d0 f4 ff ff       	call   19fc1 <sl_cs_enter>
	if (!is_aep) own_tcap = 0;
   1aaf1:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
   1aaf5:	75 07                	jne    1aafe <sl_thd_aep_alloc_ext+0x49>
   1aaf7:	c7 45 18 00 00 00 00 	movl   $0x0,0x18(%ebp)
	if (is_aep) {
   1aafe:	83 7d 14 00          	cmpl   $0x0,0x14(%ebp)
   1ab02:	74 50                	je     1ab54 <sl_thd_aep_alloc_ext+0x9f>
		t = sl_thd_aep_alloc_ext_no_cs(comp, sched_thd, idx, own_tcap ? SL_THD_PROPERTY_OWN_TCAP : 0, key, ipiwin, ipimax, extrcv);
   1ab04:	0f b7 5d e4          	movzwl -0x1c(%ebp),%ebx
   1ab08:	83 7d 18 00          	cmpl   $0x0,0x18(%ebp)
   1ab0c:	0f 95 c0             	setne  %al
   1ab0f:	0f b6 c8             	movzbl %al,%ecx
   1ab12:	8b 45 2c             	mov    0x2c(%ebp),%eax
   1ab15:	89 44 24 20          	mov    %eax,0x20(%esp)
   1ab19:	8b 45 28             	mov    0x28(%ebp),%eax
   1ab1c:	89 44 24 1c          	mov    %eax,0x1c(%esp)
   1ab20:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1ab23:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1ab26:	89 44 24 14          	mov    %eax,0x14(%esp)
   1ab2a:	89 54 24 18          	mov    %edx,0x18(%esp)
   1ab2e:	89 5c 24 10          	mov    %ebx,0x10(%esp)
   1ab32:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1ab36:	8b 45 10             	mov    0x10(%ebp),%eax
   1ab39:	89 44 24 08          	mov    %eax,0x8(%esp)
   1ab3d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ab40:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ab44:	8b 45 08             	mov    0x8(%ebp),%eax
   1ab47:	89 04 24             	mov    %eax,(%esp)
   1ab4a:	e8 7a fb ff ff       	call   1a6c9 <sl_thd_aep_alloc_ext_no_cs>
   1ab4f:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1ab52:	eb 15                	jmp    1ab69 <sl_thd_aep_alloc_ext+0xb4>
	} else {
		t = sl_thd_alloc_ext_no_cs(comp, idx);
   1ab54:	8b 45 10             	mov    0x10(%ebp),%eax
   1ab57:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ab5b:	8b 45 08             	mov    0x8(%ebp),%eax
   1ab5e:	89 04 24             	mov    %eax,(%esp)
   1ab61:	e8 27 f9 ff ff       	call   1a48d <sl_thd_alloc_ext_no_cs>
   1ab66:	89 45 f4             	mov    %eax,-0xc(%ebp)
	}
	sl_cs_exit();
   1ab69:	e8 65 f4 ff ff       	call   19fd3 <sl_cs_exit>

	return t;
   1ab6e:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1ab71:	83 c4 54             	add    $0x54,%esp
   1ab74:	5b                   	pop    %ebx
   1ab75:	5d                   	pop    %ebp
   1ab76:	c3                   	ret    

0001ab77 <sl_thd_init_ext>:

struct sl_thd *
sl_thd_init_ext(struct cos_aep_info *aepthd, struct sl_thd *sched)
{
   1ab77:	55                   	push   %ebp
   1ab78:	89 e5                	mov    %esp,%ebp
   1ab7a:	83 ec 28             	sub    $0x28,%esp
	struct sl_thd       *t   = NULL;
   1ab7d:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
	struct cos_aep_info *aep = NULL;
   1ab84:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)

	if (!aepthd || !aepthd->thd || !aepthd->tid) return NULL;
   1ab8b:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1ab8f:	74 16                	je     1aba7 <sl_thd_init_ext+0x30>
   1ab91:	8b 45 08             	mov    0x8(%ebp),%eax
   1ab94:	8b 40 04             	mov    0x4(%eax),%eax
   1ab97:	85 c0                	test   %eax,%eax
   1ab99:	74 0c                	je     1aba7 <sl_thd_init_ext+0x30>
   1ab9b:	8b 45 08             	mov    0x8(%ebp),%eax
   1ab9e:	0f b7 40 08          	movzwl 0x8(%eax),%eax
   1aba2:	66 85 c0             	test   %ax,%ax
   1aba5:	75 07                	jne    1abae <sl_thd_init_ext+0x37>
   1aba7:	b8 00 00 00 00       	mov    $0x0,%eax
   1abac:	eb 63                	jmp    1ac11 <sl_thd_init_ext+0x9a>

	sl_cs_enter();
   1abae:	e8 0e f4 ff ff       	call   19fc1 <sl_cs_enter>
	aep = sl_thd_alloc_aep_backend();
   1abb3:	e8 fc ff ff ff       	call   1abb4 <sl_thd_init_ext+0x3d>
   1abb8:	89 45 f0             	mov    %eax,-0x10(%ebp)
	if (!aep) goto done;
   1abbb:	83 7d f0 00          	cmpl   $0x0,-0x10(%ebp)
   1abbf:	75 02                	jne    1abc3 <sl_thd_init_ext+0x4c>
   1abc1:	eb 46                	jmp    1ac09 <sl_thd_init_ext+0x92>

	*aep = *aepthd;
   1abc3:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1abc6:	8b 55 08             	mov    0x8(%ebp),%edx
   1abc9:	8b 0a                	mov    (%edx),%ecx
   1abcb:	89 08                	mov    %ecx,(%eax)
   1abcd:	8b 4a 04             	mov    0x4(%edx),%ecx
   1abd0:	89 48 04             	mov    %ecx,0x4(%eax)
   1abd3:	8b 4a 08             	mov    0x8(%edx),%ecx
   1abd6:	89 48 08             	mov    %ecx,0x8(%eax)
   1abd9:	8b 4a 0c             	mov    0xc(%edx),%ecx
   1abdc:	89 48 0c             	mov    %ecx,0xc(%eax)
   1abdf:	8b 4a 10             	mov    0x10(%edx),%ecx
   1abe2:	89 48 10             	mov    %ecx,0x10(%eax)
   1abe5:	8b 52 14             	mov    0x14(%edx),%edx
   1abe8:	89 50 14             	mov    %edx,0x14(%eax)
	/* TODO: use sched info for parent -> child notifications */
	t = sl_thd_alloc_init(aep, 0, 0);
   1abeb:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   1abf2:	00 
   1abf3:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1abfa:	00 
   1abfb:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1abfe:	89 04 24             	mov    %eax,(%esp)
   1ac01:	e8 fc ff ff ff       	call   1ac02 <sl_thd_init_ext+0x8b>
   1ac06:	89 45 f4             	mov    %eax,-0xc(%ebp)

done:
	sl_cs_exit();
   1ac09:	e8 c5 f3 ff ff       	call   19fd3 <sl_cs_exit>

	return t;
   1ac0e:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1ac11:	c9                   	leave  
   1ac12:	c3                   	ret    

0001ac13 <sl_thd_retrieve>:

struct sl_thd *
sl_thd_retrieve(thdid_t tid)
{
   1ac13:	55                   	push   %ebp
   1ac14:	89 e5                	mov    %esp,%ebp
   1ac16:	83 ec 18             	sub    $0x18,%esp
   1ac19:	8b 45 08             	mov    0x8(%ebp),%eax
   1ac1c:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	return sl_mod_thd_get(sl_thd_lookup_backend(tid));
   1ac20:	0f b7 45 f4          	movzwl -0xc(%ebp),%eax
   1ac24:	89 04 24             	mov    %eax,(%esp)
   1ac27:	e8 fc ff ff ff       	call   1ac28 <sl_thd_retrieve+0x15>
   1ac2c:	89 04 24             	mov    %eax,(%esp)
   1ac2f:	e8 59 c6 ff ff       	call   1728d <sl_mod_thd_get>
}
   1ac34:	c9                   	leave  
   1ac35:	c3                   	ret    

0001ac36 <sl_thd_free>:

void
sl_thd_free(struct sl_thd *t)
{
   1ac36:	55                   	push   %ebp
   1ac37:	89 e5                	mov    %esp,%ebp
   1ac39:	83 ec 18             	sub    $0x18,%esp
	assert(t);
   1ac3c:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1ac40:	0f 94 c0             	sete   %al
   1ac43:	0f b6 c0             	movzbl %al,%eax
   1ac46:	85 c0                	test   %eax,%eax
   1ac48:	74 1c                	je     1ac66 <sl_thd_free+0x30>
   1ac4a:	c7 04 24 60 34 00 00 	movl   $0x3460,(%esp)
   1ac51:	e8 be c3 ff ff       	call   17014 <prints>
   1ac56:	a1 ac 02 00 00       	mov    0x2ac,%eax
   1ac5b:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1ac61:	e8 35 c4 ff ff       	call   1709b <__cos_noret>

	sl_cs_enter();
   1ac66:	e8 56 f3 ff ff       	call   19fc1 <sl_cs_enter>
	sl_thd_free_no_cs(t);
   1ac6b:	8b 45 08             	mov    0x8(%ebp),%eax
   1ac6e:	89 04 24             	mov    %eax,(%esp)
   1ac71:	e8 fc ff ff ff       	call   1ac72 <sl_thd_free+0x3c>
	sl_cs_exit();
   1ac76:	e8 58 f3 ff ff       	call   19fd3 <sl_cs_exit>
}
   1ac7b:	c9                   	leave  
   1ac7c:	c3                   	ret    
   1ac7d:	66 90                	xchg   %ax,%ax
   1ac7f:	90                   	nop

0001ac80 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
   1ac80:	55                   	push   %ebp
   1ac81:	89 e5                	mov    %esp,%ebp
   1ac83:	57                   	push   %edi
   1ac84:	56                   	push   %esi
   1ac85:	53                   	push   %ebx
   1ac86:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
   1ac89:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
   1ac90:	8b 45 08             	mov    0x8(%ebp),%eax
   1ac93:	83 c0 01             	add    $0x1,%eax
   1ac96:	c1 e0 10             	shl    $0x10,%eax
   1ac99:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
   1ac9c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ac9f:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
   1aca2:	8b 45 08             	mov    0x8(%ebp),%eax
   1aca5:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1aca8:	8b 75 14             	mov    0x14(%ebp),%esi
   1acab:	8b 7d 18             	mov    0x18(%ebp),%edi
   1acae:	8b 55 1c             	mov    0x1c(%ebp),%edx
   1acb1:	89 cb                	mov    %ecx,%ebx
   1acb3:	55                   	push   %ebp
   1acb4:	89 e5                	mov    %esp,%ebp
   1acb6:	b9 c8 ac 01 00       	mov    $0x1acc8,%ecx
   1acbb:	0f 34                	sysenter 
   1acbd:	8d 76 00             	lea    0x0(%esi),%esi
   1acc0:	eb 0d                	jmp    1accf <call_cap_asm+0x4f>
   1acc2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   1acc8:	b9 00 00 00 00       	mov    $0x0,%ecx
   1accd:	eb 05                	jmp    1acd4 <call_cap_asm+0x54>
   1accf:	b9 01 00 00 00       	mov    $0x1,%ecx
   1acd4:	5d                   	pop    %ebp
   1acd5:	89 ca                	mov    %ecx,%edx
   1acd7:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1acda:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
   1acdd:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
   1ace0:	83 c4 10             	add    $0x10,%esp
   1ace3:	5b                   	pop    %ebx
   1ace4:	5e                   	pop    %esi
   1ace5:	5f                   	pop    %edi
   1ace6:	5d                   	pop    %ebp
   1ace7:	c3                   	ret    

0001ace8 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
   1ace8:	55                   	push   %ebp
   1ace9:	89 e5                	mov    %esp,%ebp
   1aceb:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
   1acee:	8b 45 18             	mov    0x18(%ebp),%eax
   1acf1:	89 44 24 14          	mov    %eax,0x14(%esp)
   1acf5:	8b 45 14             	mov    0x14(%ebp),%eax
   1acf8:	89 44 24 10          	mov    %eax,0x10(%esp)
   1acfc:	8b 45 10             	mov    0x10(%ebp),%eax
   1acff:	89 44 24 0c          	mov    %eax,0xc(%esp)
   1ad03:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ad06:	89 44 24 08          	mov    %eax,0x8(%esp)
   1ad0a:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1ad11:	00 
   1ad12:	8b 45 08             	mov    0x8(%ebp),%eax
   1ad15:	89 04 24             	mov    %eax,(%esp)
   1ad18:	e8 63 ff ff ff       	call   1ac80 <call_cap_asm>
}
   1ad1d:	c9                   	leave  
   1ad1e:	c3                   	ret    

0001ad1f <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
   1ad1f:	55                   	push   %ebp
   1ad20:	89 e5                	mov    %esp,%ebp
   1ad22:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
   1ad25:	8b 45 08             	mov    0x8(%ebp),%eax
   1ad28:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   1ad2f:	00 
   1ad30:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   1ad37:	00 
   1ad38:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ad3b:	89 54 24 08          	mov    %edx,0x8(%esp)
   1ad3f:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ad43:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
   1ad4a:	e8 99 ff ff ff       	call   1ace8 <call_cap>
}
   1ad4f:	c9                   	leave  
   1ad50:	c3                   	ret    

0001ad51 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
   1ad51:	55                   	push   %ebp
   1ad52:	89 e5                	mov    %esp,%ebp
   1ad54:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
   1ad57:	89 e0                	mov    %esp,%eax
   1ad59:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
   1ad5c:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1ad5f:	25 00 f0 ff ff       	and    $0xfffff000,%eax
   1ad64:	89 c2                	mov    %eax,%edx
   1ad66:	8b 45 08             	mov    0x8(%ebp),%eax
   1ad69:	c1 e0 02             	shl    $0x2,%eax
   1ad6c:	29 c2                	sub    %eax,%edx
   1ad6e:	89 d0                	mov    %edx,%eax
   1ad70:	05 00 10 00 00       	add    $0x1000,%eax
   1ad75:	8b 00                	mov    (%eax),%eax
}
   1ad77:	c9                   	leave  
   1ad78:	c3                   	ret    

0001ad79 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
   1ad79:	55                   	push   %ebp
   1ad7a:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
   1ad7c:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
   1ad81:	5d                   	pop    %ebp
   1ad82:	c3                   	ret    

0001ad83 <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
   1ad83:	55                   	push   %ebp
   1ad84:	89 e5                	mov    %esp,%ebp
   1ad86:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
   1ad89:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
   1ad90:	e8 bc ff ff ff       	call   1ad51 <get_stk_data>
}
   1ad95:	c9                   	leave  
   1ad96:	c3                   	ret    

0001ad97 <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
   1ad97:	55                   	push   %ebp
   1ad98:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
   1ad9a:	e8 e4 ff ff ff       	call   1ad83 <cos_get_thd_id>
}
   1ad9f:	5d                   	pop    %ebp
   1ada0:	c3                   	ret    

0001ada1 <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
   1ada1:	55                   	push   %ebp
   1ada2:	89 e5                	mov    %esp,%ebp
   1ada4:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
   1ada7:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
   1adae:	eb 20                	jmp    1add0 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
   1adb0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1adb3:	83 c0 01             	add    $0x1,%eax
   1adb6:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
   1adbd:	8b 45 08             	mov    0x8(%ebp),%eax
   1adc0:	01 d0                	add    %edx,%eax
   1adc2:	8b 00                	mov    (%eax),%eax
   1adc4:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
   1adc7:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1adca:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
   1adcc:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   1add0:	8b 45 08             	mov    0x8(%ebp),%eax
   1add3:	8b 00                	mov    (%eax),%eax
   1add5:	3b 45 f4             	cmp    -0xc(%ebp),%eax
   1add8:	7f d6                	jg     1adb0 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
   1adda:	c9                   	leave  
   1addb:	c3                   	ret    

0001addc <constructors_execute>:

static void
constructors_execute(void)
{
   1addc:	55                   	push   %ebp
   1addd:	89 e5                	mov    %esp,%ebp
   1addf:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
   1ade2:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1ade9:	e8 b3 ff ff ff       	call   1ada1 <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
   1adee:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1adf5:	e8 a7 ff ff ff       	call   1ada1 <section_fnptrs_execute>
}
   1adfa:	c9                   	leave  
   1adfb:	c3                   	ret    

0001adfc <destructors_execute>:
static void
destructors_execute(void)
{
   1adfc:	55                   	push   %ebp
   1adfd:	89 e5                	mov    %esp,%ebp
   1adff:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
   1ae02:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1ae09:	e8 93 ff ff ff       	call   1ada1 <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
   1ae0e:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1ae15:	e8 87 ff ff ff       	call   1ada1 <section_fnptrs_execute>
}
   1ae1a:	c9                   	leave  
   1ae1b:	c3                   	ret    

0001ae1c <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
   1ae1c:	55                   	push   %ebp
   1ae1d:	89 e5                	mov    %esp,%ebp
   1ae1f:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
   1ae22:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1ae29:	e8 73 ff ff ff       	call   1ada1 <section_fnptrs_execute>
}
   1ae2e:	c9                   	leave  
   1ae2f:	c3                   	ret    

0001ae30 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
   1ae30:	55                   	push   %ebp
   1ae31:	89 e5                	mov    %esp,%ebp
   1ae33:	83 ec 08             	sub    $0x8,%esp
   1ae36:	8b 55 08             	mov    0x8(%ebp),%edx
   1ae39:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ae3c:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
   1ae40:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
   1ae43:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1ae47:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
   1ae4b:	ee                   	out    %al,(%dx)
}
   1ae4c:	c9                   	leave  
   1ae4d:	c3                   	ret    

0001ae4e <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
   1ae4e:	55                   	push   %ebp
   1ae4f:	89 e5                	mov    %esp,%ebp
   1ae51:	83 ec 14             	sub    $0x14,%esp
   1ae54:	8b 45 08             	mov    0x8(%ebp),%eax
   1ae57:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
   1ae5b:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
   1ae5f:	89 c2                	mov    %eax,%edx
   1ae61:	ec                   	in     (%dx),%al
   1ae62:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
   1ae65:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
   1ae69:	c9                   	leave  
   1ae6a:	c3                   	ret    

0001ae6b <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
   1ae6b:	55                   	push   %ebp
   1ae6c:	89 e5                	mov    %esp,%ebp
   1ae6e:	83 ec 0c             	sub    $0xc,%esp
   1ae71:	8b 45 08             	mov    0x8(%ebp),%eax
   1ae74:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
   1ae77:	90                   	nop
   1ae78:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
   1ae7f:	e8 ca ff ff ff       	call   1ae4e <inb>
   1ae84:	0f b6 c0             	movzbl %al,%eax
   1ae87:	83 e0 20             	and    $0x20,%eax
   1ae8a:	85 c0                	test   %eax,%eax
   1ae8c:	74 ea                	je     1ae78 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
   1ae8e:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1ae92:	0f b6 c0             	movzbl %al,%eax
   1ae95:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ae99:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
   1aea0:	e8 8b ff ff ff       	call   1ae30 <outb>
}
   1aea5:	c9                   	leave  
   1aea6:	c3                   	ret    

0001aea7 <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
   1aea7:	55                   	push   %ebp
   1aea8:	89 e5                	mov    %esp,%ebp
   1aeaa:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
   1aead:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
   1aeb4:	eb 1a                	jmp    1aed0 <cos_serial_putb+0x29>
   1aeb6:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1aeb9:	8b 55 08             	mov    0x8(%ebp),%edx
   1aebc:	01 d0                	add    %edx,%eax
   1aebe:	0f b6 00             	movzbl (%eax),%eax
   1aec1:	0f be c0             	movsbl %al,%eax
   1aec4:	89 04 24             	mov    %eax,(%esp)
   1aec7:	e8 9f ff ff ff       	call   1ae6b <cos_serial_putc>
   1aecc:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
   1aed0:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1aed3:	3b 45 0c             	cmp    0xc(%ebp),%eax
   1aed6:	72 de                	jb     1aeb6 <cos_serial_putb+0xf>
}
   1aed8:	c9                   	leave  
   1aed9:	c3                   	ret    

0001aeda <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
   1aeda:	55                   	push   %ebp
   1aedb:	89 e5                	mov    %esp,%ebp
   1aedd:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
   1aee0:	8b 45 0c             	mov    0xc(%ebp),%eax
   1aee3:	89 44 24 04          	mov    %eax,0x4(%esp)
   1aee7:	8b 45 08             	mov    0x8(%ebp),%eax
   1aeea:	89 04 24             	mov    %eax,(%esp)
   1aeed:	e8 b5 ff ff ff       	call   1aea7 <cos_serial_putb>
}
   1aef2:	c9                   	leave  
   1aef3:	c3                   	ret    

0001aef4 <prints>:

static int
prints(char *s)
{
   1aef4:	55                   	push   %ebp
   1aef5:	89 e5                	mov    %esp,%ebp
   1aef7:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
   1aefa:	8b 45 08             	mov    0x8(%ebp),%eax
   1aefd:	89 04 24             	mov    %eax,(%esp)
   1af00:	e8 fc ff ff ff       	call   1af01 <prints+0xd>
   1af05:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
   1af08:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1af0b:	89 44 24 04          	mov    %eax,0x4(%esp)
   1af0f:	8b 45 08             	mov    0x8(%ebp),%eax
   1af12:	89 04 24             	mov    %eax,(%esp)
   1af15:	e8 05 fe ff ff       	call   1ad1f <cos_print>

	return len;
   1af1a:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1af1d:	c9                   	leave  
   1af1e:	c3                   	ret    

0001af1f <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
   1af1f:	55                   	push   %ebp
   1af20:	89 e5                	mov    %esp,%ebp
   1af22:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
   1af28:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
   1af2f:	8d 45 0c             	lea    0xc(%ebp),%eax
   1af32:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
   1af38:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
   1af3e:	89 44 24 0c          	mov    %eax,0xc(%esp)
   1af42:	8b 45 08             	mov    0x8(%ebp),%eax
   1af45:	89 44 24 08          	mov    %eax,0x8(%esp)
   1af49:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1af4c:	89 44 24 04          	mov    %eax,0x4(%esp)
   1af50:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
   1af56:	89 04 24             	mov    %eax,(%esp)
   1af59:	e8 fc ff ff ff       	call   1af5a <printc+0x3b>
   1af5e:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
   1af61:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1af64:	89 44 24 04          	mov    %eax,0x4(%esp)
   1af68:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
   1af6e:	89 04 24             	mov    %eax,(%esp)
   1af71:	e8 64 ff ff ff       	call   1aeda <cos_llprint>

	return ret;
   1af76:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
   1af79:	c9                   	leave  
   1af7a:	c3                   	ret    

0001af7b <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
   1af7b:	55                   	push   %ebp
   1af7c:	89 e5                	mov    %esp,%ebp
	while (1)
		;
   1af7e:	eb fe                	jmp    1af7e <__cos_noret+0x3>

0001af80 <ps_faa>:

static inline long
ps_faa(unsigned long *target, long inc)
{
   1af80:	55                   	push   %ebp
   1af81:	89 e5                	mov    %esp,%ebp
        __asm__ __volatile__("lock " PS_FAA_STR
   1af83:	8b 55 08             	mov    0x8(%ebp),%edx
   1af86:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1af89:	8b 45 0c             	mov    0xc(%ebp),%eax
   1af8c:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1af90:	89 45 0c             	mov    %eax,0xc(%ebp)
                             : "+m" (*target), "+q" (inc)
                             : : "memory", "cc");
        return inc;
   1af93:	8b 45 0c             	mov    0xc(%ebp),%eax
}
   1af96:	5d                   	pop    %ebp
   1af97:	c3                   	ret    

0001af98 <cos_aepthd_fn>:
	struct cos_aep_info sched_aep[NUM_CPU];
};

static void
cos_aepthd_fn(void *data)
{
   1af98:	55                   	push   %ebp
   1af99:	89 e5                	mov    %esp,%ebp
   1af9b:	83 ec 28             	sub    $0x28,%esp
	struct cos_aep_info *aep_info = (struct cos_aep_info *)data;
   1af9e:	8b 45 08             	mov    0x8(%ebp),%eax
   1afa1:	89 45 f4             	mov    %eax,-0xc(%ebp)
	cos_aepthd_fn_t      aep_fn   = aep_info->fn;
   1afa4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1afa7:	8b 40 10             	mov    0x10(%eax),%eax
   1afaa:	89 45 f0             	mov    %eax,-0x10(%ebp)
	void *               fn_data  = aep_info->data;
   1afad:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1afb0:	8b 40 14             	mov    0x14(%eax),%eax
   1afb3:	89 45 ec             	mov    %eax,-0x14(%ebp)

	(aep_fn)(aep_info->rcv, fn_data);
   1afb6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1afb9:	8b 40 0c             	mov    0xc(%eax),%eax
   1afbc:	8b 55 ec             	mov    -0x14(%ebp),%edx
   1afbf:	89 54 24 04          	mov    %edx,0x4(%esp)
   1afc3:	89 04 24             	mov    %eax,(%esp)
   1afc6:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1afc9:	ff d0                	call   *%eax

	/* TODO: handling destruction */
	assert(0);
   1afcb:	c7 04 24 88 34 00 00 	movl   $0x3488,(%esp)
   1afd2:	e8 1d ff ff ff       	call   1aef4 <prints>
   1afd7:	a1 c0 02 00 00       	mov    0x2c0,%eax
   1afdc:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1afe2:	e8 94 ff ff ff       	call   1af7b <__cos_noret>

0001afe7 <ps_list_ll_empty>:
ps_list_head_init(struct ps_list_head *lh)
{ ps_list_ll_init(&lh->l); }

static inline int
ps_list_ll_empty(struct ps_list *l)
{ return l->n == l; }
   1afe7:	55                   	push   %ebp
   1afe8:	89 e5                	mov    %esp,%ebp
   1afea:	8b 45 08             	mov    0x8(%ebp),%eax
   1afed:	8b 00                	mov    (%eax),%eax
   1afef:	3b 45 08             	cmp    0x8(%ebp),%eax
   1aff2:	0f 94 c0             	sete   %al
   1aff5:	0f b6 c0             	movzbl %al,%eax
   1aff8:	5d                   	pop    %ebp
   1aff9:	c3                   	ret    

0001affa <ps_list_ll_add>:
ps_list_head_empty(struct ps_list_head *lh)
{ return ps_list_ll_empty(&lh->l); }

static inline void
ps_list_ll_add(struct ps_list *l, struct ps_list *new)
{
   1affa:	55                   	push   %ebp
   1affb:	89 e5                	mov    %esp,%ebp
	new->n    = l->n;
   1affd:	8b 45 08             	mov    0x8(%ebp),%eax
   1b000:	8b 10                	mov    (%eax),%edx
   1b002:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b005:	89 10                	mov    %edx,(%eax)
	new->p    = l;
   1b007:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b00a:	8b 55 08             	mov    0x8(%ebp),%edx
   1b00d:	89 50 04             	mov    %edx,0x4(%eax)
	l->n      = new;
   1b010:	8b 45 08             	mov    0x8(%ebp),%eax
   1b013:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b016:	89 10                	mov    %edx,(%eax)
	new->n->p = new;
   1b018:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b01b:	8b 00                	mov    (%eax),%eax
   1b01d:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b020:	89 50 04             	mov    %edx,0x4(%eax)
}
   1b023:	5d                   	pop    %ebp
   1b024:	c3                   	ret    

0001b025 <ps_list_ll_rem>:

static inline void
ps_list_ll_rem(struct ps_list *l)
{
   1b025:	55                   	push   %ebp
   1b026:	89 e5                	mov    %esp,%ebp
	l->n->p = l->p;
   1b028:	8b 45 08             	mov    0x8(%ebp),%eax
   1b02b:	8b 00                	mov    (%eax),%eax
   1b02d:	8b 55 08             	mov    0x8(%ebp),%edx
   1b030:	8b 52 04             	mov    0x4(%edx),%edx
   1b033:	89 50 04             	mov    %edx,0x4(%eax)
	l->p->n = l->n;
   1b036:	8b 45 08             	mov    0x8(%ebp),%eax
   1b039:	8b 40 04             	mov    0x4(%eax),%eax
   1b03c:	8b 55 08             	mov    0x8(%ebp),%edx
   1b03f:	8b 12                	mov    (%edx),%edx
   1b041:	89 10                	mov    %edx,(%eax)
	l->p = l->n = l;
   1b043:	8b 45 08             	mov    0x8(%ebp),%eax
   1b046:	8b 55 08             	mov    0x8(%ebp),%edx
   1b049:	89 10                	mov    %edx,(%eax)
   1b04b:	8b 45 08             	mov    0x8(%ebp),%eax
   1b04e:	8b 10                	mov    (%eax),%edx
   1b050:	8b 45 08             	mov    0x8(%ebp),%eax
   1b053:	89 50 04             	mov    %edx,0x4(%eax)
}
   1b056:	5d                   	pop    %ebp
   1b057:	c3                   	ret    

0001b058 <__slab_freelist_rem>:
static inline void __ps_slab_freelist_check(struct ps_slab_freelist *fl) { (void)fl; }
#endif /* PS_SLAB_DEBUG */

static void
__slab_freelist_rem(struct ps_slab_freelist *fl, struct ps_slab *s)
{
   1b058:	55                   	push   %ebp
   1b059:	89 e5                	mov    %esp,%ebp
   1b05b:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
   1b05e:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1b062:	0f 94 c0             	sete   %al
   1b065:	0f b6 c0             	movzbl %al,%eax
   1b068:	85 c0                	test   %eax,%eax
   1b06a:	75 0e                	jne    1b07a <__slab_freelist_rem+0x22>
   1b06c:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1b070:	0f 94 c0             	sete   %al
   1b073:	0f b6 c0             	movzbl %al,%eax
   1b076:	85 c0                	test   %eax,%eax
   1b078:	74 1c                	je     1b096 <__slab_freelist_rem+0x3e>
   1b07a:	c7 04 24 ec 34 00 00 	movl   $0x34ec,(%esp)
   1b081:	e8 6e fe ff ff       	call   1aef4 <prints>
   1b086:	a1 c0 02 00 00       	mov    0x2c0,%eax
   1b08b:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1b091:	e8 e5 fe ff ff       	call   1af7b <__cos_noret>
	if (fl->list == s) {
   1b096:	8b 45 08             	mov    0x8(%ebp),%eax
   1b099:	8b 00                	mov    (%eax),%eax
   1b09b:	3b 45 0c             	cmp    0xc(%ebp),%eax
   1b09e:	75 2b                	jne    1b0cb <__slab_freelist_rem+0x73>
		if (ps_list_singleton(s, list)) fl->list = NULL;
   1b0a0:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b0a3:	83 c0 44             	add    $0x44,%eax
   1b0a6:	89 04 24             	mov    %eax,(%esp)
   1b0a9:	e8 39 ff ff ff       	call   1afe7 <ps_list_ll_empty>
   1b0ae:	85 c0                	test   %eax,%eax
   1b0b0:	74 0b                	je     1b0bd <__slab_freelist_rem+0x65>
   1b0b2:	8b 45 08             	mov    0x8(%ebp),%eax
   1b0b5:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1b0bb:	eb 0e                	jmp    1b0cb <__slab_freelist_rem+0x73>
		else                            fl->list = ps_list_next(s, list);
   1b0bd:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b0c0:	8b 40 44             	mov    0x44(%eax),%eax
   1b0c3:	8d 50 bc             	lea    -0x44(%eax),%edx
   1b0c6:	8b 45 08             	mov    0x8(%ebp),%eax
   1b0c9:	89 10                	mov    %edx,(%eax)
	}
	ps_list_rem(s, list);
   1b0cb:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b0ce:	83 c0 44             	add    $0x44,%eax
   1b0d1:	89 04 24             	mov    %eax,(%esp)
   1b0d4:	e8 4c ff ff ff       	call   1b025 <ps_list_ll_rem>
}
   1b0d9:	c9                   	leave  
   1b0da:	c3                   	ret    

0001b0db <__slab_freelist_add>:

static void
__slab_freelist_add(struct ps_slab_freelist *fl, struct ps_slab *s)
{
   1b0db:	55                   	push   %ebp
   1b0dc:	89 e5                	mov    %esp,%ebp
   1b0de:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
   1b0e1:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1b0e5:	0f 94 c0             	sete   %al
   1b0e8:	0f b6 c0             	movzbl %al,%eax
   1b0eb:	85 c0                	test   %eax,%eax
   1b0ed:	75 0e                	jne    1b0fd <__slab_freelist_add+0x22>
   1b0ef:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1b0f3:	0f 94 c0             	sete   %al
   1b0f6:	0f b6 c0             	movzbl %al,%eax
   1b0f9:	85 c0                	test   %eax,%eax
   1b0fb:	74 1c                	je     1b119 <__slab_freelist_add+0x3e>
   1b0fd:	c7 04 24 44 35 00 00 	movl   $0x3544,(%esp)
   1b104:	e8 eb fd ff ff       	call   1aef4 <prints>
   1b109:	a1 c0 02 00 00       	mov    0x2c0,%eax
   1b10e:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1b114:	e8 62 fe ff ff       	call   1af7b <__cos_noret>
	assert(ps_list_singleton(s, list));
   1b119:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b11c:	83 c0 44             	add    $0x44,%eax
   1b11f:	89 04 24             	mov    %eax,(%esp)
   1b122:	e8 c0 fe ff ff       	call   1afe7 <ps_list_ll_empty>
   1b127:	85 c0                	test   %eax,%eax
   1b129:	0f 94 c0             	sete   %al
   1b12c:	0f b6 c0             	movzbl %al,%eax
   1b12f:	85 c0                	test   %eax,%eax
   1b131:	74 1c                	je     1b14f <__slab_freelist_add+0x74>
   1b133:	c7 04 24 9c 35 00 00 	movl   $0x359c,(%esp)
   1b13a:	e8 b5 fd ff ff       	call   1aef4 <prints>
   1b13f:	a1 c0 02 00 00       	mov    0x2c0,%eax
   1b144:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1b14a:	e8 2c fe ff ff       	call   1af7b <__cos_noret>
	assert(s != fl->list);
   1b14f:	8b 45 08             	mov    0x8(%ebp),%eax
   1b152:	8b 00                	mov    (%eax),%eax
   1b154:	3b 45 0c             	cmp    0xc(%ebp),%eax
   1b157:	0f 94 c0             	sete   %al
   1b15a:	0f b6 c0             	movzbl %al,%eax
   1b15d:	85 c0                	test   %eax,%eax
   1b15f:	74 1c                	je     1b17d <__slab_freelist_add+0xa2>
   1b161:	c7 04 24 f4 35 00 00 	movl   $0x35f4,(%esp)
   1b168:	e8 87 fd ff ff       	call   1aef4 <prints>
   1b16d:	a1 c0 02 00 00       	mov    0x2c0,%eax
   1b172:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1b178:	e8 fe fd ff ff       	call   1af7b <__cos_noret>
	if (fl->list) ps_list_add(fl->list, s, list);
   1b17d:	8b 45 08             	mov    0x8(%ebp),%eax
   1b180:	8b 00                	mov    (%eax),%eax
   1b182:	85 c0                	test   %eax,%eax
   1b184:	74 1a                	je     1b1a0 <__slab_freelist_add+0xc5>
   1b186:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b189:	8d 50 44             	lea    0x44(%eax),%edx
   1b18c:	8b 45 08             	mov    0x8(%ebp),%eax
   1b18f:	8b 00                	mov    (%eax),%eax
   1b191:	83 c0 44             	add    $0x44,%eax
   1b194:	89 54 24 04          	mov    %edx,0x4(%esp)
   1b198:	89 04 24             	mov    %eax,(%esp)
   1b19b:	e8 5a fe ff ff       	call   1affa <ps_list_ll_add>
	fl->list = s;
   1b1a0:	8b 45 08             	mov    0x8(%ebp),%eax
   1b1a3:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b1a6:	89 10                	mov    %edx,(%eax)
	/* TODO: sort based on emptiness...just use N bins */
}
   1b1a8:	c9                   	leave  
   1b1a9:	c3                   	ret    

0001b1aa <ck_cc_ffs>:
 */
#ifndef CK_MD_CC_BUILTIN_DISABLE
#define CK_F_CC_FFS
CK_CC_INLINE static int
ck_cc_ffs(unsigned int x)
{
   1b1aa:	55                   	push   %ebp
   1b1ab:	89 e5                	mov    %esp,%ebp

	return __builtin_ffsl(x);
   1b1ad:	8b 45 08             	mov    0x8(%ebp),%eax
   1b1b0:	ba ff ff ff ff       	mov    $0xffffffff,%edx
   1b1b5:	0f bc c0             	bsf    %eax,%eax
   1b1b8:	0f 44 c2             	cmove  %edx,%eax
   1b1bb:	83 c0 01             	add    $0x1,%eax
}
   1b1be:	5d                   	pop    %ebp
   1b1bf:	c3                   	ret    

0001b1c0 <ck_cc_ffsl>:

#define CK_F_CC_FFSL
CK_CC_INLINE static int
ck_cc_ffsl(unsigned long x)
{
   1b1c0:	55                   	push   %ebp
   1b1c1:	89 e5                	mov    %esp,%ebp
   1b1c3:	83 ec 18             	sub    $0x18,%esp

	return __builtin_ffsll(x);
   1b1c6:	8b 45 08             	mov    0x8(%ebp),%eax
   1b1c9:	ba 00 00 00 00       	mov    $0x0,%edx
   1b1ce:	89 04 24             	mov    %eax,(%esp)
   1b1d1:	89 54 24 04          	mov    %edx,0x4(%esp)
   1b1d5:	e8 fc ff ff ff       	call   1b1d6 <ck_cc_ffsl+0x16>
}
   1b1da:	c9                   	leave  
   1b1db:	c3                   	ret    

0001b1dc <ck_cc_ctz>:

#define CK_F_CC_CTZ
CK_CC_INLINE static int
ck_cc_ctz(unsigned int x)
{
   1b1dc:	55                   	push   %ebp
   1b1dd:	89 e5                	mov    %esp,%ebp

	return __builtin_ctz(x);
   1b1df:	f3 0f bc 45 08       	tzcnt  0x8(%ebp),%eax
}
   1b1e4:	5d                   	pop    %ebp
   1b1e5:	c3                   	ret    

0001b1e6 <ck_cc_popcount>:

#define CK_F_CC_POPCOUNT
CK_CC_INLINE static int
ck_cc_popcount(unsigned int x)
{
   1b1e6:	55                   	push   %ebp
   1b1e7:	89 e5                	mov    %esp,%ebp
   1b1e9:	83 ec 18             	sub    $0x18,%esp

	return __builtin_popcount(x);
   1b1ec:	8b 45 08             	mov    0x8(%ebp),%eax
   1b1ef:	89 04 24             	mov    %eax,(%esp)
   1b1f2:	e8 fc ff ff ff       	call   1b1f3 <ck_cc_popcount+0xd>
}
   1b1f7:	c9                   	leave  
   1b1f8:	c3                   	ret    

0001b1f9 <ck_cc_ffsll>:
   1b1f9:	55                   	push   %ebp
   1b1fa:	89 e5                	mov    %esp,%ebp
   1b1fc:	53                   	push   %ebx
   1b1fd:	83 ec 1c             	sub    $0x1c,%esp
   1b200:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b203:	89 4d e0             	mov    %ecx,-0x20(%ebp)
   1b206:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b209:	89 4d e4             	mov    %ecx,-0x1c(%ebp)
   1b20c:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   1b20f:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
   1b212:	09 d9                	or     %ebx,%ecx
   1b214:	85 c9                	test   %ecx,%ecx
   1b216:	75 07                	jne    1b21f <ck_cc_ffsll+0x26>
   1b218:	b8 00 00 00 00       	mov    $0x0,%eax
   1b21d:	eb 3a                	jmp    1b259 <ck_cc_ffsll+0x60>
   1b21f:	c7 45 f4 01 00 00 00 	movl   $0x1,-0xc(%ebp)
   1b226:	eb 16                	jmp    1b23e <ck_cc_ffsll+0x45>
   1b228:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   1b22c:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   1b22f:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
   1b232:	0f ac d9 01          	shrd   $0x1,%ebx,%ecx
   1b236:	d1 eb                	shr    %ebx
   1b238:	89 4d e0             	mov    %ecx,-0x20(%ebp)
   1b23b:	89 5d e4             	mov    %ebx,-0x1c(%ebp)
   1b23e:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   1b241:	83 e1 01             	and    $0x1,%ecx
   1b244:	89 c8                	mov    %ecx,%eax
   1b246:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
   1b249:	83 e1 00             	and    $0x0,%ecx
   1b24c:	89 ca                	mov    %ecx,%edx
   1b24e:	89 d1                	mov    %edx,%ecx
   1b250:	09 c1                	or     %eax,%ecx
   1b252:	85 c9                	test   %ecx,%ecx
   1b254:	74 d2                	je     1b228 <ck_cc_ffsll+0x2f>
   1b256:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1b259:	83 c4 1c             	add    $0x1c,%esp
   1b25c:	5b                   	pop    %ebx
   1b25d:	5d                   	pop    %ebp
   1b25e:	c3                   	ret    

0001b25f <ck_pr_stall>:
 * Prevent speculative execution in busy-wait loops (P4 <=) or "predefined
 * delay".
 */
CK_CC_INLINE static void
ck_pr_stall(void)
{
   1b25f:	55                   	push   %ebp
   1b260:	89 e5                	mov    %esp,%ebp
	__asm__ __volatile__("pause" ::: "memory");
   1b262:	f3 90                	pause  
	return;
   1b264:	90                   	nop
}
   1b265:	5d                   	pop    %ebp
   1b266:	c3                   	ret    

0001b267 <ck_pr_fence_strict_atomic>:
#define CK_MD_X86_SFENCE "sfence"
#define CK_MD_X86_LFENCE "lfence"
#define CK_MD_X86_MFENCE "mfence"
#endif /* !CK_MD_SSE_DISABLE */

CK_PR_FENCE(atomic, "")
   1b267:	55                   	push   %ebp
   1b268:	89 e5                	mov    %esp,%ebp
   1b26a:	90                   	nop
   1b26b:	5d                   	pop    %ebp
   1b26c:	c3                   	ret    

0001b26d <ck_pr_fence_strict_atomic_store>:
CK_PR_FENCE(atomic_store, "")
   1b26d:	55                   	push   %ebp
   1b26e:	89 e5                	mov    %esp,%ebp
   1b270:	90                   	nop
   1b271:	5d                   	pop    %ebp
   1b272:	c3                   	ret    

0001b273 <ck_pr_fence_strict_atomic_load>:
CK_PR_FENCE(atomic_load, "")
   1b273:	55                   	push   %ebp
   1b274:	89 e5                	mov    %esp,%ebp
   1b276:	90                   	nop
   1b277:	5d                   	pop    %ebp
   1b278:	c3                   	ret    

0001b279 <ck_pr_fence_strict_store_atomic>:
CK_PR_FENCE(store_atomic, "")
   1b279:	55                   	push   %ebp
   1b27a:	89 e5                	mov    %esp,%ebp
   1b27c:	90                   	nop
   1b27d:	5d                   	pop    %ebp
   1b27e:	c3                   	ret    

0001b27f <ck_pr_fence_strict_load_atomic>:
CK_PR_FENCE(load_atomic, "")
   1b27f:	55                   	push   %ebp
   1b280:	89 e5                	mov    %esp,%ebp
   1b282:	90                   	nop
   1b283:	5d                   	pop    %ebp
   1b284:	c3                   	ret    

0001b285 <ck_pr_fence_strict_load>:
CK_PR_FENCE(load, CK_MD_X86_LFENCE)
   1b285:	55                   	push   %ebp
   1b286:	89 e5                	mov    %esp,%ebp
   1b288:	0f ae e8             	lfence 
   1b28b:	90                   	nop
   1b28c:	5d                   	pop    %ebp
   1b28d:	c3                   	ret    

0001b28e <ck_pr_fence_strict_load_store>:
CK_PR_FENCE(load_store, CK_MD_X86_MFENCE)
   1b28e:	55                   	push   %ebp
   1b28f:	89 e5                	mov    %esp,%ebp
   1b291:	0f ae f0             	mfence 
   1b294:	90                   	nop
   1b295:	5d                   	pop    %ebp
   1b296:	c3                   	ret    

0001b297 <ck_pr_fence_strict_store>:
CK_PR_FENCE(store, CK_MD_X86_SFENCE)
   1b297:	55                   	push   %ebp
   1b298:	89 e5                	mov    %esp,%ebp
   1b29a:	0f ae f8             	sfence 
   1b29d:	90                   	nop
   1b29e:	5d                   	pop    %ebp
   1b29f:	c3                   	ret    

0001b2a0 <ck_pr_fence_strict_store_load>:
CK_PR_FENCE(store_load, CK_MD_X86_MFENCE)
   1b2a0:	55                   	push   %ebp
   1b2a1:	89 e5                	mov    %esp,%ebp
   1b2a3:	0f ae f0             	mfence 
   1b2a6:	90                   	nop
   1b2a7:	5d                   	pop    %ebp
   1b2a8:	c3                   	ret    

0001b2a9 <ck_pr_fence_strict_memory>:
CK_PR_FENCE(memory, CK_MD_X86_MFENCE)
   1b2a9:	55                   	push   %ebp
   1b2aa:	89 e5                	mov    %esp,%ebp
   1b2ac:	0f ae f0             	mfence 
   1b2af:	90                   	nop
   1b2b0:	5d                   	pop    %ebp
   1b2b1:	c3                   	ret    

0001b2b2 <ck_pr_fence_strict_release>:
CK_PR_FENCE(release, CK_MD_X86_MFENCE)
   1b2b2:	55                   	push   %ebp
   1b2b3:	89 e5                	mov    %esp,%ebp
   1b2b5:	0f ae f0             	mfence 
   1b2b8:	90                   	nop
   1b2b9:	5d                   	pop    %ebp
   1b2ba:	c3                   	ret    

0001b2bb <ck_pr_fence_strict_acquire>:
CK_PR_FENCE(acquire, CK_MD_X86_MFENCE)
   1b2bb:	55                   	push   %ebp
   1b2bc:	89 e5                	mov    %esp,%ebp
   1b2be:	0f ae f0             	mfence 
   1b2c1:	90                   	nop
   1b2c2:	5d                   	pop    %ebp
   1b2c3:	c3                   	ret    

0001b2c4 <ck_pr_fence_strict_acqrel>:
CK_PR_FENCE(acqrel, CK_MD_X86_MFENCE)
   1b2c4:	55                   	push   %ebp
   1b2c5:	89 e5                	mov    %esp,%ebp
   1b2c7:	0f ae f0             	mfence 
   1b2ca:	90                   	nop
   1b2cb:	5d                   	pop    %ebp
   1b2cc:	c3                   	ret    

0001b2cd <ck_pr_fence_strict_lock>:
CK_PR_FENCE(lock, CK_MD_X86_MFENCE)
   1b2cd:	55                   	push   %ebp
   1b2ce:	89 e5                	mov    %esp,%ebp
   1b2d0:	0f ae f0             	mfence 
   1b2d3:	90                   	nop
   1b2d4:	5d                   	pop    %ebp
   1b2d5:	c3                   	ret    

0001b2d6 <ck_pr_fence_strict_unlock>:
CK_PR_FENCE(unlock, CK_MD_X86_MFENCE)
   1b2d6:	55                   	push   %ebp
   1b2d7:	89 e5                	mov    %esp,%ebp
   1b2d9:	0f ae f0             	mfence 
   1b2dc:	90                   	nop
   1b2dd:	5d                   	pop    %ebp
   1b2de:	c3                   	ret    

0001b2df <ck_pr_fas_ptr>:
					:			\
					: "memory");		\
		return v;					\
	}

CK_PR_FAS(ptr, void, void *, char, "xchgl")
   1b2df:	55                   	push   %ebp
   1b2e0:	89 e5                	mov    %esp,%ebp
   1b2e2:	8b 55 08             	mov    0x8(%ebp),%edx
   1b2e5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b2e8:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b2eb:	87 02                	xchg   %eax,(%edx)
   1b2ed:	89 45 0c             	mov    %eax,0xc(%ebp)
   1b2f0:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b2f3:	5d                   	pop    %ebp
   1b2f4:	c3                   	ret    

0001b2f5 <ck_pr_fas_char>:

#define CK_PR_FAS_S(S, T, I) CK_PR_FAS(S, T, T, T, I)

CK_PR_FAS_S(char, char, "xchgb")
   1b2f5:	55                   	push   %ebp
   1b2f6:	89 e5                	mov    %esp,%ebp
   1b2f8:	83 ec 04             	sub    $0x4,%esp
   1b2fb:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b2fe:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b301:	8b 55 08             	mov    0x8(%ebp),%edx
   1b304:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b307:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1b30b:	86 02                	xchg   %al,(%edx)
   1b30d:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b310:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1b314:	c9                   	leave  
   1b315:	c3                   	ret    

0001b316 <ck_pr_fas_uint>:
CK_PR_FAS_S(uint, unsigned int, "xchgl")
   1b316:	55                   	push   %ebp
   1b317:	89 e5                	mov    %esp,%ebp
   1b319:	8b 55 08             	mov    0x8(%ebp),%edx
   1b31c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b31f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b322:	87 02                	xchg   %eax,(%edx)
   1b324:	89 45 0c             	mov    %eax,0xc(%ebp)
   1b327:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b32a:	5d                   	pop    %ebp
   1b32b:	c3                   	ret    

0001b32c <ck_pr_fas_int>:
CK_PR_FAS_S(int, int, "xchgl")
   1b32c:	55                   	push   %ebp
   1b32d:	89 e5                	mov    %esp,%ebp
   1b32f:	8b 55 08             	mov    0x8(%ebp),%edx
   1b332:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b335:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b338:	87 02                	xchg   %eax,(%edx)
   1b33a:	89 45 0c             	mov    %eax,0xc(%ebp)
   1b33d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b340:	5d                   	pop    %ebp
   1b341:	c3                   	ret    

0001b342 <ck_pr_fas_32>:
CK_PR_FAS_S(32, uint32_t, "xchgl")
   1b342:	55                   	push   %ebp
   1b343:	89 e5                	mov    %esp,%ebp
   1b345:	8b 55 08             	mov    0x8(%ebp),%edx
   1b348:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b34b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b34e:	87 02                	xchg   %eax,(%edx)
   1b350:	89 45 0c             	mov    %eax,0xc(%ebp)
   1b353:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b356:	5d                   	pop    %ebp
   1b357:	c3                   	ret    

0001b358 <ck_pr_fas_16>:
CK_PR_FAS_S(16, uint16_t, "xchgw")
   1b358:	55                   	push   %ebp
   1b359:	89 e5                	mov    %esp,%ebp
   1b35b:	83 ec 04             	sub    $0x4,%esp
   1b35e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b361:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1b365:	8b 55 08             	mov    0x8(%ebp),%edx
   1b368:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b36b:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1b36f:	66 87 02             	xchg   %ax,(%edx)
   1b372:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1b376:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1b37a:	c9                   	leave  
   1b37b:	c3                   	ret    

0001b37c <ck_pr_fas_8>:
CK_PR_FAS_S(8,  uint8_t,  "xchgb")
   1b37c:	55                   	push   %ebp
   1b37d:	89 e5                	mov    %esp,%ebp
   1b37f:	83 ec 04             	sub    $0x4,%esp
   1b382:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b385:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b388:	8b 55 08             	mov    0x8(%ebp),%edx
   1b38b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b38e:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1b392:	86 02                	xchg   %al,(%edx)
   1b394:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b397:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1b39b:	c9                   	leave  
   1b39c:	c3                   	ret    

0001b39d <ck_pr_md_load_ptr>:
					: "m"  (*(const C *)target)	\
					: "memory");			\
		return (r);						\
	}

CK_PR_LOAD(ptr, void, void *, char, "movl")
   1b39d:	55                   	push   %ebp
   1b39e:	89 e5                	mov    %esp,%ebp
   1b3a0:	83 ec 10             	sub    $0x10,%esp
   1b3a3:	8b 45 08             	mov    0x8(%ebp),%eax
   1b3a6:	8b 00                	mov    (%eax),%eax
   1b3a8:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1b3ab:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1b3ae:	c9                   	leave  
   1b3af:	c3                   	ret    

0001b3b0 <ck_pr_md_load_char>:

#define CK_PR_LOAD_S(S, T, I) CK_PR_LOAD(S, T, T, T, I)

CK_PR_LOAD_S(char, char, "movb")
   1b3b0:	55                   	push   %ebp
   1b3b1:	89 e5                	mov    %esp,%ebp
   1b3b3:	83 ec 10             	sub    $0x10,%esp
   1b3b6:	8b 45 08             	mov    0x8(%ebp),%eax
   1b3b9:	8a 00                	mov    (%eax),%al
   1b3bb:	88 45 ff             	mov    %al,-0x1(%ebp)
   1b3be:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1b3c2:	c9                   	leave  
   1b3c3:	c3                   	ret    

0001b3c4 <ck_pr_md_load_uint>:
CK_PR_LOAD_S(uint, unsigned int, "movl")
   1b3c4:	55                   	push   %ebp
   1b3c5:	89 e5                	mov    %esp,%ebp
   1b3c7:	83 ec 10             	sub    $0x10,%esp
   1b3ca:	8b 45 08             	mov    0x8(%ebp),%eax
   1b3cd:	8b 00                	mov    (%eax),%eax
   1b3cf:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1b3d2:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1b3d5:	c9                   	leave  
   1b3d6:	c3                   	ret    

0001b3d7 <ck_pr_md_load_int>:
CK_PR_LOAD_S(int, int, "movl")
   1b3d7:	55                   	push   %ebp
   1b3d8:	89 e5                	mov    %esp,%ebp
   1b3da:	83 ec 10             	sub    $0x10,%esp
   1b3dd:	8b 45 08             	mov    0x8(%ebp),%eax
   1b3e0:	8b 00                	mov    (%eax),%eax
   1b3e2:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1b3e5:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1b3e8:	c9                   	leave  
   1b3e9:	c3                   	ret    

0001b3ea <ck_pr_md_load_32>:
CK_PR_LOAD_S(32, uint32_t, "movl")
   1b3ea:	55                   	push   %ebp
   1b3eb:	89 e5                	mov    %esp,%ebp
   1b3ed:	83 ec 10             	sub    $0x10,%esp
   1b3f0:	8b 45 08             	mov    0x8(%ebp),%eax
   1b3f3:	8b 00                	mov    (%eax),%eax
   1b3f5:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1b3f8:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1b3fb:	c9                   	leave  
   1b3fc:	c3                   	ret    

0001b3fd <ck_pr_md_load_16>:
CK_PR_LOAD_S(16, uint16_t, "movw")
   1b3fd:	55                   	push   %ebp
   1b3fe:	89 e5                	mov    %esp,%ebp
   1b400:	83 ec 10             	sub    $0x10,%esp
   1b403:	8b 45 08             	mov    0x8(%ebp),%eax
   1b406:	66 8b 00             	mov    (%eax),%ax
   1b409:	66 89 45 fe          	mov    %ax,-0x2(%ebp)
   1b40d:	0f b7 45 fe          	movzwl -0x2(%ebp),%eax
   1b411:	c9                   	leave  
   1b412:	c3                   	ret    

0001b413 <ck_pr_md_load_8>:
CK_PR_LOAD_S(8,  uint8_t,  "movb")
   1b413:	55                   	push   %ebp
   1b414:	89 e5                	mov    %esp,%ebp
   1b416:	83 ec 10             	sub    $0x10,%esp
   1b419:	8b 45 08             	mov    0x8(%ebp),%eax
   1b41c:	8a 00                	mov    (%eax),%al
   1b41e:	88 45 ff             	mov    %al,-0x1(%ebp)
   1b421:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1b425:	c9                   	leave  
   1b426:	c3                   	ret    

0001b427 <ck_pr_md_store_ptr>:
					: CK_CC_IMM "q" (v)	\
					: "memory");		\
		return;						\
	}

CK_PR_STORE(ptr, void, const void *, char, "movl")
   1b427:	55                   	push   %ebp
   1b428:	89 e5                	mov    %esp,%ebp
   1b42a:	8b 45 08             	mov    0x8(%ebp),%eax
   1b42d:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b430:	89 10                	mov    %edx,(%eax)
   1b432:	90                   	nop
   1b433:	5d                   	pop    %ebp
   1b434:	c3                   	ret    

0001b435 <ck_pr_md_store_char>:

#define CK_PR_STORE_S(S, T, I) CK_PR_STORE(S, T, T, T, I)

CK_PR_STORE_S(char, char, "movb")
   1b435:	55                   	push   %ebp
   1b436:	89 e5                	mov    %esp,%ebp
   1b438:	83 ec 04             	sub    $0x4,%esp
   1b43b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b43e:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b441:	8b 45 08             	mov    0x8(%ebp),%eax
   1b444:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1b448:	88 10                	mov    %dl,(%eax)
   1b44a:	90                   	nop
   1b44b:	c9                   	leave  
   1b44c:	c3                   	ret    

0001b44d <ck_pr_md_store_uint>:
CK_PR_STORE_S(uint, unsigned int, "movl")
   1b44d:	55                   	push   %ebp
   1b44e:	89 e5                	mov    %esp,%ebp
   1b450:	8b 45 08             	mov    0x8(%ebp),%eax
   1b453:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b456:	89 10                	mov    %edx,(%eax)
   1b458:	90                   	nop
   1b459:	5d                   	pop    %ebp
   1b45a:	c3                   	ret    

0001b45b <ck_pr_md_store_int>:
CK_PR_STORE_S(int, int, "movl")
   1b45b:	55                   	push   %ebp
   1b45c:	89 e5                	mov    %esp,%ebp
   1b45e:	8b 45 08             	mov    0x8(%ebp),%eax
   1b461:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b464:	89 10                	mov    %edx,(%eax)
   1b466:	90                   	nop
   1b467:	5d                   	pop    %ebp
   1b468:	c3                   	ret    

0001b469 <ck_pr_md_store_32>:
CK_PR_STORE_S(32, uint32_t, "movl")
   1b469:	55                   	push   %ebp
   1b46a:	89 e5                	mov    %esp,%ebp
   1b46c:	8b 45 08             	mov    0x8(%ebp),%eax
   1b46f:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b472:	89 10                	mov    %edx,(%eax)
   1b474:	90                   	nop
   1b475:	5d                   	pop    %ebp
   1b476:	c3                   	ret    

0001b477 <ck_pr_md_store_16>:
CK_PR_STORE_S(16, uint16_t, "movw")
   1b477:	55                   	push   %ebp
   1b478:	89 e5                	mov    %esp,%ebp
   1b47a:	83 ec 04             	sub    $0x4,%esp
   1b47d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b480:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1b484:	8b 45 08             	mov    0x8(%ebp),%eax
   1b487:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1b48b:	66 89 10             	mov    %dx,(%eax)
   1b48e:	90                   	nop
   1b48f:	c9                   	leave  
   1b490:	c3                   	ret    

0001b491 <ck_pr_md_store_8>:
CK_PR_STORE_S(8,  uint8_t, "movb")
   1b491:	55                   	push   %ebp
   1b492:	89 e5                	mov    %esp,%ebp
   1b494:	83 ec 04             	sub    $0x4,%esp
   1b497:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b49a:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b49d:	8b 45 08             	mov    0x8(%ebp),%eax
   1b4a0:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1b4a4:	88 10                	mov    %dl,(%eax)
   1b4a6:	90                   	nop
   1b4a7:	c9                   	leave  
   1b4a8:	c3                   	ret    

0001b4a9 <ck_pr_faa_ptr>:
					:				\
					: "memory", "cc");		\
		return (d);						\
	}

CK_PR_FAA(ptr, void, uintptr_t, char, "xaddl")
   1b4a9:	55                   	push   %ebp
   1b4aa:	89 e5                	mov    %esp,%ebp
   1b4ac:	8b 55 08             	mov    0x8(%ebp),%edx
   1b4af:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b4b2:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b4b5:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1b4b9:	89 45 0c             	mov    %eax,0xc(%ebp)
   1b4bc:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b4bf:	5d                   	pop    %ebp
   1b4c0:	c3                   	ret    

0001b4c1 <ck_pr_faa_char>:

#define CK_PR_FAA_S(S, T, I) CK_PR_FAA(S, T, T, T, I)

CK_PR_FAA_S(char, char, "xaddb")
   1b4c1:	55                   	push   %ebp
   1b4c2:	89 e5                	mov    %esp,%ebp
   1b4c4:	83 ec 04             	sub    $0x4,%esp
   1b4c7:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b4ca:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b4cd:	8b 55 08             	mov    0x8(%ebp),%edx
   1b4d0:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b4d3:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1b4d7:	f0 0f c0 02          	lock xadd %al,(%edx)
   1b4db:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b4de:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1b4e2:	c9                   	leave  
   1b4e3:	c3                   	ret    

0001b4e4 <ck_pr_faa_uint>:
CK_PR_FAA_S(uint, unsigned int, "xaddl")
   1b4e4:	55                   	push   %ebp
   1b4e5:	89 e5                	mov    %esp,%ebp
   1b4e7:	8b 55 08             	mov    0x8(%ebp),%edx
   1b4ea:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b4ed:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b4f0:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1b4f4:	89 45 0c             	mov    %eax,0xc(%ebp)
   1b4f7:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b4fa:	5d                   	pop    %ebp
   1b4fb:	c3                   	ret    

0001b4fc <ck_pr_faa_int>:
CK_PR_FAA_S(int, int, "xaddl")
   1b4fc:	55                   	push   %ebp
   1b4fd:	89 e5                	mov    %esp,%ebp
   1b4ff:	8b 55 08             	mov    0x8(%ebp),%edx
   1b502:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b505:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b508:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1b50c:	89 45 0c             	mov    %eax,0xc(%ebp)
   1b50f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b512:	5d                   	pop    %ebp
   1b513:	c3                   	ret    

0001b514 <ck_pr_faa_32>:
CK_PR_FAA_S(32, uint32_t, "xaddl")
   1b514:	55                   	push   %ebp
   1b515:	89 e5                	mov    %esp,%ebp
   1b517:	8b 55 08             	mov    0x8(%ebp),%edx
   1b51a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b51d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b520:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1b524:	89 45 0c             	mov    %eax,0xc(%ebp)
   1b527:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b52a:	5d                   	pop    %ebp
   1b52b:	c3                   	ret    

0001b52c <ck_pr_faa_16>:
CK_PR_FAA_S(16, uint16_t, "xaddw")
   1b52c:	55                   	push   %ebp
   1b52d:	89 e5                	mov    %esp,%ebp
   1b52f:	83 ec 04             	sub    $0x4,%esp
   1b532:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b535:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1b539:	8b 55 08             	mov    0x8(%ebp),%edx
   1b53c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b53f:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1b543:	66 f0 0f c1 02       	lock xadd %ax,(%edx)
   1b548:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1b54c:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1b550:	c9                   	leave  
   1b551:	c3                   	ret    

0001b552 <ck_pr_faa_8>:
CK_PR_FAA_S(8,  uint8_t,  "xaddb")
   1b552:	55                   	push   %ebp
   1b553:	89 e5                	mov    %esp,%ebp
   1b555:	83 ec 04             	sub    $0x4,%esp
   1b558:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b55b:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b55e:	8b 55 08             	mov    0x8(%ebp),%edx
   1b561:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b564:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1b568:	f0 0f c0 02          	lock xadd %al,(%edx)
   1b56c:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b56f:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1b573:	c9                   	leave  
   1b574:	c3                   	ret    

0001b575 <ck_pr_inc_ptr>:
	CK_PR_UNARY_S(K, uint, unsigned int, #K "l")	\
	CK_PR_UNARY_S(K, 32, uint32_t, #K "l")		\
	CK_PR_UNARY_S(K, 16, uint16_t, #K "w")		\
	CK_PR_UNARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(inc)
   1b575:	55                   	push   %ebp
   1b576:	89 e5                	mov    %esp,%ebp
   1b578:	8b 45 08             	mov    0x8(%ebp),%eax
   1b57b:	8b 55 08             	mov    0x8(%ebp),%edx
   1b57e:	f0 ff 00             	lock incl (%eax)
   1b581:	90                   	nop
   1b582:	5d                   	pop    %ebp
   1b583:	c3                   	ret    

0001b584 <ck_pr_inc_ptr_zero>:
   1b584:	55                   	push   %ebp
   1b585:	89 e5                	mov    %esp,%ebp
   1b587:	8b 45 08             	mov    0x8(%ebp),%eax
   1b58a:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b58d:	8b 55 08             	mov    0x8(%ebp),%edx
   1b590:	f0 ff 00             	lock incl (%eax)
   1b593:	0f 94 01             	sete   (%ecx)
   1b596:	90                   	nop
   1b597:	5d                   	pop    %ebp
   1b598:	c3                   	ret    

0001b599 <ck_pr_inc_char>:
   1b599:	55                   	push   %ebp
   1b59a:	89 e5                	mov    %esp,%ebp
   1b59c:	8b 45 08             	mov    0x8(%ebp),%eax
   1b59f:	8b 55 08             	mov    0x8(%ebp),%edx
   1b5a2:	f0 fe 00             	lock incb (%eax)
   1b5a5:	90                   	nop
   1b5a6:	5d                   	pop    %ebp
   1b5a7:	c3                   	ret    

0001b5a8 <ck_pr_inc_char_zero>:
   1b5a8:	55                   	push   %ebp
   1b5a9:	89 e5                	mov    %esp,%ebp
   1b5ab:	8b 45 08             	mov    0x8(%ebp),%eax
   1b5ae:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b5b1:	8b 55 08             	mov    0x8(%ebp),%edx
   1b5b4:	f0 fe 00             	lock incb (%eax)
   1b5b7:	0f 94 01             	sete   (%ecx)
   1b5ba:	90                   	nop
   1b5bb:	5d                   	pop    %ebp
   1b5bc:	c3                   	ret    

0001b5bd <ck_pr_inc_int>:
   1b5bd:	55                   	push   %ebp
   1b5be:	89 e5                	mov    %esp,%ebp
   1b5c0:	8b 45 08             	mov    0x8(%ebp),%eax
   1b5c3:	8b 55 08             	mov    0x8(%ebp),%edx
   1b5c6:	f0 ff 00             	lock incl (%eax)
   1b5c9:	90                   	nop
   1b5ca:	5d                   	pop    %ebp
   1b5cb:	c3                   	ret    

0001b5cc <ck_pr_inc_int_zero>:
   1b5cc:	55                   	push   %ebp
   1b5cd:	89 e5                	mov    %esp,%ebp
   1b5cf:	8b 45 08             	mov    0x8(%ebp),%eax
   1b5d2:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b5d5:	8b 55 08             	mov    0x8(%ebp),%edx
   1b5d8:	f0 ff 00             	lock incl (%eax)
   1b5db:	0f 94 01             	sete   (%ecx)
   1b5de:	90                   	nop
   1b5df:	5d                   	pop    %ebp
   1b5e0:	c3                   	ret    

0001b5e1 <ck_pr_inc_uint>:
   1b5e1:	55                   	push   %ebp
   1b5e2:	89 e5                	mov    %esp,%ebp
   1b5e4:	8b 45 08             	mov    0x8(%ebp),%eax
   1b5e7:	8b 55 08             	mov    0x8(%ebp),%edx
   1b5ea:	f0 ff 00             	lock incl (%eax)
   1b5ed:	90                   	nop
   1b5ee:	5d                   	pop    %ebp
   1b5ef:	c3                   	ret    

0001b5f0 <ck_pr_inc_uint_zero>:
   1b5f0:	55                   	push   %ebp
   1b5f1:	89 e5                	mov    %esp,%ebp
   1b5f3:	8b 45 08             	mov    0x8(%ebp),%eax
   1b5f6:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b5f9:	8b 55 08             	mov    0x8(%ebp),%edx
   1b5fc:	f0 ff 00             	lock incl (%eax)
   1b5ff:	0f 94 01             	sete   (%ecx)
   1b602:	90                   	nop
   1b603:	5d                   	pop    %ebp
   1b604:	c3                   	ret    

0001b605 <ck_pr_inc_32>:
   1b605:	55                   	push   %ebp
   1b606:	89 e5                	mov    %esp,%ebp
   1b608:	8b 45 08             	mov    0x8(%ebp),%eax
   1b60b:	8b 55 08             	mov    0x8(%ebp),%edx
   1b60e:	f0 ff 00             	lock incl (%eax)
   1b611:	90                   	nop
   1b612:	5d                   	pop    %ebp
   1b613:	c3                   	ret    

0001b614 <ck_pr_inc_32_zero>:
   1b614:	55                   	push   %ebp
   1b615:	89 e5                	mov    %esp,%ebp
   1b617:	8b 45 08             	mov    0x8(%ebp),%eax
   1b61a:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b61d:	8b 55 08             	mov    0x8(%ebp),%edx
   1b620:	f0 ff 00             	lock incl (%eax)
   1b623:	0f 94 01             	sete   (%ecx)
   1b626:	90                   	nop
   1b627:	5d                   	pop    %ebp
   1b628:	c3                   	ret    

0001b629 <ck_pr_inc_16>:
   1b629:	55                   	push   %ebp
   1b62a:	89 e5                	mov    %esp,%ebp
   1b62c:	8b 45 08             	mov    0x8(%ebp),%eax
   1b62f:	8b 55 08             	mov    0x8(%ebp),%edx
   1b632:	66 f0 ff 00          	lock incw (%eax)
   1b636:	90                   	nop
   1b637:	5d                   	pop    %ebp
   1b638:	c3                   	ret    

0001b639 <ck_pr_inc_16_zero>:
   1b639:	55                   	push   %ebp
   1b63a:	89 e5                	mov    %esp,%ebp
   1b63c:	8b 45 08             	mov    0x8(%ebp),%eax
   1b63f:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b642:	8b 55 08             	mov    0x8(%ebp),%edx
   1b645:	66 f0 ff 00          	lock incw (%eax)
   1b649:	0f 94 01             	sete   (%ecx)
   1b64c:	90                   	nop
   1b64d:	5d                   	pop    %ebp
   1b64e:	c3                   	ret    

0001b64f <ck_pr_inc_8>:
   1b64f:	55                   	push   %ebp
   1b650:	89 e5                	mov    %esp,%ebp
   1b652:	8b 45 08             	mov    0x8(%ebp),%eax
   1b655:	8b 55 08             	mov    0x8(%ebp),%edx
   1b658:	f0 fe 00             	lock incb (%eax)
   1b65b:	90                   	nop
   1b65c:	5d                   	pop    %ebp
   1b65d:	c3                   	ret    

0001b65e <ck_pr_inc_8_zero>:
   1b65e:	55                   	push   %ebp
   1b65f:	89 e5                	mov    %esp,%ebp
   1b661:	8b 45 08             	mov    0x8(%ebp),%eax
   1b664:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b667:	8b 55 08             	mov    0x8(%ebp),%edx
   1b66a:	f0 fe 00             	lock incb (%eax)
   1b66d:	0f 94 01             	sete   (%ecx)
   1b670:	90                   	nop
   1b671:	5d                   	pop    %ebp
   1b672:	c3                   	ret    

0001b673 <ck_pr_dec_ptr>:
CK_PR_GENERATE(dec)
   1b673:	55                   	push   %ebp
   1b674:	89 e5                	mov    %esp,%ebp
   1b676:	8b 45 08             	mov    0x8(%ebp),%eax
   1b679:	8b 55 08             	mov    0x8(%ebp),%edx
   1b67c:	f0 ff 08             	lock decl (%eax)
   1b67f:	90                   	nop
   1b680:	5d                   	pop    %ebp
   1b681:	c3                   	ret    

0001b682 <ck_pr_dec_ptr_zero>:
   1b682:	55                   	push   %ebp
   1b683:	89 e5                	mov    %esp,%ebp
   1b685:	8b 45 08             	mov    0x8(%ebp),%eax
   1b688:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b68b:	8b 55 08             	mov    0x8(%ebp),%edx
   1b68e:	f0 ff 08             	lock decl (%eax)
   1b691:	0f 94 01             	sete   (%ecx)
   1b694:	90                   	nop
   1b695:	5d                   	pop    %ebp
   1b696:	c3                   	ret    

0001b697 <ck_pr_dec_char>:
   1b697:	55                   	push   %ebp
   1b698:	89 e5                	mov    %esp,%ebp
   1b69a:	8b 45 08             	mov    0x8(%ebp),%eax
   1b69d:	8b 55 08             	mov    0x8(%ebp),%edx
   1b6a0:	f0 fe 08             	lock decb (%eax)
   1b6a3:	90                   	nop
   1b6a4:	5d                   	pop    %ebp
   1b6a5:	c3                   	ret    

0001b6a6 <ck_pr_dec_char_zero>:
   1b6a6:	55                   	push   %ebp
   1b6a7:	89 e5                	mov    %esp,%ebp
   1b6a9:	8b 45 08             	mov    0x8(%ebp),%eax
   1b6ac:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b6af:	8b 55 08             	mov    0x8(%ebp),%edx
   1b6b2:	f0 fe 08             	lock decb (%eax)
   1b6b5:	0f 94 01             	sete   (%ecx)
   1b6b8:	90                   	nop
   1b6b9:	5d                   	pop    %ebp
   1b6ba:	c3                   	ret    

0001b6bb <ck_pr_dec_int>:
   1b6bb:	55                   	push   %ebp
   1b6bc:	89 e5                	mov    %esp,%ebp
   1b6be:	8b 45 08             	mov    0x8(%ebp),%eax
   1b6c1:	8b 55 08             	mov    0x8(%ebp),%edx
   1b6c4:	f0 ff 08             	lock decl (%eax)
   1b6c7:	90                   	nop
   1b6c8:	5d                   	pop    %ebp
   1b6c9:	c3                   	ret    

0001b6ca <ck_pr_dec_int_zero>:
   1b6ca:	55                   	push   %ebp
   1b6cb:	89 e5                	mov    %esp,%ebp
   1b6cd:	8b 45 08             	mov    0x8(%ebp),%eax
   1b6d0:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b6d3:	8b 55 08             	mov    0x8(%ebp),%edx
   1b6d6:	f0 ff 08             	lock decl (%eax)
   1b6d9:	0f 94 01             	sete   (%ecx)
   1b6dc:	90                   	nop
   1b6dd:	5d                   	pop    %ebp
   1b6de:	c3                   	ret    

0001b6df <ck_pr_dec_uint>:
   1b6df:	55                   	push   %ebp
   1b6e0:	89 e5                	mov    %esp,%ebp
   1b6e2:	8b 45 08             	mov    0x8(%ebp),%eax
   1b6e5:	8b 55 08             	mov    0x8(%ebp),%edx
   1b6e8:	f0 ff 08             	lock decl (%eax)
   1b6eb:	90                   	nop
   1b6ec:	5d                   	pop    %ebp
   1b6ed:	c3                   	ret    

0001b6ee <ck_pr_dec_uint_zero>:
   1b6ee:	55                   	push   %ebp
   1b6ef:	89 e5                	mov    %esp,%ebp
   1b6f1:	8b 45 08             	mov    0x8(%ebp),%eax
   1b6f4:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b6f7:	8b 55 08             	mov    0x8(%ebp),%edx
   1b6fa:	f0 ff 08             	lock decl (%eax)
   1b6fd:	0f 94 01             	sete   (%ecx)
   1b700:	90                   	nop
   1b701:	5d                   	pop    %ebp
   1b702:	c3                   	ret    

0001b703 <ck_pr_dec_32>:
   1b703:	55                   	push   %ebp
   1b704:	89 e5                	mov    %esp,%ebp
   1b706:	8b 45 08             	mov    0x8(%ebp),%eax
   1b709:	8b 55 08             	mov    0x8(%ebp),%edx
   1b70c:	f0 ff 08             	lock decl (%eax)
   1b70f:	90                   	nop
   1b710:	5d                   	pop    %ebp
   1b711:	c3                   	ret    

0001b712 <ck_pr_dec_32_zero>:
   1b712:	55                   	push   %ebp
   1b713:	89 e5                	mov    %esp,%ebp
   1b715:	8b 45 08             	mov    0x8(%ebp),%eax
   1b718:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b71b:	8b 55 08             	mov    0x8(%ebp),%edx
   1b71e:	f0 ff 08             	lock decl (%eax)
   1b721:	0f 94 01             	sete   (%ecx)
   1b724:	90                   	nop
   1b725:	5d                   	pop    %ebp
   1b726:	c3                   	ret    

0001b727 <ck_pr_dec_16>:
   1b727:	55                   	push   %ebp
   1b728:	89 e5                	mov    %esp,%ebp
   1b72a:	8b 45 08             	mov    0x8(%ebp),%eax
   1b72d:	8b 55 08             	mov    0x8(%ebp),%edx
   1b730:	66 f0 ff 08          	lock decw (%eax)
   1b734:	90                   	nop
   1b735:	5d                   	pop    %ebp
   1b736:	c3                   	ret    

0001b737 <ck_pr_dec_16_zero>:
   1b737:	55                   	push   %ebp
   1b738:	89 e5                	mov    %esp,%ebp
   1b73a:	8b 45 08             	mov    0x8(%ebp),%eax
   1b73d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b740:	8b 55 08             	mov    0x8(%ebp),%edx
   1b743:	66 f0 ff 08          	lock decw (%eax)
   1b747:	0f 94 01             	sete   (%ecx)
   1b74a:	90                   	nop
   1b74b:	5d                   	pop    %ebp
   1b74c:	c3                   	ret    

0001b74d <ck_pr_dec_8>:
   1b74d:	55                   	push   %ebp
   1b74e:	89 e5                	mov    %esp,%ebp
   1b750:	8b 45 08             	mov    0x8(%ebp),%eax
   1b753:	8b 55 08             	mov    0x8(%ebp),%edx
   1b756:	f0 fe 08             	lock decb (%eax)
   1b759:	90                   	nop
   1b75a:	5d                   	pop    %ebp
   1b75b:	c3                   	ret    

0001b75c <ck_pr_dec_8_zero>:
   1b75c:	55                   	push   %ebp
   1b75d:	89 e5                	mov    %esp,%ebp
   1b75f:	8b 45 08             	mov    0x8(%ebp),%eax
   1b762:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b765:	8b 55 08             	mov    0x8(%ebp),%edx
   1b768:	f0 fe 08             	lock decb (%eax)
   1b76b:	0f 94 01             	sete   (%ecx)
   1b76e:	90                   	nop
   1b76f:	5d                   	pop    %ebp
   1b770:	c3                   	ret    

0001b771 <ck_pr_neg_ptr>:
CK_PR_GENERATE(neg)
   1b771:	55                   	push   %ebp
   1b772:	89 e5                	mov    %esp,%ebp
   1b774:	8b 45 08             	mov    0x8(%ebp),%eax
   1b777:	8b 55 08             	mov    0x8(%ebp),%edx
   1b77a:	f0 f7 18             	lock negl (%eax)
   1b77d:	90                   	nop
   1b77e:	5d                   	pop    %ebp
   1b77f:	c3                   	ret    

0001b780 <ck_pr_neg_ptr_zero>:
   1b780:	55                   	push   %ebp
   1b781:	89 e5                	mov    %esp,%ebp
   1b783:	8b 45 08             	mov    0x8(%ebp),%eax
   1b786:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b789:	8b 55 08             	mov    0x8(%ebp),%edx
   1b78c:	f0 f7 18             	lock negl (%eax)
   1b78f:	0f 94 01             	sete   (%ecx)
   1b792:	90                   	nop
   1b793:	5d                   	pop    %ebp
   1b794:	c3                   	ret    

0001b795 <ck_pr_neg_char>:
   1b795:	55                   	push   %ebp
   1b796:	89 e5                	mov    %esp,%ebp
   1b798:	8b 45 08             	mov    0x8(%ebp),%eax
   1b79b:	8b 55 08             	mov    0x8(%ebp),%edx
   1b79e:	f0 f6 18             	lock negb (%eax)
   1b7a1:	90                   	nop
   1b7a2:	5d                   	pop    %ebp
   1b7a3:	c3                   	ret    

0001b7a4 <ck_pr_neg_char_zero>:
   1b7a4:	55                   	push   %ebp
   1b7a5:	89 e5                	mov    %esp,%ebp
   1b7a7:	8b 45 08             	mov    0x8(%ebp),%eax
   1b7aa:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b7ad:	8b 55 08             	mov    0x8(%ebp),%edx
   1b7b0:	f0 f6 18             	lock negb (%eax)
   1b7b3:	0f 94 01             	sete   (%ecx)
   1b7b6:	90                   	nop
   1b7b7:	5d                   	pop    %ebp
   1b7b8:	c3                   	ret    

0001b7b9 <ck_pr_neg_int>:
   1b7b9:	55                   	push   %ebp
   1b7ba:	89 e5                	mov    %esp,%ebp
   1b7bc:	8b 45 08             	mov    0x8(%ebp),%eax
   1b7bf:	8b 55 08             	mov    0x8(%ebp),%edx
   1b7c2:	f0 f7 18             	lock negl (%eax)
   1b7c5:	90                   	nop
   1b7c6:	5d                   	pop    %ebp
   1b7c7:	c3                   	ret    

0001b7c8 <ck_pr_neg_int_zero>:
   1b7c8:	55                   	push   %ebp
   1b7c9:	89 e5                	mov    %esp,%ebp
   1b7cb:	8b 45 08             	mov    0x8(%ebp),%eax
   1b7ce:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b7d1:	8b 55 08             	mov    0x8(%ebp),%edx
   1b7d4:	f0 f7 18             	lock negl (%eax)
   1b7d7:	0f 94 01             	sete   (%ecx)
   1b7da:	90                   	nop
   1b7db:	5d                   	pop    %ebp
   1b7dc:	c3                   	ret    

0001b7dd <ck_pr_neg_uint>:
   1b7dd:	55                   	push   %ebp
   1b7de:	89 e5                	mov    %esp,%ebp
   1b7e0:	8b 45 08             	mov    0x8(%ebp),%eax
   1b7e3:	8b 55 08             	mov    0x8(%ebp),%edx
   1b7e6:	f0 f7 18             	lock negl (%eax)
   1b7e9:	90                   	nop
   1b7ea:	5d                   	pop    %ebp
   1b7eb:	c3                   	ret    

0001b7ec <ck_pr_neg_uint_zero>:
   1b7ec:	55                   	push   %ebp
   1b7ed:	89 e5                	mov    %esp,%ebp
   1b7ef:	8b 45 08             	mov    0x8(%ebp),%eax
   1b7f2:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b7f5:	8b 55 08             	mov    0x8(%ebp),%edx
   1b7f8:	f0 f7 18             	lock negl (%eax)
   1b7fb:	0f 94 01             	sete   (%ecx)
   1b7fe:	90                   	nop
   1b7ff:	5d                   	pop    %ebp
   1b800:	c3                   	ret    

0001b801 <ck_pr_neg_32>:
   1b801:	55                   	push   %ebp
   1b802:	89 e5                	mov    %esp,%ebp
   1b804:	8b 45 08             	mov    0x8(%ebp),%eax
   1b807:	8b 55 08             	mov    0x8(%ebp),%edx
   1b80a:	f0 f7 18             	lock negl (%eax)
   1b80d:	90                   	nop
   1b80e:	5d                   	pop    %ebp
   1b80f:	c3                   	ret    

0001b810 <ck_pr_neg_32_zero>:
   1b810:	55                   	push   %ebp
   1b811:	89 e5                	mov    %esp,%ebp
   1b813:	8b 45 08             	mov    0x8(%ebp),%eax
   1b816:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b819:	8b 55 08             	mov    0x8(%ebp),%edx
   1b81c:	f0 f7 18             	lock negl (%eax)
   1b81f:	0f 94 01             	sete   (%ecx)
   1b822:	90                   	nop
   1b823:	5d                   	pop    %ebp
   1b824:	c3                   	ret    

0001b825 <ck_pr_neg_16>:
   1b825:	55                   	push   %ebp
   1b826:	89 e5                	mov    %esp,%ebp
   1b828:	8b 45 08             	mov    0x8(%ebp),%eax
   1b82b:	8b 55 08             	mov    0x8(%ebp),%edx
   1b82e:	66 f0 f7 18          	lock negw (%eax)
   1b832:	90                   	nop
   1b833:	5d                   	pop    %ebp
   1b834:	c3                   	ret    

0001b835 <ck_pr_neg_16_zero>:
   1b835:	55                   	push   %ebp
   1b836:	89 e5                	mov    %esp,%ebp
   1b838:	8b 45 08             	mov    0x8(%ebp),%eax
   1b83b:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b83e:	8b 55 08             	mov    0x8(%ebp),%edx
   1b841:	66 f0 f7 18          	lock negw (%eax)
   1b845:	0f 94 01             	sete   (%ecx)
   1b848:	90                   	nop
   1b849:	5d                   	pop    %ebp
   1b84a:	c3                   	ret    

0001b84b <ck_pr_neg_8>:
   1b84b:	55                   	push   %ebp
   1b84c:	89 e5                	mov    %esp,%ebp
   1b84e:	8b 45 08             	mov    0x8(%ebp),%eax
   1b851:	8b 55 08             	mov    0x8(%ebp),%edx
   1b854:	f0 f6 18             	lock negb (%eax)
   1b857:	90                   	nop
   1b858:	5d                   	pop    %ebp
   1b859:	c3                   	ret    

0001b85a <ck_pr_neg_8_zero>:
   1b85a:	55                   	push   %ebp
   1b85b:	89 e5                	mov    %esp,%ebp
   1b85d:	8b 45 08             	mov    0x8(%ebp),%eax
   1b860:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1b863:	8b 55 08             	mov    0x8(%ebp),%edx
   1b866:	f0 f6 18             	lock negb (%eax)
   1b869:	0f 94 01             	sete   (%ecx)
   1b86c:	90                   	nop
   1b86d:	5d                   	pop    %ebp
   1b86e:	c3                   	ret    

0001b86f <ck_pr_not_ptr>:

/* not does not affect condition flags. */
#undef CK_PR_UNARY_V
#define CK_PR_UNARY_V(a, b, c, d, e)
CK_PR_GENERATE(not)
   1b86f:	55                   	push   %ebp
   1b870:	89 e5                	mov    %esp,%ebp
   1b872:	8b 45 08             	mov    0x8(%ebp),%eax
   1b875:	8b 55 08             	mov    0x8(%ebp),%edx
   1b878:	f0 f7 10             	lock notl (%eax)
   1b87b:	90                   	nop
   1b87c:	5d                   	pop    %ebp
   1b87d:	c3                   	ret    

0001b87e <ck_pr_not_char>:
   1b87e:	55                   	push   %ebp
   1b87f:	89 e5                	mov    %esp,%ebp
   1b881:	8b 45 08             	mov    0x8(%ebp),%eax
   1b884:	8b 55 08             	mov    0x8(%ebp),%edx
   1b887:	f0 f6 10             	lock notb (%eax)
   1b88a:	90                   	nop
   1b88b:	5d                   	pop    %ebp
   1b88c:	c3                   	ret    

0001b88d <ck_pr_not_int>:
   1b88d:	55                   	push   %ebp
   1b88e:	89 e5                	mov    %esp,%ebp
   1b890:	8b 45 08             	mov    0x8(%ebp),%eax
   1b893:	8b 55 08             	mov    0x8(%ebp),%edx
   1b896:	f0 f7 10             	lock notl (%eax)
   1b899:	90                   	nop
   1b89a:	5d                   	pop    %ebp
   1b89b:	c3                   	ret    

0001b89c <ck_pr_not_uint>:
   1b89c:	55                   	push   %ebp
   1b89d:	89 e5                	mov    %esp,%ebp
   1b89f:	8b 45 08             	mov    0x8(%ebp),%eax
   1b8a2:	8b 55 08             	mov    0x8(%ebp),%edx
   1b8a5:	f0 f7 10             	lock notl (%eax)
   1b8a8:	90                   	nop
   1b8a9:	5d                   	pop    %ebp
   1b8aa:	c3                   	ret    

0001b8ab <ck_pr_not_32>:
   1b8ab:	55                   	push   %ebp
   1b8ac:	89 e5                	mov    %esp,%ebp
   1b8ae:	8b 45 08             	mov    0x8(%ebp),%eax
   1b8b1:	8b 55 08             	mov    0x8(%ebp),%edx
   1b8b4:	f0 f7 10             	lock notl (%eax)
   1b8b7:	90                   	nop
   1b8b8:	5d                   	pop    %ebp
   1b8b9:	c3                   	ret    

0001b8ba <ck_pr_not_16>:
   1b8ba:	55                   	push   %ebp
   1b8bb:	89 e5                	mov    %esp,%ebp
   1b8bd:	8b 45 08             	mov    0x8(%ebp),%eax
   1b8c0:	8b 55 08             	mov    0x8(%ebp),%edx
   1b8c3:	66 f0 f7 10          	lock notw (%eax)
   1b8c7:	90                   	nop
   1b8c8:	5d                   	pop    %ebp
   1b8c9:	c3                   	ret    

0001b8ca <ck_pr_not_8>:
   1b8ca:	55                   	push   %ebp
   1b8cb:	89 e5                	mov    %esp,%ebp
   1b8cd:	8b 45 08             	mov    0x8(%ebp),%eax
   1b8d0:	8b 55 08             	mov    0x8(%ebp),%edx
   1b8d3:	f0 f6 10             	lock notb (%eax)
   1b8d6:	90                   	nop
   1b8d7:	5d                   	pop    %ebp
   1b8d8:	c3                   	ret    

0001b8d9 <ck_pr_add_ptr>:
	CK_PR_BINARY_S(K, uint, unsigned int, #K "l")		\
	CK_PR_BINARY_S(K, 32, uint32_t, #K "l")			\
	CK_PR_BINARY_S(K, 16, uint16_t, #K "w")			\
	CK_PR_BINARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(add)
   1b8d9:	55                   	push   %ebp
   1b8da:	89 e5                	mov    %esp,%ebp
   1b8dc:	8b 45 08             	mov    0x8(%ebp),%eax
   1b8df:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b8e2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b8e5:	f0 01 10             	lock add %edx,(%eax)
   1b8e8:	90                   	nop
   1b8e9:	5d                   	pop    %ebp
   1b8ea:	c3                   	ret    

0001b8eb <ck_pr_add_char>:
   1b8eb:	55                   	push   %ebp
   1b8ec:	89 e5                	mov    %esp,%ebp
   1b8ee:	83 ec 04             	sub    $0x4,%esp
   1b8f1:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b8f4:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b8f7:	8b 45 08             	mov    0x8(%ebp),%eax
   1b8fa:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1b8fe:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b901:	f0 00 10             	lock add %dl,(%eax)
   1b904:	90                   	nop
   1b905:	c9                   	leave  
   1b906:	c3                   	ret    

0001b907 <ck_pr_add_int>:
   1b907:	55                   	push   %ebp
   1b908:	89 e5                	mov    %esp,%ebp
   1b90a:	8b 45 08             	mov    0x8(%ebp),%eax
   1b90d:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b910:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b913:	f0 01 10             	lock add %edx,(%eax)
   1b916:	90                   	nop
   1b917:	5d                   	pop    %ebp
   1b918:	c3                   	ret    

0001b919 <ck_pr_add_uint>:
   1b919:	55                   	push   %ebp
   1b91a:	89 e5                	mov    %esp,%ebp
   1b91c:	8b 45 08             	mov    0x8(%ebp),%eax
   1b91f:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b922:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b925:	f0 01 10             	lock add %edx,(%eax)
   1b928:	90                   	nop
   1b929:	5d                   	pop    %ebp
   1b92a:	c3                   	ret    

0001b92b <ck_pr_add_32>:
   1b92b:	55                   	push   %ebp
   1b92c:	89 e5                	mov    %esp,%ebp
   1b92e:	8b 45 08             	mov    0x8(%ebp),%eax
   1b931:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b934:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b937:	f0 01 10             	lock add %edx,(%eax)
   1b93a:	90                   	nop
   1b93b:	5d                   	pop    %ebp
   1b93c:	c3                   	ret    

0001b93d <ck_pr_add_16>:
   1b93d:	55                   	push   %ebp
   1b93e:	89 e5                	mov    %esp,%ebp
   1b940:	83 ec 04             	sub    $0x4,%esp
   1b943:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b946:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1b94a:	8b 45 08             	mov    0x8(%ebp),%eax
   1b94d:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1b951:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b954:	66 f0 01 10          	lock add %dx,(%eax)
   1b958:	90                   	nop
   1b959:	c9                   	leave  
   1b95a:	c3                   	ret    

0001b95b <ck_pr_add_8>:
   1b95b:	55                   	push   %ebp
   1b95c:	89 e5                	mov    %esp,%ebp
   1b95e:	83 ec 04             	sub    $0x4,%esp
   1b961:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b964:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b967:	8b 45 08             	mov    0x8(%ebp),%eax
   1b96a:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1b96e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b971:	f0 00 10             	lock add %dl,(%eax)
   1b974:	90                   	nop
   1b975:	c9                   	leave  
   1b976:	c3                   	ret    

0001b977 <ck_pr_sub_ptr>:
CK_PR_GENERATE(sub)
   1b977:	55                   	push   %ebp
   1b978:	89 e5                	mov    %esp,%ebp
   1b97a:	8b 45 08             	mov    0x8(%ebp),%eax
   1b97d:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b980:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b983:	f0 29 10             	lock sub %edx,(%eax)
   1b986:	90                   	nop
   1b987:	5d                   	pop    %ebp
   1b988:	c3                   	ret    

0001b989 <ck_pr_sub_char>:
   1b989:	55                   	push   %ebp
   1b98a:	89 e5                	mov    %esp,%ebp
   1b98c:	83 ec 04             	sub    $0x4,%esp
   1b98f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b992:	88 45 fc             	mov    %al,-0x4(%ebp)
   1b995:	8b 45 08             	mov    0x8(%ebp),%eax
   1b998:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1b99c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b99f:	f0 28 10             	lock sub %dl,(%eax)
   1b9a2:	90                   	nop
   1b9a3:	c9                   	leave  
   1b9a4:	c3                   	ret    

0001b9a5 <ck_pr_sub_int>:
   1b9a5:	55                   	push   %ebp
   1b9a6:	89 e5                	mov    %esp,%ebp
   1b9a8:	8b 45 08             	mov    0x8(%ebp),%eax
   1b9ab:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b9ae:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b9b1:	f0 29 10             	lock sub %edx,(%eax)
   1b9b4:	90                   	nop
   1b9b5:	5d                   	pop    %ebp
   1b9b6:	c3                   	ret    

0001b9b7 <ck_pr_sub_uint>:
   1b9b7:	55                   	push   %ebp
   1b9b8:	89 e5                	mov    %esp,%ebp
   1b9ba:	8b 45 08             	mov    0x8(%ebp),%eax
   1b9bd:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b9c0:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b9c3:	f0 29 10             	lock sub %edx,(%eax)
   1b9c6:	90                   	nop
   1b9c7:	5d                   	pop    %ebp
   1b9c8:	c3                   	ret    

0001b9c9 <ck_pr_sub_32>:
   1b9c9:	55                   	push   %ebp
   1b9ca:	89 e5                	mov    %esp,%ebp
   1b9cc:	8b 45 08             	mov    0x8(%ebp),%eax
   1b9cf:	8b 55 0c             	mov    0xc(%ebp),%edx
   1b9d2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b9d5:	f0 29 10             	lock sub %edx,(%eax)
   1b9d8:	90                   	nop
   1b9d9:	5d                   	pop    %ebp
   1b9da:	c3                   	ret    

0001b9db <ck_pr_sub_16>:
   1b9db:	55                   	push   %ebp
   1b9dc:	89 e5                	mov    %esp,%ebp
   1b9de:	83 ec 04             	sub    $0x4,%esp
   1b9e1:	8b 45 0c             	mov    0xc(%ebp),%eax
   1b9e4:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1b9e8:	8b 45 08             	mov    0x8(%ebp),%eax
   1b9eb:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1b9ef:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1b9f2:	66 f0 29 10          	lock sub %dx,(%eax)
   1b9f6:	90                   	nop
   1b9f7:	c9                   	leave  
   1b9f8:	c3                   	ret    

0001b9f9 <ck_pr_sub_8>:
   1b9f9:	55                   	push   %ebp
   1b9fa:	89 e5                	mov    %esp,%ebp
   1b9fc:	83 ec 04             	sub    $0x4,%esp
   1b9ff:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ba02:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ba05:	8b 45 08             	mov    0x8(%ebp),%eax
   1ba08:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ba0c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ba0f:	f0 28 10             	lock sub %dl,(%eax)
   1ba12:	90                   	nop
   1ba13:	c9                   	leave  
   1ba14:	c3                   	ret    

0001ba15 <ck_pr_and_ptr>:
CK_PR_GENERATE(and)
   1ba15:	55                   	push   %ebp
   1ba16:	89 e5                	mov    %esp,%ebp
   1ba18:	8b 45 08             	mov    0x8(%ebp),%eax
   1ba1b:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ba1e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ba21:	f0 21 10             	lock and %edx,(%eax)
   1ba24:	90                   	nop
   1ba25:	5d                   	pop    %ebp
   1ba26:	c3                   	ret    

0001ba27 <ck_pr_and_char>:
   1ba27:	55                   	push   %ebp
   1ba28:	89 e5                	mov    %esp,%ebp
   1ba2a:	83 ec 04             	sub    $0x4,%esp
   1ba2d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ba30:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ba33:	8b 45 08             	mov    0x8(%ebp),%eax
   1ba36:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ba3a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ba3d:	f0 20 10             	lock and %dl,(%eax)
   1ba40:	90                   	nop
   1ba41:	c9                   	leave  
   1ba42:	c3                   	ret    

0001ba43 <ck_pr_and_int>:
   1ba43:	55                   	push   %ebp
   1ba44:	89 e5                	mov    %esp,%ebp
   1ba46:	8b 45 08             	mov    0x8(%ebp),%eax
   1ba49:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ba4c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ba4f:	f0 21 10             	lock and %edx,(%eax)
   1ba52:	90                   	nop
   1ba53:	5d                   	pop    %ebp
   1ba54:	c3                   	ret    

0001ba55 <ck_pr_and_uint>:
   1ba55:	55                   	push   %ebp
   1ba56:	89 e5                	mov    %esp,%ebp
   1ba58:	8b 45 08             	mov    0x8(%ebp),%eax
   1ba5b:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ba5e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ba61:	f0 21 10             	lock and %edx,(%eax)
   1ba64:	90                   	nop
   1ba65:	5d                   	pop    %ebp
   1ba66:	c3                   	ret    

0001ba67 <ck_pr_and_32>:
   1ba67:	55                   	push   %ebp
   1ba68:	89 e5                	mov    %esp,%ebp
   1ba6a:	8b 45 08             	mov    0x8(%ebp),%eax
   1ba6d:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ba70:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ba73:	f0 21 10             	lock and %edx,(%eax)
   1ba76:	90                   	nop
   1ba77:	5d                   	pop    %ebp
   1ba78:	c3                   	ret    

0001ba79 <ck_pr_and_16>:
   1ba79:	55                   	push   %ebp
   1ba7a:	89 e5                	mov    %esp,%ebp
   1ba7c:	83 ec 04             	sub    $0x4,%esp
   1ba7f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ba82:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1ba86:	8b 45 08             	mov    0x8(%ebp),%eax
   1ba89:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1ba8d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ba90:	66 f0 21 10          	lock and %dx,(%eax)
   1ba94:	90                   	nop
   1ba95:	c9                   	leave  
   1ba96:	c3                   	ret    

0001ba97 <ck_pr_and_8>:
   1ba97:	55                   	push   %ebp
   1ba98:	89 e5                	mov    %esp,%ebp
   1ba9a:	83 ec 04             	sub    $0x4,%esp
   1ba9d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1baa0:	88 45 fc             	mov    %al,-0x4(%ebp)
   1baa3:	8b 45 08             	mov    0x8(%ebp),%eax
   1baa6:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1baaa:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1baad:	f0 20 10             	lock and %dl,(%eax)
   1bab0:	90                   	nop
   1bab1:	c9                   	leave  
   1bab2:	c3                   	ret    

0001bab3 <ck_pr_or_ptr>:
CK_PR_GENERATE(or)
   1bab3:	55                   	push   %ebp
   1bab4:	89 e5                	mov    %esp,%ebp
   1bab6:	8b 45 08             	mov    0x8(%ebp),%eax
   1bab9:	8b 55 0c             	mov    0xc(%ebp),%edx
   1babc:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1babf:	f0 09 10             	lock or %edx,(%eax)
   1bac2:	90                   	nop
   1bac3:	5d                   	pop    %ebp
   1bac4:	c3                   	ret    

0001bac5 <ck_pr_or_char>:
   1bac5:	55                   	push   %ebp
   1bac6:	89 e5                	mov    %esp,%ebp
   1bac8:	83 ec 04             	sub    $0x4,%esp
   1bacb:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bace:	88 45 fc             	mov    %al,-0x4(%ebp)
   1bad1:	8b 45 08             	mov    0x8(%ebp),%eax
   1bad4:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1bad8:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1badb:	f0 08 10             	lock or %dl,(%eax)
   1bade:	90                   	nop
   1badf:	c9                   	leave  
   1bae0:	c3                   	ret    

0001bae1 <ck_pr_or_int>:
   1bae1:	55                   	push   %ebp
   1bae2:	89 e5                	mov    %esp,%ebp
   1bae4:	8b 45 08             	mov    0x8(%ebp),%eax
   1bae7:	8b 55 0c             	mov    0xc(%ebp),%edx
   1baea:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1baed:	f0 09 10             	lock or %edx,(%eax)
   1baf0:	90                   	nop
   1baf1:	5d                   	pop    %ebp
   1baf2:	c3                   	ret    

0001baf3 <ck_pr_or_uint>:
   1baf3:	55                   	push   %ebp
   1baf4:	89 e5                	mov    %esp,%ebp
   1baf6:	8b 45 08             	mov    0x8(%ebp),%eax
   1baf9:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bafc:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1baff:	f0 09 10             	lock or %edx,(%eax)
   1bb02:	90                   	nop
   1bb03:	5d                   	pop    %ebp
   1bb04:	c3                   	ret    

0001bb05 <ck_pr_or_32>:
   1bb05:	55                   	push   %ebp
   1bb06:	89 e5                	mov    %esp,%ebp
   1bb08:	8b 45 08             	mov    0x8(%ebp),%eax
   1bb0b:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bb0e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bb11:	f0 09 10             	lock or %edx,(%eax)
   1bb14:	90                   	nop
   1bb15:	5d                   	pop    %ebp
   1bb16:	c3                   	ret    

0001bb17 <ck_pr_or_16>:
   1bb17:	55                   	push   %ebp
   1bb18:	89 e5                	mov    %esp,%ebp
   1bb1a:	83 ec 04             	sub    $0x4,%esp
   1bb1d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bb20:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1bb24:	8b 45 08             	mov    0x8(%ebp),%eax
   1bb27:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1bb2b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bb2e:	66 f0 09 10          	lock or %dx,(%eax)
   1bb32:	90                   	nop
   1bb33:	c9                   	leave  
   1bb34:	c3                   	ret    

0001bb35 <ck_pr_or_8>:
   1bb35:	55                   	push   %ebp
   1bb36:	89 e5                	mov    %esp,%ebp
   1bb38:	83 ec 04             	sub    $0x4,%esp
   1bb3b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bb3e:	88 45 fc             	mov    %al,-0x4(%ebp)
   1bb41:	8b 45 08             	mov    0x8(%ebp),%eax
   1bb44:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1bb48:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bb4b:	f0 08 10             	lock or %dl,(%eax)
   1bb4e:	90                   	nop
   1bb4f:	c9                   	leave  
   1bb50:	c3                   	ret    

0001bb51 <ck_pr_xor_ptr>:
CK_PR_GENERATE(xor)
   1bb51:	55                   	push   %ebp
   1bb52:	89 e5                	mov    %esp,%ebp
   1bb54:	8b 45 08             	mov    0x8(%ebp),%eax
   1bb57:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bb5a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bb5d:	f0 31 10             	lock xor %edx,(%eax)
   1bb60:	90                   	nop
   1bb61:	5d                   	pop    %ebp
   1bb62:	c3                   	ret    

0001bb63 <ck_pr_xor_char>:
   1bb63:	55                   	push   %ebp
   1bb64:	89 e5                	mov    %esp,%ebp
   1bb66:	83 ec 04             	sub    $0x4,%esp
   1bb69:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bb6c:	88 45 fc             	mov    %al,-0x4(%ebp)
   1bb6f:	8b 45 08             	mov    0x8(%ebp),%eax
   1bb72:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1bb76:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bb79:	f0 30 10             	lock xor %dl,(%eax)
   1bb7c:	90                   	nop
   1bb7d:	c9                   	leave  
   1bb7e:	c3                   	ret    

0001bb7f <ck_pr_xor_int>:
   1bb7f:	55                   	push   %ebp
   1bb80:	89 e5                	mov    %esp,%ebp
   1bb82:	8b 45 08             	mov    0x8(%ebp),%eax
   1bb85:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bb88:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bb8b:	f0 31 10             	lock xor %edx,(%eax)
   1bb8e:	90                   	nop
   1bb8f:	5d                   	pop    %ebp
   1bb90:	c3                   	ret    

0001bb91 <ck_pr_xor_uint>:
   1bb91:	55                   	push   %ebp
   1bb92:	89 e5                	mov    %esp,%ebp
   1bb94:	8b 45 08             	mov    0x8(%ebp),%eax
   1bb97:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bb9a:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bb9d:	f0 31 10             	lock xor %edx,(%eax)
   1bba0:	90                   	nop
   1bba1:	5d                   	pop    %ebp
   1bba2:	c3                   	ret    

0001bba3 <ck_pr_xor_32>:
   1bba3:	55                   	push   %ebp
   1bba4:	89 e5                	mov    %esp,%ebp
   1bba6:	8b 45 08             	mov    0x8(%ebp),%eax
   1bba9:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bbac:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bbaf:	f0 31 10             	lock xor %edx,(%eax)
   1bbb2:	90                   	nop
   1bbb3:	5d                   	pop    %ebp
   1bbb4:	c3                   	ret    

0001bbb5 <ck_pr_xor_16>:
   1bbb5:	55                   	push   %ebp
   1bbb6:	89 e5                	mov    %esp,%ebp
   1bbb8:	83 ec 04             	sub    $0x4,%esp
   1bbbb:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bbbe:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1bbc2:	8b 45 08             	mov    0x8(%ebp),%eax
   1bbc5:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1bbc9:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bbcc:	66 f0 31 10          	lock xor %dx,(%eax)
   1bbd0:	90                   	nop
   1bbd1:	c9                   	leave  
   1bbd2:	c3                   	ret    

0001bbd3 <ck_pr_xor_8>:
   1bbd3:	55                   	push   %ebp
   1bbd4:	89 e5                	mov    %esp,%ebp
   1bbd6:	83 ec 04             	sub    $0x4,%esp
   1bbd9:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bbdc:	88 45 fc             	mov    %al,-0x4(%ebp)
   1bbdf:	8b 45 08             	mov    0x8(%ebp),%eax
   1bbe2:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1bbe6:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bbe9:	f0 30 10             	lock xor %dl,(%eax)
   1bbec:	90                   	nop
   1bbed:	c9                   	leave  
   1bbee:	c3                   	ret    

0001bbef <ck_pr_cas_ptr>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return z;							\
	}

CK_PR_CAS(ptr, void, void *, char, "cmpxchgl")
   1bbef:	55                   	push   %ebp
   1bbf0:	89 e5                	mov    %esp,%ebp
   1bbf2:	53                   	push   %ebx
   1bbf3:	83 ec 10             	sub    $0x10,%esp
   1bbf6:	8b 55 08             	mov    0x8(%ebp),%edx
   1bbf9:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1bbfc:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bbff:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bc02:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1bc06:	0f 94 c0             	sete   %al
   1bc09:	88 45 fb             	mov    %al,-0x5(%ebp)
   1bc0c:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1bc10:	83 c4 10             	add    $0x10,%esp
   1bc13:	5b                   	pop    %ebx
   1bc14:	5d                   	pop    %ebp
   1bc15:	c3                   	ret    

0001bc16 <ck_pr_cas_char>:

#define CK_PR_CAS_S(S, T, I) CK_PR_CAS(S, T, T, T, I)

CK_PR_CAS_S(char, char, "cmpxchgb")
   1bc16:	55                   	push   %ebp
   1bc17:	89 e5                	mov    %esp,%ebp
   1bc19:	53                   	push   %ebx
   1bc1a:	83 ec 18             	sub    $0x18,%esp
   1bc1d:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bc20:	8b 45 10             	mov    0x10(%ebp),%eax
   1bc23:	88 55 e8             	mov    %dl,-0x18(%ebp)
   1bc26:	88 45 e4             	mov    %al,-0x1c(%ebp)
   1bc29:	8b 55 08             	mov    0x8(%ebp),%edx
   1bc2c:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   1bc30:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   1bc34:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bc37:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   1bc3b:	0f 94 c0             	sete   %al
   1bc3e:	88 45 fb             	mov    %al,-0x5(%ebp)
   1bc41:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1bc45:	83 c4 18             	add    $0x18,%esp
   1bc48:	5b                   	pop    %ebx
   1bc49:	5d                   	pop    %ebp
   1bc4a:	c3                   	ret    

0001bc4b <ck_pr_cas_int>:
CK_PR_CAS_S(int, int, "cmpxchgl")
   1bc4b:	55                   	push   %ebp
   1bc4c:	89 e5                	mov    %esp,%ebp
   1bc4e:	53                   	push   %ebx
   1bc4f:	83 ec 10             	sub    $0x10,%esp
   1bc52:	8b 55 08             	mov    0x8(%ebp),%edx
   1bc55:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1bc58:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bc5b:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bc5e:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1bc62:	0f 94 c0             	sete   %al
   1bc65:	88 45 fb             	mov    %al,-0x5(%ebp)
   1bc68:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1bc6c:	83 c4 10             	add    $0x10,%esp
   1bc6f:	5b                   	pop    %ebx
   1bc70:	5d                   	pop    %ebp
   1bc71:	c3                   	ret    

0001bc72 <ck_pr_cas_uint>:
CK_PR_CAS_S(uint, unsigned int, "cmpxchgl")
   1bc72:	55                   	push   %ebp
   1bc73:	89 e5                	mov    %esp,%ebp
   1bc75:	53                   	push   %ebx
   1bc76:	83 ec 10             	sub    $0x10,%esp
   1bc79:	8b 55 08             	mov    0x8(%ebp),%edx
   1bc7c:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1bc7f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bc82:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bc85:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1bc89:	0f 94 c0             	sete   %al
   1bc8c:	88 45 fb             	mov    %al,-0x5(%ebp)
   1bc8f:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1bc93:	83 c4 10             	add    $0x10,%esp
   1bc96:	5b                   	pop    %ebx
   1bc97:	5d                   	pop    %ebp
   1bc98:	c3                   	ret    

0001bc99 <ck_pr_cas_32>:
CK_PR_CAS_S(32, uint32_t, "cmpxchgl")
   1bc99:	55                   	push   %ebp
   1bc9a:	89 e5                	mov    %esp,%ebp
   1bc9c:	53                   	push   %ebx
   1bc9d:	83 ec 10             	sub    $0x10,%esp
   1bca0:	8b 55 08             	mov    0x8(%ebp),%edx
   1bca3:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1bca6:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bca9:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bcac:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1bcb0:	0f 94 c0             	sete   %al
   1bcb3:	88 45 fb             	mov    %al,-0x5(%ebp)
   1bcb6:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1bcba:	83 c4 10             	add    $0x10,%esp
   1bcbd:	5b                   	pop    %ebx
   1bcbe:	5d                   	pop    %ebp
   1bcbf:	c3                   	ret    

0001bcc0 <ck_pr_cas_16>:
CK_PR_CAS_S(16, uint16_t, "cmpxchgw")
   1bcc0:	55                   	push   %ebp
   1bcc1:	89 e5                	mov    %esp,%ebp
   1bcc3:	53                   	push   %ebx
   1bcc4:	83 ec 18             	sub    $0x18,%esp
   1bcc7:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bcca:	8b 45 10             	mov    0x10(%ebp),%eax
   1bccd:	66 89 55 e8          	mov    %dx,-0x18(%ebp)
   1bcd1:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   1bcd5:	8b 55 08             	mov    0x8(%ebp),%edx
   1bcd8:	0f b7 4d e4          	movzwl -0x1c(%ebp),%ecx
   1bcdc:	0f b7 45 e8          	movzwl -0x18(%ebp),%eax
   1bce0:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bce3:	66 f0 0f b1 0a       	lock cmpxchg %cx,(%edx)
   1bce8:	0f 94 c0             	sete   %al
   1bceb:	88 45 fb             	mov    %al,-0x5(%ebp)
   1bcee:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1bcf2:	83 c4 18             	add    $0x18,%esp
   1bcf5:	5b                   	pop    %ebx
   1bcf6:	5d                   	pop    %ebp
   1bcf7:	c3                   	ret    

0001bcf8 <ck_pr_cas_8>:
CK_PR_CAS_S(8,  uint8_t,  "cmpxchgb")
   1bcf8:	55                   	push   %ebp
   1bcf9:	89 e5                	mov    %esp,%ebp
   1bcfb:	53                   	push   %ebx
   1bcfc:	83 ec 18             	sub    $0x18,%esp
   1bcff:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bd02:	8b 45 10             	mov    0x10(%ebp),%eax
   1bd05:	88 55 e8             	mov    %dl,-0x18(%ebp)
   1bd08:	88 45 e4             	mov    %al,-0x1c(%ebp)
   1bd0b:	8b 55 08             	mov    0x8(%ebp),%edx
   1bd0e:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   1bd12:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   1bd16:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bd19:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   1bd1d:	0f 94 c0             	sete   %al
   1bd20:	88 45 fb             	mov    %al,-0x5(%ebp)
   1bd23:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1bd27:	83 c4 18             	add    $0x18,%esp
   1bd2a:	5b                   	pop    %ebx
   1bd2b:	5d                   	pop    %ebp
   1bd2c:	c3                   	ret    

0001bd2d <ck_pr_cas_ptr_value>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return (bool)z;							\
	}

CK_PR_CAS_O(ptr, void, void *, char, "l", "eax")
   1bd2d:	55                   	push   %ebp
   1bd2e:	89 e5                	mov    %esp,%ebp
   1bd30:	56                   	push   %esi
   1bd31:	53                   	push   %ebx
   1bd32:	83 ec 10             	sub    $0x10,%esp
   1bd35:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bd38:	8b 75 14             	mov    0x14(%ebp),%esi
   1bd3b:	8b 55 10             	mov    0x10(%ebp),%edx
   1bd3e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bd41:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bd44:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1bd48:	89 06                	mov    %eax,(%esi)
   1bd4a:	0f 94 c0             	sete   %al
   1bd4d:	88 45 f7             	mov    %al,-0x9(%ebp)
   1bd50:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1bd54:	83 c4 10             	add    $0x10,%esp
   1bd57:	5b                   	pop    %ebx
   1bd58:	5e                   	pop    %esi
   1bd59:	5d                   	pop    %ebp
   1bd5a:	c3                   	ret    

0001bd5b <ck_pr_cas_char_value>:

#define CK_PR_CAS_O_S(S, T, I, R)	\
	CK_PR_CAS_O(S, T, T, T, I, R)

CK_PR_CAS_O_S(char, char, "b", "al")
   1bd5b:	55                   	push   %ebp
   1bd5c:	89 e5                	mov    %esp,%ebp
   1bd5e:	56                   	push   %esi
   1bd5f:	53                   	push   %ebx
   1bd60:	83 ec 18             	sub    $0x18,%esp
   1bd63:	8b 55 0c             	mov    0xc(%ebp),%edx
   1bd66:	8b 45 10             	mov    0x10(%ebp),%eax
   1bd69:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   1bd6c:	88 45 e0             	mov    %al,-0x20(%ebp)
   1bd6f:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bd72:	8b 75 14             	mov    0x14(%ebp),%esi
   1bd75:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   1bd79:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   1bd7d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bd80:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   1bd84:	88 06                	mov    %al,(%esi)
   1bd86:	0f 94 c0             	sete   %al
   1bd89:	88 45 f7             	mov    %al,-0x9(%ebp)
   1bd8c:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1bd90:	83 c4 18             	add    $0x18,%esp
   1bd93:	5b                   	pop    %ebx
   1bd94:	5e                   	pop    %esi
   1bd95:	5d                   	pop    %ebp
   1bd96:	c3                   	ret    

0001bd97 <ck_pr_cas_int_value>:
CK_PR_CAS_O_S(int, int, "l", "eax")
   1bd97:	55                   	push   %ebp
   1bd98:	89 e5                	mov    %esp,%ebp
   1bd9a:	56                   	push   %esi
   1bd9b:	53                   	push   %ebx
   1bd9c:	83 ec 10             	sub    $0x10,%esp
   1bd9f:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bda2:	8b 75 14             	mov    0x14(%ebp),%esi
   1bda5:	8b 55 10             	mov    0x10(%ebp),%edx
   1bda8:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bdab:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bdae:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1bdb2:	89 06                	mov    %eax,(%esi)
   1bdb4:	0f 94 c0             	sete   %al
   1bdb7:	88 45 f7             	mov    %al,-0x9(%ebp)
   1bdba:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1bdbe:	83 c4 10             	add    $0x10,%esp
   1bdc1:	5b                   	pop    %ebx
   1bdc2:	5e                   	pop    %esi
   1bdc3:	5d                   	pop    %ebp
   1bdc4:	c3                   	ret    

0001bdc5 <ck_pr_cas_uint_value>:
CK_PR_CAS_O_S(uint, unsigned int, "l", "eax")
   1bdc5:	55                   	push   %ebp
   1bdc6:	89 e5                	mov    %esp,%ebp
   1bdc8:	56                   	push   %esi
   1bdc9:	53                   	push   %ebx
   1bdca:	83 ec 10             	sub    $0x10,%esp
   1bdcd:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bdd0:	8b 75 14             	mov    0x14(%ebp),%esi
   1bdd3:	8b 55 10             	mov    0x10(%ebp),%edx
   1bdd6:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bdd9:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bddc:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1bde0:	89 06                	mov    %eax,(%esi)
   1bde2:	0f 94 c0             	sete   %al
   1bde5:	88 45 f7             	mov    %al,-0x9(%ebp)
   1bde8:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1bdec:	83 c4 10             	add    $0x10,%esp
   1bdef:	5b                   	pop    %ebx
   1bdf0:	5e                   	pop    %esi
   1bdf1:	5d                   	pop    %ebp
   1bdf2:	c3                   	ret    

0001bdf3 <ck_pr_cas_32_value>:
CK_PR_CAS_O_S(32, uint32_t, "l", "eax")
   1bdf3:	55                   	push   %ebp
   1bdf4:	89 e5                	mov    %esp,%ebp
   1bdf6:	56                   	push   %esi
   1bdf7:	53                   	push   %ebx
   1bdf8:	83 ec 10             	sub    $0x10,%esp
   1bdfb:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1bdfe:	8b 75 14             	mov    0x14(%ebp),%esi
   1be01:	8b 55 10             	mov    0x10(%ebp),%edx
   1be04:	8b 45 0c             	mov    0xc(%ebp),%eax
   1be07:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1be0a:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1be0e:	89 06                	mov    %eax,(%esi)
   1be10:	0f 94 c0             	sete   %al
   1be13:	88 45 f7             	mov    %al,-0x9(%ebp)
   1be16:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1be1a:	83 c4 10             	add    $0x10,%esp
   1be1d:	5b                   	pop    %ebx
   1be1e:	5e                   	pop    %esi
   1be1f:	5d                   	pop    %ebp
   1be20:	c3                   	ret    

0001be21 <ck_pr_cas_16_value>:
CK_PR_CAS_O_S(16, uint16_t, "w", "ax")
   1be21:	55                   	push   %ebp
   1be22:	89 e5                	mov    %esp,%ebp
   1be24:	56                   	push   %esi
   1be25:	53                   	push   %ebx
   1be26:	83 ec 18             	sub    $0x18,%esp
   1be29:	8b 55 0c             	mov    0xc(%ebp),%edx
   1be2c:	8b 45 10             	mov    0x10(%ebp),%eax
   1be2f:	66 89 55 e4          	mov    %dx,-0x1c(%ebp)
   1be33:	66 89 45 e0          	mov    %ax,-0x20(%ebp)
   1be37:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1be3a:	8b 75 14             	mov    0x14(%ebp),%esi
   1be3d:	0f b7 55 e0          	movzwl -0x20(%ebp),%edx
   1be41:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
   1be45:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1be48:	66 f0 0f b1 13       	lock cmpxchg %dx,(%ebx)
   1be4d:	66 89 06             	mov    %ax,(%esi)
   1be50:	0f 94 c0             	sete   %al
   1be53:	88 45 f7             	mov    %al,-0x9(%ebp)
   1be56:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1be5a:	83 c4 18             	add    $0x18,%esp
   1be5d:	5b                   	pop    %ebx
   1be5e:	5e                   	pop    %esi
   1be5f:	5d                   	pop    %ebp
   1be60:	c3                   	ret    

0001be61 <ck_pr_cas_8_value>:
CK_PR_CAS_O_S(8,  uint8_t,  "b", "al")
   1be61:	55                   	push   %ebp
   1be62:	89 e5                	mov    %esp,%ebp
   1be64:	56                   	push   %esi
   1be65:	53                   	push   %ebx
   1be66:	83 ec 18             	sub    $0x18,%esp
   1be69:	8b 55 0c             	mov    0xc(%ebp),%edx
   1be6c:	8b 45 10             	mov    0x10(%ebp),%eax
   1be6f:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   1be72:	88 45 e0             	mov    %al,-0x20(%ebp)
   1be75:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1be78:	8b 75 14             	mov    0x14(%ebp),%esi
   1be7b:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   1be7f:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   1be83:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1be86:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   1be8a:	88 06                	mov    %al,(%esi)
   1be8c:	0f 94 c0             	sete   %al
   1be8f:	88 45 f7             	mov    %al,-0x9(%ebp)
   1be92:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1be96:	83 c4 18             	add    $0x18,%esp
   1be99:	5b                   	pop    %ebx
   1be9a:	5e                   	pop    %esi
   1be9b:	5d                   	pop    %ebp
   1be9c:	c3                   	ret    

0001be9d <ck_pr_btc_ptr>:
	CK_PR_BT_S(K, uint, unsigned int, #K "l %2, %0")	\
	CK_PR_BT_S(K, int, int, #K "l %2, %0")			\
	CK_PR_BT_S(K, 32, uint32_t, #K "l %2, %0")		\
	CK_PR_BT_S(K, 16, uint16_t, #K "w %w2, %0")

CK_PR_GENERATE(btc)
   1be9d:	55                   	push   %ebp
   1be9e:	89 e5                	mov    %esp,%ebp
   1bea0:	83 ec 10             	sub    $0x10,%esp
   1bea3:	8b 55 08             	mov    0x8(%ebp),%edx
   1bea6:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bea9:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1beac:	f0 0f bb 02          	lock btc %eax,(%edx)
   1beb0:	0f 92 c0             	setb   %al
   1beb3:	88 45 ff             	mov    %al,-0x1(%ebp)
   1beb6:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1beba:	c9                   	leave  
   1bebb:	c3                   	ret    

0001bebc <ck_pr_btc_uint>:
   1bebc:	55                   	push   %ebp
   1bebd:	89 e5                	mov    %esp,%ebp
   1bebf:	83 ec 10             	sub    $0x10,%esp
   1bec2:	8b 55 08             	mov    0x8(%ebp),%edx
   1bec5:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bec8:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1becb:	f0 0f bb 02          	lock btc %eax,(%edx)
   1becf:	0f 92 c0             	setb   %al
   1bed2:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bed5:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bed9:	c9                   	leave  
   1beda:	c3                   	ret    

0001bedb <ck_pr_btc_int>:
   1bedb:	55                   	push   %ebp
   1bedc:	89 e5                	mov    %esp,%ebp
   1bede:	83 ec 10             	sub    $0x10,%esp
   1bee1:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bee4:	8b 55 08             	mov    0x8(%ebp),%edx
   1bee7:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1beea:	f0 0f bb 02          	lock btc %eax,(%edx)
   1beee:	0f 92 c0             	setb   %al
   1bef1:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bef4:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bef8:	c9                   	leave  
   1bef9:	c3                   	ret    

0001befa <ck_pr_btc_32>:
   1befa:	55                   	push   %ebp
   1befb:	89 e5                	mov    %esp,%ebp
   1befd:	83 ec 10             	sub    $0x10,%esp
   1bf00:	8b 55 08             	mov    0x8(%ebp),%edx
   1bf03:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bf06:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bf09:	f0 0f bb 02          	lock btc %eax,(%edx)
   1bf0d:	0f 92 c0             	setb   %al
   1bf10:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bf13:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bf17:	c9                   	leave  
   1bf18:	c3                   	ret    

0001bf19 <ck_pr_btc_16>:
   1bf19:	55                   	push   %ebp
   1bf1a:	89 e5                	mov    %esp,%ebp
   1bf1c:	83 ec 10             	sub    $0x10,%esp
   1bf1f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bf22:	8b 55 08             	mov    0x8(%ebp),%edx
   1bf25:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bf28:	66 f0 0f bb 02       	lock btc %ax,(%edx)
   1bf2d:	0f 92 c0             	setb   %al
   1bf30:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bf33:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bf37:	c9                   	leave  
   1bf38:	c3                   	ret    

0001bf39 <ck_pr_bts_ptr>:
CK_PR_GENERATE(bts)
   1bf39:	55                   	push   %ebp
   1bf3a:	89 e5                	mov    %esp,%ebp
   1bf3c:	83 ec 10             	sub    $0x10,%esp
   1bf3f:	8b 55 08             	mov    0x8(%ebp),%edx
   1bf42:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bf45:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bf48:	f0 0f ab 02          	lock bts %eax,(%edx)
   1bf4c:	0f 92 c0             	setb   %al
   1bf4f:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bf52:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bf56:	c9                   	leave  
   1bf57:	c3                   	ret    

0001bf58 <ck_pr_bts_uint>:
   1bf58:	55                   	push   %ebp
   1bf59:	89 e5                	mov    %esp,%ebp
   1bf5b:	83 ec 10             	sub    $0x10,%esp
   1bf5e:	8b 55 08             	mov    0x8(%ebp),%edx
   1bf61:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bf64:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bf67:	f0 0f ab 02          	lock bts %eax,(%edx)
   1bf6b:	0f 92 c0             	setb   %al
   1bf6e:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bf71:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bf75:	c9                   	leave  
   1bf76:	c3                   	ret    

0001bf77 <ck_pr_bts_int>:
   1bf77:	55                   	push   %ebp
   1bf78:	89 e5                	mov    %esp,%ebp
   1bf7a:	83 ec 10             	sub    $0x10,%esp
   1bf7d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bf80:	8b 55 08             	mov    0x8(%ebp),%edx
   1bf83:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bf86:	f0 0f ab 02          	lock bts %eax,(%edx)
   1bf8a:	0f 92 c0             	setb   %al
   1bf8d:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bf90:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bf94:	c9                   	leave  
   1bf95:	c3                   	ret    

0001bf96 <ck_pr_bts_32>:
   1bf96:	55                   	push   %ebp
   1bf97:	89 e5                	mov    %esp,%ebp
   1bf99:	83 ec 10             	sub    $0x10,%esp
   1bf9c:	8b 55 08             	mov    0x8(%ebp),%edx
   1bf9f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bfa2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bfa5:	f0 0f ab 02          	lock bts %eax,(%edx)
   1bfa9:	0f 92 c0             	setb   %al
   1bfac:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bfaf:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bfb3:	c9                   	leave  
   1bfb4:	c3                   	ret    

0001bfb5 <ck_pr_bts_16>:
   1bfb5:	55                   	push   %ebp
   1bfb6:	89 e5                	mov    %esp,%ebp
   1bfb8:	83 ec 10             	sub    $0x10,%esp
   1bfbb:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bfbe:	8b 55 08             	mov    0x8(%ebp),%edx
   1bfc1:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bfc4:	66 f0 0f ab 02       	lock bts %ax,(%edx)
   1bfc9:	0f 92 c0             	setb   %al
   1bfcc:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bfcf:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bfd3:	c9                   	leave  
   1bfd4:	c3                   	ret    

0001bfd5 <ck_pr_btr_ptr>:
CK_PR_GENERATE(btr)
   1bfd5:	55                   	push   %ebp
   1bfd6:	89 e5                	mov    %esp,%ebp
   1bfd8:	83 ec 10             	sub    $0x10,%esp
   1bfdb:	8b 55 08             	mov    0x8(%ebp),%edx
   1bfde:	8b 45 0c             	mov    0xc(%ebp),%eax
   1bfe1:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1bfe4:	f0 0f b3 02          	lock btr %eax,(%edx)
   1bfe8:	0f 92 c0             	setb   %al
   1bfeb:	88 45 ff             	mov    %al,-0x1(%ebp)
   1bfee:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1bff2:	c9                   	leave  
   1bff3:	c3                   	ret    

0001bff4 <ck_pr_btr_uint>:
   1bff4:	55                   	push   %ebp
   1bff5:	89 e5                	mov    %esp,%ebp
   1bff7:	83 ec 10             	sub    $0x10,%esp
   1bffa:	8b 55 08             	mov    0x8(%ebp),%edx
   1bffd:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c000:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1c003:	f0 0f b3 02          	lock btr %eax,(%edx)
   1c007:	0f 92 c0             	setb   %al
   1c00a:	88 45 ff             	mov    %al,-0x1(%ebp)
   1c00d:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1c011:	c9                   	leave  
   1c012:	c3                   	ret    

0001c013 <ck_pr_btr_int>:
   1c013:	55                   	push   %ebp
   1c014:	89 e5                	mov    %esp,%ebp
   1c016:	83 ec 10             	sub    $0x10,%esp
   1c019:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c01c:	8b 55 08             	mov    0x8(%ebp),%edx
   1c01f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1c022:	f0 0f b3 02          	lock btr %eax,(%edx)
   1c026:	0f 92 c0             	setb   %al
   1c029:	88 45 ff             	mov    %al,-0x1(%ebp)
   1c02c:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1c030:	c9                   	leave  
   1c031:	c3                   	ret    

0001c032 <ck_pr_btr_32>:
   1c032:	55                   	push   %ebp
   1c033:	89 e5                	mov    %esp,%ebp
   1c035:	83 ec 10             	sub    $0x10,%esp
   1c038:	8b 55 08             	mov    0x8(%ebp),%edx
   1c03b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c03e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1c041:	f0 0f b3 02          	lock btr %eax,(%edx)
   1c045:	0f 92 c0             	setb   %al
   1c048:	88 45 ff             	mov    %al,-0x1(%ebp)
   1c04b:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1c04f:	c9                   	leave  
   1c050:	c3                   	ret    

0001c051 <ck_pr_btr_16>:
   1c051:	55                   	push   %ebp
   1c052:	89 e5                	mov    %esp,%ebp
   1c054:	83 ec 10             	sub    $0x10,%esp
   1c057:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c05a:	8b 55 08             	mov    0x8(%ebp),%edx
   1c05d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1c060:	66 f0 0f b3 02       	lock btr %ax,(%edx)
   1c065:	0f 92 c0             	setb   %al
   1c068:	88 45 ff             	mov    %al,-0x1(%ebp)
   1c06b:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1c06f:	c9                   	leave  
   1c070:	c3                   	ret    

0001c071 <ck_pr_barrier>:

#include <ck_cc.h>

CK_CC_INLINE static void
ck_pr_barrier(void)
{
   1c071:	55                   	push   %ebp
   1c072:	89 e5                	mov    %esp,%ebp

	__asm__ __volatile__("" ::: "memory");
	return;
   1c074:	90                   	nop
}
   1c075:	5d                   	pop    %ebp
   1c076:	c3                   	ret    

0001c077 <ck_pr_fence_load_depends>:

/*
 * None of the currently supported platforms allow for data-dependent
 * load ordering.
 */
CK_PR_FENCE_NOOP(load_depends)
   1c077:	55                   	push   %ebp
   1c078:	89 e5                	mov    %esp,%ebp
   1c07a:	e8 f2 ff ff ff       	call   1c071 <ck_pr_barrier>
   1c07f:	90                   	nop
   1c080:	5d                   	pop    %ebp
   1c081:	c3                   	ret    

0001c082 <ck_pr_fence_atomic>:
#elif defined(CK_MD_TSO)
/*
 * Only loads are re-ordered and only with respect to
 * prior stores. Atomic operations are serializing.
 */
CK_PR_FENCE_NOOP(atomic)
   1c082:	55                   	push   %ebp
   1c083:	89 e5                	mov    %esp,%ebp
   1c085:	e8 e7 ff ff ff       	call   1c071 <ck_pr_barrier>
   1c08a:	90                   	nop
   1c08b:	5d                   	pop    %ebp
   1c08c:	c3                   	ret    

0001c08d <ck_pr_fence_atomic_load>:
CK_PR_FENCE_NOOP(atomic_load)
   1c08d:	55                   	push   %ebp
   1c08e:	89 e5                	mov    %esp,%ebp
   1c090:	e8 dc ff ff ff       	call   1c071 <ck_pr_barrier>
   1c095:	90                   	nop
   1c096:	5d                   	pop    %ebp
   1c097:	c3                   	ret    

0001c098 <ck_pr_fence_atomic_store>:
CK_PR_FENCE_NOOP(atomic_store)
   1c098:	55                   	push   %ebp
   1c099:	89 e5                	mov    %esp,%ebp
   1c09b:	e8 d1 ff ff ff       	call   1c071 <ck_pr_barrier>
   1c0a0:	90                   	nop
   1c0a1:	5d                   	pop    %ebp
   1c0a2:	c3                   	ret    

0001c0a3 <ck_pr_fence_store_atomic>:
CK_PR_FENCE_NOOP(store_atomic)
   1c0a3:	55                   	push   %ebp
   1c0a4:	89 e5                	mov    %esp,%ebp
   1c0a6:	e8 c6 ff ff ff       	call   1c071 <ck_pr_barrier>
   1c0ab:	90                   	nop
   1c0ac:	5d                   	pop    %ebp
   1c0ad:	c3                   	ret    

0001c0ae <ck_pr_fence_load_atomic>:
CK_PR_FENCE_NOOP(load_atomic)
   1c0ae:	55                   	push   %ebp
   1c0af:	89 e5                	mov    %esp,%ebp
   1c0b1:	e8 bb ff ff ff       	call   1c071 <ck_pr_barrier>
   1c0b6:	90                   	nop
   1c0b7:	5d                   	pop    %ebp
   1c0b8:	c3                   	ret    

0001c0b9 <ck_pr_fence_load_store>:
CK_PR_FENCE_NOOP(load_store)
   1c0b9:	55                   	push   %ebp
   1c0ba:	89 e5                	mov    %esp,%ebp
   1c0bc:	e8 b0 ff ff ff       	call   1c071 <ck_pr_barrier>
   1c0c1:	90                   	nop
   1c0c2:	5d                   	pop    %ebp
   1c0c3:	c3                   	ret    

0001c0c4 <ck_pr_fence_store_load>:
CK_PR_FENCE_EMIT(store_load)
   1c0c4:	55                   	push   %ebp
   1c0c5:	89 e5                	mov    %esp,%ebp
   1c0c7:	e8 d4 f1 ff ff       	call   1b2a0 <ck_pr_fence_strict_store_load>
   1c0cc:	90                   	nop
   1c0cd:	5d                   	pop    %ebp
   1c0ce:	c3                   	ret    

0001c0cf <ck_pr_fence_load>:
CK_PR_FENCE_NOOP(load)
   1c0cf:	55                   	push   %ebp
   1c0d0:	89 e5                	mov    %esp,%ebp
   1c0d2:	e8 9a ff ff ff       	call   1c071 <ck_pr_barrier>
   1c0d7:	90                   	nop
   1c0d8:	5d                   	pop    %ebp
   1c0d9:	c3                   	ret    

0001c0da <ck_pr_fence_store>:
CK_PR_FENCE_NOOP(store)
   1c0da:	55                   	push   %ebp
   1c0db:	89 e5                	mov    %esp,%ebp
   1c0dd:	e8 8f ff ff ff       	call   1c071 <ck_pr_barrier>
   1c0e2:	90                   	nop
   1c0e3:	5d                   	pop    %ebp
   1c0e4:	c3                   	ret    

0001c0e5 <ck_pr_fence_memory>:
CK_PR_FENCE_EMIT(memory)
   1c0e5:	55                   	push   %ebp
   1c0e6:	89 e5                	mov    %esp,%ebp
   1c0e8:	e8 bc f1 ff ff       	call   1b2a9 <ck_pr_fence_strict_memory>
   1c0ed:	90                   	nop
   1c0ee:	5d                   	pop    %ebp
   1c0ef:	c3                   	ret    

0001c0f0 <ck_pr_fence_acquire>:
CK_PR_FENCE_NOOP(acquire)
   1c0f0:	55                   	push   %ebp
   1c0f1:	89 e5                	mov    %esp,%ebp
   1c0f3:	e8 79 ff ff ff       	call   1c071 <ck_pr_barrier>
   1c0f8:	90                   	nop
   1c0f9:	5d                   	pop    %ebp
   1c0fa:	c3                   	ret    

0001c0fb <ck_pr_fence_release>:
CK_PR_FENCE_NOOP(release)
   1c0fb:	55                   	push   %ebp
   1c0fc:	89 e5                	mov    %esp,%ebp
   1c0fe:	e8 6e ff ff ff       	call   1c071 <ck_pr_barrier>
   1c103:	90                   	nop
   1c104:	5d                   	pop    %ebp
   1c105:	c3                   	ret    

0001c106 <ck_pr_fence_acqrel>:
CK_PR_FENCE_NOOP(acqrel)
   1c106:	55                   	push   %ebp
   1c107:	89 e5                	mov    %esp,%ebp
   1c109:	e8 63 ff ff ff       	call   1c071 <ck_pr_barrier>
   1c10e:	90                   	nop
   1c10f:	5d                   	pop    %ebp
   1c110:	c3                   	ret    

0001c111 <ck_pr_fence_lock>:
CK_PR_FENCE_NOOP(lock)
   1c111:	55                   	push   %ebp
   1c112:	89 e5                	mov    %esp,%ebp
   1c114:	e8 58 ff ff ff       	call   1c071 <ck_pr_barrier>
   1c119:	90                   	nop
   1c11a:	5d                   	pop    %ebp
   1c11b:	c3                   	ret    

0001c11c <ck_pr_fence_unlock>:
CK_PR_FENCE_NOOP(unlock)
   1c11c:	55                   	push   %ebp
   1c11d:	89 e5                	mov    %esp,%ebp
   1c11f:	e8 4d ff ff ff       	call   1c071 <ck_pr_barrier>
   1c124:	90                   	nop
   1c125:	5d                   	pop    %ebp
   1c126:	c3                   	ret    

0001c127 <ck_pr_rfo>:

#ifndef CK_F_PR_RFO
#define CK_F_PR_RFO
CK_CC_INLINE static void
ck_pr_rfo(const void *m)
{
   1c127:	55                   	push   %ebp
   1c128:	89 e5                	mov    %esp,%ebp

	(void)m;
	return;
   1c12a:	90                   	nop
}
   1c12b:	5d                   	pop    %ebp
   1c12c:	c3                   	ret    

0001c12d <ck_ring_size>:
};
typedef struct ck_ring_buffer ck_ring_buffer_t;

CK_CC_INLINE static unsigned int
ck_ring_size(const struct ck_ring *ring)
{
   1c12d:	55                   	push   %ebp
   1c12e:	89 e5                	mov    %esp,%ebp
   1c130:	83 ec 14             	sub    $0x14,%esp
	unsigned int c, p;

	c = ck_pr_load_uint(&ring->c_head);
   1c133:	8b 45 08             	mov    0x8(%ebp),%eax
   1c136:	89 04 24             	mov    %eax,(%esp)
   1c139:	e8 86 f2 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c13e:	89 45 fc             	mov    %eax,-0x4(%ebp)
	p = ck_pr_load_uint(&ring->p_tail);
   1c141:	8b 45 08             	mov    0x8(%ebp),%eax
   1c144:	83 c0 40             	add    $0x40,%eax
   1c147:	89 04 24             	mov    %eax,(%esp)
   1c14a:	e8 75 f2 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c14f:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return (p - c) & ring->mask;
   1c152:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1c155:	8b 55 f8             	mov    -0x8(%ebp),%edx
   1c158:	29 c2                	sub    %eax,%edx
   1c15a:	8b 45 08             	mov    0x8(%ebp),%eax
   1c15d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c163:	21 d0                	and    %edx,%eax
}
   1c165:	c9                   	leave  
   1c166:	c3                   	ret    

0001c167 <ck_ring_capacity>:

CK_CC_INLINE static unsigned int
ck_ring_capacity(const struct ck_ring *ring)
{
   1c167:	55                   	push   %ebp
   1c168:	89 e5                	mov    %esp,%ebp
	return ring->size;
   1c16a:	8b 45 08             	mov    0x8(%ebp),%eax
   1c16d:	8b 80 80 00 00 00    	mov    0x80(%eax),%eax
}
   1c173:	5d                   	pop    %ebp
   1c174:	c3                   	ret    

0001c175 <ck_ring_init>:

CK_CC_INLINE static void
ck_ring_init(struct ck_ring *ring, unsigned int size)
{
   1c175:	55                   	push   %ebp
   1c176:	89 e5                	mov    %esp,%ebp

	ring->size = size;
   1c178:	8b 45 08             	mov    0x8(%ebp),%eax
   1c17b:	8b 55 0c             	mov    0xc(%ebp),%edx
   1c17e:	89 90 80 00 00 00    	mov    %edx,0x80(%eax)
	ring->mask = size - 1;
   1c184:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c187:	8d 50 ff             	lea    -0x1(%eax),%edx
   1c18a:	8b 45 08             	mov    0x8(%ebp),%eax
   1c18d:	89 90 84 00 00 00    	mov    %edx,0x84(%eax)
	ring->p_tail = 0;
   1c193:	8b 45 08             	mov    0x8(%ebp),%eax
   1c196:	c7 40 40 00 00 00 00 	movl   $0x0,0x40(%eax)
	ring->p_head = 0;
   1c19d:	8b 45 08             	mov    0x8(%ebp),%eax
   1c1a0:	c7 40 44 00 00 00 00 	movl   $0x0,0x44(%eax)
	ring->c_head = 0;
   1c1a7:	8b 45 08             	mov    0x8(%ebp),%eax
   1c1aa:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
	return;
   1c1b0:	90                   	nop
}
   1c1b1:	5d                   	pop    %ebp
   1c1b2:	c3                   	ret    

0001c1b3 <ck_ring_enqueue_spsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1c1b3:	55                   	push   %ebp
   1c1b4:	89 e5                	mov    %esp,%ebp
   1c1b6:	83 ec 58             	sub    $0x58,%esp
   1c1b9:	8b 45 08             	mov    0x8(%ebp),%eax
   1c1bc:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c1bf:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c1c2:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c1c5:	8d 45 10             	lea    0x10(%ebp),%eax
   1c1c8:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c1cb:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1c1d2:	8b 45 14             	mov    0x14(%ebp),%eax
   1c1d5:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1c1d8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c1db:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1c1de:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1c1e1:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1c1e4:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1c1e7:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1c1ea:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1c1ed:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1c1f0:	8d 45 b8             	lea    -0x48(%ebp),%eax
   1c1f3:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1c1f6:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c1f9:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c1ff:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1c202:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c205:	89 04 24             	mov    %eax,(%esp)
   1c208:	e8 b7 f1 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c20d:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   1c210:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c213:	8b 40 40             	mov    0x40(%eax),%eax
   1c216:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1c219:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1c21c:	83 c0 01             	add    $0x1,%eax
   1c21f:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   1c222:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1c226:	74 14                	je     1c23c <ck_ring_enqueue_spsc_size+0x89>
		*size = (producer - consumer) & mask;
   1c228:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1c22b:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   1c22e:	29 c2                	sub    %eax,%edx
   1c230:	89 d0                	mov    %edx,%eax
   1c232:	23 45 cc             	and    -0x34(%ebp),%eax
   1c235:	89 c2                	mov    %eax,%edx
   1c237:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1c23a:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1c23c:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1c23f:	8b 55 c8             	mov    -0x38(%ebp),%edx
   1c242:	31 d0                	xor    %edx,%eax
   1c244:	23 45 cc             	and    -0x34(%ebp),%eax
   1c247:	85 c0                	test   %eax,%eax
   1c249:	0f 94 c0             	sete   %al
   1c24c:	0f b6 c0             	movzbl %al,%eax
   1c24f:	85 c0                	test   %eax,%eax
   1c251:	74 07                	je     1c25a <ck_ring_enqueue_spsc_size+0xa7>
		return false;
   1c253:	b8 00 00 00 00       	mov    $0x0,%eax
   1c258:	eb 47                	jmp    1c2a1 <ck_ring_enqueue_spsc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1c25a:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1c25d:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1c260:	21 d0                	and    %edx,%eax
   1c262:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1c266:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1c269:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1c26c:	89 44 24 08          	mov    %eax,0x8(%esp)
   1c270:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c273:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c277:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1c27a:	89 04 24             	mov    %eax,(%esp)
   1c27d:	e8 fc ff ff ff       	call   1c27e <ck_ring_enqueue_spsc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1c282:	e8 53 fe ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1c287:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c28a:	8d 50 40             	lea    0x40(%eax),%edx
   1c28d:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1c290:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c294:	89 14 24             	mov    %edx,(%esp)
   1c297:	e8 b1 f1 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1c29c:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   1c2a1:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   1c2a4:	8b 55 b8             	mov    -0x48(%ebp),%edx
   1c2a7:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1c2aa:	89 10                	mov    %edx,(%eax)
	return r;
   1c2ac:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   1c2b0:	c9                   	leave  
   1c2b1:	c3                   	ret    

0001c2b2 <ck_ring_enqueue_spsc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1c2b2:	55                   	push   %ebp
   1c2b3:	89 e5                	mov    %esp,%ebp
   1c2b5:	83 ec 48             	sub    $0x48,%esp
   1c2b8:	8b 45 08             	mov    0x8(%ebp),%eax
   1c2bb:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c2be:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c2c1:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c2c4:	8d 45 10             	lea    0x10(%ebp),%eax
   1c2c7:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c2ca:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1c2d1:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1c2d8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c2db:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c2e1:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1c2e4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c2e7:	89 04 24             	mov    %eax,(%esp)
   1c2ea:	e8 d5 f0 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c2ef:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   1c2f2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c2f5:	8b 40 40             	mov    0x40(%eax),%eax
   1c2f8:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1c2fb:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c2fe:	83 c0 01             	add    $0x1,%eax
   1c301:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   1c304:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1c308:	74 14                	je     1c31e <ck_ring_enqueue_spsc+0x6c>
		*size = (producer - consumer) & mask;
   1c30a:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1c30d:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1c310:	29 c2                	sub    %eax,%edx
   1c312:	89 d0                	mov    %edx,%eax
   1c314:	23 45 e0             	and    -0x20(%ebp),%eax
   1c317:	89 c2                	mov    %eax,%edx
   1c319:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1c31c:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1c31e:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1c321:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1c324:	31 d0                	xor    %edx,%eax
   1c326:	23 45 e0             	and    -0x20(%ebp),%eax
   1c329:	85 c0                	test   %eax,%eax
   1c32b:	0f 94 c0             	sete   %al
   1c32e:	0f b6 c0             	movzbl %al,%eax
   1c331:	85 c0                	test   %eax,%eax
   1c333:	74 07                	je     1c33c <ck_ring_enqueue_spsc+0x8a>
		return false;
   1c335:	b8 00 00 00 00       	mov    $0x0,%eax
   1c33a:	eb 47                	jmp    1c383 <ck_ring_enqueue_spsc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1c33c:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c33f:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1c342:	21 d0                	and    %edx,%eax
   1c344:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1c348:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1c34b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1c34e:	89 44 24 08          	mov    %eax,0x8(%esp)
   1c352:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1c355:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c359:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1c35c:	89 04 24             	mov    %eax,(%esp)
   1c35f:	e8 fc ff ff ff       	call   1c360 <ck_ring_enqueue_spsc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1c364:	e8 71 fd ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1c369:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c36c:	8d 50 40             	lea    0x40(%eax),%edx
   1c36f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1c372:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c376:	89 14 24             	mov    %edx,(%esp)
   1c379:	e8 cf f0 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1c37e:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer,
	    &entry, sizeof(entry), NULL);
}
   1c383:	c9                   	leave  
   1c384:	c3                   	ret    

0001c385 <ck_ring_dequeue_spsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1c385:	55                   	push   %ebp
   1c386:	89 e5                	mov    %esp,%ebp
   1c388:	83 ec 38             	sub    $0x38,%esp
   1c38b:	8b 45 08             	mov    0x8(%ebp),%eax
   1c38e:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c391:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c394:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c397:	8b 45 10             	mov    0x10(%ebp),%eax
   1c39a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c39d:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1c3a4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c3a7:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c3ad:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   1c3b0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c3b3:	8b 00                	mov    (%eax),%eax
   1c3b5:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   1c3b8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c3bb:	83 c0 40             	add    $0x40,%eax
   1c3be:	89 04 24             	mov    %eax,(%esp)
   1c3c1:	e8 fe ef ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c3c6:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1c3c9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c3cc:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1c3cf:	0f 94 c0             	sete   %al
   1c3d2:	0f b6 c0             	movzbl %al,%eax
   1c3d5:	85 c0                	test   %eax,%eax
   1c3d7:	74 07                	je     1c3e0 <ck_ring_dequeue_spsc+0x5b>
		return false;
   1c3d9:	b8 00 00 00 00       	mov    $0x0,%eax
   1c3de:	eb 4c                	jmp    1c42c <ck_ring_dequeue_spsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   1c3e0:	e8 ea fc ff ff       	call   1c0cf <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1c3e5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c3e8:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1c3eb:	21 d0                	and    %edx,%eax
   1c3ed:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1c3f1:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   1c3f4:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1c3f7:	89 44 24 08          	mov    %eax,0x8(%esp)
   1c3fb:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1c3fe:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c402:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1c405:	89 04 24             	mov    %eax,(%esp)
   1c408:	e8 fc ff ff ff       	call   1c409 <ck_ring_dequeue_spsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   1c40d:	e8 c8 fc ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   1c412:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c415:	8d 50 01             	lea    0x1(%eax),%edx
   1c418:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c41b:	89 54 24 04          	mov    %edx,0x4(%esp)
   1c41f:	89 04 24             	mov    %eax,(%esp)
   1c422:	e8 26 f0 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1c427:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer,
	    (void **)data, sizeof(void *));
}
   1c42c:	c9                   	leave  
   1c42d:	c3                   	ret    

0001c42e <ck_ring_enqueue_mpmc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1c42e:	55                   	push   %ebp
   1c42f:	89 e5                	mov    %esp,%ebp
   1c431:	83 ec 48             	sub    $0x48,%esp
   1c434:	8b 45 08             	mov    0x8(%ebp),%eax
   1c437:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c43a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c43d:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c440:	8d 45 10             	lea    0x10(%ebp),%eax
   1c443:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c446:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1c44d:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1c454:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c457:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c45d:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1c460:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1c464:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c467:	83 c0 44             	add    $0x44,%eax
   1c46a:	89 04 24             	mov    %eax,(%esp)
   1c46d:	e8 52 ef ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c472:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1c475:	e8 55 fc ff ff       	call   1c0cf <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1c47a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c47d:	89 04 24             	mov    %eax,(%esp)
   1c480:	e8 3f ef ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c485:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1c488:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1c48b:	83 c0 01             	add    $0x1,%eax
   1c48e:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1c491:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1c494:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1c497:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1c49a:	0f 97 c0             	seta   %al
   1c49d:	0f b6 c0             	movzbl %al,%eax
   1c4a0:	85 c0                	test   %eax,%eax
   1c4a2:	74 29                	je     1c4cd <ck_ring_enqueue_mpmc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1c4a4:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1c4a7:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1c4aa:	8d 4a 44             	lea    0x44(%edx),%ecx
   1c4ad:	8d 55 cc             	lea    -0x34(%ebp),%edx
   1c4b0:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1c4b4:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   1c4b7:	89 54 24 08          	mov    %edx,0x8(%esp)
   1c4bb:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c4bf:	89 0c 24             	mov    %ecx,(%esp)
   1c4c2:	e8 fe f8 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
   1c4c7:	84 c0                	test   %al,%al
   1c4c9:	75 31                	jne    1c4fc <ck_ring_enqueue_mpmc+0xce>
   1c4cb:	eb a8                	jmp    1c475 <ck_ring_enqueue_mpmc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1c4cd:	e8 fd fb ff ff       	call   1c0cf <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1c4d2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c4d5:	83 c0 44             	add    $0x44,%eax
   1c4d8:	89 04 24             	mov    %eax,(%esp)
   1c4db:	e8 e4 ee ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c4e0:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1c4e3:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1c4e6:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   1c4e9:	75 06                	jne    1c4f1 <ck_ring_enqueue_mpmc+0xc3>
				r = false;
   1c4eb:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1c4ef:	eb 67                	jmp    1c558 <ck_ring_enqueue_mpmc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1c4f1:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1c4f4:	89 45 cc             	mov    %eax,-0x34(%ebp)
   1c4f7:	e9 79 ff ff ff       	jmp    1c475 <ck_ring_enqueue_mpmc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1c4fc:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1c4ff:	23 45 e0             	and    -0x20(%ebp),%eax
   1c502:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1c506:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1c509:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1c50c:	89 44 24 08          	mov    %eax,0x8(%esp)
   1c510:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1c513:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c517:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1c51a:	89 04 24             	mov    %eax,(%esp)
   1c51d:	e8 fc ff ff ff       	call   1c51e <ck_ring_enqueue_mpmc+0xf0>
   1c522:	eb 05                	jmp    1c529 <ck_ring_enqueue_mpmc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1c524:	e8 36 ed ff ff       	call   1b25f <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1c529:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c52c:	83 c0 40             	add    $0x40,%eax
   1c52f:	89 04 24             	mov    %eax,(%esp)
   1c532:	e8 8d ee ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c537:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1c53a:	39 d0                	cmp    %edx,%eax
   1c53c:	75 e6                	jne    1c524 <ck_ring_enqueue_mpmc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1c53e:	e8 97 fb ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1c543:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c546:	8d 50 40             	lea    0x40(%eax),%edx
   1c549:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1c54c:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c550:	89 14 24             	mov    %edx,(%esp)
   1c553:	e8 f5 ee ff ff       	call   1b44d <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1c558:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1c55c:	74 10                	je     1c56e <ck_ring_enqueue_mpmc+0x140>
		*size = (producer - consumer) & mask;
   1c55e:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1c561:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1c564:	23 45 e0             	and    -0x20(%ebp),%eax
   1c567:	89 c2                	mov    %eax,%edx
   1c569:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1c56c:	89 10                	mov    %edx,(%eax)

	return r;
   1c56e:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   1c572:	c9                   	leave  
   1c573:	c3                   	ret    

0001c574 <ck_ring_enqueue_mpmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1c574:	55                   	push   %ebp
   1c575:	89 e5                	mov    %esp,%ebp
   1c577:	83 ec 68             	sub    $0x68,%esp
   1c57a:	8b 45 08             	mov    0x8(%ebp),%eax
   1c57d:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c580:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c583:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c586:	8d 45 10             	lea    0x10(%ebp),%eax
   1c589:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c58c:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1c593:	8b 45 14             	mov    0x14(%ebp),%eax
   1c596:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1c599:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c59c:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1c59f:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1c5a2:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1c5a5:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1c5a8:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1c5ab:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1c5ae:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1c5b1:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1c5b4:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1c5b7:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c5ba:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c5c0:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1c5c3:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1c5c7:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c5ca:	83 c0 44             	add    $0x44,%eax
   1c5cd:	89 04 24             	mov    %eax,(%esp)
   1c5d0:	e8 ef ed ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c5d5:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1c5d8:	e8 f2 fa ff ff       	call   1c0cf <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1c5dd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c5e0:	89 04 24             	mov    %eax,(%esp)
   1c5e3:	e8 dc ed ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c5e8:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   1c5eb:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1c5ee:	83 c0 01             	add    $0x1,%eax
   1c5f1:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1c5f4:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1c5f7:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1c5fa:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   1c5fd:	0f 97 c0             	seta   %al
   1c600:	0f b6 c0             	movzbl %al,%eax
   1c603:	85 c0                	test   %eax,%eax
   1c605:	74 29                	je     1c630 <ck_ring_enqueue_mpmc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1c607:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1c60a:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1c60d:	8d 4a 44             	lea    0x44(%edx),%ecx
   1c610:	8d 55 b0             	lea    -0x50(%ebp),%edx
   1c613:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1c617:	8b 55 c0             	mov    -0x40(%ebp),%edx
   1c61a:	89 54 24 08          	mov    %edx,0x8(%esp)
   1c61e:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c622:	89 0c 24             	mov    %ecx,(%esp)
   1c625:	e8 9b f7 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
   1c62a:	84 c0                	test   %al,%al
   1c62c:	75 31                	jne    1c65f <ck_ring_enqueue_mpmc_size+0xeb>
   1c62e:	eb a8                	jmp    1c5d8 <ck_ring_enqueue_mpmc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1c630:	e8 9a fa ff ff       	call   1c0cf <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1c635:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c638:	83 c0 44             	add    $0x44,%eax
   1c63b:	89 04 24             	mov    %eax,(%esp)
   1c63e:	e8 81 ed ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c643:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1c646:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1c649:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   1c64c:	75 06                	jne    1c654 <ck_ring_enqueue_mpmc_size+0xe0>
				r = false;
   1c64e:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   1c652:	eb 67                	jmp    1c6bb <ck_ring_enqueue_mpmc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1c654:	8b 45 bc             	mov    -0x44(%ebp),%eax
   1c657:	89 45 b0             	mov    %eax,-0x50(%ebp)
   1c65a:	e9 79 ff ff ff       	jmp    1c5d8 <ck_ring_enqueue_mpmc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1c65f:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1c662:	23 45 cc             	and    -0x34(%ebp),%eax
   1c665:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1c669:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1c66c:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1c66f:	89 44 24 08          	mov    %eax,0x8(%esp)
   1c673:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c676:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c67a:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1c67d:	89 04 24             	mov    %eax,(%esp)
   1c680:	e8 fc ff ff ff       	call   1c681 <ck_ring_enqueue_mpmc_size+0x10d>
   1c685:	eb 05                	jmp    1c68c <ck_ring_enqueue_mpmc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1c687:	e8 d3 eb ff ff       	call   1b25f <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1c68c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c68f:	83 c0 40             	add    $0x40,%eax
   1c692:	89 04 24             	mov    %eax,(%esp)
   1c695:	e8 2a ed ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c69a:	8b 55 b0             	mov    -0x50(%ebp),%edx
   1c69d:	39 d0                	cmp    %edx,%eax
   1c69f:	75 e6                	jne    1c687 <ck_ring_enqueue_mpmc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1c6a1:	e8 34 fa ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1c6a6:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c6a9:	8d 50 40             	lea    0x40(%eax),%edx
   1c6ac:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1c6af:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c6b3:	89 14 24             	mov    %edx,(%esp)
   1c6b6:	e8 92 ed ff ff       	call   1b44d <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1c6bb:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1c6bf:	74 10                	je     1c6d1 <ck_ring_enqueue_mpmc_size+0x15d>
		*size = (producer - consumer) & mask;
   1c6c1:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1c6c4:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1c6c7:	23 45 cc             	and    -0x34(%ebp),%eax
   1c6ca:	89 c2                	mov    %eax,%edx
   1c6cc:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1c6cf:	89 10                	mov    %edx,(%eax)

	return r;
   1c6d1:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   1c6d5:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   1c6d8:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   1c6db:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1c6de:	89 10                	mov    %edx,(%eax)
	return r;
   1c6e0:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   1c6e4:	c9                   	leave  
   1c6e5:	c3                   	ret    

0001c6e6 <ck_ring_trydequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1c6e6:	55                   	push   %ebp
   1c6e7:	89 e5                	mov    %esp,%ebp
   1c6e9:	83 ec 38             	sub    $0x38,%esp
   1c6ec:	8b 45 08             	mov    0x8(%ebp),%eax
   1c6ef:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c6f2:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c6f5:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c6f8:	8b 45 10             	mov    0x10(%ebp),%eax
   1c6fb:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c6fe:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1c705:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c708:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c70e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1c711:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c714:	89 04 24             	mov    %eax,(%esp)
   1c717:	e8 a8 ec ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c71c:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   1c71f:	e8 ab f9 ff ff       	call   1c0cf <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   1c724:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c727:	83 c0 40             	add    $0x40,%eax
   1c72a:	89 04 24             	mov    %eax,(%esp)
   1c72d:	e8 92 ec ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c732:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1c735:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c738:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1c73b:	0f 94 c0             	sete   %al
   1c73e:	0f b6 c0             	movzbl %al,%eax
   1c741:	85 c0                	test   %eax,%eax
   1c743:	74 07                	je     1c74c <ck_ring_trydequeue_mpmc+0x66>
		return false;
   1c745:	b8 00 00 00 00       	mov    $0x0,%eax
   1c74a:	eb 4e                	jmp    1c79a <ck_ring_trydequeue_mpmc+0xb4>

	ck_pr_fence_load();
   1c74c:	e8 7e f9 ff ff       	call   1c0cf <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1c751:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c754:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1c757:	21 d0                	and    %edx,%eax
   1c759:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1c75d:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1c760:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1c763:	89 44 24 08          	mov    %eax,0x8(%esp)
   1c767:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1c76a:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c76e:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1c771:	89 04 24             	mov    %eax,(%esp)
   1c774:	e8 fc ff ff ff       	call   1c775 <ck_ring_trydequeue_mpmc+0x8f>

	ck_pr_fence_store_atomic();
   1c779:	e8 25 f9 ff ff       	call   1c0a3 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1c77e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c781:	8d 50 01             	lea    0x1(%eax),%edx
   1c784:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c787:	89 54 24 08          	mov    %edx,0x8(%esp)
   1c78b:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1c78e:	89 54 24 04          	mov    %edx,0x4(%esp)
   1c792:	89 04 24             	mov    %eax,(%esp)
   1c795:	e8 d8 f4 ff ff       	call   1bc72 <ck_pr_cas_uint>
    void *data)
{

	return _ck_ring_trydequeue_mc(ring,
	    buffer, (void **)data, sizeof(void *));
}
   1c79a:	c9                   	leave  
   1c79b:	c3                   	ret    

0001c79c <ck_ring_dequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1c79c:	55                   	push   %ebp
   1c79d:	89 e5                	mov    %esp,%ebp
   1c79f:	53                   	push   %ebx
   1c7a0:	83 ec 34             	sub    $0x34,%esp
   1c7a3:	8b 45 08             	mov    0x8(%ebp),%eax
   1c7a6:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c7a9:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c7ac:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c7af:	8b 45 10             	mov    0x10(%ebp),%eax
   1c7b2:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c7b5:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   1c7bc:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c7bf:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c7c5:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1c7c8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c7cb:	89 04 24             	mov    %eax,(%esp)
   1c7ce:	e8 f1 eb ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c7d3:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   1c7d6:	e8 f4 f8 ff ff       	call   1c0cf <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   1c7db:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c7de:	83 c0 40             	add    $0x40,%eax
   1c7e1:	89 04 24             	mov    %eax,(%esp)
   1c7e4:	e8 db eb ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c7e9:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   1c7ec:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c7ef:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1c7f2:	0f 94 c0             	sete   %al
   1c7f5:	0f b6 c0             	movzbl %al,%eax
   1c7f8:	85 c0                	test   %eax,%eax
   1c7fa:	74 07                	je     1c803 <ck_ring_dequeue_mpmc+0x67>
			return false;
   1c7fc:	b8 00 00 00 00       	mov    $0x0,%eax
   1c801:	eb 6a                	jmp    1c86d <ck_ring_dequeue_mpmc+0xd1>

		ck_pr_fence_load();
   1c803:	e8 c7 f8 ff ff       	call   1c0cf <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   1c808:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c80b:	23 45 e4             	and    -0x1c(%ebp),%eax
   1c80e:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1c812:	89 c2                	mov    %eax,%edx
   1c814:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1c817:	01 d0                	add    %edx,%eax
   1c819:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   1c81c:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1c81f:	89 44 24 08          	mov    %eax,0x8(%esp)
   1c823:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1c826:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c82a:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1c82d:	89 04 24             	mov    %eax,(%esp)
   1c830:	e8 fc ff ff ff       	call   1c831 <ck_ring_dequeue_mpmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   1c835:	e8 69 f8 ff ff       	call   1c0a3 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1c83a:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c83d:	8d 58 01             	lea    0x1(%eax),%ebx
   1c840:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1c843:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c846:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1c849:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1c84d:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1c851:	89 54 24 04          	mov    %edx,0x4(%esp)
   1c855:	89 04 24             	mov    %eax,(%esp)
   1c858:	e8 68 f5 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   1c85d:	83 f0 01             	xor    $0x1,%eax
   1c860:	84 c0                	test   %al,%al
   1c862:	0f 85 6e ff ff ff    	jne    1c7d6 <ck_ring_dequeue_mpmc+0x3a>

	return true;
   1c868:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   1c86d:	83 c4 34             	add    $0x34,%esp
   1c870:	5b                   	pop    %ebx
   1c871:	5d                   	pop    %ebp
   1c872:	c3                   	ret    

0001c873 <ck_ring_enqueue_spmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1c873:	55                   	push   %ebp
   1c874:	89 e5                	mov    %esp,%ebp
   1c876:	83 ec 58             	sub    $0x58,%esp
   1c879:	8b 45 08             	mov    0x8(%ebp),%eax
   1c87c:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c87f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c882:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c885:	8d 45 10             	lea    0x10(%ebp),%eax
   1c888:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c88b:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1c892:	8b 45 14             	mov    0x14(%ebp),%eax
   1c895:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1c898:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c89b:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1c89e:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1c8a1:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1c8a4:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1c8a7:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1c8aa:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1c8ad:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1c8b0:	8d 45 b8             	lea    -0x48(%ebp),%eax
   1c8b3:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1c8b6:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c8b9:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c8bf:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1c8c2:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c8c5:	89 04 24             	mov    %eax,(%esp)
   1c8c8:	e8 f7 ea ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c8cd:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   1c8d0:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c8d3:	8b 40 40             	mov    0x40(%eax),%eax
   1c8d6:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1c8d9:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1c8dc:	83 c0 01             	add    $0x1,%eax
   1c8df:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   1c8e2:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1c8e6:	74 14                	je     1c8fc <ck_ring_enqueue_spmc_size+0x89>
		*size = (producer - consumer) & mask;
   1c8e8:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1c8eb:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   1c8ee:	29 c2                	sub    %eax,%edx
   1c8f0:	89 d0                	mov    %edx,%eax
   1c8f2:	23 45 cc             	and    -0x34(%ebp),%eax
   1c8f5:	89 c2                	mov    %eax,%edx
   1c8f7:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1c8fa:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1c8fc:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1c8ff:	8b 55 c8             	mov    -0x38(%ebp),%edx
   1c902:	31 d0                	xor    %edx,%eax
   1c904:	23 45 cc             	and    -0x34(%ebp),%eax
   1c907:	85 c0                	test   %eax,%eax
   1c909:	0f 94 c0             	sete   %al
   1c90c:	0f b6 c0             	movzbl %al,%eax
   1c90f:	85 c0                	test   %eax,%eax
   1c911:	74 07                	je     1c91a <ck_ring_enqueue_spmc_size+0xa7>
		return false;
   1c913:	b8 00 00 00 00       	mov    $0x0,%eax
   1c918:	eb 47                	jmp    1c961 <ck_ring_enqueue_spmc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1c91a:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1c91d:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1c920:	21 d0                	and    %edx,%eax
   1c922:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1c926:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1c929:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1c92c:	89 44 24 08          	mov    %eax,0x8(%esp)
   1c930:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c933:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c937:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1c93a:	89 04 24             	mov    %eax,(%esp)
   1c93d:	e8 fc ff ff ff       	call   1c93e <ck_ring_enqueue_spmc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1c942:	e8 93 f7 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1c947:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1c94a:	8d 50 40             	lea    0x40(%eax),%edx
   1c94d:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1c950:	89 44 24 04          	mov    %eax,0x4(%esp)
   1c954:	89 14 24             	mov    %edx,(%esp)
   1c957:	e8 f1 ea ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1c95c:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   1c961:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   1c964:	8b 55 b8             	mov    -0x48(%ebp),%edx
   1c967:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1c96a:	89 10                	mov    %edx,(%eax)
	return r;
   1c96c:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   1c970:	c9                   	leave  
   1c971:	c3                   	ret    

0001c972 <ck_ring_enqueue_spmc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1c972:	55                   	push   %ebp
   1c973:	89 e5                	mov    %esp,%ebp
   1c975:	83 ec 48             	sub    $0x48,%esp
   1c978:	8b 45 08             	mov    0x8(%ebp),%eax
   1c97b:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1c97e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1c981:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1c984:	8d 45 10             	lea    0x10(%ebp),%eax
   1c987:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1c98a:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1c991:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1c998:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c99b:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1c9a1:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1c9a4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c9a7:	89 04 24             	mov    %eax,(%esp)
   1c9aa:	e8 15 ea ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1c9af:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   1c9b2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1c9b5:	8b 40 40             	mov    0x40(%eax),%eax
   1c9b8:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1c9bb:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c9be:	83 c0 01             	add    $0x1,%eax
   1c9c1:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   1c9c4:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1c9c8:	74 14                	je     1c9de <ck_ring_enqueue_spmc+0x6c>
		*size = (producer - consumer) & mask;
   1c9ca:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1c9cd:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1c9d0:	29 c2                	sub    %eax,%edx
   1c9d2:	89 d0                	mov    %edx,%eax
   1c9d4:	23 45 e0             	and    -0x20(%ebp),%eax
   1c9d7:	89 c2                	mov    %eax,%edx
   1c9d9:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1c9dc:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1c9de:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1c9e1:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1c9e4:	31 d0                	xor    %edx,%eax
   1c9e6:	23 45 e0             	and    -0x20(%ebp),%eax
   1c9e9:	85 c0                	test   %eax,%eax
   1c9eb:	0f 94 c0             	sete   %al
   1c9ee:	0f b6 c0             	movzbl %al,%eax
   1c9f1:	85 c0                	test   %eax,%eax
   1c9f3:	74 07                	je     1c9fc <ck_ring_enqueue_spmc+0x8a>
		return false;
   1c9f5:	b8 00 00 00 00       	mov    $0x0,%eax
   1c9fa:	eb 47                	jmp    1ca43 <ck_ring_enqueue_spmc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1c9fc:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1c9ff:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1ca02:	21 d0                	and    %edx,%eax
   1ca04:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1ca08:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1ca0b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1ca0e:	89 44 24 08          	mov    %eax,0x8(%esp)
   1ca12:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1ca15:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ca19:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1ca1c:	89 04 24             	mov    %eax,(%esp)
   1ca1f:	e8 fc ff ff ff       	call   1ca20 <ck_ring_enqueue_spmc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1ca24:	e8 b1 f6 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1ca29:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ca2c:	8d 50 40             	lea    0x40(%eax),%edx
   1ca2f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1ca32:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ca36:	89 14 24             	mov    %edx,(%esp)
   1ca39:	e8 0f ea ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1ca3e:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   1ca43:	c9                   	leave  
   1ca44:	c3                   	ret    

0001ca45 <ck_ring_trydequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1ca45:	55                   	push   %ebp
   1ca46:	89 e5                	mov    %esp,%ebp
   1ca48:	83 ec 38             	sub    $0x38,%esp
   1ca4b:	8b 45 08             	mov    0x8(%ebp),%eax
   1ca4e:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1ca51:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ca54:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1ca57:	8b 45 10             	mov    0x10(%ebp),%eax
   1ca5a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1ca5d:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1ca64:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ca67:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1ca6d:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1ca70:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ca73:	89 04 24             	mov    %eax,(%esp)
   1ca76:	e8 49 e9 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1ca7b:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   1ca7e:	e8 4c f6 ff ff       	call   1c0cf <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   1ca83:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ca86:	83 c0 40             	add    $0x40,%eax
   1ca89:	89 04 24             	mov    %eax,(%esp)
   1ca8c:	e8 33 e9 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1ca91:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1ca94:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1ca97:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1ca9a:	0f 94 c0             	sete   %al
   1ca9d:	0f b6 c0             	movzbl %al,%eax
   1caa0:	85 c0                	test   %eax,%eax
   1caa2:	74 07                	je     1caab <ck_ring_trydequeue_spmc+0x66>
		return false;
   1caa4:	b8 00 00 00 00       	mov    $0x0,%eax
   1caa9:	eb 4e                	jmp    1caf9 <ck_ring_trydequeue_spmc+0xb4>

	ck_pr_fence_load();
   1caab:	e8 1f f6 ff ff       	call   1c0cf <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1cab0:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cab3:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1cab6:	21 d0                	and    %edx,%eax
   1cab8:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1cabc:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1cabf:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1cac2:	89 44 24 08          	mov    %eax,0x8(%esp)
   1cac6:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1cac9:	89 44 24 04          	mov    %eax,0x4(%esp)
   1cacd:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1cad0:	89 04 24             	mov    %eax,(%esp)
   1cad3:	e8 fc ff ff ff       	call   1cad4 <ck_ring_trydequeue_spmc+0x8f>

	ck_pr_fence_store_atomic();
   1cad8:	e8 c6 f5 ff ff       	call   1c0a3 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1cadd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cae0:	8d 50 01             	lea    0x1(%eax),%edx
   1cae3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cae6:	89 54 24 08          	mov    %edx,0x8(%esp)
   1caea:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1caed:	89 54 24 04          	mov    %edx,0x4(%esp)
   1caf1:	89 04 24             	mov    %eax,(%esp)
   1caf4:	e8 79 f1 ff ff       	call   1bc72 <ck_pr_cas_uint>
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_trydequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   1caf9:	c9                   	leave  
   1cafa:	c3                   	ret    

0001cafb <ck_ring_dequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1cafb:	55                   	push   %ebp
   1cafc:	89 e5                	mov    %esp,%ebp
   1cafe:	53                   	push   %ebx
   1caff:	83 ec 34             	sub    $0x34,%esp
   1cb02:	8b 45 08             	mov    0x8(%ebp),%eax
   1cb05:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1cb08:	8b 45 0c             	mov    0xc(%ebp),%eax
   1cb0b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1cb0e:	8b 45 10             	mov    0x10(%ebp),%eax
   1cb11:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1cb14:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   1cb1b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cb1e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1cb24:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1cb27:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cb2a:	89 04 24             	mov    %eax,(%esp)
   1cb2d:	e8 92 e8 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cb32:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   1cb35:	e8 95 f5 ff ff       	call   1c0cf <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   1cb3a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cb3d:	83 c0 40             	add    $0x40,%eax
   1cb40:	89 04 24             	mov    %eax,(%esp)
   1cb43:	e8 7c e8 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cb48:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   1cb4b:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1cb4e:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1cb51:	0f 94 c0             	sete   %al
   1cb54:	0f b6 c0             	movzbl %al,%eax
   1cb57:	85 c0                	test   %eax,%eax
   1cb59:	74 07                	je     1cb62 <ck_ring_dequeue_spmc+0x67>
			return false;
   1cb5b:	b8 00 00 00 00       	mov    $0x0,%eax
   1cb60:	eb 6a                	jmp    1cbcc <ck_ring_dequeue_spmc+0xd1>

		ck_pr_fence_load();
   1cb62:	e8 68 f5 ff ff       	call   1c0cf <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   1cb67:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1cb6a:	23 45 e4             	and    -0x1c(%ebp),%eax
   1cb6d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1cb71:	89 c2                	mov    %eax,%edx
   1cb73:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1cb76:	01 d0                	add    %edx,%eax
   1cb78:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   1cb7b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1cb7e:	89 44 24 08          	mov    %eax,0x8(%esp)
   1cb82:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1cb85:	89 44 24 04          	mov    %eax,0x4(%esp)
   1cb89:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1cb8c:	89 04 24             	mov    %eax,(%esp)
   1cb8f:	e8 fc ff ff ff       	call   1cb90 <ck_ring_dequeue_spmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   1cb94:	e8 0a f5 ff ff       	call   1c0a3 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1cb99:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1cb9c:	8d 58 01             	lea    0x1(%eax),%ebx
   1cb9f:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1cba2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cba5:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1cba8:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1cbac:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1cbb0:	89 54 24 04          	mov    %edx,0x4(%esp)
   1cbb4:	89 04 24             	mov    %eax,(%esp)
   1cbb7:	e8 09 f2 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   1cbbc:	83 f0 01             	xor    $0x1,%eax
   1cbbf:	84 c0                	test   %al,%al
   1cbc1:	0f 85 6e ff ff ff    	jne    1cb35 <ck_ring_dequeue_spmc+0x3a>

	return true;
   1cbc7:	b8 01 00 00 00       	mov    $0x1,%eax
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   1cbcc:	83 c4 34             	add    $0x34,%esp
   1cbcf:	5b                   	pop    %ebx
   1cbd0:	5d                   	pop    %ebp
   1cbd1:	c3                   	ret    

0001cbd2 <ck_ring_enqueue_mpsc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1cbd2:	55                   	push   %ebp
   1cbd3:	89 e5                	mov    %esp,%ebp
   1cbd5:	83 ec 48             	sub    $0x48,%esp
   1cbd8:	8b 45 08             	mov    0x8(%ebp),%eax
   1cbdb:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1cbde:	8b 45 0c             	mov    0xc(%ebp),%eax
   1cbe1:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1cbe4:	8d 45 10             	lea    0x10(%ebp),%eax
   1cbe7:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1cbea:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1cbf1:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1cbf8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cbfb:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1cc01:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1cc04:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1cc08:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cc0b:	83 c0 44             	add    $0x44,%eax
   1cc0e:	89 04 24             	mov    %eax,(%esp)
   1cc11:	e8 ae e7 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cc16:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1cc19:	e8 b1 f4 ff ff       	call   1c0cf <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1cc1e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cc21:	89 04 24             	mov    %eax,(%esp)
   1cc24:	e8 9b e7 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cc29:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1cc2c:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1cc2f:	83 c0 01             	add    $0x1,%eax
   1cc32:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1cc35:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1cc38:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1cc3b:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1cc3e:	0f 97 c0             	seta   %al
   1cc41:	0f b6 c0             	movzbl %al,%eax
   1cc44:	85 c0                	test   %eax,%eax
   1cc46:	74 29                	je     1cc71 <ck_ring_enqueue_mpsc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1cc48:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1cc4b:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1cc4e:	8d 4a 44             	lea    0x44(%edx),%ecx
   1cc51:	8d 55 cc             	lea    -0x34(%ebp),%edx
   1cc54:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1cc58:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   1cc5b:	89 54 24 08          	mov    %edx,0x8(%esp)
   1cc5f:	89 44 24 04          	mov    %eax,0x4(%esp)
   1cc63:	89 0c 24             	mov    %ecx,(%esp)
   1cc66:	e8 5a f1 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
   1cc6b:	84 c0                	test   %al,%al
   1cc6d:	75 31                	jne    1cca0 <ck_ring_enqueue_mpsc+0xce>
   1cc6f:	eb a8                	jmp    1cc19 <ck_ring_enqueue_mpsc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1cc71:	e8 59 f4 ff ff       	call   1c0cf <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1cc76:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cc79:	83 c0 44             	add    $0x44,%eax
   1cc7c:	89 04 24             	mov    %eax,(%esp)
   1cc7f:	e8 40 e7 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cc84:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1cc87:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1cc8a:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   1cc8d:	75 06                	jne    1cc95 <ck_ring_enqueue_mpsc+0xc3>
				r = false;
   1cc8f:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1cc93:	eb 67                	jmp    1ccfc <ck_ring_enqueue_mpsc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1cc95:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1cc98:	89 45 cc             	mov    %eax,-0x34(%ebp)
   1cc9b:	e9 79 ff ff ff       	jmp    1cc19 <ck_ring_enqueue_mpsc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1cca0:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1cca3:	23 45 e0             	and    -0x20(%ebp),%eax
   1cca6:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1ccaa:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1ccad:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1ccb0:	89 44 24 08          	mov    %eax,0x8(%esp)
   1ccb4:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1ccb7:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ccbb:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1ccbe:	89 04 24             	mov    %eax,(%esp)
   1ccc1:	e8 fc ff ff ff       	call   1ccc2 <ck_ring_enqueue_mpsc+0xf0>
   1ccc6:	eb 05                	jmp    1cccd <ck_ring_enqueue_mpsc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1ccc8:	e8 92 e5 ff ff       	call   1b25f <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1cccd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ccd0:	83 c0 40             	add    $0x40,%eax
   1ccd3:	89 04 24             	mov    %eax,(%esp)
   1ccd6:	e8 e9 e6 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1ccdb:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1ccde:	39 d0                	cmp    %edx,%eax
   1cce0:	75 e6                	jne    1ccc8 <ck_ring_enqueue_mpsc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1cce2:	e8 f3 f3 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1cce7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ccea:	8d 50 40             	lea    0x40(%eax),%edx
   1cced:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1ccf0:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ccf4:	89 14 24             	mov    %edx,(%esp)
   1ccf7:	e8 51 e7 ff ff       	call   1b44d <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1ccfc:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1cd00:	74 10                	je     1cd12 <ck_ring_enqueue_mpsc+0x140>
		*size = (producer - consumer) & mask;
   1cd02:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1cd05:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1cd08:	23 45 e0             	and    -0x20(%ebp),%eax
   1cd0b:	89 c2                	mov    %eax,%edx
   1cd0d:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1cd10:	89 10                	mov    %edx,(%eax)

	return r;
   1cd12:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   1cd16:	c9                   	leave  
   1cd17:	c3                   	ret    

0001cd18 <ck_ring_enqueue_mpsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1cd18:	55                   	push   %ebp
   1cd19:	89 e5                	mov    %esp,%ebp
   1cd1b:	83 ec 68             	sub    $0x68,%esp
   1cd1e:	8b 45 08             	mov    0x8(%ebp),%eax
   1cd21:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1cd24:	8b 45 0c             	mov    0xc(%ebp),%eax
   1cd27:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1cd2a:	8d 45 10             	lea    0x10(%ebp),%eax
   1cd2d:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1cd30:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1cd37:	8b 45 14             	mov    0x14(%ebp),%eax
   1cd3a:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1cd3d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cd40:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1cd43:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1cd46:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1cd49:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1cd4c:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1cd4f:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1cd52:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1cd55:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1cd58:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1cd5b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cd5e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1cd64:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1cd67:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1cd6b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cd6e:	83 c0 44             	add    $0x44,%eax
   1cd71:	89 04 24             	mov    %eax,(%esp)
   1cd74:	e8 4b e6 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cd79:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1cd7c:	e8 4e f3 ff ff       	call   1c0cf <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1cd81:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cd84:	89 04 24             	mov    %eax,(%esp)
   1cd87:	e8 38 e6 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cd8c:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   1cd8f:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1cd92:	83 c0 01             	add    $0x1,%eax
   1cd95:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1cd98:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1cd9b:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1cd9e:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   1cda1:	0f 97 c0             	seta   %al
   1cda4:	0f b6 c0             	movzbl %al,%eax
   1cda7:	85 c0                	test   %eax,%eax
   1cda9:	74 29                	je     1cdd4 <ck_ring_enqueue_mpsc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1cdab:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1cdae:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1cdb1:	8d 4a 44             	lea    0x44(%edx),%ecx
   1cdb4:	8d 55 b0             	lea    -0x50(%ebp),%edx
   1cdb7:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1cdbb:	8b 55 c0             	mov    -0x40(%ebp),%edx
   1cdbe:	89 54 24 08          	mov    %edx,0x8(%esp)
   1cdc2:	89 44 24 04          	mov    %eax,0x4(%esp)
   1cdc6:	89 0c 24             	mov    %ecx,(%esp)
   1cdc9:	e8 f7 ef ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
   1cdce:	84 c0                	test   %al,%al
   1cdd0:	75 31                	jne    1ce03 <ck_ring_enqueue_mpsc_size+0xeb>
   1cdd2:	eb a8                	jmp    1cd7c <ck_ring_enqueue_mpsc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1cdd4:	e8 f6 f2 ff ff       	call   1c0cf <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1cdd9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cddc:	83 c0 44             	add    $0x44,%eax
   1cddf:	89 04 24             	mov    %eax,(%esp)
   1cde2:	e8 dd e5 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cde7:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1cdea:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1cded:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   1cdf0:	75 06                	jne    1cdf8 <ck_ring_enqueue_mpsc_size+0xe0>
				r = false;
   1cdf2:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   1cdf6:	eb 67                	jmp    1ce5f <ck_ring_enqueue_mpsc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1cdf8:	8b 45 bc             	mov    -0x44(%ebp),%eax
   1cdfb:	89 45 b0             	mov    %eax,-0x50(%ebp)
   1cdfe:	e9 79 ff ff ff       	jmp    1cd7c <ck_ring_enqueue_mpsc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1ce03:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1ce06:	23 45 cc             	and    -0x34(%ebp),%eax
   1ce09:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1ce0d:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1ce10:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1ce13:	89 44 24 08          	mov    %eax,0x8(%esp)
   1ce17:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1ce1a:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ce1e:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1ce21:	89 04 24             	mov    %eax,(%esp)
   1ce24:	e8 fc ff ff ff       	call   1ce25 <ck_ring_enqueue_mpsc_size+0x10d>
   1ce29:	eb 05                	jmp    1ce30 <ck_ring_enqueue_mpsc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1ce2b:	e8 2f e4 ff ff       	call   1b25f <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1ce30:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1ce33:	83 c0 40             	add    $0x40,%eax
   1ce36:	89 04 24             	mov    %eax,(%esp)
   1ce39:	e8 86 e5 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1ce3e:	8b 55 b0             	mov    -0x50(%ebp),%edx
   1ce41:	39 d0                	cmp    %edx,%eax
   1ce43:	75 e6                	jne    1ce2b <ck_ring_enqueue_mpsc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1ce45:	e8 90 f2 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1ce4a:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1ce4d:	8d 50 40             	lea    0x40(%eax),%edx
   1ce50:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1ce53:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ce57:	89 14 24             	mov    %edx,(%esp)
   1ce5a:	e8 ee e5 ff ff       	call   1b44d <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1ce5f:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1ce63:	74 10                	je     1ce75 <ck_ring_enqueue_mpsc_size+0x15d>
		*size = (producer - consumer) & mask;
   1ce65:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1ce68:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1ce6b:	23 45 cc             	and    -0x34(%ebp),%eax
   1ce6e:	89 c2                	mov    %eax,%edx
   1ce70:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1ce73:	89 10                	mov    %edx,(%eax)

	return r;
   1ce75:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   1ce79:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   1ce7c:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   1ce7f:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1ce82:	89 10                	mov    %edx,(%eax)
	return r;
   1ce84:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   1ce88:	c9                   	leave  
   1ce89:	c3                   	ret    

0001ce8a <ck_ring_dequeue_mpsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1ce8a:	55                   	push   %ebp
   1ce8b:	89 e5                	mov    %esp,%ebp
   1ce8d:	83 ec 38             	sub    $0x38,%esp
   1ce90:	8b 45 08             	mov    0x8(%ebp),%eax
   1ce93:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1ce96:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ce99:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1ce9c:	8b 45 10             	mov    0x10(%ebp),%eax
   1ce9f:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1cea2:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1cea9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ceac:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1ceb2:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   1ceb5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ceb8:	8b 00                	mov    (%eax),%eax
   1ceba:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   1cebd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cec0:	83 c0 40             	add    $0x40,%eax
   1cec3:	89 04 24             	mov    %eax,(%esp)
   1cec6:	e8 f9 e4 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cecb:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1cece:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1ced1:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1ced4:	0f 94 c0             	sete   %al
   1ced7:	0f b6 c0             	movzbl %al,%eax
   1ceda:	85 c0                	test   %eax,%eax
   1cedc:	74 07                	je     1cee5 <ck_ring_dequeue_mpsc+0x5b>
		return false;
   1cede:	b8 00 00 00 00       	mov    $0x0,%eax
   1cee3:	eb 4c                	jmp    1cf31 <ck_ring_dequeue_mpsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   1cee5:	e8 e5 f1 ff ff       	call   1c0cf <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1ceea:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1ceed:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1cef0:	21 d0                	and    %edx,%eax
   1cef2:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1cef6:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   1cef9:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1cefc:	89 44 24 08          	mov    %eax,0x8(%esp)
   1cf00:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1cf03:	89 44 24 04          	mov    %eax,0x4(%esp)
   1cf07:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1cf0a:	89 04 24             	mov    %eax,(%esp)
   1cf0d:	e8 fc ff ff ff       	call   1cf0e <ck_ring_dequeue_mpsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   1cf12:	e8 c3 f1 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   1cf17:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cf1a:	8d 50 01             	lea    0x1(%eax),%edx
   1cf1d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cf20:	89 54 24 04          	mov    %edx,0x4(%esp)
   1cf24:	89 04 24             	mov    %eax,(%esp)
   1cf27:	e8 21 e5 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1cf2c:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   1cf31:	c9                   	leave  
   1cf32:	c3                   	ret    

0001cf33 <ck_ring_enqueue_spsc_size_xcpu>:
			struct cos_defcompinfo *dci, *sched;
		} sl_xcpu_req_initaep_alloc;
	};
};

CK_RING_PROTOTYPE(xcpu, sl_xcpu_request);
   1cf33:	55                   	push   %ebp
   1cf34:	89 e5                	mov    %esp,%ebp
   1cf36:	83 ec 58             	sub    $0x58,%esp
   1cf39:	8b 45 08             	mov    0x8(%ebp),%eax
   1cf3c:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1cf3f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1cf42:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1cf45:	8b 45 10             	mov    0x10(%ebp),%eax
   1cf48:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1cf4b:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1cf52:	8b 45 14             	mov    0x14(%ebp),%eax
   1cf55:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1cf58:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1cf5b:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1cf5e:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1cf61:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1cf64:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1cf67:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1cf6a:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1cf6d:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1cf70:	8d 45 b8             	lea    -0x48(%ebp),%eax
   1cf73:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1cf76:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cf79:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1cf7f:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1cf82:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cf85:	89 04 24             	mov    %eax,(%esp)
   1cf88:	e8 37 e4 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1cf8d:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   1cf90:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1cf93:	8b 40 40             	mov    0x40(%eax),%eax
   1cf96:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1cf99:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1cf9c:	83 c0 01             	add    $0x1,%eax
   1cf9f:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   1cfa2:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1cfa6:	74 14                	je     1cfbc <ck_ring_enqueue_spsc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   1cfa8:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1cfab:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   1cfae:	29 c2                	sub    %eax,%edx
   1cfb0:	89 d0                	mov    %edx,%eax
   1cfb2:	23 45 cc             	and    -0x34(%ebp),%eax
   1cfb5:	89 c2                	mov    %eax,%edx
   1cfb7:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1cfba:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1cfbc:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1cfbf:	8b 55 c8             	mov    -0x38(%ebp),%edx
   1cfc2:	31 d0                	xor    %edx,%eax
   1cfc4:	23 45 cc             	and    -0x34(%ebp),%eax
   1cfc7:	85 c0                	test   %eax,%eax
   1cfc9:	0f 94 c0             	sete   %al
   1cfcc:	0f b6 c0             	movzbl %al,%eax
   1cfcf:	85 c0                	test   %eax,%eax
   1cfd1:	74 07                	je     1cfda <ck_ring_enqueue_spsc_size_xcpu+0xa7>
		return false;
   1cfd3:	b8 00 00 00 00       	mov    $0x0,%eax
   1cfd8:	eb 47                	jmp    1d021 <ck_ring_enqueue_spsc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1cfda:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1cfdd:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1cfe0:	21 d0                	and    %edx,%eax
   1cfe2:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1cfe6:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1cfe9:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1cfec:	89 44 24 08          	mov    %eax,0x8(%esp)
   1cff0:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1cff3:	89 44 24 04          	mov    %eax,0x4(%esp)
   1cff7:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1cffa:	89 04 24             	mov    %eax,(%esp)
   1cffd:	e8 fc ff ff ff       	call   1cffe <ck_ring_enqueue_spsc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1d002:	e8 d3 f0 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1d007:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d00a:	8d 50 40             	lea    0x40(%eax),%edx
   1d00d:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1d010:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d014:	89 14 24             	mov    %edx,(%esp)
   1d017:	e8 31 e4 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1d01c:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   1d021:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   1d024:	8b 55 b8             	mov    -0x48(%ebp),%edx
   1d027:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1d02a:	89 10                	mov    %edx,(%eax)
	return r;
   1d02c:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   1d030:	c9                   	leave  
   1d031:	c3                   	ret    

0001d032 <ck_ring_enqueue_spsc_xcpu>:
   1d032:	55                   	push   %ebp
   1d033:	89 e5                	mov    %esp,%ebp
   1d035:	83 ec 48             	sub    $0x48,%esp
   1d038:	8b 45 08             	mov    0x8(%ebp),%eax
   1d03b:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d03e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d041:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d044:	8b 45 10             	mov    0x10(%ebp),%eax
   1d047:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d04a:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1d051:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1d058:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d05b:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d061:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1d064:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d067:	89 04 24             	mov    %eax,(%esp)
   1d06a:	e8 55 e3 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d06f:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   1d072:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d075:	8b 40 40             	mov    0x40(%eax),%eax
   1d078:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1d07b:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d07e:	83 c0 01             	add    $0x1,%eax
   1d081:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   1d084:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1d088:	74 14                	je     1d09e <ck_ring_enqueue_spsc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   1d08a:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1d08d:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1d090:	29 c2                	sub    %eax,%edx
   1d092:	89 d0                	mov    %edx,%eax
   1d094:	23 45 e0             	and    -0x20(%ebp),%eax
   1d097:	89 c2                	mov    %eax,%edx
   1d099:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1d09c:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1d09e:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1d0a1:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1d0a4:	31 d0                	xor    %edx,%eax
   1d0a6:	23 45 e0             	and    -0x20(%ebp),%eax
   1d0a9:	85 c0                	test   %eax,%eax
   1d0ab:	0f 94 c0             	sete   %al
   1d0ae:	0f b6 c0             	movzbl %al,%eax
   1d0b1:	85 c0                	test   %eax,%eax
   1d0b3:	74 07                	je     1d0bc <ck_ring_enqueue_spsc_xcpu+0x8a>
		return false;
   1d0b5:	b8 00 00 00 00       	mov    $0x0,%eax
   1d0ba:	eb 47                	jmp    1d103 <ck_ring_enqueue_spsc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1d0bc:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d0bf:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1d0c2:	21 d0                	and    %edx,%eax
   1d0c4:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1d0c8:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1d0cb:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d0ce:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d0d2:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d0d5:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d0d9:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d0dc:	89 04 24             	mov    %eax,(%esp)
   1d0df:	e8 fc ff ff ff       	call   1d0e0 <ck_ring_enqueue_spsc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1d0e4:	e8 f1 ef ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1d0e9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d0ec:	8d 50 40             	lea    0x40(%eax),%edx
   1d0ef:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1d0f2:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d0f6:	89 14 24             	mov    %edx,(%esp)
   1d0f9:	e8 4f e3 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1d0fe:	b8 01 00 00 00       	mov    $0x1,%eax
   1d103:	c9                   	leave  
   1d104:	c3                   	ret    

0001d105 <ck_ring_dequeue_spsc_xcpu>:
   1d105:	55                   	push   %ebp
   1d106:	89 e5                	mov    %esp,%ebp
   1d108:	83 ec 38             	sub    $0x38,%esp
   1d10b:	8b 45 08             	mov    0x8(%ebp),%eax
   1d10e:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d111:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d114:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d117:	8b 45 10             	mov    0x10(%ebp),%eax
   1d11a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d11d:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1d124:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d127:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d12d:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   1d130:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d133:	8b 00                	mov    (%eax),%eax
   1d135:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   1d138:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d13b:	83 c0 40             	add    $0x40,%eax
   1d13e:	89 04 24             	mov    %eax,(%esp)
   1d141:	e8 7e e2 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d146:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1d149:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d14c:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1d14f:	0f 94 c0             	sete   %al
   1d152:	0f b6 c0             	movzbl %al,%eax
   1d155:	85 c0                	test   %eax,%eax
   1d157:	74 07                	je     1d160 <ck_ring_dequeue_spsc_xcpu+0x5b>
		return false;
   1d159:	b8 00 00 00 00       	mov    $0x0,%eax
   1d15e:	eb 4c                	jmp    1d1ac <ck_ring_dequeue_spsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   1d160:	e8 6a ef ff ff       	call   1c0cf <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1d165:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d168:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1d16b:	21 d0                	and    %edx,%eax
   1d16d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1d171:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   1d174:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d177:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d17b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d17e:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d182:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d185:	89 04 24             	mov    %eax,(%esp)
   1d188:	e8 fc ff ff ff       	call   1d189 <ck_ring_dequeue_spsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   1d18d:	e8 48 ef ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   1d192:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d195:	8d 50 01             	lea    0x1(%eax),%edx
   1d198:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d19b:	89 54 24 04          	mov    %edx,0x4(%esp)
   1d19f:	89 04 24             	mov    %eax,(%esp)
   1d1a2:	e8 a6 e2 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1d1a7:	b8 01 00 00 00       	mov    $0x1,%eax
   1d1ac:	c9                   	leave  
   1d1ad:	c3                   	ret    

0001d1ae <ck_ring_enqueue_spmc_size_xcpu>:
   1d1ae:	55                   	push   %ebp
   1d1af:	89 e5                	mov    %esp,%ebp
   1d1b1:	83 ec 58             	sub    $0x58,%esp
   1d1b4:	8b 45 08             	mov    0x8(%ebp),%eax
   1d1b7:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d1ba:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d1bd:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d1c0:	8b 45 10             	mov    0x10(%ebp),%eax
   1d1c3:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d1c6:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1d1cd:	8b 45 14             	mov    0x14(%ebp),%eax
   1d1d0:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1d1d3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d1d6:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1d1d9:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d1dc:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1d1df:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d1e2:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1d1e5:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d1e8:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1d1eb:	8d 45 b8             	lea    -0x48(%ebp),%eax
   1d1ee:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1d1f1:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d1f4:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d1fa:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1d1fd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d200:	89 04 24             	mov    %eax,(%esp)
   1d203:	e8 bc e1 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d208:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   1d20b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d20e:	8b 40 40             	mov    0x40(%eax),%eax
   1d211:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1d214:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1d217:	83 c0 01             	add    $0x1,%eax
   1d21a:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   1d21d:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1d221:	74 14                	je     1d237 <ck_ring_enqueue_spmc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   1d223:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1d226:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   1d229:	29 c2                	sub    %eax,%edx
   1d22b:	89 d0                	mov    %edx,%eax
   1d22d:	23 45 cc             	and    -0x34(%ebp),%eax
   1d230:	89 c2                	mov    %eax,%edx
   1d232:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1d235:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1d237:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1d23a:	8b 55 c8             	mov    -0x38(%ebp),%edx
   1d23d:	31 d0                	xor    %edx,%eax
   1d23f:	23 45 cc             	and    -0x34(%ebp),%eax
   1d242:	85 c0                	test   %eax,%eax
   1d244:	0f 94 c0             	sete   %al
   1d247:	0f b6 c0             	movzbl %al,%eax
   1d24a:	85 c0                	test   %eax,%eax
   1d24c:	74 07                	je     1d255 <ck_ring_enqueue_spmc_size_xcpu+0xa7>
		return false;
   1d24e:	b8 00 00 00 00       	mov    $0x0,%eax
   1d253:	eb 47                	jmp    1d29c <ck_ring_enqueue_spmc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1d255:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1d258:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1d25b:	21 d0                	and    %edx,%eax
   1d25d:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1d261:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1d264:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1d267:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d26b:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d26e:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d272:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1d275:	89 04 24             	mov    %eax,(%esp)
   1d278:	e8 fc ff ff ff       	call   1d279 <ck_ring_enqueue_spmc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1d27d:	e8 58 ee ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1d282:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d285:	8d 50 40             	lea    0x40(%eax),%edx
   1d288:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1d28b:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d28f:	89 14 24             	mov    %edx,(%esp)
   1d292:	e8 b6 e1 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1d297:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   1d29c:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   1d29f:	8b 55 b8             	mov    -0x48(%ebp),%edx
   1d2a2:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1d2a5:	89 10                	mov    %edx,(%eax)
	return r;
   1d2a7:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   1d2ab:	c9                   	leave  
   1d2ac:	c3                   	ret    

0001d2ad <ck_ring_enqueue_spmc_xcpu>:
   1d2ad:	55                   	push   %ebp
   1d2ae:	89 e5                	mov    %esp,%ebp
   1d2b0:	83 ec 48             	sub    $0x48,%esp
   1d2b3:	8b 45 08             	mov    0x8(%ebp),%eax
   1d2b6:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d2b9:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d2bc:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d2bf:	8b 45 10             	mov    0x10(%ebp),%eax
   1d2c2:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d2c5:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1d2cc:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1d2d3:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d2d6:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d2dc:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1d2df:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d2e2:	89 04 24             	mov    %eax,(%esp)
   1d2e5:	e8 da e0 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d2ea:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   1d2ed:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d2f0:	8b 40 40             	mov    0x40(%eax),%eax
   1d2f3:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1d2f6:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d2f9:	83 c0 01             	add    $0x1,%eax
   1d2fc:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   1d2ff:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1d303:	74 14                	je     1d319 <ck_ring_enqueue_spmc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   1d305:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1d308:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1d30b:	29 c2                	sub    %eax,%edx
   1d30d:	89 d0                	mov    %edx,%eax
   1d30f:	23 45 e0             	and    -0x20(%ebp),%eax
   1d312:	89 c2                	mov    %eax,%edx
   1d314:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1d317:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1d319:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1d31c:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1d31f:	31 d0                	xor    %edx,%eax
   1d321:	23 45 e0             	and    -0x20(%ebp),%eax
   1d324:	85 c0                	test   %eax,%eax
   1d326:	0f 94 c0             	sete   %al
   1d329:	0f b6 c0             	movzbl %al,%eax
   1d32c:	85 c0                	test   %eax,%eax
   1d32e:	74 07                	je     1d337 <ck_ring_enqueue_spmc_xcpu+0x8a>
		return false;
   1d330:	b8 00 00 00 00       	mov    $0x0,%eax
   1d335:	eb 47                	jmp    1d37e <ck_ring_enqueue_spmc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1d337:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d33a:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1d33d:	21 d0                	and    %edx,%eax
   1d33f:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1d343:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1d346:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d349:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d34d:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d350:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d354:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d357:	89 04 24             	mov    %eax,(%esp)
   1d35a:	e8 fc ff ff ff       	call   1d35b <ck_ring_enqueue_spmc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1d35f:	e8 76 ed ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1d364:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d367:	8d 50 40             	lea    0x40(%eax),%edx
   1d36a:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1d36d:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d371:	89 14 24             	mov    %edx,(%esp)
   1d374:	e8 d4 e0 ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1d379:	b8 01 00 00 00       	mov    $0x1,%eax
   1d37e:	c9                   	leave  
   1d37f:	c3                   	ret    

0001d380 <ck_ring_trydequeue_spmc_xcpu>:
   1d380:	55                   	push   %ebp
   1d381:	89 e5                	mov    %esp,%ebp
   1d383:	83 ec 38             	sub    $0x38,%esp
   1d386:	8b 45 08             	mov    0x8(%ebp),%eax
   1d389:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d38c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d38f:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d392:	8b 45 10             	mov    0x10(%ebp),%eax
   1d395:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d398:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1d39f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d3a2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d3a8:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1d3ab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d3ae:	89 04 24             	mov    %eax,(%esp)
   1d3b1:	e8 0e e0 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d3b6:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   1d3b9:	e8 11 ed ff ff       	call   1c0cf <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   1d3be:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d3c1:	83 c0 40             	add    $0x40,%eax
   1d3c4:	89 04 24             	mov    %eax,(%esp)
   1d3c7:	e8 f8 df ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d3cc:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1d3cf:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d3d2:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1d3d5:	0f 94 c0             	sete   %al
   1d3d8:	0f b6 c0             	movzbl %al,%eax
   1d3db:	85 c0                	test   %eax,%eax
   1d3dd:	74 07                	je     1d3e6 <ck_ring_trydequeue_spmc_xcpu+0x66>
		return false;
   1d3df:	b8 00 00 00 00       	mov    $0x0,%eax
   1d3e4:	eb 4e                	jmp    1d434 <ck_ring_trydequeue_spmc_xcpu+0xb4>

	ck_pr_fence_load();
   1d3e6:	e8 e4 ec ff ff       	call   1c0cf <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1d3eb:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d3ee:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1d3f1:	21 d0                	and    %edx,%eax
   1d3f3:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1d3f7:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1d3fa:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d3fd:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d401:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d404:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d408:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d40b:	89 04 24             	mov    %eax,(%esp)
   1d40e:	e8 fc ff ff ff       	call   1d40f <ck_ring_trydequeue_spmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   1d413:	e8 8b ec ff ff       	call   1c0a3 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1d418:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d41b:	8d 50 01             	lea    0x1(%eax),%edx
   1d41e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d421:	89 54 24 08          	mov    %edx,0x8(%esp)
   1d425:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1d428:	89 54 24 04          	mov    %edx,0x4(%esp)
   1d42c:	89 04 24             	mov    %eax,(%esp)
   1d42f:	e8 3e e8 ff ff       	call   1bc72 <ck_pr_cas_uint>
   1d434:	c9                   	leave  
   1d435:	c3                   	ret    

0001d436 <ck_ring_dequeue_spmc_xcpu>:
   1d436:	55                   	push   %ebp
   1d437:	89 e5                	mov    %esp,%ebp
   1d439:	53                   	push   %ebx
   1d43a:	83 ec 34             	sub    $0x34,%esp
   1d43d:	8b 45 08             	mov    0x8(%ebp),%eax
   1d440:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d443:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d446:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d449:	8b 45 10             	mov    0x10(%ebp),%eax
   1d44c:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d44f:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   1d456:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d459:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d45f:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1d462:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d465:	89 04 24             	mov    %eax,(%esp)
   1d468:	e8 57 df ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d46d:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   1d470:	e8 5a ec ff ff       	call   1c0cf <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   1d475:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d478:	83 c0 40             	add    $0x40,%eax
   1d47b:	89 04 24             	mov    %eax,(%esp)
   1d47e:	e8 41 df ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d483:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   1d486:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d489:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1d48c:	0f 94 c0             	sete   %al
   1d48f:	0f b6 c0             	movzbl %al,%eax
   1d492:	85 c0                	test   %eax,%eax
   1d494:	74 07                	je     1d49d <ck_ring_dequeue_spmc_xcpu+0x67>
			return false;
   1d496:	b8 00 00 00 00       	mov    $0x0,%eax
   1d49b:	eb 6a                	jmp    1d507 <ck_ring_dequeue_spmc_xcpu+0xd1>

		ck_pr_fence_load();
   1d49d:	e8 2d ec ff ff       	call   1c0cf <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   1d4a2:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d4a5:	23 45 e4             	and    -0x1c(%ebp),%eax
   1d4a8:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1d4ac:	89 c2                	mov    %eax,%edx
   1d4ae:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d4b1:	01 d0                	add    %edx,%eax
   1d4b3:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   1d4b6:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d4b9:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d4bd:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1d4c0:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d4c4:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d4c7:	89 04 24             	mov    %eax,(%esp)
   1d4ca:	e8 fc ff ff ff       	call   1d4cb <ck_ring_dequeue_spmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   1d4cf:	e8 cf eb ff ff       	call   1c0a3 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1d4d4:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d4d7:	8d 58 01             	lea    0x1(%eax),%ebx
   1d4da:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1d4dd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d4e0:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1d4e3:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1d4e7:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1d4eb:	89 54 24 04          	mov    %edx,0x4(%esp)
   1d4ef:	89 04 24             	mov    %eax,(%esp)
   1d4f2:	e8 ce e8 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   1d4f7:	83 f0 01             	xor    $0x1,%eax
   1d4fa:	84 c0                	test   %al,%al
   1d4fc:	0f 85 6e ff ff ff    	jne    1d470 <ck_ring_dequeue_spmc_xcpu+0x3a>

	return true;
   1d502:	b8 01 00 00 00       	mov    $0x1,%eax
   1d507:	83 c4 34             	add    $0x34,%esp
   1d50a:	5b                   	pop    %ebx
   1d50b:	5d                   	pop    %ebp
   1d50c:	c3                   	ret    

0001d50d <ck_ring_enqueue_mpsc_xcpu>:
   1d50d:	55                   	push   %ebp
   1d50e:	89 e5                	mov    %esp,%ebp
   1d510:	83 ec 48             	sub    $0x48,%esp
   1d513:	8b 45 08             	mov    0x8(%ebp),%eax
   1d516:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d519:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d51c:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d51f:	8b 45 10             	mov    0x10(%ebp),%eax
   1d522:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d525:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1d52c:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1d533:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d536:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d53c:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1d53f:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1d543:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d546:	83 c0 44             	add    $0x44,%eax
   1d549:	89 04 24             	mov    %eax,(%esp)
   1d54c:	e8 73 de ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d551:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1d554:	e8 76 eb ff ff       	call   1c0cf <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1d559:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d55c:	89 04 24             	mov    %eax,(%esp)
   1d55f:	e8 60 de ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d564:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1d567:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1d56a:	83 c0 01             	add    $0x1,%eax
   1d56d:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1d570:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1d573:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1d576:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1d579:	0f 97 c0             	seta   %al
   1d57c:	0f b6 c0             	movzbl %al,%eax
   1d57f:	85 c0                	test   %eax,%eax
   1d581:	74 29                	je     1d5ac <ck_ring_enqueue_mpsc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1d583:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1d586:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1d589:	8d 4a 44             	lea    0x44(%edx),%ecx
   1d58c:	8d 55 cc             	lea    -0x34(%ebp),%edx
   1d58f:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1d593:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   1d596:	89 54 24 08          	mov    %edx,0x8(%esp)
   1d59a:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d59e:	89 0c 24             	mov    %ecx,(%esp)
   1d5a1:	e8 1f e8 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
   1d5a6:	84 c0                	test   %al,%al
   1d5a8:	75 31                	jne    1d5db <ck_ring_enqueue_mpsc_xcpu+0xce>
   1d5aa:	eb a8                	jmp    1d554 <ck_ring_enqueue_mpsc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1d5ac:	e8 1e eb ff ff       	call   1c0cf <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1d5b1:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d5b4:	83 c0 44             	add    $0x44,%eax
   1d5b7:	89 04 24             	mov    %eax,(%esp)
   1d5ba:	e8 05 de ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d5bf:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1d5c2:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1d5c5:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   1d5c8:	75 06                	jne    1d5d0 <ck_ring_enqueue_mpsc_xcpu+0xc3>
				r = false;
   1d5ca:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1d5ce:	eb 67                	jmp    1d637 <ck_ring_enqueue_mpsc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1d5d0:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1d5d3:	89 45 cc             	mov    %eax,-0x34(%ebp)
   1d5d6:	e9 79 ff ff ff       	jmp    1d554 <ck_ring_enqueue_mpsc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1d5db:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1d5de:	23 45 e0             	and    -0x20(%ebp),%eax
   1d5e1:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1d5e5:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1d5e8:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d5eb:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d5ef:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d5f2:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d5f6:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d5f9:	89 04 24             	mov    %eax,(%esp)
   1d5fc:	e8 fc ff ff ff       	call   1d5fd <ck_ring_enqueue_mpsc_xcpu+0xf0>
   1d601:	eb 05                	jmp    1d608 <ck_ring_enqueue_mpsc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1d603:	e8 57 dc ff ff       	call   1b25f <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1d608:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d60b:	83 c0 40             	add    $0x40,%eax
   1d60e:	89 04 24             	mov    %eax,(%esp)
   1d611:	e8 ae dd ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d616:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1d619:	39 d0                	cmp    %edx,%eax
   1d61b:	75 e6                	jne    1d603 <ck_ring_enqueue_mpsc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1d61d:	e8 b8 ea ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1d622:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d625:	8d 50 40             	lea    0x40(%eax),%edx
   1d628:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1d62b:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d62f:	89 14 24             	mov    %edx,(%esp)
   1d632:	e8 16 de ff ff       	call   1b44d <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1d637:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1d63b:	74 10                	je     1d64d <ck_ring_enqueue_mpsc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   1d63d:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1d640:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1d643:	23 45 e0             	and    -0x20(%ebp),%eax
   1d646:	89 c2                	mov    %eax,%edx
   1d648:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1d64b:	89 10                	mov    %edx,(%eax)

	return r;
   1d64d:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   1d651:	c9                   	leave  
   1d652:	c3                   	ret    

0001d653 <ck_ring_enqueue_mpsc_size_xcpu>:
   1d653:	55                   	push   %ebp
   1d654:	89 e5                	mov    %esp,%ebp
   1d656:	83 ec 68             	sub    $0x68,%esp
   1d659:	8b 45 08             	mov    0x8(%ebp),%eax
   1d65c:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d65f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d662:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d665:	8b 45 10             	mov    0x10(%ebp),%eax
   1d668:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d66b:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1d672:	8b 45 14             	mov    0x14(%ebp),%eax
   1d675:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1d678:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d67b:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1d67e:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d681:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1d684:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d687:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1d68a:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d68d:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1d690:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1d693:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1d696:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d699:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d69f:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1d6a2:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1d6a6:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d6a9:	83 c0 44             	add    $0x44,%eax
   1d6ac:	89 04 24             	mov    %eax,(%esp)
   1d6af:	e8 10 dd ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d6b4:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1d6b7:	e8 13 ea ff ff       	call   1c0cf <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1d6bc:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d6bf:	89 04 24             	mov    %eax,(%esp)
   1d6c2:	e8 fd dc ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d6c7:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   1d6ca:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d6cd:	83 c0 01             	add    $0x1,%eax
   1d6d0:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1d6d3:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d6d6:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1d6d9:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   1d6dc:	0f 97 c0             	seta   %al
   1d6df:	0f b6 c0             	movzbl %al,%eax
   1d6e2:	85 c0                	test   %eax,%eax
   1d6e4:	74 29                	je     1d70f <ck_ring_enqueue_mpsc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1d6e6:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d6e9:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1d6ec:	8d 4a 44             	lea    0x44(%edx),%ecx
   1d6ef:	8d 55 b0             	lea    -0x50(%ebp),%edx
   1d6f2:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1d6f6:	8b 55 c0             	mov    -0x40(%ebp),%edx
   1d6f9:	89 54 24 08          	mov    %edx,0x8(%esp)
   1d6fd:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d701:	89 0c 24             	mov    %ecx,(%esp)
   1d704:	e8 bc e6 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
   1d709:	84 c0                	test   %al,%al
   1d70b:	75 31                	jne    1d73e <ck_ring_enqueue_mpsc_size_xcpu+0xeb>
   1d70d:	eb a8                	jmp    1d6b7 <ck_ring_enqueue_mpsc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1d70f:	e8 bb e9 ff ff       	call   1c0cf <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1d714:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d717:	83 c0 44             	add    $0x44,%eax
   1d71a:	89 04 24             	mov    %eax,(%esp)
   1d71d:	e8 a2 dc ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d722:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1d725:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d728:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   1d72b:	75 06                	jne    1d733 <ck_ring_enqueue_mpsc_size_xcpu+0xe0>
				r = false;
   1d72d:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   1d731:	eb 67                	jmp    1d79a <ck_ring_enqueue_mpsc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1d733:	8b 45 bc             	mov    -0x44(%ebp),%eax
   1d736:	89 45 b0             	mov    %eax,-0x50(%ebp)
   1d739:	e9 79 ff ff ff       	jmp    1d6b7 <ck_ring_enqueue_mpsc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1d73e:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d741:	23 45 cc             	and    -0x34(%ebp),%eax
   1d744:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1d748:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1d74b:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1d74e:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d752:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d755:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d759:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1d75c:	89 04 24             	mov    %eax,(%esp)
   1d75f:	e8 fc ff ff ff       	call   1d760 <ck_ring_enqueue_mpsc_size_xcpu+0x10d>
   1d764:	eb 05                	jmp    1d76b <ck_ring_enqueue_mpsc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1d766:	e8 f4 da ff ff       	call   1b25f <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1d76b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d76e:	83 c0 40             	add    $0x40,%eax
   1d771:	89 04 24             	mov    %eax,(%esp)
   1d774:	e8 4b dc ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d779:	8b 55 b0             	mov    -0x50(%ebp),%edx
   1d77c:	39 d0                	cmp    %edx,%eax
   1d77e:	75 e6                	jne    1d766 <ck_ring_enqueue_mpsc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1d780:	e8 55 e9 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1d785:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d788:	8d 50 40             	lea    0x40(%eax),%edx
   1d78b:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1d78e:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d792:	89 14 24             	mov    %edx,(%esp)
   1d795:	e8 b3 dc ff ff       	call   1b44d <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1d79a:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1d79e:	74 10                	je     1d7b0 <ck_ring_enqueue_mpsc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   1d7a0:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d7a3:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1d7a6:	23 45 cc             	and    -0x34(%ebp),%eax
   1d7a9:	89 c2                	mov    %eax,%edx
   1d7ab:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1d7ae:	89 10                	mov    %edx,(%eax)

	return r;
   1d7b0:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   1d7b4:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   1d7b7:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   1d7ba:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1d7bd:	89 10                	mov    %edx,(%eax)
	return r;
   1d7bf:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   1d7c3:	c9                   	leave  
   1d7c4:	c3                   	ret    

0001d7c5 <ck_ring_dequeue_mpsc_xcpu>:
   1d7c5:	55                   	push   %ebp
   1d7c6:	89 e5                	mov    %esp,%ebp
   1d7c8:	83 ec 38             	sub    $0x38,%esp
   1d7cb:	8b 45 08             	mov    0x8(%ebp),%eax
   1d7ce:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d7d1:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d7d4:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d7d7:	8b 45 10             	mov    0x10(%ebp),%eax
   1d7da:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d7dd:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1d7e4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d7e7:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d7ed:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   1d7f0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d7f3:	8b 00                	mov    (%eax),%eax
   1d7f5:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   1d7f8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d7fb:	83 c0 40             	add    $0x40,%eax
   1d7fe:	89 04 24             	mov    %eax,(%esp)
   1d801:	e8 be db ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d806:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1d809:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d80c:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1d80f:	0f 94 c0             	sete   %al
   1d812:	0f b6 c0             	movzbl %al,%eax
   1d815:	85 c0                	test   %eax,%eax
   1d817:	74 07                	je     1d820 <ck_ring_dequeue_mpsc_xcpu+0x5b>
		return false;
   1d819:	b8 00 00 00 00       	mov    $0x0,%eax
   1d81e:	eb 4c                	jmp    1d86c <ck_ring_dequeue_mpsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   1d820:	e8 aa e8 ff ff       	call   1c0cf <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1d825:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d828:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1d82b:	21 d0                	and    %edx,%eax
   1d82d:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1d831:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   1d834:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d837:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d83b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d83e:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d842:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d845:	89 04 24             	mov    %eax,(%esp)
   1d848:	e8 fc ff ff ff       	call   1d849 <ck_ring_dequeue_mpsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   1d84d:	e8 88 e8 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   1d852:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d855:	8d 50 01             	lea    0x1(%eax),%edx
   1d858:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d85b:	89 54 24 04          	mov    %edx,0x4(%esp)
   1d85f:	89 04 24             	mov    %eax,(%esp)
   1d862:	e8 e6 db ff ff       	call   1b44d <ck_pr_md_store_uint>
	return true;
   1d867:	b8 01 00 00 00       	mov    $0x1,%eax
   1d86c:	c9                   	leave  
   1d86d:	c3                   	ret    

0001d86e <ck_ring_enqueue_mpmc_size_xcpu>:
   1d86e:	55                   	push   %ebp
   1d86f:	89 e5                	mov    %esp,%ebp
   1d871:	83 ec 68             	sub    $0x68,%esp
   1d874:	8b 45 08             	mov    0x8(%ebp),%eax
   1d877:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d87a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d87d:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d880:	8b 45 10             	mov    0x10(%ebp),%eax
   1d883:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d886:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1d88d:	8b 45 14             	mov    0x14(%ebp),%eax
   1d890:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1d893:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1d896:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1d899:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1d89c:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1d89f:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1d8a2:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1d8a5:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1d8a8:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1d8ab:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1d8ae:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1d8b1:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d8b4:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1d8ba:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1d8bd:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1d8c1:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d8c4:	83 c0 44             	add    $0x44,%eax
   1d8c7:	89 04 24             	mov    %eax,(%esp)
   1d8ca:	e8 f5 da ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d8cf:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1d8d2:	e8 f8 e7 ff ff       	call   1c0cf <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1d8d7:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d8da:	89 04 24             	mov    %eax,(%esp)
   1d8dd:	e8 e2 da ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d8e2:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   1d8e5:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d8e8:	83 c0 01             	add    $0x1,%eax
   1d8eb:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1d8ee:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d8f1:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1d8f4:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   1d8f7:	0f 97 c0             	seta   %al
   1d8fa:	0f b6 c0             	movzbl %al,%eax
   1d8fd:	85 c0                	test   %eax,%eax
   1d8ff:	74 29                	je     1d92a <ck_ring_enqueue_mpmc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1d901:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d904:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1d907:	8d 4a 44             	lea    0x44(%edx),%ecx
   1d90a:	8d 55 b0             	lea    -0x50(%ebp),%edx
   1d90d:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1d911:	8b 55 c0             	mov    -0x40(%ebp),%edx
   1d914:	89 54 24 08          	mov    %edx,0x8(%esp)
   1d918:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d91c:	89 0c 24             	mov    %ecx,(%esp)
   1d91f:	e8 a1 e4 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
   1d924:	84 c0                	test   %al,%al
   1d926:	75 31                	jne    1d959 <ck_ring_enqueue_mpmc_size_xcpu+0xeb>
   1d928:	eb a8                	jmp    1d8d2 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1d92a:	e8 a0 e7 ff ff       	call   1c0cf <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1d92f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d932:	83 c0 44             	add    $0x44,%eax
   1d935:	89 04 24             	mov    %eax,(%esp)
   1d938:	e8 87 da ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d93d:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1d940:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d943:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   1d946:	75 06                	jne    1d94e <ck_ring_enqueue_mpmc_size_xcpu+0xe0>
				r = false;
   1d948:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   1d94c:	eb 67                	jmp    1d9b5 <ck_ring_enqueue_mpmc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1d94e:	8b 45 bc             	mov    -0x44(%ebp),%eax
   1d951:	89 45 b0             	mov    %eax,-0x50(%ebp)
   1d954:	e9 79 ff ff ff       	jmp    1d8d2 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1d959:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d95c:	23 45 cc             	and    -0x34(%ebp),%eax
   1d95f:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1d963:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1d966:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1d969:	89 44 24 08          	mov    %eax,0x8(%esp)
   1d96d:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1d970:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d974:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1d977:	89 04 24             	mov    %eax,(%esp)
   1d97a:	e8 fc ff ff ff       	call   1d97b <ck_ring_enqueue_mpmc_size_xcpu+0x10d>
   1d97f:	eb 05                	jmp    1d986 <ck_ring_enqueue_mpmc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1d981:	e8 d9 d8 ff ff       	call   1b25f <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1d986:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d989:	83 c0 40             	add    $0x40,%eax
   1d98c:	89 04 24             	mov    %eax,(%esp)
   1d98f:	e8 30 da ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1d994:	8b 55 b0             	mov    -0x50(%ebp),%edx
   1d997:	39 d0                	cmp    %edx,%eax
   1d999:	75 e6                	jne    1d981 <ck_ring_enqueue_mpmc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1d99b:	e8 3a e7 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1d9a0:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1d9a3:	8d 50 40             	lea    0x40(%eax),%edx
   1d9a6:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1d9a9:	89 44 24 04          	mov    %eax,0x4(%esp)
   1d9ad:	89 14 24             	mov    %edx,(%esp)
   1d9b0:	e8 98 da ff ff       	call   1b44d <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1d9b5:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1d9b9:	74 10                	je     1d9cb <ck_ring_enqueue_mpmc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   1d9bb:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1d9be:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1d9c1:	23 45 cc             	and    -0x34(%ebp),%eax
   1d9c4:	89 c2                	mov    %eax,%edx
   1d9c6:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1d9c9:	89 10                	mov    %edx,(%eax)

	return r;
   1d9cb:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   1d9cf:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   1d9d2:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   1d9d5:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1d9d8:	89 10                	mov    %edx,(%eax)
	return r;
   1d9da:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   1d9de:	c9                   	leave  
   1d9df:	c3                   	ret    

0001d9e0 <ck_ring_enqueue_mpmc_xcpu>:
   1d9e0:	55                   	push   %ebp
   1d9e1:	89 e5                	mov    %esp,%ebp
   1d9e3:	83 ec 48             	sub    $0x48,%esp
   1d9e6:	8b 45 08             	mov    0x8(%ebp),%eax
   1d9e9:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1d9ec:	8b 45 0c             	mov    0xc(%ebp),%eax
   1d9ef:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1d9f2:	8b 45 10             	mov    0x10(%ebp),%eax
   1d9f5:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1d9f8:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   1d9ff:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1da06:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1da09:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1da0f:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1da12:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1da16:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1da19:	83 c0 44             	add    $0x44,%eax
   1da1c:	89 04 24             	mov    %eax,(%esp)
   1da1f:	e8 a0 d9 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1da24:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1da27:	e8 a3 e6 ff ff       	call   1c0cf <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1da2c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1da2f:	89 04 24             	mov    %eax,(%esp)
   1da32:	e8 8d d9 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1da37:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1da3a:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1da3d:	83 c0 01             	add    $0x1,%eax
   1da40:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1da43:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1da46:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1da49:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1da4c:	0f 97 c0             	seta   %al
   1da4f:	0f b6 c0             	movzbl %al,%eax
   1da52:	85 c0                	test   %eax,%eax
   1da54:	74 29                	je     1da7f <ck_ring_enqueue_mpmc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1da56:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1da59:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1da5c:	8d 4a 44             	lea    0x44(%edx),%ecx
   1da5f:	8d 55 cc             	lea    -0x34(%ebp),%edx
   1da62:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1da66:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   1da69:	89 54 24 08          	mov    %edx,0x8(%esp)
   1da6d:	89 44 24 04          	mov    %eax,0x4(%esp)
   1da71:	89 0c 24             	mov    %ecx,(%esp)
   1da74:	e8 4c e3 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
   1da79:	84 c0                	test   %al,%al
   1da7b:	75 31                	jne    1daae <ck_ring_enqueue_mpmc_xcpu+0xce>
   1da7d:	eb a8                	jmp    1da27 <ck_ring_enqueue_mpmc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1da7f:	e8 4b e6 ff ff       	call   1c0cf <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1da84:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1da87:	83 c0 44             	add    $0x44,%eax
   1da8a:	89 04 24             	mov    %eax,(%esp)
   1da8d:	e8 32 d9 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1da92:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1da95:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1da98:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   1da9b:	75 06                	jne    1daa3 <ck_ring_enqueue_mpmc_xcpu+0xc3>
				r = false;
   1da9d:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1daa1:	eb 67                	jmp    1db0a <ck_ring_enqueue_mpmc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1daa3:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1daa6:	89 45 cc             	mov    %eax,-0x34(%ebp)
   1daa9:	e9 79 ff ff ff       	jmp    1da27 <ck_ring_enqueue_mpmc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1daae:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1dab1:	23 45 e0             	and    -0x20(%ebp),%eax
   1dab4:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1dab8:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1dabb:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1dabe:	89 44 24 08          	mov    %eax,0x8(%esp)
   1dac2:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1dac5:	89 44 24 04          	mov    %eax,0x4(%esp)
   1dac9:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1dacc:	89 04 24             	mov    %eax,(%esp)
   1dacf:	e8 fc ff ff ff       	call   1dad0 <ck_ring_enqueue_mpmc_xcpu+0xf0>
   1dad4:	eb 05                	jmp    1dadb <ck_ring_enqueue_mpmc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1dad6:	e8 84 d7 ff ff       	call   1b25f <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1dadb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1dade:	83 c0 40             	add    $0x40,%eax
   1dae1:	89 04 24             	mov    %eax,(%esp)
   1dae4:	e8 db d8 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1dae9:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1daec:	39 d0                	cmp    %edx,%eax
   1daee:	75 e6                	jne    1dad6 <ck_ring_enqueue_mpmc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1daf0:	e8 e5 e5 ff ff       	call   1c0da <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1daf5:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1daf8:	8d 50 40             	lea    0x40(%eax),%edx
   1dafb:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1dafe:	89 44 24 04          	mov    %eax,0x4(%esp)
   1db02:	89 14 24             	mov    %edx,(%esp)
   1db05:	e8 43 d9 ff ff       	call   1b44d <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1db0a:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1db0e:	74 10                	je     1db20 <ck_ring_enqueue_mpmc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   1db10:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1db13:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1db16:	23 45 e0             	and    -0x20(%ebp),%eax
   1db19:	89 c2                	mov    %eax,%edx
   1db1b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1db1e:	89 10                	mov    %edx,(%eax)

	return r;
   1db20:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   1db24:	c9                   	leave  
   1db25:	c3                   	ret    

0001db26 <ck_ring_trydequeue_mpmc_xcpu>:
   1db26:	55                   	push   %ebp
   1db27:	89 e5                	mov    %esp,%ebp
   1db29:	83 ec 38             	sub    $0x38,%esp
   1db2c:	8b 45 08             	mov    0x8(%ebp),%eax
   1db2f:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1db32:	8b 45 0c             	mov    0xc(%ebp),%eax
   1db35:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1db38:	8b 45 10             	mov    0x10(%ebp),%eax
   1db3b:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1db3e:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1db45:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1db48:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1db4e:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1db51:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1db54:	89 04 24             	mov    %eax,(%esp)
   1db57:	e8 68 d8 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1db5c:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   1db5f:	e8 6b e5 ff ff       	call   1c0cf <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   1db64:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1db67:	83 c0 40             	add    $0x40,%eax
   1db6a:	89 04 24             	mov    %eax,(%esp)
   1db6d:	e8 52 d8 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1db72:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1db75:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1db78:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1db7b:	0f 94 c0             	sete   %al
   1db7e:	0f b6 c0             	movzbl %al,%eax
   1db81:	85 c0                	test   %eax,%eax
   1db83:	74 07                	je     1db8c <ck_ring_trydequeue_mpmc_xcpu+0x66>
		return false;
   1db85:	b8 00 00 00 00       	mov    $0x0,%eax
   1db8a:	eb 4e                	jmp    1dbda <ck_ring_trydequeue_mpmc_xcpu+0xb4>

	ck_pr_fence_load();
   1db8c:	e8 3e e5 ff ff       	call   1c0cf <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1db91:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1db94:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1db97:	21 d0                	and    %edx,%eax
   1db99:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1db9d:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1dba0:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1dba3:	89 44 24 08          	mov    %eax,0x8(%esp)
   1dba7:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1dbaa:	89 44 24 04          	mov    %eax,0x4(%esp)
   1dbae:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1dbb1:	89 04 24             	mov    %eax,(%esp)
   1dbb4:	e8 fc ff ff ff       	call   1dbb5 <ck_ring_trydequeue_mpmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   1dbb9:	e8 e5 e4 ff ff       	call   1c0a3 <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1dbbe:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1dbc1:	8d 50 01             	lea    0x1(%eax),%edx
   1dbc4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1dbc7:	89 54 24 08          	mov    %edx,0x8(%esp)
   1dbcb:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1dbce:	89 54 24 04          	mov    %edx,0x4(%esp)
   1dbd2:	89 04 24             	mov    %eax,(%esp)
   1dbd5:	e8 98 e0 ff ff       	call   1bc72 <ck_pr_cas_uint>
   1dbda:	c9                   	leave  
   1dbdb:	c3                   	ret    

0001dbdc <ck_ring_dequeue_mpmc_xcpu>:
   1dbdc:	55                   	push   %ebp
   1dbdd:	89 e5                	mov    %esp,%ebp
   1dbdf:	53                   	push   %ebx
   1dbe0:	83 ec 34             	sub    $0x34,%esp
   1dbe3:	8b 45 08             	mov    0x8(%ebp),%eax
   1dbe6:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1dbe9:	8b 45 0c             	mov    0xc(%ebp),%eax
   1dbec:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1dbef:	8b 45 10             	mov    0x10(%ebp),%eax
   1dbf2:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1dbf5:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   1dbfc:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1dbff:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1dc05:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1dc08:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1dc0b:	89 04 24             	mov    %eax,(%esp)
   1dc0e:	e8 b1 d7 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1dc13:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   1dc16:	e8 b4 e4 ff ff       	call   1c0cf <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   1dc1b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1dc1e:	83 c0 40             	add    $0x40,%eax
   1dc21:	89 04 24             	mov    %eax,(%esp)
   1dc24:	e8 9b d7 ff ff       	call   1b3c4 <ck_pr_md_load_uint>
   1dc29:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   1dc2c:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1dc2f:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1dc32:	0f 94 c0             	sete   %al
   1dc35:	0f b6 c0             	movzbl %al,%eax
   1dc38:	85 c0                	test   %eax,%eax
   1dc3a:	74 07                	je     1dc43 <ck_ring_dequeue_mpmc_xcpu+0x67>
			return false;
   1dc3c:	b8 00 00 00 00       	mov    $0x0,%eax
   1dc41:	eb 6a                	jmp    1dcad <ck_ring_dequeue_mpmc_xcpu+0xd1>

		ck_pr_fence_load();
   1dc43:	e8 87 e4 ff ff       	call   1c0cf <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   1dc48:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1dc4b:	23 45 e4             	and    -0x1c(%ebp),%eax
   1dc4e:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1dc52:	89 c2                	mov    %eax,%edx
   1dc54:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1dc57:	01 d0                	add    %edx,%eax
   1dc59:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   1dc5c:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1dc5f:	89 44 24 08          	mov    %eax,0x8(%esp)
   1dc63:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1dc66:	89 44 24 04          	mov    %eax,0x4(%esp)
   1dc6a:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1dc6d:	89 04 24             	mov    %eax,(%esp)
   1dc70:	e8 fc ff ff ff       	call   1dc71 <ck_ring_dequeue_mpmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   1dc75:	e8 29 e4 ff ff       	call   1c0a3 <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1dc7a:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1dc7d:	8d 58 01             	lea    0x1(%eax),%ebx
   1dc80:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1dc83:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1dc86:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1dc89:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1dc8d:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1dc91:	89 54 24 04          	mov    %edx,0x4(%esp)
   1dc95:	89 04 24             	mov    %eax,(%esp)
   1dc98:	e8 28 e1 ff ff       	call   1bdc5 <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   1dc9d:	83 f0 01             	xor    $0x1,%eax
   1dca0:	84 c0                	test   %al,%al
   1dca2:	0f 85 6e ff ff ff    	jne    1dc16 <ck_ring_dequeue_mpmc_xcpu+0x3a>

	return true;
   1dca8:	b8 01 00 00 00       	mov    $0x1,%eax
   1dcad:	83 c4 34             	add    $0x34,%esp
   1dcb0:	5b                   	pop    %ebx
   1dcb1:	5d                   	pop    %ebp
   1dcb2:	c3                   	ret    

0001dcb3 <sl_thd_alloc_backend>:
static u32_t               __sl_aep_free_off[NUM_CPU];

/* Default implementations of backend functions */
struct sl_thd_policy *
sl_thd_alloc_backend(thdid_t tid)
{
   1dcb3:	55                   	push   %ebp
   1dcb4:	89 e5                	mov    %esp,%ebp
   1dcb6:	83 ec 18             	sub    $0x18,%esp
   1dcb9:	8b 45 08             	mov    0x8(%ebp),%eax
   1dcbc:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	assert(tid < SL_MAX_NUM_THDS);
   1dcc0:	66 83 7d f4 3f       	cmpw   $0x3f,-0xc(%ebp)
   1dcc5:	0f 97 c0             	seta   %al
   1dcc8:	0f b6 c0             	movzbl %al,%eax
   1dccb:	85 c0                	test   %eax,%eax
   1dccd:	74 1c                	je     1dceb <sl_thd_alloc_backend+0x38>
   1dccf:	c7 04 24 4c 36 00 00 	movl   $0x364c,(%esp)
   1dcd6:	e8 19 d2 ff ff       	call   1aef4 <prints>
   1dcdb:	a1 c0 02 00 00       	mov    0x2c0,%eax
   1dce0:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1dce6:	e8 90 d2 ff ff       	call   1af7b <__cos_noret>

	return &(__sl_threads[cos_cpuid()][tid]);
   1dceb:	e8 89 d0 ff ff       	call   1ad79 <cos_cpuid>
   1dcf0:	89 c1                	mov    %eax,%ecx
   1dcf2:	0f b7 45 f4          	movzwl -0xc(%ebp),%eax
   1dcf6:	89 c2                	mov    %eax,%edx
   1dcf8:	01 d2                	add    %edx,%edx
   1dcfa:	01 c2                	add    %eax,%edx
   1dcfc:	89 d0                	mov    %edx,%eax
   1dcfe:	c1 e0 06             	shl    $0x6,%eax
   1dd01:	89 c2                	mov    %eax,%edx
   1dd03:	89 c8                	mov    %ecx,%eax
   1dd05:	01 c0                	add    %eax,%eax
   1dd07:	01 c8                	add    %ecx,%eax
   1dd09:	c1 e0 0c             	shl    $0xc,%eax
   1dd0c:	01 d0                	add    %edx,%eax
   1dd0e:	05 00 03 00 00       	add    $0x300,%eax
}
   1dd13:	c9                   	leave  
   1dd14:	c3                   	ret    

0001dd15 <sl_thd_alloc_aep_backend>:

struct cos_aep_info *
sl_thd_alloc_aep_backend(void)
{
   1dd15:	55                   	push   %ebp
   1dd16:	89 e5                	mov    %esp,%ebp
   1dd18:	53                   	push   %ebx
   1dd19:	83 ec 24             	sub    $0x24,%esp
	struct cos_aep_info *aep = NULL;
   1dd1c:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)

	assert(__sl_aep_free_off[cos_cpuid()] < SL_MAX_NUM_THDS);
   1dd23:	e8 51 d0 ff ff       	call   1ad79 <cos_cpuid>
   1dd28:	8b 04 85 00 39 00 00 	mov    0x3900(,%eax,4),%eax
   1dd2f:	83 f8 3f             	cmp    $0x3f,%eax
   1dd32:	0f 97 c0             	seta   %al
   1dd35:	0f b6 c0             	movzbl %al,%eax
   1dd38:	85 c0                	test   %eax,%eax
   1dd3a:	74 1c                	je     1dd58 <sl_thd_alloc_aep_backend+0x43>
   1dd3c:	c7 04 24 84 36 00 00 	movl   $0x3684,(%esp)
   1dd43:	e8 ac d1 ff ff       	call   1aef4 <prints>
   1dd48:	a1 c0 02 00 00       	mov    0x2c0,%eax
   1dd4d:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1dd53:	e8 23 d2 ff ff       	call   1af7b <__cos_noret>
	aep = &(__sl_aep_infos[cos_cpuid()][__sl_aep_free_off[cos_cpuid()]]);
   1dd58:	e8 1c d0 ff ff       	call   1ad79 <cos_cpuid>
   1dd5d:	89 c3                	mov    %eax,%ebx
   1dd5f:	e8 15 d0 ff ff       	call   1ad79 <cos_cpuid>
   1dd64:	8b 04 85 00 39 00 00 	mov    0x3900(,%eax,4),%eax
   1dd6b:	89 c2                	mov    %eax,%edx
   1dd6d:	01 d2                	add    %edx,%edx
   1dd6f:	01 c2                	add    %eax,%edx
   1dd71:	8d 04 d5 00 00 00 00 	lea    0x0(,%edx,8),%eax
   1dd78:	89 c2                	mov    %eax,%edx
   1dd7a:	89 d8                	mov    %ebx,%eax
   1dd7c:	01 c0                	add    %eax,%eax
   1dd7e:	01 d8                	add    %ebx,%eax
   1dd80:	c1 e0 09             	shl    $0x9,%eax
   1dd83:	01 d0                	add    %edx,%eax
   1dd85:	05 00 33 00 00       	add    $0x3300,%eax
   1dd8a:	89 45 f4             	mov    %eax,-0xc(%ebp)
	ps_faa((unsigned long *)&(__sl_aep_free_off[cos_cpuid()]), 1);
   1dd8d:	e8 e7 cf ff ff       	call   1ad79 <cos_cpuid>
   1dd92:	c1 e0 02             	shl    $0x2,%eax
   1dd95:	05 00 39 00 00       	add    $0x3900,%eax
   1dd9a:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
   1dda1:	00 
   1dda2:	89 04 24             	mov    %eax,(%esp)
   1dda5:	e8 d6 d1 ff ff       	call   1af80 <ps_faa>

	return aep;
   1ddaa:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1ddad:	83 c4 24             	add    $0x24,%esp
   1ddb0:	5b                   	pop    %ebx
   1ddb1:	5d                   	pop    %ebp
   1ddb2:	c3                   	ret    

0001ddb3 <sl_thd_free_backend>:

void
sl_thd_free_backend(struct sl_thd_policy *t)
{ }
   1ddb3:	55                   	push   %ebp
   1ddb4:	89 e5                	mov    %esp,%ebp
   1ddb6:	5d                   	pop    %ebp
   1ddb7:	c3                   	ret    

0001ddb8 <sl_thd_index_add_backend>:

void
sl_thd_index_add_backend(struct sl_thd_policy *t)
{ }
   1ddb8:	55                   	push   %ebp
   1ddb9:	89 e5                	mov    %esp,%ebp
   1ddbb:	5d                   	pop    %ebp
   1ddbc:	c3                   	ret    

0001ddbd <sl_thd_index_rem_backend>:

void
sl_thd_index_rem_backend(struct sl_thd_policy *t)
{ }
   1ddbd:	55                   	push   %ebp
   1ddbe:	89 e5                	mov    %esp,%ebp
   1ddc0:	5d                   	pop    %ebp
   1ddc1:	c3                   	ret    

0001ddc2 <sl_thd_lookup_backend>:

struct sl_thd_policy *
sl_thd_lookup_backend(thdid_t tid)
{
   1ddc2:	55                   	push   %ebp
   1ddc3:	89 e5                	mov    %esp,%ebp
   1ddc5:	83 ec 18             	sub    $0x18,%esp
   1ddc8:	8b 45 08             	mov    0x8(%ebp),%eax
   1ddcb:	66 89 45 f4          	mov    %ax,-0xc(%ebp)
	assert(tid < SL_MAX_NUM_THDS);
   1ddcf:	66 83 7d f4 3f       	cmpw   $0x3f,-0xc(%ebp)
   1ddd4:	0f 97 c0             	seta   %al
   1ddd7:	0f b6 c0             	movzbl %al,%eax
   1ddda:	85 c0                	test   %eax,%eax
   1dddc:	74 1c                	je     1ddfa <sl_thd_lookup_backend+0x38>
   1ddde:	c7 04 24 bc 36 00 00 	movl   $0x36bc,(%esp)
   1dde5:	e8 0a d1 ff ff       	call   1aef4 <prints>
   1ddea:	a1 c0 02 00 00       	mov    0x2c0,%eax
   1ddef:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1ddf5:	e8 81 d1 ff ff       	call   1af7b <__cos_noret>

	return &(__sl_threads[cos_cpuid()][tid]);
   1ddfa:	e8 7a cf ff ff       	call   1ad79 <cos_cpuid>
   1ddff:	89 c1                	mov    %eax,%ecx
   1de01:	0f b7 45 f4          	movzwl -0xc(%ebp),%eax
   1de05:	89 c2                	mov    %eax,%edx
   1de07:	01 d2                	add    %edx,%edx
   1de09:	01 c2                	add    %eax,%edx
   1de0b:	89 d0                	mov    %edx,%eax
   1de0d:	c1 e0 06             	shl    $0x6,%eax
   1de10:	89 c2                	mov    %eax,%edx
   1de12:	89 c8                	mov    %ecx,%eax
   1de14:	01 c0                	add    %eax,%eax
   1de16:	01 c8                	add    %ecx,%eax
   1de18:	c1 e0 0c             	shl    $0xc,%eax
   1de1b:	01 d0                	add    %edx,%eax
   1de1d:	05 00 03 00 00       	add    $0x300,%eax
}
   1de22:	c9                   	leave  
   1de23:	c3                   	ret    

0001de24 <sl_thd_init_backend>:

void
sl_thd_init_backend(void)
{
   1de24:	55                   	push   %ebp
   1de25:	89 e5                	mov    %esp,%ebp
   1de27:	83 ec 18             	sub    $0x18,%esp
	assert(SL_MAX_NUM_THDS <= MAX_NUM_THREADS);

	memset(__sl_threads[cos_cpuid()], 0, sizeof(struct sl_thd_policy)*SL_MAX_NUM_THDS);
   1de2a:	e8 4a cf ff ff       	call   1ad79 <cos_cpuid>
   1de2f:	89 c2                	mov    %eax,%edx
   1de31:	89 d0                	mov    %edx,%eax
   1de33:	01 c0                	add    %eax,%eax
   1de35:	01 d0                	add    %edx,%eax
   1de37:	c1 e0 0c             	shl    $0xc,%eax
   1de3a:	05 00 03 00 00       	add    $0x300,%eax
   1de3f:	c7 44 24 08 00 30 00 	movl   $0x3000,0x8(%esp)
   1de46:	00 
   1de47:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1de4e:	00 
   1de4f:	89 04 24             	mov    %eax,(%esp)
   1de52:	e8 fc ff ff ff       	call   1de53 <sl_thd_init_backend+0x2f>
	memset(__sl_aep_infos[cos_cpuid()], 0, sizeof(struct cos_aep_info)*SL_MAX_NUM_THDS);
   1de57:	e8 1d cf ff ff       	call   1ad79 <cos_cpuid>
   1de5c:	89 c2                	mov    %eax,%edx
   1de5e:	89 d0                	mov    %edx,%eax
   1de60:	01 c0                	add    %eax,%eax
   1de62:	01 d0                	add    %edx,%eax
   1de64:	c1 e0 09             	shl    $0x9,%eax
   1de67:	05 00 33 00 00       	add    $0x3300,%eax
   1de6c:	c7 44 24 08 00 06 00 	movl   $0x600,0x8(%esp)
   1de73:	00 
   1de74:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1de7b:	00 
   1de7c:	89 04 24             	mov    %eax,(%esp)
   1de7f:	e8 fc ff ff ff       	call   1de80 <sl_thd_init_backend+0x5c>
	__sl_aep_free_off[cos_cpuid()] = 0;
   1de84:	e8 f0 ce ff ff       	call   1ad79 <cos_cpuid>
   1de89:	c7 04 85 00 39 00 00 	movl   $0x0,0x3900(,%eax,4)
   1de90:	00 00 00 00 
}
   1de94:	c9                   	leave  
   1de95:	c3                   	ret    
   1de96:	66 90                	xchg   %ax,%ax

0001de98 <call_cap_asm>:
void libc_init();

/* temporary */
static inline int
call_cap_asm(u32_t cap_no, u32_t op, int arg1, int arg2, int arg3, int arg4)
{
   1de98:	55                   	push   %ebp
   1de99:	89 e5                	mov    %esp,%ebp
   1de9b:	57                   	push   %edi
   1de9c:	56                   	push   %esi
   1de9d:	53                   	push   %ebx
   1de9e:	83 ec 10             	sub    $0x10,%esp
	long fault = 0;
   1dea1:	c7 45 f0 00 00 00 00 	movl   $0x0,-0x10(%ebp)
	int  ret;

	cap_no = (cap_no + 1) << COS_CAPABILITY_OFFSET;
   1dea8:	8b 45 08             	mov    0x8(%ebp),%eax
   1deab:	83 c0 01             	add    $0x1,%eax
   1deae:	c1 e0 10             	shl    $0x10,%eax
   1deb1:	89 45 08             	mov    %eax,0x8(%ebp)
	cap_no += op;
   1deb4:	8b 45 0c             	mov    0xc(%ebp),%eax
   1deb7:	01 45 08             	add    %eax,0x8(%ebp)

	__asm__ __volatile__("pushl %%ebp\n\t"		\
   1deba:	8b 45 08             	mov    0x8(%ebp),%eax
   1debd:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1dec0:	8b 75 14             	mov    0x14(%ebp),%esi
   1dec3:	8b 7d 18             	mov    0x18(%ebp),%edi
   1dec6:	8b 55 1c             	mov    0x1c(%ebp),%edx
   1dec9:	89 cb                	mov    %ecx,%ebx
   1decb:	55                   	push   %ebp
   1decc:	89 e5                	mov    %esp,%ebp
   1dece:	b9 e0 de 01 00       	mov    $0x1dee0,%ecx
   1ded3:	0f 34                	sysenter 
   1ded5:	8d 76 00             	lea    0x0(%esi),%esi
   1ded8:	eb 0d                	jmp    1dee7 <call_cap_asm+0x4f>
   1deda:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   1dee0:	b9 00 00 00 00       	mov    $0x0,%ecx
   1dee5:	eb 05                	jmp    1deec <call_cap_asm+0x54>
   1dee7:	b9 01 00 00 00       	mov    $0x1,%ecx
   1deec:	5d                   	pop    %ebp
   1deed:	89 ca                	mov    %ecx,%edx
   1deef:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1def2:	89 55 f0             	mov    %edx,-0x10(%ebp)
	                     "popl %%ebp"		\
	                     : "=a"(ret), "=c"(fault)
	                     : "a"(cap_no), "b"(arg1), "S"(arg2), "D"(arg3), "d"(arg4)
	                     : "memory", "cc");

	return ret;
   1def5:	8b 45 ec             	mov    -0x14(%ebp),%eax
}
   1def8:	83 c4 10             	add    $0x10,%esp
   1defb:	5b                   	pop    %ebx
   1defc:	5e                   	pop    %esi
   1defd:	5f                   	pop    %edi
   1defe:	5d                   	pop    %ebp
   1deff:	c3                   	ret    

0001df00 <call_cap>:
	return call_cap_asm(cap_no, 0, 0, 0, 0, 0);
}

static inline int
call_cap(u32_t cap_no, int arg1, int arg2, int arg3, int arg4)
{
   1df00:	55                   	push   %ebp
   1df01:	89 e5                	mov    %esp,%ebp
   1df03:	83 ec 18             	sub    $0x18,%esp
	return call_cap_asm(cap_no, 0, arg1, arg2, arg3, arg4);
   1df06:	8b 45 18             	mov    0x18(%ebp),%eax
   1df09:	89 44 24 14          	mov    %eax,0x14(%esp)
   1df0d:	8b 45 14             	mov    0x14(%ebp),%eax
   1df10:	89 44 24 10          	mov    %eax,0x10(%esp)
   1df14:	8b 45 10             	mov    0x10(%ebp),%eax
   1df17:	89 44 24 0c          	mov    %eax,0xc(%esp)
   1df1b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1df1e:	89 44 24 08          	mov    %eax,0x8(%esp)
   1df22:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   1df29:	00 
   1df2a:	8b 45 08             	mov    0x8(%ebp),%eax
   1df2d:	89 04 24             	mov    %eax,(%esp)
   1df30:	e8 63 ff ff ff       	call   1de98 <call_cap_asm>
}
   1df35:	c9                   	leave  
   1df36:	c3                   	ret    

0001df37 <cos_print>:
	return call_cap_asm(cap_no, op_code, arg1, arg2, arg3, arg4);
}

static void
cos_print(char *s, int len)
{
   1df37:	55                   	push   %ebp
   1df38:	89 e5                	mov    %esp,%ebp
   1df3a:	83 ec 14             	sub    $0x14,%esp
	// FIXME: casting from a pointer to an int can be lossy
	call_cap(PRINT_CAP_TEMP, (int) s, len, 0, 0);
   1df3d:	8b 45 08             	mov    0x8(%ebp),%eax
   1df40:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   1df47:	00 
   1df48:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   1df4f:	00 
   1df50:	8b 55 0c             	mov    0xc(%ebp),%edx
   1df53:	89 54 24 08          	mov    %edx,0x8(%esp)
   1df57:	89 44 24 04          	mov    %eax,0x4(%esp)
   1df5b:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
   1df62:	e8 99 ff ff ff       	call   1df00 <call_cap>
}
   1df67:	c9                   	leave  
   1df68:	c3                   	ret    

0001df69 <get_stk_data>:

extern struct cos_component_information cos_comp_info;

static inline long
get_stk_data(int offset)
{
   1df69:	55                   	push   %ebp
   1df6a:	89 e5                	mov    %esp,%ebp
   1df6c:	83 ec 10             	sub    $0x10,%esp
	unsigned long curr_stk_pointer;

	__asm__("movl %%esp, %0;" : "=r"(curr_stk_pointer));
   1df6f:	89 e0                	mov    %esp,%eax
   1df71:	89 45 fc             	mov    %eax,-0x4(%ebp)
	 * access.  We want to find the struct cos_stk (see the stkmgr
	 * interface) so that we can then offset into it and get the
	 * cpu_id.  This struct is at the _top_ of the current stack,
	 * and cpu_id is at the top of the struct (it is a u32_t).
	 */
	return *(long *)((curr_stk_pointer & ~(COS_STACK_SZ - 1)) + COS_STACK_SZ - offset * sizeof(u32_t));
   1df74:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1df77:	25 00 f0 ff ff       	and    $0xfffff000,%eax
   1df7c:	89 c2                	mov    %eax,%edx
   1df7e:	8b 45 08             	mov    0x8(%ebp),%eax
   1df81:	c1 e0 02             	shl    $0x2,%eax
   1df84:	29 c2                	sub    %eax,%edx
   1df86:	89 d0                	mov    %edx,%eax
   1df88:	05 00 10 00 00       	add    $0x1000,%eax
   1df8d:	8b 00                	mov    (%eax),%eax
}
   1df8f:	c9                   	leave  
   1df90:	c3                   	ret    

0001df91 <cos_cpuid>:

#define GET_CURR_CPU cos_cpuid()

static inline long
cos_cpuid(void)
{
   1df91:	55                   	push   %ebp
   1df92:	89 e5                	mov    %esp,%ebp
#if NUM_CPU == 1
	return 0;
   1df94:	b8 00 00 00 00       	mov    $0x0,%eax
#endif
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(CPUID_OFFSET);
}
   1df99:	5d                   	pop    %ebp
   1df9a:	c3                   	ret    

0001df9b <cos_get_thd_id>:

static inline unsigned short int
cos_get_thd_id(void)
{
   1df9b:	55                   	push   %ebp
   1df9c:	89 e5                	mov    %esp,%ebp
   1df9e:	83 ec 04             	sub    $0x4,%esp
	/*
	 * see comments in the get_stk_data above.
	 */
	return get_stk_data(THDID_OFFSET);
   1dfa1:	c7 04 24 02 00 00 00 	movl   $0x2,(%esp)
   1dfa8:	e8 bc ff ff ff       	call   1df69 <get_stk_data>
}
   1dfad:	c9                   	leave  
   1dfae:	c3                   	ret    

0001dfaf <cos_thdid>:

typedef u16_t cos_thdid_t;

static cos_thdid_t
cos_thdid(void)
{
   1dfaf:	55                   	push   %ebp
   1dfb0:	89 e5                	mov    %esp,%ebp
	return cos_get_thd_id();
   1dfb2:	e8 e4 ff ff ff       	call   1df9b <cos_get_thd_id>
}
   1dfb7:	5d                   	pop    %ebp
   1dfb8:	c3                   	ret    

0001dfb9 <section_fnptrs_execute>:
#define CDTOR __attribute__((destructor)) /* currently unused! */
#define CRECOV(fnname) long crecov_##fnname##_ptr __attribute__((section(".crecov"))) = (long)fnname

static inline void
section_fnptrs_execute(long *list)
{
   1dfb9:	55                   	push   %ebp
   1dfba:	89 e5                	mov    %esp,%ebp
   1dfbc:	83 ec 18             	sub    $0x18,%esp
	int i;

	for (i = 0; i < list[0]; i++) {
   1dfbf:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
   1dfc6:	eb 20                	jmp    1dfe8 <section_fnptrs_execute+0x2f>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
   1dfc8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1dfcb:	83 c0 01             	add    $0x1,%eax
   1dfce:	8d 14 85 00 00 00 00 	lea    0x0(,%eax,4),%edx
   1dfd5:	8b 45 08             	mov    0x8(%ebp),%eax
   1dfd8:	01 d0                	add    %edx,%eax
   1dfda:	8b 00                	mov    (%eax),%eax
   1dfdc:	89 45 f0             	mov    %eax,-0x10(%ebp)
		ctors();
   1dfdf:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1dfe2:	ff d0                	call   *%eax
static inline void
section_fnptrs_execute(long *list)
{
	int i;

	for (i = 0; i < list[0]; i++) {
   1dfe4:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   1dfe8:	8b 45 08             	mov    0x8(%ebp),%eax
   1dfeb:	8b 00                	mov    (%eax),%eax
   1dfed:	3b 45 f4             	cmp    -0xc(%ebp),%eax
   1dff0:	7f d6                	jg     1dfc8 <section_fnptrs_execute+0xf>
		typedef void (*ctors_t)(void);
		ctors_t ctors = (ctors_t)list[i + 1];
		ctors();
	}
}
   1dff2:	c9                   	leave  
   1dff3:	c3                   	ret    

0001dff4 <constructors_execute>:

static void
constructors_execute(void)
{
   1dff4:	55                   	push   %ebp
   1dff5:	89 e5                	mov    %esp,%ebp
   1dff7:	83 ec 18             	sub    $0x18,%esp
	extern long __CTOR_LIST__;
	extern long __INIT_ARRAY_LIST__;
	section_fnptrs_execute(&__CTOR_LIST__);
   1dffa:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1e001:	e8 b3 ff ff ff       	call   1dfb9 <section_fnptrs_execute>
	section_fnptrs_execute(&__INIT_ARRAY_LIST__);
   1e006:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1e00d:	e8 a7 ff ff ff       	call   1dfb9 <section_fnptrs_execute>
}
   1e012:	c9                   	leave  
   1e013:	c3                   	ret    

0001e014 <destructors_execute>:
static void
destructors_execute(void)
{
   1e014:	55                   	push   %ebp
   1e015:	89 e5                	mov    %esp,%ebp
   1e017:	83 ec 18             	sub    $0x18,%esp
	extern long __DTOR_LIST__;
	extern long __FINI_ARRAY_LIST__;
	section_fnptrs_execute(&__DTOR_LIST__);
   1e01a:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1e021:	e8 93 ff ff ff       	call   1dfb9 <section_fnptrs_execute>
	section_fnptrs_execute(&__FINI_ARRAY_LIST__);
   1e026:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1e02d:	e8 87 ff ff ff       	call   1dfb9 <section_fnptrs_execute>
}
   1e032:	c9                   	leave  
   1e033:	c3                   	ret    

0001e034 <recoveryfns_execute>:
static void
recoveryfns_execute(void)
{
   1e034:	55                   	push   %ebp
   1e035:	89 e5                	mov    %esp,%ebp
   1e037:	83 ec 18             	sub    $0x18,%esp
	extern long __CRECOV_LIST__;
	section_fnptrs_execute(&__CRECOV_LIST__);
   1e03a:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   1e041:	e8 73 ff ff ff       	call   1dfb9 <section_fnptrs_execute>
}
   1e046:	c9                   	leave  
   1e047:	c3                   	ret    

0001e048 <outb>:
/**
 * Write byte to specific port
 */
static inline void
outb(u16_t port, u8_t value)
{
   1e048:	55                   	push   %ebp
   1e049:	89 e5                	mov    %esp,%ebp
   1e04b:	83 ec 08             	sub    $0x8,%esp
   1e04e:	8b 55 08             	mov    0x8(%ebp),%edx
   1e051:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e054:	66 89 55 fc          	mov    %dx,-0x4(%ebp)
   1e058:	88 45 f8             	mov    %al,-0x8(%ebp)
	__asm__ __volatile__("outb %1, %0" : : "dN"(port), "a"(value));
   1e05b:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1e05f:	0f b6 45 f8          	movzbl -0x8(%ebp),%eax
   1e063:	ee                   	out    %al,(%dx)
}
   1e064:	c9                   	leave  
   1e065:	c3                   	ret    

0001e066 <inb>:
/**
 * Read byte from port
 */
static inline u8_t
inb(u16_t port)
{
   1e066:	55                   	push   %ebp
   1e067:	89 e5                	mov    %esp,%ebp
   1e069:	83 ec 14             	sub    $0x14,%esp
   1e06c:	8b 45 08             	mov    0x8(%ebp),%eax
   1e06f:	66 89 45 ec          	mov    %ax,-0x14(%ebp)
	u8_t ret;

	__asm__ __volatile__("inb %1, %0" : "=a"(ret) : "dN"(port));
   1e073:	0f b7 45 ec          	movzwl -0x14(%ebp),%eax
   1e077:	89 c2                	mov    %eax,%edx
   1e079:	ec                   	in     (%dx),%al
   1e07a:	88 45 ff             	mov    %al,-0x1(%ebp)

	return ret;
   1e07d:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
}
   1e081:	c9                   	leave  
   1e082:	c3                   	ret    

0001e083 <cos_serial_putc>:
	COS_SERIAL_PORT_D = 0x2E8
};

static inline void
cos_serial_putc(char out)
{
   1e083:	55                   	push   %ebp
   1e084:	89 e5                	mov    %esp,%ebp
   1e086:	83 ec 0c             	sub    $0xc,%esp
   1e089:	8b 45 08             	mov    0x8(%ebp),%eax
   1e08c:	88 45 fc             	mov    %al,-0x4(%ebp)
	while ((inb(COS_SERIAL_PORT_A + 5) & 0x20) == 0) {
   1e08f:	90                   	nop
   1e090:	c7 04 24 fd 03 00 00 	movl   $0x3fd,(%esp)
   1e097:	e8 ca ff ff ff       	call   1e066 <inb>
   1e09c:	0f b6 c0             	movzbl %al,%eax
   1e09f:	83 e0 20             	and    $0x20,%eax
   1e0a2:	85 c0                	test   %eax,%eax
   1e0a4:	74 ea                	je     1e090 <cos_serial_putc+0xd>
		/* wait for port to be ready to send */
	}
	outb(COS_SERIAL_PORT_A, out);
   1e0a6:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e0aa:	0f b6 c0             	movzbl %al,%eax
   1e0ad:	89 44 24 04          	mov    %eax,0x4(%esp)
   1e0b1:	c7 04 24 f8 03 00 00 	movl   $0x3f8,(%esp)
   1e0b8:	e8 8b ff ff ff       	call   1e048 <outb>
}
   1e0bd:	c9                   	leave  
   1e0be:	c3                   	ret    

0001e0bf <cos_serial_putb>:
}

/* for binary printing */
static inline void
cos_serial_putb(const char *s, size_t len)
{
   1e0bf:	55                   	push   %ebp
   1e0c0:	89 e5                	mov    %esp,%ebp
   1e0c2:	83 ec 14             	sub    $0x14,%esp
	size_t i;

	for (i = 0; i < len; i++) cos_serial_putc(*(s + i));
   1e0c5:	c7 45 fc 00 00 00 00 	movl   $0x0,-0x4(%ebp)
   1e0cc:	eb 1a                	jmp    1e0e8 <cos_serial_putb+0x29>
   1e0ce:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1e0d1:	8b 55 08             	mov    0x8(%ebp),%edx
   1e0d4:	01 d0                	add    %edx,%eax
   1e0d6:	0f b6 00             	movzbl (%eax),%eax
   1e0d9:	0f be c0             	movsbl %al,%eax
   1e0dc:	89 04 24             	mov    %eax,(%esp)
   1e0df:	e8 9f ff ff ff       	call   1e083 <cos_serial_putc>
   1e0e4:	83 45 fc 01          	addl   $0x1,-0x4(%ebp)
   1e0e8:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1e0eb:	3b 45 0c             	cmp    0xc(%ebp),%eax
   1e0ee:	72 de                	jb     1e0ce <cos_serial_putb+0xf>
}
   1e0f0:	c9                   	leave  
   1e0f1:	c3                   	ret    

0001e0f2 <cos_llprint>:
#include <cos_component.h>
#include <cos_serial.h>

static void
cos_llprint(char *s, int len)
{
   1e0f2:	55                   	push   %ebp
   1e0f3:	89 e5                	mov    %esp,%ebp
   1e0f5:	83 ec 08             	sub    $0x8,%esp
	cos_serial_putb(s, len);
   1e0f8:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e0fb:	89 44 24 04          	mov    %eax,0x4(%esp)
   1e0ff:	8b 45 08             	mov    0x8(%ebp),%eax
   1e102:	89 04 24             	mov    %eax,(%esp)
   1e105:	e8 b5 ff ff ff       	call   1e0bf <cos_serial_putb>
}
   1e10a:	c9                   	leave  
   1e10b:	c3                   	ret    

0001e10c <prints>:

static int
prints(char *s)
{
   1e10c:	55                   	push   %ebp
   1e10d:	89 e5                	mov    %esp,%ebp
   1e10f:	83 ec 28             	sub    $0x28,%esp
	size_t len = strlen(s);
   1e112:	8b 45 08             	mov    0x8(%ebp),%eax
   1e115:	89 04 24             	mov    %eax,(%esp)
   1e118:	e8 fc ff ff ff       	call   1e119 <prints+0xd>
   1e11d:	89 45 f4             	mov    %eax,-0xc(%ebp)

	cos_print(s, len); /* use syscall to print, so it prints to vga as well */
   1e120:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1e123:	89 44 24 04          	mov    %eax,0x4(%esp)
   1e127:	8b 45 08             	mov    0x8(%ebp),%eax
   1e12a:	89 04 24             	mov    %eax,(%esp)
   1e12d:	e8 05 fe ff ff       	call   1df37 <cos_print>

	return len;
   1e132:	8b 45 f4             	mov    -0xc(%ebp),%eax
}
   1e135:	c9                   	leave  
   1e136:	c3                   	ret    

0001e137 <printc>:

static int  __attribute__((format(printf, 1, 2)))
printc(char *fmt, ...)
{
   1e137:	55                   	push   %ebp
   1e138:	89 e5                	mov    %esp,%ebp
   1e13a:	81 ec a8 00 00 00    	sub    $0xa8,%esp
	char    s[128];
	va_list arg_ptr;
	size_t  ret, len = 128;
   1e140:	c7 45 f4 80 00 00 00 	movl   $0x80,-0xc(%ebp)

	va_start(arg_ptr, fmt);
   1e147:	8d 45 0c             	lea    0xc(%ebp),%eax
   1e14a:	89 85 6c ff ff ff    	mov    %eax,-0x94(%ebp)
	ret = vsnprintf(s, len, fmt, arg_ptr);
   1e150:	8b 85 6c ff ff ff    	mov    -0x94(%ebp),%eax
   1e156:	89 44 24 0c          	mov    %eax,0xc(%esp)
   1e15a:	8b 45 08             	mov    0x8(%ebp),%eax
   1e15d:	89 44 24 08          	mov    %eax,0x8(%esp)
   1e161:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1e164:	89 44 24 04          	mov    %eax,0x4(%esp)
   1e168:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
   1e16e:	89 04 24             	mov    %eax,(%esp)
   1e171:	e8 fc ff ff ff       	call   1e172 <printc+0x3b>
   1e176:	89 45 f0             	mov    %eax,-0x10(%ebp)
	va_end(arg_ptr);
	cos_llprint(s, ret);
   1e179:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1e17c:	89 44 24 04          	mov    %eax,0x4(%esp)
   1e180:	8d 85 70 ff ff ff    	lea    -0x90(%ebp),%eax
   1e186:	89 04 24             	mov    %eax,(%esp)
   1e189:	e8 64 ff ff ff       	call   1e0f2 <cos_llprint>

	return ret;
   1e18e:	8b 45 f0             	mov    -0x10(%ebp),%eax
}
   1e191:	c9                   	leave  
   1e192:	c3                   	ret    

0001e193 <__cos_noret>:
 * Tell the compiler that we will not return, thus it can make the
 * static assertion that the condition is true past the assertion.
 */
__attribute__((noreturn)) static inline void
__cos_noret(void)
{
   1e193:	55                   	push   %ebp
   1e194:	89 e5                	mov    %esp,%ebp
	while (1)
		;
   1e196:	eb fe                	jmp    1e196 <__cos_noret+0x3>

0001e198 <cos_aepthd_fn>:
	struct cos_aep_info sched_aep[NUM_CPU];
};

static void
cos_aepthd_fn(void *data)
{
   1e198:	55                   	push   %ebp
   1e199:	89 e5                	mov    %esp,%ebp
   1e19b:	83 ec 28             	sub    $0x28,%esp
	struct cos_aep_info *aep_info = (struct cos_aep_info *)data;
   1e19e:	8b 45 08             	mov    0x8(%ebp),%eax
   1e1a1:	89 45 f4             	mov    %eax,-0xc(%ebp)
	cos_aepthd_fn_t      aep_fn   = aep_info->fn;
   1e1a4:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1e1a7:	8b 40 10             	mov    0x10(%eax),%eax
   1e1aa:	89 45 f0             	mov    %eax,-0x10(%ebp)
	void *               fn_data  = aep_info->data;
   1e1ad:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1e1b0:	8b 40 14             	mov    0x14(%eax),%eax
   1e1b3:	89 45 ec             	mov    %eax,-0x14(%ebp)

	(aep_fn)(aep_info->rcv, fn_data);
   1e1b6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1e1b9:	8b 40 0c             	mov    0xc(%eax),%eax
   1e1bc:	8b 55 ec             	mov    -0x14(%ebp),%edx
   1e1bf:	89 54 24 04          	mov    %edx,0x4(%esp)
   1e1c3:	89 04 24             	mov    %eax,(%esp)
   1e1c6:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1e1c9:	ff d0                	call   *%eax

	/* TODO: handling destruction */
	assert(0);
   1e1cb:	c7 04 24 f4 36 00 00 	movl   $0x36f4,(%esp)
   1e1d2:	e8 35 ff ff ff       	call   1e10c <prints>
   1e1d7:	a1 04 39 00 00       	mov    0x3904,%eax
   1e1dc:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1e1e2:	e8 ac ff ff ff       	call   1e193 <__cos_noret>

0001e1e7 <ps_list_ll_init>:

#define PS_LIST_DEF_NAME list

static inline void
ps_list_ll_init(struct ps_list *l)
{ l->n = l->p = l; }
   1e1e7:	55                   	push   %ebp
   1e1e8:	89 e5                	mov    %esp,%ebp
   1e1ea:	8b 45 08             	mov    0x8(%ebp),%eax
   1e1ed:	8b 55 08             	mov    0x8(%ebp),%edx
   1e1f0:	89 50 04             	mov    %edx,0x4(%eax)
   1e1f3:	8b 45 08             	mov    0x8(%ebp),%eax
   1e1f6:	8b 50 04             	mov    0x4(%eax),%edx
   1e1f9:	8b 45 08             	mov    0x8(%ebp),%eax
   1e1fc:	89 10                	mov    %edx,(%eax)
   1e1fe:	5d                   	pop    %ebp
   1e1ff:	c3                   	ret    

0001e200 <ps_list_head_init>:

static inline void
ps_list_head_init(struct ps_list_head *lh)
{ ps_list_ll_init(&lh->l); }
   1e200:	55                   	push   %ebp
   1e201:	89 e5                	mov    %esp,%ebp
   1e203:	83 ec 04             	sub    $0x4,%esp
   1e206:	8b 45 08             	mov    0x8(%ebp),%eax
   1e209:	89 04 24             	mov    %eax,(%esp)
   1e20c:	e8 d6 ff ff ff       	call   1e1e7 <ps_list_ll_init>
   1e211:	c9                   	leave  
   1e212:	c3                   	ret    

0001e213 <ps_list_ll_empty>:

static inline int
ps_list_ll_empty(struct ps_list *l)
{ return l->n == l; }
   1e213:	55                   	push   %ebp
   1e214:	89 e5                	mov    %esp,%ebp
   1e216:	8b 45 08             	mov    0x8(%ebp),%eax
   1e219:	8b 00                	mov    (%eax),%eax
   1e21b:	3b 45 08             	cmp    0x8(%ebp),%eax
   1e21e:	0f 94 c0             	sete   %al
   1e221:	0f b6 c0             	movzbl %al,%eax
   1e224:	5d                   	pop    %ebp
   1e225:	c3                   	ret    

0001e226 <ps_list_head_empty>:

static inline int
ps_list_head_empty(struct ps_list_head *lh)
{ return ps_list_ll_empty(&lh->l); }
   1e226:	55                   	push   %ebp
   1e227:	89 e5                	mov    %esp,%ebp
   1e229:	83 ec 04             	sub    $0x4,%esp
   1e22c:	8b 45 08             	mov    0x8(%ebp),%eax
   1e22f:	89 04 24             	mov    %eax,(%esp)
   1e232:	e8 dc ff ff ff       	call   1e213 <ps_list_ll_empty>
   1e237:	c9                   	leave  
   1e238:	c3                   	ret    

0001e239 <ps_list_ll_add>:

static inline void
ps_list_ll_add(struct ps_list *l, struct ps_list *new)
{
   1e239:	55                   	push   %ebp
   1e23a:	89 e5                	mov    %esp,%ebp
	new->n    = l->n;
   1e23c:	8b 45 08             	mov    0x8(%ebp),%eax
   1e23f:	8b 10                	mov    (%eax),%edx
   1e241:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e244:	89 10                	mov    %edx,(%eax)
	new->p    = l;
   1e246:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e249:	8b 55 08             	mov    0x8(%ebp),%edx
   1e24c:	89 50 04             	mov    %edx,0x4(%eax)
	l->n      = new;
   1e24f:	8b 45 08             	mov    0x8(%ebp),%eax
   1e252:	8b 55 0c             	mov    0xc(%ebp),%edx
   1e255:	89 10                	mov    %edx,(%eax)
	new->n->p = new;
   1e257:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e25a:	8b 00                	mov    (%eax),%eax
   1e25c:	8b 55 0c             	mov    0xc(%ebp),%edx
   1e25f:	89 50 04             	mov    %edx,0x4(%eax)
}
   1e262:	5d                   	pop    %ebp
   1e263:	c3                   	ret    

0001e264 <ps_list_ll_rem>:

static inline void
ps_list_ll_rem(struct ps_list *l)
{
   1e264:	55                   	push   %ebp
   1e265:	89 e5                	mov    %esp,%ebp
	l->n->p = l->p;
   1e267:	8b 45 08             	mov    0x8(%ebp),%eax
   1e26a:	8b 00                	mov    (%eax),%eax
   1e26c:	8b 55 08             	mov    0x8(%ebp),%edx
   1e26f:	8b 52 04             	mov    0x4(%edx),%edx
   1e272:	89 50 04             	mov    %edx,0x4(%eax)
	l->p->n = l->n;
   1e275:	8b 45 08             	mov    0x8(%ebp),%eax
   1e278:	8b 40 04             	mov    0x4(%eax),%eax
   1e27b:	8b 55 08             	mov    0x8(%ebp),%edx
   1e27e:	8b 12                	mov    (%edx),%edx
   1e280:	89 10                	mov    %edx,(%eax)
	l->p = l->n = l;
   1e282:	8b 45 08             	mov    0x8(%ebp),%eax
   1e285:	8b 55 08             	mov    0x8(%ebp),%edx
   1e288:	89 10                	mov    %edx,(%eax)
   1e28a:	8b 45 08             	mov    0x8(%ebp),%eax
   1e28d:	8b 10                	mov    (%eax),%edx
   1e28f:	8b 45 08             	mov    0x8(%ebp),%eax
   1e292:	89 50 04             	mov    %edx,0x4(%eax)
}
   1e295:	5d                   	pop    %ebp
   1e296:	c3                   	ret    

0001e297 <__slab_freelist_rem>:
static inline void __ps_slab_freelist_check(struct ps_slab_freelist *fl) { (void)fl; }
#endif /* PS_SLAB_DEBUG */

static void
__slab_freelist_rem(struct ps_slab_freelist *fl, struct ps_slab *s)
{
   1e297:	55                   	push   %ebp
   1e298:	89 e5                	mov    %esp,%ebp
   1e29a:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
   1e29d:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1e2a1:	0f 94 c0             	sete   %al
   1e2a4:	0f b6 c0             	movzbl %al,%eax
   1e2a7:	85 c0                	test   %eax,%eax
   1e2a9:	75 0e                	jne    1e2b9 <__slab_freelist_rem+0x22>
   1e2ab:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1e2af:	0f 94 c0             	sete   %al
   1e2b2:	0f b6 c0             	movzbl %al,%eax
   1e2b5:	85 c0                	test   %eax,%eax
   1e2b7:	74 1c                	je     1e2d5 <__slab_freelist_rem+0x3e>
   1e2b9:	c7 04 24 58 37 00 00 	movl   $0x3758,(%esp)
   1e2c0:	e8 47 fe ff ff       	call   1e10c <prints>
   1e2c5:	a1 04 39 00 00       	mov    0x3904,%eax
   1e2ca:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1e2d0:	e8 be fe ff ff       	call   1e193 <__cos_noret>
	if (fl->list == s) {
   1e2d5:	8b 45 08             	mov    0x8(%ebp),%eax
   1e2d8:	8b 00                	mov    (%eax),%eax
   1e2da:	3b 45 0c             	cmp    0xc(%ebp),%eax
   1e2dd:	75 2b                	jne    1e30a <__slab_freelist_rem+0x73>
		if (ps_list_singleton(s, list)) fl->list = NULL;
   1e2df:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e2e2:	83 c0 44             	add    $0x44,%eax
   1e2e5:	89 04 24             	mov    %eax,(%esp)
   1e2e8:	e8 26 ff ff ff       	call   1e213 <ps_list_ll_empty>
   1e2ed:	85 c0                	test   %eax,%eax
   1e2ef:	74 0b                	je     1e2fc <__slab_freelist_rem+0x65>
   1e2f1:	8b 45 08             	mov    0x8(%ebp),%eax
   1e2f4:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1e2fa:	eb 0e                	jmp    1e30a <__slab_freelist_rem+0x73>
		else                            fl->list = ps_list_next(s, list);
   1e2fc:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e2ff:	8b 40 44             	mov    0x44(%eax),%eax
   1e302:	8d 50 bc             	lea    -0x44(%eax),%edx
   1e305:	8b 45 08             	mov    0x8(%ebp),%eax
   1e308:	89 10                	mov    %edx,(%eax)
	}
	ps_list_rem(s, list);
   1e30a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e30d:	83 c0 44             	add    $0x44,%eax
   1e310:	89 04 24             	mov    %eax,(%esp)
   1e313:	e8 4c ff ff ff       	call   1e264 <ps_list_ll_rem>
}
   1e318:	c9                   	leave  
   1e319:	c3                   	ret    

0001e31a <__slab_freelist_add>:

static void
__slab_freelist_add(struct ps_slab_freelist *fl, struct ps_slab *s)
{
   1e31a:	55                   	push   %ebp
   1e31b:	89 e5                	mov    %esp,%ebp
   1e31d:	83 ec 18             	sub    $0x18,%esp
	assert(s && fl);
   1e320:	83 7d 0c 00          	cmpl   $0x0,0xc(%ebp)
   1e324:	0f 94 c0             	sete   %al
   1e327:	0f b6 c0             	movzbl %al,%eax
   1e32a:	85 c0                	test   %eax,%eax
   1e32c:	75 0e                	jne    1e33c <__slab_freelist_add+0x22>
   1e32e:	83 7d 08 00          	cmpl   $0x0,0x8(%ebp)
   1e332:	0f 94 c0             	sete   %al
   1e335:	0f b6 c0             	movzbl %al,%eax
   1e338:	85 c0                	test   %eax,%eax
   1e33a:	74 1c                	je     1e358 <__slab_freelist_add+0x3e>
   1e33c:	c7 04 24 b0 37 00 00 	movl   $0x37b0,(%esp)
   1e343:	e8 c4 fd ff ff       	call   1e10c <prints>
   1e348:	a1 04 39 00 00       	mov    0x3904,%eax
   1e34d:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1e353:	e8 3b fe ff ff       	call   1e193 <__cos_noret>
	assert(ps_list_singleton(s, list));
   1e358:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e35b:	83 c0 44             	add    $0x44,%eax
   1e35e:	89 04 24             	mov    %eax,(%esp)
   1e361:	e8 ad fe ff ff       	call   1e213 <ps_list_ll_empty>
   1e366:	85 c0                	test   %eax,%eax
   1e368:	0f 94 c0             	sete   %al
   1e36b:	0f b6 c0             	movzbl %al,%eax
   1e36e:	85 c0                	test   %eax,%eax
   1e370:	74 1c                	je     1e38e <__slab_freelist_add+0x74>
   1e372:	c7 04 24 08 38 00 00 	movl   $0x3808,(%esp)
   1e379:	e8 8e fd ff ff       	call   1e10c <prints>
   1e37e:	a1 04 39 00 00       	mov    0x3904,%eax
   1e383:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1e389:	e8 05 fe ff ff       	call   1e193 <__cos_noret>
	assert(s != fl->list);
   1e38e:	8b 45 08             	mov    0x8(%ebp),%eax
   1e391:	8b 00                	mov    (%eax),%eax
   1e393:	3b 45 0c             	cmp    0xc(%ebp),%eax
   1e396:	0f 94 c0             	sete   %al
   1e399:	0f b6 c0             	movzbl %al,%eax
   1e39c:	85 c0                	test   %eax,%eax
   1e39e:	74 1c                	je     1e3bc <__slab_freelist_add+0xa2>
   1e3a0:	c7 04 24 60 38 00 00 	movl   $0x3860,(%esp)
   1e3a7:	e8 60 fd ff ff       	call   1e10c <prints>
   1e3ac:	a1 04 39 00 00       	mov    0x3904,%eax
   1e3b1:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   1e3b7:	e8 d7 fd ff ff       	call   1e193 <__cos_noret>
	if (fl->list) ps_list_add(fl->list, s, list);
   1e3bc:	8b 45 08             	mov    0x8(%ebp),%eax
   1e3bf:	8b 00                	mov    (%eax),%eax
   1e3c1:	85 c0                	test   %eax,%eax
   1e3c3:	74 1a                	je     1e3df <__slab_freelist_add+0xc5>
   1e3c5:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e3c8:	8d 50 44             	lea    0x44(%eax),%edx
   1e3cb:	8b 45 08             	mov    0x8(%ebp),%eax
   1e3ce:	8b 00                	mov    (%eax),%eax
   1e3d0:	83 c0 44             	add    $0x44,%eax
   1e3d3:	89 54 24 04          	mov    %edx,0x4(%esp)
   1e3d7:	89 04 24             	mov    %eax,(%esp)
   1e3da:	e8 5a fe ff ff       	call   1e239 <ps_list_ll_add>
	fl->list = s;
   1e3df:	8b 45 08             	mov    0x8(%ebp),%eax
   1e3e2:	8b 55 0c             	mov    0xc(%ebp),%edx
   1e3e5:	89 10                	mov    %edx,(%eax)
	/* TODO: sort based on emptiness...just use N bins */
}
   1e3e7:	c9                   	leave  
   1e3e8:	c3                   	ret    

0001e3e9 <sl_mod_thd_get>:
	struct ps_list list;
} CACHE_ALIGNED;

static inline struct sl_thd *
sl_mod_thd_get(struct sl_thd_policy *tp)
{
   1e3e9:	55                   	push   %ebp
   1e3ea:	89 e5                	mov    %esp,%ebp
	return &tp->thd;
   1e3ec:	8b 45 08             	mov    0x8(%ebp),%eax
}
   1e3ef:	5d                   	pop    %ebp
   1e3f0:	c3                   	ret    

0001e3f1 <ck_cc_ffs>:
 */
#ifndef CK_MD_CC_BUILTIN_DISABLE
#define CK_F_CC_FFS
CK_CC_INLINE static int
ck_cc_ffs(unsigned int x)
{
   1e3f1:	55                   	push   %ebp
   1e3f2:	89 e5                	mov    %esp,%ebp

	return __builtin_ffsl(x);
   1e3f4:	8b 45 08             	mov    0x8(%ebp),%eax
   1e3f7:	ba ff ff ff ff       	mov    $0xffffffff,%edx
   1e3fc:	0f bc c0             	bsf    %eax,%eax
   1e3ff:	0f 44 c2             	cmove  %edx,%eax
   1e402:	83 c0 01             	add    $0x1,%eax
}
   1e405:	5d                   	pop    %ebp
   1e406:	c3                   	ret    

0001e407 <ck_cc_ffsl>:

#define CK_F_CC_FFSL
CK_CC_INLINE static int
ck_cc_ffsl(unsigned long x)
{
   1e407:	55                   	push   %ebp
   1e408:	89 e5                	mov    %esp,%ebp
   1e40a:	83 ec 18             	sub    $0x18,%esp

	return __builtin_ffsll(x);
   1e40d:	8b 45 08             	mov    0x8(%ebp),%eax
   1e410:	ba 00 00 00 00       	mov    $0x0,%edx
   1e415:	89 04 24             	mov    %eax,(%esp)
   1e418:	89 54 24 04          	mov    %edx,0x4(%esp)
   1e41c:	e8 fc ff ff ff       	call   1e41d <ck_cc_ffsl+0x16>
}
   1e421:	c9                   	leave  
   1e422:	c3                   	ret    

0001e423 <ck_cc_ctz>:

#define CK_F_CC_CTZ
CK_CC_INLINE static int
ck_cc_ctz(unsigned int x)
{
   1e423:	55                   	push   %ebp
   1e424:	89 e5                	mov    %esp,%ebp

	return __builtin_ctz(x);
   1e426:	f3 0f bc 45 08       	tzcnt  0x8(%ebp),%eax
}
   1e42b:	5d                   	pop    %ebp
   1e42c:	c3                   	ret    

0001e42d <ck_cc_popcount>:

#define CK_F_CC_POPCOUNT
CK_CC_INLINE static int
ck_cc_popcount(unsigned int x)
{
   1e42d:	55                   	push   %ebp
   1e42e:	89 e5                	mov    %esp,%ebp
   1e430:	83 ec 18             	sub    $0x18,%esp

	return __builtin_popcount(x);
   1e433:	8b 45 08             	mov    0x8(%ebp),%eax
   1e436:	89 04 24             	mov    %eax,(%esp)
   1e439:	e8 fc ff ff ff       	call   1e43a <ck_cc_popcount+0xd>
}
   1e43e:	c9                   	leave  
   1e43f:	c3                   	ret    

0001e440 <ck_cc_ffsll>:
   1e440:	55                   	push   %ebp
   1e441:	89 e5                	mov    %esp,%ebp
   1e443:	53                   	push   %ebx
   1e444:	83 ec 1c             	sub    $0x1c,%esp
   1e447:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e44a:	89 4d e0             	mov    %ecx,-0x20(%ebp)
   1e44d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e450:	89 4d e4             	mov    %ecx,-0x1c(%ebp)
   1e453:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   1e456:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
   1e459:	09 d9                	or     %ebx,%ecx
   1e45b:	85 c9                	test   %ecx,%ecx
   1e45d:	75 07                	jne    1e466 <ck_cc_ffsll+0x26>
   1e45f:	b8 00 00 00 00       	mov    $0x0,%eax
   1e464:	eb 3a                	jmp    1e4a0 <ck_cc_ffsll+0x60>
   1e466:	c7 45 f4 01 00 00 00 	movl   $0x1,-0xc(%ebp)
   1e46d:	eb 16                	jmp    1e485 <ck_cc_ffsll+0x45>
   1e46f:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   1e473:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   1e476:	8b 5d e4             	mov    -0x1c(%ebp),%ebx
   1e479:	0f ac d9 01          	shrd   $0x1,%ebx,%ecx
   1e47d:	d1 eb                	shr    %ebx
   1e47f:	89 4d e0             	mov    %ecx,-0x20(%ebp)
   1e482:	89 5d e4             	mov    %ebx,-0x1c(%ebp)
   1e485:	8b 4d e0             	mov    -0x20(%ebp),%ecx
   1e488:	83 e1 01             	and    $0x1,%ecx
   1e48b:	89 c8                	mov    %ecx,%eax
   1e48d:	8b 4d e4             	mov    -0x1c(%ebp),%ecx
   1e490:	83 e1 00             	and    $0x0,%ecx
   1e493:	89 ca                	mov    %ecx,%edx
   1e495:	89 d1                	mov    %edx,%ecx
   1e497:	09 c1                	or     %eax,%ecx
   1e499:	85 c9                	test   %ecx,%ecx
   1e49b:	74 d2                	je     1e46f <ck_cc_ffsll+0x2f>
   1e49d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1e4a0:	83 c4 1c             	add    $0x1c,%esp
   1e4a3:	5b                   	pop    %ebx
   1e4a4:	5d                   	pop    %ebp
   1e4a5:	c3                   	ret    

0001e4a6 <ck_pr_stall>:
 * Prevent speculative execution in busy-wait loops (P4 <=) or "predefined
 * delay".
 */
CK_CC_INLINE static void
ck_pr_stall(void)
{
   1e4a6:	55                   	push   %ebp
   1e4a7:	89 e5                	mov    %esp,%ebp
	__asm__ __volatile__("pause" ::: "memory");
   1e4a9:	f3 90                	pause  
	return;
   1e4ab:	90                   	nop
}
   1e4ac:	5d                   	pop    %ebp
   1e4ad:	c3                   	ret    

0001e4ae <ck_pr_fence_strict_atomic>:
#define CK_MD_X86_SFENCE "sfence"
#define CK_MD_X86_LFENCE "lfence"
#define CK_MD_X86_MFENCE "mfence"
#endif /* !CK_MD_SSE_DISABLE */

CK_PR_FENCE(atomic, "")
   1e4ae:	55                   	push   %ebp
   1e4af:	89 e5                	mov    %esp,%ebp
   1e4b1:	90                   	nop
   1e4b2:	5d                   	pop    %ebp
   1e4b3:	c3                   	ret    

0001e4b4 <ck_pr_fence_strict_atomic_store>:
CK_PR_FENCE(atomic_store, "")
   1e4b4:	55                   	push   %ebp
   1e4b5:	89 e5                	mov    %esp,%ebp
   1e4b7:	90                   	nop
   1e4b8:	5d                   	pop    %ebp
   1e4b9:	c3                   	ret    

0001e4ba <ck_pr_fence_strict_atomic_load>:
CK_PR_FENCE(atomic_load, "")
   1e4ba:	55                   	push   %ebp
   1e4bb:	89 e5                	mov    %esp,%ebp
   1e4bd:	90                   	nop
   1e4be:	5d                   	pop    %ebp
   1e4bf:	c3                   	ret    

0001e4c0 <ck_pr_fence_strict_store_atomic>:
CK_PR_FENCE(store_atomic, "")
   1e4c0:	55                   	push   %ebp
   1e4c1:	89 e5                	mov    %esp,%ebp
   1e4c3:	90                   	nop
   1e4c4:	5d                   	pop    %ebp
   1e4c5:	c3                   	ret    

0001e4c6 <ck_pr_fence_strict_load_atomic>:
CK_PR_FENCE(load_atomic, "")
   1e4c6:	55                   	push   %ebp
   1e4c7:	89 e5                	mov    %esp,%ebp
   1e4c9:	90                   	nop
   1e4ca:	5d                   	pop    %ebp
   1e4cb:	c3                   	ret    

0001e4cc <ck_pr_fence_strict_load>:
CK_PR_FENCE(load, CK_MD_X86_LFENCE)
   1e4cc:	55                   	push   %ebp
   1e4cd:	89 e5                	mov    %esp,%ebp
   1e4cf:	0f ae e8             	lfence 
   1e4d2:	90                   	nop
   1e4d3:	5d                   	pop    %ebp
   1e4d4:	c3                   	ret    

0001e4d5 <ck_pr_fence_strict_load_store>:
CK_PR_FENCE(load_store, CK_MD_X86_MFENCE)
   1e4d5:	55                   	push   %ebp
   1e4d6:	89 e5                	mov    %esp,%ebp
   1e4d8:	0f ae f0             	mfence 
   1e4db:	90                   	nop
   1e4dc:	5d                   	pop    %ebp
   1e4dd:	c3                   	ret    

0001e4de <ck_pr_fence_strict_store>:
CK_PR_FENCE(store, CK_MD_X86_SFENCE)
   1e4de:	55                   	push   %ebp
   1e4df:	89 e5                	mov    %esp,%ebp
   1e4e1:	0f ae f8             	sfence 
   1e4e4:	90                   	nop
   1e4e5:	5d                   	pop    %ebp
   1e4e6:	c3                   	ret    

0001e4e7 <ck_pr_fence_strict_store_load>:
CK_PR_FENCE(store_load, CK_MD_X86_MFENCE)
   1e4e7:	55                   	push   %ebp
   1e4e8:	89 e5                	mov    %esp,%ebp
   1e4ea:	0f ae f0             	mfence 
   1e4ed:	90                   	nop
   1e4ee:	5d                   	pop    %ebp
   1e4ef:	c3                   	ret    

0001e4f0 <ck_pr_fence_strict_memory>:
CK_PR_FENCE(memory, CK_MD_X86_MFENCE)
   1e4f0:	55                   	push   %ebp
   1e4f1:	89 e5                	mov    %esp,%ebp
   1e4f3:	0f ae f0             	mfence 
   1e4f6:	90                   	nop
   1e4f7:	5d                   	pop    %ebp
   1e4f8:	c3                   	ret    

0001e4f9 <ck_pr_fence_strict_release>:
CK_PR_FENCE(release, CK_MD_X86_MFENCE)
   1e4f9:	55                   	push   %ebp
   1e4fa:	89 e5                	mov    %esp,%ebp
   1e4fc:	0f ae f0             	mfence 
   1e4ff:	90                   	nop
   1e500:	5d                   	pop    %ebp
   1e501:	c3                   	ret    

0001e502 <ck_pr_fence_strict_acquire>:
CK_PR_FENCE(acquire, CK_MD_X86_MFENCE)
   1e502:	55                   	push   %ebp
   1e503:	89 e5                	mov    %esp,%ebp
   1e505:	0f ae f0             	mfence 
   1e508:	90                   	nop
   1e509:	5d                   	pop    %ebp
   1e50a:	c3                   	ret    

0001e50b <ck_pr_fence_strict_acqrel>:
CK_PR_FENCE(acqrel, CK_MD_X86_MFENCE)
   1e50b:	55                   	push   %ebp
   1e50c:	89 e5                	mov    %esp,%ebp
   1e50e:	0f ae f0             	mfence 
   1e511:	90                   	nop
   1e512:	5d                   	pop    %ebp
   1e513:	c3                   	ret    

0001e514 <ck_pr_fence_strict_lock>:
CK_PR_FENCE(lock, CK_MD_X86_MFENCE)
   1e514:	55                   	push   %ebp
   1e515:	89 e5                	mov    %esp,%ebp
   1e517:	0f ae f0             	mfence 
   1e51a:	90                   	nop
   1e51b:	5d                   	pop    %ebp
   1e51c:	c3                   	ret    

0001e51d <ck_pr_fence_strict_unlock>:
CK_PR_FENCE(unlock, CK_MD_X86_MFENCE)
   1e51d:	55                   	push   %ebp
   1e51e:	89 e5                	mov    %esp,%ebp
   1e520:	0f ae f0             	mfence 
   1e523:	90                   	nop
   1e524:	5d                   	pop    %ebp
   1e525:	c3                   	ret    

0001e526 <ck_pr_fas_ptr>:
					:			\
					: "memory");		\
		return v;					\
	}

CK_PR_FAS(ptr, void, void *, char, "xchgl")
   1e526:	55                   	push   %ebp
   1e527:	89 e5                	mov    %esp,%ebp
   1e529:	8b 55 08             	mov    0x8(%ebp),%edx
   1e52c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e52f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e532:	87 02                	xchg   %eax,(%edx)
   1e534:	89 45 0c             	mov    %eax,0xc(%ebp)
   1e537:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e53a:	5d                   	pop    %ebp
   1e53b:	c3                   	ret    

0001e53c <ck_pr_fas_char>:

#define CK_PR_FAS_S(S, T, I) CK_PR_FAS(S, T, T, T, I)

CK_PR_FAS_S(char, char, "xchgb")
   1e53c:	55                   	push   %ebp
   1e53d:	89 e5                	mov    %esp,%ebp
   1e53f:	83 ec 04             	sub    $0x4,%esp
   1e542:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e545:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e548:	8b 55 08             	mov    0x8(%ebp),%edx
   1e54b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e54e:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e552:	86 02                	xchg   %al,(%edx)
   1e554:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e557:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e55b:	c9                   	leave  
   1e55c:	c3                   	ret    

0001e55d <ck_pr_fas_uint>:
CK_PR_FAS_S(uint, unsigned int, "xchgl")
   1e55d:	55                   	push   %ebp
   1e55e:	89 e5                	mov    %esp,%ebp
   1e560:	8b 55 08             	mov    0x8(%ebp),%edx
   1e563:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e566:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e569:	87 02                	xchg   %eax,(%edx)
   1e56b:	89 45 0c             	mov    %eax,0xc(%ebp)
   1e56e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e571:	5d                   	pop    %ebp
   1e572:	c3                   	ret    

0001e573 <ck_pr_fas_int>:
CK_PR_FAS_S(int, int, "xchgl")
   1e573:	55                   	push   %ebp
   1e574:	89 e5                	mov    %esp,%ebp
   1e576:	8b 55 08             	mov    0x8(%ebp),%edx
   1e579:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e57c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e57f:	87 02                	xchg   %eax,(%edx)
   1e581:	89 45 0c             	mov    %eax,0xc(%ebp)
   1e584:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e587:	5d                   	pop    %ebp
   1e588:	c3                   	ret    

0001e589 <ck_pr_fas_32>:
CK_PR_FAS_S(32, uint32_t, "xchgl")
   1e589:	55                   	push   %ebp
   1e58a:	89 e5                	mov    %esp,%ebp
   1e58c:	8b 55 08             	mov    0x8(%ebp),%edx
   1e58f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e592:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e595:	87 02                	xchg   %eax,(%edx)
   1e597:	89 45 0c             	mov    %eax,0xc(%ebp)
   1e59a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e59d:	5d                   	pop    %ebp
   1e59e:	c3                   	ret    

0001e59f <ck_pr_fas_16>:
CK_PR_FAS_S(16, uint16_t, "xchgw")
   1e59f:	55                   	push   %ebp
   1e5a0:	89 e5                	mov    %esp,%ebp
   1e5a2:	83 ec 04             	sub    $0x4,%esp
   1e5a5:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e5a8:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1e5ac:	8b 55 08             	mov    0x8(%ebp),%edx
   1e5af:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e5b2:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1e5b6:	66 87 02             	xchg   %ax,(%edx)
   1e5b9:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1e5bd:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1e5c1:	c9                   	leave  
   1e5c2:	c3                   	ret    

0001e5c3 <ck_pr_fas_8>:
CK_PR_FAS_S(8,  uint8_t,  "xchgb")
   1e5c3:	55                   	push   %ebp
   1e5c4:	89 e5                	mov    %esp,%ebp
   1e5c6:	83 ec 04             	sub    $0x4,%esp
   1e5c9:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e5cc:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e5cf:	8b 55 08             	mov    0x8(%ebp),%edx
   1e5d2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e5d5:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e5d9:	86 02                	xchg   %al,(%edx)
   1e5db:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e5de:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e5e2:	c9                   	leave  
   1e5e3:	c3                   	ret    

0001e5e4 <ck_pr_md_load_ptr>:
					: "m"  (*(const C *)target)	\
					: "memory");			\
		return (r);						\
	}

CK_PR_LOAD(ptr, void, void *, char, "movl")
   1e5e4:	55                   	push   %ebp
   1e5e5:	89 e5                	mov    %esp,%ebp
   1e5e7:	83 ec 10             	sub    $0x10,%esp
   1e5ea:	8b 45 08             	mov    0x8(%ebp),%eax
   1e5ed:	8b 00                	mov    (%eax),%eax
   1e5ef:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1e5f2:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1e5f5:	c9                   	leave  
   1e5f6:	c3                   	ret    

0001e5f7 <ck_pr_md_load_char>:

#define CK_PR_LOAD_S(S, T, I) CK_PR_LOAD(S, T, T, T, I)

CK_PR_LOAD_S(char, char, "movb")
   1e5f7:	55                   	push   %ebp
   1e5f8:	89 e5                	mov    %esp,%ebp
   1e5fa:	83 ec 10             	sub    $0x10,%esp
   1e5fd:	8b 45 08             	mov    0x8(%ebp),%eax
   1e600:	8a 00                	mov    (%eax),%al
   1e602:	88 45 ff             	mov    %al,-0x1(%ebp)
   1e605:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1e609:	c9                   	leave  
   1e60a:	c3                   	ret    

0001e60b <ck_pr_md_load_uint>:
CK_PR_LOAD_S(uint, unsigned int, "movl")
   1e60b:	55                   	push   %ebp
   1e60c:	89 e5                	mov    %esp,%ebp
   1e60e:	83 ec 10             	sub    $0x10,%esp
   1e611:	8b 45 08             	mov    0x8(%ebp),%eax
   1e614:	8b 00                	mov    (%eax),%eax
   1e616:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1e619:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1e61c:	c9                   	leave  
   1e61d:	c3                   	ret    

0001e61e <ck_pr_md_load_int>:
CK_PR_LOAD_S(int, int, "movl")
   1e61e:	55                   	push   %ebp
   1e61f:	89 e5                	mov    %esp,%ebp
   1e621:	83 ec 10             	sub    $0x10,%esp
   1e624:	8b 45 08             	mov    0x8(%ebp),%eax
   1e627:	8b 00                	mov    (%eax),%eax
   1e629:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1e62c:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1e62f:	c9                   	leave  
   1e630:	c3                   	ret    

0001e631 <ck_pr_md_load_32>:
CK_PR_LOAD_S(32, uint32_t, "movl")
   1e631:	55                   	push   %ebp
   1e632:	89 e5                	mov    %esp,%ebp
   1e634:	83 ec 10             	sub    $0x10,%esp
   1e637:	8b 45 08             	mov    0x8(%ebp),%eax
   1e63a:	8b 00                	mov    (%eax),%eax
   1e63c:	89 45 fc             	mov    %eax,-0x4(%ebp)
   1e63f:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1e642:	c9                   	leave  
   1e643:	c3                   	ret    

0001e644 <ck_pr_md_load_16>:
CK_PR_LOAD_S(16, uint16_t, "movw")
   1e644:	55                   	push   %ebp
   1e645:	89 e5                	mov    %esp,%ebp
   1e647:	83 ec 10             	sub    $0x10,%esp
   1e64a:	8b 45 08             	mov    0x8(%ebp),%eax
   1e64d:	66 8b 00             	mov    (%eax),%ax
   1e650:	66 89 45 fe          	mov    %ax,-0x2(%ebp)
   1e654:	0f b7 45 fe          	movzwl -0x2(%ebp),%eax
   1e658:	c9                   	leave  
   1e659:	c3                   	ret    

0001e65a <ck_pr_md_load_8>:
CK_PR_LOAD_S(8,  uint8_t,  "movb")
   1e65a:	55                   	push   %ebp
   1e65b:	89 e5                	mov    %esp,%ebp
   1e65d:	83 ec 10             	sub    $0x10,%esp
   1e660:	8b 45 08             	mov    0x8(%ebp),%eax
   1e663:	8a 00                	mov    (%eax),%al
   1e665:	88 45 ff             	mov    %al,-0x1(%ebp)
   1e668:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1e66c:	c9                   	leave  
   1e66d:	c3                   	ret    

0001e66e <ck_pr_md_store_ptr>:
					: CK_CC_IMM "q" (v)	\
					: "memory");		\
		return;						\
	}

CK_PR_STORE(ptr, void, const void *, char, "movl")
   1e66e:	55                   	push   %ebp
   1e66f:	89 e5                	mov    %esp,%ebp
   1e671:	8b 45 08             	mov    0x8(%ebp),%eax
   1e674:	8b 55 0c             	mov    0xc(%ebp),%edx
   1e677:	89 10                	mov    %edx,(%eax)
   1e679:	90                   	nop
   1e67a:	5d                   	pop    %ebp
   1e67b:	c3                   	ret    

0001e67c <ck_pr_md_store_char>:

#define CK_PR_STORE_S(S, T, I) CK_PR_STORE(S, T, T, T, I)

CK_PR_STORE_S(char, char, "movb")
   1e67c:	55                   	push   %ebp
   1e67d:	89 e5                	mov    %esp,%ebp
   1e67f:	83 ec 04             	sub    $0x4,%esp
   1e682:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e685:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e688:	8b 45 08             	mov    0x8(%ebp),%eax
   1e68b:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1e68f:	88 10                	mov    %dl,(%eax)
   1e691:	90                   	nop
   1e692:	c9                   	leave  
   1e693:	c3                   	ret    

0001e694 <ck_pr_md_store_uint>:
CK_PR_STORE_S(uint, unsigned int, "movl")
   1e694:	55                   	push   %ebp
   1e695:	89 e5                	mov    %esp,%ebp
   1e697:	8b 45 08             	mov    0x8(%ebp),%eax
   1e69a:	8b 55 0c             	mov    0xc(%ebp),%edx
   1e69d:	89 10                	mov    %edx,(%eax)
   1e69f:	90                   	nop
   1e6a0:	5d                   	pop    %ebp
   1e6a1:	c3                   	ret    

0001e6a2 <ck_pr_md_store_int>:
CK_PR_STORE_S(int, int, "movl")
   1e6a2:	55                   	push   %ebp
   1e6a3:	89 e5                	mov    %esp,%ebp
   1e6a5:	8b 45 08             	mov    0x8(%ebp),%eax
   1e6a8:	8b 55 0c             	mov    0xc(%ebp),%edx
   1e6ab:	89 10                	mov    %edx,(%eax)
   1e6ad:	90                   	nop
   1e6ae:	5d                   	pop    %ebp
   1e6af:	c3                   	ret    

0001e6b0 <ck_pr_md_store_32>:
CK_PR_STORE_S(32, uint32_t, "movl")
   1e6b0:	55                   	push   %ebp
   1e6b1:	89 e5                	mov    %esp,%ebp
   1e6b3:	8b 45 08             	mov    0x8(%ebp),%eax
   1e6b6:	8b 55 0c             	mov    0xc(%ebp),%edx
   1e6b9:	89 10                	mov    %edx,(%eax)
   1e6bb:	90                   	nop
   1e6bc:	5d                   	pop    %ebp
   1e6bd:	c3                   	ret    

0001e6be <ck_pr_md_store_16>:
CK_PR_STORE_S(16, uint16_t, "movw")
   1e6be:	55                   	push   %ebp
   1e6bf:	89 e5                	mov    %esp,%ebp
   1e6c1:	83 ec 04             	sub    $0x4,%esp
   1e6c4:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e6c7:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1e6cb:	8b 45 08             	mov    0x8(%ebp),%eax
   1e6ce:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1e6d2:	66 89 10             	mov    %dx,(%eax)
   1e6d5:	90                   	nop
   1e6d6:	c9                   	leave  
   1e6d7:	c3                   	ret    

0001e6d8 <ck_pr_md_store_8>:
CK_PR_STORE_S(8,  uint8_t, "movb")
   1e6d8:	55                   	push   %ebp
   1e6d9:	89 e5                	mov    %esp,%ebp
   1e6db:	83 ec 04             	sub    $0x4,%esp
   1e6de:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e6e1:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e6e4:	8b 45 08             	mov    0x8(%ebp),%eax
   1e6e7:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1e6eb:	88 10                	mov    %dl,(%eax)
   1e6ed:	90                   	nop
   1e6ee:	c9                   	leave  
   1e6ef:	c3                   	ret    

0001e6f0 <ck_pr_faa_ptr>:
					:				\
					: "memory", "cc");		\
		return (d);						\
	}

CK_PR_FAA(ptr, void, uintptr_t, char, "xaddl")
   1e6f0:	55                   	push   %ebp
   1e6f1:	89 e5                	mov    %esp,%ebp
   1e6f3:	8b 55 08             	mov    0x8(%ebp),%edx
   1e6f6:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e6f9:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e6fc:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1e700:	89 45 0c             	mov    %eax,0xc(%ebp)
   1e703:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e706:	5d                   	pop    %ebp
   1e707:	c3                   	ret    

0001e708 <ck_pr_faa_char>:

#define CK_PR_FAA_S(S, T, I) CK_PR_FAA(S, T, T, T, I)

CK_PR_FAA_S(char, char, "xaddb")
   1e708:	55                   	push   %ebp
   1e709:	89 e5                	mov    %esp,%ebp
   1e70b:	83 ec 04             	sub    $0x4,%esp
   1e70e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e711:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e714:	8b 55 08             	mov    0x8(%ebp),%edx
   1e717:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e71a:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e71e:	f0 0f c0 02          	lock xadd %al,(%edx)
   1e722:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e725:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e729:	c9                   	leave  
   1e72a:	c3                   	ret    

0001e72b <ck_pr_faa_uint>:
CK_PR_FAA_S(uint, unsigned int, "xaddl")
   1e72b:	55                   	push   %ebp
   1e72c:	89 e5                	mov    %esp,%ebp
   1e72e:	8b 55 08             	mov    0x8(%ebp),%edx
   1e731:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e734:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e737:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1e73b:	89 45 0c             	mov    %eax,0xc(%ebp)
   1e73e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e741:	5d                   	pop    %ebp
   1e742:	c3                   	ret    

0001e743 <ck_pr_faa_int>:
CK_PR_FAA_S(int, int, "xaddl")
   1e743:	55                   	push   %ebp
   1e744:	89 e5                	mov    %esp,%ebp
   1e746:	8b 55 08             	mov    0x8(%ebp),%edx
   1e749:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e74c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e74f:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1e753:	89 45 0c             	mov    %eax,0xc(%ebp)
   1e756:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e759:	5d                   	pop    %ebp
   1e75a:	c3                   	ret    

0001e75b <ck_pr_faa_32>:
CK_PR_FAA_S(32, uint32_t, "xaddl")
   1e75b:	55                   	push   %ebp
   1e75c:	89 e5                	mov    %esp,%ebp
   1e75e:	8b 55 08             	mov    0x8(%ebp),%edx
   1e761:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e764:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e767:	f0 0f c1 02          	lock xadd %eax,(%edx)
   1e76b:	89 45 0c             	mov    %eax,0xc(%ebp)
   1e76e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e771:	5d                   	pop    %ebp
   1e772:	c3                   	ret    

0001e773 <ck_pr_faa_16>:
CK_PR_FAA_S(16, uint16_t, "xaddw")
   1e773:	55                   	push   %ebp
   1e774:	89 e5                	mov    %esp,%ebp
   1e776:	83 ec 04             	sub    $0x4,%esp
   1e779:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e77c:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1e780:	8b 55 08             	mov    0x8(%ebp),%edx
   1e783:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e786:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1e78a:	66 f0 0f c1 02       	lock xadd %ax,(%edx)
   1e78f:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1e793:	0f b7 45 fc          	movzwl -0x4(%ebp),%eax
   1e797:	c9                   	leave  
   1e798:	c3                   	ret    

0001e799 <ck_pr_faa_8>:
CK_PR_FAA_S(8,  uint8_t,  "xaddb")
   1e799:	55                   	push   %ebp
   1e79a:	89 e5                	mov    %esp,%ebp
   1e79c:	83 ec 04             	sub    $0x4,%esp
   1e79f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1e7a2:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e7a5:	8b 55 08             	mov    0x8(%ebp),%edx
   1e7a8:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1e7ab:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e7af:	f0 0f c0 02          	lock xadd %al,(%edx)
   1e7b3:	88 45 fc             	mov    %al,-0x4(%ebp)
   1e7b6:	0f b6 45 fc          	movzbl -0x4(%ebp),%eax
   1e7ba:	c9                   	leave  
   1e7bb:	c3                   	ret    

0001e7bc <ck_pr_inc_ptr>:
	CK_PR_UNARY_S(K, uint, unsigned int, #K "l")	\
	CK_PR_UNARY_S(K, 32, uint32_t, #K "l")		\
	CK_PR_UNARY_S(K, 16, uint16_t, #K "w")		\
	CK_PR_UNARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(inc)
   1e7bc:	55                   	push   %ebp
   1e7bd:	89 e5                	mov    %esp,%ebp
   1e7bf:	8b 45 08             	mov    0x8(%ebp),%eax
   1e7c2:	8b 55 08             	mov    0x8(%ebp),%edx
   1e7c5:	f0 ff 00             	lock incl (%eax)
   1e7c8:	90                   	nop
   1e7c9:	5d                   	pop    %ebp
   1e7ca:	c3                   	ret    

0001e7cb <ck_pr_inc_ptr_zero>:
   1e7cb:	55                   	push   %ebp
   1e7cc:	89 e5                	mov    %esp,%ebp
   1e7ce:	8b 45 08             	mov    0x8(%ebp),%eax
   1e7d1:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e7d4:	8b 55 08             	mov    0x8(%ebp),%edx
   1e7d7:	f0 ff 00             	lock incl (%eax)
   1e7da:	0f 94 01             	sete   (%ecx)
   1e7dd:	90                   	nop
   1e7de:	5d                   	pop    %ebp
   1e7df:	c3                   	ret    

0001e7e0 <ck_pr_inc_char>:
   1e7e0:	55                   	push   %ebp
   1e7e1:	89 e5                	mov    %esp,%ebp
   1e7e3:	8b 45 08             	mov    0x8(%ebp),%eax
   1e7e6:	8b 55 08             	mov    0x8(%ebp),%edx
   1e7e9:	f0 fe 00             	lock incb (%eax)
   1e7ec:	90                   	nop
   1e7ed:	5d                   	pop    %ebp
   1e7ee:	c3                   	ret    

0001e7ef <ck_pr_inc_char_zero>:
   1e7ef:	55                   	push   %ebp
   1e7f0:	89 e5                	mov    %esp,%ebp
   1e7f2:	8b 45 08             	mov    0x8(%ebp),%eax
   1e7f5:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e7f8:	8b 55 08             	mov    0x8(%ebp),%edx
   1e7fb:	f0 fe 00             	lock incb (%eax)
   1e7fe:	0f 94 01             	sete   (%ecx)
   1e801:	90                   	nop
   1e802:	5d                   	pop    %ebp
   1e803:	c3                   	ret    

0001e804 <ck_pr_inc_int>:
   1e804:	55                   	push   %ebp
   1e805:	89 e5                	mov    %esp,%ebp
   1e807:	8b 45 08             	mov    0x8(%ebp),%eax
   1e80a:	8b 55 08             	mov    0x8(%ebp),%edx
   1e80d:	f0 ff 00             	lock incl (%eax)
   1e810:	90                   	nop
   1e811:	5d                   	pop    %ebp
   1e812:	c3                   	ret    

0001e813 <ck_pr_inc_int_zero>:
   1e813:	55                   	push   %ebp
   1e814:	89 e5                	mov    %esp,%ebp
   1e816:	8b 45 08             	mov    0x8(%ebp),%eax
   1e819:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e81c:	8b 55 08             	mov    0x8(%ebp),%edx
   1e81f:	f0 ff 00             	lock incl (%eax)
   1e822:	0f 94 01             	sete   (%ecx)
   1e825:	90                   	nop
   1e826:	5d                   	pop    %ebp
   1e827:	c3                   	ret    

0001e828 <ck_pr_inc_uint>:
   1e828:	55                   	push   %ebp
   1e829:	89 e5                	mov    %esp,%ebp
   1e82b:	8b 45 08             	mov    0x8(%ebp),%eax
   1e82e:	8b 55 08             	mov    0x8(%ebp),%edx
   1e831:	f0 ff 00             	lock incl (%eax)
   1e834:	90                   	nop
   1e835:	5d                   	pop    %ebp
   1e836:	c3                   	ret    

0001e837 <ck_pr_inc_uint_zero>:
   1e837:	55                   	push   %ebp
   1e838:	89 e5                	mov    %esp,%ebp
   1e83a:	8b 45 08             	mov    0x8(%ebp),%eax
   1e83d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e840:	8b 55 08             	mov    0x8(%ebp),%edx
   1e843:	f0 ff 00             	lock incl (%eax)
   1e846:	0f 94 01             	sete   (%ecx)
   1e849:	90                   	nop
   1e84a:	5d                   	pop    %ebp
   1e84b:	c3                   	ret    

0001e84c <ck_pr_inc_32>:
   1e84c:	55                   	push   %ebp
   1e84d:	89 e5                	mov    %esp,%ebp
   1e84f:	8b 45 08             	mov    0x8(%ebp),%eax
   1e852:	8b 55 08             	mov    0x8(%ebp),%edx
   1e855:	f0 ff 00             	lock incl (%eax)
   1e858:	90                   	nop
   1e859:	5d                   	pop    %ebp
   1e85a:	c3                   	ret    

0001e85b <ck_pr_inc_32_zero>:
   1e85b:	55                   	push   %ebp
   1e85c:	89 e5                	mov    %esp,%ebp
   1e85e:	8b 45 08             	mov    0x8(%ebp),%eax
   1e861:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e864:	8b 55 08             	mov    0x8(%ebp),%edx
   1e867:	f0 ff 00             	lock incl (%eax)
   1e86a:	0f 94 01             	sete   (%ecx)
   1e86d:	90                   	nop
   1e86e:	5d                   	pop    %ebp
   1e86f:	c3                   	ret    

0001e870 <ck_pr_inc_16>:
   1e870:	55                   	push   %ebp
   1e871:	89 e5                	mov    %esp,%ebp
   1e873:	8b 45 08             	mov    0x8(%ebp),%eax
   1e876:	8b 55 08             	mov    0x8(%ebp),%edx
   1e879:	66 f0 ff 00          	lock incw (%eax)
   1e87d:	90                   	nop
   1e87e:	5d                   	pop    %ebp
   1e87f:	c3                   	ret    

0001e880 <ck_pr_inc_16_zero>:
   1e880:	55                   	push   %ebp
   1e881:	89 e5                	mov    %esp,%ebp
   1e883:	8b 45 08             	mov    0x8(%ebp),%eax
   1e886:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e889:	8b 55 08             	mov    0x8(%ebp),%edx
   1e88c:	66 f0 ff 00          	lock incw (%eax)
   1e890:	0f 94 01             	sete   (%ecx)
   1e893:	90                   	nop
   1e894:	5d                   	pop    %ebp
   1e895:	c3                   	ret    

0001e896 <ck_pr_inc_8>:
   1e896:	55                   	push   %ebp
   1e897:	89 e5                	mov    %esp,%ebp
   1e899:	8b 45 08             	mov    0x8(%ebp),%eax
   1e89c:	8b 55 08             	mov    0x8(%ebp),%edx
   1e89f:	f0 fe 00             	lock incb (%eax)
   1e8a2:	90                   	nop
   1e8a3:	5d                   	pop    %ebp
   1e8a4:	c3                   	ret    

0001e8a5 <ck_pr_inc_8_zero>:
   1e8a5:	55                   	push   %ebp
   1e8a6:	89 e5                	mov    %esp,%ebp
   1e8a8:	8b 45 08             	mov    0x8(%ebp),%eax
   1e8ab:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e8ae:	8b 55 08             	mov    0x8(%ebp),%edx
   1e8b1:	f0 fe 00             	lock incb (%eax)
   1e8b4:	0f 94 01             	sete   (%ecx)
   1e8b7:	90                   	nop
   1e8b8:	5d                   	pop    %ebp
   1e8b9:	c3                   	ret    

0001e8ba <ck_pr_dec_ptr>:
CK_PR_GENERATE(dec)
   1e8ba:	55                   	push   %ebp
   1e8bb:	89 e5                	mov    %esp,%ebp
   1e8bd:	8b 45 08             	mov    0x8(%ebp),%eax
   1e8c0:	8b 55 08             	mov    0x8(%ebp),%edx
   1e8c3:	f0 ff 08             	lock decl (%eax)
   1e8c6:	90                   	nop
   1e8c7:	5d                   	pop    %ebp
   1e8c8:	c3                   	ret    

0001e8c9 <ck_pr_dec_ptr_zero>:
   1e8c9:	55                   	push   %ebp
   1e8ca:	89 e5                	mov    %esp,%ebp
   1e8cc:	8b 45 08             	mov    0x8(%ebp),%eax
   1e8cf:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e8d2:	8b 55 08             	mov    0x8(%ebp),%edx
   1e8d5:	f0 ff 08             	lock decl (%eax)
   1e8d8:	0f 94 01             	sete   (%ecx)
   1e8db:	90                   	nop
   1e8dc:	5d                   	pop    %ebp
   1e8dd:	c3                   	ret    

0001e8de <ck_pr_dec_char>:
   1e8de:	55                   	push   %ebp
   1e8df:	89 e5                	mov    %esp,%ebp
   1e8e1:	8b 45 08             	mov    0x8(%ebp),%eax
   1e8e4:	8b 55 08             	mov    0x8(%ebp),%edx
   1e8e7:	f0 fe 08             	lock decb (%eax)
   1e8ea:	90                   	nop
   1e8eb:	5d                   	pop    %ebp
   1e8ec:	c3                   	ret    

0001e8ed <ck_pr_dec_char_zero>:
   1e8ed:	55                   	push   %ebp
   1e8ee:	89 e5                	mov    %esp,%ebp
   1e8f0:	8b 45 08             	mov    0x8(%ebp),%eax
   1e8f3:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e8f6:	8b 55 08             	mov    0x8(%ebp),%edx
   1e8f9:	f0 fe 08             	lock decb (%eax)
   1e8fc:	0f 94 01             	sete   (%ecx)
   1e8ff:	90                   	nop
   1e900:	5d                   	pop    %ebp
   1e901:	c3                   	ret    

0001e902 <ck_pr_dec_int>:
   1e902:	55                   	push   %ebp
   1e903:	89 e5                	mov    %esp,%ebp
   1e905:	8b 45 08             	mov    0x8(%ebp),%eax
   1e908:	8b 55 08             	mov    0x8(%ebp),%edx
   1e90b:	f0 ff 08             	lock decl (%eax)
   1e90e:	90                   	nop
   1e90f:	5d                   	pop    %ebp
   1e910:	c3                   	ret    

0001e911 <ck_pr_dec_int_zero>:
   1e911:	55                   	push   %ebp
   1e912:	89 e5                	mov    %esp,%ebp
   1e914:	8b 45 08             	mov    0x8(%ebp),%eax
   1e917:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e91a:	8b 55 08             	mov    0x8(%ebp),%edx
   1e91d:	f0 ff 08             	lock decl (%eax)
   1e920:	0f 94 01             	sete   (%ecx)
   1e923:	90                   	nop
   1e924:	5d                   	pop    %ebp
   1e925:	c3                   	ret    

0001e926 <ck_pr_dec_uint>:
   1e926:	55                   	push   %ebp
   1e927:	89 e5                	mov    %esp,%ebp
   1e929:	8b 45 08             	mov    0x8(%ebp),%eax
   1e92c:	8b 55 08             	mov    0x8(%ebp),%edx
   1e92f:	f0 ff 08             	lock decl (%eax)
   1e932:	90                   	nop
   1e933:	5d                   	pop    %ebp
   1e934:	c3                   	ret    

0001e935 <ck_pr_dec_uint_zero>:
   1e935:	55                   	push   %ebp
   1e936:	89 e5                	mov    %esp,%ebp
   1e938:	8b 45 08             	mov    0x8(%ebp),%eax
   1e93b:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e93e:	8b 55 08             	mov    0x8(%ebp),%edx
   1e941:	f0 ff 08             	lock decl (%eax)
   1e944:	0f 94 01             	sete   (%ecx)
   1e947:	90                   	nop
   1e948:	5d                   	pop    %ebp
   1e949:	c3                   	ret    

0001e94a <ck_pr_dec_32>:
   1e94a:	55                   	push   %ebp
   1e94b:	89 e5                	mov    %esp,%ebp
   1e94d:	8b 45 08             	mov    0x8(%ebp),%eax
   1e950:	8b 55 08             	mov    0x8(%ebp),%edx
   1e953:	f0 ff 08             	lock decl (%eax)
   1e956:	90                   	nop
   1e957:	5d                   	pop    %ebp
   1e958:	c3                   	ret    

0001e959 <ck_pr_dec_32_zero>:
   1e959:	55                   	push   %ebp
   1e95a:	89 e5                	mov    %esp,%ebp
   1e95c:	8b 45 08             	mov    0x8(%ebp),%eax
   1e95f:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e962:	8b 55 08             	mov    0x8(%ebp),%edx
   1e965:	f0 ff 08             	lock decl (%eax)
   1e968:	0f 94 01             	sete   (%ecx)
   1e96b:	90                   	nop
   1e96c:	5d                   	pop    %ebp
   1e96d:	c3                   	ret    

0001e96e <ck_pr_dec_16>:
   1e96e:	55                   	push   %ebp
   1e96f:	89 e5                	mov    %esp,%ebp
   1e971:	8b 45 08             	mov    0x8(%ebp),%eax
   1e974:	8b 55 08             	mov    0x8(%ebp),%edx
   1e977:	66 f0 ff 08          	lock decw (%eax)
   1e97b:	90                   	nop
   1e97c:	5d                   	pop    %ebp
   1e97d:	c3                   	ret    

0001e97e <ck_pr_dec_16_zero>:
   1e97e:	55                   	push   %ebp
   1e97f:	89 e5                	mov    %esp,%ebp
   1e981:	8b 45 08             	mov    0x8(%ebp),%eax
   1e984:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e987:	8b 55 08             	mov    0x8(%ebp),%edx
   1e98a:	66 f0 ff 08          	lock decw (%eax)
   1e98e:	0f 94 01             	sete   (%ecx)
   1e991:	90                   	nop
   1e992:	5d                   	pop    %ebp
   1e993:	c3                   	ret    

0001e994 <ck_pr_dec_8>:
   1e994:	55                   	push   %ebp
   1e995:	89 e5                	mov    %esp,%ebp
   1e997:	8b 45 08             	mov    0x8(%ebp),%eax
   1e99a:	8b 55 08             	mov    0x8(%ebp),%edx
   1e99d:	f0 fe 08             	lock decb (%eax)
   1e9a0:	90                   	nop
   1e9a1:	5d                   	pop    %ebp
   1e9a2:	c3                   	ret    

0001e9a3 <ck_pr_dec_8_zero>:
   1e9a3:	55                   	push   %ebp
   1e9a4:	89 e5                	mov    %esp,%ebp
   1e9a6:	8b 45 08             	mov    0x8(%ebp),%eax
   1e9a9:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e9ac:	8b 55 08             	mov    0x8(%ebp),%edx
   1e9af:	f0 fe 08             	lock decb (%eax)
   1e9b2:	0f 94 01             	sete   (%ecx)
   1e9b5:	90                   	nop
   1e9b6:	5d                   	pop    %ebp
   1e9b7:	c3                   	ret    

0001e9b8 <ck_pr_neg_ptr>:
CK_PR_GENERATE(neg)
   1e9b8:	55                   	push   %ebp
   1e9b9:	89 e5                	mov    %esp,%ebp
   1e9bb:	8b 45 08             	mov    0x8(%ebp),%eax
   1e9be:	8b 55 08             	mov    0x8(%ebp),%edx
   1e9c1:	f0 f7 18             	lock negl (%eax)
   1e9c4:	90                   	nop
   1e9c5:	5d                   	pop    %ebp
   1e9c6:	c3                   	ret    

0001e9c7 <ck_pr_neg_ptr_zero>:
   1e9c7:	55                   	push   %ebp
   1e9c8:	89 e5                	mov    %esp,%ebp
   1e9ca:	8b 45 08             	mov    0x8(%ebp),%eax
   1e9cd:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e9d0:	8b 55 08             	mov    0x8(%ebp),%edx
   1e9d3:	f0 f7 18             	lock negl (%eax)
   1e9d6:	0f 94 01             	sete   (%ecx)
   1e9d9:	90                   	nop
   1e9da:	5d                   	pop    %ebp
   1e9db:	c3                   	ret    

0001e9dc <ck_pr_neg_char>:
   1e9dc:	55                   	push   %ebp
   1e9dd:	89 e5                	mov    %esp,%ebp
   1e9df:	8b 45 08             	mov    0x8(%ebp),%eax
   1e9e2:	8b 55 08             	mov    0x8(%ebp),%edx
   1e9e5:	f0 f6 18             	lock negb (%eax)
   1e9e8:	90                   	nop
   1e9e9:	5d                   	pop    %ebp
   1e9ea:	c3                   	ret    

0001e9eb <ck_pr_neg_char_zero>:
   1e9eb:	55                   	push   %ebp
   1e9ec:	89 e5                	mov    %esp,%ebp
   1e9ee:	8b 45 08             	mov    0x8(%ebp),%eax
   1e9f1:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1e9f4:	8b 55 08             	mov    0x8(%ebp),%edx
   1e9f7:	f0 f6 18             	lock negb (%eax)
   1e9fa:	0f 94 01             	sete   (%ecx)
   1e9fd:	90                   	nop
   1e9fe:	5d                   	pop    %ebp
   1e9ff:	c3                   	ret    

0001ea00 <ck_pr_neg_int>:
   1ea00:	55                   	push   %ebp
   1ea01:	89 e5                	mov    %esp,%ebp
   1ea03:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea06:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea09:	f0 f7 18             	lock negl (%eax)
   1ea0c:	90                   	nop
   1ea0d:	5d                   	pop    %ebp
   1ea0e:	c3                   	ret    

0001ea0f <ck_pr_neg_int_zero>:
   1ea0f:	55                   	push   %ebp
   1ea10:	89 e5                	mov    %esp,%ebp
   1ea12:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea15:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1ea18:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea1b:	f0 f7 18             	lock negl (%eax)
   1ea1e:	0f 94 01             	sete   (%ecx)
   1ea21:	90                   	nop
   1ea22:	5d                   	pop    %ebp
   1ea23:	c3                   	ret    

0001ea24 <ck_pr_neg_uint>:
   1ea24:	55                   	push   %ebp
   1ea25:	89 e5                	mov    %esp,%ebp
   1ea27:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea2a:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea2d:	f0 f7 18             	lock negl (%eax)
   1ea30:	90                   	nop
   1ea31:	5d                   	pop    %ebp
   1ea32:	c3                   	ret    

0001ea33 <ck_pr_neg_uint_zero>:
   1ea33:	55                   	push   %ebp
   1ea34:	89 e5                	mov    %esp,%ebp
   1ea36:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea39:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1ea3c:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea3f:	f0 f7 18             	lock negl (%eax)
   1ea42:	0f 94 01             	sete   (%ecx)
   1ea45:	90                   	nop
   1ea46:	5d                   	pop    %ebp
   1ea47:	c3                   	ret    

0001ea48 <ck_pr_neg_32>:
   1ea48:	55                   	push   %ebp
   1ea49:	89 e5                	mov    %esp,%ebp
   1ea4b:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea4e:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea51:	f0 f7 18             	lock negl (%eax)
   1ea54:	90                   	nop
   1ea55:	5d                   	pop    %ebp
   1ea56:	c3                   	ret    

0001ea57 <ck_pr_neg_32_zero>:
   1ea57:	55                   	push   %ebp
   1ea58:	89 e5                	mov    %esp,%ebp
   1ea5a:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea5d:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1ea60:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea63:	f0 f7 18             	lock negl (%eax)
   1ea66:	0f 94 01             	sete   (%ecx)
   1ea69:	90                   	nop
   1ea6a:	5d                   	pop    %ebp
   1ea6b:	c3                   	ret    

0001ea6c <ck_pr_neg_16>:
   1ea6c:	55                   	push   %ebp
   1ea6d:	89 e5                	mov    %esp,%ebp
   1ea6f:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea72:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea75:	66 f0 f7 18          	lock negw (%eax)
   1ea79:	90                   	nop
   1ea7a:	5d                   	pop    %ebp
   1ea7b:	c3                   	ret    

0001ea7c <ck_pr_neg_16_zero>:
   1ea7c:	55                   	push   %ebp
   1ea7d:	89 e5                	mov    %esp,%ebp
   1ea7f:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea82:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1ea85:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea88:	66 f0 f7 18          	lock negw (%eax)
   1ea8c:	0f 94 01             	sete   (%ecx)
   1ea8f:	90                   	nop
   1ea90:	5d                   	pop    %ebp
   1ea91:	c3                   	ret    

0001ea92 <ck_pr_neg_8>:
   1ea92:	55                   	push   %ebp
   1ea93:	89 e5                	mov    %esp,%ebp
   1ea95:	8b 45 08             	mov    0x8(%ebp),%eax
   1ea98:	8b 55 08             	mov    0x8(%ebp),%edx
   1ea9b:	f0 f6 18             	lock negb (%eax)
   1ea9e:	90                   	nop
   1ea9f:	5d                   	pop    %ebp
   1eaa0:	c3                   	ret    

0001eaa1 <ck_pr_neg_8_zero>:
   1eaa1:	55                   	push   %ebp
   1eaa2:	89 e5                	mov    %esp,%ebp
   1eaa4:	8b 45 08             	mov    0x8(%ebp),%eax
   1eaa7:	8b 4d 0c             	mov    0xc(%ebp),%ecx
   1eaaa:	8b 55 08             	mov    0x8(%ebp),%edx
   1eaad:	f0 f6 18             	lock negb (%eax)
   1eab0:	0f 94 01             	sete   (%ecx)
   1eab3:	90                   	nop
   1eab4:	5d                   	pop    %ebp
   1eab5:	c3                   	ret    

0001eab6 <ck_pr_not_ptr>:

/* not does not affect condition flags. */
#undef CK_PR_UNARY_V
#define CK_PR_UNARY_V(a, b, c, d, e)
CK_PR_GENERATE(not)
   1eab6:	55                   	push   %ebp
   1eab7:	89 e5                	mov    %esp,%ebp
   1eab9:	8b 45 08             	mov    0x8(%ebp),%eax
   1eabc:	8b 55 08             	mov    0x8(%ebp),%edx
   1eabf:	f0 f7 10             	lock notl (%eax)
   1eac2:	90                   	nop
   1eac3:	5d                   	pop    %ebp
   1eac4:	c3                   	ret    

0001eac5 <ck_pr_not_char>:
   1eac5:	55                   	push   %ebp
   1eac6:	89 e5                	mov    %esp,%ebp
   1eac8:	8b 45 08             	mov    0x8(%ebp),%eax
   1eacb:	8b 55 08             	mov    0x8(%ebp),%edx
   1eace:	f0 f6 10             	lock notb (%eax)
   1ead1:	90                   	nop
   1ead2:	5d                   	pop    %ebp
   1ead3:	c3                   	ret    

0001ead4 <ck_pr_not_int>:
   1ead4:	55                   	push   %ebp
   1ead5:	89 e5                	mov    %esp,%ebp
   1ead7:	8b 45 08             	mov    0x8(%ebp),%eax
   1eada:	8b 55 08             	mov    0x8(%ebp),%edx
   1eadd:	f0 f7 10             	lock notl (%eax)
   1eae0:	90                   	nop
   1eae1:	5d                   	pop    %ebp
   1eae2:	c3                   	ret    

0001eae3 <ck_pr_not_uint>:
   1eae3:	55                   	push   %ebp
   1eae4:	89 e5                	mov    %esp,%ebp
   1eae6:	8b 45 08             	mov    0x8(%ebp),%eax
   1eae9:	8b 55 08             	mov    0x8(%ebp),%edx
   1eaec:	f0 f7 10             	lock notl (%eax)
   1eaef:	90                   	nop
   1eaf0:	5d                   	pop    %ebp
   1eaf1:	c3                   	ret    

0001eaf2 <ck_pr_not_32>:
   1eaf2:	55                   	push   %ebp
   1eaf3:	89 e5                	mov    %esp,%ebp
   1eaf5:	8b 45 08             	mov    0x8(%ebp),%eax
   1eaf8:	8b 55 08             	mov    0x8(%ebp),%edx
   1eafb:	f0 f7 10             	lock notl (%eax)
   1eafe:	90                   	nop
   1eaff:	5d                   	pop    %ebp
   1eb00:	c3                   	ret    

0001eb01 <ck_pr_not_16>:
   1eb01:	55                   	push   %ebp
   1eb02:	89 e5                	mov    %esp,%ebp
   1eb04:	8b 45 08             	mov    0x8(%ebp),%eax
   1eb07:	8b 55 08             	mov    0x8(%ebp),%edx
   1eb0a:	66 f0 f7 10          	lock notw (%eax)
   1eb0e:	90                   	nop
   1eb0f:	5d                   	pop    %ebp
   1eb10:	c3                   	ret    

0001eb11 <ck_pr_not_8>:
   1eb11:	55                   	push   %ebp
   1eb12:	89 e5                	mov    %esp,%ebp
   1eb14:	8b 45 08             	mov    0x8(%ebp),%eax
   1eb17:	8b 55 08             	mov    0x8(%ebp),%edx
   1eb1a:	f0 f6 10             	lock notb (%eax)
   1eb1d:	90                   	nop
   1eb1e:	5d                   	pop    %ebp
   1eb1f:	c3                   	ret    

0001eb20 <ck_pr_add_ptr>:
	CK_PR_BINARY_S(K, uint, unsigned int, #K "l")		\
	CK_PR_BINARY_S(K, 32, uint32_t, #K "l")			\
	CK_PR_BINARY_S(K, 16, uint16_t, #K "w")			\
	CK_PR_BINARY_S(K, 8, uint8_t, #K "b")

CK_PR_GENERATE(add)
   1eb20:	55                   	push   %ebp
   1eb21:	89 e5                	mov    %esp,%ebp
   1eb23:	8b 45 08             	mov    0x8(%ebp),%eax
   1eb26:	8b 55 0c             	mov    0xc(%ebp),%edx
   1eb29:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eb2c:	f0 01 10             	lock add %edx,(%eax)
   1eb2f:	90                   	nop
   1eb30:	5d                   	pop    %ebp
   1eb31:	c3                   	ret    

0001eb32 <ck_pr_add_char>:
   1eb32:	55                   	push   %ebp
   1eb33:	89 e5                	mov    %esp,%ebp
   1eb35:	83 ec 04             	sub    $0x4,%esp
   1eb38:	8b 45 0c             	mov    0xc(%ebp),%eax
   1eb3b:	88 45 fc             	mov    %al,-0x4(%ebp)
   1eb3e:	8b 45 08             	mov    0x8(%ebp),%eax
   1eb41:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1eb45:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eb48:	f0 00 10             	lock add %dl,(%eax)
   1eb4b:	90                   	nop
   1eb4c:	c9                   	leave  
   1eb4d:	c3                   	ret    

0001eb4e <ck_pr_add_int>:
   1eb4e:	55                   	push   %ebp
   1eb4f:	89 e5                	mov    %esp,%ebp
   1eb51:	8b 45 08             	mov    0x8(%ebp),%eax
   1eb54:	8b 55 0c             	mov    0xc(%ebp),%edx
   1eb57:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eb5a:	f0 01 10             	lock add %edx,(%eax)
   1eb5d:	90                   	nop
   1eb5e:	5d                   	pop    %ebp
   1eb5f:	c3                   	ret    

0001eb60 <ck_pr_add_uint>:
   1eb60:	55                   	push   %ebp
   1eb61:	89 e5                	mov    %esp,%ebp
   1eb63:	8b 45 08             	mov    0x8(%ebp),%eax
   1eb66:	8b 55 0c             	mov    0xc(%ebp),%edx
   1eb69:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eb6c:	f0 01 10             	lock add %edx,(%eax)
   1eb6f:	90                   	nop
   1eb70:	5d                   	pop    %ebp
   1eb71:	c3                   	ret    

0001eb72 <ck_pr_add_32>:
   1eb72:	55                   	push   %ebp
   1eb73:	89 e5                	mov    %esp,%ebp
   1eb75:	8b 45 08             	mov    0x8(%ebp),%eax
   1eb78:	8b 55 0c             	mov    0xc(%ebp),%edx
   1eb7b:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eb7e:	f0 01 10             	lock add %edx,(%eax)
   1eb81:	90                   	nop
   1eb82:	5d                   	pop    %ebp
   1eb83:	c3                   	ret    

0001eb84 <ck_pr_add_16>:
   1eb84:	55                   	push   %ebp
   1eb85:	89 e5                	mov    %esp,%ebp
   1eb87:	83 ec 04             	sub    $0x4,%esp
   1eb8a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1eb8d:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1eb91:	8b 45 08             	mov    0x8(%ebp),%eax
   1eb94:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1eb98:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eb9b:	66 f0 01 10          	lock add %dx,(%eax)
   1eb9f:	90                   	nop
   1eba0:	c9                   	leave  
   1eba1:	c3                   	ret    

0001eba2 <ck_pr_add_8>:
   1eba2:	55                   	push   %ebp
   1eba3:	89 e5                	mov    %esp,%ebp
   1eba5:	83 ec 04             	sub    $0x4,%esp
   1eba8:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ebab:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ebae:	8b 45 08             	mov    0x8(%ebp),%eax
   1ebb1:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ebb5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ebb8:	f0 00 10             	lock add %dl,(%eax)
   1ebbb:	90                   	nop
   1ebbc:	c9                   	leave  
   1ebbd:	c3                   	ret    

0001ebbe <ck_pr_sub_ptr>:
CK_PR_GENERATE(sub)
   1ebbe:	55                   	push   %ebp
   1ebbf:	89 e5                	mov    %esp,%ebp
   1ebc1:	8b 45 08             	mov    0x8(%ebp),%eax
   1ebc4:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ebc7:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ebca:	f0 29 10             	lock sub %edx,(%eax)
   1ebcd:	90                   	nop
   1ebce:	5d                   	pop    %ebp
   1ebcf:	c3                   	ret    

0001ebd0 <ck_pr_sub_char>:
   1ebd0:	55                   	push   %ebp
   1ebd1:	89 e5                	mov    %esp,%ebp
   1ebd3:	83 ec 04             	sub    $0x4,%esp
   1ebd6:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ebd9:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ebdc:	8b 45 08             	mov    0x8(%ebp),%eax
   1ebdf:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ebe3:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ebe6:	f0 28 10             	lock sub %dl,(%eax)
   1ebe9:	90                   	nop
   1ebea:	c9                   	leave  
   1ebeb:	c3                   	ret    

0001ebec <ck_pr_sub_int>:
   1ebec:	55                   	push   %ebp
   1ebed:	89 e5                	mov    %esp,%ebp
   1ebef:	8b 45 08             	mov    0x8(%ebp),%eax
   1ebf2:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ebf5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ebf8:	f0 29 10             	lock sub %edx,(%eax)
   1ebfb:	90                   	nop
   1ebfc:	5d                   	pop    %ebp
   1ebfd:	c3                   	ret    

0001ebfe <ck_pr_sub_uint>:
   1ebfe:	55                   	push   %ebp
   1ebff:	89 e5                	mov    %esp,%ebp
   1ec01:	8b 45 08             	mov    0x8(%ebp),%eax
   1ec04:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ec07:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ec0a:	f0 29 10             	lock sub %edx,(%eax)
   1ec0d:	90                   	nop
   1ec0e:	5d                   	pop    %ebp
   1ec0f:	c3                   	ret    

0001ec10 <ck_pr_sub_32>:
   1ec10:	55                   	push   %ebp
   1ec11:	89 e5                	mov    %esp,%ebp
   1ec13:	8b 45 08             	mov    0x8(%ebp),%eax
   1ec16:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ec19:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ec1c:	f0 29 10             	lock sub %edx,(%eax)
   1ec1f:	90                   	nop
   1ec20:	5d                   	pop    %ebp
   1ec21:	c3                   	ret    

0001ec22 <ck_pr_sub_16>:
   1ec22:	55                   	push   %ebp
   1ec23:	89 e5                	mov    %esp,%ebp
   1ec25:	83 ec 04             	sub    $0x4,%esp
   1ec28:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ec2b:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1ec2f:	8b 45 08             	mov    0x8(%ebp),%eax
   1ec32:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1ec36:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ec39:	66 f0 29 10          	lock sub %dx,(%eax)
   1ec3d:	90                   	nop
   1ec3e:	c9                   	leave  
   1ec3f:	c3                   	ret    

0001ec40 <ck_pr_sub_8>:
   1ec40:	55                   	push   %ebp
   1ec41:	89 e5                	mov    %esp,%ebp
   1ec43:	83 ec 04             	sub    $0x4,%esp
   1ec46:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ec49:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ec4c:	8b 45 08             	mov    0x8(%ebp),%eax
   1ec4f:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ec53:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ec56:	f0 28 10             	lock sub %dl,(%eax)
   1ec59:	90                   	nop
   1ec5a:	c9                   	leave  
   1ec5b:	c3                   	ret    

0001ec5c <ck_pr_and_ptr>:
CK_PR_GENERATE(and)
   1ec5c:	55                   	push   %ebp
   1ec5d:	89 e5                	mov    %esp,%ebp
   1ec5f:	8b 45 08             	mov    0x8(%ebp),%eax
   1ec62:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ec65:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ec68:	f0 21 10             	lock and %edx,(%eax)
   1ec6b:	90                   	nop
   1ec6c:	5d                   	pop    %ebp
   1ec6d:	c3                   	ret    

0001ec6e <ck_pr_and_char>:
   1ec6e:	55                   	push   %ebp
   1ec6f:	89 e5                	mov    %esp,%ebp
   1ec71:	83 ec 04             	sub    $0x4,%esp
   1ec74:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ec77:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ec7a:	8b 45 08             	mov    0x8(%ebp),%eax
   1ec7d:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ec81:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ec84:	f0 20 10             	lock and %dl,(%eax)
   1ec87:	90                   	nop
   1ec88:	c9                   	leave  
   1ec89:	c3                   	ret    

0001ec8a <ck_pr_and_int>:
   1ec8a:	55                   	push   %ebp
   1ec8b:	89 e5                	mov    %esp,%ebp
   1ec8d:	8b 45 08             	mov    0x8(%ebp),%eax
   1ec90:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ec93:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ec96:	f0 21 10             	lock and %edx,(%eax)
   1ec99:	90                   	nop
   1ec9a:	5d                   	pop    %ebp
   1ec9b:	c3                   	ret    

0001ec9c <ck_pr_and_uint>:
   1ec9c:	55                   	push   %ebp
   1ec9d:	89 e5                	mov    %esp,%ebp
   1ec9f:	8b 45 08             	mov    0x8(%ebp),%eax
   1eca2:	8b 55 0c             	mov    0xc(%ebp),%edx
   1eca5:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eca8:	f0 21 10             	lock and %edx,(%eax)
   1ecab:	90                   	nop
   1ecac:	5d                   	pop    %ebp
   1ecad:	c3                   	ret    

0001ecae <ck_pr_and_32>:
   1ecae:	55                   	push   %ebp
   1ecaf:	89 e5                	mov    %esp,%ebp
   1ecb1:	8b 45 08             	mov    0x8(%ebp),%eax
   1ecb4:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ecb7:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ecba:	f0 21 10             	lock and %edx,(%eax)
   1ecbd:	90                   	nop
   1ecbe:	5d                   	pop    %ebp
   1ecbf:	c3                   	ret    

0001ecc0 <ck_pr_and_16>:
   1ecc0:	55                   	push   %ebp
   1ecc1:	89 e5                	mov    %esp,%ebp
   1ecc3:	83 ec 04             	sub    $0x4,%esp
   1ecc6:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ecc9:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1eccd:	8b 45 08             	mov    0x8(%ebp),%eax
   1ecd0:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1ecd4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ecd7:	66 f0 21 10          	lock and %dx,(%eax)
   1ecdb:	90                   	nop
   1ecdc:	c9                   	leave  
   1ecdd:	c3                   	ret    

0001ecde <ck_pr_and_8>:
   1ecde:	55                   	push   %ebp
   1ecdf:	89 e5                	mov    %esp,%ebp
   1ece1:	83 ec 04             	sub    $0x4,%esp
   1ece4:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ece7:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ecea:	8b 45 08             	mov    0x8(%ebp),%eax
   1eced:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ecf1:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ecf4:	f0 20 10             	lock and %dl,(%eax)
   1ecf7:	90                   	nop
   1ecf8:	c9                   	leave  
   1ecf9:	c3                   	ret    

0001ecfa <ck_pr_or_ptr>:
CK_PR_GENERATE(or)
   1ecfa:	55                   	push   %ebp
   1ecfb:	89 e5                	mov    %esp,%ebp
   1ecfd:	8b 45 08             	mov    0x8(%ebp),%eax
   1ed00:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ed03:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ed06:	f0 09 10             	lock or %edx,(%eax)
   1ed09:	90                   	nop
   1ed0a:	5d                   	pop    %ebp
   1ed0b:	c3                   	ret    

0001ed0c <ck_pr_or_char>:
   1ed0c:	55                   	push   %ebp
   1ed0d:	89 e5                	mov    %esp,%ebp
   1ed0f:	83 ec 04             	sub    $0x4,%esp
   1ed12:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ed15:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ed18:	8b 45 08             	mov    0x8(%ebp),%eax
   1ed1b:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ed1f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ed22:	f0 08 10             	lock or %dl,(%eax)
   1ed25:	90                   	nop
   1ed26:	c9                   	leave  
   1ed27:	c3                   	ret    

0001ed28 <ck_pr_or_int>:
   1ed28:	55                   	push   %ebp
   1ed29:	89 e5                	mov    %esp,%ebp
   1ed2b:	8b 45 08             	mov    0x8(%ebp),%eax
   1ed2e:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ed31:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ed34:	f0 09 10             	lock or %edx,(%eax)
   1ed37:	90                   	nop
   1ed38:	5d                   	pop    %ebp
   1ed39:	c3                   	ret    

0001ed3a <ck_pr_or_uint>:
   1ed3a:	55                   	push   %ebp
   1ed3b:	89 e5                	mov    %esp,%ebp
   1ed3d:	8b 45 08             	mov    0x8(%ebp),%eax
   1ed40:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ed43:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ed46:	f0 09 10             	lock or %edx,(%eax)
   1ed49:	90                   	nop
   1ed4a:	5d                   	pop    %ebp
   1ed4b:	c3                   	ret    

0001ed4c <ck_pr_or_32>:
   1ed4c:	55                   	push   %ebp
   1ed4d:	89 e5                	mov    %esp,%ebp
   1ed4f:	8b 45 08             	mov    0x8(%ebp),%eax
   1ed52:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ed55:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ed58:	f0 09 10             	lock or %edx,(%eax)
   1ed5b:	90                   	nop
   1ed5c:	5d                   	pop    %ebp
   1ed5d:	c3                   	ret    

0001ed5e <ck_pr_or_16>:
   1ed5e:	55                   	push   %ebp
   1ed5f:	89 e5                	mov    %esp,%ebp
   1ed61:	83 ec 04             	sub    $0x4,%esp
   1ed64:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ed67:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1ed6b:	8b 45 08             	mov    0x8(%ebp),%eax
   1ed6e:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1ed72:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ed75:	66 f0 09 10          	lock or %dx,(%eax)
   1ed79:	90                   	nop
   1ed7a:	c9                   	leave  
   1ed7b:	c3                   	ret    

0001ed7c <ck_pr_or_8>:
   1ed7c:	55                   	push   %ebp
   1ed7d:	89 e5                	mov    %esp,%ebp
   1ed7f:	83 ec 04             	sub    $0x4,%esp
   1ed82:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ed85:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ed88:	8b 45 08             	mov    0x8(%ebp),%eax
   1ed8b:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ed8f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ed92:	f0 08 10             	lock or %dl,(%eax)
   1ed95:	90                   	nop
   1ed96:	c9                   	leave  
   1ed97:	c3                   	ret    

0001ed98 <ck_pr_xor_ptr>:
CK_PR_GENERATE(xor)
   1ed98:	55                   	push   %ebp
   1ed99:	89 e5                	mov    %esp,%ebp
   1ed9b:	8b 45 08             	mov    0x8(%ebp),%eax
   1ed9e:	8b 55 0c             	mov    0xc(%ebp),%edx
   1eda1:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eda4:	f0 31 10             	lock xor %edx,(%eax)
   1eda7:	90                   	nop
   1eda8:	5d                   	pop    %ebp
   1eda9:	c3                   	ret    

0001edaa <ck_pr_xor_char>:
   1edaa:	55                   	push   %ebp
   1edab:	89 e5                	mov    %esp,%ebp
   1edad:	83 ec 04             	sub    $0x4,%esp
   1edb0:	8b 45 0c             	mov    0xc(%ebp),%eax
   1edb3:	88 45 fc             	mov    %al,-0x4(%ebp)
   1edb6:	8b 45 08             	mov    0x8(%ebp),%eax
   1edb9:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1edbd:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1edc0:	f0 30 10             	lock xor %dl,(%eax)
   1edc3:	90                   	nop
   1edc4:	c9                   	leave  
   1edc5:	c3                   	ret    

0001edc6 <ck_pr_xor_int>:
   1edc6:	55                   	push   %ebp
   1edc7:	89 e5                	mov    %esp,%ebp
   1edc9:	8b 45 08             	mov    0x8(%ebp),%eax
   1edcc:	8b 55 0c             	mov    0xc(%ebp),%edx
   1edcf:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1edd2:	f0 31 10             	lock xor %edx,(%eax)
   1edd5:	90                   	nop
   1edd6:	5d                   	pop    %ebp
   1edd7:	c3                   	ret    

0001edd8 <ck_pr_xor_uint>:
   1edd8:	55                   	push   %ebp
   1edd9:	89 e5                	mov    %esp,%ebp
   1eddb:	8b 45 08             	mov    0x8(%ebp),%eax
   1edde:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ede1:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ede4:	f0 31 10             	lock xor %edx,(%eax)
   1ede7:	90                   	nop
   1ede8:	5d                   	pop    %ebp
   1ede9:	c3                   	ret    

0001edea <ck_pr_xor_32>:
   1edea:	55                   	push   %ebp
   1edeb:	89 e5                	mov    %esp,%ebp
   1eded:	8b 45 08             	mov    0x8(%ebp),%eax
   1edf0:	8b 55 0c             	mov    0xc(%ebp),%edx
   1edf3:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1edf6:	f0 31 10             	lock xor %edx,(%eax)
   1edf9:	90                   	nop
   1edfa:	5d                   	pop    %ebp
   1edfb:	c3                   	ret    

0001edfc <ck_pr_xor_16>:
   1edfc:	55                   	push   %ebp
   1edfd:	89 e5                	mov    %esp,%ebp
   1edff:	83 ec 04             	sub    $0x4,%esp
   1ee02:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ee05:	66 89 45 fc          	mov    %ax,-0x4(%ebp)
   1ee09:	8b 45 08             	mov    0x8(%ebp),%eax
   1ee0c:	0f b7 55 fc          	movzwl -0x4(%ebp),%edx
   1ee10:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ee13:	66 f0 31 10          	lock xor %dx,(%eax)
   1ee17:	90                   	nop
   1ee18:	c9                   	leave  
   1ee19:	c3                   	ret    

0001ee1a <ck_pr_xor_8>:
   1ee1a:	55                   	push   %ebp
   1ee1b:	89 e5                	mov    %esp,%ebp
   1ee1d:	83 ec 04             	sub    $0x4,%esp
   1ee20:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ee23:	88 45 fc             	mov    %al,-0x4(%ebp)
   1ee26:	8b 45 08             	mov    0x8(%ebp),%eax
   1ee29:	0f b6 55 fc          	movzbl -0x4(%ebp),%edx
   1ee2d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ee30:	f0 30 10             	lock xor %dl,(%eax)
   1ee33:	90                   	nop
   1ee34:	c9                   	leave  
   1ee35:	c3                   	ret    

0001ee36 <ck_pr_cas_ptr>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return z;							\
	}

CK_PR_CAS(ptr, void, void *, char, "cmpxchgl")
   1ee36:	55                   	push   %ebp
   1ee37:	89 e5                	mov    %esp,%ebp
   1ee39:	53                   	push   %ebx
   1ee3a:	83 ec 10             	sub    $0x10,%esp
   1ee3d:	8b 55 08             	mov    0x8(%ebp),%edx
   1ee40:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1ee43:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ee46:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1ee49:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1ee4d:	0f 94 c0             	sete   %al
   1ee50:	88 45 fb             	mov    %al,-0x5(%ebp)
   1ee53:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1ee57:	83 c4 10             	add    $0x10,%esp
   1ee5a:	5b                   	pop    %ebx
   1ee5b:	5d                   	pop    %ebp
   1ee5c:	c3                   	ret    

0001ee5d <ck_pr_cas_char>:

#define CK_PR_CAS_S(S, T, I) CK_PR_CAS(S, T, T, T, I)

CK_PR_CAS_S(char, char, "cmpxchgb")
   1ee5d:	55                   	push   %ebp
   1ee5e:	89 e5                	mov    %esp,%ebp
   1ee60:	53                   	push   %ebx
   1ee61:	83 ec 18             	sub    $0x18,%esp
   1ee64:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ee67:	8b 45 10             	mov    0x10(%ebp),%eax
   1ee6a:	88 55 e8             	mov    %dl,-0x18(%ebp)
   1ee6d:	88 45 e4             	mov    %al,-0x1c(%ebp)
   1ee70:	8b 55 08             	mov    0x8(%ebp),%edx
   1ee73:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   1ee77:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   1ee7b:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1ee7e:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   1ee82:	0f 94 c0             	sete   %al
   1ee85:	88 45 fb             	mov    %al,-0x5(%ebp)
   1ee88:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1ee8c:	83 c4 18             	add    $0x18,%esp
   1ee8f:	5b                   	pop    %ebx
   1ee90:	5d                   	pop    %ebp
   1ee91:	c3                   	ret    

0001ee92 <ck_pr_cas_int>:
CK_PR_CAS_S(int, int, "cmpxchgl")
   1ee92:	55                   	push   %ebp
   1ee93:	89 e5                	mov    %esp,%ebp
   1ee95:	53                   	push   %ebx
   1ee96:	83 ec 10             	sub    $0x10,%esp
   1ee99:	8b 55 08             	mov    0x8(%ebp),%edx
   1ee9c:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1ee9f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1eea2:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1eea5:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1eea9:	0f 94 c0             	sete   %al
   1eeac:	88 45 fb             	mov    %al,-0x5(%ebp)
   1eeaf:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1eeb3:	83 c4 10             	add    $0x10,%esp
   1eeb6:	5b                   	pop    %ebx
   1eeb7:	5d                   	pop    %ebp
   1eeb8:	c3                   	ret    

0001eeb9 <ck_pr_cas_uint>:
CK_PR_CAS_S(uint, unsigned int, "cmpxchgl")
   1eeb9:	55                   	push   %ebp
   1eeba:	89 e5                	mov    %esp,%ebp
   1eebc:	53                   	push   %ebx
   1eebd:	83 ec 10             	sub    $0x10,%esp
   1eec0:	8b 55 08             	mov    0x8(%ebp),%edx
   1eec3:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1eec6:	8b 45 0c             	mov    0xc(%ebp),%eax
   1eec9:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1eecc:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1eed0:	0f 94 c0             	sete   %al
   1eed3:	88 45 fb             	mov    %al,-0x5(%ebp)
   1eed6:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1eeda:	83 c4 10             	add    $0x10,%esp
   1eedd:	5b                   	pop    %ebx
   1eede:	5d                   	pop    %ebp
   1eedf:	c3                   	ret    

0001eee0 <ck_pr_cas_32>:
CK_PR_CAS_S(32, uint32_t, "cmpxchgl")
   1eee0:	55                   	push   %ebp
   1eee1:	89 e5                	mov    %esp,%ebp
   1eee3:	53                   	push   %ebx
   1eee4:	83 ec 10             	sub    $0x10,%esp
   1eee7:	8b 55 08             	mov    0x8(%ebp),%edx
   1eeea:	8b 4d 10             	mov    0x10(%ebp),%ecx
   1eeed:	8b 45 0c             	mov    0xc(%ebp),%eax
   1eef0:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1eef3:	f0 0f b1 0a          	lock cmpxchg %ecx,(%edx)
   1eef7:	0f 94 c0             	sete   %al
   1eefa:	88 45 fb             	mov    %al,-0x5(%ebp)
   1eefd:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1ef01:	83 c4 10             	add    $0x10,%esp
   1ef04:	5b                   	pop    %ebx
   1ef05:	5d                   	pop    %ebp
   1ef06:	c3                   	ret    

0001ef07 <ck_pr_cas_16>:
CK_PR_CAS_S(16, uint16_t, "cmpxchgw")
   1ef07:	55                   	push   %ebp
   1ef08:	89 e5                	mov    %esp,%ebp
   1ef0a:	53                   	push   %ebx
   1ef0b:	83 ec 18             	sub    $0x18,%esp
   1ef0e:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ef11:	8b 45 10             	mov    0x10(%ebp),%eax
   1ef14:	66 89 55 e8          	mov    %dx,-0x18(%ebp)
   1ef18:	66 89 45 e4          	mov    %ax,-0x1c(%ebp)
   1ef1c:	8b 55 08             	mov    0x8(%ebp),%edx
   1ef1f:	0f b7 4d e4          	movzwl -0x1c(%ebp),%ecx
   1ef23:	0f b7 45 e8          	movzwl -0x18(%ebp),%eax
   1ef27:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1ef2a:	66 f0 0f b1 0a       	lock cmpxchg %cx,(%edx)
   1ef2f:	0f 94 c0             	sete   %al
   1ef32:	88 45 fb             	mov    %al,-0x5(%ebp)
   1ef35:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1ef39:	83 c4 18             	add    $0x18,%esp
   1ef3c:	5b                   	pop    %ebx
   1ef3d:	5d                   	pop    %ebp
   1ef3e:	c3                   	ret    

0001ef3f <ck_pr_cas_8>:
CK_PR_CAS_S(8,  uint8_t,  "cmpxchgb")
   1ef3f:	55                   	push   %ebp
   1ef40:	89 e5                	mov    %esp,%ebp
   1ef42:	53                   	push   %ebx
   1ef43:	83 ec 18             	sub    $0x18,%esp
   1ef46:	8b 55 0c             	mov    0xc(%ebp),%edx
   1ef49:	8b 45 10             	mov    0x10(%ebp),%eax
   1ef4c:	88 55 e8             	mov    %dl,-0x18(%ebp)
   1ef4f:	88 45 e4             	mov    %al,-0x1c(%ebp)
   1ef52:	8b 55 08             	mov    0x8(%ebp),%edx
   1ef55:	0f b6 4d e4          	movzbl -0x1c(%ebp),%ecx
   1ef59:	0f b6 45 e8          	movzbl -0x18(%ebp),%eax
   1ef5d:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1ef60:	f0 0f b0 0a          	lock cmpxchg %cl,(%edx)
   1ef64:	0f 94 c0             	sete   %al
   1ef67:	88 45 fb             	mov    %al,-0x5(%ebp)
   1ef6a:	0f b6 45 fb          	movzbl -0x5(%ebp),%eax
   1ef6e:	83 c4 18             	add    $0x18,%esp
   1ef71:	5b                   	pop    %ebx
   1ef72:	5d                   	pop    %ebp
   1ef73:	c3                   	ret    

0001ef74 <ck_pr_cas_ptr_value>:
					  "a"   (compare)			\
					: "memory", "cc");			\
		return (bool)z;							\
	}

CK_PR_CAS_O(ptr, void, void *, char, "l", "eax")
   1ef74:	55                   	push   %ebp
   1ef75:	89 e5                	mov    %esp,%ebp
   1ef77:	56                   	push   %esi
   1ef78:	53                   	push   %ebx
   1ef79:	83 ec 10             	sub    $0x10,%esp
   1ef7c:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1ef7f:	8b 75 14             	mov    0x14(%ebp),%esi
   1ef82:	8b 55 10             	mov    0x10(%ebp),%edx
   1ef85:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ef88:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1ef8b:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1ef8f:	89 06                	mov    %eax,(%esi)
   1ef91:	0f 94 c0             	sete   %al
   1ef94:	88 45 f7             	mov    %al,-0x9(%ebp)
   1ef97:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1ef9b:	83 c4 10             	add    $0x10,%esp
   1ef9e:	5b                   	pop    %ebx
   1ef9f:	5e                   	pop    %esi
   1efa0:	5d                   	pop    %ebp
   1efa1:	c3                   	ret    

0001efa2 <ck_pr_cas_char_value>:

#define CK_PR_CAS_O_S(S, T, I, R)	\
	CK_PR_CAS_O(S, T, T, T, I, R)

CK_PR_CAS_O_S(char, char, "b", "al")
   1efa2:	55                   	push   %ebp
   1efa3:	89 e5                	mov    %esp,%ebp
   1efa5:	56                   	push   %esi
   1efa6:	53                   	push   %ebx
   1efa7:	83 ec 18             	sub    $0x18,%esp
   1efaa:	8b 55 0c             	mov    0xc(%ebp),%edx
   1efad:	8b 45 10             	mov    0x10(%ebp),%eax
   1efb0:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   1efb3:	88 45 e0             	mov    %al,-0x20(%ebp)
   1efb6:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1efb9:	8b 75 14             	mov    0x14(%ebp),%esi
   1efbc:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   1efc0:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   1efc4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1efc7:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   1efcb:	88 06                	mov    %al,(%esi)
   1efcd:	0f 94 c0             	sete   %al
   1efd0:	88 45 f7             	mov    %al,-0x9(%ebp)
   1efd3:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1efd7:	83 c4 18             	add    $0x18,%esp
   1efda:	5b                   	pop    %ebx
   1efdb:	5e                   	pop    %esi
   1efdc:	5d                   	pop    %ebp
   1efdd:	c3                   	ret    

0001efde <ck_pr_cas_int_value>:
CK_PR_CAS_O_S(int, int, "l", "eax")
   1efde:	55                   	push   %ebp
   1efdf:	89 e5                	mov    %esp,%ebp
   1efe1:	56                   	push   %esi
   1efe2:	53                   	push   %ebx
   1efe3:	83 ec 10             	sub    $0x10,%esp
   1efe6:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1efe9:	8b 75 14             	mov    0x14(%ebp),%esi
   1efec:	8b 55 10             	mov    0x10(%ebp),%edx
   1efef:	8b 45 0c             	mov    0xc(%ebp),%eax
   1eff2:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1eff5:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1eff9:	89 06                	mov    %eax,(%esi)
   1effb:	0f 94 c0             	sete   %al
   1effe:	88 45 f7             	mov    %al,-0x9(%ebp)
   1f001:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1f005:	83 c4 10             	add    $0x10,%esp
   1f008:	5b                   	pop    %ebx
   1f009:	5e                   	pop    %esi
   1f00a:	5d                   	pop    %ebp
   1f00b:	c3                   	ret    

0001f00c <ck_pr_cas_uint_value>:
CK_PR_CAS_O_S(uint, unsigned int, "l", "eax")
   1f00c:	55                   	push   %ebp
   1f00d:	89 e5                	mov    %esp,%ebp
   1f00f:	56                   	push   %esi
   1f010:	53                   	push   %ebx
   1f011:	83 ec 10             	sub    $0x10,%esp
   1f014:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1f017:	8b 75 14             	mov    0x14(%ebp),%esi
   1f01a:	8b 55 10             	mov    0x10(%ebp),%edx
   1f01d:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f020:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f023:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1f027:	89 06                	mov    %eax,(%esi)
   1f029:	0f 94 c0             	sete   %al
   1f02c:	88 45 f7             	mov    %al,-0x9(%ebp)
   1f02f:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1f033:	83 c4 10             	add    $0x10,%esp
   1f036:	5b                   	pop    %ebx
   1f037:	5e                   	pop    %esi
   1f038:	5d                   	pop    %ebp
   1f039:	c3                   	ret    

0001f03a <ck_pr_cas_32_value>:
CK_PR_CAS_O_S(32, uint32_t, "l", "eax")
   1f03a:	55                   	push   %ebp
   1f03b:	89 e5                	mov    %esp,%ebp
   1f03d:	56                   	push   %esi
   1f03e:	53                   	push   %ebx
   1f03f:	83 ec 10             	sub    $0x10,%esp
   1f042:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1f045:	8b 75 14             	mov    0x14(%ebp),%esi
   1f048:	8b 55 10             	mov    0x10(%ebp),%edx
   1f04b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f04e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f051:	f0 0f b1 13          	lock cmpxchg %edx,(%ebx)
   1f055:	89 06                	mov    %eax,(%esi)
   1f057:	0f 94 c0             	sete   %al
   1f05a:	88 45 f7             	mov    %al,-0x9(%ebp)
   1f05d:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1f061:	83 c4 10             	add    $0x10,%esp
   1f064:	5b                   	pop    %ebx
   1f065:	5e                   	pop    %esi
   1f066:	5d                   	pop    %ebp
   1f067:	c3                   	ret    

0001f068 <ck_pr_cas_16_value>:
CK_PR_CAS_O_S(16, uint16_t, "w", "ax")
   1f068:	55                   	push   %ebp
   1f069:	89 e5                	mov    %esp,%ebp
   1f06b:	56                   	push   %esi
   1f06c:	53                   	push   %ebx
   1f06d:	83 ec 18             	sub    $0x18,%esp
   1f070:	8b 55 0c             	mov    0xc(%ebp),%edx
   1f073:	8b 45 10             	mov    0x10(%ebp),%eax
   1f076:	66 89 55 e4          	mov    %dx,-0x1c(%ebp)
   1f07a:	66 89 45 e0          	mov    %ax,-0x20(%ebp)
   1f07e:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1f081:	8b 75 14             	mov    0x14(%ebp),%esi
   1f084:	0f b7 55 e0          	movzwl -0x20(%ebp),%edx
   1f088:	0f b7 45 e4          	movzwl -0x1c(%ebp),%eax
   1f08c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f08f:	66 f0 0f b1 13       	lock cmpxchg %dx,(%ebx)
   1f094:	66 89 06             	mov    %ax,(%esi)
   1f097:	0f 94 c0             	sete   %al
   1f09a:	88 45 f7             	mov    %al,-0x9(%ebp)
   1f09d:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1f0a1:	83 c4 18             	add    $0x18,%esp
   1f0a4:	5b                   	pop    %ebx
   1f0a5:	5e                   	pop    %esi
   1f0a6:	5d                   	pop    %ebp
   1f0a7:	c3                   	ret    

0001f0a8 <ck_pr_cas_8_value>:
CK_PR_CAS_O_S(8,  uint8_t,  "b", "al")
   1f0a8:	55                   	push   %ebp
   1f0a9:	89 e5                	mov    %esp,%ebp
   1f0ab:	56                   	push   %esi
   1f0ac:	53                   	push   %ebx
   1f0ad:	83 ec 18             	sub    $0x18,%esp
   1f0b0:	8b 55 0c             	mov    0xc(%ebp),%edx
   1f0b3:	8b 45 10             	mov    0x10(%ebp),%eax
   1f0b6:	88 55 e4             	mov    %dl,-0x1c(%ebp)
   1f0b9:	88 45 e0             	mov    %al,-0x20(%ebp)
   1f0bc:	8b 5d 08             	mov    0x8(%ebp),%ebx
   1f0bf:	8b 75 14             	mov    0x14(%ebp),%esi
   1f0c2:	0f b6 55 e0          	movzbl -0x20(%ebp),%edx
   1f0c6:	0f b6 45 e4          	movzbl -0x1c(%ebp),%eax
   1f0ca:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f0cd:	f0 0f b0 13          	lock cmpxchg %dl,(%ebx)
   1f0d1:	88 06                	mov    %al,(%esi)
   1f0d3:	0f 94 c0             	sete   %al
   1f0d6:	88 45 f7             	mov    %al,-0x9(%ebp)
   1f0d9:	0f b6 45 f7          	movzbl -0x9(%ebp),%eax
   1f0dd:	83 c4 18             	add    $0x18,%esp
   1f0e0:	5b                   	pop    %ebx
   1f0e1:	5e                   	pop    %esi
   1f0e2:	5d                   	pop    %ebp
   1f0e3:	c3                   	ret    

0001f0e4 <ck_pr_btc_ptr>:
	CK_PR_BT_S(K, uint, unsigned int, #K "l %2, %0")	\
	CK_PR_BT_S(K, int, int, #K "l %2, %0")			\
	CK_PR_BT_S(K, 32, uint32_t, #K "l %2, %0")		\
	CK_PR_BT_S(K, 16, uint16_t, #K "w %w2, %0")

CK_PR_GENERATE(btc)
   1f0e4:	55                   	push   %ebp
   1f0e5:	89 e5                	mov    %esp,%ebp
   1f0e7:	83 ec 10             	sub    $0x10,%esp
   1f0ea:	8b 55 08             	mov    0x8(%ebp),%edx
   1f0ed:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f0f0:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f0f3:	f0 0f bb 02          	lock btc %eax,(%edx)
   1f0f7:	0f 92 c0             	setb   %al
   1f0fa:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f0fd:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f101:	c9                   	leave  
   1f102:	c3                   	ret    

0001f103 <ck_pr_btc_uint>:
   1f103:	55                   	push   %ebp
   1f104:	89 e5                	mov    %esp,%ebp
   1f106:	83 ec 10             	sub    $0x10,%esp
   1f109:	8b 55 08             	mov    0x8(%ebp),%edx
   1f10c:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f10f:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f112:	f0 0f bb 02          	lock btc %eax,(%edx)
   1f116:	0f 92 c0             	setb   %al
   1f119:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f11c:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f120:	c9                   	leave  
   1f121:	c3                   	ret    

0001f122 <ck_pr_btc_int>:
   1f122:	55                   	push   %ebp
   1f123:	89 e5                	mov    %esp,%ebp
   1f125:	83 ec 10             	sub    $0x10,%esp
   1f128:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f12b:	8b 55 08             	mov    0x8(%ebp),%edx
   1f12e:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f131:	f0 0f bb 02          	lock btc %eax,(%edx)
   1f135:	0f 92 c0             	setb   %al
   1f138:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f13b:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f13f:	c9                   	leave  
   1f140:	c3                   	ret    

0001f141 <ck_pr_btc_32>:
   1f141:	55                   	push   %ebp
   1f142:	89 e5                	mov    %esp,%ebp
   1f144:	83 ec 10             	sub    $0x10,%esp
   1f147:	8b 55 08             	mov    0x8(%ebp),%edx
   1f14a:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f14d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f150:	f0 0f bb 02          	lock btc %eax,(%edx)
   1f154:	0f 92 c0             	setb   %al
   1f157:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f15a:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f15e:	c9                   	leave  
   1f15f:	c3                   	ret    

0001f160 <ck_pr_btc_16>:
   1f160:	55                   	push   %ebp
   1f161:	89 e5                	mov    %esp,%ebp
   1f163:	83 ec 10             	sub    $0x10,%esp
   1f166:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f169:	8b 55 08             	mov    0x8(%ebp),%edx
   1f16c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f16f:	66 f0 0f bb 02       	lock btc %ax,(%edx)
   1f174:	0f 92 c0             	setb   %al
   1f177:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f17a:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f17e:	c9                   	leave  
   1f17f:	c3                   	ret    

0001f180 <ck_pr_bts_ptr>:
CK_PR_GENERATE(bts)
   1f180:	55                   	push   %ebp
   1f181:	89 e5                	mov    %esp,%ebp
   1f183:	83 ec 10             	sub    $0x10,%esp
   1f186:	8b 55 08             	mov    0x8(%ebp),%edx
   1f189:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f18c:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f18f:	f0 0f ab 02          	lock bts %eax,(%edx)
   1f193:	0f 92 c0             	setb   %al
   1f196:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f199:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f19d:	c9                   	leave  
   1f19e:	c3                   	ret    

0001f19f <ck_pr_bts_uint>:
   1f19f:	55                   	push   %ebp
   1f1a0:	89 e5                	mov    %esp,%ebp
   1f1a2:	83 ec 10             	sub    $0x10,%esp
   1f1a5:	8b 55 08             	mov    0x8(%ebp),%edx
   1f1a8:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f1ab:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f1ae:	f0 0f ab 02          	lock bts %eax,(%edx)
   1f1b2:	0f 92 c0             	setb   %al
   1f1b5:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f1b8:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f1bc:	c9                   	leave  
   1f1bd:	c3                   	ret    

0001f1be <ck_pr_bts_int>:
   1f1be:	55                   	push   %ebp
   1f1bf:	89 e5                	mov    %esp,%ebp
   1f1c1:	83 ec 10             	sub    $0x10,%esp
   1f1c4:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f1c7:	8b 55 08             	mov    0x8(%ebp),%edx
   1f1ca:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f1cd:	f0 0f ab 02          	lock bts %eax,(%edx)
   1f1d1:	0f 92 c0             	setb   %al
   1f1d4:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f1d7:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f1db:	c9                   	leave  
   1f1dc:	c3                   	ret    

0001f1dd <ck_pr_bts_32>:
   1f1dd:	55                   	push   %ebp
   1f1de:	89 e5                	mov    %esp,%ebp
   1f1e0:	83 ec 10             	sub    $0x10,%esp
   1f1e3:	8b 55 08             	mov    0x8(%ebp),%edx
   1f1e6:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f1e9:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f1ec:	f0 0f ab 02          	lock bts %eax,(%edx)
   1f1f0:	0f 92 c0             	setb   %al
   1f1f3:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f1f6:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f1fa:	c9                   	leave  
   1f1fb:	c3                   	ret    

0001f1fc <ck_pr_bts_16>:
   1f1fc:	55                   	push   %ebp
   1f1fd:	89 e5                	mov    %esp,%ebp
   1f1ff:	83 ec 10             	sub    $0x10,%esp
   1f202:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f205:	8b 55 08             	mov    0x8(%ebp),%edx
   1f208:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f20b:	66 f0 0f ab 02       	lock bts %ax,(%edx)
   1f210:	0f 92 c0             	setb   %al
   1f213:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f216:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f21a:	c9                   	leave  
   1f21b:	c3                   	ret    

0001f21c <ck_pr_btr_ptr>:
CK_PR_GENERATE(btr)
   1f21c:	55                   	push   %ebp
   1f21d:	89 e5                	mov    %esp,%ebp
   1f21f:	83 ec 10             	sub    $0x10,%esp
   1f222:	8b 55 08             	mov    0x8(%ebp),%edx
   1f225:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f228:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f22b:	f0 0f b3 02          	lock btr %eax,(%edx)
   1f22f:	0f 92 c0             	setb   %al
   1f232:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f235:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f239:	c9                   	leave  
   1f23a:	c3                   	ret    

0001f23b <ck_pr_btr_uint>:
   1f23b:	55                   	push   %ebp
   1f23c:	89 e5                	mov    %esp,%ebp
   1f23e:	83 ec 10             	sub    $0x10,%esp
   1f241:	8b 55 08             	mov    0x8(%ebp),%edx
   1f244:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f247:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f24a:	f0 0f b3 02          	lock btr %eax,(%edx)
   1f24e:	0f 92 c0             	setb   %al
   1f251:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f254:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f258:	c9                   	leave  
   1f259:	c3                   	ret    

0001f25a <ck_pr_btr_int>:
   1f25a:	55                   	push   %ebp
   1f25b:	89 e5                	mov    %esp,%ebp
   1f25d:	83 ec 10             	sub    $0x10,%esp
   1f260:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f263:	8b 55 08             	mov    0x8(%ebp),%edx
   1f266:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f269:	f0 0f b3 02          	lock btr %eax,(%edx)
   1f26d:	0f 92 c0             	setb   %al
   1f270:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f273:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f277:	c9                   	leave  
   1f278:	c3                   	ret    

0001f279 <ck_pr_btr_32>:
   1f279:	55                   	push   %ebp
   1f27a:	89 e5                	mov    %esp,%ebp
   1f27c:	83 ec 10             	sub    $0x10,%esp
   1f27f:	8b 55 08             	mov    0x8(%ebp),%edx
   1f282:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f285:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f288:	f0 0f b3 02          	lock btr %eax,(%edx)
   1f28c:	0f 92 c0             	setb   %al
   1f28f:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f292:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f296:	c9                   	leave  
   1f297:	c3                   	ret    

0001f298 <ck_pr_btr_16>:
   1f298:	55                   	push   %ebp
   1f299:	89 e5                	mov    %esp,%ebp
   1f29b:	83 ec 10             	sub    $0x10,%esp
   1f29e:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f2a1:	8b 55 08             	mov    0x8(%ebp),%edx
   1f2a4:	8b 4d 08             	mov    0x8(%ebp),%ecx
   1f2a7:	66 f0 0f b3 02       	lock btr %ax,(%edx)
   1f2ac:	0f 92 c0             	setb   %al
   1f2af:	88 45 ff             	mov    %al,-0x1(%ebp)
   1f2b2:	0f b6 45 ff          	movzbl -0x1(%ebp),%eax
   1f2b6:	c9                   	leave  
   1f2b7:	c3                   	ret    

0001f2b8 <ck_pr_barrier>:

#include <ck_cc.h>

CK_CC_INLINE static void
ck_pr_barrier(void)
{
   1f2b8:	55                   	push   %ebp
   1f2b9:	89 e5                	mov    %esp,%ebp

	__asm__ __volatile__("" ::: "memory");
	return;
   1f2bb:	90                   	nop
}
   1f2bc:	5d                   	pop    %ebp
   1f2bd:	c3                   	ret    

0001f2be <ck_pr_fence_load_depends>:

/*
 * None of the currently supported platforms allow for data-dependent
 * load ordering.
 */
CK_PR_FENCE_NOOP(load_depends)
   1f2be:	55                   	push   %ebp
   1f2bf:	89 e5                	mov    %esp,%ebp
   1f2c1:	e8 f2 ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f2c6:	90                   	nop
   1f2c7:	5d                   	pop    %ebp
   1f2c8:	c3                   	ret    

0001f2c9 <ck_pr_fence_atomic>:
#elif defined(CK_MD_TSO)
/*
 * Only loads are re-ordered and only with respect to
 * prior stores. Atomic operations are serializing.
 */
CK_PR_FENCE_NOOP(atomic)
   1f2c9:	55                   	push   %ebp
   1f2ca:	89 e5                	mov    %esp,%ebp
   1f2cc:	e8 e7 ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f2d1:	90                   	nop
   1f2d2:	5d                   	pop    %ebp
   1f2d3:	c3                   	ret    

0001f2d4 <ck_pr_fence_atomic_load>:
CK_PR_FENCE_NOOP(atomic_load)
   1f2d4:	55                   	push   %ebp
   1f2d5:	89 e5                	mov    %esp,%ebp
   1f2d7:	e8 dc ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f2dc:	90                   	nop
   1f2dd:	5d                   	pop    %ebp
   1f2de:	c3                   	ret    

0001f2df <ck_pr_fence_atomic_store>:
CK_PR_FENCE_NOOP(atomic_store)
   1f2df:	55                   	push   %ebp
   1f2e0:	89 e5                	mov    %esp,%ebp
   1f2e2:	e8 d1 ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f2e7:	90                   	nop
   1f2e8:	5d                   	pop    %ebp
   1f2e9:	c3                   	ret    

0001f2ea <ck_pr_fence_store_atomic>:
CK_PR_FENCE_NOOP(store_atomic)
   1f2ea:	55                   	push   %ebp
   1f2eb:	89 e5                	mov    %esp,%ebp
   1f2ed:	e8 c6 ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f2f2:	90                   	nop
   1f2f3:	5d                   	pop    %ebp
   1f2f4:	c3                   	ret    

0001f2f5 <ck_pr_fence_load_atomic>:
CK_PR_FENCE_NOOP(load_atomic)
   1f2f5:	55                   	push   %ebp
   1f2f6:	89 e5                	mov    %esp,%ebp
   1f2f8:	e8 bb ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f2fd:	90                   	nop
   1f2fe:	5d                   	pop    %ebp
   1f2ff:	c3                   	ret    

0001f300 <ck_pr_fence_load_store>:
CK_PR_FENCE_NOOP(load_store)
   1f300:	55                   	push   %ebp
   1f301:	89 e5                	mov    %esp,%ebp
   1f303:	e8 b0 ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f308:	90                   	nop
   1f309:	5d                   	pop    %ebp
   1f30a:	c3                   	ret    

0001f30b <ck_pr_fence_store_load>:
CK_PR_FENCE_EMIT(store_load)
   1f30b:	55                   	push   %ebp
   1f30c:	89 e5                	mov    %esp,%ebp
   1f30e:	e8 d4 f1 ff ff       	call   1e4e7 <ck_pr_fence_strict_store_load>
   1f313:	90                   	nop
   1f314:	5d                   	pop    %ebp
   1f315:	c3                   	ret    

0001f316 <ck_pr_fence_load>:
CK_PR_FENCE_NOOP(load)
   1f316:	55                   	push   %ebp
   1f317:	89 e5                	mov    %esp,%ebp
   1f319:	e8 9a ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f31e:	90                   	nop
   1f31f:	5d                   	pop    %ebp
   1f320:	c3                   	ret    

0001f321 <ck_pr_fence_store>:
CK_PR_FENCE_NOOP(store)
   1f321:	55                   	push   %ebp
   1f322:	89 e5                	mov    %esp,%ebp
   1f324:	e8 8f ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f329:	90                   	nop
   1f32a:	5d                   	pop    %ebp
   1f32b:	c3                   	ret    

0001f32c <ck_pr_fence_memory>:
CK_PR_FENCE_EMIT(memory)
   1f32c:	55                   	push   %ebp
   1f32d:	89 e5                	mov    %esp,%ebp
   1f32f:	e8 bc f1 ff ff       	call   1e4f0 <ck_pr_fence_strict_memory>
   1f334:	90                   	nop
   1f335:	5d                   	pop    %ebp
   1f336:	c3                   	ret    

0001f337 <ck_pr_fence_acquire>:
CK_PR_FENCE_NOOP(acquire)
   1f337:	55                   	push   %ebp
   1f338:	89 e5                	mov    %esp,%ebp
   1f33a:	e8 79 ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f33f:	90                   	nop
   1f340:	5d                   	pop    %ebp
   1f341:	c3                   	ret    

0001f342 <ck_pr_fence_release>:
CK_PR_FENCE_NOOP(release)
   1f342:	55                   	push   %ebp
   1f343:	89 e5                	mov    %esp,%ebp
   1f345:	e8 6e ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f34a:	90                   	nop
   1f34b:	5d                   	pop    %ebp
   1f34c:	c3                   	ret    

0001f34d <ck_pr_fence_acqrel>:
CK_PR_FENCE_NOOP(acqrel)
   1f34d:	55                   	push   %ebp
   1f34e:	89 e5                	mov    %esp,%ebp
   1f350:	e8 63 ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f355:	90                   	nop
   1f356:	5d                   	pop    %ebp
   1f357:	c3                   	ret    

0001f358 <ck_pr_fence_lock>:
CK_PR_FENCE_NOOP(lock)
   1f358:	55                   	push   %ebp
   1f359:	89 e5                	mov    %esp,%ebp
   1f35b:	e8 58 ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f360:	90                   	nop
   1f361:	5d                   	pop    %ebp
   1f362:	c3                   	ret    

0001f363 <ck_pr_fence_unlock>:
CK_PR_FENCE_NOOP(unlock)
   1f363:	55                   	push   %ebp
   1f364:	89 e5                	mov    %esp,%ebp
   1f366:	e8 4d ff ff ff       	call   1f2b8 <ck_pr_barrier>
   1f36b:	90                   	nop
   1f36c:	5d                   	pop    %ebp
   1f36d:	c3                   	ret    

0001f36e <ck_pr_rfo>:

#ifndef CK_F_PR_RFO
#define CK_F_PR_RFO
CK_CC_INLINE static void
ck_pr_rfo(const void *m)
{
   1f36e:	55                   	push   %ebp
   1f36f:	89 e5                	mov    %esp,%ebp

	(void)m;
	return;
   1f371:	90                   	nop
}
   1f372:	5d                   	pop    %ebp
   1f373:	c3                   	ret    

0001f374 <ck_ring_size>:
};
typedef struct ck_ring_buffer ck_ring_buffer_t;

CK_CC_INLINE static unsigned int
ck_ring_size(const struct ck_ring *ring)
{
   1f374:	55                   	push   %ebp
   1f375:	89 e5                	mov    %esp,%ebp
   1f377:	83 ec 14             	sub    $0x14,%esp
	unsigned int c, p;

	c = ck_pr_load_uint(&ring->c_head);
   1f37a:	8b 45 08             	mov    0x8(%ebp),%eax
   1f37d:	89 04 24             	mov    %eax,(%esp)
   1f380:	e8 86 f2 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f385:	89 45 fc             	mov    %eax,-0x4(%ebp)
	p = ck_pr_load_uint(&ring->p_tail);
   1f388:	8b 45 08             	mov    0x8(%ebp),%eax
   1f38b:	83 c0 40             	add    $0x40,%eax
   1f38e:	89 04 24             	mov    %eax,(%esp)
   1f391:	e8 75 f2 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f396:	89 45 f8             	mov    %eax,-0x8(%ebp)
	return (p - c) & ring->mask;
   1f399:	8b 45 fc             	mov    -0x4(%ebp),%eax
   1f39c:	8b 55 f8             	mov    -0x8(%ebp),%edx
   1f39f:	29 c2                	sub    %eax,%edx
   1f3a1:	8b 45 08             	mov    0x8(%ebp),%eax
   1f3a4:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1f3aa:	21 d0                	and    %edx,%eax
}
   1f3ac:	c9                   	leave  
   1f3ad:	c3                   	ret    

0001f3ae <ck_ring_capacity>:

CK_CC_INLINE static unsigned int
ck_ring_capacity(const struct ck_ring *ring)
{
   1f3ae:	55                   	push   %ebp
   1f3af:	89 e5                	mov    %esp,%ebp
	return ring->size;
   1f3b1:	8b 45 08             	mov    0x8(%ebp),%eax
   1f3b4:	8b 80 80 00 00 00    	mov    0x80(%eax),%eax
}
   1f3ba:	5d                   	pop    %ebp
   1f3bb:	c3                   	ret    

0001f3bc <ck_ring_init>:

CK_CC_INLINE static void
ck_ring_init(struct ck_ring *ring, unsigned int size)
{
   1f3bc:	55                   	push   %ebp
   1f3bd:	89 e5                	mov    %esp,%ebp

	ring->size = size;
   1f3bf:	8b 45 08             	mov    0x8(%ebp),%eax
   1f3c2:	8b 55 0c             	mov    0xc(%ebp),%edx
   1f3c5:	89 90 80 00 00 00    	mov    %edx,0x80(%eax)
	ring->mask = size - 1;
   1f3cb:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f3ce:	8d 50 ff             	lea    -0x1(%eax),%edx
   1f3d1:	8b 45 08             	mov    0x8(%ebp),%eax
   1f3d4:	89 90 84 00 00 00    	mov    %edx,0x84(%eax)
	ring->p_tail = 0;
   1f3da:	8b 45 08             	mov    0x8(%ebp),%eax
   1f3dd:	c7 40 40 00 00 00 00 	movl   $0x0,0x40(%eax)
	ring->p_head = 0;
   1f3e4:	8b 45 08             	mov    0x8(%ebp),%eax
   1f3e7:	c7 40 44 00 00 00 00 	movl   $0x0,0x44(%eax)
	ring->c_head = 0;
   1f3ee:	8b 45 08             	mov    0x8(%ebp),%eax
   1f3f1:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
	return;
   1f3f7:	90                   	nop
}
   1f3f8:	5d                   	pop    %ebp
   1f3f9:	c3                   	ret    

0001f3fa <ck_ring_enqueue_spsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1f3fa:	55                   	push   %ebp
   1f3fb:	89 e5                	mov    %esp,%ebp
   1f3fd:	83 ec 58             	sub    $0x58,%esp
   1f400:	8b 45 08             	mov    0x8(%ebp),%eax
   1f403:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1f406:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f409:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1f40c:	8d 45 10             	lea    0x10(%ebp),%eax
   1f40f:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1f412:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1f419:	8b 45 14             	mov    0x14(%ebp),%eax
   1f41c:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1f41f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f422:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1f425:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1f428:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1f42b:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1f42e:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1f431:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1f434:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1f437:	8d 45 b8             	lea    -0x48(%ebp),%eax
   1f43a:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1f43d:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f440:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1f446:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1f449:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f44c:	89 04 24             	mov    %eax,(%esp)
   1f44f:	e8 b7 f1 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f454:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   1f457:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f45a:	8b 40 40             	mov    0x40(%eax),%eax
   1f45d:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1f460:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1f463:	83 c0 01             	add    $0x1,%eax
   1f466:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   1f469:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1f46d:	74 14                	je     1f483 <ck_ring_enqueue_spsc_size+0x89>
		*size = (producer - consumer) & mask;
   1f46f:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1f472:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   1f475:	29 c2                	sub    %eax,%edx
   1f477:	89 d0                	mov    %edx,%eax
   1f479:	23 45 cc             	and    -0x34(%ebp),%eax
   1f47c:	89 c2                	mov    %eax,%edx
   1f47e:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1f481:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1f483:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1f486:	8b 55 c8             	mov    -0x38(%ebp),%edx
   1f489:	31 d0                	xor    %edx,%eax
   1f48b:	23 45 cc             	and    -0x34(%ebp),%eax
   1f48e:	85 c0                	test   %eax,%eax
   1f490:	0f 94 c0             	sete   %al
   1f493:	0f b6 c0             	movzbl %al,%eax
   1f496:	85 c0                	test   %eax,%eax
   1f498:	74 07                	je     1f4a1 <ck_ring_enqueue_spsc_size+0xa7>
		return false;
   1f49a:	b8 00 00 00 00       	mov    $0x0,%eax
   1f49f:	eb 47                	jmp    1f4e8 <ck_ring_enqueue_spsc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1f4a1:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1f4a4:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1f4a7:	21 d0                	and    %edx,%eax
   1f4a9:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1f4ad:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1f4b0:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1f4b3:	89 44 24 08          	mov    %eax,0x8(%esp)
   1f4b7:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1f4ba:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f4be:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1f4c1:	89 04 24             	mov    %eax,(%esp)
   1f4c4:	e8 fc ff ff ff       	call   1f4c5 <ck_ring_enqueue_spsc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1f4c9:	e8 53 fe ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1f4ce:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f4d1:	8d 50 40             	lea    0x40(%eax),%edx
   1f4d4:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1f4d7:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f4db:	89 14 24             	mov    %edx,(%esp)
   1f4de:	e8 b1 f1 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   1f4e3:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   1f4e8:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   1f4eb:	8b 55 b8             	mov    -0x48(%ebp),%edx
   1f4ee:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1f4f1:	89 10                	mov    %edx,(%eax)
	return r;
   1f4f3:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   1f4f7:	c9                   	leave  
   1f4f8:	c3                   	ret    

0001f4f9 <ck_ring_enqueue_spsc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1f4f9:	55                   	push   %ebp
   1f4fa:	89 e5                	mov    %esp,%ebp
   1f4fc:	83 ec 48             	sub    $0x48,%esp
   1f4ff:	8b 45 08             	mov    0x8(%ebp),%eax
   1f502:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1f505:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f508:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1f50b:	8d 45 10             	lea    0x10(%ebp),%eax
   1f50e:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1f511:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1f518:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1f51f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f522:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1f528:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1f52b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f52e:	89 04 24             	mov    %eax,(%esp)
   1f531:	e8 d5 f0 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f536:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   1f539:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f53c:	8b 40 40             	mov    0x40(%eax),%eax
   1f53f:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1f542:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1f545:	83 c0 01             	add    $0x1,%eax
   1f548:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   1f54b:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1f54f:	74 14                	je     1f565 <ck_ring_enqueue_spsc+0x6c>
		*size = (producer - consumer) & mask;
   1f551:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1f554:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1f557:	29 c2                	sub    %eax,%edx
   1f559:	89 d0                	mov    %edx,%eax
   1f55b:	23 45 e0             	and    -0x20(%ebp),%eax
   1f55e:	89 c2                	mov    %eax,%edx
   1f560:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1f563:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1f565:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1f568:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1f56b:	31 d0                	xor    %edx,%eax
   1f56d:	23 45 e0             	and    -0x20(%ebp),%eax
   1f570:	85 c0                	test   %eax,%eax
   1f572:	0f 94 c0             	sete   %al
   1f575:	0f b6 c0             	movzbl %al,%eax
   1f578:	85 c0                	test   %eax,%eax
   1f57a:	74 07                	je     1f583 <ck_ring_enqueue_spsc+0x8a>
		return false;
   1f57c:	b8 00 00 00 00       	mov    $0x0,%eax
   1f581:	eb 47                	jmp    1f5ca <ck_ring_enqueue_spsc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1f583:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1f586:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1f589:	21 d0                	and    %edx,%eax
   1f58b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1f58f:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1f592:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1f595:	89 44 24 08          	mov    %eax,0x8(%esp)
   1f599:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1f59c:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f5a0:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1f5a3:	89 04 24             	mov    %eax,(%esp)
   1f5a6:	e8 fc ff ff ff       	call   1f5a7 <ck_ring_enqueue_spsc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1f5ab:	e8 71 fd ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1f5b0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f5b3:	8d 50 40             	lea    0x40(%eax),%edx
   1f5b6:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1f5b9:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f5bd:	89 14 24             	mov    %edx,(%esp)
   1f5c0:	e8 cf f0 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   1f5c5:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer,
	    &entry, sizeof(entry), NULL);
}
   1f5ca:	c9                   	leave  
   1f5cb:	c3                   	ret    

0001f5cc <ck_ring_dequeue_spsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1f5cc:	55                   	push   %ebp
   1f5cd:	89 e5                	mov    %esp,%ebp
   1f5cf:	83 ec 38             	sub    $0x38,%esp
   1f5d2:	8b 45 08             	mov    0x8(%ebp),%eax
   1f5d5:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1f5d8:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f5db:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1f5de:	8b 45 10             	mov    0x10(%ebp),%eax
   1f5e1:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1f5e4:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1f5eb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f5ee:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1f5f4:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   1f5f7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f5fa:	8b 00                	mov    (%eax),%eax
   1f5fc:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   1f5ff:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f602:	83 c0 40             	add    $0x40,%eax
   1f605:	89 04 24             	mov    %eax,(%esp)
   1f608:	e8 fe ef ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f60d:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1f610:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f613:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1f616:	0f 94 c0             	sete   %al
   1f619:	0f b6 c0             	movzbl %al,%eax
   1f61c:	85 c0                	test   %eax,%eax
   1f61e:	74 07                	je     1f627 <ck_ring_dequeue_spsc+0x5b>
		return false;
   1f620:	b8 00 00 00 00       	mov    $0x0,%eax
   1f625:	eb 4c                	jmp    1f673 <ck_ring_dequeue_spsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   1f627:	e8 ea fc ff ff       	call   1f316 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1f62c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f62f:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1f632:	21 d0                	and    %edx,%eax
   1f634:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1f638:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   1f63b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1f63e:	89 44 24 08          	mov    %eax,0x8(%esp)
   1f642:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1f645:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f649:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1f64c:	89 04 24             	mov    %eax,(%esp)
   1f64f:	e8 fc ff ff ff       	call   1f650 <ck_ring_dequeue_spsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   1f654:	e8 c8 fc ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   1f659:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f65c:	8d 50 01             	lea    0x1(%eax),%edx
   1f65f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f662:	89 54 24 04          	mov    %edx,0x4(%esp)
   1f666:	89 04 24             	mov    %eax,(%esp)
   1f669:	e8 26 f0 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   1f66e:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer,
	    (void **)data, sizeof(void *));
}
   1f673:	c9                   	leave  
   1f674:	c3                   	ret    

0001f675 <ck_ring_enqueue_mpmc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1f675:	55                   	push   %ebp
   1f676:	89 e5                	mov    %esp,%ebp
   1f678:	83 ec 48             	sub    $0x48,%esp
   1f67b:	8b 45 08             	mov    0x8(%ebp),%eax
   1f67e:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1f681:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f684:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1f687:	8d 45 10             	lea    0x10(%ebp),%eax
   1f68a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1f68d:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1f694:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1f69b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f69e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1f6a4:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1f6a7:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1f6ab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f6ae:	83 c0 44             	add    $0x44,%eax
   1f6b1:	89 04 24             	mov    %eax,(%esp)
   1f6b4:	e8 52 ef ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f6b9:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1f6bc:	e8 55 fc ff ff       	call   1f316 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1f6c1:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f6c4:	89 04 24             	mov    %eax,(%esp)
   1f6c7:	e8 3f ef ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f6cc:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1f6cf:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1f6d2:	83 c0 01             	add    $0x1,%eax
   1f6d5:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1f6d8:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1f6db:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1f6de:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1f6e1:	0f 97 c0             	seta   %al
   1f6e4:	0f b6 c0             	movzbl %al,%eax
   1f6e7:	85 c0                	test   %eax,%eax
   1f6e9:	74 29                	je     1f714 <ck_ring_enqueue_mpmc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1f6eb:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1f6ee:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1f6f1:	8d 4a 44             	lea    0x44(%edx),%ecx
   1f6f4:	8d 55 cc             	lea    -0x34(%ebp),%edx
   1f6f7:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1f6fb:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   1f6fe:	89 54 24 08          	mov    %edx,0x8(%esp)
   1f702:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f706:	89 0c 24             	mov    %ecx,(%esp)
   1f709:	e8 fe f8 ff ff       	call   1f00c <ck_pr_cas_uint_value>
   1f70e:	84 c0                	test   %al,%al
   1f710:	75 31                	jne    1f743 <ck_ring_enqueue_mpmc+0xce>
   1f712:	eb a8                	jmp    1f6bc <ck_ring_enqueue_mpmc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1f714:	e8 fd fb ff ff       	call   1f316 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1f719:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f71c:	83 c0 44             	add    $0x44,%eax
   1f71f:	89 04 24             	mov    %eax,(%esp)
   1f722:	e8 e4 ee ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f727:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1f72a:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1f72d:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   1f730:	75 06                	jne    1f738 <ck_ring_enqueue_mpmc+0xc3>
				r = false;
   1f732:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1f736:	eb 67                	jmp    1f79f <ck_ring_enqueue_mpmc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1f738:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1f73b:	89 45 cc             	mov    %eax,-0x34(%ebp)
   1f73e:	e9 79 ff ff ff       	jmp    1f6bc <ck_ring_enqueue_mpmc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1f743:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1f746:	23 45 e0             	and    -0x20(%ebp),%eax
   1f749:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1f74d:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1f750:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1f753:	89 44 24 08          	mov    %eax,0x8(%esp)
   1f757:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1f75a:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f75e:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1f761:	89 04 24             	mov    %eax,(%esp)
   1f764:	e8 fc ff ff ff       	call   1f765 <ck_ring_enqueue_mpmc+0xf0>
   1f769:	eb 05                	jmp    1f770 <ck_ring_enqueue_mpmc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1f76b:	e8 36 ed ff ff       	call   1e4a6 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1f770:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f773:	83 c0 40             	add    $0x40,%eax
   1f776:	89 04 24             	mov    %eax,(%esp)
   1f779:	e8 8d ee ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f77e:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1f781:	39 d0                	cmp    %edx,%eax
   1f783:	75 e6                	jne    1f76b <ck_ring_enqueue_mpmc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1f785:	e8 97 fb ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1f78a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f78d:	8d 50 40             	lea    0x40(%eax),%edx
   1f790:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1f793:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f797:	89 14 24             	mov    %edx,(%esp)
   1f79a:	e8 f5 ee ff ff       	call   1e694 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1f79f:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1f7a3:	74 10                	je     1f7b5 <ck_ring_enqueue_mpmc+0x140>
		*size = (producer - consumer) & mask;
   1f7a5:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1f7a8:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1f7ab:	23 45 e0             	and    -0x20(%ebp),%eax
   1f7ae:	89 c2                	mov    %eax,%edx
   1f7b0:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1f7b3:	89 10                	mov    %edx,(%eax)

	return r;
   1f7b5:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   1f7b9:	c9                   	leave  
   1f7ba:	c3                   	ret    

0001f7bb <ck_ring_enqueue_mpmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1f7bb:	55                   	push   %ebp
   1f7bc:	89 e5                	mov    %esp,%ebp
   1f7be:	83 ec 68             	sub    $0x68,%esp
   1f7c1:	8b 45 08             	mov    0x8(%ebp),%eax
   1f7c4:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1f7c7:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f7ca:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1f7cd:	8d 45 10             	lea    0x10(%ebp),%eax
   1f7d0:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1f7d3:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1f7da:	8b 45 14             	mov    0x14(%ebp),%eax
   1f7dd:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1f7e0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f7e3:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1f7e6:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1f7e9:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1f7ec:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1f7ef:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1f7f2:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1f7f5:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1f7f8:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1f7fb:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1f7fe:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f801:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1f807:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1f80a:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1f80e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f811:	83 c0 44             	add    $0x44,%eax
   1f814:	89 04 24             	mov    %eax,(%esp)
   1f817:	e8 ef ed ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f81c:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1f81f:	e8 f2 fa ff ff       	call   1f316 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1f824:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f827:	89 04 24             	mov    %eax,(%esp)
   1f82a:	e8 dc ed ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f82f:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   1f832:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1f835:	83 c0 01             	add    $0x1,%eax
   1f838:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1f83b:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1f83e:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1f841:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   1f844:	0f 97 c0             	seta   %al
   1f847:	0f b6 c0             	movzbl %al,%eax
   1f84a:	85 c0                	test   %eax,%eax
   1f84c:	74 29                	je     1f877 <ck_ring_enqueue_mpmc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1f84e:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1f851:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1f854:	8d 4a 44             	lea    0x44(%edx),%ecx
   1f857:	8d 55 b0             	lea    -0x50(%ebp),%edx
   1f85a:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1f85e:	8b 55 c0             	mov    -0x40(%ebp),%edx
   1f861:	89 54 24 08          	mov    %edx,0x8(%esp)
   1f865:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f869:	89 0c 24             	mov    %ecx,(%esp)
   1f86c:	e8 9b f7 ff ff       	call   1f00c <ck_pr_cas_uint_value>
   1f871:	84 c0                	test   %al,%al
   1f873:	75 31                	jne    1f8a6 <ck_ring_enqueue_mpmc_size+0xeb>
   1f875:	eb a8                	jmp    1f81f <ck_ring_enqueue_mpmc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1f877:	e8 9a fa ff ff       	call   1f316 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1f87c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f87f:	83 c0 44             	add    $0x44,%eax
   1f882:	89 04 24             	mov    %eax,(%esp)
   1f885:	e8 81 ed ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f88a:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1f88d:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1f890:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   1f893:	75 06                	jne    1f89b <ck_ring_enqueue_mpmc_size+0xe0>
				r = false;
   1f895:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   1f899:	eb 67                	jmp    1f902 <ck_ring_enqueue_mpmc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1f89b:	8b 45 bc             	mov    -0x44(%ebp),%eax
   1f89e:	89 45 b0             	mov    %eax,-0x50(%ebp)
   1f8a1:	e9 79 ff ff ff       	jmp    1f81f <ck_ring_enqueue_mpmc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1f8a6:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1f8a9:	23 45 cc             	and    -0x34(%ebp),%eax
   1f8ac:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1f8b0:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1f8b3:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1f8b6:	89 44 24 08          	mov    %eax,0x8(%esp)
   1f8ba:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1f8bd:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f8c1:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1f8c4:	89 04 24             	mov    %eax,(%esp)
   1f8c7:	e8 fc ff ff ff       	call   1f8c8 <ck_ring_enqueue_mpmc_size+0x10d>
   1f8cc:	eb 05                	jmp    1f8d3 <ck_ring_enqueue_mpmc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1f8ce:	e8 d3 eb ff ff       	call   1e4a6 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1f8d3:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f8d6:	83 c0 40             	add    $0x40,%eax
   1f8d9:	89 04 24             	mov    %eax,(%esp)
   1f8dc:	e8 2a ed ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f8e1:	8b 55 b0             	mov    -0x50(%ebp),%edx
   1f8e4:	39 d0                	cmp    %edx,%eax
   1f8e6:	75 e6                	jne    1f8ce <ck_ring_enqueue_mpmc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1f8e8:	e8 34 fa ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1f8ed:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f8f0:	8d 50 40             	lea    0x40(%eax),%edx
   1f8f3:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1f8f6:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f8fa:	89 14 24             	mov    %edx,(%esp)
   1f8fd:	e8 92 ed ff ff       	call   1e694 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1f902:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1f906:	74 10                	je     1f918 <ck_ring_enqueue_mpmc_size+0x15d>
		*size = (producer - consumer) & mask;
   1f908:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1f90b:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1f90e:	23 45 cc             	and    -0x34(%ebp),%eax
   1f911:	89 c2                	mov    %eax,%edx
   1f913:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1f916:	89 10                	mov    %edx,(%eax)

	return r;
   1f918:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   1f91c:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   1f91f:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   1f922:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1f925:	89 10                	mov    %edx,(%eax)
	return r;
   1f927:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   1f92b:	c9                   	leave  
   1f92c:	c3                   	ret    

0001f92d <ck_ring_trydequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1f92d:	55                   	push   %ebp
   1f92e:	89 e5                	mov    %esp,%ebp
   1f930:	83 ec 38             	sub    $0x38,%esp
   1f933:	8b 45 08             	mov    0x8(%ebp),%eax
   1f936:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1f939:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f93c:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1f93f:	8b 45 10             	mov    0x10(%ebp),%eax
   1f942:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1f945:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1f94c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f94f:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1f955:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1f958:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f95b:	89 04 24             	mov    %eax,(%esp)
   1f95e:	e8 a8 ec ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f963:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   1f966:	e8 ab f9 ff ff       	call   1f316 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   1f96b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f96e:	83 c0 40             	add    $0x40,%eax
   1f971:	89 04 24             	mov    %eax,(%esp)
   1f974:	e8 92 ec ff ff       	call   1e60b <ck_pr_md_load_uint>
   1f979:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1f97c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f97f:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1f982:	0f 94 c0             	sete   %al
   1f985:	0f b6 c0             	movzbl %al,%eax
   1f988:	85 c0                	test   %eax,%eax
   1f98a:	74 07                	je     1f993 <ck_ring_trydequeue_mpmc+0x66>
		return false;
   1f98c:	b8 00 00 00 00       	mov    $0x0,%eax
   1f991:	eb 4e                	jmp    1f9e1 <ck_ring_trydequeue_mpmc+0xb4>

	ck_pr_fence_load();
   1f993:	e8 7e f9 ff ff       	call   1f316 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1f998:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f99b:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1f99e:	21 d0                	and    %edx,%eax
   1f9a0:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1f9a4:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1f9a7:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1f9aa:	89 44 24 08          	mov    %eax,0x8(%esp)
   1f9ae:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1f9b1:	89 44 24 04          	mov    %eax,0x4(%esp)
   1f9b5:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1f9b8:	89 04 24             	mov    %eax,(%esp)
   1f9bb:	e8 fc ff ff ff       	call   1f9bc <ck_ring_trydequeue_mpmc+0x8f>

	ck_pr_fence_store_atomic();
   1f9c0:	e8 25 f9 ff ff       	call   1f2ea <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1f9c5:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1f9c8:	8d 50 01             	lea    0x1(%eax),%edx
   1f9cb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1f9ce:	89 54 24 08          	mov    %edx,0x8(%esp)
   1f9d2:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1f9d5:	89 54 24 04          	mov    %edx,0x4(%esp)
   1f9d9:	89 04 24             	mov    %eax,(%esp)
   1f9dc:	e8 d8 f4 ff ff       	call   1eeb9 <ck_pr_cas_uint>
    void *data)
{

	return _ck_ring_trydequeue_mc(ring,
	    buffer, (void **)data, sizeof(void *));
}
   1f9e1:	c9                   	leave  
   1f9e2:	c3                   	ret    

0001f9e3 <ck_ring_dequeue_mpmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1f9e3:	55                   	push   %ebp
   1f9e4:	89 e5                	mov    %esp,%ebp
   1f9e6:	53                   	push   %ebx
   1f9e7:	83 ec 34             	sub    $0x34,%esp
   1f9ea:	8b 45 08             	mov    0x8(%ebp),%eax
   1f9ed:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1f9f0:	8b 45 0c             	mov    0xc(%ebp),%eax
   1f9f3:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1f9f6:	8b 45 10             	mov    0x10(%ebp),%eax
   1f9f9:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1f9fc:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   1fa03:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fa06:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1fa0c:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1fa0f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fa12:	89 04 24             	mov    %eax,(%esp)
   1fa15:	e8 f1 eb ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fa1a:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   1fa1d:	e8 f4 f8 ff ff       	call   1f316 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   1fa22:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fa25:	83 c0 40             	add    $0x40,%eax
   1fa28:	89 04 24             	mov    %eax,(%esp)
   1fa2b:	e8 db eb ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fa30:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   1fa33:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fa36:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1fa39:	0f 94 c0             	sete   %al
   1fa3c:	0f b6 c0             	movzbl %al,%eax
   1fa3f:	85 c0                	test   %eax,%eax
   1fa41:	74 07                	je     1fa4a <ck_ring_dequeue_mpmc+0x67>
			return false;
   1fa43:	b8 00 00 00 00       	mov    $0x0,%eax
   1fa48:	eb 6a                	jmp    1fab4 <ck_ring_dequeue_mpmc+0xd1>

		ck_pr_fence_load();
   1fa4a:	e8 c7 f8 ff ff       	call   1f316 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   1fa4f:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fa52:	23 45 e4             	and    -0x1c(%ebp),%eax
   1fa55:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1fa59:	89 c2                	mov    %eax,%edx
   1fa5b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1fa5e:	01 d0                	add    %edx,%eax
   1fa60:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   1fa63:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1fa66:	89 44 24 08          	mov    %eax,0x8(%esp)
   1fa6a:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1fa6d:	89 44 24 04          	mov    %eax,0x4(%esp)
   1fa71:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1fa74:	89 04 24             	mov    %eax,(%esp)
   1fa77:	e8 fc ff ff ff       	call   1fa78 <ck_ring_dequeue_mpmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   1fa7c:	e8 69 f8 ff ff       	call   1f2ea <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1fa81:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fa84:	8d 58 01             	lea    0x1(%eax),%ebx
   1fa87:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1fa8a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fa8d:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1fa90:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1fa94:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1fa98:	89 54 24 04          	mov    %edx,0x4(%esp)
   1fa9c:	89 04 24             	mov    %eax,(%esp)
   1fa9f:	e8 68 f5 ff ff       	call   1f00c <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   1faa4:	83 f0 01             	xor    $0x1,%eax
   1faa7:	84 c0                	test   %al,%al
   1faa9:	0f 85 6e ff ff ff    	jne    1fa1d <ck_ring_dequeue_mpmc+0x3a>

	return true;
   1faaf:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   1fab4:	83 c4 34             	add    $0x34,%esp
   1fab7:	5b                   	pop    %ebx
   1fab8:	5d                   	pop    %ebp
   1fab9:	c3                   	ret    

0001faba <ck_ring_enqueue_spmc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_spmc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1faba:	55                   	push   %ebp
   1fabb:	89 e5                	mov    %esp,%ebp
   1fabd:	83 ec 58             	sub    $0x58,%esp
   1fac0:	8b 45 08             	mov    0x8(%ebp),%eax
   1fac3:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1fac6:	8b 45 0c             	mov    0xc(%ebp),%eax
   1fac9:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1facc:	8d 45 10             	lea    0x10(%ebp),%eax
   1facf:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1fad2:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1fad9:	8b 45 14             	mov    0x14(%ebp),%eax
   1fadc:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1fadf:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fae2:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1fae5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1fae8:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1faeb:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1faee:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1faf1:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1faf4:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1faf7:	8d 45 b8             	lea    -0x48(%ebp),%eax
   1fafa:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1fafd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1fb00:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1fb06:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1fb09:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1fb0c:	89 04 24             	mov    %eax,(%esp)
   1fb0f:	e8 f7 ea ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fb14:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   1fb17:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1fb1a:	8b 40 40             	mov    0x40(%eax),%eax
   1fb1d:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   1fb20:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1fb23:	83 c0 01             	add    $0x1,%eax
   1fb26:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   1fb29:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   1fb2d:	74 14                	je     1fb43 <ck_ring_enqueue_spmc_size+0x89>
		*size = (producer - consumer) & mask;
   1fb2f:	8b 45 c8             	mov    -0x38(%ebp),%eax
   1fb32:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   1fb35:	29 c2                	sub    %eax,%edx
   1fb37:	89 d0                	mov    %edx,%eax
   1fb39:	23 45 cc             	and    -0x34(%ebp),%eax
   1fb3c:	89 c2                	mov    %eax,%edx
   1fb3e:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1fb41:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1fb43:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1fb46:	8b 55 c8             	mov    -0x38(%ebp),%edx
   1fb49:	31 d0                	xor    %edx,%eax
   1fb4b:	23 45 cc             	and    -0x34(%ebp),%eax
   1fb4e:	85 c0                	test   %eax,%eax
   1fb50:	0f 94 c0             	sete   %al
   1fb53:	0f b6 c0             	movzbl %al,%eax
   1fb56:	85 c0                	test   %eax,%eax
   1fb58:	74 07                	je     1fb61 <ck_ring_enqueue_spmc_size+0xa7>
		return false;
   1fb5a:	b8 00 00 00 00       	mov    $0x0,%eax
   1fb5f:	eb 47                	jmp    1fba8 <ck_ring_enqueue_spmc_size+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   1fb61:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   1fb64:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1fb67:	21 d0                	and    %edx,%eax
   1fb69:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   1fb6d:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   1fb70:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1fb73:	89 44 24 08          	mov    %eax,0x8(%esp)
   1fb77:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fb7a:	89 44 24 04          	mov    %eax,0x4(%esp)
   1fb7e:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1fb81:	89 04 24             	mov    %eax,(%esp)
   1fb84:	e8 fc ff ff ff       	call   1fb85 <ck_ring_enqueue_spmc_size+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1fb89:	e8 93 f7 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1fb8e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1fb91:	8d 50 40             	lea    0x40(%eax),%edx
   1fb94:	8b 45 c0             	mov    -0x40(%ebp),%eax
   1fb97:	89 44 24 04          	mov    %eax,0x4(%esp)
   1fb9b:	89 14 24             	mov    %edx,(%esp)
   1fb9e:	e8 f1 ea ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   1fba3:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   1fba8:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   1fbab:	8b 55 b8             	mov    -0x48(%ebp),%edx
   1fbae:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1fbb1:	89 10                	mov    %edx,(%eax)
	return r;
   1fbb3:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_sp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   1fbb7:	c9                   	leave  
   1fbb8:	c3                   	ret    

0001fbb9 <ck_ring_enqueue_spmc>:

CK_CC_INLINE static bool
ck_ring_enqueue_spmc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1fbb9:	55                   	push   %ebp
   1fbba:	89 e5                	mov    %esp,%ebp
   1fbbc:	83 ec 48             	sub    $0x48,%esp
   1fbbf:	8b 45 08             	mov    0x8(%ebp),%eax
   1fbc2:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1fbc5:	8b 45 0c             	mov    0xc(%ebp),%eax
   1fbc8:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1fbcb:	8d 45 10             	lea    0x10(%ebp),%eax
   1fbce:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1fbd1:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1fbd8:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1fbdf:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fbe2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1fbe8:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   1fbeb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fbee:	89 04 24             	mov    %eax,(%esp)
   1fbf1:	e8 15 ea ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fbf6:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   1fbf9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fbfc:	8b 40 40             	mov    0x40(%eax),%eax
   1fbff:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   1fc02:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fc05:	83 c0 01             	add    $0x1,%eax
   1fc08:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   1fc0b:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1fc0f:	74 14                	je     1fc25 <ck_ring_enqueue_spmc+0x6c>
		*size = (producer - consumer) & mask;
   1fc11:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1fc14:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1fc17:	29 c2                	sub    %eax,%edx
   1fc19:	89 d0                	mov    %edx,%eax
   1fc1b:	23 45 e0             	and    -0x20(%ebp),%eax
   1fc1e:	89 c2                	mov    %eax,%edx
   1fc20:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1fc23:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   1fc25:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1fc28:	8b 55 dc             	mov    -0x24(%ebp),%edx
   1fc2b:	31 d0                	xor    %edx,%eax
   1fc2d:	23 45 e0             	and    -0x20(%ebp),%eax
   1fc30:	85 c0                	test   %eax,%eax
   1fc32:	0f 94 c0             	sete   %al
   1fc35:	0f b6 c0             	movzbl %al,%eax
   1fc38:	85 c0                	test   %eax,%eax
   1fc3a:	74 07                	je     1fc43 <ck_ring_enqueue_spmc+0x8a>
		return false;
   1fc3c:	b8 00 00 00 00       	mov    $0x0,%eax
   1fc41:	eb 47                	jmp    1fc8a <ck_ring_enqueue_spmc+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   1fc43:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fc46:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1fc49:	21 d0                	and    %edx,%eax
   1fc4b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1fc4f:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1fc52:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1fc55:	89 44 24 08          	mov    %eax,0x8(%esp)
   1fc59:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1fc5c:	89 44 24 04          	mov    %eax,0x4(%esp)
   1fc60:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1fc63:	89 04 24             	mov    %eax,(%esp)
   1fc66:	e8 fc ff ff ff       	call   1fc67 <ck_ring_enqueue_spmc+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   1fc6b:	e8 b1 f6 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1fc70:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fc73:	8d 50 40             	lea    0x40(%eax),%edx
   1fc76:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1fc79:	89 44 24 04          	mov    %eax,0x4(%esp)
   1fc7d:	89 14 24             	mov    %edx,(%esp)
   1fc80:	e8 0f ea ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   1fc85:	b8 01 00 00 00       	mov    $0x1,%eax
    const void *entry)
{

	return _ck_ring_enqueue_sp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   1fc8a:	c9                   	leave  
   1fc8b:	c3                   	ret    

0001fc8c <ck_ring_trydequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_trydequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1fc8c:	55                   	push   %ebp
   1fc8d:	89 e5                	mov    %esp,%ebp
   1fc8f:	83 ec 38             	sub    $0x38,%esp
   1fc92:	8b 45 08             	mov    0x8(%ebp),%eax
   1fc95:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1fc98:	8b 45 0c             	mov    0xc(%ebp),%eax
   1fc9b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1fc9e:	8b 45 10             	mov    0x10(%ebp),%eax
   1fca1:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1fca4:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   1fcab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fcae:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1fcb4:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1fcb7:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fcba:	89 04 24             	mov    %eax,(%esp)
   1fcbd:	e8 49 e9 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fcc2:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   1fcc5:	e8 4c f6 ff ff       	call   1f316 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   1fcca:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fccd:	83 c0 40             	add    $0x40,%eax
   1fcd0:	89 04 24             	mov    %eax,(%esp)
   1fcd3:	e8 33 e9 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fcd8:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   1fcdb:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1fcde:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   1fce1:	0f 94 c0             	sete   %al
   1fce4:	0f b6 c0             	movzbl %al,%eax
   1fce7:	85 c0                	test   %eax,%eax
   1fce9:	74 07                	je     1fcf2 <ck_ring_trydequeue_spmc+0x66>
		return false;
   1fceb:	b8 00 00 00 00       	mov    $0x0,%eax
   1fcf0:	eb 4e                	jmp    1fd40 <ck_ring_trydequeue_spmc+0xb4>

	ck_pr_fence_load();
   1fcf2:	e8 1f f6 ff ff       	call   1f316 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   1fcf7:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1fcfa:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   1fcfd:	21 d0                	and    %edx,%eax
   1fcff:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1fd03:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   1fd06:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1fd09:	89 44 24 08          	mov    %eax,0x8(%esp)
   1fd0d:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1fd10:	89 44 24 04          	mov    %eax,0x4(%esp)
   1fd14:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1fd17:	89 04 24             	mov    %eax,(%esp)
   1fd1a:	e8 fc ff ff ff       	call   1fd1b <ck_ring_trydequeue_spmc+0x8f>

	ck_pr_fence_store_atomic();
   1fd1f:	e8 c6 f5 ff ff       	call   1f2ea <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   1fd24:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1fd27:	8d 50 01             	lea    0x1(%eax),%edx
   1fd2a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fd2d:	89 54 24 08          	mov    %edx,0x8(%esp)
   1fd31:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1fd34:	89 54 24 04          	mov    %edx,0x4(%esp)
   1fd38:	89 04 24             	mov    %eax,(%esp)
   1fd3b:	e8 79 f1 ff ff       	call   1eeb9 <ck_pr_cas_uint>
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_trydequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   1fd40:	c9                   	leave  
   1fd41:	c3                   	ret    

0001fd42 <ck_ring_dequeue_spmc>:

CK_CC_INLINE static bool
ck_ring_dequeue_spmc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   1fd42:	55                   	push   %ebp
   1fd43:	89 e5                	mov    %esp,%ebp
   1fd45:	53                   	push   %ebx
   1fd46:	83 ec 34             	sub    $0x34,%esp
   1fd49:	8b 45 08             	mov    0x8(%ebp),%eax
   1fd4c:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1fd4f:	8b 45 0c             	mov    0xc(%ebp),%eax
   1fd52:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1fd55:	8b 45 10             	mov    0x10(%ebp),%eax
   1fd58:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1fd5b:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   1fd62:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fd65:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1fd6b:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   1fd6e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fd71:	89 04 24             	mov    %eax,(%esp)
   1fd74:	e8 92 e8 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fd79:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   1fd7c:	e8 95 f5 ff ff       	call   1f316 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   1fd81:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fd84:	83 c0 40             	add    $0x40,%eax
   1fd87:	89 04 24             	mov    %eax,(%esp)
   1fd8a:	e8 7c e8 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fd8f:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   1fd92:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fd95:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1fd98:	0f 94 c0             	sete   %al
   1fd9b:	0f b6 c0             	movzbl %al,%eax
   1fd9e:	85 c0                	test   %eax,%eax
   1fda0:	74 07                	je     1fda9 <ck_ring_dequeue_spmc+0x67>
			return false;
   1fda2:	b8 00 00 00 00       	mov    $0x0,%eax
   1fda7:	eb 6a                	jmp    1fe13 <ck_ring_dequeue_spmc+0xd1>

		ck_pr_fence_load();
   1fda9:	e8 68 f5 ff ff       	call   1f316 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   1fdae:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fdb1:	23 45 e4             	and    -0x1c(%ebp),%eax
   1fdb4:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1fdb8:	89 c2                	mov    %eax,%edx
   1fdba:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1fdbd:	01 d0                	add    %edx,%eax
   1fdbf:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   1fdc2:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1fdc5:	89 44 24 08          	mov    %eax,0x8(%esp)
   1fdc9:	8b 45 dc             	mov    -0x24(%ebp),%eax
   1fdcc:	89 44 24 04          	mov    %eax,0x4(%esp)
   1fdd0:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1fdd3:	89 04 24             	mov    %eax,(%esp)
   1fdd6:	e8 fc ff ff ff       	call   1fdd7 <ck_ring_dequeue_spmc+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   1fddb:	e8 0a f5 ff ff       	call   1f2ea <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   1fde0:	8b 45 d8             	mov    -0x28(%ebp),%eax
   1fde3:	8d 58 01             	lea    0x1(%eax),%ebx
   1fde6:	8b 55 d8             	mov    -0x28(%ebp),%edx
   1fde9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fdec:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   1fdef:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   1fdf3:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   1fdf7:	89 54 24 04          	mov    %edx,0x4(%esp)
   1fdfb:	89 04 24             	mov    %eax,(%esp)
   1fdfe:	e8 09 f2 ff ff       	call   1f00c <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   1fe03:	83 f0 01             	xor    $0x1,%eax
   1fe06:	84 c0                	test   %al,%al
   1fe08:	0f 85 6e ff ff ff    	jne    1fd7c <ck_ring_dequeue_spmc+0x3a>

	return true;
   1fe0e:	b8 01 00 00 00       	mov    $0x1,%eax
    const struct ck_ring_buffer *buffer,
    void *data)
{

	return _ck_ring_dequeue_mc(ring, buffer, (void **)data, sizeof(void *));
}
   1fe13:	83 c4 34             	add    $0x34,%esp
   1fe16:	5b                   	pop    %ebx
   1fe17:	5d                   	pop    %ebp
   1fe18:	c3                   	ret    

0001fe19 <ck_ring_enqueue_mpsc>:
 */
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry)
{
   1fe19:	55                   	push   %ebp
   1fe1a:	89 e5                	mov    %esp,%ebp
   1fe1c:	83 ec 48             	sub    $0x48,%esp
   1fe1f:	8b 45 08             	mov    0x8(%ebp),%eax
   1fe22:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1fe25:	8b 45 0c             	mov    0xc(%ebp),%eax
   1fe28:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1fe2b:	8d 45 10             	lea    0x10(%ebp),%eax
   1fe2e:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1fe31:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1fe38:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1fe3f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fe42:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1fe48:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1fe4b:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1fe4f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fe52:	83 c0 44             	add    $0x44,%eax
   1fe55:	89 04 24             	mov    %eax,(%esp)
   1fe58:	e8 ae e7 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fe5d:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1fe60:	e8 b1 f4 ff ff       	call   1f316 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1fe65:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fe68:	89 04 24             	mov    %eax,(%esp)
   1fe6b:	e8 9b e7 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fe70:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   1fe73:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1fe76:	83 c0 01             	add    $0x1,%eax
   1fe79:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1fe7c:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1fe7f:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1fe82:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   1fe85:	0f 97 c0             	seta   %al
   1fe88:	0f b6 c0             	movzbl %al,%eax
   1fe8b:	85 c0                	test   %eax,%eax
   1fe8d:	74 29                	je     1feb8 <ck_ring_enqueue_mpsc+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1fe8f:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1fe92:	8b 55 f4             	mov    -0xc(%ebp),%edx
   1fe95:	8d 4a 44             	lea    0x44(%edx),%ecx
   1fe98:	8d 55 cc             	lea    -0x34(%ebp),%edx
   1fe9b:	89 54 24 0c          	mov    %edx,0xc(%esp)
   1fe9f:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   1fea2:	89 54 24 08          	mov    %edx,0x8(%esp)
   1fea6:	89 44 24 04          	mov    %eax,0x4(%esp)
   1feaa:	89 0c 24             	mov    %ecx,(%esp)
   1fead:	e8 5a f1 ff ff       	call   1f00c <ck_pr_cas_uint_value>
   1feb2:	84 c0                	test   %al,%al
   1feb4:	75 31                	jne    1fee7 <ck_ring_enqueue_mpsc+0xce>
   1feb6:	eb a8                	jmp    1fe60 <ck_ring_enqueue_mpsc+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   1feb8:	e8 59 f4 ff ff       	call   1f316 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   1febd:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1fec0:	83 c0 44             	add    $0x44,%eax
   1fec3:	89 04 24             	mov    %eax,(%esp)
   1fec6:	e8 40 e7 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1fecb:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   1fece:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1fed1:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   1fed4:	75 06                	jne    1fedc <ck_ring_enqueue_mpsc+0xc3>
				r = false;
   1fed6:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   1feda:	eb 67                	jmp    1ff43 <ck_ring_enqueue_mpsc+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   1fedc:	8b 45 d0             	mov    -0x30(%ebp),%eax
   1fedf:	89 45 cc             	mov    %eax,-0x34(%ebp)
   1fee2:	e9 79 ff ff ff       	jmp    1fe60 <ck_ring_enqueue_mpsc+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   1fee7:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1feea:	23 45 e0             	and    -0x20(%ebp),%eax
   1feed:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   1fef1:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   1fef4:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1fef7:	89 44 24 08          	mov    %eax,0x8(%esp)
   1fefb:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1fefe:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ff02:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1ff05:	89 04 24             	mov    %eax,(%esp)
   1ff08:	e8 fc ff ff ff       	call   1ff09 <ck_ring_enqueue_mpsc+0xf0>
   1ff0d:	eb 05                	jmp    1ff14 <ck_ring_enqueue_mpsc+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   1ff0f:	e8 92 e5 ff ff       	call   1e4a6 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   1ff14:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ff17:	83 c0 40             	add    $0x40,%eax
   1ff1a:	89 04 24             	mov    %eax,(%esp)
   1ff1d:	e8 e9 e6 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1ff22:	8b 55 cc             	mov    -0x34(%ebp),%edx
   1ff25:	39 d0                	cmp    %edx,%eax
   1ff27:	75 e6                	jne    1ff0f <ck_ring_enqueue_mpsc+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   1ff29:	e8 f3 f3 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   1ff2e:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ff31:	8d 50 40             	lea    0x40(%eax),%edx
   1ff34:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   1ff37:	89 44 24 04          	mov    %eax,0x4(%esp)
   1ff3b:	89 14 24             	mov    %edx,(%esp)
   1ff3e:	e8 51 e7 ff ff       	call   1e694 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   1ff43:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   1ff47:	74 10                	je     1ff59 <ck_ring_enqueue_mpsc+0x140>
		*size = (producer - consumer) & mask;
   1ff49:	8b 45 cc             	mov    -0x34(%ebp),%eax
   1ff4c:	2b 45 d8             	sub    -0x28(%ebp),%eax
   1ff4f:	23 45 e0             	and    -0x20(%ebp),%eax
   1ff52:	89 c2                	mov    %eax,%edx
   1ff54:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   1ff57:	89 10                	mov    %edx,(%eax)

	return r;
   1ff59:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
    const void *entry)
{

	return _ck_ring_enqueue_mp(ring, buffer, &entry,
	    sizeof(entry), NULL);
}
   1ff5d:	c9                   	leave  
   1ff5e:	c3                   	ret    

0001ff5f <ck_ring_enqueue_mpsc_size>:
CK_CC_INLINE static bool
ck_ring_enqueue_mpsc_size(struct ck_ring *ring,
    struct ck_ring_buffer *buffer,
    const void *entry,
    unsigned int *size)
{
   1ff5f:	55                   	push   %ebp
   1ff60:	89 e5                	mov    %esp,%ebp
   1ff62:	83 ec 68             	sub    $0x68,%esp
   1ff65:	8b 45 08             	mov    0x8(%ebp),%eax
   1ff68:	89 45 f4             	mov    %eax,-0xc(%ebp)
   1ff6b:	8b 45 0c             	mov    0xc(%ebp),%eax
   1ff6e:	89 45 f0             	mov    %eax,-0x10(%ebp)
   1ff71:	8d 45 10             	lea    0x10(%ebp),%eax
   1ff74:	89 45 ec             	mov    %eax,-0x14(%ebp)
   1ff77:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
   1ff7e:	8b 45 14             	mov    0x14(%ebp),%eax
   1ff81:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   1ff84:	8b 45 f4             	mov    -0xc(%ebp),%eax
   1ff87:	89 45 e0             	mov    %eax,-0x20(%ebp)
   1ff8a:	8b 45 f0             	mov    -0x10(%ebp),%eax
   1ff8d:	89 45 dc             	mov    %eax,-0x24(%ebp)
   1ff90:	8b 45 ec             	mov    -0x14(%ebp),%eax
   1ff93:	89 45 d8             	mov    %eax,-0x28(%ebp)
   1ff96:	8b 45 e8             	mov    -0x18(%ebp),%eax
   1ff99:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   1ff9c:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   1ff9f:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   1ffa2:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1ffa5:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   1ffab:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   1ffae:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   1ffb2:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1ffb5:	83 c0 44             	add    $0x44,%eax
   1ffb8:	89 04 24             	mov    %eax,(%esp)
   1ffbb:	e8 4b e6 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1ffc0:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   1ffc3:	e8 4e f3 ff ff       	call   1f316 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   1ffc8:	8b 45 e0             	mov    -0x20(%ebp),%eax
   1ffcb:	89 04 24             	mov    %eax,(%esp)
   1ffce:	e8 38 e6 ff ff       	call   1e60b <ck_pr_md_load_uint>
   1ffd3:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   1ffd6:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1ffd9:	83 c0 01             	add    $0x1,%eax
   1ffdc:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   1ffdf:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1ffe2:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   1ffe5:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   1ffe8:	0f 97 c0             	seta   %al
   1ffeb:	0f b6 c0             	movzbl %al,%eax
   1ffee:	85 c0                	test   %eax,%eax
   1fff0:	74 29                	je     2001b <ck_ring_enqueue_mpsc_size+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   1fff2:	8b 45 b0             	mov    -0x50(%ebp),%eax
   1fff5:	8b 55 e0             	mov    -0x20(%ebp),%edx
   1fff8:	8d 4a 44             	lea    0x44(%edx),%ecx
   1fffb:	8d 55 b0             	lea    -0x50(%ebp),%edx
   1fffe:	89 54 24 0c          	mov    %edx,0xc(%esp)
   20002:	8b 55 c0             	mov    -0x40(%ebp),%edx
   20005:	89 54 24 08          	mov    %edx,0x8(%esp)
   20009:	89 44 24 04          	mov    %eax,0x4(%esp)
   2000d:	89 0c 24             	mov    %ecx,(%esp)
   20010:	e8 f7 ef ff ff       	call   1f00c <ck_pr_cas_uint_value>
   20015:	84 c0                	test   %al,%al
   20017:	75 31                	jne    2004a <ck_ring_enqueue_mpsc_size+0xeb>
   20019:	eb a8                	jmp    1ffc3 <ck_ring_enqueue_mpsc_size+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   2001b:	e8 f6 f2 ff ff       	call   1f316 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   20020:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20023:	83 c0 44             	add    $0x44,%eax
   20026:	89 04 24             	mov    %eax,(%esp)
   20029:	e8 dd e5 ff ff       	call   1e60b <ck_pr_md_load_uint>
   2002e:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   20031:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20034:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   20037:	75 06                	jne    2003f <ck_ring_enqueue_mpsc_size+0xe0>
				r = false;
   20039:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   2003d:	eb 67                	jmp    200a6 <ck_ring_enqueue_mpsc_size+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   2003f:	8b 45 bc             	mov    -0x44(%ebp),%eax
   20042:	89 45 b0             	mov    %eax,-0x50(%ebp)
   20045:	e9 79 ff ff ff       	jmp    1ffc3 <ck_ring_enqueue_mpsc_size+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   2004a:	8b 45 b0             	mov    -0x50(%ebp),%eax
   2004d:	23 45 cc             	and    -0x34(%ebp),%eax
   20050:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   20054:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   20057:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   2005a:	89 44 24 08          	mov    %eax,0x8(%esp)
   2005e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   20061:	89 44 24 04          	mov    %eax,0x4(%esp)
   20065:	8b 45 dc             	mov    -0x24(%ebp),%eax
   20068:	89 04 24             	mov    %eax,(%esp)
   2006b:	e8 fc ff ff ff       	call   2006c <ck_ring_enqueue_mpsc_size+0x10d>
   20070:	eb 05                	jmp    20077 <ck_ring_enqueue_mpsc_size+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   20072:	e8 2f e4 ff ff       	call   1e4a6 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   20077:	8b 45 e0             	mov    -0x20(%ebp),%eax
   2007a:	83 c0 40             	add    $0x40,%eax
   2007d:	89 04 24             	mov    %eax,(%esp)
   20080:	e8 86 e5 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20085:	8b 55 b0             	mov    -0x50(%ebp),%edx
   20088:	39 d0                	cmp    %edx,%eax
   2008a:	75 e6                	jne    20072 <ck_ring_enqueue_mpsc_size+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   2008c:	e8 90 f2 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   20091:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20094:	8d 50 40             	lea    0x40(%eax),%edx
   20097:	8b 45 c0             	mov    -0x40(%ebp),%eax
   2009a:	89 44 24 04          	mov    %eax,0x4(%esp)
   2009e:	89 14 24             	mov    %edx,(%esp)
   200a1:	e8 ee e5 ff ff       	call   1e694 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   200a6:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   200aa:	74 10                	je     200bc <ck_ring_enqueue_mpsc_size+0x15d>
		*size = (producer - consumer) & mask;
   200ac:	8b 45 b0             	mov    -0x50(%ebp),%eax
   200af:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   200b2:	23 45 cc             	and    -0x34(%ebp),%eax
   200b5:	89 c2                	mov    %eax,%edx
   200b7:	8b 45 d0             	mov    -0x30(%ebp),%eax
   200ba:	89 10                	mov    %edx,(%eax)

	return r;
   200bc:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   200c0:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   200c3:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   200c6:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   200c9:	89 10                	mov    %edx,(%eax)
	return r;
   200cb:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
    unsigned int *size)
{

	return _ck_ring_enqueue_mp_size(ring, buffer, &entry,
	    sizeof(entry), size);
}
   200cf:	c9                   	leave  
   200d0:	c3                   	ret    

000200d1 <ck_ring_dequeue_mpsc>:

CK_CC_INLINE static bool
ck_ring_dequeue_mpsc(struct ck_ring *ring,
    const struct ck_ring_buffer *buffer,
    void *data)
{
   200d1:	55                   	push   %ebp
   200d2:	89 e5                	mov    %esp,%ebp
   200d4:	83 ec 38             	sub    $0x38,%esp
   200d7:	8b 45 08             	mov    0x8(%ebp),%eax
   200da:	89 45 f4             	mov    %eax,-0xc(%ebp)
   200dd:	8b 45 0c             	mov    0xc(%ebp),%eax
   200e0:	89 45 f0             	mov    %eax,-0x10(%ebp)
   200e3:	8b 45 10             	mov    0x10(%ebp),%eax
   200e6:	89 45 ec             	mov    %eax,-0x14(%ebp)
   200e9:	c7 45 e8 04 00 00 00 	movl   $0x4,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   200f0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   200f3:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   200f9:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   200fc:	8b 45 f4             	mov    -0xc(%ebp),%eax
   200ff:	8b 00                	mov    (%eax),%eax
   20101:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   20104:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20107:	83 c0 40             	add    $0x40,%eax
   2010a:	89 04 24             	mov    %eax,(%esp)
   2010d:	e8 f9 e4 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20112:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   20115:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20118:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   2011b:	0f 94 c0             	sete   %al
   2011e:	0f b6 c0             	movzbl %al,%eax
   20121:	85 c0                	test   %eax,%eax
   20123:	74 07                	je     2012c <ck_ring_dequeue_mpsc+0x5b>
		return false;
   20125:	b8 00 00 00 00       	mov    $0x0,%eax
   2012a:	eb 4c                	jmp    20178 <ck_ring_dequeue_mpsc+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   2012c:	e8 e5 f1 ff ff       	call   1f316 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   20131:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20134:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   20137:	21 d0                	and    %edx,%eax
   20139:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   2013d:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   20140:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20143:	89 44 24 08          	mov    %eax,0x8(%esp)
   20147:	8b 45 f0             	mov    -0x10(%ebp),%eax
   2014a:	89 44 24 04          	mov    %eax,0x4(%esp)
   2014e:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20151:	89 04 24             	mov    %eax,(%esp)
   20154:	e8 fc ff ff ff       	call   20155 <ck_ring_dequeue_mpsc+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   20159:	e8 c3 f1 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   2015e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20161:	8d 50 01             	lea    0x1(%eax),%edx
   20164:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20167:	89 54 24 04          	mov    %edx,0x4(%esp)
   2016b:	89 04 24             	mov    %eax,(%esp)
   2016e:	e8 21 e5 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   20173:	b8 01 00 00 00       	mov    $0x1,%eax
    void *data)
{

	return _ck_ring_dequeue_sc(ring, buffer, (void **)data,
	    sizeof(void *));
}
   20178:	c9                   	leave  
   20179:	c3                   	ret    

0002017a <ck_ring_enqueue_spsc_size_xcpu>:
   2017a:	55                   	push   %ebp
   2017b:	89 e5                	mov    %esp,%ebp
   2017d:	83 ec 58             	sub    $0x58,%esp
   20180:	8b 45 08             	mov    0x8(%ebp),%eax
   20183:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20186:	8b 45 0c             	mov    0xc(%ebp),%eax
   20189:	89 45 f0             	mov    %eax,-0x10(%ebp)
   2018c:	8b 45 10             	mov    0x10(%ebp),%eax
   2018f:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20192:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   20199:	8b 45 14             	mov    0x14(%ebp),%eax
   2019c:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   2019f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   201a2:	89 45 e0             	mov    %eax,-0x20(%ebp)
   201a5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   201a8:	89 45 dc             	mov    %eax,-0x24(%ebp)
   201ab:	8b 45 ec             	mov    -0x14(%ebp),%eax
   201ae:	89 45 d8             	mov    %eax,-0x28(%ebp)
   201b1:	8b 45 e8             	mov    -0x18(%ebp),%eax
   201b4:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   201b7:	8d 45 b8             	lea    -0x48(%ebp),%eax
   201ba:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   201bd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   201c0:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   201c6:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   201c9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   201cc:	89 04 24             	mov    %eax,(%esp)
   201cf:	e8 37 e4 ff ff       	call   1e60b <ck_pr_md_load_uint>
   201d4:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   201d7:	8b 45 e0             	mov    -0x20(%ebp),%eax
   201da:	8b 40 40             	mov    0x40(%eax),%eax
   201dd:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   201e0:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   201e3:	83 c0 01             	add    $0x1,%eax
   201e6:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   201e9:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   201ed:	74 14                	je     20203 <ck_ring_enqueue_spsc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   201ef:	8b 45 c8             	mov    -0x38(%ebp),%eax
   201f2:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   201f5:	29 c2                	sub    %eax,%edx
   201f7:	89 d0                	mov    %edx,%eax
   201f9:	23 45 cc             	and    -0x34(%ebp),%eax
   201fc:	89 c2                	mov    %eax,%edx
   201fe:	8b 45 d0             	mov    -0x30(%ebp),%eax
   20201:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   20203:	8b 45 c0             	mov    -0x40(%ebp),%eax
   20206:	8b 55 c8             	mov    -0x38(%ebp),%edx
   20209:	31 d0                	xor    %edx,%eax
   2020b:	23 45 cc             	and    -0x34(%ebp),%eax
   2020e:	85 c0                	test   %eax,%eax
   20210:	0f 94 c0             	sete   %al
   20213:	0f b6 c0             	movzbl %al,%eax
   20216:	85 c0                	test   %eax,%eax
   20218:	74 07                	je     20221 <ck_ring_enqueue_spsc_size_xcpu+0xa7>
		return false;
   2021a:	b8 00 00 00 00       	mov    $0x0,%eax
   2021f:	eb 47                	jmp    20268 <ck_ring_enqueue_spsc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   20221:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   20224:	8b 55 cc             	mov    -0x34(%ebp),%edx
   20227:	21 d0                	and    %edx,%eax
   20229:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   2022d:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   20230:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   20233:	89 44 24 08          	mov    %eax,0x8(%esp)
   20237:	8b 45 d8             	mov    -0x28(%ebp),%eax
   2023a:	89 44 24 04          	mov    %eax,0x4(%esp)
   2023e:	8b 45 dc             	mov    -0x24(%ebp),%eax
   20241:	89 04 24             	mov    %eax,(%esp)
   20244:	e8 fc ff ff ff       	call   20245 <ck_ring_enqueue_spsc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   20249:	e8 d3 f0 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   2024e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20251:	8d 50 40             	lea    0x40(%eax),%edx
   20254:	8b 45 c0             	mov    -0x40(%ebp),%eax
   20257:	89 44 24 04          	mov    %eax,0x4(%esp)
   2025b:	89 14 24             	mov    %edx,(%esp)
   2025e:	e8 31 e4 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   20263:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   20268:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   2026b:	8b 55 b8             	mov    -0x48(%ebp),%edx
   2026e:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   20271:	89 10                	mov    %edx,(%eax)
	return r;
   20273:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   20277:	c9                   	leave  
   20278:	c3                   	ret    

00020279 <ck_ring_enqueue_spsc_xcpu>:
   20279:	55                   	push   %ebp
   2027a:	89 e5                	mov    %esp,%ebp
   2027c:	83 ec 48             	sub    $0x48,%esp
   2027f:	8b 45 08             	mov    0x8(%ebp),%eax
   20282:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20285:	8b 45 0c             	mov    0xc(%ebp),%eax
   20288:	89 45 f0             	mov    %eax,-0x10(%ebp)
   2028b:	8b 45 10             	mov    0x10(%ebp),%eax
   2028e:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20291:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   20298:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   2029f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   202a2:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   202a8:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   202ab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   202ae:	89 04 24             	mov    %eax,(%esp)
   202b1:	e8 55 e3 ff ff       	call   1e60b <ck_pr_md_load_uint>
   202b6:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   202b9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   202bc:	8b 40 40             	mov    0x40(%eax),%eax
   202bf:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   202c2:	8b 45 d8             	mov    -0x28(%ebp),%eax
   202c5:	83 c0 01             	add    $0x1,%eax
   202c8:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   202cb:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   202cf:	74 14                	je     202e5 <ck_ring_enqueue_spsc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   202d1:	8b 45 dc             	mov    -0x24(%ebp),%eax
   202d4:	8b 55 d8             	mov    -0x28(%ebp),%edx
   202d7:	29 c2                	sub    %eax,%edx
   202d9:	89 d0                	mov    %edx,%eax
   202db:	23 45 e0             	and    -0x20(%ebp),%eax
   202de:	89 c2                	mov    %eax,%edx
   202e0:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   202e3:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   202e5:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   202e8:	8b 55 dc             	mov    -0x24(%ebp),%edx
   202eb:	31 d0                	xor    %edx,%eax
   202ed:	23 45 e0             	and    -0x20(%ebp),%eax
   202f0:	85 c0                	test   %eax,%eax
   202f2:	0f 94 c0             	sete   %al
   202f5:	0f b6 c0             	movzbl %al,%eax
   202f8:	85 c0                	test   %eax,%eax
   202fa:	74 07                	je     20303 <ck_ring_enqueue_spsc_xcpu+0x8a>
		return false;
   202fc:	b8 00 00 00 00       	mov    $0x0,%eax
   20301:	eb 47                	jmp    2034a <ck_ring_enqueue_spsc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   20303:	8b 45 d8             	mov    -0x28(%ebp),%eax
   20306:	8b 55 e0             	mov    -0x20(%ebp),%edx
   20309:	21 d0                	and    %edx,%eax
   2030b:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   2030f:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   20312:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20315:	89 44 24 08          	mov    %eax,0x8(%esp)
   20319:	8b 45 ec             	mov    -0x14(%ebp),%eax
   2031c:	89 44 24 04          	mov    %eax,0x4(%esp)
   20320:	8b 45 f0             	mov    -0x10(%ebp),%eax
   20323:	89 04 24             	mov    %eax,(%esp)
   20326:	e8 fc ff ff ff       	call   20327 <ck_ring_enqueue_spsc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   2032b:	e8 f1 ef ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   20330:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20333:	8d 50 40             	lea    0x40(%eax),%edx
   20336:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   20339:	89 44 24 04          	mov    %eax,0x4(%esp)
   2033d:	89 14 24             	mov    %edx,(%esp)
   20340:	e8 4f e3 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   20345:	b8 01 00 00 00       	mov    $0x1,%eax
   2034a:	c9                   	leave  
   2034b:	c3                   	ret    

0002034c <ck_ring_dequeue_spsc_xcpu>:
   2034c:	55                   	push   %ebp
   2034d:	89 e5                	mov    %esp,%ebp
   2034f:	83 ec 38             	sub    $0x38,%esp
   20352:	8b 45 08             	mov    0x8(%ebp),%eax
   20355:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20358:	8b 45 0c             	mov    0xc(%ebp),%eax
   2035b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   2035e:	8b 45 10             	mov    0x10(%ebp),%eax
   20361:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20364:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   2036b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   2036e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20374:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   20377:	8b 45 f4             	mov    -0xc(%ebp),%eax
   2037a:	8b 00                	mov    (%eax),%eax
   2037c:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   2037f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20382:	83 c0 40             	add    $0x40,%eax
   20385:	89 04 24             	mov    %eax,(%esp)
   20388:	e8 7e e2 ff ff       	call   1e60b <ck_pr_md_load_uint>
   2038d:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   20390:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20393:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   20396:	0f 94 c0             	sete   %al
   20399:	0f b6 c0             	movzbl %al,%eax
   2039c:	85 c0                	test   %eax,%eax
   2039e:	74 07                	je     203a7 <ck_ring_dequeue_spsc_xcpu+0x5b>
		return false;
   203a0:	b8 00 00 00 00       	mov    $0x0,%eax
   203a5:	eb 4c                	jmp    203f3 <ck_ring_dequeue_spsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   203a7:	e8 6a ef ff ff       	call   1f316 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   203ac:	8b 45 e0             	mov    -0x20(%ebp),%eax
   203af:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   203b2:	21 d0                	and    %edx,%eax
   203b4:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   203b8:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   203bb:	8b 45 e8             	mov    -0x18(%ebp),%eax
   203be:	89 44 24 08          	mov    %eax,0x8(%esp)
   203c2:	8b 45 f0             	mov    -0x10(%ebp),%eax
   203c5:	89 44 24 04          	mov    %eax,0x4(%esp)
   203c9:	8b 45 ec             	mov    -0x14(%ebp),%eax
   203cc:	89 04 24             	mov    %eax,(%esp)
   203cf:	e8 fc ff ff ff       	call   203d0 <ck_ring_dequeue_spsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   203d4:	e8 48 ef ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   203d9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   203dc:	8d 50 01             	lea    0x1(%eax),%edx
   203df:	8b 45 f4             	mov    -0xc(%ebp),%eax
   203e2:	89 54 24 04          	mov    %edx,0x4(%esp)
   203e6:	89 04 24             	mov    %eax,(%esp)
   203e9:	e8 a6 e2 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   203ee:	b8 01 00 00 00       	mov    $0x1,%eax
   203f3:	c9                   	leave  
   203f4:	c3                   	ret    

000203f5 <ck_ring_enqueue_spmc_size_xcpu>:
   203f5:	55                   	push   %ebp
   203f6:	89 e5                	mov    %esp,%ebp
   203f8:	83 ec 58             	sub    $0x58,%esp
   203fb:	8b 45 08             	mov    0x8(%ebp),%eax
   203fe:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20401:	8b 45 0c             	mov    0xc(%ebp),%eax
   20404:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20407:	8b 45 10             	mov    0x10(%ebp),%eax
   2040a:	89 45 ec             	mov    %eax,-0x14(%ebp)
   2040d:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   20414:	8b 45 14             	mov    0x14(%ebp),%eax
   20417:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   2041a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   2041d:	89 45 e0             	mov    %eax,-0x20(%ebp)
   20420:	8b 45 f0             	mov    -0x10(%ebp),%eax
   20423:	89 45 dc             	mov    %eax,-0x24(%ebp)
   20426:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20429:	89 45 d8             	mov    %eax,-0x28(%ebp)
   2042c:	8b 45 e8             	mov    -0x18(%ebp),%eax
   2042f:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   20432:	8d 45 b8             	lea    -0x48(%ebp),%eax
   20435:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   20438:	8b 45 e0             	mov    -0x20(%ebp),%eax
   2043b:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20441:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   20444:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20447:	89 04 24             	mov    %eax,(%esp)
   2044a:	e8 bc e1 ff ff       	call   1e60b <ck_pr_md_load_uint>
   2044f:	89 45 c8             	mov    %eax,-0x38(%ebp)
	producer = ring->p_tail;
   20452:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20455:	8b 40 40             	mov    0x40(%eax),%eax
   20458:	89 45 c4             	mov    %eax,-0x3c(%ebp)
	delta = producer + 1;
   2045b:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   2045e:	83 c0 01             	add    $0x1,%eax
   20461:	89 45 c0             	mov    %eax,-0x40(%ebp)
	if (size != NULL)
   20464:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   20468:	74 14                	je     2047e <ck_ring_enqueue_spmc_size_xcpu+0x89>
		*size = (producer - consumer) & mask;
   2046a:	8b 45 c8             	mov    -0x38(%ebp),%eax
   2046d:	8b 55 c4             	mov    -0x3c(%ebp),%edx
   20470:	29 c2                	sub    %eax,%edx
   20472:	89 d0                	mov    %edx,%eax
   20474:	23 45 cc             	and    -0x34(%ebp),%eax
   20477:	89 c2                	mov    %eax,%edx
   20479:	8b 45 d0             	mov    -0x30(%ebp),%eax
   2047c:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   2047e:	8b 45 c0             	mov    -0x40(%ebp),%eax
   20481:	8b 55 c8             	mov    -0x38(%ebp),%edx
   20484:	31 d0                	xor    %edx,%eax
   20486:	23 45 cc             	and    -0x34(%ebp),%eax
   20489:	85 c0                	test   %eax,%eax
   2048b:	0f 94 c0             	sete   %al
   2048e:	0f b6 c0             	movzbl %al,%eax
   20491:	85 c0                	test   %eax,%eax
   20493:	74 07                	je     2049c <ck_ring_enqueue_spmc_size_xcpu+0xa7>
		return false;
   20495:	b8 00 00 00 00       	mov    $0x0,%eax
   2049a:	eb 47                	jmp    204e3 <ck_ring_enqueue_spmc_size_xcpu+0xee>

	buffer = (char *)buffer + ts * (producer & mask);
   2049c:	8b 45 c4             	mov    -0x3c(%ebp),%eax
   2049f:	8b 55 cc             	mov    -0x34(%ebp),%edx
   204a2:	21 d0                	and    %edx,%eax
   204a4:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   204a8:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   204ab:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   204ae:	89 44 24 08          	mov    %eax,0x8(%esp)
   204b2:	8b 45 d8             	mov    -0x28(%ebp),%eax
   204b5:	89 44 24 04          	mov    %eax,0x4(%esp)
   204b9:	8b 45 dc             	mov    -0x24(%ebp),%eax
   204bc:	89 04 24             	mov    %eax,(%esp)
   204bf:	e8 fc ff ff ff       	call   204c0 <ck_ring_enqueue_spmc_size_xcpu+0xcb>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   204c4:	e8 58 ee ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   204c9:	8b 45 e0             	mov    -0x20(%ebp),%eax
   204cc:	8d 50 40             	lea    0x40(%eax),%edx
   204cf:	8b 45 c0             	mov    -0x40(%ebp),%eax
   204d2:	89 44 24 04          	mov    %eax,0x4(%esp)
   204d6:	89 14 24             	mov    %edx,(%esp)
   204d9:	e8 b6 e1 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   204de:	b8 01 00 00 00       	mov    $0x1,%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_sp(ring, buffer, entry, ts, &sz);
   204e3:	88 45 bf             	mov    %al,-0x41(%ebp)
	*size = sz;
   204e6:	8b 55 b8             	mov    -0x48(%ebp),%edx
   204e9:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   204ec:	89 10                	mov    %edx,(%eax)
	return r;
   204ee:	0f b6 45 bf          	movzbl -0x41(%ebp),%eax
   204f2:	c9                   	leave  
   204f3:	c3                   	ret    

000204f4 <ck_ring_enqueue_spmc_xcpu>:
   204f4:	55                   	push   %ebp
   204f5:	89 e5                	mov    %esp,%ebp
   204f7:	83 ec 48             	sub    $0x48,%esp
   204fa:	8b 45 08             	mov    0x8(%ebp),%eax
   204fd:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20500:	8b 45 0c             	mov    0xc(%ebp),%eax
   20503:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20506:	8b 45 10             	mov    0x10(%ebp),%eax
   20509:	89 45 ec             	mov    %eax,-0x14(%ebp)
   2050c:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   20513:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *CK_CC_RESTRICT buffer,
    const void *CK_CC_RESTRICT entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   2051a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   2051d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20523:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int consumer, producer, delta;

	consumer = ck_pr_load_uint(&ring->c_head);
   20526:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20529:	89 04 24             	mov    %eax,(%esp)
   2052c:	e8 da e0 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20531:	89 45 dc             	mov    %eax,-0x24(%ebp)
	producer = ring->p_tail;
   20534:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20537:	8b 40 40             	mov    0x40(%eax),%eax
   2053a:	89 45 d8             	mov    %eax,-0x28(%ebp)
	delta = producer + 1;
   2053d:	8b 45 d8             	mov    -0x28(%ebp),%eax
   20540:	83 c0 01             	add    $0x1,%eax
   20543:	89 45 d4             	mov    %eax,-0x2c(%ebp)
	if (size != NULL)
   20546:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   2054a:	74 14                	je     20560 <ck_ring_enqueue_spmc_xcpu+0x6c>
		*size = (producer - consumer) & mask;
   2054c:	8b 45 dc             	mov    -0x24(%ebp),%eax
   2054f:	8b 55 d8             	mov    -0x28(%ebp),%edx
   20552:	29 c2                	sub    %eax,%edx
   20554:	89 d0                	mov    %edx,%eax
   20556:	23 45 e0             	and    -0x20(%ebp),%eax
   20559:	89 c2                	mov    %eax,%edx
   2055b:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   2055e:	89 10                	mov    %edx,(%eax)

	if (CK_CC_UNLIKELY((delta & mask) == (consumer & mask)))
   20560:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   20563:	8b 55 dc             	mov    -0x24(%ebp),%edx
   20566:	31 d0                	xor    %edx,%eax
   20568:	23 45 e0             	and    -0x20(%ebp),%eax
   2056b:	85 c0                	test   %eax,%eax
   2056d:	0f 94 c0             	sete   %al
   20570:	0f b6 c0             	movzbl %al,%eax
   20573:	85 c0                	test   %eax,%eax
   20575:	74 07                	je     2057e <ck_ring_enqueue_spmc_xcpu+0x8a>
		return false;
   20577:	b8 00 00 00 00       	mov    $0x0,%eax
   2057c:	eb 47                	jmp    205c5 <ck_ring_enqueue_spmc_xcpu+0xd1>

	buffer = (char *)buffer + ts * (producer & mask);
   2057e:	8b 45 d8             	mov    -0x28(%ebp),%eax
   20581:	8b 55 e0             	mov    -0x20(%ebp),%edx
   20584:	21 d0                	and    %edx,%eax
   20586:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   2058a:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   2058d:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20590:	89 44 24 08          	mov    %eax,0x8(%esp)
   20594:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20597:	89 44 24 04          	mov    %eax,0x4(%esp)
   2059b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   2059e:	89 04 24             	mov    %eax,(%esp)
   205a1:	e8 fc ff ff ff       	call   205a2 <ck_ring_enqueue_spmc_xcpu+0xae>

	/*
	 * Make sure to update slot value before indicating
	 * that the slot is available for consumption.
	 */
	ck_pr_fence_store();
   205a6:	e8 76 ed ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   205ab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   205ae:	8d 50 40             	lea    0x40(%eax),%edx
   205b1:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   205b4:	89 44 24 04          	mov    %eax,0x4(%esp)
   205b8:	89 14 24             	mov    %edx,(%esp)
   205bb:	e8 d4 e0 ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   205c0:	b8 01 00 00 00       	mov    $0x1,%eax
   205c5:	c9                   	leave  
   205c6:	c3                   	ret    

000205c7 <ck_ring_trydequeue_spmc_xcpu>:
   205c7:	55                   	push   %ebp
   205c8:	89 e5                	mov    %esp,%ebp
   205ca:	83 ec 38             	sub    $0x38,%esp
   205cd:	8b 45 08             	mov    0x8(%ebp),%eax
   205d0:	89 45 f4             	mov    %eax,-0xc(%ebp)
   205d3:	8b 45 0c             	mov    0xc(%ebp),%eax
   205d6:	89 45 f0             	mov    %eax,-0x10(%ebp)
   205d9:	8b 45 10             	mov    0x10(%ebp),%eax
   205dc:	89 45 ec             	mov    %eax,-0x14(%ebp)
   205df:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   205e6:	8b 45 f4             	mov    -0xc(%ebp),%eax
   205e9:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   205ef:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   205f2:	8b 45 f4             	mov    -0xc(%ebp),%eax
   205f5:	89 04 24             	mov    %eax,(%esp)
   205f8:	e8 0e e0 ff ff       	call   1e60b <ck_pr_md_load_uint>
   205fd:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   20600:	e8 11 ed ff ff       	call   1f316 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   20605:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20608:	83 c0 40             	add    $0x40,%eax
   2060b:	89 04 24             	mov    %eax,(%esp)
   2060e:	e8 f8 df ff ff       	call   1e60b <ck_pr_md_load_uint>
   20613:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   20616:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20619:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   2061c:	0f 94 c0             	sete   %al
   2061f:	0f b6 c0             	movzbl %al,%eax
   20622:	85 c0                	test   %eax,%eax
   20624:	74 07                	je     2062d <ck_ring_trydequeue_spmc_xcpu+0x66>
		return false;
   20626:	b8 00 00 00 00       	mov    $0x0,%eax
   2062b:	eb 4e                	jmp    2067b <ck_ring_trydequeue_spmc_xcpu+0xb4>

	ck_pr_fence_load();
   2062d:	e8 e4 ec ff ff       	call   1f316 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   20632:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20635:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   20638:	21 d0                	and    %edx,%eax
   2063a:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   2063e:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   20641:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20644:	89 44 24 08          	mov    %eax,0x8(%esp)
   20648:	8b 45 f0             	mov    -0x10(%ebp),%eax
   2064b:	89 44 24 04          	mov    %eax,0x4(%esp)
   2064f:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20652:	89 04 24             	mov    %eax,(%esp)
   20655:	e8 fc ff ff ff       	call   20656 <ck_ring_trydequeue_spmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   2065a:	e8 8b ec ff ff       	call   1f2ea <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   2065f:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20662:	8d 50 01             	lea    0x1(%eax),%edx
   20665:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20668:	89 54 24 08          	mov    %edx,0x8(%esp)
   2066c:	8b 55 e0             	mov    -0x20(%ebp),%edx
   2066f:	89 54 24 04          	mov    %edx,0x4(%esp)
   20673:	89 04 24             	mov    %eax,(%esp)
   20676:	e8 3e e8 ff ff       	call   1eeb9 <ck_pr_cas_uint>
   2067b:	c9                   	leave  
   2067c:	c3                   	ret    

0002067d <ck_ring_dequeue_spmc_xcpu>:
   2067d:	55                   	push   %ebp
   2067e:	89 e5                	mov    %esp,%ebp
   20680:	53                   	push   %ebx
   20681:	83 ec 34             	sub    $0x34,%esp
   20684:	8b 45 08             	mov    0x8(%ebp),%eax
   20687:	89 45 f4             	mov    %eax,-0xc(%ebp)
   2068a:	8b 45 0c             	mov    0xc(%ebp),%eax
   2068d:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20690:	8b 45 10             	mov    0x10(%ebp),%eax
   20693:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20696:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   2069d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   206a0:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   206a6:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   206a9:	8b 45 f4             	mov    -0xc(%ebp),%eax
   206ac:	89 04 24             	mov    %eax,(%esp)
   206af:	e8 57 df ff ff       	call   1e60b <ck_pr_md_load_uint>
   206b4:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   206b7:	e8 5a ec ff ff       	call   1f316 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   206bc:	8b 45 f4             	mov    -0xc(%ebp),%eax
   206bf:	83 c0 40             	add    $0x40,%eax
   206c2:	89 04 24             	mov    %eax,(%esp)
   206c5:	e8 41 df ff ff       	call   1e60b <ck_pr_md_load_uint>
   206ca:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   206cd:	8b 45 d8             	mov    -0x28(%ebp),%eax
   206d0:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   206d3:	0f 94 c0             	sete   %al
   206d6:	0f b6 c0             	movzbl %al,%eax
   206d9:	85 c0                	test   %eax,%eax
   206db:	74 07                	je     206e4 <ck_ring_dequeue_spmc_xcpu+0x67>
			return false;
   206dd:	b8 00 00 00 00       	mov    $0x0,%eax
   206e2:	eb 6a                	jmp    2074e <ck_ring_dequeue_spmc_xcpu+0xd1>

		ck_pr_fence_load();
   206e4:	e8 2d ec ff ff       	call   1f316 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   206e9:	8b 45 d8             	mov    -0x28(%ebp),%eax
   206ec:	23 45 e4             	and    -0x1c(%ebp),%eax
   206ef:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   206f3:	89 c2                	mov    %eax,%edx
   206f5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   206f8:	01 d0                	add    %edx,%eax
   206fa:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   206fd:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20700:	89 44 24 08          	mov    %eax,0x8(%esp)
   20704:	8b 45 dc             	mov    -0x24(%ebp),%eax
   20707:	89 44 24 04          	mov    %eax,0x4(%esp)
   2070b:	8b 45 ec             	mov    -0x14(%ebp),%eax
   2070e:	89 04 24             	mov    %eax,(%esp)
   20711:	e8 fc ff ff ff       	call   20712 <ck_ring_dequeue_spmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   20716:	e8 cf eb ff ff       	call   1f2ea <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   2071b:	8b 45 d8             	mov    -0x28(%ebp),%eax
   2071e:	8d 58 01             	lea    0x1(%eax),%ebx
   20721:	8b 55 d8             	mov    -0x28(%ebp),%edx
   20724:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20727:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   2072a:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   2072e:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   20732:	89 54 24 04          	mov    %edx,0x4(%esp)
   20736:	89 04 24             	mov    %eax,(%esp)
   20739:	e8 ce e8 ff ff       	call   1f00c <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   2073e:	83 f0 01             	xor    $0x1,%eax
   20741:	84 c0                	test   %al,%al
   20743:	0f 85 6e ff ff ff    	jne    206b7 <ck_ring_dequeue_spmc_xcpu+0x3a>

	return true;
   20749:	b8 01 00 00 00       	mov    $0x1,%eax
   2074e:	83 c4 34             	add    $0x34,%esp
   20751:	5b                   	pop    %ebx
   20752:	5d                   	pop    %ebp
   20753:	c3                   	ret    

00020754 <ck_ring_enqueue_mpsc_xcpu>:
   20754:	55                   	push   %ebp
   20755:	89 e5                	mov    %esp,%ebp
   20757:	83 ec 48             	sub    $0x48,%esp
   2075a:	8b 45 08             	mov    0x8(%ebp),%eax
   2075d:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20760:	8b 45 0c             	mov    0xc(%ebp),%eax
   20763:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20766:	8b 45 10             	mov    0x10(%ebp),%eax
   20769:	89 45 ec             	mov    %eax,-0x14(%ebp)
   2076c:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   20773:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   2077a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   2077d:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20783:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   20786:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   2078a:	8b 45 f4             	mov    -0xc(%ebp),%eax
   2078d:	83 c0 44             	add    $0x44,%eax
   20790:	89 04 24             	mov    %eax,(%esp)
   20793:	e8 73 de ff ff       	call   1e60b <ck_pr_md_load_uint>
   20798:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   2079b:	e8 76 eb ff ff       	call   1f316 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   207a0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   207a3:	89 04 24             	mov    %eax,(%esp)
   207a6:	e8 60 de ff ff       	call   1e60b <ck_pr_md_load_uint>
   207ab:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   207ae:	8b 45 cc             	mov    -0x34(%ebp),%eax
   207b1:	83 c0 01             	add    $0x1,%eax
   207b4:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   207b7:	8b 45 cc             	mov    -0x34(%ebp),%eax
   207ba:	2b 45 d8             	sub    -0x28(%ebp),%eax
   207bd:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   207c0:	0f 97 c0             	seta   %al
   207c3:	0f b6 c0             	movzbl %al,%eax
   207c6:	85 c0                	test   %eax,%eax
   207c8:	74 29                	je     207f3 <ck_ring_enqueue_mpsc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   207ca:	8b 45 cc             	mov    -0x34(%ebp),%eax
   207cd:	8b 55 f4             	mov    -0xc(%ebp),%edx
   207d0:	8d 4a 44             	lea    0x44(%edx),%ecx
   207d3:	8d 55 cc             	lea    -0x34(%ebp),%edx
   207d6:	89 54 24 0c          	mov    %edx,0xc(%esp)
   207da:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   207dd:	89 54 24 08          	mov    %edx,0x8(%esp)
   207e1:	89 44 24 04          	mov    %eax,0x4(%esp)
   207e5:	89 0c 24             	mov    %ecx,(%esp)
   207e8:	e8 1f e8 ff ff       	call   1f00c <ck_pr_cas_uint_value>
   207ed:	84 c0                	test   %al,%al
   207ef:	75 31                	jne    20822 <ck_ring_enqueue_mpsc_xcpu+0xce>
   207f1:	eb a8                	jmp    2079b <ck_ring_enqueue_mpsc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   207f3:	e8 1e eb ff ff       	call   1f316 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   207f8:	8b 45 f4             	mov    -0xc(%ebp),%eax
   207fb:	83 c0 44             	add    $0x44,%eax
   207fe:	89 04 24             	mov    %eax,(%esp)
   20801:	e8 05 de ff ff       	call   1e60b <ck_pr_md_load_uint>
   20806:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   20809:	8b 45 cc             	mov    -0x34(%ebp),%eax
   2080c:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   2080f:	75 06                	jne    20817 <ck_ring_enqueue_mpsc_xcpu+0xc3>
				r = false;
   20811:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   20815:	eb 67                	jmp    2087e <ck_ring_enqueue_mpsc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   20817:	8b 45 d0             	mov    -0x30(%ebp),%eax
   2081a:	89 45 cc             	mov    %eax,-0x34(%ebp)
   2081d:	e9 79 ff ff ff       	jmp    2079b <ck_ring_enqueue_mpsc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   20822:	8b 45 cc             	mov    -0x34(%ebp),%eax
   20825:	23 45 e0             	and    -0x20(%ebp),%eax
   20828:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   2082c:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   2082f:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20832:	89 44 24 08          	mov    %eax,0x8(%esp)
   20836:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20839:	89 44 24 04          	mov    %eax,0x4(%esp)
   2083d:	8b 45 f0             	mov    -0x10(%ebp),%eax
   20840:	89 04 24             	mov    %eax,(%esp)
   20843:	e8 fc ff ff ff       	call   20844 <ck_ring_enqueue_mpsc_xcpu+0xf0>
   20848:	eb 05                	jmp    2084f <ck_ring_enqueue_mpsc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   2084a:	e8 57 dc ff ff       	call   1e4a6 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   2084f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20852:	83 c0 40             	add    $0x40,%eax
   20855:	89 04 24             	mov    %eax,(%esp)
   20858:	e8 ae dd ff ff       	call   1e60b <ck_pr_md_load_uint>
   2085d:	8b 55 cc             	mov    -0x34(%ebp),%edx
   20860:	39 d0                	cmp    %edx,%eax
   20862:	75 e6                	jne    2084a <ck_ring_enqueue_mpsc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   20864:	e8 b8 ea ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   20869:	8b 45 f4             	mov    -0xc(%ebp),%eax
   2086c:	8d 50 40             	lea    0x40(%eax),%edx
   2086f:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   20872:	89 44 24 04          	mov    %eax,0x4(%esp)
   20876:	89 14 24             	mov    %edx,(%esp)
   20879:	e8 16 de ff ff       	call   1e694 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   2087e:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   20882:	74 10                	je     20894 <ck_ring_enqueue_mpsc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   20884:	8b 45 cc             	mov    -0x34(%ebp),%eax
   20887:	2b 45 d8             	sub    -0x28(%ebp),%eax
   2088a:	23 45 e0             	and    -0x20(%ebp),%eax
   2088d:	89 c2                	mov    %eax,%edx
   2088f:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   20892:	89 10                	mov    %edx,(%eax)

	return r;
   20894:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   20898:	c9                   	leave  
   20899:	c3                   	ret    

0002089a <ck_ring_enqueue_mpsc_size_xcpu>:
   2089a:	55                   	push   %ebp
   2089b:	89 e5                	mov    %esp,%ebp
   2089d:	83 ec 68             	sub    $0x68,%esp
   208a0:	8b 45 08             	mov    0x8(%ebp),%eax
   208a3:	89 45 f4             	mov    %eax,-0xc(%ebp)
   208a6:	8b 45 0c             	mov    0xc(%ebp),%eax
   208a9:	89 45 f0             	mov    %eax,-0x10(%ebp)
   208ac:	8b 45 10             	mov    0x10(%ebp),%eax
   208af:	89 45 ec             	mov    %eax,-0x14(%ebp)
   208b2:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   208b9:	8b 45 14             	mov    0x14(%ebp),%eax
   208bc:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   208bf:	8b 45 f4             	mov    -0xc(%ebp),%eax
   208c2:	89 45 e0             	mov    %eax,-0x20(%ebp)
   208c5:	8b 45 f0             	mov    -0x10(%ebp),%eax
   208c8:	89 45 dc             	mov    %eax,-0x24(%ebp)
   208cb:	8b 45 ec             	mov    -0x14(%ebp),%eax
   208ce:	89 45 d8             	mov    %eax,-0x28(%ebp)
   208d1:	8b 45 e8             	mov    -0x18(%ebp),%eax
   208d4:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   208d7:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   208da:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   208dd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   208e0:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   208e6:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   208e9:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   208ed:	8b 45 e0             	mov    -0x20(%ebp),%eax
   208f0:	83 c0 44             	add    $0x44,%eax
   208f3:	89 04 24             	mov    %eax,(%esp)
   208f6:	e8 10 dd ff ff       	call   1e60b <ck_pr_md_load_uint>
   208fb:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   208fe:	e8 13 ea ff ff       	call   1f316 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   20903:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20906:	89 04 24             	mov    %eax,(%esp)
   20909:	e8 fd dc ff ff       	call   1e60b <ck_pr_md_load_uint>
   2090e:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   20911:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20914:	83 c0 01             	add    $0x1,%eax
   20917:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   2091a:	8b 45 b0             	mov    -0x50(%ebp),%eax
   2091d:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   20920:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   20923:	0f 97 c0             	seta   %al
   20926:	0f b6 c0             	movzbl %al,%eax
   20929:	85 c0                	test   %eax,%eax
   2092b:	74 29                	je     20956 <ck_ring_enqueue_mpsc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   2092d:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20930:	8b 55 e0             	mov    -0x20(%ebp),%edx
   20933:	8d 4a 44             	lea    0x44(%edx),%ecx
   20936:	8d 55 b0             	lea    -0x50(%ebp),%edx
   20939:	89 54 24 0c          	mov    %edx,0xc(%esp)
   2093d:	8b 55 c0             	mov    -0x40(%ebp),%edx
   20940:	89 54 24 08          	mov    %edx,0x8(%esp)
   20944:	89 44 24 04          	mov    %eax,0x4(%esp)
   20948:	89 0c 24             	mov    %ecx,(%esp)
   2094b:	e8 bc e6 ff ff       	call   1f00c <ck_pr_cas_uint_value>
   20950:	84 c0                	test   %al,%al
   20952:	75 31                	jne    20985 <ck_ring_enqueue_mpsc_size_xcpu+0xeb>
   20954:	eb a8                	jmp    208fe <ck_ring_enqueue_mpsc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   20956:	e8 bb e9 ff ff       	call   1f316 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   2095b:	8b 45 e0             	mov    -0x20(%ebp),%eax
   2095e:	83 c0 44             	add    $0x44,%eax
   20961:	89 04 24             	mov    %eax,(%esp)
   20964:	e8 a2 dc ff ff       	call   1e60b <ck_pr_md_load_uint>
   20969:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   2096c:	8b 45 b0             	mov    -0x50(%ebp),%eax
   2096f:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   20972:	75 06                	jne    2097a <ck_ring_enqueue_mpsc_size_xcpu+0xe0>
				r = false;
   20974:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   20978:	eb 67                	jmp    209e1 <ck_ring_enqueue_mpsc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   2097a:	8b 45 bc             	mov    -0x44(%ebp),%eax
   2097d:	89 45 b0             	mov    %eax,-0x50(%ebp)
   20980:	e9 79 ff ff ff       	jmp    208fe <ck_ring_enqueue_mpsc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   20985:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20988:	23 45 cc             	and    -0x34(%ebp),%eax
   2098b:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   2098f:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   20992:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   20995:	89 44 24 08          	mov    %eax,0x8(%esp)
   20999:	8b 45 d8             	mov    -0x28(%ebp),%eax
   2099c:	89 44 24 04          	mov    %eax,0x4(%esp)
   209a0:	8b 45 dc             	mov    -0x24(%ebp),%eax
   209a3:	89 04 24             	mov    %eax,(%esp)
   209a6:	e8 fc ff ff ff       	call   209a7 <ck_ring_enqueue_mpsc_size_xcpu+0x10d>
   209ab:	eb 05                	jmp    209b2 <ck_ring_enqueue_mpsc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   209ad:	e8 f4 da ff ff       	call   1e4a6 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   209b2:	8b 45 e0             	mov    -0x20(%ebp),%eax
   209b5:	83 c0 40             	add    $0x40,%eax
   209b8:	89 04 24             	mov    %eax,(%esp)
   209bb:	e8 4b dc ff ff       	call   1e60b <ck_pr_md_load_uint>
   209c0:	8b 55 b0             	mov    -0x50(%ebp),%edx
   209c3:	39 d0                	cmp    %edx,%eax
   209c5:	75 e6                	jne    209ad <ck_ring_enqueue_mpsc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   209c7:	e8 55 e9 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   209cc:	8b 45 e0             	mov    -0x20(%ebp),%eax
   209cf:	8d 50 40             	lea    0x40(%eax),%edx
   209d2:	8b 45 c0             	mov    -0x40(%ebp),%eax
   209d5:	89 44 24 04          	mov    %eax,0x4(%esp)
   209d9:	89 14 24             	mov    %edx,(%esp)
   209dc:	e8 b3 dc ff ff       	call   1e694 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   209e1:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   209e5:	74 10                	je     209f7 <ck_ring_enqueue_mpsc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   209e7:	8b 45 b0             	mov    -0x50(%ebp),%eax
   209ea:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   209ed:	23 45 cc             	and    -0x34(%ebp),%eax
   209f0:	89 c2                	mov    %eax,%edx
   209f2:	8b 45 d0             	mov    -0x30(%ebp),%eax
   209f5:	89 10                	mov    %edx,(%eax)

	return r;
   209f7:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   209fb:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   209fe:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   20a01:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   20a04:	89 10                	mov    %edx,(%eax)
	return r;
   20a06:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   20a0a:	c9                   	leave  
   20a0b:	c3                   	ret    

00020a0c <ck_ring_dequeue_mpsc_xcpu>:
   20a0c:	55                   	push   %ebp
   20a0d:	89 e5                	mov    %esp,%ebp
   20a0f:	83 ec 38             	sub    $0x38,%esp
   20a12:	8b 45 08             	mov    0x8(%ebp),%eax
   20a15:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20a18:	8b 45 0c             	mov    0xc(%ebp),%eax
   20a1b:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20a1e:	8b 45 10             	mov    0x10(%ebp),%eax
   20a21:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20a24:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_sc(struct ck_ring *ring,
    const void *CK_CC_RESTRICT buffer,
    void *CK_CC_RESTRICT target,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   20a2b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20a2e:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20a34:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ring->c_head;
   20a37:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20a3a:	8b 00                	mov    (%eax),%eax
   20a3c:	89 45 e0             	mov    %eax,-0x20(%ebp)
	producer = ck_pr_load_uint(&ring->p_tail);
   20a3f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20a42:	83 c0 40             	add    $0x40,%eax
   20a45:	89 04 24             	mov    %eax,(%esp)
   20a48:	e8 be db ff ff       	call   1e60b <ck_pr_md_load_uint>
   20a4d:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   20a50:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20a53:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   20a56:	0f 94 c0             	sete   %al
   20a59:	0f b6 c0             	movzbl %al,%eax
   20a5c:	85 c0                	test   %eax,%eax
   20a5e:	74 07                	je     20a67 <ck_ring_dequeue_mpsc_xcpu+0x5b>
		return false;
   20a60:	b8 00 00 00 00       	mov    $0x0,%eax
   20a65:	eb 4c                	jmp    20ab3 <ck_ring_dequeue_mpsc_xcpu+0xa7>

	/*
	 * Make sure to serialize with respect to our snapshot
	 * of the producer counter.
	 */
	ck_pr_fence_load();
   20a67:	e8 aa e8 ff ff       	call   1f316 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   20a6c:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20a6f:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   20a72:	21 d0                	and    %edx,%eax
   20a74:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   20a78:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(target, buffer, size);
   20a7b:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20a7e:	89 44 24 08          	mov    %eax,0x8(%esp)
   20a82:	8b 45 f0             	mov    -0x10(%ebp),%eax
   20a85:	89 44 24 04          	mov    %eax,0x4(%esp)
   20a89:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20a8c:	89 04 24             	mov    %eax,(%esp)
   20a8f:	e8 fc ff ff ff       	call   20a90 <ck_ring_dequeue_mpsc_xcpu+0x84>

	/*
	 * Make sure copy is completed with respect to consumer
	 * update.
	 */
	ck_pr_fence_store();
   20a94:	e8 88 e8 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->c_head, consumer + 1);
   20a99:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20a9c:	8d 50 01             	lea    0x1(%eax),%edx
   20a9f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20aa2:	89 54 24 04          	mov    %edx,0x4(%esp)
   20aa6:	89 04 24             	mov    %eax,(%esp)
   20aa9:	e8 e6 db ff ff       	call   1e694 <ck_pr_md_store_uint>
	return true;
   20aae:	b8 01 00 00 00       	mov    $0x1,%eax
   20ab3:	c9                   	leave  
   20ab4:	c3                   	ret    

00020ab5 <ck_ring_enqueue_mpmc_size_xcpu>:
   20ab5:	55                   	push   %ebp
   20ab6:	89 e5                	mov    %esp,%ebp
   20ab8:	83 ec 68             	sub    $0x68,%esp
   20abb:	8b 45 08             	mov    0x8(%ebp),%eax
   20abe:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20ac1:	8b 45 0c             	mov    0xc(%ebp),%eax
   20ac4:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20ac7:	8b 45 10             	mov    0x10(%ebp),%eax
   20aca:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20acd:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   20ad4:	8b 45 14             	mov    0x14(%ebp),%eax
   20ad7:	89 45 e4             	mov    %eax,-0x1c(%ebp)
   20ada:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20add:	89 45 e0             	mov    %eax,-0x20(%ebp)
   20ae0:	8b 45 f0             	mov    -0x10(%ebp),%eax
   20ae3:	89 45 dc             	mov    %eax,-0x24(%ebp)
   20ae6:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20ae9:	89 45 d8             	mov    %eax,-0x28(%ebp)
   20aec:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20aef:	89 45 d4             	mov    %eax,-0x2c(%ebp)
   20af2:	8d 45 b4             	lea    -0x4c(%ebp),%eax
   20af5:	89 45 d0             	mov    %eax,-0x30(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   20af8:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20afb:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20b01:	89 45 cc             	mov    %eax,-0x34(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   20b04:	c6 45 cb 01          	movb   $0x1,-0x35(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   20b08:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20b0b:	83 c0 44             	add    $0x44,%eax
   20b0e:	89 04 24             	mov    %eax,(%esp)
   20b11:	e8 f5 da ff ff       	call   1e60b <ck_pr_md_load_uint>
   20b16:	89 45 b0             	mov    %eax,-0x50(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   20b19:	e8 f8 e7 ff ff       	call   1f316 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   20b1e:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20b21:	89 04 24             	mov    %eax,(%esp)
   20b24:	e8 e2 da ff ff       	call   1e60b <ck_pr_md_load_uint>
   20b29:	89 45 c4             	mov    %eax,-0x3c(%ebp)

		delta = producer + 1;
   20b2c:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20b2f:	83 c0 01             	add    $0x1,%eax
   20b32:	89 45 c0             	mov    %eax,-0x40(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   20b35:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20b38:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   20b3b:	39 45 cc             	cmp    %eax,-0x34(%ebp)
   20b3e:	0f 97 c0             	seta   %al
   20b41:	0f b6 c0             	movzbl %al,%eax
   20b44:	85 c0                	test   %eax,%eax
   20b46:	74 29                	je     20b71 <ck_ring_enqueue_mpmc_size_xcpu+0xbc>
			if (ck_pr_cas_uint_value(&ring->p_head,
   20b48:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20b4b:	8b 55 e0             	mov    -0x20(%ebp),%edx
   20b4e:	8d 4a 44             	lea    0x44(%edx),%ecx
   20b51:	8d 55 b0             	lea    -0x50(%ebp),%edx
   20b54:	89 54 24 0c          	mov    %edx,0xc(%esp)
   20b58:	8b 55 c0             	mov    -0x40(%ebp),%edx
   20b5b:	89 54 24 08          	mov    %edx,0x8(%esp)
   20b5f:	89 44 24 04          	mov    %eax,0x4(%esp)
   20b63:	89 0c 24             	mov    %ecx,(%esp)
   20b66:	e8 a1 e4 ff ff       	call   1f00c <ck_pr_cas_uint_value>
   20b6b:	84 c0                	test   %al,%al
   20b6d:	75 31                	jne    20ba0 <ck_ring_enqueue_mpmc_size_xcpu+0xeb>
   20b6f:	eb a8                	jmp    20b19 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   20b71:	e8 a0 e7 ff ff       	call   1f316 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   20b76:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20b79:	83 c0 44             	add    $0x44,%eax
   20b7c:	89 04 24             	mov    %eax,(%esp)
   20b7f:	e8 87 da ff ff       	call   1e60b <ck_pr_md_load_uint>
   20b84:	89 45 bc             	mov    %eax,-0x44(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   20b87:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20b8a:	39 45 bc             	cmp    %eax,-0x44(%ebp)
   20b8d:	75 06                	jne    20b95 <ck_ring_enqueue_mpmc_size_xcpu+0xe0>
				r = false;
   20b8f:	c6 45 cb 00          	movb   $0x0,-0x35(%ebp)
   20b93:	eb 67                	jmp    20bfc <ck_ring_enqueue_mpmc_size_xcpu+0x147>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   20b95:	8b 45 bc             	mov    -0x44(%ebp),%eax
   20b98:	89 45 b0             	mov    %eax,-0x50(%ebp)
   20b9b:	e9 79 ff ff ff       	jmp    20b19 <ck_ring_enqueue_mpmc_size_xcpu+0x64>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   20ba0:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20ba3:	23 45 cc             	and    -0x34(%ebp),%eax
   20ba6:	0f af 45 d4          	imul   -0x2c(%ebp),%eax
   20baa:	01 45 dc             	add    %eax,-0x24(%ebp)
	memcpy(buffer, entry, ts);
   20bad:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   20bb0:	89 44 24 08          	mov    %eax,0x8(%esp)
   20bb4:	8b 45 d8             	mov    -0x28(%ebp),%eax
   20bb7:	89 44 24 04          	mov    %eax,0x4(%esp)
   20bbb:	8b 45 dc             	mov    -0x24(%ebp),%eax
   20bbe:	89 04 24             	mov    %eax,(%esp)
   20bc1:	e8 fc ff ff ff       	call   20bc2 <ck_ring_enqueue_mpmc_size_xcpu+0x10d>
   20bc6:	eb 05                	jmp    20bcd <ck_ring_enqueue_mpmc_size_xcpu+0x118>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   20bc8:	e8 d9 d8 ff ff       	call   1e4a6 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   20bcd:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20bd0:	83 c0 40             	add    $0x40,%eax
   20bd3:	89 04 24             	mov    %eax,(%esp)
   20bd6:	e8 30 da ff ff       	call   1e60b <ck_pr_md_load_uint>
   20bdb:	8b 55 b0             	mov    -0x50(%ebp),%edx
   20bde:	39 d0                	cmp    %edx,%eax
   20be0:	75 e6                	jne    20bc8 <ck_ring_enqueue_mpmc_size_xcpu+0x113>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   20be2:	e8 3a e7 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   20be7:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20bea:	8d 50 40             	lea    0x40(%eax),%edx
   20bed:	8b 45 c0             	mov    -0x40(%ebp),%eax
   20bf0:	89 44 24 04          	mov    %eax,0x4(%esp)
   20bf4:	89 14 24             	mov    %edx,(%esp)
   20bf7:	e8 98 da ff ff       	call   1e694 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   20bfc:	83 7d d0 00          	cmpl   $0x0,-0x30(%ebp)
   20c00:	74 10                	je     20c12 <ck_ring_enqueue_mpmc_size_xcpu+0x15d>
		*size = (producer - consumer) & mask;
   20c02:	8b 45 b0             	mov    -0x50(%ebp),%eax
   20c05:	2b 45 c4             	sub    -0x3c(%ebp),%eax
   20c08:	23 45 cc             	and    -0x34(%ebp),%eax
   20c0b:	89 c2                	mov    %eax,%edx
   20c0d:	8b 45 d0             	mov    -0x30(%ebp),%eax
   20c10:	89 10                	mov    %edx,(%eax)

	return r;
   20c12:	0f b6 45 cb          	movzbl -0x35(%ebp),%eax
    unsigned int *size)
{
	unsigned int sz;
	bool r;

	r = _ck_ring_enqueue_mp(ring, buffer, entry, ts, &sz);
   20c16:	88 45 bb             	mov    %al,-0x45(%ebp)
	*size = sz;
   20c19:	8b 55 b4             	mov    -0x4c(%ebp),%edx
   20c1c:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   20c1f:	89 10                	mov    %edx,(%eax)
	return r;
   20c21:	0f b6 45 bb          	movzbl -0x45(%ebp),%eax
   20c25:	c9                   	leave  
   20c26:	c3                   	ret    

00020c27 <ck_ring_enqueue_mpmc_xcpu>:
   20c27:	55                   	push   %ebp
   20c28:	89 e5                	mov    %esp,%ebp
   20c2a:	83 ec 48             	sub    $0x48,%esp
   20c2d:	8b 45 08             	mov    0x8(%ebp),%eax
   20c30:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20c33:	8b 45 0c             	mov    0xc(%ebp),%eax
   20c36:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20c39:	8b 45 10             	mov    0x10(%ebp),%eax
   20c3c:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20c3f:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
   20c46:	c7 45 e4 00 00 00 00 	movl   $0x0,-0x1c(%ebp)
    void *buffer,
    const void *entry,
    unsigned int ts,
    unsigned int *size)
{
	const unsigned int mask = ring->mask;
   20c4d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20c50:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20c56:	89 45 e0             	mov    %eax,-0x20(%ebp)
	unsigned int producer, consumer, delta;
	bool r = true;
   20c59:	c6 45 df 01          	movb   $0x1,-0x21(%ebp)

	producer = ck_pr_load_uint(&ring->p_head);
   20c5d:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20c60:	83 c0 44             	add    $0x44,%eax
   20c63:	89 04 24             	mov    %eax,(%esp)
   20c66:	e8 a0 d9 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20c6b:	89 45 cc             	mov    %eax,-0x34(%ebp)
	for (;;) {
		/*
		 * The snapshot of producer must be up to date with respect to
		 * consumer.
		 */
		ck_pr_fence_load();
   20c6e:	e8 a3 e6 ff ff       	call   1f316 <ck_pr_fence_load>
		consumer = ck_pr_load_uint(&ring->c_head);
   20c73:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20c76:	89 04 24             	mov    %eax,(%esp)
   20c79:	e8 8d d9 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20c7e:	89 45 d8             	mov    %eax,-0x28(%ebp)

		delta = producer + 1;
   20c81:	8b 45 cc             	mov    -0x34(%ebp),%eax
   20c84:	83 c0 01             	add    $0x1,%eax
   20c87:	89 45 d4             	mov    %eax,-0x2c(%ebp)

		/*
		 * Only try to CAS if the producer is not clearly stale (not
		 * less than consumer) and the buffer is definitely not full.
		 */
		if (CK_CC_LIKELY((producer - consumer) < mask)) {
   20c8a:	8b 45 cc             	mov    -0x34(%ebp),%eax
   20c8d:	2b 45 d8             	sub    -0x28(%ebp),%eax
   20c90:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   20c93:	0f 97 c0             	seta   %al
   20c96:	0f b6 c0             	movzbl %al,%eax
   20c99:	85 c0                	test   %eax,%eax
   20c9b:	74 29                	je     20cc6 <ck_ring_enqueue_mpmc_xcpu+0x9f>
			if (ck_pr_cas_uint_value(&ring->p_head,
   20c9d:	8b 45 cc             	mov    -0x34(%ebp),%eax
   20ca0:	8b 55 f4             	mov    -0xc(%ebp),%edx
   20ca3:	8d 4a 44             	lea    0x44(%edx),%ecx
   20ca6:	8d 55 cc             	lea    -0x34(%ebp),%edx
   20ca9:	89 54 24 0c          	mov    %edx,0xc(%esp)
   20cad:	8b 55 d4             	mov    -0x2c(%ebp),%edx
   20cb0:	89 54 24 08          	mov    %edx,0x8(%esp)
   20cb4:	89 44 24 04          	mov    %eax,0x4(%esp)
   20cb8:	89 0c 24             	mov    %ecx,(%esp)
   20cbb:	e8 4c e3 ff ff       	call   1f00c <ck_pr_cas_uint_value>
   20cc0:	84 c0                	test   %al,%al
   20cc2:	75 31                	jne    20cf5 <ck_ring_enqueue_mpmc_xcpu+0xce>
   20cc4:	eb a8                	jmp    20c6e <ck_ring_enqueue_mpmc_xcpu+0x47>
			 * Slow path.  Either the buffer is full or we have a
			 * stale snapshot of p_head.  Execute a second read of
			 * p_read that must be ordered wrt the snapshot of
			 * c_head.
			 */
			ck_pr_fence_load();
   20cc6:	e8 4b e6 ff ff       	call   1f316 <ck_pr_fence_load>
			new_producer = ck_pr_load_uint(&ring->p_head);
   20ccb:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20cce:	83 c0 44             	add    $0x44,%eax
   20cd1:	89 04 24             	mov    %eax,(%esp)
   20cd4:	e8 32 d9 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20cd9:	89 45 d0             	mov    %eax,-0x30(%ebp)
			 * Only fail if we haven't made forward progress in
			 * production: the buffer must have been full when we
			 * read new_producer (or we wrapped around UINT_MAX
			 * during this iteration).
			 */
			if (producer == new_producer) {
   20cdc:	8b 45 cc             	mov    -0x34(%ebp),%eax
   20cdf:	39 45 d0             	cmp    %eax,-0x30(%ebp)
   20ce2:	75 06                	jne    20cea <ck_ring_enqueue_mpmc_xcpu+0xc3>
				r = false;
   20ce4:	c6 45 df 00          	movb   $0x0,-0x21(%ebp)
   20ce8:	eb 67                	jmp    20d51 <ck_ring_enqueue_mpmc_xcpu+0x12a>
			}

			/*
			 * p_head advanced during this iteration. Try again.
			 */
			producer = new_producer;
   20cea:	8b 45 d0             	mov    -0x30(%ebp),%eax
   20ced:	89 45 cc             	mov    %eax,-0x34(%ebp)
   20cf0:	e9 79 ff ff ff       	jmp    20c6e <ck_ring_enqueue_mpmc_xcpu+0x47>
		}
	}

	buffer = (char *)buffer + ts * (producer & mask);
   20cf5:	8b 45 cc             	mov    -0x34(%ebp),%eax
   20cf8:	23 45 e0             	and    -0x20(%ebp),%eax
   20cfb:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   20cff:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(buffer, entry, ts);
   20d02:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20d05:	89 44 24 08          	mov    %eax,0x8(%esp)
   20d09:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20d0c:	89 44 24 04          	mov    %eax,0x4(%esp)
   20d10:	8b 45 f0             	mov    -0x10(%ebp),%eax
   20d13:	89 04 24             	mov    %eax,(%esp)
   20d16:	e8 fc ff ff ff       	call   20d17 <ck_ring_enqueue_mpmc_xcpu+0xf0>
   20d1b:	eb 05                	jmp    20d22 <ck_ring_enqueue_mpmc_xcpu+0xfb>
	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
		ck_pr_stall();
   20d1d:	e8 84 d7 ff ff       	call   1e4a6 <ck_pr_stall>

	/*
	 * Wait until all concurrent producers have completed writing
	 * their data into the ring buffer.
	 */
	while (ck_pr_load_uint(&ring->p_tail) != producer)
   20d22:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20d25:	83 c0 40             	add    $0x40,%eax
   20d28:	89 04 24             	mov    %eax,(%esp)
   20d2b:	e8 db d8 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20d30:	8b 55 cc             	mov    -0x34(%ebp),%edx
   20d33:	39 d0                	cmp    %edx,%eax
   20d35:	75 e6                	jne    20d1d <ck_ring_enqueue_mpmc_xcpu+0xf6>

	/*
	 * Ensure that copy is completed before updating shared producer
	 * counter.
	 */
	ck_pr_fence_store();
   20d37:	e8 e5 e5 ff ff       	call   1f321 <ck_pr_fence_store>
	ck_pr_store_uint(&ring->p_tail, delta);
   20d3c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20d3f:	8d 50 40             	lea    0x40(%eax),%edx
   20d42:	8b 45 d4             	mov    -0x2c(%ebp),%eax
   20d45:	89 44 24 04          	mov    %eax,0x4(%esp)
   20d49:	89 14 24             	mov    %edx,(%esp)
   20d4c:	e8 43 d9 ff ff       	call   1e694 <ck_pr_md_store_uint>

leave:
	if (size != NULL)
   20d51:	83 7d e4 00          	cmpl   $0x0,-0x1c(%ebp)
   20d55:	74 10                	je     20d67 <ck_ring_enqueue_mpmc_xcpu+0x140>
		*size = (producer - consumer) & mask;
   20d57:	8b 45 cc             	mov    -0x34(%ebp),%eax
   20d5a:	2b 45 d8             	sub    -0x28(%ebp),%eax
   20d5d:	23 45 e0             	and    -0x20(%ebp),%eax
   20d60:	89 c2                	mov    %eax,%edx
   20d62:	8b 45 e4             	mov    -0x1c(%ebp),%eax
   20d65:	89 10                	mov    %edx,(%eax)

	return r;
   20d67:	0f b6 45 df          	movzbl -0x21(%ebp),%eax
   20d6b:	c9                   	leave  
   20d6c:	c3                   	ret    

00020d6d <ck_ring_trydequeue_mpmc_xcpu>:
   20d6d:	55                   	push   %ebp
   20d6e:	89 e5                	mov    %esp,%ebp
   20d70:	83 ec 38             	sub    $0x38,%esp
   20d73:	8b 45 08             	mov    0x8(%ebp),%eax
   20d76:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20d79:	8b 45 0c             	mov    0xc(%ebp),%eax
   20d7c:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20d7f:	8b 45 10             	mov    0x10(%ebp),%eax
   20d82:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20d85:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_trydequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int size)
{
	const unsigned int mask = ring->mask;
   20d8c:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20d8f:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20d95:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   20d98:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20d9b:	89 04 24             	mov    %eax,(%esp)
   20d9e:	e8 68 d8 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20da3:	89 45 e0             	mov    %eax,-0x20(%ebp)
	ck_pr_fence_load();
   20da6:	e8 6b e5 ff ff       	call   1f316 <ck_pr_fence_load>
	producer = ck_pr_load_uint(&ring->p_tail);
   20dab:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20dae:	83 c0 40             	add    $0x40,%eax
   20db1:	89 04 24             	mov    %eax,(%esp)
   20db4:	e8 52 d8 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20db9:	89 45 dc             	mov    %eax,-0x24(%ebp)

	if (CK_CC_UNLIKELY(consumer == producer))
   20dbc:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20dbf:	3b 45 dc             	cmp    -0x24(%ebp),%eax
   20dc2:	0f 94 c0             	sete   %al
   20dc5:	0f b6 c0             	movzbl %al,%eax
   20dc8:	85 c0                	test   %eax,%eax
   20dca:	74 07                	je     20dd3 <ck_ring_trydequeue_mpmc_xcpu+0x66>
		return false;
   20dcc:	b8 00 00 00 00       	mov    $0x0,%eax
   20dd1:	eb 4e                	jmp    20e21 <ck_ring_trydequeue_mpmc_xcpu+0xb4>

	ck_pr_fence_load();
   20dd3:	e8 3e e5 ff ff       	call   1f316 <ck_pr_fence_load>

	buffer = (const char *)buffer + size * (consumer & mask);
   20dd8:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20ddb:	8b 55 e4             	mov    -0x1c(%ebp),%edx
   20dde:	21 d0                	and    %edx,%eax
   20de0:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   20de4:	01 45 f0             	add    %eax,-0x10(%ebp)
	memcpy(data, buffer, size);
   20de7:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20dea:	89 44 24 08          	mov    %eax,0x8(%esp)
   20dee:	8b 45 f0             	mov    -0x10(%ebp),%eax
   20df1:	89 44 24 04          	mov    %eax,0x4(%esp)
   20df5:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20df8:	89 04 24             	mov    %eax,(%esp)
   20dfb:	e8 fc ff ff ff       	call   20dfc <ck_ring_trydequeue_mpmc_xcpu+0x8f>

	ck_pr_fence_store_atomic();
   20e00:	e8 e5 e4 ff ff       	call   1f2ea <ck_pr_fence_store_atomic>
	return ck_pr_cas_uint(&ring->c_head, consumer, consumer + 1);
   20e05:	8b 45 e0             	mov    -0x20(%ebp),%eax
   20e08:	8d 50 01             	lea    0x1(%eax),%edx
   20e0b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20e0e:	89 54 24 08          	mov    %edx,0x8(%esp)
   20e12:	8b 55 e0             	mov    -0x20(%ebp),%edx
   20e15:	89 54 24 04          	mov    %edx,0x4(%esp)
   20e19:	89 04 24             	mov    %eax,(%esp)
   20e1c:	e8 98 e0 ff ff       	call   1eeb9 <ck_pr_cas_uint>
   20e21:	c9                   	leave  
   20e22:	c3                   	ret    

00020e23 <ck_ring_dequeue_mpmc_xcpu>:
   20e23:	55                   	push   %ebp
   20e24:	89 e5                	mov    %esp,%ebp
   20e26:	53                   	push   %ebx
   20e27:	83 ec 34             	sub    $0x34,%esp
   20e2a:	8b 45 08             	mov    0x8(%ebp),%eax
   20e2d:	89 45 f4             	mov    %eax,-0xc(%ebp)
   20e30:	8b 45 0c             	mov    0xc(%ebp),%eax
   20e33:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20e36:	8b 45 10             	mov    0x10(%ebp),%eax
   20e39:	89 45 ec             	mov    %eax,-0x14(%ebp)
   20e3c:	c7 45 e8 30 00 00 00 	movl   $0x30,-0x18(%ebp)
_ck_ring_dequeue_mc(struct ck_ring *ring,
    const void *buffer,
    void *data,
    unsigned int ts)
{
	const unsigned int mask = ring->mask;
   20e43:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20e46:	8b 80 84 00 00 00    	mov    0x84(%eax),%eax
   20e4c:	89 45 e4             	mov    %eax,-0x1c(%ebp)
	unsigned int consumer, producer;

	consumer = ck_pr_load_uint(&ring->c_head);
   20e4f:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20e52:	89 04 24             	mov    %eax,(%esp)
   20e55:	e8 b1 d7 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20e5a:	89 45 d8             	mov    %eax,-0x28(%ebp)

		/*
		 * Producer counter must represent state relative to
		 * our latest consumer snapshot.
		 */
		ck_pr_fence_load();
   20e5d:	e8 b4 e4 ff ff       	call   1f316 <ck_pr_fence_load>
		producer = ck_pr_load_uint(&ring->p_tail);
   20e62:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20e65:	83 c0 40             	add    $0x40,%eax
   20e68:	89 04 24             	mov    %eax,(%esp)
   20e6b:	e8 9b d7 ff ff       	call   1e60b <ck_pr_md_load_uint>
   20e70:	89 45 e0             	mov    %eax,-0x20(%ebp)

		if (CK_CC_UNLIKELY(consumer == producer))
   20e73:	8b 45 d8             	mov    -0x28(%ebp),%eax
   20e76:	39 45 e0             	cmp    %eax,-0x20(%ebp)
   20e79:	0f 94 c0             	sete   %al
   20e7c:	0f b6 c0             	movzbl %al,%eax
   20e7f:	85 c0                	test   %eax,%eax
   20e81:	74 07                	je     20e8a <ck_ring_dequeue_mpmc_xcpu+0x67>
			return false;
   20e83:	b8 00 00 00 00       	mov    $0x0,%eax
   20e88:	eb 6a                	jmp    20ef4 <ck_ring_dequeue_mpmc_xcpu+0xd1>

		ck_pr_fence_load();
   20e8a:	e8 87 e4 ff ff       	call   1f316 <ck_pr_fence_load>

		target = (const char *)buffer + ts * (consumer & mask);
   20e8f:	8b 45 d8             	mov    -0x28(%ebp),%eax
   20e92:	23 45 e4             	and    -0x1c(%ebp),%eax
   20e95:	0f af 45 e8          	imul   -0x18(%ebp),%eax
   20e99:	89 c2                	mov    %eax,%edx
   20e9b:	8b 45 f0             	mov    -0x10(%ebp),%eax
   20e9e:	01 d0                	add    %edx,%eax
   20ea0:	89 45 dc             	mov    %eax,-0x24(%ebp)
		memcpy(data, target, ts);
   20ea3:	8b 45 e8             	mov    -0x18(%ebp),%eax
   20ea6:	89 44 24 08          	mov    %eax,0x8(%esp)
   20eaa:	8b 45 dc             	mov    -0x24(%ebp),%eax
   20ead:	89 44 24 04          	mov    %eax,0x4(%esp)
   20eb1:	8b 45 ec             	mov    -0x14(%ebp),%eax
   20eb4:	89 04 24             	mov    %eax,(%esp)
   20eb7:	e8 fc ff ff ff       	call   20eb8 <ck_ring_dequeue_mpmc_xcpu+0x95>

		/* Serialize load with respect to head update. */
		ck_pr_fence_store_atomic();
   20ebc:	e8 29 e4 ff ff       	call   1f2ea <ck_pr_fence_store_atomic>
	} while (ck_pr_cas_uint_value(&ring->c_head,
   20ec1:	8b 45 d8             	mov    -0x28(%ebp),%eax
   20ec4:	8d 58 01             	lea    0x1(%eax),%ebx
   20ec7:	8b 55 d8             	mov    -0x28(%ebp),%edx
   20eca:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20ecd:	8d 4d d8             	lea    -0x28(%ebp),%ecx
   20ed0:	89 4c 24 0c          	mov    %ecx,0xc(%esp)
   20ed4:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   20ed8:	89 54 24 04          	mov    %edx,0x4(%esp)
   20edc:	89 04 24             	mov    %eax,(%esp)
   20edf:	e8 28 e1 ff ff       	call   1f00c <ck_pr_cas_uint_value>
				      consumer,
				      consumer + 1,
				      &consumer) == false);
   20ee4:	83 f0 01             	xor    $0x1,%eax
   20ee7:	84 c0                	test   %al,%al
   20ee9:	0f 85 6e ff ff ff    	jne    20e5d <ck_ring_dequeue_mpmc_xcpu+0x3a>

	return true;
   20eef:	b8 01 00 00 00       	mov    $0x1,%eax
   20ef4:	83 c4 34             	add    $0x34,%esp
   20ef7:	5b                   	pop    %ebx
   20ef8:	5d                   	pop    %ebp
   20ef9:	c3                   	ret    

00020efa <sl__globals_cpu>:

extern struct sl_global_cpu sl_global_cpu_data[];

static inline struct sl_global_cpu *
sl__globals_cpu(void)
{
   20efa:	55                   	push   %ebp
   20efb:	89 e5                	mov    %esp,%ebp
	return &(sl_global_cpu_data[cos_cpuid()]);
   20efd:	e8 8f d0 ff ff       	call   1df91 <cos_cpuid>
   20f02:	c1 e0 03             	shl    $0x3,%eax
   20f05:	8d 14 c5 00 00 00 00 	lea    0x0(,%eax,8),%edx
   20f0c:	29 c2                	sub    %eax,%edx
   20f0e:	8d 82 00 00 00 00    	lea    0x0(%edx),%eax
}
   20f14:	5d                   	pop    %ebp
   20f15:	c3                   	ret    

00020f16 <sl_thd_setprio>:

static inline void
sl_thd_setprio(struct sl_thd *t, tcap_prio_t p)
{
   20f16:	55                   	push   %ebp
   20f17:	89 e5                	mov    %esp,%ebp
   20f19:	83 ec 08             	sub    $0x8,%esp
   20f1c:	8b 45 0c             	mov    0xc(%ebp),%eax
   20f1f:	89 45 f8             	mov    %eax,-0x8(%ebp)
   20f22:	8b 45 10             	mov    0x10(%ebp),%eax
   20f25:	89 45 fc             	mov    %eax,-0x4(%ebp)
	t->prio = p;
   20f28:	8b 4d 08             	mov    0x8(%ebp),%ecx
   20f2b:	8b 45 f8             	mov    -0x8(%ebp),%eax
   20f2e:	8b 55 fc             	mov    -0x4(%ebp),%edx
   20f31:	89 41 28             	mov    %eax,0x28(%ecx)
   20f34:	89 51 2c             	mov    %edx,0x2c(%ecx)
}
   20f37:	c9                   	leave  
   20f38:	c3                   	ret    

00020f39 <sl_usec2cyc>:
	return cyc / sl__globals_cpu()->cyc_per_usec;
}

static inline cycles_t
sl_usec2cyc(microsec_t usec)
{
   20f39:	55                   	push   %ebp
   20f3a:	89 e5                	mov    %esp,%ebp
   20f3c:	53                   	push   %ebx
   20f3d:	83 ec 0c             	sub    $0xc,%esp
   20f40:	8b 45 08             	mov    0x8(%ebp),%eax
   20f43:	89 45 f0             	mov    %eax,-0x10(%ebp)
   20f46:	8b 45 0c             	mov    0xc(%ebp),%eax
   20f49:	89 45 f4             	mov    %eax,-0xc(%ebp)
	return usec * sl__globals_cpu()->cyc_per_usec;
   20f4c:	e8 a9 ff ff ff       	call   20efa <sl__globals_cpu>
   20f51:	8b 40 18             	mov    0x18(%eax),%eax
   20f54:	99                   	cltd   
   20f55:	8b 4d f0             	mov    -0x10(%ebp),%ecx
   20f58:	89 cb                	mov    %ecx,%ebx
   20f5a:	0f af da             	imul   %edx,%ebx
   20f5d:	8b 4d f4             	mov    -0xc(%ebp),%ecx
   20f60:	0f af c8             	imul   %eax,%ecx
   20f63:	01 d9                	add    %ebx,%ecx
   20f65:	f7 65 f0             	mull   -0x10(%ebp)
   20f68:	01 d1                	add    %edx,%ecx
   20f6a:	89 ca                	mov    %ecx,%edx
}
   20f6c:	83 c4 0c             	add    $0xc,%esp
   20f6f:	5b                   	pop    %ebx
   20f70:	5d                   	pop    %ebp
   20f71:	c3                   	ret    

00020f72 <sl_mod_execution>:
struct ps_list_head threads[NUM_CPU][SL_FPRR_NPRIOS] CACHE_ALIGNED;

/* No RR yet */
void
sl_mod_execution(struct sl_thd_policy *t, cycles_t cycles)
{ }
   20f72:	55                   	push   %ebp
   20f73:	89 e5                	mov    %esp,%ebp
   20f75:	83 ec 08             	sub    $0x8,%esp
   20f78:	8b 45 0c             	mov    0xc(%ebp),%eax
   20f7b:	89 45 f8             	mov    %eax,-0x8(%ebp)
   20f7e:	8b 45 10             	mov    0x10(%ebp),%eax
   20f81:	89 45 fc             	mov    %eax,-0x4(%ebp)
   20f84:	c9                   	leave  
   20f85:	c3                   	ret    

00020f86 <sl_mod_schedule>:

struct sl_thd_policy *
sl_mod_schedule(void)
{
   20f86:	55                   	push   %ebp
   20f87:	89 e5                	mov    %esp,%ebp
   20f89:	53                   	push   %ebx
   20f8a:	83 ec 18             	sub    $0x18,%esp
	int i;
	struct sl_thd_policy *t;

	for (i = 0 ; i < SL_FPRR_NPRIOS ; i++) {
   20f8d:	c7 45 f8 00 00 00 00 	movl   $0x0,-0x8(%ebp)
   20f94:	e9 87 00 00 00       	jmp    21020 <sl_mod_schedule+0x9a>
		if (ps_list_head_empty(&threads[cos_cpuid()][i])) continue;
   20f99:	e8 f3 cf ff ff       	call   1df91 <cos_cpuid>
   20f9e:	c1 e0 05             	shl    $0x5,%eax
   20fa1:	89 c2                	mov    %eax,%edx
   20fa3:	8b 45 f8             	mov    -0x8(%ebp),%eax
   20fa6:	01 d0                	add    %edx,%eax
   20fa8:	c1 e0 03             	shl    $0x3,%eax
   20fab:	05 00 00 00 00       	add    $0x0,%eax
   20fb0:	89 04 24             	mov    %eax,(%esp)
   20fb3:	e8 6e d2 ff ff       	call   1e226 <ps_list_head_empty>
   20fb8:	85 c0                	test   %eax,%eax
   20fba:	74 06                	je     20fc2 <sl_mod_schedule+0x3c>
sl_mod_schedule(void)
{
	int i;
	struct sl_thd_policy *t;

	for (i = 0 ; i < SL_FPRR_NPRIOS ; i++) {
   20fbc:	83 45 f8 01          	addl   $0x1,-0x8(%ebp)
   20fc0:	eb 5e                	jmp    21020 <sl_mod_schedule+0x9a>
		if (ps_list_head_empty(&threads[cos_cpuid()][i])) continue;
		t = ps_list_head_first_d(&threads[cos_cpuid()][i], struct sl_thd_policy);
   20fc2:	e8 ca cf ff ff       	call   1df91 <cos_cpuid>
   20fc7:	c1 e0 05             	shl    $0x5,%eax
   20fca:	89 c2                	mov    %eax,%edx
   20fcc:	8b 45 f8             	mov    -0x8(%ebp),%eax
   20fcf:	01 d0                	add    %edx,%eax
   20fd1:	8b 04 c5 00 00 00 00 	mov    0x0(,%eax,8),%eax
   20fd8:	2d 90 00 00 00       	sub    $0x90,%eax
   20fdd:	89 45 f4             	mov    %eax,-0xc(%ebp)

		/*
		 * We want to move the selected thread to the back of the list.
		 * Otherwise fprr won't be truly round robin
		 */
		ps_list_rem_d(t);
   20fe0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20fe3:	05 90 00 00 00       	add    $0x90,%eax
   20fe8:	89 04 24             	mov    %eax,(%esp)
   20feb:	e8 74 d2 ff ff       	call   1e264 <ps_list_ll_rem>
		ps_list_head_append_d(&threads[cos_cpuid()][i], t);
   20ff0:	8b 45 f4             	mov    -0xc(%ebp),%eax
   20ff3:	8d 98 90 00 00 00    	lea    0x90(%eax),%ebx
   20ff9:	e8 93 cf ff ff       	call   1df91 <cos_cpuid>
   20ffe:	c1 e0 05             	shl    $0x5,%eax
   21001:	89 c2                	mov    %eax,%edx
   21003:	8b 45 f8             	mov    -0x8(%ebp),%eax
   21006:	01 d0                	add    %edx,%eax
   21008:	8b 04 c5 04 00 00 00 	mov    0x4(,%eax,8),%eax
   2100f:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   21013:	89 04 24             	mov    %eax,(%esp)
   21016:	e8 1e d2 ff ff       	call   1e239 <ps_list_ll_add>

		return t;
   2101b:	8b 45 f4             	mov    -0xc(%ebp),%eax
   2101e:	eb 0f                	jmp    2102f <sl_mod_schedule+0xa9>
sl_mod_schedule(void)
{
	int i;
	struct sl_thd_policy *t;

	for (i = 0 ; i < SL_FPRR_NPRIOS ; i++) {
   21020:	83 7d f8 1f          	cmpl   $0x1f,-0x8(%ebp)
   21024:	0f 8e 6f ff ff ff    	jle    20f99 <sl_mod_schedule+0x13>
		ps_list_head_append_d(&threads[cos_cpuid()][i], t);

		return t;
	}

	return NULL;
   2102a:	b8 00 00 00 00       	mov    $0x0,%eax
}
   2102f:	83 c4 18             	add    $0x18,%esp
   21032:	5b                   	pop    %ebx
   21033:	5d                   	pop    %ebp
   21034:	c3                   	ret    

00021035 <sl_mod_block>:

void
sl_mod_block(struct sl_thd_policy *t)
{
   21035:	55                   	push   %ebp
   21036:	89 e5                	mov    %esp,%ebp
   21038:	83 ec 04             	sub    $0x4,%esp
	ps_list_rem_d(t);
   2103b:	8b 45 08             	mov    0x8(%ebp),%eax
   2103e:	05 90 00 00 00       	add    $0x90,%eax
   21043:	89 04 24             	mov    %eax,(%esp)
   21046:	e8 19 d2 ff ff       	call   1e264 <ps_list_ll_rem>
}
   2104b:	c9                   	leave  
   2104c:	c3                   	ret    

0002104d <sl_mod_wakeup>:

void
sl_mod_wakeup(struct sl_thd_policy *t)
{
   2104d:	55                   	push   %ebp
   2104e:	89 e5                	mov    %esp,%ebp
   21050:	53                   	push   %ebx
   21051:	83 ec 14             	sub    $0x14,%esp
	assert(ps_list_singleton_d(t));
   21054:	8b 45 08             	mov    0x8(%ebp),%eax
   21057:	05 90 00 00 00       	add    $0x90,%eax
   2105c:	89 04 24             	mov    %eax,(%esp)
   2105f:	e8 af d1 ff ff       	call   1e213 <ps_list_ll_empty>
   21064:	85 c0                	test   %eax,%eax
   21066:	0f 94 c0             	sete   %al
   21069:	0f b6 c0             	movzbl %al,%eax
   2106c:	85 c0                	test   %eax,%eax
   2106e:	74 1c                	je     2108c <sl_mod_wakeup+0x3f>
   21070:	c7 04 24 b8 38 00 00 	movl   $0x38b8,(%esp)
   21077:	e8 90 d0 ff ff       	call   1e10c <prints>
   2107c:	a1 04 39 00 00       	mov    0x3904,%eax
   21081:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   21087:	e8 07 d1 ff ff       	call   1e193 <__cos_noret>

	ps_list_head_append_d(&threads[cos_cpuid()][t->priority - 1], t);
   2108c:	8b 45 08             	mov    0x8(%ebp),%eax
   2108f:	8d 98 90 00 00 00    	lea    0x90(%eax),%ebx
   21095:	e8 f7 ce ff ff       	call   1df91 <cos_cpuid>
   2109a:	89 c1                	mov    %eax,%ecx
   2109c:	8b 45 08             	mov    0x8(%ebp),%eax
   2109f:	8b 50 7c             	mov    0x7c(%eax),%edx
   210a2:	8b 40 78             	mov    0x78(%eax),%eax
   210a5:	83 c0 ff             	add    $0xffffffff,%eax
   210a8:	83 d2 ff             	adc    $0xffffffff,%edx
   210ab:	c1 e1 05             	shl    $0x5,%ecx
   210ae:	01 c8                	add    %ecx,%eax
   210b0:	8b 04 c5 04 00 00 00 	mov    0x4(,%eax,8),%eax
   210b7:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   210bb:	89 04 24             	mov    %eax,(%esp)
   210be:	e8 76 d1 ff ff       	call   1e239 <ps_list_ll_add>
}
   210c3:	83 c4 14             	add    $0x14,%esp
   210c6:	5b                   	pop    %ebx
   210c7:	5d                   	pop    %ebp
   210c8:	c3                   	ret    

000210c9 <sl_mod_yield>:

void
sl_mod_yield(struct sl_thd_policy *t, struct sl_thd_policy *yield_to)
{
   210c9:	55                   	push   %ebp
   210ca:	89 e5                	mov    %esp,%ebp
   210cc:	53                   	push   %ebx
   210cd:	83 ec 0c             	sub    $0xc,%esp
	ps_list_rem_d(t);
   210d0:	8b 45 08             	mov    0x8(%ebp),%eax
   210d3:	05 90 00 00 00       	add    $0x90,%eax
   210d8:	89 04 24             	mov    %eax,(%esp)
   210db:	e8 84 d1 ff ff       	call   1e264 <ps_list_ll_rem>
	ps_list_head_append_d(&threads[cos_cpuid()][t->priority - 1], t);
   210e0:	8b 45 08             	mov    0x8(%ebp),%eax
   210e3:	8d 98 90 00 00 00    	lea    0x90(%eax),%ebx
   210e9:	e8 a3 ce ff ff       	call   1df91 <cos_cpuid>
   210ee:	89 c1                	mov    %eax,%ecx
   210f0:	8b 45 08             	mov    0x8(%ebp),%eax
   210f3:	8b 50 7c             	mov    0x7c(%eax),%edx
   210f6:	8b 40 78             	mov    0x78(%eax),%eax
   210f9:	83 c0 ff             	add    $0xffffffff,%eax
   210fc:	83 d2 ff             	adc    $0xffffffff,%edx
   210ff:	c1 e1 05             	shl    $0x5,%ecx
   21102:	01 c8                	add    %ecx,%eax
   21104:	8b 04 c5 04 00 00 00 	mov    0x4(,%eax,8),%eax
   2110b:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   2110f:	89 04 24             	mov    %eax,(%esp)
   21112:	e8 22 d1 ff ff       	call   1e239 <ps_list_ll_add>
}
   21117:	83 c4 0c             	add    $0xc,%esp
   2111a:	5b                   	pop    %ebx
   2111b:	5d                   	pop    %ebp
   2111c:	c3                   	ret    

0002111d <sl_mod_thd_create>:

void
sl_mod_thd_create(struct sl_thd_policy *t)
{
   2111d:	55                   	push   %ebp
   2111e:	89 e5                	mov    %esp,%ebp
   21120:	56                   	push   %esi
   21121:	53                   	push   %ebx
   21122:	83 ec 10             	sub    $0x10,%esp
	t->priority    = SL_FPRR_PRIO_LOWEST;
   21125:	8b 45 08             	mov    0x8(%ebp),%eax
   21128:	c7 40 78 20 00 00 00 	movl   $0x20,0x78(%eax)
   2112f:	c7 40 7c 00 00 00 00 	movl   $0x0,0x7c(%eax)
	t->period      = 0;
   21136:	8b 45 08             	mov    0x8(%ebp),%eax
   21139:	c7 80 88 00 00 00 00 	movl   $0x0,0x88(%eax)
   21140:	00 00 00 
   21143:	c7 80 8c 00 00 00 00 	movl   $0x0,0x8c(%eax)
   2114a:	00 00 00 
	t->period_usec = 0;
   2114d:	8b 45 08             	mov    0x8(%ebp),%eax
   21150:	c7 80 80 00 00 00 00 	movl   $0x0,0x80(%eax)
   21157:	00 00 00 
   2115a:	c7 80 84 00 00 00 00 	movl   $0x0,0x84(%eax)
   21161:	00 00 00 
	sl_thd_setprio(sl_mod_thd_get(t), t->priority);
   21164:	8b 45 08             	mov    0x8(%ebp),%eax
   21167:	8b 58 78             	mov    0x78(%eax),%ebx
   2116a:	8b 70 7c             	mov    0x7c(%eax),%esi
   2116d:	8b 45 08             	mov    0x8(%ebp),%eax
   21170:	89 04 24             	mov    %eax,(%esp)
   21173:	e8 71 d2 ff ff       	call   1e3e9 <sl_mod_thd_get>
   21178:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   2117c:	89 74 24 08          	mov    %esi,0x8(%esp)
   21180:	89 04 24             	mov    %eax,(%esp)
   21183:	e8 8e fd ff ff       	call   20f16 <sl_thd_setprio>
	ps_list_init_d(t);
   21188:	8b 45 08             	mov    0x8(%ebp),%eax
   2118b:	05 90 00 00 00       	add    $0x90,%eax
   21190:	89 04 24             	mov    %eax,(%esp)
   21193:	e8 4f d0 ff ff       	call   1e1e7 <ps_list_ll_init>
}
   21198:	83 c4 10             	add    $0x10,%esp
   2119b:	5b                   	pop    %ebx
   2119c:	5e                   	pop    %esi
   2119d:	5d                   	pop    %ebp
   2119e:	c3                   	ret    

0002119f <sl_mod_thd_delete>:

void
sl_mod_thd_delete(struct sl_thd_policy *t)
{ ps_list_rem_d(t); }
   2119f:	55                   	push   %ebp
   211a0:	89 e5                	mov    %esp,%ebp
   211a2:	83 ec 04             	sub    $0x4,%esp
   211a5:	8b 45 08             	mov    0x8(%ebp),%eax
   211a8:	05 90 00 00 00       	add    $0x90,%eax
   211ad:	89 04 24             	mov    %eax,(%esp)
   211b0:	e8 af d0 ff ff       	call   1e264 <ps_list_ll_rem>
   211b5:	c9                   	leave  
   211b6:	c3                   	ret    

000211b7 <sl_mod_thd_param_set>:

void
sl_mod_thd_param_set(struct sl_thd_policy *t, sched_param_type_t type, unsigned int v)
{
   211b7:	55                   	push   %ebp
   211b8:	89 e5                	mov    %esp,%ebp
   211ba:	56                   	push   %esi
   211bb:	53                   	push   %ebx
   211bc:	83 ec 10             	sub    $0x10,%esp
	switch (type) {
   211bf:	8b 45 0c             	mov    0xc(%ebp),%eax
   211c2:	83 f8 05             	cmp    $0x5,%eax
   211c5:	0f 84 50 01 00 00    	je     2131b <sl_mod_thd_param_set+0x164>
   211cb:	83 f8 06             	cmp    $0x6,%eax
   211ce:	0f 84 c2 00 00 00    	je     21296 <sl_mod_thd_param_set+0xdf>
   211d4:	83 f8 01             	cmp    $0x1,%eax
   211d7:	0f 85 22 01 00 00    	jne    212ff <sl_mod_thd_param_set+0x148>
	case SCHEDP_PRIO:
	{
		assert(v >= SL_FPRR_PRIO_HIGHEST && v <= SL_FPRR_PRIO_LOWEST);
   211dd:	83 7d 10 00          	cmpl   $0x0,0x10(%ebp)
   211e1:	0f 94 c0             	sete   %al
   211e4:	0f b6 c0             	movzbl %al,%eax
   211e7:	85 c0                	test   %eax,%eax
   211e9:	75 0e                	jne    211f9 <sl_mod_thd_param_set+0x42>
   211eb:	83 7d 10 20          	cmpl   $0x20,0x10(%ebp)
   211ef:	0f 97 c0             	seta   %al
   211f2:	0f b6 c0             	movzbl %al,%eax
   211f5:	85 c0                	test   %eax,%eax
   211f7:	74 1c                	je     21215 <sl_mod_thd_param_set+0x5e>
   211f9:	c7 04 24 e4 38 00 00 	movl   $0x38e4,(%esp)
   21200:	e8 07 cf ff ff       	call   1e10c <prints>
   21205:	a1 04 39 00 00       	mov    0x3904,%eax
   2120a:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   21210:	e8 7e cf ff ff       	call   1e193 <__cos_noret>
		ps_list_rem_d(t); /* if we're already on a list, and we're updating priority */
   21215:	8b 45 08             	mov    0x8(%ebp),%eax
   21218:	05 90 00 00 00       	add    $0x90,%eax
   2121d:	89 04 24             	mov    %eax,(%esp)
   21220:	e8 3f d0 ff ff       	call   1e264 <ps_list_ll_rem>
		t->priority = v;
   21225:	8b 45 10             	mov    0x10(%ebp),%eax
   21228:	ba 00 00 00 00       	mov    $0x0,%edx
   2122d:	8b 4d 08             	mov    0x8(%ebp),%ecx
   21230:	89 41 78             	mov    %eax,0x78(%ecx)
   21233:	89 51 7c             	mov    %edx,0x7c(%ecx)
		ps_list_head_append_d(&threads[cos_cpuid()][t->priority - 1], t);
   21236:	8b 45 08             	mov    0x8(%ebp),%eax
   21239:	8d 98 90 00 00 00    	lea    0x90(%eax),%ebx
   2123f:	e8 4d cd ff ff       	call   1df91 <cos_cpuid>
   21244:	89 c1                	mov    %eax,%ecx
   21246:	8b 45 08             	mov    0x8(%ebp),%eax
   21249:	8b 50 7c             	mov    0x7c(%eax),%edx
   2124c:	8b 40 78             	mov    0x78(%eax),%eax
   2124f:	83 c0 ff             	add    $0xffffffff,%eax
   21252:	83 d2 ff             	adc    $0xffffffff,%edx
   21255:	c1 e1 05             	shl    $0x5,%ecx
   21258:	01 c8                	add    %ecx,%eax
   2125a:	8b 04 c5 04 00 00 00 	mov    0x4(,%eax,8),%eax
   21261:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   21265:	89 04 24             	mov    %eax,(%esp)
   21268:	e8 cc cf ff ff       	call   1e239 <ps_list_ll_add>
		sl_thd_setprio(sl_mod_thd_get(t), t->priority);
   2126d:	8b 45 08             	mov    0x8(%ebp),%eax
   21270:	8b 58 78             	mov    0x78(%eax),%ebx
   21273:	8b 70 7c             	mov    0x7c(%eax),%esi
   21276:	8b 45 08             	mov    0x8(%ebp),%eax
   21279:	89 04 24             	mov    %eax,(%esp)
   2127c:	e8 68 d1 ff ff       	call   1e3e9 <sl_mod_thd_get>
   21281:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   21285:	89 74 24 08          	mov    %esi,0x8(%esp)
   21289:	89 04 24             	mov    %eax,(%esp)
   2128c:	e8 85 fc ff ff       	call   20f16 <sl_thd_setprio>

		break;
   21291:	e9 86 00 00 00       	jmp    2131c <sl_mod_thd_param_set+0x165>
	}
	case SCHEDP_WINDOW:
	{
		assert(v >= SL_FPRR_PERIOD_US_MIN);
   21296:	81 7d 10 e7 03 00 00 	cmpl   $0x3e7,0x10(%ebp)
   2129d:	0f 96 c0             	setbe  %al
   212a0:	0f b6 c0             	movzbl %al,%eax
   212a3:	85 c0                	test   %eax,%eax
   212a5:	74 1c                	je     212c3 <sl_mod_thd_param_set+0x10c>
   212a7:	c7 04 24 10 39 00 00 	movl   $0x3910,(%esp)
   212ae:	e8 59 ce ff ff       	call   1e10c <prints>
   212b3:	a1 04 39 00 00       	mov    0x3904,%eax
   212b8:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   212be:	e8 d0 ce ff ff       	call   1e193 <__cos_noret>
		t->period_usec    = v;
   212c3:	8b 45 10             	mov    0x10(%ebp),%eax
   212c6:	ba 00 00 00 00       	mov    $0x0,%edx
   212cb:	8b 4d 08             	mov    0x8(%ebp),%ecx
   212ce:	89 81 80 00 00 00    	mov    %eax,0x80(%ecx)
   212d4:	89 91 84 00 00 00    	mov    %edx,0x84(%ecx)
		t->period         = sl_usec2cyc(v);
   212da:	8b 45 10             	mov    0x10(%ebp),%eax
   212dd:	ba 00 00 00 00       	mov    $0x0,%edx
   212e2:	89 04 24             	mov    %eax,(%esp)
   212e5:	89 54 24 04          	mov    %edx,0x4(%esp)
   212e9:	e8 4b fc ff ff       	call   20f39 <sl_usec2cyc>
   212ee:	8b 4d 08             	mov    0x8(%ebp),%ecx
   212f1:	89 81 88 00 00 00    	mov    %eax,0x88(%ecx)
   212f7:	89 91 8c 00 00 00    	mov    %edx,0x8c(%ecx)
		/* FIXME: synchronize periods for all tasks */

		break;
   212fd:	eb 1d                	jmp    2131c <sl_mod_thd_param_set+0x165>
	}
	case SCHEDP_BUDGET:
	{
		break;
	}
	default: assert(0);
   212ff:	c7 04 24 3c 39 00 00 	movl   $0x393c,(%esp)
   21306:	e8 01 ce ff ff       	call   1e10c <prints>
   2130b:	a1 04 39 00 00       	mov    0x3904,%eax
   21310:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   21316:	e8 78 ce ff ff       	call   1e193 <__cos_noret>

		break;
	}
	case SCHEDP_BUDGET:
	{
		break;
   2131b:	90                   	nop
	}
	default: assert(0);
	}
}
   2131c:	83 c4 10             	add    $0x10,%esp
   2131f:	5b                   	pop    %ebx
   21320:	5e                   	pop    %esi
   21321:	5d                   	pop    %ebp
   21322:	c3                   	ret    

00021323 <sl_mod_init>:

void
sl_mod_init(void)
{
   21323:	55                   	push   %ebp
   21324:	89 e5                	mov    %esp,%ebp
   21326:	83 ec 28             	sub    $0x28,%esp
	int i;

	memset(threads[cos_cpuid()], 0, sizeof(struct ps_list_head) * SL_FPRR_NPRIOS);
   21329:	e8 63 cc ff ff       	call   1df91 <cos_cpuid>
   2132e:	c1 e0 08             	shl    $0x8,%eax
   21331:	05 00 00 00 00       	add    $0x0,%eax
   21336:	c7 44 24 08 00 01 00 	movl   $0x100,0x8(%esp)
   2133d:	00 
   2133e:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   21345:	00 
   21346:	89 04 24             	mov    %eax,(%esp)
   21349:	e8 fc ff ff ff       	call   2134a <sl_mod_init+0x27>
	for (i = 0 ; i < SL_FPRR_NPRIOS ; i++) {
   2134e:	c7 45 f4 00 00 00 00 	movl   $0x0,-0xc(%ebp)
   21355:	eb 23                	jmp    2137a <sl_mod_init+0x57>
		ps_list_head_init(&threads[cos_cpuid()][i]);
   21357:	e8 35 cc ff ff       	call   1df91 <cos_cpuid>
   2135c:	c1 e0 05             	shl    $0x5,%eax
   2135f:	89 c2                	mov    %eax,%edx
   21361:	8b 45 f4             	mov    -0xc(%ebp),%eax
   21364:	01 d0                	add    %edx,%eax
   21366:	c1 e0 03             	shl    $0x3,%eax
   21369:	05 00 00 00 00       	add    $0x0,%eax
   2136e:	89 04 24             	mov    %eax,(%esp)
   21371:	e8 8a ce ff ff       	call   1e200 <ps_list_head_init>
sl_mod_init(void)
{
	int i;

	memset(threads[cos_cpuid()], 0, sizeof(struct ps_list_head) * SL_FPRR_NPRIOS);
	for (i = 0 ; i < SL_FPRR_NPRIOS ; i++) {
   21376:	83 45 f4 01          	addl   $0x1,-0xc(%ebp)
   2137a:	83 7d f4 1f          	cmpl   $0x1f,-0xc(%ebp)
   2137e:	7e d7                	jle    21357 <sl_mod_init+0x34>
		ps_list_head_init(&threads[cos_cpuid()][i]);
	}
}
   21380:	c9                   	leave  
   21381:	c3                   	ret    
   21382:	66 90                	xchg   %ax,%ax
   21384:	66 90                	xchg   %ax,%ax
   21386:	66 90                	xchg   %ax,%ax
   21388:	66 90                	xchg   %ax,%ax
   2138a:	66 90                	xchg   %ax,%ax
   2138c:	66 90                	xchg   %ax,%ax
   2138e:	66 90                	xchg   %ax,%ax

00021390 <_init>:
   21390:	f3 c3                	repz ret 
   21392:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   21399:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

000213a0 <__init_ssp>:
   213a0:	f3 c3                	repz ret 
   213a2:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   213a9:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

000213b0 <__init_libc>:
   213b0:	57                   	push   %edi
   213b1:	31 c0                	xor    %eax,%eax
   213b3:	56                   	push   %esi
   213b4:	b9 26 00 00 00       	mov    $0x26,%ecx
   213b9:	53                   	push   %ebx
   213ba:	81 ec d0 00 00 00    	sub    $0xd0,%esp
   213c0:	8b 94 24 e0 00 00 00 	mov    0xe0(%esp),%edx
   213c7:	8d 74 24 38          	lea    0x38(%esp),%esi
   213cb:	89 f7                	mov    %esi,%edi
   213cd:	8b 9c 24 e4 00 00 00 	mov    0xe4(%esp),%ebx
   213d4:	f3 ab                	rep stos %eax,%es:(%edi)
   213d6:	89 15 00 00 00 00    	mov    %edx,0x0
   213dc:	8b 3a                	mov    (%edx),%edi
   213de:	85 ff                	test   %edi,%edi
   213e0:	0f 84 68 02 00 00    	je     2164e <__init_libc+0x29e>
   213e6:	66 90                	xchg   %ax,%ax
   213e8:	83 c0 01             	add    $0x1,%eax
   213eb:	8b 0c 82             	mov    (%edx,%eax,4),%ecx
   213ee:	85 c9                	test   %ecx,%ecx
   213f0:	75 f6                	jne    213e8 <__init_libc+0x38>
   213f2:	8d 04 85 04 00 00 00 	lea    0x4(,%eax,4),%eax
   213f9:	01 c2                	add    %eax,%edx
   213fb:	8b 02                	mov    (%edx),%eax
   213fd:	89 15 10 00 00 00    	mov    %edx,0x10
   21403:	85 c0                	test   %eax,%eax
   21405:	0f 84 4d 02 00 00    	je     21658 <__init_libc+0x2a8>
   2140b:	83 c2 08             	add    $0x8,%edx
   2140e:	66 90                	xchg   %ax,%ax
   21410:	83 f8 25             	cmp    $0x25,%eax
   21413:	77 07                	ja     2141c <__init_libc+0x6c>
   21415:	8b 4a fc             	mov    -0x4(%edx),%ecx
   21418:	89 4c 84 38          	mov    %ecx,0x38(%esp,%eax,4)
   2141c:	83 c2 08             	add    $0x8,%edx
   2141f:	8b 42 f8             	mov    -0x8(%edx),%eax
   21422:	85 c0                	test   %eax,%eax
   21424:	75 ea                	jne    21410 <__init_libc+0x60>
   21426:	8b 4c 24 78          	mov    0x78(%esp),%ecx
   2142a:	8b 94 24 b8 00 00 00 	mov    0xb8(%esp),%edx
   21431:	8b 44 24 50          	mov    0x50(%esp),%eax
   21435:	85 db                	test   %ebx,%ebx
   21437:	89 0d 00 00 00 00    	mov    %ecx,0x0
   2143d:	89 15 00 00 00 00    	mov    %edx,0x0
   21443:	a3 18 00 00 00       	mov    %eax,0x18
   21448:	74 3c                	je     21486 <__init_libc+0xd6>
   2144a:	89 1d 00 00 00 00    	mov    %ebx,0x0
   21450:	89 1d 00 00 00 00    	mov    %ebx,0x0
   21456:	0f b6 03             	movzbl (%ebx),%eax
   21459:	84 c0                	test   %al,%al
   2145b:	74 29                	je     21486 <__init_libc+0xd6>
   2145d:	83 c3 01             	add    $0x1,%ebx
   21460:	eb 10                	jmp    21472 <__init_libc+0xc2>
   21462:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   21468:	0f b6 03             	movzbl (%ebx),%eax
   2146b:	83 c3 01             	add    $0x1,%ebx
   2146e:	84 c0                	test   %al,%al
   21470:	74 14                	je     21486 <__init_libc+0xd6>
   21472:	3c 2f                	cmp    $0x2f,%al
   21474:	75 f2                	jne    21468 <__init_libc+0xb8>
   21476:	89 1d 00 00 00 00    	mov    %ebx,0x0
   2147c:	0f b6 03             	movzbl (%ebx),%eax
   2147f:	83 c3 01             	add    $0x1,%ebx
   21482:	84 c0                	test   %al,%al
   21484:	75 ec                	jne    21472 <__init_libc+0xc2>
   21486:	89 34 24             	mov    %esi,(%esp)
   21489:	e8 fc ff ff ff       	call   2148a <__init_libc+0xda>
   2148e:	8b 84 24 9c 00 00 00 	mov    0x9c(%esp),%eax
   21495:	89 04 24             	mov    %eax,(%esp)
   21498:	e8 fc ff ff ff       	call   21499 <__init_libc+0xe9>
   2149d:	8b 44 24 68          	mov    0x68(%esp),%eax
   214a1:	39 44 24 64          	cmp    %eax,0x64(%esp)
   214a5:	0f 84 95 00 00 00    	je     21540 <__init_libc+0x190>
   214ab:	31 c0                	xor    %eax,%eax
   214ad:	c7 44 04 20 00 00 00 	movl   $0x0,0x20(%esp,%eax,1)
   214b4:	00 
   214b5:	83 c0 04             	add    $0x4,%eax
   214b8:	83 f8 18             	cmp    $0x18,%eax
   214bb:	72 f0                	jb     214ad <__init_libc+0xfd>
   214bd:	8d 44 24 20          	lea    0x20(%esp),%eax
   214c1:	89 04 24             	mov    %eax,(%esp)
   214c4:	b8 a8 00 00 00       	mov    $0xa8,%eax
   214c9:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   214d0:	00 
   214d1:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   214d8:	00 
   214d9:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   214e0:	00 
   214e1:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   214e8:	00 
   214e9:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   214f0:	00 
   214f1:	c7 44 24 04 03 00 00 	movl   $0x3,0x4(%esp)
   214f8:	00 
   214f9:	c7 44 24 28 01 00 00 	movl   $0x1,0x28(%esp)
   21500:	00 
   21501:	c7 44 24 30 02 00 00 	movl   $0x2,0x30(%esp)
   21508:	00 
   21509:	e8 fc ff ff ff       	call   2150a <__init_libc+0x15a>
   2150e:	f6 44 24 26 20       	testb  $0x20,0x26(%esp)
   21513:	0f 85 e6 00 00 00    	jne    215ff <__init_libc+0x24f>
   21519:	f6 44 24 2e 20       	testb  $0x20,0x2e(%esp)
   2151e:	0f 85 8c 00 00 00    	jne    215b0 <__init_libc+0x200>
   21524:	f6 44 24 36 20       	testb  $0x20,0x36(%esp)
   21529:	75 35                	jne    21560 <__init_libc+0x1b0>
   2152b:	c7 05 08 00 00 00 01 	movl   $0x1,0x8
   21532:	00 00 00 
   21535:	81 c4 d0 00 00 00    	add    $0xd0,%esp
   2153b:	5b                   	pop    %ebx
   2153c:	5e                   	pop    %esi
   2153d:	5f                   	pop    %edi
   2153e:	c3                   	ret    
   2153f:	90                   	nop
   21540:	8b 44 24 70          	mov    0x70(%esp),%eax
   21544:	39 44 24 6c          	cmp    %eax,0x6c(%esp)
   21548:	0f 85 5d ff ff ff    	jne    214ab <__init_libc+0xfb>
   2154e:	8b 84 24 94 00 00 00 	mov    0x94(%esp),%eax
   21555:	85 c0                	test   %eax,%eax
   21557:	74 dc                	je     21535 <__init_libc+0x185>
   21559:	e9 4d ff ff ff       	jmp    214ab <__init_libc+0xfb>
   2155e:	66 90                	xchg   %ax,%ax
   21560:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   21567:	00 
   21568:	b8 05 00 00 00       	mov    $0x5,%eax
   2156d:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   21574:	00 
   21575:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   2157c:	00 
   2157d:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   21584:	00 
   21585:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   2158c:	00 
   2158d:	c7 44 24 04 02 80 00 	movl   $0x8002,0x4(%esp)
   21594:	00 
   21595:	c7 04 24 20 45 00 00 	movl   $0x4520,(%esp)
   2159c:	e8 fc ff ff ff       	call   2159d <__init_libc+0x1ed>
   215a1:	85 c0                	test   %eax,%eax
   215a3:	79 86                	jns    2152b <__init_libc+0x17b>
   215a5:	f4                   	hlt    
   215a6:	e9 80 ff ff ff       	jmp    2152b <__init_libc+0x17b>
   215ab:	90                   	nop
   215ac:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   215b0:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   215b7:	00 
   215b8:	b8 05 00 00 00       	mov    $0x5,%eax
   215bd:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   215c4:	00 
   215c5:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   215cc:	00 
   215cd:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   215d4:	00 
   215d5:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   215dc:	00 
   215dd:	c7 44 24 04 02 80 00 	movl   $0x8002,0x4(%esp)
   215e4:	00 
   215e5:	c7 04 24 20 45 00 00 	movl   $0x4520,(%esp)
   215ec:	e8 fc ff ff ff       	call   215ed <__init_libc+0x23d>
   215f1:	85 c0                	test   %eax,%eax
   215f3:	0f 89 2b ff ff ff    	jns    21524 <__init_libc+0x174>
   215f9:	f4                   	hlt    
   215fa:	e9 25 ff ff ff       	jmp    21524 <__init_libc+0x174>
   215ff:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   21606:	00 
   21607:	b8 05 00 00 00       	mov    $0x5,%eax
   2160c:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   21613:	00 
   21614:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   2161b:	00 
   2161c:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   21623:	00 
   21624:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   2162b:	00 
   2162c:	c7 44 24 04 02 80 00 	movl   $0x8002,0x4(%esp)
   21633:	00 
   21634:	c7 04 24 20 45 00 00 	movl   $0x4520,(%esp)
   2163b:	e8 fc ff ff ff       	call   2163c <__init_libc+0x28c>
   21640:	85 c0                	test   %eax,%eax
   21642:	0f 89 d1 fe ff ff    	jns    21519 <__init_libc+0x169>
   21648:	f4                   	hlt    
   21649:	e9 cb fe ff ff       	jmp    21519 <__init_libc+0x169>
   2164e:	b8 04 00 00 00       	mov    $0x4,%eax
   21653:	e9 a1 fd ff ff       	jmp    213f9 <__init_libc+0x49>
   21658:	31 c0                	xor    %eax,%eax
   2165a:	31 d2                	xor    %edx,%edx
   2165c:	31 c9                	xor    %ecx,%ecx
   2165e:	e9 d2 fd ff ff       	jmp    21435 <__init_libc+0x85>
   21663:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   21669:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

00021670 <__libc_start_main>:
   21670:	55                   	push   %ebp
   21671:	57                   	push   %edi
   21672:	56                   	push   %esi
   21673:	53                   	push   %ebx
   21674:	bb 00 00 00 00       	mov    $0x0,%ebx
   21679:	83 ec 1c             	sub    $0x1c,%esp
   2167c:	8b 74 24 38          	mov    0x38(%esp),%esi
   21680:	8b 6c 24 34          	mov    0x34(%esp),%ebp
   21684:	8b 06                	mov    (%esi),%eax
   21686:	8d 7c ae 04          	lea    0x4(%esi,%ebp,4),%edi
   2168a:	89 3c 24             	mov    %edi,(%esp)
   2168d:	89 44 24 04          	mov    %eax,0x4(%esp)
   21691:	e8 fc ff ff ff       	call   21692 <__libc_start_main+0x22>
   21696:	e8 fc ff ff ff       	call   21697 <__libc_start_main+0x27>
   2169b:	81 fb 00 00 00 00    	cmp    $0x0,%ebx
   216a1:	73 12                	jae    216b5 <__libc_start_main+0x45>
   216a3:	90                   	nop
   216a4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   216a8:	ff 13                	call   *(%ebx)
   216aa:	83 c3 04             	add    $0x4,%ebx
   216ad:	81 fb 00 00 00 00    	cmp    $0x0,%ebx
   216b3:	72 f3                	jb     216a8 <__libc_start_main+0x38>
   216b5:	89 7c 24 08          	mov    %edi,0x8(%esp)
   216b9:	89 74 24 04          	mov    %esi,0x4(%esp)
   216bd:	89 2c 24             	mov    %ebp,(%esp)
   216c0:	ff 54 24 30          	call   *0x30(%esp)
   216c4:	89 04 24             	mov    %eax,(%esp)
   216c7:	e8 fc ff ff ff       	call   216c8 <__libc_start_main+0x58>
   216cc:	66 90                	xchg   %ax,%ax
   216ce:	66 90                	xchg   %ax,%ax

000216d0 <__funcs_on_exit>:
   216d0:	f3 c3                	repz ret 
   216d2:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   216d9:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

000216e0 <exit>:
   216e0:	53                   	push   %ebx
   216e1:	bb 00 00 00 00       	mov    $0x0,%ebx
   216e6:	83 ec 18             	sub    $0x18,%esp
   216e9:	e8 fc ff ff ff       	call   216ea <exit+0xa>
   216ee:	81 fb 00 00 00 00    	cmp    $0x0,%ebx
   216f4:	76 0f                	jbe    21705 <exit+0x25>
   216f6:	66 90                	xchg   %ax,%ax
   216f8:	83 eb 04             	sub    $0x4,%ebx
   216fb:	ff 13                	call   *(%ebx)
   216fd:	81 fb 00 00 00 00    	cmp    $0x0,%ebx
   21703:	77 f3                	ja     216f8 <exit+0x18>
   21705:	e8 fc ff ff ff       	call   21706 <exit+0x26>
   2170a:	e8 fc ff ff ff       	call   2170b <exit+0x2b>
   2170f:	8b 44 24 20          	mov    0x20(%esp),%eax
   21713:	89 04 24             	mov    %eax,(%esp)
   21716:	e8 fc ff ff ff       	call   21717 <exit+0x37>
   2171b:	66 90                	xchg   %ax,%ax
   2171d:	66 90                	xchg   %ax,%ax
   2171f:	90                   	nop

00021720 <sn_write>:
   21720:	57                   	push   %edi
   21721:	56                   	push   %esi
   21722:	53                   	push   %ebx
   21723:	83 ec 10             	sub    $0x10,%esp
   21726:	8b 5c 24 20          	mov    0x20(%esp),%ebx
   2172a:	8b 74 24 28          	mov    0x28(%esp),%esi
   2172e:	8b 43 14             	mov    0x14(%ebx),%eax
   21731:	8b 53 10             	mov    0x10(%ebx),%edx
   21734:	89 f7                	mov    %esi,%edi
   21736:	29 c2                	sub    %eax,%edx
   21738:	39 d6                	cmp    %edx,%esi
   2173a:	76 02                	jbe    2173e <sn_write+0x1e>
   2173c:	89 d7                	mov    %edx,%edi
   2173e:	8b 54 24 24          	mov    0x24(%esp),%edx
   21742:	89 7c 24 08          	mov    %edi,0x8(%esp)
   21746:	89 04 24             	mov    %eax,(%esp)
   21749:	89 54 24 04          	mov    %edx,0x4(%esp)
   2174d:	e8 fc ff ff ff       	call   2174e <sn_write+0x2e>
   21752:	89 f0                	mov    %esi,%eax
   21754:	01 7b 14             	add    %edi,0x14(%ebx)
   21757:	83 c4 10             	add    $0x10,%esp
   2175a:	5b                   	pop    %ebx
   2175b:	5e                   	pop    %esi
   2175c:	5f                   	pop    %edi
   2175d:	c3                   	ret    
   2175e:	66 90                	xchg   %ax,%ax

00021760 <vsnprintf>:
   21760:	55                   	push   %ebp
   21761:	31 c0                	xor    %eax,%eax
   21763:	57                   	push   %edi
   21764:	b9 22 00 00 00       	mov    $0x22,%ecx
   21769:	56                   	push   %esi
   2176a:	53                   	push   %ebx
   2176b:	81 ec ac 00 00 00    	sub    $0xac,%esp
   21771:	8b b4 24 c4 00 00 00 	mov    0xc4(%esp),%esi
   21778:	8d 6c 24 18          	lea    0x18(%esp),%ebp
   2177c:	89 ef                	mov    %ebp,%edi
   2177e:	8b 94 24 c0 00 00 00 	mov    0xc0(%esp),%edx
   21785:	f3 ab                	rep stos %eax,%es:(%edi)
   21787:	c7 44 24 3c 20 17 02 	movl   $0x21720,0x3c(%esp)
   2178e:	00 
   2178f:	8d 46 ff             	lea    -0x1(%esi),%eax
   21792:	3d fe ff ff 7f       	cmp    $0x7ffffffe,%eax
   21797:	c6 44 24 63 ff       	movb   $0xff,0x63(%esp)
   2179c:	c7 44 24 64 ff ff ff 	movl   $0xffffffff,0x64(%esp)
   217a3:	ff 
   217a4:	76 11                	jbe    217b7 <vsnprintf+0x57>
   217a6:	85 f6                	test   %esi,%esi
   217a8:	0f 85 b2 00 00 00    	jne    21860 <vsnprintf+0x100>
   217ae:	be 01 00 00 00       	mov    $0x1,%esi
   217b3:	8d 54 24 14          	lea    0x14(%esp),%edx
   217b7:	bb fe ff ff ff       	mov    $0xfffffffe,%ebx
   217bc:	29 d3                	sub    %edx,%ebx
   217be:	39 de                	cmp    %ebx,%esi
   217c0:	77 56                	ja     21818 <vsnprintf+0xb8>
   217c2:	8b 84 24 cc 00 00 00 	mov    0xcc(%esp),%eax
   217c9:	89 54 24 2c          	mov    %edx,0x2c(%esp)
   217cd:	89 54 24 44          	mov    %edx,0x44(%esp)
   217d1:	01 f2                	add    %esi,%edx
   217d3:	89 2c 24             	mov    %ebp,(%esp)
   217d6:	89 44 24 08          	mov    %eax,0x8(%esp)
   217da:	8b 84 24 c8 00 00 00 	mov    0xc8(%esp),%eax
   217e1:	89 74 24 48          	mov    %esi,0x48(%esp)
   217e5:	89 54 24 28          	mov    %edx,0x28(%esp)
   217e9:	89 54 24 34          	mov    %edx,0x34(%esp)
   217ed:	89 44 24 04          	mov    %eax,0x4(%esp)
   217f1:	e8 fc ff ff ff       	call   217f2 <vsnprintf+0x92>
   217f6:	8b 54 24 2c          	mov    0x2c(%esp),%edx
   217fa:	31 c9                	xor    %ecx,%ecx
   217fc:	3b 54 24 28          	cmp    0x28(%esp),%edx
   21800:	0f 94 c1             	sete   %cl
   21803:	29 ca                	sub    %ecx,%edx
   21805:	c6 02 00             	movb   $0x0,(%edx)
   21808:	81 c4 ac 00 00 00    	add    $0xac,%esp
   2180e:	5b                   	pop    %ebx
   2180f:	5e                   	pop    %esi
   21810:	5f                   	pop    %edi
   21811:	5d                   	pop    %ebp
   21812:	c3                   	ret    
   21813:	90                   	nop
   21814:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   21818:	8b 84 24 cc 00 00 00 	mov    0xcc(%esp),%eax
   2181f:	89 54 24 2c          	mov    %edx,0x2c(%esp)
   21823:	89 54 24 44          	mov    %edx,0x44(%esp)
   21827:	01 da                	add    %ebx,%edx
   21829:	89 2c 24             	mov    %ebp,(%esp)
   2182c:	89 44 24 08          	mov    %eax,0x8(%esp)
   21830:	8b 84 24 c8 00 00 00 	mov    0xc8(%esp),%eax
   21837:	89 5c 24 48          	mov    %ebx,0x48(%esp)
   2183b:	89 54 24 28          	mov    %edx,0x28(%esp)
   2183f:	89 54 24 34          	mov    %edx,0x34(%esp)
   21843:	89 44 24 04          	mov    %eax,0x4(%esp)
   21847:	e8 fc ff ff ff       	call   21848 <vsnprintf+0xe8>
   2184c:	85 db                	test   %ebx,%ebx
   2184e:	75 a6                	jne    217f6 <vsnprintf+0x96>
   21850:	81 c4 ac 00 00 00    	add    $0xac,%esp
   21856:	5b                   	pop    %ebx
   21857:	5e                   	pop    %esi
   21858:	5f                   	pop    %edi
   21859:	5d                   	pop    %ebp
   2185a:	c3                   	ret    
   2185b:	90                   	nop
   2185c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   21860:	e8 fc ff ff ff       	call   21861 <vsnprintf+0x101>
   21865:	c7 00 4b 00 00 00    	movl   $0x4b,(%eax)
   2186b:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
   21870:	eb 96                	jmp    21808 <vsnprintf+0xa8>

00021872 <memcpy>:
   21872:	56                   	push   %esi
   21873:	57                   	push   %edi
   21874:	8b 7c 24 0c          	mov    0xc(%esp),%edi
   21878:	8b 74 24 10          	mov    0x10(%esp),%esi
   2187c:	8b 4c 24 14          	mov    0x14(%esp),%ecx
   21880:	89 f8                	mov    %edi,%eax
   21882:	83 f9 04             	cmp    $0x4,%ecx
   21885:	72 12                	jb     21899 <memcpy+0x27>
   21887:	f7 c7 03 00 00 00    	test   $0x3,%edi
   2188d:	74 0a                	je     21899 <memcpy+0x27>
   2188f:	a4                   	movsb  %ds:(%esi),%es:(%edi)
   21890:	49                   	dec    %ecx
   21891:	f7 c7 03 00 00 00    	test   $0x3,%edi
   21897:	75 f6                	jne    2188f <memcpy+0x1d>
   21899:	89 ca                	mov    %ecx,%edx
   2189b:	c1 e9 02             	shr    $0x2,%ecx
   2189e:	f3 a5                	rep movsl %ds:(%esi),%es:(%edi)
   218a0:	83 e2 03             	and    $0x3,%edx
   218a3:	74 04                	je     218a9 <memcpy+0x37>
   218a5:	a4                   	movsb  %ds:(%esi),%es:(%edi)
   218a6:	4a                   	dec    %edx
   218a7:	75 fc                	jne    218a5 <memcpy+0x33>
   218a9:	5f                   	pop    %edi
   218aa:	5e                   	pop    %esi
   218ab:	c3                   	ret    

000218ac <memset>:
   218ac:	8b 4c 24 0c          	mov    0xc(%esp),%ecx
   218b0:	83 f9 3e             	cmp    $0x3e,%ecx
   218b3:	77 6e                	ja     21923 <memset+0x77>
   218b5:	8a 54 24 08          	mov    0x8(%esp),%dl
   218b9:	8b 44 24 04          	mov    0x4(%esp),%eax
   218bd:	85 c9                	test   %ecx,%ecx
   218bf:	74 61                	je     21922 <memset+0x76>
   218c1:	88 d6                	mov    %dl,%dh
   218c3:	88 10                	mov    %dl,(%eax)
   218c5:	88 54 08 ff          	mov    %dl,-0x1(%eax,%ecx,1)
   218c9:	83 f9 02             	cmp    $0x2,%ecx
   218cc:	76 54                	jbe    21922 <memset+0x76>
   218ce:	66 89 50 01          	mov    %dx,0x1(%eax)
   218d2:	66 89 54 08 fd       	mov    %dx,-0x3(%eax,%ecx,1)
   218d7:	83 f9 06             	cmp    $0x6,%ecx
   218da:	76 46                	jbe    21922 <memset+0x76>
   218dc:	c1 e2 10             	shl    $0x10,%edx
   218df:	8a 54 24 08          	mov    0x8(%esp),%dl
   218e3:	8a 74 24 08          	mov    0x8(%esp),%dh
   218e7:	89 50 03             	mov    %edx,0x3(%eax)
   218ea:	89 54 08 f9          	mov    %edx,-0x7(%eax,%ecx,1)
   218ee:	83 f9 0e             	cmp    $0xe,%ecx
   218f1:	76 2f                	jbe    21922 <memset+0x76>
   218f3:	89 50 07             	mov    %edx,0x7(%eax)
   218f6:	89 50 0b             	mov    %edx,0xb(%eax)
   218f9:	89 54 08 f1          	mov    %edx,-0xf(%eax,%ecx,1)
   218fd:	89 54 08 f5          	mov    %edx,-0xb(%eax,%ecx,1)
   21901:	83 f9 1e             	cmp    $0x1e,%ecx
   21904:	76 1c                	jbe    21922 <memset+0x76>
   21906:	89 50 0f             	mov    %edx,0xf(%eax)
   21909:	89 50 13             	mov    %edx,0x13(%eax)
   2190c:	89 50 17             	mov    %edx,0x17(%eax)
   2190f:	89 50 1b             	mov    %edx,0x1b(%eax)
   21912:	89 54 08 e1          	mov    %edx,-0x1f(%eax,%ecx,1)
   21916:	89 54 08 e5          	mov    %edx,-0x1b(%eax,%ecx,1)
   2191a:	89 54 08 e9          	mov    %edx,-0x17(%eax,%ecx,1)
   2191e:	89 54 08 ed          	mov    %edx,-0x13(%eax,%ecx,1)
   21922:	c3                   	ret    
   21923:	0f b6 44 24 08       	movzbl 0x8(%esp),%eax
   21928:	89 7c 24 0c          	mov    %edi,0xc(%esp)
   2192c:	69 c0 01 01 01 01    	imul   $0x1010101,%eax,%eax
   21932:	8b 7c 24 04          	mov    0x4(%esp),%edi
   21936:	f7 c7 0f 00 00 00    	test   $0xf,%edi
   2193c:	89 44 0f fc          	mov    %eax,-0x4(%edi,%ecx,1)
   21940:	75 0e                	jne    21950 <memset+0xa4>
   21942:	c1 e9 02             	shr    $0x2,%ecx
   21945:	f3 ab                	rep stos %eax,%es:(%edi)
   21947:	8b 44 24 04          	mov    0x4(%esp),%eax
   2194b:	8b 7c 24 0c          	mov    0xc(%esp),%edi
   2194f:	c3                   	ret    
   21950:	31 d2                	xor    %edx,%edx
   21952:	29 fa                	sub    %edi,%edx
   21954:	83 e2 0f             	and    $0xf,%edx
   21957:	89 07                	mov    %eax,(%edi)
   21959:	89 47 04             	mov    %eax,0x4(%edi)
   2195c:	89 47 08             	mov    %eax,0x8(%edi)
   2195f:	89 47 0c             	mov    %eax,0xc(%edi)
   21962:	29 d1                	sub    %edx,%ecx
   21964:	01 d7                	add    %edx,%edi
   21966:	eb da                	jmp    21942 <memset+0x96>
   21968:	66 90                	xchg   %ax,%ax
   2196a:	66 90                	xchg   %ax,%ax
   2196c:	66 90                	xchg   %ax,%ax
   2196e:	66 90                	xchg   %ax,%ax

00021970 <strlen>:
   21970:	53                   	push   %ebx
   21971:	8b 5c 24 08          	mov    0x8(%esp),%ebx
   21975:	f6 c3 03             	test   $0x3,%bl
   21978:	74 4a                	je     219c4 <strlen+0x54>
   2197a:	80 3b 00             	cmpb   $0x0,(%ebx)
   2197d:	89 d8                	mov    %ebx,%eax
   2197f:	75 0c                	jne    2198d <strlen+0x1d>
   21981:	eb 45                	jmp    219c8 <strlen+0x58>
   21983:	90                   	nop
   21984:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   21988:	80 38 00             	cmpb   $0x0,(%eax)
   2198b:	74 33                	je     219c0 <strlen+0x50>
   2198d:	83 c0 01             	add    $0x1,%eax
   21990:	a8 03                	test   $0x3,%al
   21992:	75 f4                	jne    21988 <strlen+0x18>
   21994:	eb 05                	jmp    2199b <strlen+0x2b>
   21996:	66 90                	xchg   %ax,%ax
   21998:	83 c0 04             	add    $0x4,%eax
   2199b:	8b 08                	mov    (%eax),%ecx
   2199d:	8d 91 ff fe fe fe    	lea    -0x1010101(%ecx),%edx
   219a3:	f7 d1                	not    %ecx
   219a5:	21 ca                	and    %ecx,%edx
   219a7:	81 e2 80 80 80 80    	and    $0x80808080,%edx
   219ad:	74 e9                	je     21998 <strlen+0x28>
   219af:	80 38 00             	cmpb   $0x0,(%eax)
   219b2:	74 0c                	je     219c0 <strlen+0x50>
   219b4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   219b8:	83 c0 01             	add    $0x1,%eax
   219bb:	80 38 00             	cmpb   $0x0,(%eax)
   219be:	75 f8                	jne    219b8 <strlen+0x48>
   219c0:	29 d8                	sub    %ebx,%eax
   219c2:	5b                   	pop    %ebx
   219c3:	c3                   	ret    
   219c4:	89 d8                	mov    %ebx,%eax
   219c6:	eb d3                	jmp    2199b <strlen+0x2b>
   219c8:	31 c0                	xor    %eax,%eax
   219ca:	5b                   	pop    %ebx
   219cb:	c3                   	ret    
   219cc:	66 90                	xchg   %ax,%ax
   219ce:	66 90                	xchg   %ax,%ax

000219d0 <__copy_tls>:
   219d0:	53                   	push   %ebx
   219d1:	83 ec 18             	sub    $0x18,%esp
   219d4:	8b 15 00 00 00 00    	mov    0x0,%edx
   219da:	8b 44 24 20          	mov    0x20(%esp),%eax
   219de:	85 d2                	test   %edx,%edx
   219e0:	74 4d                	je     21a2f <__copy_tls+0x5f>
   219e2:	8b 15 14 00 00 00    	mov    0x14,%edx
   219e8:	8b 1d 0c 00 00 00    	mov    0xc,%ebx
   219ee:	c7 00 01 00 00 00    	movl   $0x1,(%eax)
   219f4:	8d 94 10 2c ff ff ff 	lea    -0xd4(%eax,%edx,1),%edx
   219fb:	f7 db                	neg    %ebx
   219fd:	21 d3                	and    %edx,%ebx
   219ff:	89 da                	mov    %ebx,%edx
   21a01:	2b 15 08 00 00 00    	sub    0x8,%edx
   21a07:	89 83 d0 00 00 00    	mov    %eax,0xd0(%ebx)
   21a0d:	89 43 04             	mov    %eax,0x4(%ebx)
   21a10:	89 50 04             	mov    %edx,0x4(%eax)
   21a13:	a1 04 00 00 00       	mov    0x4,%eax
   21a18:	89 14 24             	mov    %edx,(%esp)
   21a1b:	89 44 24 08          	mov    %eax,0x8(%esp)
   21a1f:	a1 00 00 00 00       	mov    0x0,%eax
   21a24:	89 44 24 04          	mov    %eax,0x4(%esp)
   21a28:	e8 fc ff ff ff       	call   21a29 <__copy_tls+0x59>
   21a2d:	89 d8                	mov    %ebx,%eax
   21a2f:	83 c4 18             	add    $0x18,%esp
   21a32:	5b                   	pop    %ebx
   21a33:	c3                   	ret    
   21a34:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   21a3a:	8d bf 00 00 00 00    	lea    0x0(%edi),%edi

00021a40 <__init_tls>:
   21a40:	55                   	push   %ebp
   21a41:	57                   	push   %edi
   21a42:	56                   	push   %esi
   21a43:	53                   	push   %ebx
   21a44:	83 ec 2c             	sub    $0x2c,%esp
   21a47:	8b 4c 24 40          	mov    0x40(%esp),%ecx
   21a4b:	8b 51 14             	mov    0x14(%ecx),%edx
   21a4e:	8b 79 0c             	mov    0xc(%ecx),%edi
   21a51:	85 d2                	test   %edx,%edx
   21a53:	0f 84 bf 01 00 00    	je     21c18 <__init_tls+0x1d8>
   21a59:	89 f8                	mov    %edi,%eax
   21a5b:	8b 59 10             	mov    0x10(%ecx),%ebx
   21a5e:	31 ed                	xor    %ebp,%ebp
   21a60:	31 f6                	xor    %esi,%esi
   21a62:	eb 12                	jmp    21a76 <__init_tls+0x36>
   21a64:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   21a68:	83 f9 07             	cmp    $0x7,%ecx
   21a6b:	75 02                	jne    21a6f <__init_tls+0x2f>
   21a6d:	89 c6                	mov    %eax,%esi
   21a6f:	01 d8                	add    %ebx,%eax
   21a71:	83 ea 01             	sub    $0x1,%edx
   21a74:	74 13                	je     21a89 <__init_tls+0x49>
   21a76:	8b 08                	mov    (%eax),%ecx
   21a78:	83 f9 06             	cmp    $0x6,%ecx
   21a7b:	75 eb                	jne    21a68 <__init_tls+0x28>
   21a7d:	89 fd                	mov    %edi,%ebp
   21a7f:	2b 68 08             	sub    0x8(%eax),%ebp
   21a82:	01 d8                	add    %ebx,%eax
   21a84:	83 ea 01             	sub    $0x1,%edx
   21a87:	75 ed                	jne    21a76 <__init_tls+0x36>
   21a89:	85 f6                	test   %esi,%esi
   21a8b:	0f 84 87 01 00 00    	je     21c18 <__init_tls+0x1d8>
   21a91:	8b 46 10             	mov    0x10(%esi),%eax
   21a94:	8b 4e 1c             	mov    0x1c(%esi),%ecx
   21a97:	03 6e 08             	add    0x8(%esi),%ebp
   21a9a:	8b 56 14             	mov    0x14(%esi),%edx
   21a9d:	a3 04 00 00 00       	mov    %eax,0x4
   21aa2:	89 2d 00 00 00 00    	mov    %ebp,0x0
   21aa8:	89 0d 0c 00 00 00    	mov    %ecx,0xc
   21aae:	8d 44 15 00          	lea    0x0(%ebp,%edx,1),%eax
   21ab2:	f7 d8                	neg    %eax
   21ab4:	8d 59 ff             	lea    -0x1(%ecx),%ebx
   21ab7:	21 d8                	and    %ebx,%eax
   21ab9:	01 d0                	add    %edx,%eax
   21abb:	83 f9 03             	cmp    $0x3,%ecx
   21abe:	a3 08 00 00 00       	mov    %eax,0x8
   21ac3:	8d 91 df 00 00 00    	lea    0xdf(%ecx),%edx
   21ac9:	77 0f                	ja     21ada <__init_tls+0x9a>
   21acb:	c7 05 0c 00 00 00 04 	movl   $0x4,0xc
   21ad2:	00 00 00 
   21ad5:	ba e3 00 00 00       	mov    $0xe3,%edx
   21ada:	01 c2                	add    %eax,%edx
   21adc:	b8 20 39 00 00       	mov    $0x3920,%eax
   21ae1:	83 e2 fc             	and    $0xfffffffc,%edx
   21ae4:	81 fa 18 01 00 00    	cmp    $0x118,%edx
   21aea:	89 15 14 00 00 00    	mov    %edx,0x14
   21af0:	0f 87 da 00 00 00    	ja     21bd0 <__init_tls+0x190>
   21af6:	85 ed                	test   %ebp,%ebp
   21af8:	89 c3                	mov    %eax,%ebx
   21afa:	74 4e                	je     21b4a <__init_tls+0x10a>
   21afc:	c7 00 01 00 00 00    	movl   $0x1,(%eax)
   21b02:	8b 35 0c 00 00 00    	mov    0xc,%esi
   21b08:	a1 14 00 00 00       	mov    0x14,%eax
   21b0d:	8b 15 04 00 00 00    	mov    0x4,%edx
   21b13:	f7 de                	neg    %esi
   21b15:	8d 84 03 2c ff ff ff 	lea    -0xd4(%ebx,%eax,1),%eax
   21b1c:	21 c6                	and    %eax,%esi
   21b1e:	89 f0                	mov    %esi,%eax
   21b20:	2b 05 08 00 00 00    	sub    0x8,%eax
   21b26:	89 9e d0 00 00 00    	mov    %ebx,0xd0(%esi)
   21b2c:	89 5e 04             	mov    %ebx,0x4(%esi)
   21b2f:	89 43 04             	mov    %eax,0x4(%ebx)
   21b32:	89 f3                	mov    %esi,%ebx
   21b34:	89 54 24 08          	mov    %edx,0x8(%esp)
   21b38:	8b 15 00 00 00 00    	mov    0x0,%edx
   21b3e:	89 04 24             	mov    %eax,(%esp)
   21b41:	89 54 24 04          	mov    %edx,0x4(%esp)
   21b45:	e8 fc ff ff ff       	call   21b46 <__init_tls+0x106>
   21b4a:	89 1b                	mov    %ebx,(%ebx)
   21b4c:	89 1c 24             	mov    %ebx,(%esp)
   21b4f:	e8 fc ff ff ff       	call   21b50 <__init_tls+0x110>
   21b54:	85 c0                	test   %eax,%eax
   21b56:	0f 88 d3 00 00 00    	js     21c2f <__init_tls+0x1ef>
   21b5c:	74 62                	je     21bc0 <__init_tls+0x180>
   21b5e:	8d 43 1c             	lea    0x1c(%ebx),%eax
   21b61:	89 04 24             	mov    %eax,(%esp)
   21b64:	b8 02 01 00 00       	mov    $0x102,%eax
   21b69:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   21b70:	00 
   21b71:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   21b78:	00 
   21b79:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   21b80:	00 
   21b81:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   21b88:	00 
   21b89:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   21b90:	00 
   21b91:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   21b98:	00 
   21b99:	e8 fc ff ff ff       	call   21b9a <__init_tls+0x15a>
   21b9e:	c7 83 9c 00 00 00 1c 	movl   $0x1c,0x9c(%ebx)
   21ba5:	00 00 00 
   21ba8:	89 43 1c             	mov    %eax,0x1c(%ebx)
   21bab:	8d 83 88 00 00 00    	lea    0x88(%ebx),%eax
   21bb1:	89 83 88 00 00 00    	mov    %eax,0x88(%ebx)
   21bb7:	83 c4 2c             	add    $0x2c,%esp
   21bba:	5b                   	pop    %ebx
   21bbb:	5e                   	pop    %esi
   21bbc:	5f                   	pop    %edi
   21bbd:	5d                   	pop    %ebp
   21bbe:	c3                   	ret    
   21bbf:	90                   	nop
   21bc0:	c7 05 00 00 00 00 01 	movl   $0x1,0x0
   21bc7:	00 00 00 
   21bca:	eb 92                	jmp    21b5e <__init_tls+0x11e>
   21bcc:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   21bd0:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   21bd7:	00 
   21bd8:	b8 c0 00 00 00       	mov    $0xc0,%eax
   21bdd:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   21be4:	00 
   21be5:	c7 44 24 10 ff ff ff 	movl   $0xffffffff,0x10(%esp)
   21bec:	ff 
   21bed:	c7 44 24 0c 22 00 00 	movl   $0x22,0xc(%esp)
   21bf4:	00 
   21bf5:	c7 44 24 08 03 00 00 	movl   $0x3,0x8(%esp)
   21bfc:	00 
   21bfd:	89 54 24 04          	mov    %edx,0x4(%esp)
   21c01:	c7 04 24 00 00 00 00 	movl   $0x0,(%esp)
   21c08:	e8 fc ff ff ff       	call   21c09 <__init_tls+0x1c9>
   21c0d:	8b 2d 00 00 00 00    	mov    0x0,%ebp
   21c13:	e9 de fe ff ff       	jmp    21af6 <__init_tls+0xb6>
   21c18:	8b 15 08 00 00 00    	mov    0x8,%edx
   21c1e:	8b 2d 00 00 00 00    	mov    0x0,%ebp
   21c24:	8b 0d 0c 00 00 00    	mov    0xc,%ecx
   21c2a:	e9 7f fe ff ff       	jmp    21aae <__init_tls+0x6e>
   21c2f:	f4                   	hlt    
   21c30:	eb 85                	jmp    21bb7 <__init_tls+0x177>
   21c32:	66 90                	xchg   %ax,%ax
   21c34:	66 90                	xchg   %ax,%ax
   21c36:	66 90                	xchg   %ax,%ax
   21c38:	66 90                	xchg   %ax,%ax
   21c3a:	66 90                	xchg   %ax,%ax
   21c3c:	66 90                	xchg   %ax,%ax
   21c3e:	66 90                	xchg   %ax,%ax

00021c40 <__errno_location>:
   21c40:	b8 38 3a 00 00       	mov    $0x3a38,%eax
   21c45:	c3                   	ret    
   21c46:	66 90                	xchg   %ax,%ax
   21c48:	66 90                	xchg   %ax,%ax
   21c4a:	66 90                	xchg   %ax,%ax
   21c4c:	66 90                	xchg   %ax,%ax
   21c4e:	66 90                	xchg   %ax,%ax

00021c50 <_Exit>:
   21c50:	53                   	push   %ebx
   21c51:	b8 fc 00 00 00       	mov    $0xfc,%eax
   21c56:	83 ec 28             	sub    $0x28,%esp
   21c59:	8b 5c 24 30          	mov    0x30(%esp),%ebx
   21c5d:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   21c64:	00 
   21c65:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   21c6c:	00 
   21c6d:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   21c74:	00 
   21c75:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   21c7c:	00 
   21c7d:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   21c84:	00 
   21c85:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   21c8c:	00 
   21c8d:	89 1c 24             	mov    %ebx,(%esp)
   21c90:	e8 fc ff ff ff       	call   21c91 <_Exit+0x41>
   21c95:	8d 76 00             	lea    0x0(%esi),%esi
   21c98:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   21c9f:	00 
   21ca0:	b8 01 00 00 00       	mov    $0x1,%eax
   21ca5:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   21cac:	00 
   21cad:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   21cb4:	00 
   21cb5:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   21cbc:	00 
   21cbd:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   21cc4:	00 
   21cc5:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   21ccc:	00 
   21ccd:	89 1c 24             	mov    %ebx,(%esp)
   21cd0:	e8 fc ff ff ff       	call   21cd1 <_Exit+0x81>
   21cd5:	eb c1                	jmp    21c98 <_Exit+0x48>
   21cd7:	66 90                	xchg   %ax,%ax
   21cd9:	66 90                	xchg   %ax,%ax
   21cdb:	66 90                	xchg   %ax,%ax
   21cdd:	66 90                	xchg   %ax,%ax
   21cdf:	90                   	nop

00021ce0 <pop_arg.part.0>:
   21ce0:	83 ea 09             	sub    $0x9,%edx
   21ce3:	83 fa 09             	cmp    $0x9,%edx
   21ce6:	77 18                	ja     21d00 <pop_arg.part.0+0x20>
   21ce8:	53                   	push   %ebx
   21ce9:	ff 24 95 80 39 00 00 	jmp    *0x3980(,%edx,4)
   21cf0:	8b 11                	mov    (%ecx),%edx
   21cf2:	db 2a                	fldt   (%edx)
   21cf4:	8d 5a 0c             	lea    0xc(%edx),%ebx
   21cf7:	89 19                	mov    %ebx,(%ecx)
   21cf9:	db 38                	fstpt  (%eax)
   21cfb:	5b                   	pop    %ebx
   21cfc:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   21d00:	f3 c3                	repz ret 
   21d02:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   21d08:	8b 11                	mov    (%ecx),%edx
   21d0a:	8d 5a 08             	lea    0x8(%edx),%ebx
   21d0d:	dd 02                	fldl   (%edx)
   21d0f:	89 19                	mov    %ebx,(%ecx)
   21d11:	db 38                	fstpt  (%eax)
   21d13:	5b                   	pop    %ebx
   21d14:	eb ea                	jmp    21d00 <pop_arg.part.0+0x20>
   21d16:	66 90                	xchg   %ax,%ax
   21d18:	8b 11                	mov    (%ecx),%edx
   21d1a:	8d 5a 04             	lea    0x4(%edx),%ebx
   21d1d:	89 19                	mov    %ebx,(%ecx)
   21d1f:	8b 12                	mov    (%edx),%edx
   21d21:	5b                   	pop    %ebx
   21d22:	89 10                	mov    %edx,(%eax)
   21d24:	eb da                	jmp    21d00 <pop_arg.part.0+0x20>
   21d26:	66 90                	xchg   %ax,%ax
   21d28:	8b 11                	mov    (%ecx),%edx
   21d2a:	8d 5a 04             	lea    0x4(%edx),%ebx
   21d2d:	8b 12                	mov    (%edx),%edx
   21d2f:	89 19                	mov    %ebx,(%ecx)
   21d31:	89 10                	mov    %edx,(%eax)
   21d33:	c1 fa 1f             	sar    $0x1f,%edx
   21d36:	89 50 04             	mov    %edx,0x4(%eax)
   21d39:	5b                   	pop    %ebx
   21d3a:	eb c4                	jmp    21d00 <pop_arg.part.0+0x20>
   21d3c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   21d40:	8b 11                	mov    (%ecx),%edx
   21d42:	8d 5a 04             	lea    0x4(%edx),%ebx
   21d45:	89 19                	mov    %ebx,(%ecx)
   21d47:	8b 1a                	mov    (%edx),%ebx
   21d49:	c7 40 04 00 00 00 00 	movl   $0x0,0x4(%eax)
   21d50:	89 18                	mov    %ebx,(%eax)
   21d52:	5b                   	pop    %ebx
   21d53:	eb ab                	jmp    21d00 <pop_arg.part.0+0x20>
   21d55:	8d 76 00             	lea    0x0(%esi),%esi
   21d58:	8b 11                	mov    (%ecx),%edx
   21d5a:	8d 5a 08             	lea    0x8(%edx),%ebx
   21d5d:	89 19                	mov    %ebx,(%ecx)
   21d5f:	8b 5a 04             	mov    0x4(%edx),%ebx
   21d62:	8b 0a                	mov    (%edx),%ecx
   21d64:	89 58 04             	mov    %ebx,0x4(%eax)
   21d67:	89 08                	mov    %ecx,(%eax)
   21d69:	5b                   	pop    %ebx
   21d6a:	eb 94                	jmp    21d00 <pop_arg.part.0+0x20>
   21d6c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   21d70:	8b 11                	mov    (%ecx),%edx
   21d72:	8d 5a 04             	lea    0x4(%edx),%ebx
   21d75:	0f bf 12             	movswl (%edx),%edx
   21d78:	89 19                	mov    %ebx,(%ecx)
   21d7a:	89 10                	mov    %edx,(%eax)
   21d7c:	c1 fa 1f             	sar    $0x1f,%edx
   21d7f:	89 50 04             	mov    %edx,0x4(%eax)
   21d82:	5b                   	pop    %ebx
   21d83:	e9 78 ff ff ff       	jmp    21d00 <pop_arg.part.0+0x20>
   21d88:	8b 11                	mov    (%ecx),%edx
   21d8a:	8d 5a 04             	lea    0x4(%edx),%ebx
   21d8d:	0f b7 12             	movzwl (%edx),%edx
   21d90:	89 19                	mov    %ebx,(%ecx)
   21d92:	c7 40 04 00 00 00 00 	movl   $0x0,0x4(%eax)
   21d99:	5b                   	pop    %ebx
   21d9a:	89 10                	mov    %edx,(%eax)
   21d9c:	e9 5f ff ff ff       	jmp    21d00 <pop_arg.part.0+0x20>
   21da1:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   21da8:	8b 11                	mov    (%ecx),%edx
   21daa:	8d 5a 04             	lea    0x4(%edx),%ebx
   21dad:	0f be 12             	movsbl (%edx),%edx
   21db0:	89 19                	mov    %ebx,(%ecx)
   21db2:	89 10                	mov    %edx,(%eax)
   21db4:	c1 fa 1f             	sar    $0x1f,%edx
   21db7:	89 50 04             	mov    %edx,0x4(%eax)
   21dba:	5b                   	pop    %ebx
   21dbb:	e9 40 ff ff ff       	jmp    21d00 <pop_arg.part.0+0x20>
   21dc0:	8b 11                	mov    (%ecx),%edx
   21dc2:	8d 5a 04             	lea    0x4(%edx),%ebx
   21dc5:	0f b6 12             	movzbl (%edx),%edx
   21dc8:	89 19                	mov    %ebx,(%ecx)
   21dca:	c7 40 04 00 00 00 00 	movl   $0x0,0x4(%eax)
   21dd1:	5b                   	pop    %ebx
   21dd2:	89 10                	mov    %edx,(%eax)
   21dd4:	e9 27 ff ff ff       	jmp    21d00 <pop_arg.part.0+0x20>
   21dd9:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi

00021de0 <pad.part.1>:
   21de0:	55                   	push   %ebp
   21de1:	89 cd                	mov    %ecx,%ebp
   21de3:	57                   	push   %edi
   21de4:	56                   	push   %esi
   21de5:	89 c6                	mov    %eax,%esi
   21de7:	53                   	push   %ebx
   21de8:	81 ec 1c 01 00 00    	sub    $0x11c,%esp
   21dee:	2b ac 24 30 01 00 00 	sub    0x130(%esp),%ebp
   21df5:	81 fd 00 01 00 00    	cmp    $0x100,%ebp
   21dfb:	89 e8                	mov    %ebp,%eax
   21dfd:	76 05                	jbe    21e04 <pad.part.1+0x24>
   21dff:	b8 00 01 00 00       	mov    $0x100,%eax
   21e04:	0f be d2             	movsbl %dl,%edx
   21e07:	8d 7c 24 10          	lea    0x10(%esp),%edi
   21e0b:	89 44 24 08          	mov    %eax,0x8(%esp)
   21e0f:	89 54 24 04          	mov    %edx,0x4(%esp)
   21e13:	89 3c 24             	mov    %edi,(%esp)
   21e16:	e8 fc ff ff ff       	call   21e17 <pad.part.1+0x37>
   21e1b:	81 fd ff 00 00 00    	cmp    $0xff,%ebp
   21e21:	76 6f                	jbe    21e92 <pad.part.1+0xb2>
   21e23:	8b 16                	mov    (%esi),%edx
   21e25:	89 eb                	mov    %ebp,%ebx
   21e27:	eb 15                	jmp    21e3e <pad.part.1+0x5e>
   21e29:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   21e30:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   21e36:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   21e3c:	76 30                	jbe    21e6e <pad.part.1+0x8e>
   21e3e:	89 d0                	mov    %edx,%eax
   21e40:	83 e0 20             	and    $0x20,%eax
   21e43:	75 eb                	jne    21e30 <pad.part.1+0x50>
   21e45:	89 74 24 08          	mov    %esi,0x8(%esp)
   21e49:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   21e4f:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   21e56:	00 
   21e57:	89 3c 24             	mov    %edi,(%esp)
   21e5a:	e8 fc ff ff ff       	call   21e5b <pad.part.1+0x7b>
   21e5f:	8b 16                	mov    (%esi),%edx
   21e61:	89 d0                	mov    %edx,%eax
   21e63:	83 e0 20             	and    $0x20,%eax
   21e66:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   21e6c:	77 d0                	ja     21e3e <pad.part.1+0x5e>
   21e6e:	89 e9                	mov    %ebp,%ecx
   21e70:	0f b6 e9             	movzbl %cl,%ebp
   21e73:	85 c0                	test   %eax,%eax
   21e75:	75 10                	jne    21e87 <pad.part.1+0xa7>
   21e77:	89 74 24 08          	mov    %esi,0x8(%esp)
   21e7b:	89 6c 24 04          	mov    %ebp,0x4(%esp)
   21e7f:	89 3c 24             	mov    %edi,(%esp)
   21e82:	e8 fc ff ff ff       	call   21e83 <pad.part.1+0xa3>
   21e87:	81 c4 1c 01 00 00    	add    $0x11c,%esp
   21e8d:	5b                   	pop    %ebx
   21e8e:	5e                   	pop    %esi
   21e8f:	5f                   	pop    %edi
   21e90:	5d                   	pop    %ebp
   21e91:	c3                   	ret    
   21e92:	8b 06                	mov    (%esi),%eax
   21e94:	83 e0 20             	and    $0x20,%eax
   21e97:	eb da                	jmp    21e73 <pad.part.1+0x93>
   21e99:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi

00021ea0 <fmt_fp>:
   21ea0:	55                   	push   %ebp
   21ea1:	57                   	push   %edi
   21ea2:	56                   	push   %esi
   21ea3:	53                   	push   %ebx
   21ea4:	81 ec 5c 1e 00 00    	sub    $0x1e5c,%esp
   21eaa:	db ac 24 70 1e 00 00 	fldt   0x1e70(%esp)
   21eb1:	89 44 24 38          	mov    %eax,0x38(%esp)
   21eb5:	89 54 24 48          	mov    %edx,0x48(%esp)
   21eb9:	db 3c 24             	fstpt  (%esp)
   21ebc:	89 4c 24 34          	mov    %ecx,0x34(%esp)
   21ec0:	c7 44 24 78 00 00 00 	movl   $0x0,0x78(%esp)
   21ec7:	00 
   21ec8:	e8 fc ff ff ff       	call   21ec9 <fmt_fp+0x29>
   21ecd:	85 c0                	test   %eax,%eax
   21ecf:	0f 84 4b 02 00 00    	je     22120 <fmt_fp+0x280>
   21ed5:	db ac 24 70 1e 00 00 	fldt   0x1e70(%esp)
   21edc:	bb 04 00 00 00       	mov    $0x4,%ebx
   21ee1:	c7 44 24 58 01 00 00 	movl   $0x1,0x58(%esp)
   21ee8:	00 
   21ee9:	c7 44 24 50 01 00 00 	movl   $0x1,0x50(%esp)
   21ef0:	00 
   21ef1:	d9 e0                	fchs   
   21ef3:	db bc 24 70 1e 00 00 	fstpt  0x1e70(%esp)
   21efa:	c7 44 24 54 2a 45 00 	movl   $0x452a,0x54(%esp)
   21f01:	00 
   21f02:	db ac 24 70 1e 00 00 	fldt   0x1e70(%esp)
   21f09:	db 3c 24             	fstpt  (%esp)
   21f0c:	e8 fc ff ff ff       	call   21f0d <fmt_fp+0x6d>
   21f11:	83 f8 01             	cmp    $0x1,%eax
   21f14:	0f 8e 76 02 00 00    	jle    22190 <fmt_fp+0x2f0>
   21f1a:	db ac 24 70 1e 00 00 	fldt   0x1e70(%esp)
   21f21:	8d 44 24 78          	lea    0x78(%esp),%eax
   21f25:	db 3c 24             	fstpt  (%esp)
   21f28:	89 44 24 0c          	mov    %eax,0xc(%esp)
   21f2c:	e8 fc ff ff ff       	call   21f2d <fmt_fp+0x8d>
   21f31:	d8 c0                	fadd   %st(0),%st
   21f33:	d9 ee                	fldz   
   21f35:	d9 c9                	fxch   %st(1)
   21f37:	dd e1                	fucom  %st(1)
   21f39:	df e0                	fnstsw %ax
   21f3b:	dd d9                	fstp   %st(1)
   21f3d:	9e                   	sahf   
   21f3e:	8b 44 24 78          	mov    0x78(%esp),%eax
   21f42:	0f 8b 07 02 00 00    	jnp    2214f <fmt_fp+0x2af>
   21f48:	83 e8 01             	sub    $0x1,%eax
   21f4b:	89 44 24 78          	mov    %eax,0x78(%esp)
   21f4f:	89 44 24 30          	mov    %eax,0x30(%esp)
   21f53:	8b 84 24 80 1e 00 00 	mov    0x1e80(%esp),%eax
   21f5a:	83 c8 20             	or     $0x20,%eax
   21f5d:	83 f8 61             	cmp    $0x61,%eax
   21f60:	89 44 24 44          	mov    %eax,0x44(%esp)
   21f64:	0f 84 9a 0a 00 00    	je     22a04 <fmt_fp+0xb64>
   21f6a:	8b 44 24 34          	mov    0x34(%esp),%eax
   21f6e:	85 c0                	test   %eax,%eax
   21f70:	0f 88 cc 10 00 00    	js     23042 <fmt_fp+0x11a2>
   21f76:	d9 ee                	fldz   
   21f78:	d9 c9                	fxch   %st(1)
   21f7a:	dd e1                	fucom  %st(1)
   21f7c:	df e0                	fnstsw %ax
   21f7e:	dd d9                	fstp   %st(1)
   21f80:	9e                   	sahf   
   21f81:	7a 02                	jp     21f85 <fmt_fp+0xe5>
   21f83:	74 15                	je     21f9a <fmt_fp+0xfa>
   21f85:	8b 44 24 30          	mov    0x30(%esp),%eax
   21f89:	d8 0d 7c 45 00 00    	fmuls  0x457c
   21f8f:	83 e8 1c             	sub    $0x1c,%eax
   21f92:	89 44 24 78          	mov    %eax,0x78(%esp)
   21f96:	89 44 24 30          	mov    %eax,0x30(%esp)
   21f9a:	8b 6c 24 30          	mov    0x30(%esp),%ebp
   21f9e:	8d 84 24 a4 01 00 00 	lea    0x1a4(%esp),%eax
   21fa5:	89 44 24 3c          	mov    %eax,0x3c(%esp)
   21fa9:	85 ed                	test   %ebp,%ebp
   21fab:	78 0b                	js     21fb8 <fmt_fp+0x118>
   21fad:	8d 84 24 4c 1d 00 00 	lea    0x1d4c(%esp),%eax
   21fb4:	89 44 24 3c          	mov    %eax,0x3c(%esp)
   21fb8:	d9 7c 24 6e          	fnstcw 0x6e(%esp)
   21fbc:	89 c1                	mov    %eax,%ecx
   21fbe:	d9 05 80 45 00 00    	flds   0x4580
   21fc4:	d9 c9                	fxch   %st(1)
   21fc6:	0f b7 44 24 6e       	movzwl 0x6e(%esp),%eax
   21fcb:	b4 0c                	mov    $0xc,%ah
   21fcd:	66 89 44 24 6c       	mov    %ax,0x6c(%esp)
   21fd2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   21fd8:	d9 c0                	fld    %st(0)
   21fda:	d9 6c 24 6c          	fldcw  0x6c(%esp)
   21fde:	df 7c 24 60          	fistpll 0x60(%esp)
   21fe2:	d9 6c 24 6e          	fldcw  0x6e(%esp)
   21fe6:	31 d2                	xor    %edx,%edx
   21fe8:	83 c1 04             	add    $0x4,%ecx
   21feb:	8b 7c 24 60          	mov    0x60(%esp),%edi
   21fef:	89 79 fc             	mov    %edi,-0x4(%ecx)
   21ff2:	89 7c 24 60          	mov    %edi,0x60(%esp)
   21ff6:	89 54 24 64          	mov    %edx,0x64(%esp)
   21ffa:	df 6c 24 60          	fildll 0x60(%esp)
   21ffe:	de e9                	fsubrp %st,%st(1)
   22000:	d8 c9                	fmul   %st(1),%st
   22002:	d9 ee                	fldz   
   22004:	d9 c9                	fxch   %st(1)
   22006:	dd e1                	fucom  %st(1)
   22008:	df e0                	fnstsw %ax
   2200a:	dd d9                	fstp   %st(1)
   2200c:	9e                   	sahf   
   2200d:	7a c9                	jp     21fd8 <fmt_fp+0x138>
   2200f:	75 c7                	jne    21fd8 <fmt_fp+0x138>
   22011:	dd d8                	fstp   %st(0)
   22013:	dd d8                	fstp   %st(0)
   22015:	8b 44 24 30          	mov    0x30(%esp),%eax
   22019:	89 4c 24 2c          	mov    %ecx,0x2c(%esp)
   2201d:	85 c0                	test   %eax,%eax
   2201f:	0f 8e a5 15 00 00    	jle    235ca <fmt_fp+0x172a>
   22025:	8b 7c 24 3c          	mov    0x3c(%esp),%edi
   22029:	89 7c 24 10          	mov    %edi,0x10(%esp)
   2202d:	8d 76 00             	lea    0x0(%esi),%esi
   22030:	83 f8 1d             	cmp    $0x1d,%eax
   22033:	89 44 24 20          	mov    %eax,0x20(%esp)
   22037:	7e 08                	jle    22041 <fmt_fp+0x1a1>
   22039:	c7 44 24 20 1d 00 00 	movl   $0x1d,0x20(%esp)
   22040:	00 
   22041:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   22045:	8b 7c 24 10          	mov    0x10(%esp),%edi
   22049:	8d 58 fc             	lea    -0x4(%eax),%ebx
   2204c:	39 fb                	cmp    %edi,%ebx
   2204e:	89 dd                	mov    %ebx,%ebp
   22050:	0f 82 80 00 00 00    	jb     220d6 <fmt_fp+0x236>
   22056:	89 5c 24 40          	mov    %ebx,0x40(%esp)
   2205a:	31 c0                	xor    %eax,%eax
   2205c:	89 fb                	mov    %edi,%ebx
   2205e:	66 90                	xchg   %ax,%ax
   22060:	0f b6 4c 24 20       	movzbl 0x20(%esp),%ecx
   22065:	31 ff                	xor    %edi,%edi
   22067:	8b 75 00             	mov    0x0(%ebp),%esi
   2206a:	0f a5 f7             	shld   %cl,%esi,%edi
   2206d:	d3 e6                	shl    %cl,%esi
   2206f:	f6 c1 20             	test   $0x20,%cl
   22072:	74 04                	je     22078 <fmt_fp+0x1d8>
   22074:	89 f7                	mov    %esi,%edi
   22076:	31 f6                	xor    %esi,%esi
   22078:	31 d2                	xor    %edx,%edx
   2207a:	01 c6                	add    %eax,%esi
   2207c:	11 d7                	adc    %edx,%edi
   2207e:	83 ed 04             	sub    $0x4,%ebp
   22081:	c7 44 24 08 00 ca 9a 	movl   $0x3b9aca00,0x8(%esp)
   22088:	3b 
   22089:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   22090:	00 
   22091:	89 34 24             	mov    %esi,(%esp)
   22094:	89 7c 24 04          	mov    %edi,0x4(%esp)
   22098:	e8 fc ff ff ff       	call   22099 <fmt_fp+0x1f9>
   2209d:	89 45 04             	mov    %eax,0x4(%ebp)
   220a0:	c7 44 24 08 00 ca 9a 	movl   $0x3b9aca00,0x8(%esp)
   220a7:	3b 
   220a8:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   220af:	00 
   220b0:	89 34 24             	mov    %esi,(%esp)
   220b3:	89 7c 24 04          	mov    %edi,0x4(%esp)
   220b7:	e8 fc ff ff ff       	call   220b8 <fmt_fp+0x218>
   220bc:	39 dd                	cmp    %ebx,%ebp
   220be:	73 a0                	jae    22060 <fmt_fp+0x1c0>
   220c0:	85 c0                	test   %eax,%eax
   220c2:	8b 5c 24 40          	mov    0x40(%esp),%ebx
   220c6:	74 0e                	je     220d6 <fmt_fp+0x236>
   220c8:	8b 7c 24 10          	mov    0x10(%esp),%edi
   220cc:	89 47 fc             	mov    %eax,-0x4(%edi)
   220cf:	8d 47 fc             	lea    -0x4(%edi),%eax
   220d2:	89 44 24 10          	mov    %eax,0x10(%esp)
   220d6:	8b 7c 24 2c          	mov    0x2c(%esp),%edi
   220da:	8b 44 24 10          	mov    0x10(%esp),%eax
   220de:	39 f8                	cmp    %edi,%eax
   220e0:	73 22                	jae    22104 <fmt_fp+0x264>
   220e2:	8b 7f fc             	mov    -0x4(%edi),%edi
   220e5:	85 ff                	test   %edi,%edi
   220e7:	74 11                	je     220fa <fmt_fp+0x25a>
   220e9:	eb 19                	jmp    22104 <fmt_fp+0x264>
   220eb:	90                   	nop
   220ec:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   220f0:	8b 73 fc             	mov    -0x4(%ebx),%esi
   220f3:	85 f6                	test   %esi,%esi
   220f5:	75 09                	jne    22100 <fmt_fp+0x260>
   220f7:	83 eb 04             	sub    $0x4,%ebx
   220fa:	39 c3                	cmp    %eax,%ebx
   220fc:	89 da                	mov    %ebx,%edx
   220fe:	77 f0                	ja     220f0 <fmt_fp+0x250>
   22100:	89 54 24 2c          	mov    %edx,0x2c(%esp)
   22104:	8b 44 24 30          	mov    0x30(%esp),%eax
   22108:	2b 44 24 20          	sub    0x20(%esp),%eax
   2210c:	85 c0                	test   %eax,%eax
   2210e:	0f 8e 6a 02 00 00    	jle    2237e <fmt_fp+0x4de>
   22114:	89 44 24 30          	mov    %eax,0x30(%esp)
   22118:	e9 13 ff ff ff       	jmp    22030 <fmt_fp+0x190>
   2211d:	8d 76 00             	lea    0x0(%esi),%esi
   22120:	f7 84 24 7c 1e 00 00 	testl  $0x800,0x1e7c(%esp)
   22127:	00 08 00 00 
   2212b:	74 2d                	je     2215a <fmt_fp+0x2ba>
   2212d:	c7 44 24 58 01 00 00 	movl   $0x1,0x58(%esp)
   22134:	00 
   22135:	bb 04 00 00 00       	mov    $0x4,%ebx
   2213a:	c7 44 24 50 01 00 00 	movl   $0x1,0x50(%esp)
   22141:	00 
   22142:	c7 44 24 54 03 00 00 	movl   $0x3,0x54(%esp)
   22149:	00 
   2214a:	e9 b3 fd ff ff       	jmp    21f02 <fmt_fp+0x62>
   2214f:	0f 85 f3 fd ff ff    	jne    21f48 <fmt_fp+0xa8>
   22155:	e9 f5 fd ff ff       	jmp    21f4f <fmt_fp+0xaf>
   2215a:	8b 84 24 7c 1e 00 00 	mov    0x1e7c(%esp),%eax
   22161:	83 e0 01             	and    $0x1,%eax
   22164:	89 44 24 58          	mov    %eax,0x58(%esp)
   22168:	0f 84 b8 00 00 00    	je     22226 <fmt_fp+0x386>
   2216e:	c7 44 24 58 01 00 00 	movl   $0x1,0x58(%esp)
   22175:	00 
   22176:	bb 04 00 00 00       	mov    $0x4,%ebx
   2217b:	c7 44 24 50 01 00 00 	movl   $0x1,0x50(%esp)
   22182:	00 
   22183:	c7 44 24 54 06 00 00 	movl   $0x6,0x54(%esp)
   2218a:	00 
   2218b:	e9 72 fd ff ff       	jmp    21f02 <fmt_fp+0x62>
   22190:	f6 84 24 80 1e 00 00 	testb  $0x20,0x1e80(%esp)
   22197:	20 
   22198:	74 1e                	je     221b8 <fmt_fp+0x318>
   2219a:	db ac 24 70 1e 00 00 	fldt   0x1e70(%esp)
   221a1:	bf 45 45 00 00       	mov    $0x4545,%edi
   221a6:	dd e8                	fucomp %st(0)
   221a8:	df e0                	fnstsw %ax
   221aa:	9e                   	sahf   
   221ab:	7a 23                	jp     221d0 <fmt_fp+0x330>
   221ad:	bf 49 45 00 00       	mov    $0x4549,%edi
   221b2:	eb 1c                	jmp    221d0 <fmt_fp+0x330>
   221b4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   221b8:	db ac 24 70 1e 00 00 	fldt   0x1e70(%esp)
   221bf:	bf 41 45 00 00       	mov    $0x4541,%edi
   221c4:	dd e8                	fucomp %st(0)
   221c6:	df e0                	fnstsw %ax
   221c8:	9e                   	sahf   
   221c9:	7a 05                	jp     221d0 <fmt_fp+0x330>
   221cb:	bf 3d 45 00 00       	mov    $0x453d,%edi
   221d0:	f7 84 24 7c 1e 00 00 	testl  $0x2000,0x1e7c(%esp)
   221d7:	00 20 00 00 
   221db:	75 0a                	jne    221e7 <fmt_fp+0x347>
   221dd:	39 5c 24 48          	cmp    %ebx,0x48(%esp)
   221e1:	0f 8f 11 01 00 00    	jg     222f8 <fmt_fp+0x458>
   221e7:	8b 44 24 38          	mov    0x38(%esp),%eax
   221eb:	8b 00                	mov    (%eax),%eax
   221ed:	83 e0 20             	and    $0x20,%eax
   221f0:	85 c0                	test   %eax,%eax
   221f2:	0f 84 19 0b 00 00    	je     22d11 <fmt_fp+0xe71>
   221f8:	8b 84 24 7c 1e 00 00 	mov    0x1e7c(%esp),%eax
   221ff:	80 f4 20             	xor    $0x20,%ah
   22202:	a9 00 20 01 00       	test   $0x12000,%eax
   22207:	75 06                	jne    2220f <fmt_fp+0x36f>
   22209:	39 5c 24 48          	cmp    %ebx,0x48(%esp)
   2220d:	7f 31                	jg     22240 <fmt_fp+0x3a0>
   2220f:	3b 5c 24 48          	cmp    0x48(%esp),%ebx
   22213:	89 d8                	mov    %ebx,%eax
   22215:	7d 04                	jge    2221b <fmt_fp+0x37b>
   22217:	8b 44 24 48          	mov    0x48(%esp),%eax
   2221b:	81 c4 5c 1e 00 00    	add    $0x1e5c,%esp
   22221:	5b                   	pop    %ebx
   22222:	5e                   	pop    %esi
   22223:	5f                   	pop    %edi
   22224:	5d                   	pop    %ebp
   22225:	c3                   	ret    
   22226:	bb 03 00 00 00       	mov    $0x3,%ebx
   2222b:	c7 44 24 50 00 00 00 	movl   $0x0,0x50(%esp)
   22232:	00 
   22233:	c7 44 24 54 01 00 00 	movl   $0x1,0x54(%esp)
   2223a:	00 
   2223b:	e9 c2 fc ff ff       	jmp    21f02 <fmt_fp+0x62>
   22240:	8b 74 24 48          	mov    0x48(%esp),%esi
   22244:	29 de                	sub    %ebx,%esi
   22246:	81 fe 00 01 00 00    	cmp    $0x100,%esi
   2224c:	89 f0                	mov    %esi,%eax
   2224e:	76 05                	jbe    22255 <fmt_fp+0x3b5>
   22250:	b8 00 01 00 00       	mov    $0x100,%eax
   22255:	8d ac 24 a4 01 00 00 	lea    0x1a4(%esp),%ebp
   2225c:	89 44 24 08          	mov    %eax,0x8(%esp)
   22260:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   22267:	00 
   22268:	89 2c 24             	mov    %ebp,(%esp)
   2226b:	e8 fc ff ff ff       	call   2226c <fmt_fp+0x3cc>
   22270:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   22276:	0f 86 95 15 00 00    	jbe    23811 <fmt_fp+0x1971>
   2227c:	8b 4c 24 38          	mov    0x38(%esp),%ecx
   22280:	89 5c 24 20          	mov    %ebx,0x20(%esp)
   22284:	89 f3                	mov    %esi,%ebx
   22286:	8b 01                	mov    (%ecx),%eax
   22288:	89 cf                	mov    %ecx,%edi
   2228a:	eb 12                	jmp    2229e <fmt_fp+0x3fe>
   2228c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   22290:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   22296:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   2229c:	76 30                	jbe    222ce <fmt_fp+0x42e>
   2229e:	89 c2                	mov    %eax,%edx
   222a0:	83 e2 20             	and    $0x20,%edx
   222a3:	75 eb                	jne    22290 <fmt_fp+0x3f0>
   222a5:	89 7c 24 08          	mov    %edi,0x8(%esp)
   222a9:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   222af:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   222b6:	00 
   222b7:	89 2c 24             	mov    %ebp,(%esp)
   222ba:	e8 fc ff ff ff       	call   222bb <fmt_fp+0x41b>
   222bf:	8b 07                	mov    (%edi),%eax
   222c1:	89 c2                	mov    %eax,%edx
   222c3:	83 e2 20             	and    $0x20,%edx
   222c6:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   222cc:	77 d0                	ja     2229e <fmt_fp+0x3fe>
   222ce:	8b 5c 24 20          	mov    0x20(%esp),%ebx
   222d2:	89 f0                	mov    %esi,%eax
   222d4:	0f b6 f0             	movzbl %al,%esi
   222d7:	85 d2                	test   %edx,%edx
   222d9:	0f 85 30 ff ff ff    	jne    2220f <fmt_fp+0x36f>
   222df:	8b 44 24 38          	mov    0x38(%esp),%eax
   222e3:	89 74 24 04          	mov    %esi,0x4(%esp)
   222e7:	89 2c 24             	mov    %ebp,(%esp)
   222ea:	89 44 24 08          	mov    %eax,0x8(%esp)
   222ee:	e8 fc ff ff ff       	call   222ef <fmt_fp+0x44f>
   222f3:	e9 17 ff ff ff       	jmp    2220f <fmt_fp+0x36f>
   222f8:	8b 44 24 48          	mov    0x48(%esp),%eax
   222fc:	29 d8                	sub    %ebx,%eax
   222fe:	3d 00 01 00 00       	cmp    $0x100,%eax
   22303:	89 44 24 20          	mov    %eax,0x20(%esp)
   22307:	0f 87 d2 11 00 00    	ja     234df <fmt_fp+0x163f>
   2230d:	8d ac 24 a4 01 00 00 	lea    0x1a4(%esp),%ebp
   22314:	89 44 24 08          	mov    %eax,0x8(%esp)
   22318:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   2231f:	00 
   22320:	89 2c 24             	mov    %ebp,(%esp)
   22323:	e8 fc ff ff ff       	call   22324 <fmt_fp+0x484>
   22328:	8b 44 24 38          	mov    0x38(%esp),%eax
   2232c:	81 7c 24 20 ff 00 00 	cmpl   $0xff,0x20(%esp)
   22333:	00 
   22334:	0f 86 31 15 00 00    	jbe    2386b <fmt_fp+0x19cb>
   2233a:	89 5c 24 10          	mov    %ebx,0x10(%esp)
   2233e:	8b 10                	mov    (%eax),%edx
   22340:	89 c3                	mov    %eax,%ebx
   22342:	8b 74 24 20          	mov    0x20(%esp),%esi
   22346:	eb 12                	jmp    2235a <fmt_fp+0x4ba>
   22348:	81 ee 00 01 00 00    	sub    $0x100,%esi
   2234e:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   22354:	0f 86 a6 0e 00 00    	jbe    23200 <fmt_fp+0x1360>
   2235a:	89 d0                	mov    %edx,%eax
   2235c:	83 e0 20             	and    $0x20,%eax
   2235f:	75 e7                	jne    22348 <fmt_fp+0x4a8>
   22361:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   22365:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   2236c:	00 
   2236d:	89 2c 24             	mov    %ebp,(%esp)
   22370:	e8 fc ff ff ff       	call   22371 <fmt_fp+0x4d1>
   22375:	8b 13                	mov    (%ebx),%edx
   22377:	89 d0                	mov    %edx,%eax
   22379:	83 e0 20             	and    $0x20,%eax
   2237c:	eb ca                	jmp    22348 <fmt_fp+0x4a8>
   2237e:	89 44 24 78          	mov    %eax,0x78(%esp)
   22382:	89 c7                	mov    %eax,%edi
   22384:	89 44 24 30          	mov    %eax,0x30(%esp)
   22388:	85 ff                	test   %edi,%edi
   2238a:	0f 84 cd 00 00 00    	je     2245d <fmt_fp+0x5bd>
   22390:	8b 44 24 34          	mov    0x34(%esp),%eax
   22394:	ba 39 8e e3 38       	mov    $0x38e38e39,%edx
   22399:	8b 7c 24 2c          	mov    0x2c(%esp),%edi
   2239d:	8d 48 1d             	lea    0x1d(%eax),%ecx
   223a0:	89 c8                	mov    %ecx,%eax
   223a2:	f7 ea                	imul   %edx
   223a4:	c1 f9 1f             	sar    $0x1f,%ecx
   223a7:	d1 fa                	sar    %edx
   223a9:	29 ca                	sub    %ecx,%edx
   223ab:	8b 4c 24 30          	mov    0x30(%esp),%ecx
   223af:	8d 42 01             	lea    0x1(%edx),%eax
   223b2:	89 44 24 40          	mov    %eax,0x40(%esp)
   223b6:	c1 e0 02             	shl    $0x2,%eax
   223b9:	89 44 24 4c          	mov    %eax,0x4c(%esp)
   223bd:	8d 76 00             	lea    0x0(%esi),%esi
   223c0:	f7 d9                	neg    %ecx
   223c2:	83 f9 09             	cmp    $0x9,%ecx
   223c5:	7e 05                	jle    223cc <fmt_fp+0x52c>
   223c7:	b9 09 00 00 00       	mov    $0x9,%ecx
   223cc:	8b 44 24 10          	mov    0x10(%esp),%eax
   223d0:	39 f8                	cmp    %edi,%eax
   223d2:	0f 83 b8 05 00 00    	jae    22990 <fmt_fp+0xaf0>
   223d8:	bd 01 00 00 00       	mov    $0x1,%ebp
   223dd:	be 00 ca 9a 3b       	mov    $0x3b9aca00,%esi
   223e2:	d3 e5                	shl    %cl,%ebp
   223e4:	31 d2                	xor    %edx,%edx
   223e6:	d3 fe                	sar    %cl,%esi
   223e8:	83 ed 01             	sub    $0x1,%ebp
   223eb:	89 74 24 20          	mov    %esi,0x20(%esp)
   223ef:	90                   	nop
   223f0:	8b 18                	mov    (%eax),%ebx
   223f2:	83 c0 04             	add    $0x4,%eax
   223f5:	89 de                	mov    %ebx,%esi
   223f7:	d3 ee                	shr    %cl,%esi
   223f9:	01 f2                	add    %esi,%edx
   223fb:	89 50 fc             	mov    %edx,-0x4(%eax)
   223fe:	89 da                	mov    %ebx,%edx
   22400:	21 ea                	and    %ebp,%edx
   22402:	0f af 54 24 20       	imul   0x20(%esp),%edx
   22407:	39 f8                	cmp    %edi,%eax
   22409:	72 e5                	jb     223f0 <fmt_fp+0x550>
   2240b:	8b 44 24 10          	mov    0x10(%esp),%eax
   2240f:	8b 18                	mov    (%eax),%ebx
   22411:	85 db                	test   %ebx,%ebx
   22413:	75 05                	jne    2241a <fmt_fp+0x57a>
   22415:	83 44 24 10 04       	addl   $0x4,0x10(%esp)
   2241a:	85 d2                	test   %edx,%edx
   2241c:	74 05                	je     22423 <fmt_fp+0x583>
   2241e:	89 17                	mov    %edx,(%edi)
   22420:	83 c7 04             	add    $0x4,%edi
   22423:	83 7c 24 44 66       	cmpl   $0x66,0x44(%esp)
   22428:	8b 54 24 3c          	mov    0x3c(%esp),%edx
   2242c:	74 04                	je     22432 <fmt_fp+0x592>
   2242e:	8b 54 24 10          	mov    0x10(%esp),%edx
   22432:	89 f8                	mov    %edi,%eax
   22434:	29 d0                	sub    %edx,%eax
   22436:	c1 f8 02             	sar    $0x2,%eax
   22439:	3b 44 24 40          	cmp    0x40(%esp),%eax
   2243d:	7e 07                	jle    22446 <fmt_fp+0x5a6>
   2243f:	8b 44 24 4c          	mov    0x4c(%esp),%eax
   22443:	8d 3c 02             	lea    (%edx,%eax,1),%edi
   22446:	03 4c 24 30          	add    0x30(%esp),%ecx
   2244a:	79 09                	jns    22455 <fmt_fp+0x5b5>
   2244c:	89 4c 24 30          	mov    %ecx,0x30(%esp)
   22450:	e9 6b ff ff ff       	jmp    223c0 <fmt_fp+0x520>
   22455:	89 7c 24 2c          	mov    %edi,0x2c(%esp)
   22459:	89 4c 24 78          	mov    %ecx,0x78(%esp)
   2245d:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   22461:	39 44 24 10          	cmp    %eax,0x10(%esp)
   22465:	0f 82 3c 05 00 00    	jb     229a7 <fmt_fp+0xb07>
   2246b:	8b 4c 24 34          	mov    0x34(%esp),%ecx
   2246f:	31 c0                	xor    %eax,%eax
   22471:	31 ed                	xor    %ebp,%ebp
   22473:	29 c1                	sub    %eax,%ecx
   22475:	31 c0                	xor    %eax,%eax
   22477:	83 7c 24 44 67       	cmpl   $0x67,0x44(%esp)
   2247c:	0f 84 72 05 00 00    	je     229f4 <fmt_fp+0xb54>
   22482:	29 c1                	sub    %eax,%ecx
   22484:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   22488:	2b 44 24 3c          	sub    0x3c(%esp),%eax
   2248c:	c1 f8 02             	sar    $0x2,%eax
   2248f:	8d 44 c0 f7          	lea    -0x9(%eax,%eax,8),%eax
   22493:	39 c1                	cmp    %eax,%ecx
   22495:	0f 8d da 00 00 00    	jge    22575 <fmt_fp+0x6d5>
   2249b:	81 c1 00 40 02 00    	add    $0x24000,%ecx
   224a1:	ba 39 8e e3 38       	mov    $0x38e38e39,%edx
   224a6:	89 c8                	mov    %ecx,%eax
   224a8:	f7 ea                	imul   %edx
   224aa:	89 c8                	mov    %ecx,%eax
   224ac:	c1 f8 1f             	sar    $0x1f,%eax
   224af:	d1 fa                	sar    %edx
   224b1:	29 c2                	sub    %eax,%edx
   224b3:	8b 44 24 3c          	mov    0x3c(%esp),%eax
   224b7:	8d 9c 90 04 00 ff ff 	lea    -0xfffc(%eax,%edx,4),%ebx
   224be:	8d 04 d2             	lea    (%edx,%edx,8),%eax
   224c1:	29 c1                	sub    %eax,%ecx
   224c3:	8d 41 01             	lea    0x1(%ecx),%eax
   224c6:	83 f8 09             	cmp    $0x9,%eax
   224c9:	0f 84 33 13 00 00    	je     23802 <fmt_fp+0x1962>
   224cf:	b9 0a 00 00 00       	mov    $0xa,%ecx
   224d4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   224d8:	8d 0c 89             	lea    (%ecx,%ecx,4),%ecx
   224db:	83 c0 01             	add    $0x1,%eax
   224de:	01 c9                	add    %ecx,%ecx
   224e0:	83 f8 09             	cmp    $0x9,%eax
   224e3:	75 f3                	jne    224d8 <fmt_fp+0x638>
   224e5:	89 ce                	mov    %ecx,%esi
   224e7:	8b 03                	mov    (%ebx),%eax
   224e9:	31 d2                	xor    %edx,%edx
   224eb:	89 44 24 20          	mov    %eax,0x20(%esp)
   224ef:	f7 f6                	div    %esi
   224f1:	85 d2                	test   %edx,%edx
   224f3:	89 d7                	mov    %edx,%edi
   224f5:	75 09                	jne    22500 <fmt_fp+0x660>
   224f7:	8d 43 04             	lea    0x4(%ebx),%eax
   224fa:	3b 44 24 2c          	cmp    0x2c(%esp),%eax
   224fe:	74 6b                	je     2256b <fmt_fp+0x6cb>
   22500:	8b 44 24 20          	mov    0x20(%esp),%eax
   22504:	31 d2                	xor    %edx,%edx
   22506:	f7 f6                	div    %esi
   22508:	a8 01                	test   $0x1,%al
   2250a:	0f 85 50 0b 00 00    	jne    23060 <fmt_fp+0x11c0>
   22510:	d9 05 64 45 00 00    	flds   0x4564
   22516:	d1 f9                	sar    %ecx
   22518:	39 cf                	cmp    %ecx,%edi
   2251a:	0f 82 2f 0b 00 00    	jb     2304f <fmt_fp+0x11af>
   22520:	0f 84 e8 10 00 00    	je     2360e <fmt_fp+0x176e>
   22526:	d9 05 70 45 00 00    	flds   0x4570
   2252c:	d9 05 74 45 00 00    	flds   0x4574
   22532:	8b 44 24 50          	mov    0x50(%esp),%eax
   22536:	85 c0                	test   %eax,%eax
   22538:	74 11                	je     2254b <fmt_fp+0x6ab>
   2253a:	8b 44 24 54          	mov    0x54(%esp),%eax
   2253e:	80 38 2d             	cmpb   $0x2d,(%eax)
   22541:	0f 84 ba 10 00 00    	je     23601 <fmt_fp+0x1761>
   22547:	dd d9                	fstp   %st(1)
   22549:	eb 02                	jmp    2254d <fmt_fp+0x6ad>
   2254b:	dd d9                	fstp   %st(1)
   2254d:	d8 c1                	fadd   %st(1),%st
   2254f:	8b 54 24 20          	mov    0x20(%esp),%edx
   22553:	da e9                	fucompp 
   22555:	df e0                	fnstsw %ax
   22557:	29 fa                	sub    %edi,%edx
   22559:	9e                   	sahf   
   2255a:	0f 8a 1b 03 00 00    	jp     2287b <fmt_fp+0x9db>
   22560:	0f 85 15 03 00 00    	jne    2287b <fmt_fp+0x9db>
   22566:	89 13                	mov    %edx,(%ebx)
   22568:	8d 43 04             	lea    0x4(%ebx),%eax
   2256b:	39 44 24 2c          	cmp    %eax,0x2c(%esp)
   2256f:	76 04                	jbe    22575 <fmt_fp+0x6d5>
   22571:	89 44 24 2c          	mov    %eax,0x2c(%esp)
   22575:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   22579:	8b 54 24 10          	mov    0x10(%esp),%edx
   2257d:	39 c2                	cmp    %eax,%edx
   2257f:	73 21                	jae    225a2 <fmt_fp+0x702>
   22581:	8b 58 fc             	mov    -0x4(%eax),%ebx
   22584:	85 db                	test   %ebx,%ebx
   22586:	74 0f                	je     22597 <fmt_fp+0x6f7>
   22588:	eb 18                	jmp    225a2 <fmt_fp+0x702>
   2258a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   22590:	8b 48 fc             	mov    -0x4(%eax),%ecx
   22593:	85 c9                	test   %ecx,%ecx
   22595:	75 07                	jne    2259e <fmt_fp+0x6fe>
   22597:	83 e8 04             	sub    $0x4,%eax
   2259a:	39 d0                	cmp    %edx,%eax
   2259c:	77 f2                	ja     22590 <fmt_fp+0x6f0>
   2259e:	89 44 24 2c          	mov    %eax,0x2c(%esp)
   225a2:	83 7c 24 44 67       	cmpl   $0x67,0x44(%esp)
   225a7:	0f 84 29 0a 00 00    	je     22fd6 <fmt_fp+0x1136>
   225ad:	8b 7c 24 34          	mov    0x34(%esp),%edi
   225b1:	b8 01 00 00 00       	mov    $0x1,%eax
   225b6:	85 ff                	test   %edi,%edi
   225b8:	8d 57 01             	lea    0x1(%edi),%edx
   225bb:	75 0d                	jne    225ca <fmt_fp+0x72a>
   225bd:	8b 84 24 7c 1e 00 00 	mov    0x1e7c(%esp),%eax
   225c4:	c1 e8 03             	shr    $0x3,%eax
   225c7:	83 e0 01             	and    $0x1,%eax
   225ca:	01 d0                	add    %edx,%eax
   225cc:	83 7c 24 44 66       	cmpl   $0x66,0x44(%esp)
   225d1:	89 44 24 30          	mov    %eax,0x30(%esp)
   225d5:	0f 84 56 0a 00 00    	je     23031 <fmt_fp+0x1191>
   225db:	89 ea                	mov    %ebp,%edx
   225dd:	c1 fa 1f             	sar    $0x1f,%edx
   225e0:	89 d0                	mov    %edx,%eax
   225e2:	31 e8                	xor    %ebp,%eax
   225e4:	29 d0                	sub    %edx,%eax
   225e6:	99                   	cltd   
   225e7:	8d bc 24 88 00 00 00 	lea    0x88(%esp),%edi
   225ee:	83 fa 00             	cmp    $0x0,%edx
   225f1:	89 44 24 20          	mov    %eax,0x20(%esp)
   225f5:	89 fb                	mov    %edi,%ebx
   225f7:	89 54 24 24          	mov    %edx,0x24(%esp)
   225fb:	76 60                	jbe    2265d <fmt_fp+0x7bd>
   225fd:	8b 44 24 20          	mov    0x20(%esp),%eax
   22601:	8b 54 24 24          	mov    0x24(%esp),%edx
   22605:	8d 76 00             	lea    0x0(%esi),%esi
   22608:	c7 44 24 08 0a 00 00 	movl   $0xa,0x8(%esp)
   2260f:	00 
   22610:	83 eb 01             	sub    $0x1,%ebx
   22613:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   2261a:	00 
   2261b:	89 04 24             	mov    %eax,(%esp)
   2261e:	89 54 24 04          	mov    %edx,0x4(%esp)
   22622:	e8 fc ff ff ff       	call   22623 <fmt_fp+0x783>
   22627:	8b 54 24 24          	mov    0x24(%esp),%edx
   2262b:	83 c0 30             	add    $0x30,%eax
   2262e:	88 03                	mov    %al,(%ebx)
   22630:	8b 44 24 20          	mov    0x20(%esp),%eax
   22634:	c7 44 24 08 0a 00 00 	movl   $0xa,0x8(%esp)
   2263b:	00 
   2263c:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   22643:	00 
   22644:	89 54 24 04          	mov    %edx,0x4(%esp)
   22648:	89 04 24             	mov    %eax,(%esp)
   2264b:	e8 fc ff ff ff       	call   2264c <fmt_fp+0x7ac>
   22650:	83 fa 00             	cmp    $0x0,%edx
   22653:	89 44 24 20          	mov    %eax,0x20(%esp)
   22657:	89 54 24 24          	mov    %edx,0x24(%esp)
   2265b:	77 ab                	ja     22608 <fmt_fp+0x768>
   2265d:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   22661:	85 c9                	test   %ecx,%ecx
   22663:	74 39                	je     2269e <fmt_fp+0x7fe>
   22665:	be cd cc cc cc       	mov    $0xcccccccd,%esi
   2266a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   22670:	89 c8                	mov    %ecx,%eax
   22672:	83 eb 01             	sub    $0x1,%ebx
   22675:	f7 e6                	mul    %esi
   22677:	c1 ea 03             	shr    $0x3,%edx
   2267a:	8d 04 92             	lea    (%edx,%edx,4),%eax
   2267d:	01 c0                	add    %eax,%eax
   2267f:	29 c1                	sub    %eax,%ecx
   22681:	83 c1 30             	add    $0x30,%ecx
   22684:	85 d2                	test   %edx,%edx
   22686:	88 0b                	mov    %cl,(%ebx)
   22688:	89 d1                	mov    %edx,%ecx
   2268a:	75 e4                	jne    22670 <fmt_fp+0x7d0>
   2268c:	89 f8                	mov    %edi,%eax
   2268e:	29 d8                	sub    %ebx,%eax
   22690:	83 f8 01             	cmp    $0x1,%eax
   22693:	7f 12                	jg     226a7 <fmt_fp+0x807>
   22695:	8d 76 00             	lea    0x0(%esi),%esi
   22698:	83 eb 01             	sub    $0x1,%ebx
   2269b:	c6 03 30             	movb   $0x30,(%ebx)
   2269e:	89 f8                	mov    %edi,%eax
   226a0:	29 d8                	sub    %ebx,%eax
   226a2:	83 f8 01             	cmp    $0x1,%eax
   226a5:	7e f1                	jle    22698 <fmt_fp+0x7f8>
   226a7:	89 e8                	mov    %ebp,%eax
   226a9:	c1 f8 1f             	sar    $0x1f,%eax
   226ac:	83 e0 02             	and    $0x2,%eax
   226af:	83 c0 2b             	add    $0x2b,%eax
   226b2:	88 43 ff             	mov    %al,-0x1(%ebx)
   226b5:	8d 43 fe             	lea    -0x2(%ebx),%eax
   226b8:	89 c6                	mov    %eax,%esi
   226ba:	89 44 24 5c          	mov    %eax,0x5c(%esp)
   226be:	0f b6 84 24 80 1e 00 	movzbl 0x1e80(%esp),%eax
   226c5:	00 
   226c6:	29 f7                	sub    %esi,%edi
   226c8:	01 7c 24 30          	add    %edi,0x30(%esp)
   226cc:	88 43 fe             	mov    %al,-0x2(%ebx)
   226cf:	8b 44 24 50          	mov    0x50(%esp),%eax
   226d3:	03 44 24 30          	add    0x30(%esp),%eax
   226d7:	f7 84 24 7c 1e 00 00 	testl  $0x12000,0x1e7c(%esp)
   226de:	00 20 01 00 
   226e2:	89 44 24 30          	mov    %eax,0x30(%esp)
   226e6:	75 0a                	jne    226f2 <fmt_fp+0x852>
   226e8:	39 44 24 48          	cmp    %eax,0x48(%esp)
   226ec:	0f 8f 45 0c 00 00    	jg     23337 <fmt_fp+0x1497>
   226f2:	8b 44 24 38          	mov    0x38(%esp),%eax
   226f6:	8b 00                	mov    (%eax),%eax
   226f8:	83 e0 20             	and    $0x20,%eax
   226fb:	85 c0                	test   %eax,%eax
   226fd:	0f 84 8a 06 00 00    	je     22d8d <fmt_fp+0xeed>
   22703:	8b 84 24 7c 1e 00 00 	mov    0x1e7c(%esp),%eax
   2270a:	35 00 00 01 00       	xor    $0x10000,%eax
   2270f:	a9 00 20 01 00       	test   $0x12000,%eax
   22714:	75 0e                	jne    22724 <fmt_fp+0x884>
   22716:	8b 44 24 30          	mov    0x30(%esp),%eax
   2271a:	39 44 24 48          	cmp    %eax,0x48(%esp)
   2271e:	0f 8f 13 0b 00 00    	jg     23237 <fmt_fp+0x1397>
   22724:	83 7c 24 44 66       	cmpl   $0x66,0x44(%esp)
   22729:	0f 84 7f 06 00 00    	je     22dae <fmt_fp+0xf0e>
   2272f:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   22733:	39 44 24 10          	cmp    %eax,0x10(%esp)
   22737:	72 0b                	jb     22744 <fmt_fp+0x8a4>
   22739:	8b 44 24 10          	mov    0x10(%esp),%eax
   2273d:	83 c0 04             	add    $0x4,%eax
   22740:	89 44 24 2c          	mov    %eax,0x2c(%esp)
   22744:	8b 44 24 10          	mov    0x10(%esp),%eax
   22748:	39 44 24 2c          	cmp    %eax,0x2c(%esp)
   2274c:	0f 86 b7 00 00 00    	jbe    22809 <fmt_fp+0x969>
   22752:	8b 5c 24 34          	mov    0x34(%esp),%ebx
   22756:	85 db                	test   %ebx,%ebx
   22758:	0f 88 ab 00 00 00    	js     22809 <fmt_fp+0x969>
   2275e:	8d bc 24 91 00 00 00 	lea    0x91(%esp),%edi
   22765:	89 c5                	mov    %eax,%ebp
   22767:	89 7c 24 20          	mov    %edi,0x20(%esp)
   2276b:	8b bc 24 7c 1e 00 00 	mov    0x1e7c(%esp),%edi
   22772:	83 e7 08             	and    $0x8,%edi
   22775:	89 7c 24 40          	mov    %edi,0x40(%esp)
   22779:	8d bc 24 88 00 00 00 	lea    0x88(%esp),%edi
   22780:	8b 4d 00             	mov    0x0(%ebp),%ecx
   22783:	be cd cc cc cc       	mov    $0xcccccccd,%esi
   22788:	8b 5c 24 20          	mov    0x20(%esp),%ebx
   2278c:	85 c9                	test   %ecx,%ecx
   2278e:	0f 84 8c 01 00 00    	je     22920 <fmt_fp+0xa80>
   22794:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   22798:	89 c8                	mov    %ecx,%eax
   2279a:	83 eb 01             	sub    $0x1,%ebx
   2279d:	f7 e6                	mul    %esi
   2279f:	c1 ea 03             	shr    $0x3,%edx
   227a2:	8d 04 92             	lea    (%edx,%edx,4),%eax
   227a5:	01 c0                	add    %eax,%eax
   227a7:	29 c1                	sub    %eax,%ecx
   227a9:	83 c1 30             	add    $0x30,%ecx
   227ac:	85 d2                	test   %edx,%edx
   227ae:	88 0b                	mov    %cl,(%ebx)
   227b0:	89 d1                	mov    %edx,%ecx
   227b2:	75 e4                	jne    22798 <fmt_fp+0x8f8>
   227b4:	3b 5c 24 20          	cmp    0x20(%esp),%ebx
   227b8:	0f 84 62 01 00 00    	je     22920 <fmt_fp+0xa80>
   227be:	3b 6c 24 10          	cmp    0x10(%esp),%ebp
   227c2:	0f 84 78 01 00 00    	je     22940 <fmt_fp+0xaa0>
   227c8:	39 fb                	cmp    %edi,%ebx
   227ca:	0f 86 c7 01 00 00    	jbe    22997 <fmt_fp+0xaf7>
   227d0:	83 eb 01             	sub    $0x1,%ebx
   227d3:	39 fb                	cmp    %edi,%ebx
   227d5:	c6 03 30             	movb   $0x30,(%ebx)
   227d8:	75 f6                	jne    227d0 <fmt_fp+0x930>
   227da:	8b 44 24 38          	mov    0x38(%esp),%eax
   227de:	8d b4 24 88 00 00 00 	lea    0x88(%esp),%esi
   227e5:	8b 00                	mov    (%eax),%eax
   227e7:	83 e0 20             	and    $0x20,%eax
   227ea:	85 c0                	test   %eax,%eax
   227ec:	0f 84 fe 00 00 00    	je     228f0 <fmt_fp+0xa50>
   227f2:	2b 74 24 20          	sub    0x20(%esp),%esi
   227f6:	83 c5 04             	add    $0x4,%ebp
   227f9:	01 74 24 34          	add    %esi,0x34(%esp)
   227fd:	78 0a                	js     22809 <fmt_fp+0x969>
   227ff:	39 6c 24 2c          	cmp    %ebp,0x2c(%esp)
   22803:	0f 87 77 ff ff ff    	ja     22780 <fmt_fp+0x8e0>
   22809:	8b 44 24 34          	mov    0x34(%esp),%eax
   2280d:	85 c0                	test   %eax,%eax
   2280f:	0f 8f 56 08 00 00    	jg     2306b <fmt_fp+0x11cb>
   22815:	8b 44 24 38          	mov    0x38(%esp),%eax
   22819:	8b 00                	mov    (%eax),%eax
   2281b:	83 e0 20             	and    $0x20,%eax
   2281e:	85 c0                	test   %eax,%eax
   22820:	75 21                	jne    22843 <fmt_fp+0x9a3>
   22822:	8b 44 24 38          	mov    0x38(%esp),%eax
   22826:	8b 7c 24 5c          	mov    0x5c(%esp),%edi
   2282a:	89 44 24 08          	mov    %eax,0x8(%esp)
   2282e:	8d 84 24 88 00 00 00 	lea    0x88(%esp),%eax
   22835:	29 f8                	sub    %edi,%eax
   22837:	89 44 24 04          	mov    %eax,0x4(%esp)
   2283b:	89 3c 24             	mov    %edi,(%esp)
   2283e:	e8 fc ff ff ff       	call   2283f <fmt_fp+0x99f>
   22843:	8b 84 24 7c 1e 00 00 	mov    0x1e7c(%esp),%eax
   2284a:	80 f4 20             	xor    $0x20,%ah
   2284d:	a9 00 20 01 00       	test   $0x12000,%eax
   22852:	75 0e                	jne    22862 <fmt_fp+0x9c2>
   22854:	8b 44 24 30          	mov    0x30(%esp),%eax
   22858:	39 44 24 48          	cmp    %eax,0x48(%esp)
   2285c:	0f 8f 55 0a 00 00    	jg     232b7 <fmt_fp+0x1417>
   22862:	8b 44 24 30          	mov    0x30(%esp),%eax
   22866:	3b 44 24 48          	cmp    0x48(%esp),%eax
   2286a:	0f 8c a7 f9 ff ff    	jl     22217 <fmt_fp+0x377>
   22870:	81 c4 5c 1e 00 00    	add    $0x1e5c,%esp
   22876:	5b                   	pop    %ebx
   22877:	5e                   	pop    %esi
   22878:	5f                   	pop    %edi
   22879:	5d                   	pop    %ebp
   2287a:	c3                   	ret    
   2287b:	01 f2                	add    %esi,%edx
   2287d:	81 fa ff c9 9a 3b    	cmp    $0x3b9ac9ff,%edx
   22883:	89 13                	mov    %edx,(%ebx)
   22885:	76 33                	jbe    228ba <fmt_fp+0xa1a>
   22887:	8b 54 24 10          	mov    0x10(%esp),%edx
   2288b:	90                   	nop
   2288c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   22890:	83 eb 04             	sub    $0x4,%ebx
   22893:	39 d3                	cmp    %edx,%ebx
   22895:	c7 43 04 00 00 00 00 	movl   $0x0,0x4(%ebx)
   2289c:	73 0a                	jae    228a8 <fmt_fp+0xa08>
   2289e:	c7 42 fc 00 00 00 00 	movl   $0x0,-0x4(%edx)
   228a5:	83 ea 04             	sub    $0x4,%edx
   228a8:	8b 03                	mov    (%ebx),%eax
   228aa:	83 c0 01             	add    $0x1,%eax
   228ad:	3d ff c9 9a 3b       	cmp    $0x3b9ac9ff,%eax
   228b2:	89 03                	mov    %eax,(%ebx)
   228b4:	77 da                	ja     22890 <fmt_fp+0x9f0>
   228b6:	89 54 24 10          	mov    %edx,0x10(%esp)
   228ba:	8b 7c 24 10          	mov    0x10(%esp),%edi
   228be:	8b 44 24 3c          	mov    0x3c(%esp),%eax
   228c2:	8b 17                	mov    (%edi),%edx
   228c4:	29 f8                	sub    %edi,%eax
   228c6:	c1 f8 02             	sar    $0x2,%eax
   228c9:	8d 2c c0             	lea    (%eax,%eax,8),%ebp
   228cc:	b8 0a 00 00 00       	mov    $0xa,%eax
   228d1:	83 fa 09             	cmp    $0x9,%edx
   228d4:	76 0e                	jbe    228e4 <fmt_fp+0xa44>
   228d6:	66 90                	xchg   %ax,%ax
   228d8:	8d 04 80             	lea    (%eax,%eax,4),%eax
   228db:	83 c5 01             	add    $0x1,%ebp
   228de:	01 c0                	add    %eax,%eax
   228e0:	39 d0                	cmp    %edx,%eax
   228e2:	76 f4                	jbe    228d8 <fmt_fp+0xa38>
   228e4:	8d 43 04             	lea    0x4(%ebx),%eax
   228e7:	e9 7f fc ff ff       	jmp    2256b <fmt_fp+0x6cb>
   228ec:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   228f0:	8b 44 24 38          	mov    0x38(%esp),%eax
   228f4:	89 44 24 08          	mov    %eax,0x8(%esp)
   228f8:	8b 44 24 20          	mov    0x20(%esp),%eax
   228fc:	29 f0                	sub    %esi,%eax
   228fe:	3b 44 24 34          	cmp    0x34(%esp),%eax
   22902:	7e 04                	jle    22908 <fmt_fp+0xa68>
   22904:	8b 44 24 34          	mov    0x34(%esp),%eax
   22908:	89 44 24 04          	mov    %eax,0x4(%esp)
   2290c:	89 34 24             	mov    %esi,(%esp)
   2290f:	e8 fc ff ff ff       	call   22910 <fmt_fp+0xa70>
   22914:	e9 d9 fe ff ff       	jmp    227f2 <fmt_fp+0x952>
   22919:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   22920:	3b 6c 24 10          	cmp    0x10(%esp),%ebp
   22924:	c6 84 24 90 00 00 00 	movb   $0x30,0x90(%esp)
   2292b:	30 
   2292c:	8d 9c 24 90 00 00 00 	lea    0x90(%esp),%ebx
   22933:	0f 85 97 fe ff ff    	jne    227d0 <fmt_fp+0x930>
   22939:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   22940:	8b 44 24 38          	mov    0x38(%esp),%eax
   22944:	8d 73 01             	lea    0x1(%ebx),%esi
   22947:	8b 00                	mov    (%eax),%eax
   22949:	89 44 24 3c          	mov    %eax,0x3c(%esp)
   2294d:	83 e0 20             	and    $0x20,%eax
   22950:	0f 84 f9 03 00 00    	je     22d4f <fmt_fp+0xeaf>
   22956:	8b 4c 24 34          	mov    0x34(%esp),%ecx
   2295a:	85 c9                	test   %ecx,%ecx
   2295c:	0f 84 1a 04 00 00    	je     22d7c <fmt_fp+0xedc>
   22962:	85 c0                	test   %eax,%eax
   22964:	0f 85 88 fe ff ff    	jne    227f2 <fmt_fp+0x952>
   2296a:	8b 5c 24 38          	mov    0x38(%esp),%ebx
   2296e:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
   22975:	00 
   22976:	c7 04 24 4d 45 00 00 	movl   $0x454d,(%esp)
   2297d:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   22981:	e8 fc ff ff ff       	call   22982 <fmt_fp+0xae2>
   22986:	8b 03                	mov    (%ebx),%eax
   22988:	83 e0 20             	and    $0x20,%eax
   2298b:	e9 5a fe ff ff       	jmp    227ea <fmt_fp+0x94a>
   22990:	31 d2                	xor    %edx,%edx
   22992:	e9 74 fa ff ff       	jmp    2240b <fmt_fp+0x56b>
   22997:	8b 44 24 38          	mov    0x38(%esp),%eax
   2299b:	89 de                	mov    %ebx,%esi
   2299d:	8b 00                	mov    (%eax),%eax
   2299f:	83 e0 20             	and    $0x20,%eax
   229a2:	e9 43 fe ff ff       	jmp    227ea <fmt_fp+0x94a>
   229a7:	8b 7c 24 10          	mov    0x10(%esp),%edi
   229ab:	8b 44 24 3c          	mov    0x3c(%esp),%eax
   229af:	8b 17                	mov    (%edi),%edx
   229b1:	29 f8                	sub    %edi,%eax
   229b3:	c1 f8 02             	sar    $0x2,%eax
   229b6:	8d 2c c0             	lea    (%eax,%eax,8),%ebp
   229b9:	b8 0a 00 00 00       	mov    $0xa,%eax
   229be:	83 fa 09             	cmp    $0x9,%edx
   229c1:	76 11                	jbe    229d4 <fmt_fp+0xb34>
   229c3:	90                   	nop
   229c4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   229c8:	8d 04 80             	lea    (%eax,%eax,4),%eax
   229cb:	83 c5 01             	add    $0x1,%ebp
   229ce:	01 c0                	add    %eax,%eax
   229d0:	39 d0                	cmp    %edx,%eax
   229d2:	76 f4                	jbe    229c8 <fmt_fp+0xb28>
   229d4:	31 c0                	xor    %eax,%eax
   229d6:	8b 4c 24 34          	mov    0x34(%esp),%ecx
   229da:	83 7c 24 44 66       	cmpl   $0x66,0x44(%esp)
   229df:	0f 95 c0             	setne  %al
   229e2:	0f af c5             	imul   %ebp,%eax
   229e5:	29 c1                	sub    %eax,%ecx
   229e7:	31 c0                	xor    %eax,%eax
   229e9:	83 7c 24 44 67       	cmpl   $0x67,0x44(%esp)
   229ee:	0f 85 8e fa ff ff    	jne    22482 <fmt_fp+0x5e2>
   229f4:	8b 54 24 34          	mov    0x34(%esp),%edx
   229f8:	31 c0                	xor    %eax,%eax
   229fa:	85 d2                	test   %edx,%edx
   229fc:	0f 95 c0             	setne  %al
   229ff:	e9 7e fa ff ff       	jmp    22482 <fmt_fp+0x5e2>
   22a04:	f6 84 24 80 1e 00 00 	testb  $0x20,0x1e80(%esp)
   22a0b:	20 
   22a0c:	74 05                	je     22a13 <fmt_fp+0xb73>
   22a0e:	83 44 24 54 09       	addl   $0x9,0x54(%esp)
   22a13:	8b 44 24 50          	mov    0x50(%esp),%eax
   22a17:	83 c0 02             	add    $0x2,%eax
   22a1a:	83 7c 24 34 0e       	cmpl   $0xe,0x34(%esp)
   22a1f:	89 44 24 3c          	mov    %eax,0x3c(%esp)
   22a23:	77 38                	ja     22a5d <fmt_fp+0xbbd>
   22a25:	b8 0e 00 00 00       	mov    $0xe,%eax
   22a2a:	d9 05 60 45 00 00    	flds   0x4560
   22a30:	2b 44 24 34          	sub    0x34(%esp),%eax
   22a34:	d9 05 78 45 00 00    	flds   0x4578
   22a3a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   22a40:	83 e8 01             	sub    $0x1,%eax
   22a43:	83 f8 ff             	cmp    $0xffffffff,%eax
   22a46:	dc c9                	fmul   %st,%st(1)
   22a48:	75 f6                	jne    22a40 <fmt_fp+0xba0>
   22a4a:	dd d8                	fstp   %st(0)
   22a4c:	8b 44 24 54          	mov    0x54(%esp),%eax
   22a50:	80 38 2d             	cmpb   $0x2d,(%eax)
   22a53:	0f 84 10 0c 00 00    	je     23669 <fmt_fp+0x17c9>
   22a59:	dc c1                	fadd   %st,%st(1)
   22a5b:	de e9                	fsubrp %st,%st(1)
   22a5d:	8b 44 24 30          	mov    0x30(%esp),%eax
   22a61:	8d bc 24 88 00 00 00 	lea    0x88(%esp),%edi
   22a68:	89 fb                	mov    %edi,%ebx
   22a6a:	89 c2                	mov    %eax,%edx
   22a6c:	c1 fa 1f             	sar    $0x1f,%edx
   22a6f:	31 d0                	xor    %edx,%eax
   22a71:	29 d0                	sub    %edx,%eax
   22a73:	99                   	cltd   
   22a74:	83 fa 00             	cmp    $0x0,%edx
   22a77:	89 44 24 20          	mov    %eax,0x20(%esp)
   22a7b:	89 54 24 24          	mov    %edx,0x24(%esp)
   22a7f:	76 68                	jbe    22ae9 <fmt_fp+0xc49>
   22a81:	8b 44 24 20          	mov    0x20(%esp),%eax
   22a85:	8b 54 24 24          	mov    0x24(%esp),%edx
   22a89:	db 7c 24 10          	fstpt  0x10(%esp)
   22a8d:	8d 76 00             	lea    0x0(%esi),%esi
   22a90:	83 eb 01             	sub    $0x1,%ebx
   22a93:	c7 44 24 08 0a 00 00 	movl   $0xa,0x8(%esp)
   22a9a:	00 
   22a9b:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   22aa2:	00 
   22aa3:	89 04 24             	mov    %eax,(%esp)
   22aa6:	89 54 24 04          	mov    %edx,0x4(%esp)
   22aaa:	e8 fc ff ff ff       	call   22aab <fmt_fp+0xc0b>
   22aaf:	8b 54 24 24          	mov    0x24(%esp),%edx
   22ab3:	83 c0 30             	add    $0x30,%eax
   22ab6:	88 03                	mov    %al,(%ebx)
   22ab8:	8b 44 24 20          	mov    0x20(%esp),%eax
   22abc:	c7 44 24 08 0a 00 00 	movl   $0xa,0x8(%esp)
   22ac3:	00 
   22ac4:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   22acb:	00 
   22acc:	89 54 24 04          	mov    %edx,0x4(%esp)
   22ad0:	89 04 24             	mov    %eax,(%esp)
   22ad3:	e8 fc ff ff ff       	call   22ad4 <fmt_fp+0xc34>
   22ad8:	83 fa 00             	cmp    $0x0,%edx
   22adb:	89 44 24 20          	mov    %eax,0x20(%esp)
   22adf:	89 54 24 24          	mov    %edx,0x24(%esp)
   22ae3:	77 ab                	ja     22a90 <fmt_fp+0xbf0>
   22ae5:	db 6c 24 10          	fldt   0x10(%esp)
   22ae9:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   22aed:	85 c9                	test   %ecx,%ecx
   22aef:	74 23                	je     22b14 <fmt_fp+0xc74>
   22af1:	be cd cc cc cc       	mov    $0xcccccccd,%esi
   22af6:	66 90                	xchg   %ax,%ax
   22af8:	89 c8                	mov    %ecx,%eax
   22afa:	83 eb 01             	sub    $0x1,%ebx
   22afd:	f7 e6                	mul    %esi
   22aff:	c1 ea 03             	shr    $0x3,%edx
   22b02:	8d 04 92             	lea    (%edx,%edx,4),%eax
   22b05:	01 c0                	add    %eax,%eax
   22b07:	29 c1                	sub    %eax,%ecx
   22b09:	83 c1 30             	add    $0x30,%ecx
   22b0c:	85 d2                	test   %edx,%edx
   22b0e:	88 0b                	mov    %cl,(%ebx)
   22b10:	89 d1                	mov    %edx,%ecx
   22b12:	75 e4                	jne    22af8 <fmt_fp+0xc58>
   22b14:	39 fb                	cmp    %edi,%ebx
   22b16:	0f 84 5c 0b 00 00    	je     23678 <fmt_fp+0x17d8>
   22b1c:	8b 44 24 30          	mov    0x30(%esp),%eax
   22b20:	0f b6 94 24 80 1e 00 	movzbl 0x1e80(%esp),%edx
   22b27:	00 
   22b28:	c1 f8 1f             	sar    $0x1f,%eax
   22b2b:	83 e0 02             	and    $0x2,%eax
   22b2e:	83 e2 20             	and    $0x20,%edx
   22b31:	83 c0 2b             	add    $0x2b,%eax
   22b34:	88 43 ff             	mov    %al,-0x1(%ebx)
   22b37:	8d 43 fe             	lea    -0x2(%ebx),%eax
   22b3a:	89 44 24 10          	mov    %eax,0x10(%esp)
   22b3e:	0f b6 84 24 80 1e 00 	movzbl 0x1e80(%esp),%eax
   22b45:	00 
   22b46:	83 c0 0f             	add    $0xf,%eax
   22b49:	f6 84 24 7c 1e 00 00 	testb  $0x8,0x1e7c(%esp)
   22b50:	08 
   22b51:	88 43 fe             	mov    %al,-0x2(%ebx)
   22b54:	0f 85 bb 05 00 00    	jne    23115 <fmt_fp+0x1275>
   22b5a:	d9 7c 24 6e          	fnstcw 0x6e(%esp)
   22b5e:	8b 74 24 34          	mov    0x34(%esp),%esi
   22b62:	89 f9                	mov    %edi,%ecx
   22b64:	d9 05 78 45 00 00    	flds   0x4578
   22b6a:	d9 c9                	fxch   %st(1)
   22b6c:	0f b7 44 24 6e       	movzwl 0x6e(%esp),%eax
   22b71:	b4 0c                	mov    $0xc,%ah
   22b73:	66 89 44 24 6c       	mov    %ax,0x6c(%esp)
   22b78:	d9 c0                	fld    %st(0)
   22b7a:	d9 6c 24 6c          	fldcw  0x6c(%esp)
   22b7e:	db 5c 24 68          	fistpl 0x68(%esp)
   22b82:	d9 6c 24 6e          	fldcw  0x6e(%esp)
   22b86:	89 d3                	mov    %edx,%ebx
   22b88:	8b 44 24 68          	mov    0x68(%esp),%eax
   22b8c:	0a 98 a8 3a 00 00    	or     0x3aa8(%eax),%bl
   22b92:	39 cf                	cmp    %ecx,%edi
   22b94:	88 19                	mov    %bl,(%ecx)
   22b96:	8d 59 01             	lea    0x1(%ecx),%ebx
   22b99:	89 44 24 68          	mov    %eax,0x68(%esp)
   22b9d:	db 44 24 68          	fildl  0x68(%esp)
   22ba1:	de e9                	fsubrp %st,%st(1)
   22ba3:	d8 c9                	fmul   %st(1),%st
   22ba5:	0f 84 43 01 00 00    	je     22cee <fmt_fp+0xe4e>
   22bab:	d9 ee                	fldz   
   22bad:	d9 c9                	fxch   %st(1)
   22baf:	dd e1                	fucom  %st(1)
   22bb1:	df e0                	fnstsw %ax
   22bb3:	dd d9                	fstp   %st(1)
   22bb5:	9e                   	sahf   
   22bb6:	7b 04                	jnp    22bbc <fmt_fp+0xd1c>
   22bb8:	89 d9                	mov    %ebx,%ecx
   22bba:	eb bc                	jmp    22b78 <fmt_fp+0xcd8>
   22bbc:	75 fa                	jne    22bb8 <fmt_fp+0xd18>
   22bbe:	dd d8                	fstp   %st(0)
   22bc0:	dd d8                	fstp   %st(0)
   22bc2:	eb 04                	jmp    22bc8 <fmt_fp+0xd28>
   22bc4:	dd d8                	fstp   %st(0)
   22bc6:	dd d8                	fstp   %st(0)
   22bc8:	8b 54 24 34          	mov    0x34(%esp),%edx
   22bcc:	89 d8                	mov    %ebx,%eax
   22bce:	29 f8                	sub    %edi,%eax
   22bd0:	89 44 24 30          	mov    %eax,0x30(%esp)
   22bd4:	85 d2                	test   %edx,%edx
   22bd6:	74 0d                	je     22be5 <fmt_fp+0xd45>
   22bd8:	83 e8 01             	sub    $0x1,%eax
   22bdb:	39 44 24 34          	cmp    %eax,0x34(%esp)
   22bdf:	0f 8d df 08 00 00    	jge    234c4 <fmt_fp+0x1624>
   22be5:	89 f8                	mov    %edi,%eax
   22be7:	2b 44 24 10          	sub    0x10(%esp),%eax
   22beb:	89 44 24 40          	mov    %eax,0x40(%esp)
   22bef:	03 44 24 30          	add    0x30(%esp),%eax
   22bf3:	89 44 24 2c          	mov    %eax,0x2c(%esp)
   22bf7:	8b 44 24 3c          	mov    0x3c(%esp),%eax
   22bfb:	03 44 24 2c          	add    0x2c(%esp),%eax
   22bff:	f7 84 24 7c 1e 00 00 	testl  $0x12000,0x1e7c(%esp)
   22c06:	00 20 01 00 
   22c0a:	89 44 24 20          	mov    %eax,0x20(%esp)
   22c0e:	75 0a                	jne    22c1a <fmt_fp+0xd7a>
   22c10:	39 44 24 48          	cmp    %eax,0x48(%esp)
   22c14:	0f 8f 06 0b 00 00    	jg     23720 <fmt_fp+0x1880>
   22c1a:	8b 44 24 38          	mov    0x38(%esp),%eax
   22c1e:	8b 00                	mov    (%eax),%eax
   22c20:	83 e0 20             	and    $0x20,%eax
   22c23:	85 c0                	test   %eax,%eax
   22c25:	0f 84 e9 08 00 00    	je     23514 <fmt_fp+0x1674>
   22c2b:	8b 84 24 7c 1e 00 00 	mov    0x1e7c(%esp),%eax
   22c32:	35 00 00 01 00       	xor    $0x10000,%eax
   22c37:	a9 00 20 01 00       	test   $0x12000,%eax
   22c3c:	75 0e                	jne    22c4c <fmt_fp+0xdac>
   22c3e:	8b 44 24 20          	mov    0x20(%esp),%eax
   22c42:	39 44 24 48          	cmp    %eax,0x48(%esp)
   22c46:	0f 8f 40 0a 00 00    	jg     2368c <fmt_fp+0x17ec>
   22c4c:	8b 44 24 38          	mov    0x38(%esp),%eax
   22c50:	8b 00                	mov    (%eax),%eax
   22c52:	83 e0 20             	and    $0x20,%eax
   22c55:	85 c0                	test   %eax,%eax
   22c57:	0f 84 d8 08 00 00    	je     23535 <fmt_fp+0x1695>
   22c5d:	8b 44 24 10          	mov    0x10(%esp),%eax
   22c61:	29 f8                	sub    %edi,%eax
   22c63:	29 df                	sub    %ebx,%edi
   22c65:	03 44 24 2c          	add    0x2c(%esp),%eax
   22c69:	8d 1c 38             	lea    (%eax,%edi,1),%ebx
   22c6c:	85 db                	test   %ebx,%ebx
   22c6e:	0f 8e 0f 05 00 00    	jle    23183 <fmt_fp+0x12e3>
   22c74:	81 fb 00 01 00 00    	cmp    $0x100,%ebx
   22c7a:	89 de                	mov    %ebx,%esi
   22c7c:	89 d8                	mov    %ebx,%eax
   22c7e:	0f 87 36 08 00 00    	ja     234ba <fmt_fp+0x161a>
   22c84:	8d ac 24 a4 01 00 00 	lea    0x1a4(%esp),%ebp
   22c8b:	89 44 24 08          	mov    %eax,0x8(%esp)
   22c8f:	c7 44 24 04 30 00 00 	movl   $0x30,0x4(%esp)
   22c96:	00 
   22c97:	89 2c 24             	mov    %ebp,(%esp)
   22c9a:	e8 fc ff ff ff       	call   22c9b <fmt_fp+0xdfb>
   22c9f:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   22ca5:	0f 86 7e 0b 00 00    	jbe    23829 <fmt_fp+0x1989>
   22cab:	8b 7c 24 38          	mov    0x38(%esp),%edi
   22caf:	89 de                	mov    %ebx,%esi
   22cb1:	8b 07                	mov    (%edi),%eax
   22cb3:	eb 15                	jmp    22cca <fmt_fp+0xe2a>
   22cb5:	8d 76 00             	lea    0x0(%esi),%esi
   22cb8:	81 ee 00 01 00 00    	sub    $0x100,%esi
   22cbe:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   22cc4:	0f 86 14 05 00 00    	jbe    231de <fmt_fp+0x133e>
   22cca:	89 c2                	mov    %eax,%edx
   22ccc:	83 e2 20             	and    $0x20,%edx
   22ccf:	75 e7                	jne    22cb8 <fmt_fp+0xe18>
   22cd1:	89 7c 24 08          	mov    %edi,0x8(%esp)
   22cd5:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   22cdc:	00 
   22cdd:	89 2c 24             	mov    %ebp,(%esp)
   22ce0:	e8 fc ff ff ff       	call   22ce1 <fmt_fp+0xe41>
   22ce5:	8b 07                	mov    (%edi),%eax
   22ce7:	89 c2                	mov    %eax,%edx
   22ce9:	83 e2 20             	and    $0x20,%edx
   22cec:	eb ca                	jmp    22cb8 <fmt_fp+0xe18>
   22cee:	d9 ee                	fldz   
   22cf0:	d9 c9                	fxch   %st(1)
   22cf2:	dd e1                	fucom  %st(1)
   22cf4:	df e0                	fnstsw %ax
   22cf6:	dd d9                	fstp   %st(1)
   22cf8:	9e                   	sahf   
   22cf9:	7a 0a                	jp     22d05 <fmt_fp+0xe65>
   22cfb:	75 08                	jne    22d05 <fmt_fp+0xe65>
   22cfd:	85 f6                	test   %esi,%esi
   22cff:	0f 8e a6 fe ff ff    	jle    22bab <fmt_fp+0xd0b>
   22d05:	8d 59 02             	lea    0x2(%ecx),%ebx
   22d08:	c6 41 01 2e          	movb   $0x2e,0x1(%ecx)
   22d0c:	e9 9a fe ff ff       	jmp    22bab <fmt_fp+0xd0b>
   22d11:	8b 44 24 58          	mov    0x58(%esp),%eax
   22d15:	8b 74 24 38          	mov    0x38(%esp),%esi
   22d19:	89 44 24 04          	mov    %eax,0x4(%esp)
   22d1d:	8b 44 24 54          	mov    0x54(%esp),%eax
   22d21:	89 74 24 08          	mov    %esi,0x8(%esp)
   22d25:	89 04 24             	mov    %eax,(%esp)
   22d28:	e8 fc ff ff ff       	call   22d29 <fmt_fp+0xe89>
   22d2d:	f6 06 20             	testb  $0x20,(%esi)
   22d30:	0f 85 c2 f4 ff ff    	jne    221f8 <fmt_fp+0x358>
   22d36:	89 74 24 08          	mov    %esi,0x8(%esp)
   22d3a:	c7 44 24 04 03 00 00 	movl   $0x3,0x4(%esp)
   22d41:	00 
   22d42:	89 3c 24             	mov    %edi,(%esp)
   22d45:	e8 fc ff ff ff       	call   22d46 <fmt_fp+0xea6>
   22d4a:	e9 a9 f4 ff ff       	jmp    221f8 <fmt_fp+0x358>
   22d4f:	8b 44 24 38          	mov    0x38(%esp),%eax
   22d53:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
   22d5a:	00 
   22d5b:	89 1c 24             	mov    %ebx,(%esp)
   22d5e:	89 44 24 08          	mov    %eax,0x8(%esp)
   22d62:	e8 fc ff ff ff       	call   22d63 <fmt_fp+0xec3>
   22d67:	8b 44 24 38          	mov    0x38(%esp),%eax
   22d6b:	8b 4c 24 34          	mov    0x34(%esp),%ecx
   22d6f:	8b 00                	mov    (%eax),%eax
   22d71:	83 e0 20             	and    $0x20,%eax
   22d74:	85 c9                	test   %ecx,%ecx
   22d76:	0f 85 e6 fb ff ff    	jne    22962 <fmt_fp+0xac2>
   22d7c:	8b 54 24 40          	mov    0x40(%esp),%edx
   22d80:	85 d2                	test   %edx,%edx
   22d82:	0f 84 62 fa ff ff    	je     227ea <fmt_fp+0x94a>
   22d88:	e9 d5 fb ff ff       	jmp    22962 <fmt_fp+0xac2>
   22d8d:	8b 44 24 38          	mov    0x38(%esp),%eax
   22d91:	89 44 24 08          	mov    %eax,0x8(%esp)
   22d95:	8b 44 24 58          	mov    0x58(%esp),%eax
   22d99:	89 44 24 04          	mov    %eax,0x4(%esp)
   22d9d:	8b 44 24 54          	mov    0x54(%esp),%eax
   22da1:	89 04 24             	mov    %eax,(%esp)
   22da4:	e8 fc ff ff ff       	call   22da5 <fmt_fp+0xf05>
   22da9:	e9 55 f9 ff ff       	jmp    22703 <fmt_fp+0x863>
   22dae:	8b 6c 24 10          	mov    0x10(%esp),%ebp
   22db2:	3b 6c 24 3c          	cmp    0x3c(%esp),%ebp
   22db6:	76 04                	jbe    22dbc <fmt_fp+0xf1c>
   22db8:	8b 6c 24 3c          	mov    0x3c(%esp),%ebp
   22dbc:	39 6c 24 3c          	cmp    %ebp,0x3c(%esp)
   22dc0:	0f 82 97 00 00 00    	jb     22e5d <fmt_fp+0xfbd>
   22dc6:	89 ef                	mov    %ebp,%edi
   22dc8:	be cd cc cc cc       	mov    $0xcccccccd,%esi
   22dcd:	89 6c 24 10          	mov    %ebp,0x10(%esp)
   22dd1:	8b 6c 24 38          	mov    0x38(%esp),%ebp
   22dd5:	8d 84 24 91 00 00 00 	lea    0x91(%esp),%eax
   22ddc:	89 44 24 20          	mov    %eax,0x20(%esp)
   22de0:	8b 0f                	mov    (%edi),%ecx
   22de2:	85 c9                	test   %ecx,%ecx
   22de4:	0f 84 d2 0a 00 00    	je     238bc <fmt_fp+0x1a1c>
   22dea:	8b 5c 24 20          	mov    0x20(%esp),%ebx
   22dee:	66 90                	xchg   %ax,%ax
   22df0:	89 c8                	mov    %ecx,%eax
   22df2:	83 eb 01             	sub    $0x1,%ebx
   22df5:	f7 e6                	mul    %esi
   22df7:	c1 ea 03             	shr    $0x3,%edx
   22dfa:	8d 04 92             	lea    (%edx,%edx,4),%eax
   22dfd:	01 c0                	add    %eax,%eax
   22dff:	29 c1                	sub    %eax,%ecx
   22e01:	83 c1 30             	add    $0x30,%ecx
   22e04:	85 d2                	test   %edx,%edx
   22e06:	88 0b                	mov    %cl,(%ebx)
   22e08:	89 d1                	mov    %edx,%ecx
   22e0a:	75 e4                	jne    22df0 <fmt_fp+0xf50>
   22e0c:	3b 7c 24 10          	cmp    0x10(%esp),%edi
   22e10:	0f 84 88 0a 00 00    	je     2389e <fmt_fp+0x19fe>
   22e16:	8d 84 24 88 00 00 00 	lea    0x88(%esp),%eax
   22e1d:	39 c3                	cmp    %eax,%ebx
   22e1f:	76 18                	jbe    22e39 <fmt_fp+0xf99>
   22e21:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   22e28:	83 eb 01             	sub    $0x1,%ebx
   22e2b:	39 c3                	cmp    %eax,%ebx
   22e2d:	c6 03 30             	movb   $0x30,(%ebx)
   22e30:	75 f6                	jne    22e28 <fmt_fp+0xf88>
   22e32:	8d 9c 24 88 00 00 00 	lea    0x88(%esp),%ebx
   22e39:	f6 45 00 20          	testb  $0x20,0x0(%ebp)
   22e3d:	0f 84 78 01 00 00    	je     22fbb <fmt_fp+0x111b>
   22e43:	83 c7 04             	add    $0x4,%edi
   22e46:	39 7c 24 3c          	cmp    %edi,0x3c(%esp)
   22e4a:	73 94                	jae    22de0 <fmt_fp+0xf40>
   22e4c:	8b 6c 24 10          	mov    0x10(%esp),%ebp
   22e50:	8b 44 24 3c          	mov    0x3c(%esp),%eax
   22e54:	29 e8                	sub    %ebp,%eax
   22e56:	c1 e8 02             	shr    $0x2,%eax
   22e59:	8d 6c 85 04          	lea    0x4(%ebp,%eax,4),%ebp
   22e5d:	8b 44 24 34          	mov    0x34(%esp),%eax
   22e61:	85 c0                	test   %eax,%eax
   22e63:	75 0e                	jne    22e73 <fmt_fp+0xfd3>
   22e65:	f6 84 24 7c 1e 00 00 	testb  $0x8,0x1e7c(%esp)
   22e6c:	08 
   22e6d:	0f 84 d0 f9 ff ff    	je     22843 <fmt_fp+0x9a3>
   22e73:	8b 44 24 38          	mov    0x38(%esp),%eax
   22e77:	f6 00 20             	testb  $0x20,(%eax)
   22e7a:	0f 84 cc 07 00 00    	je     2364c <fmt_fp+0x17ac>
   22e80:	3b 6c 24 2c          	cmp    0x2c(%esp),%ebp
   22e84:	73 7f                	jae    22f05 <fmt_fp+0x1065>
   22e86:	8b 44 24 34          	mov    0x34(%esp),%eax
   22e8a:	85 c0                	test   %eax,%eax
   22e8c:	7e 77                	jle    22f05 <fmt_fp+0x1065>
   22e8e:	8d 84 24 91 00 00 00 	lea    0x91(%esp),%eax
   22e95:	be cd cc cc cc       	mov    $0xcccccccd,%esi
   22e9a:	8d bc 24 88 00 00 00 	lea    0x88(%esp),%edi
   22ea1:	89 44 24 20          	mov    %eax,0x20(%esp)
   22ea5:	8d 76 00             	lea    0x0(%esi),%esi
   22ea8:	8b 5d 00             	mov    0x0(%ebp),%ebx
   22eab:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   22eaf:	85 db                	test   %ebx,%ebx
   22eb1:	74 25                	je     22ed8 <fmt_fp+0x1038>
   22eb3:	90                   	nop
   22eb4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   22eb8:	89 d8                	mov    %ebx,%eax
   22eba:	83 e9 01             	sub    $0x1,%ecx
   22ebd:	f7 e6                	mul    %esi
   22ebf:	c1 ea 03             	shr    $0x3,%edx
   22ec2:	8d 04 92             	lea    (%edx,%edx,4),%eax
   22ec5:	01 c0                	add    %eax,%eax
   22ec7:	29 c3                	sub    %eax,%ebx
   22ec9:	83 c3 30             	add    $0x30,%ebx
   22ecc:	85 d2                	test   %edx,%edx
   22ece:	88 19                	mov    %bl,(%ecx)
   22ed0:	89 d3                	mov    %edx,%ebx
   22ed2:	75 e4                	jne    22eb8 <fmt_fp+0x1018>
   22ed4:	39 f9                	cmp    %edi,%ecx
   22ed6:	76 0a                	jbe    22ee2 <fmt_fp+0x1042>
   22ed8:	83 e9 01             	sub    $0x1,%ecx
   22edb:	39 f9                	cmp    %edi,%ecx
   22edd:	c6 01 30             	movb   $0x30,(%ecx)
   22ee0:	77 f6                	ja     22ed8 <fmt_fp+0x1038>
   22ee2:	8b 44 24 38          	mov    0x38(%esp),%eax
   22ee6:	f6 00 20             	testb  $0x20,(%eax)
   22ee9:	0f 84 a7 00 00 00    	je     22f96 <fmt_fp+0x10f6>
   22eef:	83 6c 24 34 09       	subl   $0x9,0x34(%esp)
   22ef4:	83 c5 04             	add    $0x4,%ebp
   22ef7:	8b 44 24 34          	mov    0x34(%esp),%eax
   22efb:	85 c0                	test   %eax,%eax
   22efd:	7e 06                	jle    22f05 <fmt_fp+0x1065>
   22eff:	3b 6c 24 2c          	cmp    0x2c(%esp),%ebp
   22f03:	72 a3                	jb     22ea8 <fmt_fp+0x1008>
   22f05:	8b 74 24 34          	mov    0x34(%esp),%esi
   22f09:	85 f6                	test   %esi,%esi
   22f0b:	0f 8e 32 f9 ff ff    	jle    22843 <fmt_fp+0x9a3>
   22f11:	8b 7c 24 34          	mov    0x34(%esp),%edi
   22f15:	81 ff 00 01 00 00    	cmp    $0x100,%edi
   22f1b:	89 fe                	mov    %edi,%esi
   22f1d:	89 f8                	mov    %edi,%eax
   22f1f:	76 05                	jbe    22f26 <fmt_fp+0x1086>
   22f21:	b8 00 01 00 00       	mov    $0x100,%eax
   22f26:	8d 9c 24 a4 00 00 00 	lea    0xa4(%esp),%ebx
   22f2d:	89 44 24 08          	mov    %eax,0x8(%esp)
   22f31:	c7 44 24 04 30 00 00 	movl   $0x30,0x4(%esp)
   22f38:	00 
   22f39:	89 1c 24             	mov    %ebx,(%esp)
   22f3c:	e8 fc ff ff ff       	call   22f3d <fmt_fp+0x109d>
   22f41:	81 7c 24 34 ff 00 00 	cmpl   $0xff,0x34(%esp)
   22f48:	00 
   22f49:	0f 86 0e 09 00 00    	jbe    2385d <fmt_fp+0x19bd>
   22f4f:	8b 7c 24 38          	mov    0x38(%esp),%edi
   22f53:	8b 74 24 34          	mov    0x34(%esp),%esi
   22f57:	8b 07                	mov    (%edi),%eax
   22f59:	eb 17                	jmp    22f72 <fmt_fp+0x10d2>
   22f5b:	90                   	nop
   22f5c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   22f60:	81 ee 00 01 00 00    	sub    $0x100,%esi
   22f66:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   22f6c:	0f 86 b4 06 00 00    	jbe    23626 <fmt_fp+0x1786>
   22f72:	89 c2                	mov    %eax,%edx
   22f74:	83 e2 20             	and    $0x20,%edx
   22f77:	75 e7                	jne    22f60 <fmt_fp+0x10c0>
   22f79:	89 7c 24 08          	mov    %edi,0x8(%esp)
   22f7d:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   22f84:	00 
   22f85:	89 1c 24             	mov    %ebx,(%esp)
   22f88:	e8 fc ff ff ff       	call   22f89 <fmt_fp+0x10e9>
   22f8d:	8b 07                	mov    (%edi),%eax
   22f8f:	89 c2                	mov    %eax,%edx
   22f91:	83 e2 20             	and    $0x20,%edx
   22f94:	eb ca                	jmp    22f60 <fmt_fp+0x10c0>
   22f96:	8b 54 24 34          	mov    0x34(%esp),%edx
   22f9a:	89 44 24 08          	mov    %eax,0x8(%esp)
   22f9e:	83 fa 09             	cmp    $0x9,%edx
   22fa1:	89 d0                	mov    %edx,%eax
   22fa3:	7e 05                	jle    22faa <fmt_fp+0x110a>
   22fa5:	b8 09 00 00 00       	mov    $0x9,%eax
   22faa:	89 44 24 04          	mov    %eax,0x4(%esp)
   22fae:	89 0c 24             	mov    %ecx,(%esp)
   22fb1:	e8 fc ff ff ff       	call   22fb2 <fmt_fp+0x1112>
   22fb6:	e9 34 ff ff ff       	jmp    22eef <fmt_fp+0x104f>
   22fbb:	8b 44 24 20          	mov    0x20(%esp),%eax
   22fbf:	89 6c 24 08          	mov    %ebp,0x8(%esp)
   22fc3:	89 1c 24             	mov    %ebx,(%esp)
   22fc6:	29 d8                	sub    %ebx,%eax
   22fc8:	89 44 24 04          	mov    %eax,0x4(%esp)
   22fcc:	e8 fc ff ff ff       	call   22fcd <fmt_fp+0x112d>
   22fd1:	e9 6d fe ff ff       	jmp    22e43 <fmt_fp+0xfa3>
   22fd6:	8b 44 24 34          	mov    0x34(%esp),%eax
   22fda:	85 c0                	test   %eax,%eax
   22fdc:	75 08                	jne    22fe6 <fmt_fp+0x1146>
   22fde:	c7 44 24 34 01 00 00 	movl   $0x1,0x34(%esp)
   22fe5:	00 
   22fe6:	39 6c 24 34          	cmp    %ebp,0x34(%esp)
   22fea:	7e 05                	jle    22ff1 <fmt_fp+0x1151>
   22fec:	83 fd fc             	cmp    $0xfffffffc,%ebp
   22fef:	7d 2e                	jge    2301f <fmt_fp+0x117f>
   22ff1:	83 ac 24 80 1e 00 00 	subl   $0x2,0x1e80(%esp)
   22ff8:	02 
   22ff9:	83 6c 24 34 01       	subl   $0x1,0x34(%esp)
   22ffe:	f6 84 24 7c 1e 00 00 	testb  $0x8,0x1e7c(%esp)
   23005:	08 
   23006:	0f 84 1e 04 00 00    	je     2342a <fmt_fp+0x158a>
   2300c:	8b 84 24 80 1e 00 00 	mov    0x1e80(%esp),%eax
   23013:	83 c8 20             	or     $0x20,%eax
   23016:	89 44 24 44          	mov    %eax,0x44(%esp)
   2301a:	e9 8e f5 ff ff       	jmp    225ad <fmt_fp+0x70d>
   2301f:	89 e8                	mov    %ebp,%eax
   23021:	f7 d0                	not    %eax
   23023:	83 ac 24 80 1e 00 00 	subl   $0x1,0x1e80(%esp)
   2302a:	01 
   2302b:	01 44 24 34          	add    %eax,0x34(%esp)
   2302f:	eb cd                	jmp    22ffe <fmt_fp+0x115e>
   23031:	85 ed                	test   %ebp,%ebp
   23033:	0f 8e 96 f6 ff ff    	jle    226cf <fmt_fp+0x82f>
   23039:	01 6c 24 30          	add    %ebp,0x30(%esp)
   2303d:	e9 8d f6 ff ff       	jmp    226cf <fmt_fp+0x82f>
   23042:	c7 44 24 34 06 00 00 	movl   $0x6,0x34(%esp)
   23049:	00 
   2304a:	e9 27 ef ff ff       	jmp    21f76 <fmt_fp+0xd6>
   2304f:	d9 05 68 45 00 00    	flds   0x4568
   23055:	d9 05 6c 45 00 00    	flds   0x456c
   2305b:	e9 d2 f4 ff ff       	jmp    22532 <fmt_fp+0x692>
   23060:	db 2d 90 45 00 00    	fldt   0x4590
   23066:	e9 ab f4 ff ff       	jmp    22516 <fmt_fp+0x676>
   2306b:	8b 7c 24 34          	mov    0x34(%esp),%edi
   2306f:	81 ff 00 01 00 00    	cmp    $0x100,%edi
   23075:	89 fe                	mov    %edi,%esi
   23077:	89 f8                	mov    %edi,%eax
   23079:	0f 87 31 04 00 00    	ja     234b0 <fmt_fp+0x1610>
   2307f:	8d 9c 24 a4 00 00 00 	lea    0xa4(%esp),%ebx
   23086:	89 44 24 08          	mov    %eax,0x8(%esp)
   2308a:	c7 44 24 04 30 00 00 	movl   $0x30,0x4(%esp)
   23091:	00 
   23092:	89 1c 24             	mov    %ebx,(%esp)
   23095:	e8 fc ff ff ff       	call   23096 <fmt_fp+0x11f6>
   2309a:	8b 44 24 38          	mov    0x38(%esp),%eax
   2309e:	81 7c 24 34 ff 00 00 	cmpl   $0xff,0x34(%esp)
   230a5:	00 
   230a6:	0f 86 73 07 00 00    	jbe    2381f <fmt_fp+0x197f>
   230ac:	8b 10                	mov    (%eax),%edx
   230ae:	89 c7                	mov    %eax,%edi
   230b0:	8b 74 24 34          	mov    0x34(%esp),%esi
   230b4:	eb 10                	jmp    230c6 <fmt_fp+0x1226>
   230b6:	66 90                	xchg   %ax,%ax
   230b8:	81 ee 00 01 00 00    	sub    $0x100,%esi
   230be:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   230c4:	76 24                	jbe    230ea <fmt_fp+0x124a>
   230c6:	89 d0                	mov    %edx,%eax
   230c8:	83 e0 20             	and    $0x20,%eax
   230cb:	75 eb                	jne    230b8 <fmt_fp+0x1218>
   230cd:	89 7c 24 08          	mov    %edi,0x8(%esp)
   230d1:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   230d8:	00 
   230d9:	89 1c 24             	mov    %ebx,(%esp)
   230dc:	e8 fc ff ff ff       	call   230dd <fmt_fp+0x123d>
   230e1:	8b 17                	mov    (%edi),%edx
   230e3:	89 d0                	mov    %edx,%eax
   230e5:	83 e0 20             	and    $0x20,%eax
   230e8:	eb ce                	jmp    230b8 <fmt_fp+0x1218>
   230ea:	0f b6 74 24 34       	movzbl 0x34(%esp),%esi
   230ef:	85 c0                	test   %eax,%eax
   230f1:	0f 85 4c f7 ff ff    	jne    22843 <fmt_fp+0x9a3>
   230f7:	8b 7c 24 38          	mov    0x38(%esp),%edi
   230fb:	89 74 24 04          	mov    %esi,0x4(%esp)
   230ff:	89 1c 24             	mov    %ebx,(%esp)
   23102:	89 7c 24 08          	mov    %edi,0x8(%esp)
   23106:	e8 fc ff ff ff       	call   23107 <fmt_fp+0x1267>
   2310b:	8b 07                	mov    (%edi),%eax
   2310d:	83 e0 20             	and    $0x20,%eax
   23110:	e9 09 f7 ff ff       	jmp    2281e <fmt_fp+0x97e>
   23115:	d9 7c 24 6e          	fnstcw 0x6e(%esp)
   23119:	89 f8                	mov    %edi,%eax
   2311b:	d9 05 78 45 00 00    	flds   0x4578
   23121:	d9 c9                	fxch   %st(1)
   23123:	0f b7 4c 24 6e       	movzwl 0x6e(%esp),%ecx
   23128:	b5 0c                	mov    $0xc,%ch
   2312a:	66 89 4c 24 6c       	mov    %cx,0x6c(%esp)
   2312f:	90                   	nop
   23130:	d9 c0                	fld    %st(0)
   23132:	d9 6c 24 6c          	fldcw  0x6c(%esp)
   23136:	db 5c 24 68          	fistpl 0x68(%esp)
   2313a:	d9 6c 24 6e          	fldcw  0x6e(%esp)
   2313e:	89 d3                	mov    %edx,%ebx
   23140:	8b 4c 24 68          	mov    0x68(%esp),%ecx
   23144:	0a 99 a8 3a 00 00    	or     0x3aa8(%ecx),%bl
   2314a:	39 c7                	cmp    %eax,%edi
   2314c:	88 18                	mov    %bl,(%eax)
   2314e:	8d 58 01             	lea    0x1(%eax),%ebx
   23151:	89 4c 24 68          	mov    %ecx,0x68(%esp)
   23155:	db 44 24 68          	fildl  0x68(%esp)
   23159:	de e9                	fsubrp %st,%st(1)
   2315b:	d8 c9                	fmul   %st(1),%st
   2315d:	74 1b                	je     2317a <fmt_fp+0x12da>
   2315f:	d9 ee                	fldz   
   23161:	d9 c9                	fxch   %st(1)
   23163:	dd e1                	fucom  %st(1)
   23165:	df e0                	fnstsw %ax
   23167:	dd d9                	fstp   %st(1)
   23169:	9e                   	sahf   
   2316a:	7b 04                	jnp    23170 <fmt_fp+0x12d0>
   2316c:	89 d8                	mov    %ebx,%eax
   2316e:	eb c0                	jmp    23130 <fmt_fp+0x1290>
   23170:	0f 84 4e fa ff ff    	je     22bc4 <fmt_fp+0xd24>
   23176:	89 d8                	mov    %ebx,%eax
   23178:	eb b6                	jmp    23130 <fmt_fp+0x1290>
   2317a:	8d 58 02             	lea    0x2(%eax),%ebx
   2317d:	c6 40 01 2e          	movb   $0x2e,0x1(%eax)
   23181:	eb dc                	jmp    2315f <fmt_fp+0x12bf>
   23183:	8b 44 24 38          	mov    0x38(%esp),%eax
   23187:	8b 10                	mov    (%eax),%edx
   23189:	83 e2 20             	and    $0x20,%edx
   2318c:	85 d2                	test   %edx,%edx
   2318e:	75 1c                	jne    231ac <fmt_fp+0x130c>
   23190:	8b 44 24 38          	mov    0x38(%esp),%eax
   23194:	89 44 24 08          	mov    %eax,0x8(%esp)
   23198:	8b 44 24 40          	mov    0x40(%esp),%eax
   2319c:	89 44 24 04          	mov    %eax,0x4(%esp)
   231a0:	8b 44 24 10          	mov    0x10(%esp),%eax
   231a4:	89 04 24             	mov    %eax,(%esp)
   231a7:	e8 fc ff ff ff       	call   231a8 <fmt_fp+0x1308>
   231ac:	8b 84 24 7c 1e 00 00 	mov    0x1e7c(%esp),%eax
   231b3:	80 f4 20             	xor    $0x20,%ah
   231b6:	a9 00 20 01 00       	test   $0x12000,%eax
   231bb:	75 0e                	jne    231cb <fmt_fp+0x132b>
   231bd:	8b 44 24 20          	mov    0x20(%esp),%eax
   231c1:	39 44 24 48          	cmp    %eax,0x48(%esp)
   231c5:	0f 8f 87 03 00 00    	jg     23552 <fmt_fp+0x16b2>
   231cb:	8b 44 24 20          	mov    0x20(%esp),%eax
   231cf:	3b 44 24 48          	cmp    0x48(%esp),%eax
   231d3:	0f 8d 42 f0 ff ff    	jge    2221b <fmt_fp+0x37b>
   231d9:	e9 39 f0 ff ff       	jmp    22217 <fmt_fp+0x377>
   231de:	0f b6 f3             	movzbl %bl,%esi
   231e1:	85 d2                	test   %edx,%edx
   231e3:	75 c7                	jne    231ac <fmt_fp+0x130c>
   231e5:	8b 7c 24 38          	mov    0x38(%esp),%edi
   231e9:	89 74 24 04          	mov    %esi,0x4(%esp)
   231ed:	89 2c 24             	mov    %ebp,(%esp)
   231f0:	89 7c 24 08          	mov    %edi,0x8(%esp)
   231f4:	e8 fc ff ff ff       	call   231f5 <fmt_fp+0x1355>
   231f9:	8b 17                	mov    (%edi),%edx
   231fb:	83 e2 20             	and    $0x20,%edx
   231fe:	eb 8c                	jmp    2318c <fmt_fp+0x12ec>
   23200:	0f b6 74 24 20       	movzbl 0x20(%esp),%esi
   23205:	8b 5c 24 10          	mov    0x10(%esp),%ebx
   23209:	89 74 24 20          	mov    %esi,0x20(%esp)
   2320d:	85 c0                	test   %eax,%eax
   2320f:	0f 85 e3 ef ff ff    	jne    221f8 <fmt_fp+0x358>
   23215:	8b 74 24 38          	mov    0x38(%esp),%esi
   23219:	8b 44 24 20          	mov    0x20(%esp),%eax
   2321d:	89 2c 24             	mov    %ebp,(%esp)
   23220:	89 74 24 08          	mov    %esi,0x8(%esp)
   23224:	89 44 24 04          	mov    %eax,0x4(%esp)
   23228:	e8 fc ff ff ff       	call   23229 <fmt_fp+0x1389>
   2322d:	8b 06                	mov    (%esi),%eax
   2322f:	83 e0 20             	and    $0x20,%eax
   23232:	e9 b9 ef ff ff       	jmp    221f0 <fmt_fp+0x350>
   23237:	8b 74 24 48          	mov    0x48(%esp),%esi
   2323b:	29 c6                	sub    %eax,%esi
   2323d:	81 fe 00 01 00 00    	cmp    $0x100,%esi
   23243:	89 f0                	mov    %esi,%eax
   23245:	0f 87 b2 02 00 00    	ja     234fd <fmt_fp+0x165d>
   2324b:	8d 9c 24 a4 00 00 00 	lea    0xa4(%esp),%ebx
   23252:	89 44 24 08          	mov    %eax,0x8(%esp)
   23256:	c7 44 24 04 30 00 00 	movl   $0x30,0x4(%esp)
   2325d:	00 
   2325e:	89 1c 24             	mov    %ebx,(%esp)
   23261:	e8 fc ff ff ff       	call   23262 <fmt_fp+0x13c2>
   23266:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   2326c:	0f 86 d3 05 00 00    	jbe    23845 <fmt_fp+0x19a5>
   23272:	8b 6c 24 38          	mov    0x38(%esp),%ebp
   23276:	89 f7                	mov    %esi,%edi
   23278:	8b 45 00             	mov    0x0(%ebp),%eax
   2327b:	eb 15                	jmp    23292 <fmt_fp+0x13f2>
   2327d:	8d 76 00             	lea    0x0(%esi),%esi
   23280:	81 ef 00 01 00 00    	sub    $0x100,%edi
   23286:	81 ff ff 00 00 00    	cmp    $0xff,%edi
   2328c:	0f 86 72 01 00 00    	jbe    23404 <fmt_fp+0x1564>
   23292:	89 c2                	mov    %eax,%edx
   23294:	83 e2 20             	and    $0x20,%edx
   23297:	75 e7                	jne    23280 <fmt_fp+0x13e0>
   23299:	89 6c 24 08          	mov    %ebp,0x8(%esp)
   2329d:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   232a4:	00 
   232a5:	89 1c 24             	mov    %ebx,(%esp)
   232a8:	e8 fc ff ff ff       	call   232a9 <fmt_fp+0x1409>
   232ad:	8b 45 00             	mov    0x0(%ebp),%eax
   232b0:	89 c2                	mov    %eax,%edx
   232b2:	83 e2 20             	and    $0x20,%edx
   232b5:	eb c9                	jmp    23280 <fmt_fp+0x13e0>
   232b7:	8b 74 24 48          	mov    0x48(%esp),%esi
   232bb:	29 c6                	sub    %eax,%esi
   232bd:	81 fe 00 01 00 00    	cmp    $0x100,%esi
   232c3:	89 f0                	mov    %esi,%eax
   232c5:	0f 87 28 02 00 00    	ja     234f3 <fmt_fp+0x1653>
   232cb:	8d 9c 24 a4 00 00 00 	lea    0xa4(%esp),%ebx
   232d2:	89 44 24 08          	mov    %eax,0x8(%esp)
   232d6:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   232dd:	00 
   232de:	89 1c 24             	mov    %ebx,(%esp)
   232e1:	e8 fc ff ff ff       	call   232e2 <fmt_fp+0x1442>
   232e6:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   232ec:	0f 86 45 05 00 00    	jbe    23837 <fmt_fp+0x1997>
   232f2:	8b 6c 24 38          	mov    0x38(%esp),%ebp
   232f6:	89 f7                	mov    %esi,%edi
   232f8:	8b 45 00             	mov    0x0(%ebp),%eax
   232fb:	eb 15                	jmp    23312 <fmt_fp+0x1472>
   232fd:	8d 76 00             	lea    0x0(%esi),%esi
   23300:	81 ef 00 01 00 00    	sub    $0x100,%edi
   23306:	81 ff ff 00 00 00    	cmp    $0xff,%edi
   2330c:	0f 86 cc 00 00 00    	jbe    233de <fmt_fp+0x153e>
   23312:	89 c2                	mov    %eax,%edx
   23314:	83 e2 20             	and    $0x20,%edx
   23317:	75 e7                	jne    23300 <fmt_fp+0x1460>
   23319:	89 6c 24 08          	mov    %ebp,0x8(%esp)
   2331d:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   23324:	00 
   23325:	89 1c 24             	mov    %ebx,(%esp)
   23328:	e8 fc ff ff ff       	call   23329 <fmt_fp+0x1489>
   2332d:	8b 45 00             	mov    0x0(%ebp),%eax
   23330:	89 c2                	mov    %eax,%edx
   23332:	83 e2 20             	and    $0x20,%edx
   23335:	eb c9                	jmp    23300 <fmt_fp+0x1460>
   23337:	8b 74 24 48          	mov    0x48(%esp),%esi
   2333b:	29 c6                	sub    %eax,%esi
   2333d:	81 fe 00 01 00 00    	cmp    $0x100,%esi
   23343:	89 f0                	mov    %esi,%eax
   23345:	0f 87 9e 01 00 00    	ja     234e9 <fmt_fp+0x1649>
   2334b:	8d 9c 24 a4 00 00 00 	lea    0xa4(%esp),%ebx
   23352:	89 44 24 08          	mov    %eax,0x8(%esp)
   23356:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   2335d:	00 
   2335e:	89 1c 24             	mov    %ebx,(%esp)
   23361:	e8 fc ff ff ff       	call   23362 <fmt_fp+0x14c2>
   23366:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   2336c:	8b 44 24 38          	mov    0x38(%esp),%eax
   23370:	0f 86 dd 04 00 00    	jbe    23853 <fmt_fp+0x19b3>
   23376:	8b 10                	mov    (%eax),%edx
   23378:	89 f7                	mov    %esi,%edi
   2337a:	89 c5                	mov    %eax,%ebp
   2337c:	eb 10                	jmp    2338e <fmt_fp+0x14ee>
   2337e:	66 90                	xchg   %ax,%ax
   23380:	81 ef 00 01 00 00    	sub    $0x100,%edi
   23386:	81 ff ff 00 00 00    	cmp    $0xff,%edi
   2338c:	76 25                	jbe    233b3 <fmt_fp+0x1513>
   2338e:	89 d0                	mov    %edx,%eax
   23390:	83 e0 20             	and    $0x20,%eax
   23393:	75 eb                	jne    23380 <fmt_fp+0x14e0>
   23395:	89 6c 24 08          	mov    %ebp,0x8(%esp)
   23399:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   233a0:	00 
   233a1:	89 1c 24             	mov    %ebx,(%esp)
   233a4:	e8 fc ff ff ff       	call   233a5 <fmt_fp+0x1505>
   233a9:	8b 55 00             	mov    0x0(%ebp),%edx
   233ac:	89 d0                	mov    %edx,%eax
   233ae:	83 e0 20             	and    $0x20,%eax
   233b1:	eb cd                	jmp    23380 <fmt_fp+0x14e0>
   233b3:	89 f2                	mov    %esi,%edx
   233b5:	0f b6 f2             	movzbl %dl,%esi
   233b8:	85 c0                	test   %eax,%eax
   233ba:	0f 85 43 f3 ff ff    	jne    22703 <fmt_fp+0x863>
   233c0:	8b 7c 24 38          	mov    0x38(%esp),%edi
   233c4:	89 74 24 04          	mov    %esi,0x4(%esp)
   233c8:	89 1c 24             	mov    %ebx,(%esp)
   233cb:	89 7c 24 08          	mov    %edi,0x8(%esp)
   233cf:	e8 fc ff ff ff       	call   233d0 <fmt_fp+0x1530>
   233d4:	8b 07                	mov    (%edi),%eax
   233d6:	83 e0 20             	and    $0x20,%eax
   233d9:	e9 1d f3 ff ff       	jmp    226fb <fmt_fp+0x85b>
   233de:	89 f0                	mov    %esi,%eax
   233e0:	0f b6 f0             	movzbl %al,%esi
   233e3:	85 d2                	test   %edx,%edx
   233e5:	0f 85 77 f4 ff ff    	jne    22862 <fmt_fp+0x9c2>
   233eb:	8b 44 24 38          	mov    0x38(%esp),%eax
   233ef:	89 74 24 04          	mov    %esi,0x4(%esp)
   233f3:	89 1c 24             	mov    %ebx,(%esp)
   233f6:	89 44 24 08          	mov    %eax,0x8(%esp)
   233fa:	e8 fc ff ff ff       	call   233fb <fmt_fp+0x155b>
   233ff:	e9 5e f4 ff ff       	jmp    22862 <fmt_fp+0x9c2>
   23404:	89 f0                	mov    %esi,%eax
   23406:	0f b6 f0             	movzbl %al,%esi
   23409:	85 d2                	test   %edx,%edx
   2340b:	0f 85 13 f3 ff ff    	jne    22724 <fmt_fp+0x884>
   23411:	8b 44 24 38          	mov    0x38(%esp),%eax
   23415:	89 74 24 04          	mov    %esi,0x4(%esp)
   23419:	89 1c 24             	mov    %ebx,(%esp)
   2341c:	89 44 24 08          	mov    %eax,0x8(%esp)
   23420:	e8 fc ff ff ff       	call   23421 <fmt_fp+0x1581>
   23425:	e9 fa f2 ff ff       	jmp    22724 <fmt_fp+0x884>
   2342a:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   2342e:	bb 09 00 00 00       	mov    $0x9,%ebx
   23433:	39 44 24 10          	cmp    %eax,0x10(%esp)
   23437:	73 39                	jae    23472 <fmt_fp+0x15d2>
   23439:	8b 70 fc             	mov    -0x4(%eax),%esi
   2343c:	85 f6                	test   %esi,%esi
   2343e:	74 32                	je     23472 <fmt_fp+0x15d2>
   23440:	89 f0                	mov    %esi,%eax
   23442:	ba cd cc cc cc       	mov    $0xcccccccd,%edx
   23447:	f7 e2                	mul    %edx
   23449:	c1 ea 03             	shr    $0x3,%edx
   2344c:	8d 04 92             	lea    (%edx,%edx,4),%eax
   2344f:	01 c0                	add    %eax,%eax
   23451:	39 c6                	cmp    %eax,%esi
   23453:	0f 85 2a 04 00 00    	jne    23883 <fmt_fp+0x19e3>
   23459:	30 db                	xor    %bl,%bl
   2345b:	b9 0a 00 00 00       	mov    $0xa,%ecx
   23460:	8d 0c 89             	lea    (%ecx,%ecx,4),%ecx
   23463:	31 d2                	xor    %edx,%edx
   23465:	01 c9                	add    %ecx,%ecx
   23467:	89 f0                	mov    %esi,%eax
   23469:	f7 f1                	div    %ecx
   2346b:	83 c3 01             	add    $0x1,%ebx
   2346e:	85 d2                	test   %edx,%edx
   23470:	74 ee                	je     23460 <fmt_fp+0x15c0>
   23472:	8b 84 24 80 1e 00 00 	mov    0x1e80(%esp),%eax
   23479:	83 c8 20             	or     $0x20,%eax
   2347c:	83 f8 66             	cmp    $0x66,%eax
   2347f:	89 44 24 44          	mov    %eax,0x44(%esp)
   23483:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   23487:	74 7e                	je     23507 <fmt_fp+0x1667>
   23489:	2b 44 24 3c          	sub    0x3c(%esp),%eax
   2348d:	c1 f8 02             	sar    $0x2,%eax
   23490:	8d 44 c0 f7          	lea    -0x9(%eax,%eax,8),%eax
   23494:	01 e8                	add    %ebp,%eax
   23496:	29 d8                	sub    %ebx,%eax
   23498:	99                   	cltd   
   23499:	f7 d2                	not    %edx
   2349b:	21 d0                	and    %edx,%eax
   2349d:	39 44 24 34          	cmp    %eax,0x34(%esp)
   234a1:	0f 8e 06 f1 ff ff    	jle    225ad <fmt_fp+0x70d>
   234a7:	89 44 24 34          	mov    %eax,0x34(%esp)
   234ab:	e9 fd f0 ff ff       	jmp    225ad <fmt_fp+0x70d>
   234b0:	b8 00 01 00 00       	mov    $0x100,%eax
   234b5:	e9 c5 fb ff ff       	jmp    2307f <fmt_fp+0x11df>
   234ba:	b8 00 01 00 00       	mov    $0x100,%eax
   234bf:	e9 c0 f7 ff ff       	jmp    22c84 <fmt_fp+0xde4>
   234c4:	8b 74 24 34          	mov    0x34(%esp),%esi
   234c8:	89 f8                	mov    %edi,%eax
   234ca:	2b 44 24 10          	sub    0x10(%esp),%eax
   234ce:	89 44 24 40          	mov    %eax,0x40(%esp)
   234d2:	8d 44 30 02          	lea    0x2(%eax,%esi,1),%eax
   234d6:	89 44 24 2c          	mov    %eax,0x2c(%esp)
   234da:	e9 18 f7 ff ff       	jmp    22bf7 <fmt_fp+0xd57>
   234df:	b8 00 01 00 00       	mov    $0x100,%eax
   234e4:	e9 24 ee ff ff       	jmp    2230d <fmt_fp+0x46d>
   234e9:	b8 00 01 00 00       	mov    $0x100,%eax
   234ee:	e9 58 fe ff ff       	jmp    2334b <fmt_fp+0x14ab>
   234f3:	b8 00 01 00 00       	mov    $0x100,%eax
   234f8:	e9 ce fd ff ff       	jmp    232cb <fmt_fp+0x142b>
   234fd:	b8 00 01 00 00       	mov    $0x100,%eax
   23502:	e9 44 fd ff ff       	jmp    2324b <fmt_fp+0x13ab>
   23507:	2b 44 24 3c          	sub    0x3c(%esp),%eax
   2350b:	c1 f8 02             	sar    $0x2,%eax
   2350e:	8d 44 c0 f7          	lea    -0x9(%eax,%eax,8),%eax
   23512:	eb 82                	jmp    23496 <fmt_fp+0x15f6>
   23514:	8b 44 24 38          	mov    0x38(%esp),%eax
   23518:	89 44 24 08          	mov    %eax,0x8(%esp)
   2351c:	8b 44 24 3c          	mov    0x3c(%esp),%eax
   23520:	89 44 24 04          	mov    %eax,0x4(%esp)
   23524:	8b 44 24 54          	mov    0x54(%esp),%eax
   23528:	89 04 24             	mov    %eax,(%esp)
   2352b:	e8 fc ff ff ff       	call   2352c <fmt_fp+0x168c>
   23530:	e9 f6 f6 ff ff       	jmp    22c2b <fmt_fp+0xd8b>
   23535:	8b 44 24 38          	mov    0x38(%esp),%eax
   23539:	89 3c 24             	mov    %edi,(%esp)
   2353c:	89 44 24 08          	mov    %eax,0x8(%esp)
   23540:	8b 44 24 30          	mov    0x30(%esp),%eax
   23544:	89 44 24 04          	mov    %eax,0x4(%esp)
   23548:	e8 fc ff ff ff       	call   23549 <fmt_fp+0x16a9>
   2354d:	e9 0b f7 ff ff       	jmp    22c5d <fmt_fp+0xdbd>
   23552:	8b 74 24 48          	mov    0x48(%esp),%esi
   23556:	29 c6                	sub    %eax,%esi
   23558:	81 fe 00 01 00 00    	cmp    $0x100,%esi
   2355e:	89 f0                	mov    %esi,%eax
   23560:	76 05                	jbe    23567 <fmt_fp+0x16c7>
   23562:	b8 00 01 00 00       	mov    $0x100,%eax
   23567:	8d ac 24 a4 01 00 00 	lea    0x1a4(%esp),%ebp
   2356e:	89 44 24 08          	mov    %eax,0x8(%esp)
   23572:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   23579:	00 
   2357a:	89 2c 24             	mov    %ebp,(%esp)
   2357d:	e8 fc ff ff ff       	call   2357e <fmt_fp+0x16de>
   23582:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   23588:	0f 86 e7 02 00 00    	jbe    23875 <fmt_fp+0x19d5>
   2358e:	8b 7c 24 38          	mov    0x38(%esp),%edi
   23592:	89 f3                	mov    %esi,%ebx
   23594:	8b 07                	mov    (%edi),%eax
   23596:	eb 0e                	jmp    235a6 <fmt_fp+0x1706>
   23598:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   2359e:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   235a4:	76 35                	jbe    235db <fmt_fp+0x173b>
   235a6:	89 c2                	mov    %eax,%edx
   235a8:	83 e2 20             	and    $0x20,%edx
   235ab:	75 eb                	jne    23598 <fmt_fp+0x16f8>
   235ad:	89 7c 24 08          	mov    %edi,0x8(%esp)
   235b1:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   235b8:	00 
   235b9:	89 2c 24             	mov    %ebp,(%esp)
   235bc:	e8 fc ff ff ff       	call   235bd <fmt_fp+0x171d>
   235c1:	8b 07                	mov    (%edi),%eax
   235c3:	89 c2                	mov    %eax,%edx
   235c5:	83 e2 20             	and    $0x20,%edx
   235c8:	eb ce                	jmp    23598 <fmt_fp+0x16f8>
   235ca:	8b 44 24 3c          	mov    0x3c(%esp),%eax
   235ce:	8b 7c 24 30          	mov    0x30(%esp),%edi
   235d2:	89 44 24 10          	mov    %eax,0x10(%esp)
   235d6:	e9 ad ed ff ff       	jmp    22388 <fmt_fp+0x4e8>
   235db:	89 f0                	mov    %esi,%eax
   235dd:	0f b6 f0             	movzbl %al,%esi
   235e0:	85 d2                	test   %edx,%edx
   235e2:	0f 85 e3 fb ff ff    	jne    231cb <fmt_fp+0x132b>
   235e8:	8b 44 24 38          	mov    0x38(%esp),%eax
   235ec:	89 74 24 04          	mov    %esi,0x4(%esp)
   235f0:	89 2c 24             	mov    %ebp,(%esp)
   235f3:	89 44 24 08          	mov    %eax,0x8(%esp)
   235f7:	e8 fc ff ff ff       	call   235f8 <fmt_fp+0x1758>
   235fc:	e9 ca fb ff ff       	jmp    231cb <fmt_fp+0x132b>
   23601:	dd d8                	fstp   %st(0)
   23603:	d9 c9                	fxch   %st(1)
   23605:	d9 e0                	fchs   
   23607:	d9 c9                	fxch   %st(1)
   23609:	e9 3f ef ff ff       	jmp    2254d <fmt_fp+0x6ad>
   2360e:	8d 43 04             	lea    0x4(%ebx),%eax
   23611:	39 44 24 2c          	cmp    %eax,0x2c(%esp)
   23615:	0f 85 0b ef ff ff    	jne    22526 <fmt_fp+0x686>
   2361b:	d9 e8                	fld1   
   2361d:	d9 e0                	fchs   
   2361f:	d9 e8                	fld1   
   23621:	e9 0c ef ff ff       	jmp    22532 <fmt_fp+0x692>
   23626:	0f b6 74 24 34       	movzbl 0x34(%esp),%esi
   2362b:	85 d2                	test   %edx,%edx
   2362d:	0f 85 10 f2 ff ff    	jne    22843 <fmt_fp+0x9a3>
   23633:	8b 44 24 38          	mov    0x38(%esp),%eax
   23637:	89 74 24 04          	mov    %esi,0x4(%esp)
   2363b:	89 1c 24             	mov    %ebx,(%esp)
   2363e:	89 44 24 08          	mov    %eax,0x8(%esp)
   23642:	e8 fc ff ff ff       	call   23643 <fmt_fp+0x17a3>
   23647:	e9 f7 f1 ff ff       	jmp    22843 <fmt_fp+0x9a3>
   2364c:	89 44 24 08          	mov    %eax,0x8(%esp)
   23650:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
   23657:	00 
   23658:	c7 04 24 4d 45 00 00 	movl   $0x454d,(%esp)
   2365f:	e8 fc ff ff ff       	call   23660 <fmt_fp+0x17c0>
   23664:	e9 17 f8 ff ff       	jmp    22e80 <fmt_fp+0xfe0>
   23669:	d9 c9                	fxch   %st(1)
   2366b:	d9 e0                	fchs   
   2366d:	d8 e1                	fsub   %st(1),%st
   2366f:	de c1                	faddp  %st,%st(1)
   23671:	d9 e0                	fchs   
   23673:	e9 e5 f3 ff ff       	jmp    22a5d <fmt_fp+0xbbd>
   23678:	c6 84 24 87 00 00 00 	movb   $0x30,0x87(%esp)
   2367f:	30 
   23680:	8d 9c 24 87 00 00 00 	lea    0x87(%esp),%ebx
   23687:	e9 90 f4 ff ff       	jmp    22b1c <fmt_fp+0xc7c>
   2368c:	8b 4c 24 48          	mov    0x48(%esp),%ecx
   23690:	29 c1                	sub    %eax,%ecx
   23692:	81 f9 00 01 00 00    	cmp    $0x100,%ecx
   23698:	89 c8                	mov    %ecx,%eax
   2369a:	76 05                	jbe    236a1 <fmt_fp+0x1801>
   2369c:	b8 00 01 00 00       	mov    $0x100,%eax
   236a1:	8d ac 24 a4 01 00 00 	lea    0x1a4(%esp),%ebp
   236a8:	89 44 24 08          	mov    %eax,0x8(%esp)
   236ac:	c7 44 24 04 30 00 00 	movl   $0x30,0x4(%esp)
   236b3:	00 
   236b4:	89 2c 24             	mov    %ebp,(%esp)
   236b7:	89 4c 24 34          	mov    %ecx,0x34(%esp)
   236bb:	e8 fc ff ff ff       	call   236bc <fmt_fp+0x181c>
   236c0:	8b 4c 24 34          	mov    0x34(%esp),%ecx
   236c4:	8b 44 24 38          	mov    0x38(%esp),%eax
   236c8:	81 f9 ff 00 00 00    	cmp    $0xff,%ecx
   236ce:	0f 86 c0 01 00 00    	jbe    23894 <fmt_fp+0x19f4>
   236d4:	8b 10                	mov    (%eax),%edx
   236d6:	89 ce                	mov    %ecx,%esi
   236d8:	eb 12                	jmp    236ec <fmt_fp+0x184c>
   236da:	81 ee 00 01 00 00    	sub    $0x100,%esi
   236e0:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   236e6:	0f 86 ed 00 00 00    	jbe    237d9 <fmt_fp+0x1939>
   236ec:	89 d0                	mov    %edx,%eax
   236ee:	83 e0 20             	and    $0x20,%eax
   236f1:	75 e7                	jne    236da <fmt_fp+0x183a>
   236f3:	8b 44 24 38          	mov    0x38(%esp),%eax
   236f7:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   236fe:	00 
   236ff:	89 2c 24             	mov    %ebp,(%esp)
   23702:	89 4c 24 34          	mov    %ecx,0x34(%esp)
   23706:	89 44 24 08          	mov    %eax,0x8(%esp)
   2370a:	e8 fc ff ff ff       	call   2370b <fmt_fp+0x186b>
   2370f:	8b 44 24 38          	mov    0x38(%esp),%eax
   23713:	8b 4c 24 34          	mov    0x34(%esp),%ecx
   23717:	8b 10                	mov    (%eax),%edx
   23719:	89 d0                	mov    %edx,%eax
   2371b:	83 e0 20             	and    $0x20,%eax
   2371e:	eb ba                	jmp    236da <fmt_fp+0x183a>
   23720:	8b 4c 24 48          	mov    0x48(%esp),%ecx
   23724:	29 c1                	sub    %eax,%ecx
   23726:	81 f9 00 01 00 00    	cmp    $0x100,%ecx
   2372c:	89 c8                	mov    %ecx,%eax
   2372e:	76 05                	jbe    23735 <fmt_fp+0x1895>
   23730:	b8 00 01 00 00       	mov    $0x100,%eax
   23735:	8d ac 24 a4 01 00 00 	lea    0x1a4(%esp),%ebp
   2373c:	89 44 24 08          	mov    %eax,0x8(%esp)
   23740:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   23747:	00 
   23748:	89 2c 24             	mov    %ebp,(%esp)
   2374b:	89 4c 24 34          	mov    %ecx,0x34(%esp)
   2374f:	e8 fc ff ff ff       	call   23750 <fmt_fp+0x18b0>
   23754:	8b 4c 24 34          	mov    0x34(%esp),%ecx
   23758:	8b 44 24 38          	mov    0x38(%esp),%eax
   2375c:	81 f9 ff 00 00 00    	cmp    $0xff,%ecx
   23762:	0f 86 22 01 00 00    	jbe    2388a <fmt_fp+0x19ea>
   23768:	8b 10                	mov    (%eax),%edx
   2376a:	89 ce                	mov    %ecx,%esi
   2376c:	eb 0e                	jmp    2377c <fmt_fp+0x18dc>
   2376e:	81 ee 00 01 00 00    	sub    $0x100,%esi
   23774:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   2377a:	76 34                	jbe    237b0 <fmt_fp+0x1910>
   2377c:	89 d0                	mov    %edx,%eax
   2377e:	83 e0 20             	and    $0x20,%eax
   23781:	75 eb                	jne    2376e <fmt_fp+0x18ce>
   23783:	8b 44 24 38          	mov    0x38(%esp),%eax
   23787:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   2378e:	00 
   2378f:	89 2c 24             	mov    %ebp,(%esp)
   23792:	89 4c 24 34          	mov    %ecx,0x34(%esp)
   23796:	89 44 24 08          	mov    %eax,0x8(%esp)
   2379a:	e8 fc ff ff ff       	call   2379b <fmt_fp+0x18fb>
   2379f:	8b 44 24 38          	mov    0x38(%esp),%eax
   237a3:	8b 4c 24 34          	mov    0x34(%esp),%ecx
   237a7:	8b 10                	mov    (%eax),%edx
   237a9:	89 d0                	mov    %edx,%eax
   237ab:	83 e0 20             	and    $0x20,%eax
   237ae:	eb be                	jmp    2376e <fmt_fp+0x18ce>
   237b0:	0f b6 c9             	movzbl %cl,%ecx
   237b3:	85 c0                	test   %eax,%eax
   237b5:	0f 85 70 f4 ff ff    	jne    22c2b <fmt_fp+0xd8b>
   237bb:	8b 74 24 38          	mov    0x38(%esp),%esi
   237bf:	89 4c 24 04          	mov    %ecx,0x4(%esp)
   237c3:	89 2c 24             	mov    %ebp,(%esp)
   237c6:	89 74 24 08          	mov    %esi,0x8(%esp)
   237ca:	e8 fc ff ff ff       	call   237cb <fmt_fp+0x192b>
   237cf:	8b 06                	mov    (%esi),%eax
   237d1:	83 e0 20             	and    $0x20,%eax
   237d4:	e9 4a f4 ff ff       	jmp    22c23 <fmt_fp+0xd83>
   237d9:	0f b6 c9             	movzbl %cl,%ecx
   237dc:	85 c0                	test   %eax,%eax
   237de:	0f 85 79 f4 ff ff    	jne    22c5d <fmt_fp+0xdbd>
   237e4:	8b 74 24 38          	mov    0x38(%esp),%esi
   237e8:	89 4c 24 04          	mov    %ecx,0x4(%esp)
   237ec:	89 2c 24             	mov    %ebp,(%esp)
   237ef:	89 74 24 08          	mov    %esi,0x8(%esp)
   237f3:	e8 fc ff ff ff       	call   237f4 <fmt_fp+0x1954>
   237f8:	8b 06                	mov    (%esi),%eax
   237fa:	83 e0 20             	and    $0x20,%eax
   237fd:	e9 53 f4 ff ff       	jmp    22c55 <fmt_fp+0xdb5>
   23802:	be 0a 00 00 00       	mov    $0xa,%esi
   23807:	b9 0a 00 00 00       	mov    $0xa,%ecx
   2380c:	e9 d6 ec ff ff       	jmp    224e7 <fmt_fp+0x647>
   23811:	8b 44 24 38          	mov    0x38(%esp),%eax
   23815:	8b 10                	mov    (%eax),%edx
   23817:	83 e2 20             	and    $0x20,%edx
   2381a:	e9 b8 ea ff ff       	jmp    222d7 <fmt_fp+0x437>
   2381f:	8b 00                	mov    (%eax),%eax
   23821:	83 e0 20             	and    $0x20,%eax
   23824:	e9 c6 f8 ff ff       	jmp    230ef <fmt_fp+0x124f>
   23829:	8b 44 24 38          	mov    0x38(%esp),%eax
   2382d:	8b 10                	mov    (%eax),%edx
   2382f:	83 e2 20             	and    $0x20,%edx
   23832:	e9 aa f9 ff ff       	jmp    231e1 <fmt_fp+0x1341>
   23837:	8b 44 24 38          	mov    0x38(%esp),%eax
   2383b:	8b 10                	mov    (%eax),%edx
   2383d:	83 e2 20             	and    $0x20,%edx
   23840:	e9 9e fb ff ff       	jmp    233e3 <fmt_fp+0x1543>
   23845:	8b 44 24 38          	mov    0x38(%esp),%eax
   23849:	8b 10                	mov    (%eax),%edx
   2384b:	83 e2 20             	and    $0x20,%edx
   2384e:	e9 b6 fb ff ff       	jmp    23409 <fmt_fp+0x1569>
   23853:	8b 00                	mov    (%eax),%eax
   23855:	83 e0 20             	and    $0x20,%eax
   23858:	e9 5b fb ff ff       	jmp    233b8 <fmt_fp+0x1518>
   2385d:	8b 44 24 38          	mov    0x38(%esp),%eax
   23861:	8b 10                	mov    (%eax),%edx
   23863:	83 e2 20             	and    $0x20,%edx
   23866:	e9 c0 fd ff ff       	jmp    2362b <fmt_fp+0x178b>
   2386b:	8b 00                	mov    (%eax),%eax
   2386d:	83 e0 20             	and    $0x20,%eax
   23870:	e9 98 f9 ff ff       	jmp    2320d <fmt_fp+0x136d>
   23875:	8b 44 24 38          	mov    0x38(%esp),%eax
   23879:	8b 10                	mov    (%eax),%edx
   2387b:	83 e2 20             	and    $0x20,%edx
   2387e:	e9 5d fd ff ff       	jmp    235e0 <fmt_fp+0x1740>
   23883:	31 db                	xor    %ebx,%ebx
   23885:	e9 e8 fb ff ff       	jmp    23472 <fmt_fp+0x15d2>
   2388a:	8b 00                	mov    (%eax),%eax
   2388c:	83 e0 20             	and    $0x20,%eax
   2388f:	e9 1f ff ff ff       	jmp    237b3 <fmt_fp+0x1913>
   23894:	8b 00                	mov    (%eax),%eax
   23896:	83 e0 20             	and    $0x20,%eax
   23899:	e9 3e ff ff ff       	jmp    237dc <fmt_fp+0x193c>
   2389e:	3b 5c 24 20          	cmp    0x20(%esp),%ebx
   238a2:	0f 85 91 f5 ff ff    	jne    22e39 <fmt_fp+0xf99>
   238a8:	c6 84 24 90 00 00 00 	movb   $0x30,0x90(%esp)
   238af:	30 
   238b0:	8d 9c 24 90 00 00 00 	lea    0x90(%esp),%ebx
   238b7:	e9 7d f5 ff ff       	jmp    22e39 <fmt_fp+0xf99>
   238bc:	3b 7c 24 10          	cmp    0x10(%esp),%edi
   238c0:	74 e6                	je     238a8 <fmt_fp+0x1a08>
   238c2:	8b 5c 24 20          	mov    0x20(%esp),%ebx
   238c6:	8d 84 24 88 00 00 00 	lea    0x88(%esp),%eax
   238cd:	e9 56 f5 ff ff       	jmp    22e28 <fmt_fp+0xf88>
   238d2:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   238d9:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

000238e0 <vfprintf>:
   238e0:	55                   	push   %ebp
   238e1:	31 c0                	xor    %eax,%eax
   238e3:	57                   	push   %edi
   238e4:	b9 0a 00 00 00       	mov    $0xa,%ecx
   238e9:	56                   	push   %esi
   238ea:	31 ed                	xor    %ebp,%ebp
   238ec:	53                   	push   %ebx
   238ed:	81 ec 9c 02 00 00    	sub    $0x29c,%esp
   238f3:	8d 7c 24 74          	lea    0x74(%esp),%edi
   238f7:	8b 9c 24 b4 02 00 00 	mov    0x2b4(%esp),%ebx
   238fe:	f3 ab                	rep stos %eax,%es:(%edi)
   23900:	8b 84 24 b8 02 00 00 	mov    0x2b8(%esp),%eax
   23907:	bf 89 28 01 00       	mov    $0x12889,%edi
   2390c:	c7 44 24 1c 00 00 00 	movl   $0x0,0x1c(%esp)
   23913:	00 
   23914:	c7 44 24 24 00 00 00 	movl   $0x0,0x24(%esp)
   2391b:	00 
   2391c:	89 44 24 58          	mov    %eax,0x58(%esp)
   23920:	85 ed                	test   %ebp,%ebp
   23922:	78 21                	js     23945 <vfprintf+0x65>
   23924:	8b 74 24 1c          	mov    0x1c(%esp),%esi
   23928:	b8 ff ff ff 7f       	mov    $0x7fffffff,%eax
   2392d:	29 e8                	sub    %ebp,%eax
   2392f:	01 f5                	add    %esi,%ebp
   23931:	39 f0                	cmp    %esi,%eax
   23933:	7d 10                	jge    23945 <vfprintf+0x65>
   23935:	e8 fc ff ff ff       	call   23936 <vfprintf+0x56>
   2393a:	bd ff ff ff ff       	mov    $0xffffffff,%ebp
   2393f:	c7 00 4b 00 00 00    	movl   $0x4b,(%eax)
   23945:	0f b6 03             	movzbl (%ebx),%eax
   23948:	84 c0                	test   %al,%al
   2394a:	0f 84 5b 01 00 00    	je     23aab <vfprintf+0x1cb>
   23950:	3c 25                	cmp    $0x25,%al
   23952:	89 da                	mov    %ebx,%edx
   23954:	75 06                	jne    2395c <vfprintf+0x7c>
   23956:	eb 16                	jmp    2396e <vfprintf+0x8e>
   23958:	84 c9                	test   %cl,%cl
   2395a:	74 0d                	je     23969 <vfprintf+0x89>
   2395c:	8d 42 01             	lea    0x1(%edx),%eax
   2395f:	0f b6 08             	movzbl (%eax),%ecx
   23962:	89 c2                	mov    %eax,%edx
   23964:	80 f9 25             	cmp    $0x25,%cl
   23967:	75 ef                	jne    23958 <vfprintf+0x78>
   23969:	80 f9 25             	cmp    $0x25,%cl
   2396c:	75 1d                	jne    2398b <vfprintf+0xab>
   2396e:	80 7a 01 25          	cmpb   $0x25,0x1(%edx)
   23972:	89 d0                	mov    %edx,%eax
   23974:	74 08                	je     2397e <vfprintf+0x9e>
   23976:	eb 13                	jmp    2398b <vfprintf+0xab>
   23978:	80 79 01 25          	cmpb   $0x25,0x1(%ecx)
   2397c:	75 0d                	jne    2398b <vfprintf+0xab>
   2397e:	8d 48 02             	lea    0x2(%eax),%ecx
   23981:	83 c2 01             	add    $0x1,%edx
   23984:	80 39 25             	cmpb   $0x25,(%ecx)
   23987:	89 c8                	mov    %ecx,%eax
   23989:	74 ed                	je     23978 <vfprintf+0x98>
   2398b:	29 da                	sub    %ebx,%edx
   2398d:	89 54 24 1c          	mov    %edx,0x1c(%esp)
   23991:	0f 85 e1 00 00 00    	jne    23a78 <vfprintf+0x198>
   23997:	0f b6 48 01          	movzbl 0x1(%eax),%ecx
   2399b:	0f be d1             	movsbl %cl,%edx
   2399e:	8d 5a d0             	lea    -0x30(%edx),%ebx
   239a1:	83 fb 09             	cmp    $0x9,%ebx
   239a4:	77 0a                	ja     239b0 <vfprintf+0xd0>
   239a6:	80 78 02 24          	cmpb   $0x24,0x2(%eax)
   239aa:	0f 84 69 12 00 00    	je     24c19 <vfprintf+0x1339>
   239b0:	83 c0 01             	add    $0x1,%eax
   239b3:	c7 44 24 20 ff ff ff 	movl   $0xffffffff,0x20(%esp)
   239ba:	ff 
   239bb:	8d 5a e0             	lea    -0x20(%edx),%ebx
   239be:	83 fb 1f             	cmp    $0x1f,%ebx
   239c1:	76 16                	jbe    239d9 <vfprintf+0xf9>
   239c3:	eb 19                	jmp    239de <vfprintf+0xfe>
   239c5:	8d 76 00             	lea    0x0(%esi),%esi
   239c8:	83 c0 01             	add    $0x1,%eax
   239cb:	0f b6 08             	movzbl (%eax),%ecx
   239ce:	0f be d1             	movsbl %cl,%edx
   239d1:	8d 5a e0             	lea    -0x20(%edx),%ebx
   239d4:	83 fb 1f             	cmp    $0x1f,%ebx
   239d7:	77 05                	ja     239de <vfprintf+0xfe>
   239d9:	0f a3 df             	bt     %ebx,%edi
   239dc:	72 ea                	jb     239c8 <vfprintf+0xe8>
   239de:	80 f9 2a             	cmp    $0x2a,%cl
   239e1:	0f 84 39 06 00 00    	je     24020 <vfprintf+0x740>
   239e7:	8d 72 d0             	lea    -0x30(%edx),%esi
   239ea:	31 db                	xor    %ebx,%ebx
   239ec:	83 fe 09             	cmp    $0x9,%esi
   239ef:	77 23                	ja     23a14 <vfprintf+0x134>
   239f1:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   239f8:	8d 0c 9b             	lea    (%ebx,%ebx,4),%ecx
   239fb:	83 c0 01             	add    $0x1,%eax
   239fe:	8d 5c 4a d0          	lea    -0x30(%edx,%ecx,2),%ebx
   23a02:	0f b6 08             	movzbl (%eax),%ecx
   23a05:	0f be d1             	movsbl %cl,%edx
   23a08:	8d 72 d0             	lea    -0x30(%edx),%esi
   23a0b:	83 fe 09             	cmp    $0x9,%esi
   23a0e:	76 e8                	jbe    239f8 <vfprintf+0x118>
   23a10:	85 db                	test   %ebx,%ebx
   23a12:	78 2d                	js     23a41 <vfprintf+0x161>
   23a14:	80 f9 2e             	cmp    $0x2e,%cl
   23a17:	74 67                	je     23a80 <vfprintf+0x1a0>
   23a19:	31 d2                	xor    %edx,%edx
   23a1b:	eb 19                	jmp    23a36 <vfprintf+0x156>
   23a1d:	8d 76 00             	lea    0x0(%esi),%esi
   23a20:	6b d2 3a             	imul   $0x3a,%edx,%edx
   23a23:	83 c0 01             	add    $0x1,%eax
   23a26:	0f b6 94 11 7f 3a 00 	movzbl 0x3a7f(%ecx,%edx,1),%edx
   23a2d:	00 
   23a2e:	8d 4a ff             	lea    -0x1(%edx),%ecx
   23a31:	83 f9 07             	cmp    $0x7,%ecx
   23a34:	77 22                	ja     23a58 <vfprintf+0x178>
   23a36:	0f be 08             	movsbl (%eax),%ecx
   23a39:	8d 59 bf             	lea    -0x41(%ecx),%ebx
   23a3c:	83 fb 39             	cmp    $0x39,%ebx
   23a3f:	76 df                	jbe    23a20 <vfprintf+0x140>
   23a41:	81 c4 9c 02 00 00    	add    $0x29c,%esp
   23a47:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
   23a4c:	5b                   	pop    %ebx
   23a4d:	5e                   	pop    %esi
   23a4e:	5f                   	pop    %edi
   23a4f:	5d                   	pop    %ebp
   23a50:	c3                   	ret    
   23a51:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   23a58:	85 d2                	test   %edx,%edx
   23a5a:	74 e5                	je     23a41 <vfprintf+0x161>
   23a5c:	83 fa 13             	cmp    $0x13,%edx
   23a5f:	0f 84 cd 0c 00 00    	je     24732 <vfprintf+0xe52>
   23a65:	8b 74 24 20          	mov    0x20(%esp),%esi
   23a69:	85 f6                	test   %esi,%esi
   23a6b:	0f 88 3c 01 00 00    	js     23bad <vfprintf+0x2cd>
   23a71:	89 54 b4 74          	mov    %edx,0x74(%esp,%esi,4)
   23a75:	8d 76 00             	lea    0x0(%esi),%esi
   23a78:	89 c3                	mov    %eax,%ebx
   23a7a:	e9 a1 fe ff ff       	jmp    23920 <vfprintf+0x40>
   23a7f:	90                   	nop
   23a80:	0f be 50 01          	movsbl 0x1(%eax),%edx
   23a84:	80 fa 2a             	cmp    $0x2a,%dl
   23a87:	0f 84 34 0e 00 00    	je     248c1 <vfprintf+0xfe1>
   23a8d:	83 ea 30             	sub    $0x30,%edx
   23a90:	83 c0 01             	add    $0x1,%eax
   23a93:	83 fa 09             	cmp    $0x9,%edx
   23a96:	77 81                	ja     23a19 <vfprintf+0x139>
   23a98:	83 c0 01             	add    $0x1,%eax
   23a9b:	0f be 10             	movsbl (%eax),%edx
   23a9e:	83 ea 30             	sub    $0x30,%edx
   23aa1:	83 fa 09             	cmp    $0x9,%edx
   23aa4:	76 f2                	jbe    23a98 <vfprintf+0x1b8>
   23aa6:	e9 6e ff ff ff       	jmp    23a19 <vfprintf+0x139>
   23aab:	8b 4c 24 24          	mov    0x24(%esp),%ecx
   23aaf:	85 c9                	test   %ecx,%ecx
   23ab1:	0f 84 f6 00 00 00    	je     23bad <vfprintf+0x2cd>
   23ab7:	8b 54 24 78          	mov    0x78(%esp),%edx
   23abb:	85 d2                	test   %edx,%edx
   23abd:	0f 84 13 15 00 00    	je     24fd6 <vfprintf+0x16f6>
   23ac3:	83 fa 14             	cmp    $0x14,%edx
   23ac6:	0f 86 e5 13 00 00    	jbe    24eb1 <vfprintf+0x15d1>
   23acc:	8b 54 24 7c          	mov    0x7c(%esp),%edx
   23ad0:	85 d2                	test   %edx,%edx
   23ad2:	0f 84 e6 14 00 00    	je     24fbe <vfprintf+0x16de>
   23ad8:	83 fa 14             	cmp    $0x14,%edx
   23adb:	77 10                	ja     23aed <vfprintf+0x20d>
   23add:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   23ae1:	8d 84 24 30 01 00 00 	lea    0x130(%esp),%eax
   23ae8:	e8 f3 e1 ff ff       	call   21ce0 <pop_arg.part.0>
   23aed:	8b 94 24 80 00 00 00 	mov    0x80(%esp),%edx
   23af4:	85 d2                	test   %edx,%edx
   23af6:	0f 84 d3 14 00 00    	je     24fcf <vfprintf+0x16ef>
   23afc:	83 fa 14             	cmp    $0x14,%edx
   23aff:	77 10                	ja     23b11 <vfprintf+0x231>
   23b01:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   23b05:	8d 84 24 3c 01 00 00 	lea    0x13c(%esp),%eax
   23b0c:	e8 cf e1 ff ff       	call   21ce0 <pop_arg.part.0>
   23b11:	8b 94 24 84 00 00 00 	mov    0x84(%esp),%edx
   23b18:	85 d2                	test   %edx,%edx
   23b1a:	0f 84 89 14 00 00    	je     24fa9 <vfprintf+0x16c9>
   23b20:	83 fa 14             	cmp    $0x14,%edx
   23b23:	0f 86 1c 14 00 00    	jbe    24f45 <vfprintf+0x1665>
   23b29:	8b 94 24 88 00 00 00 	mov    0x88(%esp),%edx
   23b30:	85 d2                	test   %edx,%edx
   23b32:	0f 84 6a 14 00 00    	je     24fa2 <vfprintf+0x16c2>
   23b38:	83 fa 14             	cmp    $0x14,%edx
   23b3b:	0f 86 ef 13 00 00    	jbe    24f30 <vfprintf+0x1650>
   23b41:	8b 94 24 8c 00 00 00 	mov    0x8c(%esp),%edx
   23b48:	85 d2                	test   %edx,%edx
   23b4a:	0f 84 67 14 00 00    	je     24fb7 <vfprintf+0x16d7>
   23b50:	83 fa 14             	cmp    $0x14,%edx
   23b53:	0f 86 c2 13 00 00    	jbe    24f1b <vfprintf+0x163b>
   23b59:	8b 94 24 90 00 00 00 	mov    0x90(%esp),%edx
   23b60:	85 d2                	test   %edx,%edx
   23b62:	0f 84 48 14 00 00    	je     24fb0 <vfprintf+0x16d0>
   23b68:	83 fa 14             	cmp    $0x14,%edx
   23b6b:	0f 86 95 13 00 00    	jbe    24f06 <vfprintf+0x1626>
   23b71:	8b 94 24 94 00 00 00 	mov    0x94(%esp),%edx
   23b78:	85 d2                	test   %edx,%edx
   23b7a:	0f 84 11 14 00 00    	je     24f91 <vfprintf+0x16b1>
   23b80:	83 fa 14             	cmp    $0x14,%edx
   23b83:	0f 86 5e 13 00 00    	jbe    24ee7 <vfprintf+0x1607>
   23b89:	8b 94 24 98 00 00 00 	mov    0x98(%esp),%edx
   23b90:	85 d2                	test   %edx,%edx
   23b92:	0f 84 d9 13 00 00    	je     24f71 <vfprintf+0x1691>
   23b98:	83 fa 14             	cmp    $0x14,%edx
   23b9b:	77 10                	ja     23bad <vfprintf+0x2cd>
   23b9d:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   23ba1:	8d 84 24 84 01 00 00 	lea    0x184(%esp),%eax
   23ba8:	e8 33 e1 ff ff       	call   21ce0 <pop_arg.part.0>
   23bad:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23bb4:	8b 40 4c             	mov    0x4c(%eax),%eax
   23bb7:	85 c0                	test   %eax,%eax
   23bb9:	0f 88 b6 04 00 00    	js     24075 <vfprintf+0x795>
   23bbf:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23bc6:	89 04 24             	mov    %eax,(%esp)
   23bc9:	e8 fc ff ff ff       	call   23bca <vfprintf+0x2ea>
   23bce:	89 44 24 44          	mov    %eax,0x44(%esp)
   23bd2:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23bd9:	8b 00                	mov    (%eax),%eax
   23bdb:	89 c7                	mov    %eax,%edi
   23bdd:	83 e7 20             	and    $0x20,%edi
   23be0:	89 7c 24 40          	mov    %edi,0x40(%esp)
   23be4:	8b bc 24 b0 02 00 00 	mov    0x2b0(%esp),%edi
   23beb:	80 7f 4a 00          	cmpb   $0x0,0x4a(%edi)
   23bef:	0f 8e 61 04 00 00    	jle    24056 <vfprintf+0x776>
   23bf5:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23bfc:	c7 44 24 3c 00 00 00 	movl   $0x0,0x3c(%esp)
   23c03:	00 
   23c04:	8b 68 30             	mov    0x30(%eax),%ebp
   23c07:	85 ed                	test   %ebp,%ebp
   23c09:	75 2a                	jne    23c35 <vfprintf+0x355>
   23c0b:	89 c7                	mov    %eax,%edi
   23c0d:	8b 40 2c             	mov    0x2c(%eax),%eax
   23c10:	c7 47 30 50 00 00 00 	movl   $0x50,0x30(%edi)
   23c17:	89 44 24 3c          	mov    %eax,0x3c(%esp)
   23c1b:	8d 84 24 c8 00 00 00 	lea    0xc8(%esp),%eax
   23c22:	89 47 2c             	mov    %eax,0x2c(%edi)
   23c25:	89 47 1c             	mov    %eax,0x1c(%edi)
   23c28:	89 47 14             	mov    %eax,0x14(%edi)
   23c2b:	8d 84 24 18 01 00 00 	lea    0x118(%esp),%eax
   23c32:	89 47 10             	mov    %eax,0x10(%edi)
   23c35:	c7 44 24 24 00 00 00 	movl   $0x0,0x24(%esp)
   23c3c:	00 
   23c3d:	c7 44 24 28 00 00 00 	movl   $0x0,0x28(%esp)
   23c44:	00 
   23c45:	c7 44 24 48 00 00 00 	movl   $0x0,0x48(%esp)
   23c4c:	00 
   23c4d:	8b 7c 24 28          	mov    0x28(%esp),%edi
   23c51:	85 ff                	test   %edi,%edi
   23c53:	78 26                	js     23c7b <vfprintf+0x39b>
   23c55:	b8 ff ff ff 7f       	mov    $0x7fffffff,%eax
   23c5a:	29 f8                	sub    %edi,%eax
   23c5c:	8b 7c 24 24          	mov    0x24(%esp),%edi
   23c60:	01 7c 24 28          	add    %edi,0x28(%esp)
   23c64:	39 f8                	cmp    %edi,%eax
   23c66:	7d 13                	jge    23c7b <vfprintf+0x39b>
   23c68:	e8 fc ff ff ff       	call   23c69 <vfprintf+0x389>
   23c6d:	c7 44 24 28 ff ff ff 	movl   $0xffffffff,0x28(%esp)
   23c74:	ff 
   23c75:	c7 00 4b 00 00 00    	movl   $0x4b,(%eax)
   23c7b:	8b 84 24 b4 02 00 00 	mov    0x2b4(%esp),%eax
   23c82:	0f b6 00             	movzbl (%eax),%eax
   23c85:	84 c0                	test   %al,%al
   23c87:	0f 84 6e 01 00 00    	je     23dfb <vfprintf+0x51b>
   23c8d:	3c 25                	cmp    $0x25,%al
   23c8f:	8b b4 24 b4 02 00 00 	mov    0x2b4(%esp),%esi
   23c96:	75 0c                	jne    23ca4 <vfprintf+0x3c4>
   23c98:	eb 20                	jmp    23cba <vfprintf+0x3da>
   23c9a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   23ca0:	84 d2                	test   %dl,%dl
   23ca2:	74 0d                	je     23cb1 <vfprintf+0x3d1>
   23ca4:	8d 46 01             	lea    0x1(%esi),%eax
   23ca7:	0f b6 10             	movzbl (%eax),%edx
   23caa:	89 c6                	mov    %eax,%esi
   23cac:	80 fa 25             	cmp    $0x25,%dl
   23caf:	75 ef                	jne    23ca0 <vfprintf+0x3c0>
   23cb1:	80 fa 25             	cmp    $0x25,%dl
   23cb4:	0f 85 8b 0a 00 00    	jne    24745 <vfprintf+0xe65>
   23cba:	80 7e 01 25          	cmpb   $0x25,0x1(%esi)
   23cbe:	89 f2                	mov    %esi,%edx
   23cc0:	74 0c                	je     23cce <vfprintf+0x3ee>
   23cc2:	eb 17                	jmp    23cdb <vfprintf+0x3fb>
   23cc4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   23cc8:	80 78 01 25          	cmpb   $0x25,0x1(%eax)
   23ccc:	75 0d                	jne    23cdb <vfprintf+0x3fb>
   23cce:	8d 46 02             	lea    0x2(%esi),%eax
   23cd1:	83 c2 01             	add    $0x1,%edx
   23cd4:	80 38 25             	cmpb   $0x25,(%eax)
   23cd7:	89 c6                	mov    %eax,%esi
   23cd9:	74 ed                	je     23cc8 <vfprintf+0x3e8>
   23cdb:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23ce2:	2b 94 24 b4 02 00 00 	sub    0x2b4(%esp),%edx
   23ce9:	f6 00 20             	testb  $0x20,(%eax)
   23cec:	89 54 24 24          	mov    %edx,0x24(%esp)
   23cf0:	0f 84 e2 01 00 00    	je     23ed8 <vfprintf+0x5f8>
   23cf6:	8b 7c 24 24          	mov    0x24(%esp),%edi
   23cfa:	85 ff                	test   %edi,%edi
   23cfc:	0f 85 c6 01 00 00    	jne    23ec8 <vfprintf+0x5e8>
   23d02:	0f b6 56 01          	movzbl 0x1(%esi),%edx
   23d06:	0f be c2             	movsbl %dl,%eax
   23d09:	8d 48 d0             	lea    -0x30(%eax),%ecx
   23d0c:	83 f9 09             	cmp    $0x9,%ecx
   23d0f:	77 0a                	ja     23d1b <vfprintf+0x43b>
   23d11:	80 7e 02 24          	cmpb   $0x24,0x2(%esi)
   23d15:	0f 84 e4 0b 00 00    	je     248ff <vfprintf+0x101f>
   23d1b:	8d 5e 01             	lea    0x1(%esi),%ebx
   23d1e:	c7 44 24 38 ff ff ff 	movl   $0xffffffff,0x38(%esp)
   23d25:	ff 
   23d26:	8d 48 e0             	lea    -0x20(%eax),%ecx
   23d29:	83 f9 1f             	cmp    $0x1f,%ecx
   23d2c:	0f 87 42 0a 00 00    	ja     24774 <vfprintf+0xe94>
   23d32:	be 89 28 01 00       	mov    $0x12889,%esi
   23d37:	0f a3 ce             	bt     %ecx,%esi
   23d3a:	0f 83 34 0a 00 00    	jae    24774 <vfprintf+0xe94>
   23d40:	31 ed                	xor    %ebp,%ebp
   23d42:	be 01 00 00 00       	mov    $0x1,%esi
   23d47:	bf 89 28 01 00       	mov    $0x12889,%edi
   23d4c:	eb 07                	jmp    23d55 <vfprintf+0x475>
   23d4e:	66 90                	xchg   %ax,%ax
   23d50:	0f a3 cf             	bt     %ecx,%edi
   23d53:	73 17                	jae    23d6c <vfprintf+0x48c>
   23d55:	83 c3 01             	add    $0x1,%ebx
   23d58:	0f b6 13             	movzbl (%ebx),%edx
   23d5b:	89 f0                	mov    %esi,%eax
   23d5d:	d3 e0                	shl    %cl,%eax
   23d5f:	09 c5                	or     %eax,%ebp
   23d61:	0f be c2             	movsbl %dl,%eax
   23d64:	8d 48 e0             	lea    -0x20(%eax),%ecx
   23d67:	83 f9 1f             	cmp    $0x1f,%ecx
   23d6a:	76 e4                	jbe    23d50 <vfprintf+0x470>
   23d6c:	89 6c 24 2c          	mov    %ebp,0x2c(%esp)
   23d70:	80 fa 2a             	cmp    $0x2a,%dl
   23d73:	0f 84 17 02 00 00    	je     23f90 <vfprintf+0x6b0>
   23d79:	8d 48 d0             	lea    -0x30(%eax),%ecx
   23d7c:	31 ff                	xor    %edi,%edi
   23d7e:	83 f9 09             	cmp    $0x9,%ecx
   23d81:	77 21                	ja     23da4 <vfprintf+0x4c4>
   23d83:	90                   	nop
   23d84:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   23d88:	8d 14 bf             	lea    (%edi,%edi,4),%edx
   23d8b:	83 c3 01             	add    $0x1,%ebx
   23d8e:	8d 7c 50 d0          	lea    -0x30(%eax,%edx,2),%edi
   23d92:	0f b6 13             	movzbl (%ebx),%edx
   23d95:	0f be c2             	movsbl %dl,%eax
   23d98:	8d 48 d0             	lea    -0x30(%eax),%ecx
   23d9b:	83 f9 09             	cmp    $0x9,%ecx
   23d9e:	76 e8                	jbe    23d88 <vfprintf+0x4a8>
   23da0:	85 ff                	test   %edi,%edi
   23da2:	78 4f                	js     23df3 <vfprintf+0x513>
   23da4:	80 fa 2e             	cmp    $0x2e,%dl
   23da7:	c7 44 24 30 ff ff ff 	movl   $0xffffffff,0x30(%esp)
   23dae:	ff 
   23daf:	0f 84 29 02 00 00    	je     23fde <vfprintf+0x6fe>
   23db5:	31 ed                	xor    %ebp,%ebp
   23db7:	89 7c 24 34          	mov    %edi,0x34(%esp)
   23dbb:	89 ef                	mov    %ebp,%edi
   23dbd:	eb 25                	jmp    23de4 <vfprintf+0x504>
   23dbf:	90                   	nop
   23dc0:	6b d7 3a             	imul   $0x3a,%edi,%edx
   23dc3:	8d 4b 01             	lea    0x1(%ebx),%ecx
   23dc6:	89 ce                	mov    %ecx,%esi
   23dc8:	0f b6 94 10 7f 3a 00 	movzbl 0x3a7f(%eax,%edx,1),%edx
   23dcf:	00 
   23dd0:	8d 6a ff             	lea    -0x1(%edx),%ebp
   23dd3:	83 fd 07             	cmp    $0x7,%ebp
   23dd6:	88 54 24 20          	mov    %dl,0x20(%esp)
   23dda:	0f 87 18 01 00 00    	ja     23ef8 <vfprintf+0x618>
   23de0:	89 cb                	mov    %ecx,%ebx
   23de2:	89 d7                	mov    %edx,%edi
   23de4:	0f be 03             	movsbl (%ebx),%eax
   23de7:	8d 50 bf             	lea    -0x41(%eax),%edx
   23dea:	83 fa 39             	cmp    $0x39,%edx
   23ded:	88 44 24 1c          	mov    %al,0x1c(%esp)
   23df1:	76 cd                	jbe    23dc0 <vfprintf+0x4e0>
   23df3:	c7 44 24 28 ff ff ff 	movl   $0xffffffff,0x28(%esp)
   23dfa:	ff 
   23dfb:	8b 7c 24 3c          	mov    0x3c(%esp),%edi
   23dff:	85 ff                	test   %edi,%edi
   23e01:	74 54                	je     23e57 <vfprintf+0x577>
   23e03:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23e0a:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   23e11:	00 
   23e12:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   23e19:	00 
   23e1a:	89 04 24             	mov    %eax,(%esp)
   23e1d:	ff 50 24             	call   *0x24(%eax)
   23e20:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23e27:	8b b4 24 b0 02 00 00 	mov    0x2b0(%esp),%esi
   23e2e:	83 78 14 01          	cmpl   $0x1,0x14(%eax)
   23e32:	89 7e 2c             	mov    %edi,0x2c(%esi)
   23e35:	c7 46 30 00 00 00 00 	movl   $0x0,0x30(%esi)
   23e3c:	19 c0                	sbb    %eax,%eax
   23e3e:	09 44 24 28          	or     %eax,0x28(%esp)
   23e42:	c7 46 10 00 00 00 00 	movl   $0x0,0x10(%esi)
   23e49:	c7 46 1c 00 00 00 00 	movl   $0x0,0x1c(%esi)
   23e50:	c7 46 14 00 00 00 00 	movl   $0x0,0x14(%esi)
   23e57:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23e5e:	8b 10                	mov    (%eax),%edx
   23e60:	89 d0                	mov    %edx,%eax
   23e62:	c1 e0 1a             	shl    $0x1a,%eax
   23e65:	c1 f8 1f             	sar    $0x1f,%eax
   23e68:	09 44 24 28          	or     %eax,0x28(%esp)
   23e6c:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23e73:	0b 54 24 40          	or     0x40(%esp),%edx
   23e77:	89 10                	mov    %edx,(%eax)
   23e79:	8b 54 24 44          	mov    0x44(%esp),%edx
   23e7d:	85 d2                	test   %edx,%edx
   23e7f:	0f 85 c4 01 00 00    	jne    24049 <vfprintf+0x769>
   23e85:	8b 44 24 28          	mov    0x28(%esp),%eax
   23e89:	81 c4 9c 02 00 00    	add    $0x29c,%esp
   23e8f:	5b                   	pop    %ebx
   23e90:	5e                   	pop    %esi
   23e91:	5f                   	pop    %edi
   23e92:	5d                   	pop    %ebp
   23e93:	c3                   	ret    
   23e94:	89 e8                	mov    %ebp,%eax
   23e96:	0f b6 e8             	movzbl %al,%ebp
   23e99:	85 d2                	test   %edx,%edx
   23e9b:	75 1e                	jne    23ebb <vfprintf+0x5db>
   23e9d:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   23ea4:	89 6c 24 04          	mov    %ebp,0x4(%esp)
   23ea8:	89 44 24 08          	mov    %eax,0x8(%esp)
   23eac:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   23eb3:	89 04 24             	mov    %eax,(%esp)
   23eb6:	e8 fc ff ff ff       	call   23eb7 <vfprintf+0x5d7>
   23ebb:	39 7c 24 24          	cmp    %edi,0x24(%esp)
   23ebf:	7d 07                	jge    23ec8 <vfprintf+0x5e8>
   23ec1:	89 7c 24 24          	mov    %edi,0x24(%esp)
   23ec5:	8d 76 00             	lea    0x0(%esi),%esi
   23ec8:	89 b4 24 b4 02 00 00 	mov    %esi,0x2b4(%esp)
   23ecf:	e9 79 fd ff ff       	jmp    23c4d <vfprintf+0x36d>
   23ed4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   23ed8:	89 44 24 08          	mov    %eax,0x8(%esp)
   23edc:	8b 84 24 b4 02 00 00 	mov    0x2b4(%esp),%eax
   23ee3:	89 54 24 04          	mov    %edx,0x4(%esp)
   23ee7:	89 04 24             	mov    %eax,(%esp)
   23eea:	e8 fc ff ff ff       	call   23eeb <vfprintf+0x60b>
   23eef:	e9 02 fe ff ff       	jmp    23cf6 <vfprintf+0x416>
   23ef4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   23ef8:	85 d2                	test   %edx,%edx
   23efa:	89 fd                	mov    %edi,%ebp
   23efc:	8b 7c 24 34          	mov    0x34(%esp),%edi
   23f00:	0f 84 ed fe ff ff    	je     23df3 <vfprintf+0x513>
   23f06:	83 fa 13             	cmp    $0x13,%edx
   23f09:	0f 84 51 01 00 00    	je     24060 <vfprintf+0x780>
   23f0f:	8b 4c 24 38          	mov    0x38(%esp),%ecx
   23f13:	85 c9                	test   %ecx,%ecx
   23f15:	0f 88 31 08 00 00    	js     2474c <vfprintf+0xe6c>
   23f1b:	89 54 8c 74          	mov    %edx,0x74(%esp,%ecx,4)
   23f1f:	8d 14 49             	lea    (%ecx,%ecx,2),%edx
   23f22:	c1 e2 02             	shl    $0x2,%edx
   23f25:	8d 84 14 18 01 00 00 	lea    0x118(%esp,%edx,1),%eax
   23f2c:	8b 94 14 18 01 00 00 	mov    0x118(%esp,%edx,1),%edx
   23f33:	89 54 24 68          	mov    %edx,0x68(%esp)
   23f37:	8b 50 04             	mov    0x4(%eax),%edx
   23f3a:	8b 40 08             	mov    0x8(%eax),%eax
   23f3d:	89 54 24 6c          	mov    %edx,0x6c(%esp)
   23f41:	89 44 24 70          	mov    %eax,0x70(%esp)
   23f45:	0f be 03             	movsbl (%ebx),%eax
   23f48:	88 44 24 1c          	mov    %al,0x1c(%esp)
   23f4c:	89 44 24 34          	mov    %eax,0x34(%esp)
   23f50:	85 ed                	test   %ebp,%ebp
   23f52:	74 10                	je     23f64 <vfprintf+0x684>
   23f54:	0f b6 44 24 1c       	movzbl 0x1c(%esp),%eax
   23f59:	83 e0 0f             	and    $0xf,%eax
   23f5c:	3c 03                	cmp    $0x3,%al
   23f5e:	0f 84 87 09 00 00    	je     248eb <vfprintf+0x100b>
   23f64:	f7 44 24 2c 00 20 00 	testl  $0x2000,0x2c(%esp)
   23f6b:	00 
   23f6c:	74 08                	je     23f76 <vfprintf+0x696>
   23f6e:	81 64 24 2c ff ff fe 	andl   $0xfffeffff,0x2c(%esp)
   23f75:	ff 
   23f76:	8b 44 24 34          	mov    0x34(%esp),%eax
   23f7a:	83 e8 41             	sub    $0x41,%eax
   23f7d:	83 f8 37             	cmp    $0x37,%eax
   23f80:	0f 87 4b 07 00 00    	ja     246d1 <vfprintf+0xdf1>
   23f86:	ff 24 85 a8 39 00 00 	jmp    *0x39a8(,%eax,4)
   23f8d:	8d 76 00             	lea    0x0(%esi),%esi
   23f90:	0f be 43 01          	movsbl 0x1(%ebx),%eax
   23f94:	8d 50 d0             	lea    -0x30(%eax),%edx
   23f97:	83 fa 09             	cmp    $0x9,%edx
   23f9a:	77 0a                	ja     23fa6 <vfprintf+0x6c6>
   23f9c:	80 7b 02 24          	cmpb   $0x24,0x2(%ebx)
   23fa0:	0f 84 dc 00 00 00    	je     24082 <vfprintf+0x7a2>
   23fa6:	8b 74 24 48          	mov    0x48(%esp),%esi
   23faa:	85 f6                	test   %esi,%esi
   23fac:	0f 85 41 fe ff ff    	jne    23df3 <vfprintf+0x513>
   23fb2:	8b 44 24 58          	mov    0x58(%esp),%eax
   23fb6:	83 c3 01             	add    $0x1,%ebx
   23fb9:	8b 38                	mov    (%eax),%edi
   23fbb:	8d 50 04             	lea    0x4(%eax),%edx
   23fbe:	89 54 24 58          	mov    %edx,0x58(%esp)
   23fc2:	85 ff                	test   %edi,%edi
   23fc4:	0f 88 e8 08 00 00    	js     248b2 <vfprintf+0xfd2>
   23fca:	0f b6 13             	movzbl (%ebx),%edx
   23fcd:	c7 44 24 30 ff ff ff 	movl   $0xffffffff,0x30(%esp)
   23fd4:	ff 
   23fd5:	80 fa 2e             	cmp    $0x2e,%dl
   23fd8:	0f 85 d7 fd ff ff    	jne    23db5 <vfprintf+0x4d5>
   23fde:	0f be 43 01          	movsbl 0x1(%ebx),%eax
   23fe2:	3c 2a                	cmp    $0x2a,%al
   23fe4:	0f 84 8d 08 00 00    	je     24877 <vfprintf+0xf97>
   23fea:	8d 50 d0             	lea    -0x30(%eax),%edx
   23fed:	83 c3 01             	add    $0x1,%ebx
   23ff0:	83 fa 09             	cmp    $0x9,%edx
   23ff3:	0f 87 19 0e 00 00    	ja     24e12 <vfprintf+0x1532>
   23ff9:	31 d2                	xor    %edx,%edx
   23ffb:	90                   	nop
   23ffc:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   24000:	83 c3 01             	add    $0x1,%ebx
   24003:	8d 14 92             	lea    (%edx,%edx,4),%edx
   24006:	8d 54 50 d0          	lea    -0x30(%eax,%edx,2),%edx
   2400a:	0f be 03             	movsbl (%ebx),%eax
   2400d:	8d 48 d0             	lea    -0x30(%eax),%ecx
   24010:	83 f9 09             	cmp    $0x9,%ecx
   24013:	76 eb                	jbe    24000 <vfprintf+0x720>
   24015:	89 54 24 30          	mov    %edx,0x30(%esp)
   24019:	e9 97 fd ff ff       	jmp    23db5 <vfprintf+0x4d5>
   2401e:	66 90                	xchg   %ax,%ax
   24020:	0f b6 48 01          	movzbl 0x1(%eax),%ecx
   24024:	0f be d1             	movsbl %cl,%edx
   24027:	8d 5a d0             	lea    -0x30(%edx),%ebx
   2402a:	83 fb 09             	cmp    $0x9,%ebx
   2402d:	77 06                	ja     24035 <vfprintf+0x755>
   2402f:	80 78 02 24          	cmpb   $0x24,0x2(%eax)
   24033:	74 73                	je     240a8 <vfprintf+0x7c8>
   24035:	8b 54 24 24          	mov    0x24(%esp),%edx
   24039:	85 d2                	test   %edx,%edx
   2403b:	0f 85 00 fa ff ff    	jne    23a41 <vfprintf+0x161>
   24041:	83 c0 01             	add    $0x1,%eax
   24044:	e9 cb f9 ff ff       	jmp    23a14 <vfprintf+0x134>
   24049:	89 04 24             	mov    %eax,(%esp)
   2404c:	e8 fc ff ff ff       	call   2404d <vfprintf+0x76d>
   24051:	e9 2f fe ff ff       	jmp    23e85 <vfprintf+0x5a5>
   24056:	83 e0 df             	and    $0xffffffdf,%eax
   24059:	89 07                	mov    %eax,(%edi)
   2405b:	e9 95 fb ff ff       	jmp    23bf5 <vfprintf+0x315>
   24060:	8b 54 24 38          	mov    0x38(%esp),%edx
   24064:	85 d2                	test   %edx,%edx
   24066:	0f 89 87 fd ff ff    	jns    23df3 <vfprintf+0x513>
   2406c:	89 44 24 34          	mov    %eax,0x34(%esp)
   24070:	e9 db fe ff ff       	jmp    23f50 <vfprintf+0x670>
   24075:	c7 44 24 44 00 00 00 	movl   $0x0,0x44(%esp)
   2407c:	00 
   2407d:	e9 50 fb ff ff       	jmp    23bd2 <vfprintf+0x2f2>
   24082:	c7 44 84 b4 0a 00 00 	movl   $0xa,-0x4c(%esp,%eax,4)
   24089:	00 
   2408a:	0f be 43 01          	movsbl 0x1(%ebx),%eax
   2408e:	83 c3 03             	add    $0x3,%ebx
   24091:	c7 44 24 48 01 00 00 	movl   $0x1,0x48(%esp)
   24098:	00 
   24099:	8d 04 40             	lea    (%eax,%eax,2),%eax
   2409c:	8b bc 84 d8 fe ff ff 	mov    -0x128(%esp,%eax,4),%edi
   240a3:	e9 1a ff ff ff       	jmp    23fc2 <vfprintf+0x6e2>
   240a8:	c7 44 94 b4 0a 00 00 	movl   $0xa,-0x4c(%esp,%edx,4)
   240af:	00 
   240b0:	83 c0 03             	add    $0x3,%eax
   240b3:	0f b6 08             	movzbl (%eax),%ecx
   240b6:	c7 44 24 24 01 00 00 	movl   $0x1,0x24(%esp)
   240bd:	00 
   240be:	e9 51 f9 ff ff       	jmp    23a14 <vfprintf+0x134>
   240c3:	8b 5c 24 30          	mov    0x30(%esp),%ebx
   240c7:	8b 6c 24 68          	mov    0x68(%esp),%ebp
   240cb:	85 db                	test   %ebx,%ebx
   240cd:	0f 84 fd 0d 00 00    	je     24ed0 <vfprintf+0x15f0>
   240d3:	8b 45 00             	mov    0x0(%ebp),%eax
   240d6:	85 c0                	test   %eax,%eax
   240d8:	0f 84 f2 0d 00 00    	je     24ed0 <vfprintf+0x15f0>
   240de:	31 c9                	xor    %ecx,%ecx
   240e0:	89 7c 24 20          	mov    %edi,0x20(%esp)
   240e4:	89 cf                	mov    %ecx,%edi
   240e6:	89 74 24 30          	mov    %esi,0x30(%esp)
   240ea:	89 ee                	mov    %ebp,%esi
   240ec:	8b 6c 24 24          	mov    0x24(%esp),%ebp
   240f0:	eb 28                	jmp    2411a <vfprintf+0x83a>
   240f2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   240f8:	89 d9                	mov    %ebx,%ecx
   240fa:	29 f9                	sub    %edi,%ecx
   240fc:	39 c8                	cmp    %ecx,%eax
   240fe:	0f 87 16 08 00 00    	ja     2491a <vfprintf+0x103a>
   24104:	01 c5                	add    %eax,%ebp
   24106:	39 eb                	cmp    %ebp,%ebx
   24108:	89 ef                	mov    %ebp,%edi
   2410a:	0f 86 0a 08 00 00    	jbe    2491a <vfprintf+0x103a>
   24110:	8b 06                	mov    (%esi),%eax
   24112:	85 c0                	test   %eax,%eax
   24114:	0f 84 00 08 00 00    	je     2491a <vfprintf+0x103a>
   2411a:	89 44 24 04          	mov    %eax,0x4(%esp)
   2411e:	8d 44 24 5c          	lea    0x5c(%esp),%eax
   24122:	83 c6 04             	add    $0x4,%esi
   24125:	89 04 24             	mov    %eax,(%esp)
   24128:	e8 fc ff ff ff       	call   24129 <vfprintf+0x849>
   2412d:	85 c0                	test   %eax,%eax
   2412f:	79 c7                	jns    240f8 <vfprintf+0x818>
   24131:	e9 bd fc ff ff       	jmp    23df3 <vfprintf+0x513>
   24136:	8b 6c 24 68          	mov    0x68(%esp),%ebp
   2413a:	8b 5c 24 6c          	mov    0x6c(%esp),%ebx
   2413e:	c7 44 24 38 00 00 00 	movl   $0x0,0x38(%esp)
   24145:	00 
   24146:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   2414d:	00 
   2414e:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   24155:	00 
   24156:	8d 84 24 c8 00 00 00 	lea    0xc8(%esp),%eax
   2415d:	83 fb 00             	cmp    $0x0,%ebx
   24160:	89 84 24 b4 02 00 00 	mov    %eax,0x2b4(%esp)
   24167:	76 67                	jbe    241d0 <vfprintf+0x8f0>
   24169:	89 7c 24 1c          	mov    %edi,0x1c(%esp)
   2416d:	89 ef                	mov    %ebp,%edi
   2416f:	89 f5                	mov    %esi,%ebp
   24171:	89 c6                	mov    %eax,%esi
   24173:	90                   	nop
   24174:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   24178:	89 3c 24             	mov    %edi,(%esp)
   2417b:	83 ee 01             	sub    $0x1,%esi
   2417e:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   24182:	c7 44 24 08 0a 00 00 	movl   $0xa,0x8(%esp)
   24189:	00 
   2418a:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   24191:	00 
   24192:	e8 fc ff ff ff       	call   24193 <vfprintf+0x8b3>
   24197:	83 c0 30             	add    $0x30,%eax
   2419a:	88 06                	mov    %al,(%esi)
   2419c:	89 3c 24             	mov    %edi,(%esp)
   2419f:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   241a3:	c7 44 24 08 0a 00 00 	movl   $0xa,0x8(%esp)
   241aa:	00 
   241ab:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   241b2:	00 
   241b3:	e8 fc ff ff ff       	call   241b4 <vfprintf+0x8d4>
   241b8:	83 fa 00             	cmp    $0x0,%edx
   241bb:	89 c7                	mov    %eax,%edi
   241bd:	89 d3                	mov    %edx,%ebx
   241bf:	77 b7                	ja     24178 <vfprintf+0x898>
   241c1:	8b 7c 24 1c          	mov    0x1c(%esp),%edi
   241c5:	89 b4 24 b4 02 00 00 	mov    %esi,0x2b4(%esp)
   241cc:	89 ee                	mov    %ebp,%esi
   241ce:	89 c5                	mov    %eax,%ebp
   241d0:	89 e9                	mov    %ebp,%ecx
   241d2:	bb cd cc cc cc       	mov    $0xcccccccd,%ebx
   241d7:	8b ac 24 b4 02 00 00 	mov    0x2b4(%esp),%ebp
   241de:	85 c9                	test   %ecx,%ecx
   241e0:	74 2a                	je     2420c <vfprintf+0x92c>
   241e2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   241e8:	89 c8                	mov    %ecx,%eax
   241ea:	83 ed 01             	sub    $0x1,%ebp
   241ed:	f7 e3                	mul    %ebx
   241ef:	c1 ea 03             	shr    $0x3,%edx
   241f2:	8d 04 92             	lea    (%edx,%edx,4),%eax
   241f5:	01 c0                	add    %eax,%eax
   241f7:	29 c1                	sub    %eax,%ecx
   241f9:	83 c1 30             	add    $0x30,%ecx
   241fc:	85 d2                	test   %edx,%edx
   241fe:	88 4d 00             	mov    %cl,0x0(%ebp)
   24201:	89 d1                	mov    %edx,%ecx
   24203:	75 e3                	jne    241e8 <vfprintf+0x908>
   24205:	89 ac 24 b4 02 00 00 	mov    %ebp,0x2b4(%esp)
   2420c:	8b 44 24 68          	mov    0x68(%esp),%eax
   24210:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   24217:	8b 54 24 6c          	mov    0x6c(%esp),%edx
   2421b:	8b 6c 24 30          	mov    0x30(%esp),%ebp
   2421f:	85 ed                	test   %ebp,%ebp
   24221:	78 08                	js     2422b <vfprintf+0x94b>
   24223:	81 64 24 2c ff ff fe 	andl   $0xfffeffff,0x2c(%esp)
   2422a:	ff 
   2422b:	89 d3                	mov    %edx,%ebx
   2422d:	09 c3                	or     %eax,%ebx
   2422f:	0f 85 c7 04 00 00    	jne    246fc <vfprintf+0xe1c>
   24235:	8b 5c 24 30          	mov    0x30(%esp),%ebx
   24239:	85 db                	test   %ebx,%ebx
   2423b:	0f 85 bb 04 00 00    	jne    246fc <vfprintf+0xe1c>
   24241:	8d 84 24 c8 00 00 00 	lea    0xc8(%esp),%eax
   24248:	31 c9                	xor    %ecx,%ecx
   2424a:	c7 44 24 1c 00 00 00 	movl   $0x0,0x1c(%esp)
   24251:	00 
   24252:	c7 44 24 4c 00 00 00 	movl   $0x0,0x4c(%esp)
   24259:	00 
   2425a:	89 84 24 b4 02 00 00 	mov    %eax,0x2b4(%esp)
   24261:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   24268:	8b 6c 24 20          	mov    0x20(%esp),%ebp
   2426c:	03 6c 24 1c          	add    0x1c(%esp),%ebp
   24270:	39 fd                	cmp    %edi,%ebp
   24272:	89 6c 24 24          	mov    %ebp,0x24(%esp)
   24276:	7d 04                	jge    2427c <vfprintf+0x99c>
   24278:	89 7c 24 24          	mov    %edi,0x24(%esp)
   2427c:	f7 44 24 2c 00 20 01 	testl  $0x12000,0x2c(%esp)
   24283:	00 
   24284:	75 0a                	jne    24290 <vfprintf+0x9b0>
   24286:	39 6c 24 24          	cmp    %ebp,0x24(%esp)
   2428a:	0f 8f 50 08 00 00    	jg     24ae0 <vfprintf+0x1200>
   24290:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24297:	8b 00                	mov    (%eax),%eax
   24299:	83 e0 20             	and    $0x20,%eax
   2429c:	85 c0                	test   %eax,%eax
   2429e:	0f 84 dd 04 00 00    	je     24781 <vfprintf+0xea1>
   242a4:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   242a8:	35 00 00 01 00       	xor    $0x10000,%eax
   242ad:	a9 00 20 01 00       	test   $0x12000,%eax
   242b2:	75 0a                	jne    242be <vfprintf+0x9de>
   242b4:	39 6c 24 24          	cmp    %ebp,0x24(%esp)
   242b8:	0f 8f bf 08 00 00    	jg     24b7d <vfprintf+0x129d>
   242be:	3b 4c 24 1c          	cmp    0x1c(%esp),%ecx
   242c2:	0f 8c e5 04 00 00    	jl     247ad <vfprintf+0xecd>
   242c8:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   242cf:	8b 10                	mov    (%eax),%edx
   242d1:	83 e2 20             	and    $0x20,%edx
   242d4:	85 d2                	test   %edx,%edx
   242d6:	75 22                	jne    242fa <vfprintf+0xa1a>
   242d8:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   242df:	89 44 24 08          	mov    %eax,0x8(%esp)
   242e3:	8b 44 24 4c          	mov    0x4c(%esp),%eax
   242e7:	89 44 24 04          	mov    %eax,0x4(%esp)
   242eb:	8b 84 24 b4 02 00 00 	mov    0x2b4(%esp),%eax
   242f2:	89 04 24             	mov    %eax,(%esp)
   242f5:	e8 fc ff ff ff       	call   242f6 <vfprintf+0xa16>
   242fa:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   242fe:	80 f4 20             	xor    $0x20,%ah
   24301:	a9 00 20 01 00       	test   $0x12000,%eax
   24306:	0f 85 bc fb ff ff    	jne    23ec8 <vfprintf+0x5e8>
   2430c:	39 6c 24 24          	cmp    %ebp,0x24(%esp)
   24310:	0f 8e b2 fb ff ff    	jle    23ec8 <vfprintf+0x5e8>
   24316:	8b 5c 24 24          	mov    0x24(%esp),%ebx
   2431a:	29 eb                	sub    %ebp,%ebx
   2431c:	81 fb 00 01 00 00    	cmp    $0x100,%ebx
   24322:	89 d8                	mov    %ebx,%eax
   24324:	0f 87 ec 09 00 00    	ja     24d16 <vfprintf+0x1436>
   2432a:	89 44 24 08          	mov    %eax,0x8(%esp)
   2432e:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24335:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   2433c:	00 
   2433d:	89 04 24             	mov    %eax,(%esp)
   24340:	e8 fc ff ff ff       	call   24341 <vfprintf+0xa61>
   24345:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   2434b:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24352:	0f 86 a4 0b 00 00    	jbe    24efc <vfprintf+0x161c>
   24358:	8b 00                	mov    (%eax),%eax
   2435a:	89 df                	mov    %ebx,%edi
   2435c:	8b ac 24 b0 02 00 00 	mov    0x2b0(%esp),%ebp
   24363:	eb 15                	jmp    2437a <vfprintf+0xa9a>
   24365:	8d 76 00             	lea    0x0(%esi),%esi
   24368:	81 ef 00 01 00 00    	sub    $0x100,%edi
   2436e:	81 ff ff 00 00 00    	cmp    $0xff,%edi
   24374:	0f 86 46 09 00 00    	jbe    24cc0 <vfprintf+0x13e0>
   2437a:	89 c2                	mov    %eax,%edx
   2437c:	83 e2 20             	and    $0x20,%edx
   2437f:	75 e7                	jne    24368 <vfprintf+0xa88>
   24381:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24388:	89 6c 24 08          	mov    %ebp,0x8(%esp)
   2438c:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   24393:	00 
   24394:	89 04 24             	mov    %eax,(%esp)
   24397:	e8 fc ff ff ff       	call   24398 <vfprintf+0xab8>
   2439c:	8b 45 00             	mov    0x0(%ebp),%eax
   2439f:	89 c2                	mov    %eax,%edx
   243a1:	83 e2 20             	and    $0x20,%edx
   243a4:	eb c2                	jmp    24368 <vfprintf+0xa88>
   243a6:	8b 44 24 68          	mov    0x68(%esp),%eax
   243aa:	85 c0                	test   %eax,%eax
   243ac:	89 84 24 b4 02 00 00 	mov    %eax,0x2b4(%esp)
   243b3:	0f 85 02 02 00 00    	jne    245bb <vfprintf+0xcdb>
   243b9:	c7 84 24 b4 02 00 00 	movl   $0x4559,0x2b4(%esp)
   243c0:	59 45 00 00 
   243c4:	e9 f2 01 00 00       	jmp    245bb <vfprintf+0xcdb>
   243c9:	8b 5c 24 34          	mov    0x34(%esp),%ebx
   243cd:	83 e3 20             	and    $0x20,%ebx
   243d0:	8b 54 24 6c          	mov    0x6c(%esp),%edx
   243d4:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   243db:	8b 44 24 68          	mov    0x68(%esp),%eax
   243df:	89 8c 24 b4 02 00 00 	mov    %ecx,0x2b4(%esp)
   243e6:	89 d1                	mov    %edx,%ecx
   243e8:	09 c1                	or     %eax,%ecx
   243ea:	0f 84 fe 08 00 00    	je     24cee <vfprintf+0x140e>
   243f0:	89 dd                	mov    %ebx,%ebp
   243f2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   243f8:	89 c3                	mov    %eax,%ebx
   243fa:	89 e9                	mov    %ebp,%ecx
   243fc:	83 e3 0f             	and    $0xf,%ebx
   243ff:	0a 8b a8 3a 00 00    	or     0x3aa8(%ebx),%cl
   24405:	83 ac 24 b4 02 00 00 	subl   $0x1,0x2b4(%esp)
   2440c:	01 
   2440d:	0f ac d0 04          	shrd   $0x4,%edx,%eax
   24411:	89 cb                	mov    %ecx,%ebx
   24413:	8b 8c 24 b4 02 00 00 	mov    0x2b4(%esp),%ecx
   2441a:	c1 ea 04             	shr    $0x4,%edx
   2441d:	88 19                	mov    %bl,(%ecx)
   2441f:	89 d3                	mov    %edx,%ebx
   24421:	09 c3                	or     %eax,%ebx
   24423:	75 d3                	jne    243f8 <vfprintf+0xb18>
   24425:	8b 54 24 6c          	mov    0x6c(%esp),%edx
   24429:	8b 44 24 68          	mov    0x68(%esp),%eax
   2442d:	89 d3                	mov    %edx,%ebx
   2442f:	09 c3                	or     %eax,%ebx
   24431:	0f 84 b7 08 00 00    	je     24cee <vfprintf+0x140e>
   24437:	8b 5c 24 2c          	mov    0x2c(%esp),%ebx
   2443b:	83 e3 08             	and    $0x8,%ebx
   2443e:	89 5c 24 38          	mov    %ebx,0x38(%esp)
   24442:	0f 84 1a 09 00 00    	je     24d62 <vfprintf+0x1482>
   24448:	8b 6c 24 34          	mov    0x34(%esp),%ebp
   2444c:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   24453:	c7 44 24 38 02 00 00 	movl   $0x2,0x38(%esp)
   2445a:	00 
   2445b:	c7 44 24 20 02 00 00 	movl   $0x2,0x20(%esp)
   24462:	00 
   24463:	c1 fd 04             	sar    $0x4,%ebp
   24466:	8d 9d 4f 45 00 00    	lea    0x454f(%ebp),%ebx
   2446c:	89 5c 24 34          	mov    %ebx,0x34(%esp)
   24470:	e9 a6 fd ff ff       	jmp    2421b <vfprintf+0x93b>
   24475:	8b 44 24 68          	mov    0x68(%esp),%eax
   24479:	8d 6c 24 60          	lea    0x60(%esp),%ebp
   2447d:	bb ff ff ff ff       	mov    $0xffffffff,%ebx
   24482:	c7 44 24 64 00 00 00 	movl   $0x0,0x64(%esp)
   24489:	00 
   2448a:	89 6c 24 68          	mov    %ebp,0x68(%esp)
   2448e:	89 44 24 60          	mov    %eax,0x60(%esp)
   24492:	e9 3f fc ff ff       	jmp    240d6 <vfprintf+0x7f6>
   24497:	8b 44 24 34          	mov    0x34(%esp),%eax
   2449b:	89 fa                	mov    %edi,%edx
   2449d:	db 6c 24 68          	fldt   0x68(%esp)
   244a1:	8b 4c 24 30          	mov    0x30(%esp),%ecx
   244a5:	89 44 24 10          	mov    %eax,0x10(%esp)
   244a9:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   244ad:	db 3c 24             	fstpt  (%esp)
   244b0:	89 44 24 0c          	mov    %eax,0xc(%esp)
   244b4:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   244bb:	e8 e0 d9 ff ff       	call   21ea0 <fmt_fp>
   244c0:	89 44 24 24          	mov    %eax,0x24(%esp)
   244c4:	e9 ff f9 ff ff       	jmp    23ec8 <vfprintf+0x5e8>
   244c9:	8b 44 24 30          	mov    0x30(%esp),%eax
   244cd:	83 f8 08             	cmp    $0x8,%eax
   244d0:	0f 82 82 08 00 00    	jb     24d58 <vfprintf+0x1478>
   244d6:	89 44 24 30          	mov    %eax,0x30(%esp)
   244da:	bb 20 00 00 00       	mov    $0x20,%ebx
   244df:	83 4c 24 2c 08       	orl    $0x8,0x2c(%esp)
   244e4:	c7 44 24 34 78 00 00 	movl   $0x78,0x34(%esp)
   244eb:	00 
   244ec:	e9 df fe ff ff       	jmp    243d0 <vfprintf+0xaf0>
   244f1:	8b 54 24 6c          	mov    0x6c(%esp),%edx
   244f5:	8b 44 24 68          	mov    0x68(%esp),%eax
   244f9:	89 d3                	mov    %edx,%ebx
   244fb:	09 c3                	or     %eax,%ebx
   244fd:	0f 84 57 0a 00 00    	je     24f5a <vfprintf+0x167a>
   24503:	8d 9c 24 c8 00 00 00 	lea    0xc8(%esp),%ebx
   2450a:	89 9c 24 b4 02 00 00 	mov    %ebx,0x2b4(%esp)
   24511:	89 d9                	mov    %ebx,%ecx
   24513:	90                   	nop
   24514:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   24518:	89 c3                	mov    %eax,%ebx
   2451a:	83 e9 01             	sub    $0x1,%ecx
   2451d:	83 e3 07             	and    $0x7,%ebx
   24520:	83 c3 30             	add    $0x30,%ebx
   24523:	0f ac d0 03          	shrd   $0x3,%edx,%eax
   24527:	c1 ea 03             	shr    $0x3,%edx
   2452a:	88 19                	mov    %bl,(%ecx)
   2452c:	89 d3                	mov    %edx,%ebx
   2452e:	09 c3                	or     %eax,%ebx
   24530:	75 e6                	jne    24518 <vfprintf+0xc38>
   24532:	8b 44 24 68          	mov    0x68(%esp),%eax
   24536:	8b 54 24 6c          	mov    0x6c(%esp),%edx
   2453a:	89 8c 24 b4 02 00 00 	mov    %ecx,0x2b4(%esp)
   24541:	8b 5c 24 2c          	mov    0x2c(%esp),%ebx
   24545:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   2454c:	83 e3 08             	and    $0x8,%ebx
   2454f:	89 5c 24 38          	mov    %ebx,0x38(%esp)
   24553:	0f 84 ea 07 00 00    	je     24d43 <vfprintf+0x1463>
   24559:	2b 8c 24 b4 02 00 00 	sub    0x2b4(%esp),%ecx
   24560:	39 4c 24 30          	cmp    %ecx,0x30(%esp)
   24564:	0f 8f ca 07 00 00    	jg     24d34 <vfprintf+0x1454>
   2456a:	8d 59 01             	lea    0x1(%ecx),%ebx
   2456d:	89 5c 24 30          	mov    %ebx,0x30(%esp)
   24571:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   24578:	c7 44 24 38 00 00 00 	movl   $0x0,0x38(%esp)
   2457f:	00 
   24580:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   24587:	00 
   24588:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   2458f:	00 
   24590:	e9 86 fc ff ff       	jmp    2421b <vfprintf+0x93b>
   24595:	83 fd 07             	cmp    $0x7,%ebp
   24598:	0f 87 2a f9 ff ff    	ja     23ec8 <vfprintf+0x5e8>
   2459e:	ff 24 ad 88 3a 00 00 	jmp    *0x3a88(,%ebp,4)
   245a5:	e8 fc ff ff ff       	call   245a6 <vfprintf+0xcc6>
   245aa:	8b 00                	mov    (%eax),%eax
   245ac:	89 04 24             	mov    %eax,(%esp)
   245af:	e8 fc ff ff ff       	call   245b0 <vfprintf+0xcd0>
   245b4:	89 84 24 b4 02 00 00 	mov    %eax,0x2b4(%esp)
   245bb:	8b 44 24 30          	mov    0x30(%esp),%eax
   245bf:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   245c6:	00 
   245c7:	89 44 24 08          	mov    %eax,0x8(%esp)
   245cb:	8b 84 24 b4 02 00 00 	mov    0x2b4(%esp),%eax
   245d2:	89 04 24             	mov    %eax,(%esp)
   245d5:	e8 fc ff ff ff       	call   245d6 <vfprintf+0xcf6>
   245da:	8b 4c 24 30          	mov    0x30(%esp),%ecx
   245de:	85 c0                	test   %eax,%eax
   245e0:	74 0d                	je     245ef <vfprintf+0xd0f>
   245e2:	2b 84 24 b4 02 00 00 	sub    0x2b4(%esp),%eax
   245e9:	89 44 24 30          	mov    %eax,0x30(%esp)
   245ed:	89 c1                	mov    %eax,%ecx
   245ef:	81 64 24 2c ff ff fe 	andl   $0xfffeffff,0x2c(%esp)
   245f6:	ff 
   245f7:	3b 4c 24 30          	cmp    0x30(%esp),%ecx
   245fb:	89 4c 24 4c          	mov    %ecx,0x4c(%esp)
   245ff:	89 4c 24 1c          	mov    %ecx,0x1c(%esp)
   24603:	7d 08                	jge    2460d <vfprintf+0xd2d>
   24605:	8b 44 24 30          	mov    0x30(%esp),%eax
   24609:	89 44 24 1c          	mov    %eax,0x1c(%esp)
   2460d:	c7 44 24 38 00 00 00 	movl   $0x0,0x38(%esp)
   24614:	00 
   24615:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   2461c:	00 
   2461d:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   24624:	00 
   24625:	e9 3e fc ff ff       	jmp    24268 <vfprintf+0x988>
   2462a:	8b 54 24 6c          	mov    0x6c(%esp),%edx
   2462e:	8b 44 24 68          	mov    0x68(%esp),%eax
   24632:	85 d2                	test   %edx,%edx
   24634:	0f 88 63 07 00 00    	js     24d9d <vfprintf+0x14bd>
   2463a:	f7 44 24 2c 00 08 00 	testl  $0x800,0x2c(%esp)
   24641:	00 
   24642:	0f 85 d7 07 00 00    	jne    24e1f <vfprintf+0x153f>
   24648:	8b 5c 24 2c          	mov    0x2c(%esp),%ebx
   2464c:	89 c5                	mov    %eax,%ebp
   2464e:	83 e3 01             	and    $0x1,%ebx
   24651:	89 5c 24 38          	mov    %ebx,0x38(%esp)
   24655:	89 d3                	mov    %edx,%ebx
   24657:	0f 84 3f 08 00 00    	je     24e9c <vfprintf+0x15bc>
   2465d:	c7 44 24 38 01 00 00 	movl   $0x1,0x38(%esp)
   24664:	00 
   24665:	c7 44 24 20 01 00 00 	movl   $0x1,0x20(%esp)
   2466c:	00 
   2466d:	c7 44 24 34 02 00 00 	movl   $0x2,0x34(%esp)
   24674:	00 
   24675:	e9 dc fa ff ff       	jmp    24156 <vfprintf+0x876>
   2467a:	8b 44 24 68          	mov    0x68(%esp),%eax
   2467e:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   24685:	81 64 24 2c ff ff fe 	andl   $0xfffeffff,0x2c(%esp)
   2468c:	ff 
   2468d:	88 84 24 c7 00 00 00 	mov    %al,0xc7(%esp)
   24694:	8d 84 24 c7 00 00 00 	lea    0xc7(%esp),%eax
   2469b:	29 c1                	sub    %eax,%ecx
   2469d:	85 c9                	test   %ecx,%ecx
   2469f:	89 4c 24 4c          	mov    %ecx,0x4c(%esp)
   246a3:	89 4c 24 1c          	mov    %ecx,0x1c(%esp)
   246a7:	0f 8e 37 07 00 00    	jle    24de4 <vfprintf+0x1504>
   246ad:	c7 44 24 38 00 00 00 	movl   $0x0,0x38(%esp)
   246b4:	00 
   246b5:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   246bc:	00 
   246bd:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   246c4:	00 
   246c5:	89 84 24 b4 02 00 00 	mov    %eax,0x2b4(%esp)
   246cc:	e9 97 fb ff ff       	jmp    24268 <vfprintf+0x988>
   246d1:	8b 44 24 30          	mov    0x30(%esp),%eax
   246d5:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   246dc:	2b 8c 24 b4 02 00 00 	sub    0x2b4(%esp),%ecx
   246e3:	39 c8                	cmp    %ecx,%eax
   246e5:	89 4c 24 4c          	mov    %ecx,0x4c(%esp)
   246e9:	89 44 24 1c          	mov    %eax,0x1c(%esp)
   246ed:	0f 8d 1a ff ff ff    	jge    2460d <vfprintf+0xd2d>
   246f3:	89 4c 24 1c          	mov    %ecx,0x1c(%esp)
   246f7:	e9 11 ff ff ff       	jmp    2460d <vfprintf+0xd2d>
   246fc:	2b 8c 24 b4 02 00 00 	sub    0x2b4(%esp),%ecx
   24703:	3b 4c 24 30          	cmp    0x30(%esp),%ecx
   24707:	89 4c 24 4c          	mov    %ecx,0x4c(%esp)
   2470b:	89 cb                	mov    %ecx,%ebx
   2470d:	7d 04                	jge    24713 <vfprintf+0xe33>
   2470f:	8b 5c 24 30          	mov    0x30(%esp),%ebx
   24713:	09 d0                	or     %edx,%eax
   24715:	0f 94 c0             	sete   %al
   24718:	0f b6 c0             	movzbl %al,%eax
   2471b:	01 c8                	add    %ecx,%eax
   2471d:	39 c3                	cmp    %eax,%ebx
   2471f:	89 5c 24 1c          	mov    %ebx,0x1c(%esp)
   24723:	0f 8d 3f fb ff ff    	jge    24268 <vfprintf+0x988>
   24729:	89 44 24 1c          	mov    %eax,0x1c(%esp)
   2472d:	e9 36 fb ff ff       	jmp    24268 <vfprintf+0x988>
   24732:	8b 5c 24 20          	mov    0x20(%esp),%ebx
   24736:	85 db                	test   %ebx,%ebx
   24738:	0f 89 03 f3 ff ff    	jns    23a41 <vfprintf+0x161>
   2473e:	89 c3                	mov    %eax,%ebx
   24740:	e9 db f1 ff ff       	jmp    23920 <vfprintf+0x40>
   24745:	89 c2                	mov    %eax,%edx
   24747:	e9 8f f5 ff ff       	jmp    23cdb <vfprintf+0x3fb>
   2474c:	80 7c 24 20 14       	cmpb   $0x14,0x20(%esp)
   24751:	89 44 24 34          	mov    %eax,0x34(%esp)
   24755:	0f 87 f5 f7 ff ff    	ja     23f50 <vfprintf+0x670>
   2475b:	8d 44 24 68          	lea    0x68(%esp),%eax
   2475f:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   24763:	e8 78 d5 ff ff       	call   21ce0 <pop_arg.part.0>
   24768:	0f be 03             	movsbl (%ebx),%eax
   2476b:	88 44 24 1c          	mov    %al,0x1c(%esp)
   2476f:	e9 f8 f8 ff ff       	jmp    2406c <vfprintf+0x78c>
   24774:	c7 44 24 2c 00 00 00 	movl   $0x0,0x2c(%esp)
   2477b:	00 
   2477c:	e9 ef f5 ff ff       	jmp    23d70 <vfprintf+0x490>
   24781:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24788:	89 4c 24 20          	mov    %ecx,0x20(%esp)
   2478c:	89 44 24 08          	mov    %eax,0x8(%esp)
   24790:	8b 44 24 38          	mov    0x38(%esp),%eax
   24794:	89 44 24 04          	mov    %eax,0x4(%esp)
   24798:	8b 44 24 34          	mov    0x34(%esp),%eax
   2479c:	89 04 24             	mov    %eax,(%esp)
   2479f:	e8 fc ff ff ff       	call   247a0 <vfprintf+0xec0>
   247a4:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   247a8:	e9 f7 fa ff ff       	jmp    242a4 <vfprintf+0x9c4>
   247ad:	8b 5c 24 1c          	mov    0x1c(%esp),%ebx
   247b1:	29 cb                	sub    %ecx,%ebx
   247b3:	81 fb 00 01 00 00    	cmp    $0x100,%ebx
   247b9:	89 d8                	mov    %ebx,%eax
   247bb:	76 05                	jbe    247c2 <vfprintf+0xee2>
   247bd:	b8 00 01 00 00       	mov    $0x100,%eax
   247c2:	89 44 24 08          	mov    %eax,0x8(%esp)
   247c6:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   247cd:	c7 44 24 04 30 00 00 	movl   $0x30,0x4(%esp)
   247d4:	00 
   247d5:	89 04 24             	mov    %eax,(%esp)
   247d8:	e8 fc ff ff ff       	call   247d9 <vfprintf+0xef9>
   247dd:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   247e3:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   247ea:	0f 86 a2 06 00 00    	jbe    24e92 <vfprintf+0x15b2>
   247f0:	8b 00                	mov    (%eax),%eax
   247f2:	89 5c 24 1c          	mov    %ebx,0x1c(%esp)
   247f6:	8b bc 24 b0 02 00 00 	mov    0x2b0(%esp),%edi
   247fd:	eb 0f                	jmp    2480e <vfprintf+0xf2e>
   247ff:	90                   	nop
   24800:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   24806:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   2480c:	76 37                	jbe    24845 <vfprintf+0xf65>
   2480e:	89 c2                	mov    %eax,%edx
   24810:	83 e2 20             	and    $0x20,%edx
   24813:	75 eb                	jne    24800 <vfprintf+0xf20>
   24815:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   2481c:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   24822:	89 7c 24 08          	mov    %edi,0x8(%esp)
   24826:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   2482d:	00 
   2482e:	89 04 24             	mov    %eax,(%esp)
   24831:	e8 fc ff ff ff       	call   24832 <vfprintf+0xf52>
   24836:	8b 07                	mov    (%edi),%eax
   24838:	89 c2                	mov    %eax,%edx
   2483a:	83 e2 20             	and    $0x20,%edx
   2483d:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   24843:	77 c9                	ja     2480e <vfprintf+0xf2e>
   24845:	8b 5c 24 1c          	mov    0x1c(%esp),%ebx
   24849:	0f b6 db             	movzbl %bl,%ebx
   2484c:	85 d2                	test   %edx,%edx
   2484e:	0f 85 a6 fa ff ff    	jne    242fa <vfprintf+0xa1a>
   24854:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   2485b:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   2485f:	89 44 24 08          	mov    %eax,0x8(%esp)
   24863:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   2486a:	89 04 24             	mov    %eax,(%esp)
   2486d:	e8 fc ff ff ff       	call   2486e <vfprintf+0xf8e>
   24872:	e9 51 fa ff ff       	jmp    242c8 <vfprintf+0x9e8>
   24877:	0f be 43 02          	movsbl 0x2(%ebx),%eax
   2487b:	8d 50 d0             	lea    -0x30(%eax),%edx
   2487e:	83 fa 09             	cmp    $0x9,%edx
   24881:	77 0a                	ja     2488d <vfprintf+0xfad>
   24883:	80 7b 03 24          	cmpb   $0x24,0x3(%ebx)
   24887:	0f 84 b3 05 00 00    	je     24e40 <vfprintf+0x1560>
   2488d:	8b 4c 24 48          	mov    0x48(%esp),%ecx
   24891:	85 c9                	test   %ecx,%ecx
   24893:	0f 85 5a f5 ff ff    	jne    23df3 <vfprintf+0x513>
   24899:	8b 44 24 58          	mov    0x58(%esp),%eax
   2489d:	83 c3 02             	add    $0x2,%ebx
   248a0:	8d 50 04             	lea    0x4(%eax),%edx
   248a3:	8b 00                	mov    (%eax),%eax
   248a5:	89 54 24 58          	mov    %edx,0x58(%esp)
   248a9:	89 44 24 30          	mov    %eax,0x30(%esp)
   248ad:	e9 03 f5 ff ff       	jmp    23db5 <vfprintf+0x4d5>
   248b2:	81 4c 24 2c 00 20 00 	orl    $0x2000,0x2c(%esp)
   248b9:	00 
   248ba:	f7 df                	neg    %edi
   248bc:	e9 09 f7 ff ff       	jmp    23fca <vfprintf+0x6ea>
   248c1:	0f be 50 02          	movsbl 0x2(%eax),%edx
   248c5:	8d 4a d0             	lea    -0x30(%edx),%ecx
   248c8:	83 f9 09             	cmp    $0x9,%ecx
   248cb:	77 0a                	ja     248d7 <vfprintf+0xff7>
   248cd:	80 78 03 24          	cmpb   $0x24,0x3(%eax)
   248d1:	0f 84 b6 04 00 00    	je     24d8d <vfprintf+0x14ad>
   248d7:	8b 74 24 24          	mov    0x24(%esp),%esi
   248db:	85 f6                	test   %esi,%esi
   248dd:	0f 85 5e f1 ff ff    	jne    23a41 <vfprintf+0x161>
   248e3:	83 c0 02             	add    $0x2,%eax
   248e6:	e9 2e f1 ff ff       	jmp    23a19 <vfprintf+0x139>
   248eb:	0f b6 44 24 1c       	movzbl 0x1c(%esp),%eax
   248f0:	83 e0 df             	and    $0xffffffdf,%eax
   248f3:	0f be c0             	movsbl %al,%eax
   248f6:	89 44 24 34          	mov    %eax,0x34(%esp)
   248fa:	e9 65 f6 ff ff       	jmp    23f64 <vfprintf+0x684>
   248ff:	0f b6 56 03          	movzbl 0x3(%esi),%edx
   24903:	8d 5e 03             	lea    0x3(%esi),%ebx
   24906:	89 4c 24 38          	mov    %ecx,0x38(%esp)
   2490a:	c7 44 24 48 01 00 00 	movl   $0x1,0x48(%esp)
   24911:	00 
   24912:	0f be c2             	movsbl %dl,%eax
   24915:	e9 0c f4 ff ff       	jmp    23d26 <vfprintf+0x446>
   2491a:	89 7c 24 1c          	mov    %edi,0x1c(%esp)
   2491e:	8b 74 24 30          	mov    0x30(%esp),%esi
   24922:	8b 7c 24 20          	mov    0x20(%esp),%edi
   24926:	89 6c 24 24          	mov    %ebp,0x24(%esp)
   2492a:	f7 44 24 2c 00 20 01 	testl  $0x12000,0x2c(%esp)
   24931:	00 
   24932:	74 62                	je     24996 <vfprintf+0x10b6>
   24934:	8b 6c 24 68          	mov    0x68(%esp),%ebp
   24938:	31 db                	xor    %ebx,%ebx
   2493a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   24940:	39 5c 24 1c          	cmp    %ebx,0x1c(%esp)
   24944:	0f 86 e6 00 00 00    	jbe    24a30 <vfprintf+0x1150>
   2494a:	8b 45 00             	mov    0x0(%ebp),%eax
   2494d:	85 c0                	test   %eax,%eax
   2494f:	0f 84 db 00 00 00    	je     24a30 <vfprintf+0x1150>
   24955:	89 44 24 04          	mov    %eax,0x4(%esp)
   24959:	8d 44 24 5c          	lea    0x5c(%esp),%eax
   2495d:	83 c5 04             	add    $0x4,%ebp
   24960:	89 04 24             	mov    %eax,(%esp)
   24963:	e8 fc ff ff ff       	call   24964 <vfprintf+0x1084>
   24968:	01 c3                	add    %eax,%ebx
   2496a:	3b 5c 24 24          	cmp    0x24(%esp),%ebx
   2496e:	0f 8f bc 00 00 00    	jg     24a30 <vfprintf+0x1150>
   24974:	8b 8c 24 b0 02 00 00 	mov    0x2b0(%esp),%ecx
   2497b:	f6 01 20             	testb  $0x20,(%ecx)
   2497e:	75 c0                	jne    24940 <vfprintf+0x1060>
   24980:	89 44 24 04          	mov    %eax,0x4(%esp)
   24984:	8d 44 24 5c          	lea    0x5c(%esp),%eax
   24988:	89 4c 24 08          	mov    %ecx,0x8(%esp)
   2498c:	89 04 24             	mov    %eax,(%esp)
   2498f:	e8 fc ff ff ff       	call   24990 <vfprintf+0x10b0>
   24994:	eb aa                	jmp    24940 <vfprintf+0x1060>
   24996:	3b 7c 24 24          	cmp    0x24(%esp),%edi
   2499a:	7e 98                	jle    24934 <vfprintf+0x1054>
   2499c:	89 fd                	mov    %edi,%ebp
   2499e:	2b 6c 24 24          	sub    0x24(%esp),%ebp
   249a2:	81 fd 00 01 00 00    	cmp    $0x100,%ebp
   249a8:	89 e8                	mov    %ebp,%eax
   249aa:	76 05                	jbe    249b1 <vfprintf+0x10d1>
   249ac:	b8 00 01 00 00       	mov    $0x100,%eax
   249b1:	89 44 24 08          	mov    %eax,0x8(%esp)
   249b5:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   249bc:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   249c3:	00 
   249c4:	89 04 24             	mov    %eax,(%esp)
   249c7:	e8 fc ff ff ff       	call   249c8 <vfprintf+0x10e8>
   249cc:	81 fd ff 00 00 00    	cmp    $0xff,%ebp
   249d2:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   249d9:	0f 86 e6 05 00 00    	jbe    24fc5 <vfprintf+0x16e5>
   249df:	8b 00                	mov    (%eax),%eax
   249e1:	89 eb                	mov    %ebp,%ebx
   249e3:	eb 12                	jmp    249f7 <vfprintf+0x1117>
   249e5:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   249eb:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   249f1:	0f 86 6b 04 00 00    	jbe    24e62 <vfprintf+0x1582>
   249f7:	89 c2                	mov    %eax,%edx
   249f9:	83 e2 20             	and    $0x20,%edx
   249fc:	75 e7                	jne    249e5 <vfprintf+0x1105>
   249fe:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24a05:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   24a0c:	00 
   24a0d:	89 44 24 08          	mov    %eax,0x8(%esp)
   24a11:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24a18:	89 04 24             	mov    %eax,(%esp)
   24a1b:	e8 fc ff ff ff       	call   24a1c <vfprintf+0x113c>
   24a20:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24a27:	8b 00                	mov    (%eax),%eax
   24a29:	89 c2                	mov    %eax,%edx
   24a2b:	83 e2 20             	and    $0x20,%edx
   24a2e:	eb b5                	jmp    249e5 <vfprintf+0x1105>
   24a30:	8b 44 24 2c          	mov    0x2c(%esp),%eax
   24a34:	80 f4 20             	xor    $0x20,%ah
   24a37:	a9 00 20 01 00       	test   $0x12000,%eax
   24a3c:	0f 85 79 f4 ff ff    	jne    23ebb <vfprintf+0x5db>
   24a42:	3b 7c 24 24          	cmp    0x24(%esp),%edi
   24a46:	0f 8e 6f f4 ff ff    	jle    23ebb <vfprintf+0x5db>
   24a4c:	89 fd                	mov    %edi,%ebp
   24a4e:	2b 6c 24 24          	sub    0x24(%esp),%ebp
   24a52:	81 fd 00 01 00 00    	cmp    $0x100,%ebp
   24a58:	89 e8                	mov    %ebp,%eax
   24a5a:	76 05                	jbe    24a61 <vfprintf+0x1181>
   24a5c:	b8 00 01 00 00       	mov    $0x100,%eax
   24a61:	89 44 24 08          	mov    %eax,0x8(%esp)
   24a65:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24a6c:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   24a73:	00 
   24a74:	89 04 24             	mov    %eax,(%esp)
   24a77:	e8 fc ff ff ff       	call   24a78 <vfprintf+0x1198>
   24a7c:	81 fd ff 00 00 00    	cmp    $0xff,%ebp
   24a82:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24a89:	0f 86 09 05 00 00    	jbe    24f98 <vfprintf+0x16b8>
   24a8f:	8b 00                	mov    (%eax),%eax
   24a91:	89 eb                	mov    %ebp,%ebx
   24a93:	eb 12                	jmp    24aa7 <vfprintf+0x11c7>
   24a95:	81 eb 00 01 00 00    	sub    $0x100,%ebx
   24a9b:	81 fb ff 00 00 00    	cmp    $0xff,%ebx
   24aa1:	0f 86 ed f3 ff ff    	jbe    23e94 <vfprintf+0x5b4>
   24aa7:	89 c2                	mov    %eax,%edx
   24aa9:	83 e2 20             	and    $0x20,%edx
   24aac:	75 e7                	jne    24a95 <vfprintf+0x11b5>
   24aae:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24ab5:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   24abc:	00 
   24abd:	89 44 24 08          	mov    %eax,0x8(%esp)
   24ac1:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24ac8:	89 04 24             	mov    %eax,(%esp)
   24acb:	e8 fc ff ff ff       	call   24acc <vfprintf+0x11ec>
   24ad0:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24ad7:	8b 00                	mov    (%eax),%eax
   24ad9:	89 c2                	mov    %eax,%edx
   24adb:	83 e2 20             	and    $0x20,%edx
   24ade:	eb b5                	jmp    24a95 <vfprintf+0x11b5>
   24ae0:	8b 7c 24 24          	mov    0x24(%esp),%edi
   24ae4:	29 ef                	sub    %ebp,%edi
   24ae6:	81 ff 00 01 00 00    	cmp    $0x100,%edi
   24aec:	89 f8                	mov    %edi,%eax
   24aee:	0f 87 36 02 00 00    	ja     24d2a <vfprintf+0x144a>
   24af4:	89 44 24 08          	mov    %eax,0x8(%esp)
   24af8:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24aff:	c7 44 24 04 20 00 00 	movl   $0x20,0x4(%esp)
   24b06:	00 
   24b07:	89 04 24             	mov    %eax,(%esp)
   24b0a:	89 4c 24 20          	mov    %ecx,0x20(%esp)
   24b0e:	e8 fc ff ff ff       	call   24b0f <vfprintf+0x122f>
   24b13:	81 ff ff 00 00 00    	cmp    $0xff,%edi
   24b19:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24b20:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   24b24:	0f 86 b3 03 00 00    	jbe    24edd <vfprintf+0x15fd>
   24b2a:	89 74 24 30          	mov    %esi,0x30(%esp)
   24b2e:	8b 10                	mov    (%eax),%edx
   24b30:	89 fe                	mov    %edi,%esi
   24b32:	89 4c 24 20          	mov    %ecx,0x20(%esp)
   24b36:	89 c3                	mov    %eax,%ebx
   24b38:	eb 18                	jmp    24b52 <vfprintf+0x1272>
   24b3a:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   24b40:	81 ee 00 01 00 00    	sub    $0x100,%esi
   24b46:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   24b4c:	0f 86 22 01 00 00    	jbe    24c74 <vfprintf+0x1394>
   24b52:	89 d0                	mov    %edx,%eax
   24b54:	83 e0 20             	and    $0x20,%eax
   24b57:	75 e7                	jne    24b40 <vfprintf+0x1260>
   24b59:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24b60:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   24b64:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   24b6b:	00 
   24b6c:	89 04 24             	mov    %eax,(%esp)
   24b6f:	e8 fc ff ff ff       	call   24b70 <vfprintf+0x1290>
   24b74:	8b 13                	mov    (%ebx),%edx
   24b76:	89 d0                	mov    %edx,%eax
   24b78:	83 e0 20             	and    $0x20,%eax
   24b7b:	eb c3                	jmp    24b40 <vfprintf+0x1260>
   24b7d:	8b 7c 24 24          	mov    0x24(%esp),%edi
   24b81:	29 ef                	sub    %ebp,%edi
   24b83:	81 ff 00 01 00 00    	cmp    $0x100,%edi
   24b89:	89 f8                	mov    %edi,%eax
   24b8b:	0f 87 8f 01 00 00    	ja     24d20 <vfprintf+0x1440>
   24b91:	89 44 24 08          	mov    %eax,0x8(%esp)
   24b95:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24b9c:	c7 44 24 04 30 00 00 	movl   $0x30,0x4(%esp)
   24ba3:	00 
   24ba4:	89 04 24             	mov    %eax,(%esp)
   24ba7:	89 4c 24 20          	mov    %ecx,0x20(%esp)
   24bab:	e8 fc ff ff ff       	call   24bac <vfprintf+0x12cc>
   24bb0:	81 ff ff 00 00 00    	cmp    $0xff,%edi
   24bb6:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24bbd:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   24bc1:	0f 86 ff 02 00 00    	jbe    24ec6 <vfprintf+0x15e6>
   24bc7:	89 74 24 30          	mov    %esi,0x30(%esp)
   24bcb:	8b 00                	mov    (%eax),%eax
   24bcd:	89 fe                	mov    %edi,%esi
   24bcf:	89 4c 24 20          	mov    %ecx,0x20(%esp)
   24bd3:	8b 9c 24 b0 02 00 00 	mov    0x2b0(%esp),%ebx
   24bda:	eb 12                	jmp    24bee <vfprintf+0x130e>
   24bdc:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   24be0:	81 ee 00 01 00 00    	sub    $0x100,%esi
   24be6:	81 fe ff 00 00 00    	cmp    $0xff,%esi
   24bec:	76 46                	jbe    24c34 <vfprintf+0x1354>
   24bee:	89 c2                	mov    %eax,%edx
   24bf0:	83 e2 20             	and    $0x20,%edx
   24bf3:	75 eb                	jne    24be0 <vfprintf+0x1300>
   24bf5:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24bfc:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   24c00:	c7 44 24 04 00 01 00 	movl   $0x100,0x4(%esp)
   24c07:	00 
   24c08:	89 04 24             	mov    %eax,(%esp)
   24c0b:	e8 fc ff ff ff       	call   24c0c <vfprintf+0x132c>
   24c10:	8b 03                	mov    (%ebx),%eax
   24c12:	89 c2                	mov    %eax,%edx
   24c14:	83 e2 20             	and    $0x20,%edx
   24c17:	eb c7                	jmp    24be0 <vfprintf+0x1300>
   24c19:	0f b6 48 03          	movzbl 0x3(%eax),%ecx
   24c1d:	83 c0 03             	add    $0x3,%eax
   24c20:	89 5c 24 20          	mov    %ebx,0x20(%esp)
   24c24:	c7 44 24 24 01 00 00 	movl   $0x1,0x24(%esp)
   24c2b:	00 
   24c2c:	0f be d1             	movsbl %cl,%edx
   24c2f:	e9 87 ed ff ff       	jmp    239bb <vfprintf+0xdb>
   24c34:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   24c38:	89 f8                	mov    %edi,%eax
   24c3a:	8b 74 24 30          	mov    0x30(%esp),%esi
   24c3e:	0f b6 f8             	movzbl %al,%edi
   24c41:	85 d2                	test   %edx,%edx
   24c43:	0f 85 75 f6 ff ff    	jne    242be <vfprintf+0x9de>
   24c49:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24c50:	89 7c 24 04          	mov    %edi,0x4(%esp)
   24c54:	89 4c 24 20          	mov    %ecx,0x20(%esp)
   24c58:	89 44 24 08          	mov    %eax,0x8(%esp)
   24c5c:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24c63:	89 04 24             	mov    %eax,(%esp)
   24c66:	e8 fc ff ff ff       	call   24c67 <vfprintf+0x1387>
   24c6b:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   24c6f:	e9 4a f6 ff ff       	jmp    242be <vfprintf+0x9de>
   24c74:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   24c78:	89 fb                	mov    %edi,%ebx
   24c7a:	8b 74 24 30          	mov    0x30(%esp),%esi
   24c7e:	0f b6 fb             	movzbl %bl,%edi
   24c81:	85 c0                	test   %eax,%eax
   24c83:	0f 85 1b f6 ff ff    	jne    242a4 <vfprintf+0x9c4>
   24c89:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24c90:	89 7c 24 04          	mov    %edi,0x4(%esp)
   24c94:	89 4c 24 20          	mov    %ecx,0x20(%esp)
   24c98:	89 44 24 08          	mov    %eax,0x8(%esp)
   24c9c:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24ca3:	89 04 24             	mov    %eax,(%esp)
   24ca6:	e8 fc ff ff ff       	call   24ca7 <vfprintf+0x13c7>
   24cab:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24cb2:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   24cb6:	8b 00                	mov    (%eax),%eax
   24cb8:	83 e0 20             	and    $0x20,%eax
   24cbb:	e9 dc f5 ff ff       	jmp    2429c <vfprintf+0x9bc>
   24cc0:	0f b6 db             	movzbl %bl,%ebx
   24cc3:	85 d2                	test   %edx,%edx
   24cc5:	0f 85 fd f1 ff ff    	jne    23ec8 <vfprintf+0x5e8>
   24ccb:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24cd2:	89 5c 24 04          	mov    %ebx,0x4(%esp)
   24cd6:	89 44 24 08          	mov    %eax,0x8(%esp)
   24cda:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24ce1:	89 04 24             	mov    %eax,(%esp)
   24ce4:	e8 fc ff ff ff       	call   24ce5 <vfprintf+0x1405>
   24ce9:	e9 da f1 ff ff       	jmp    23ec8 <vfprintf+0x5e8>
   24cee:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   24cf5:	31 c0                	xor    %eax,%eax
   24cf7:	c7 44 24 38 00 00 00 	movl   $0x0,0x38(%esp)
   24cfe:	00 
   24cff:	31 d2                	xor    %edx,%edx
   24d01:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   24d08:	00 
   24d09:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   24d10:	00 
   24d11:	e9 05 f5 ff ff       	jmp    2421b <vfprintf+0x93b>
   24d16:	b8 00 01 00 00       	mov    $0x100,%eax
   24d1b:	e9 0a f6 ff ff       	jmp    2432a <vfprintf+0xa4a>
   24d20:	b8 00 01 00 00       	mov    $0x100,%eax
   24d25:	e9 67 fe ff ff       	jmp    24b91 <vfprintf+0x12b1>
   24d2a:	b8 00 01 00 00       	mov    $0x100,%eax
   24d2f:	e9 c0 fd ff ff       	jmp    24af4 <vfprintf+0x1214>
   24d34:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   24d3b:	c7 44 24 38 00 00 00 	movl   $0x0,0x38(%esp)
   24d42:	00 
   24d43:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   24d4a:	00 
   24d4b:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   24d52:	00 
   24d53:	e9 c3 f4 ff ff       	jmp    2421b <vfprintf+0x93b>
   24d58:	b8 08 00 00 00       	mov    $0x8,%eax
   24d5d:	e9 74 f7 ff ff       	jmp    244d6 <vfprintf+0xbf6>
   24d62:	8d 8c 24 c8 00 00 00 	lea    0xc8(%esp),%ecx
   24d69:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   24d70:	00 
   24d71:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   24d78:	00 
   24d79:	e9 9d f4 ff ff       	jmp    2421b <vfprintf+0x93b>
   24d7e:	8b 44 24 68          	mov    0x68(%esp),%eax
   24d82:	8b 7c 24 28          	mov    0x28(%esp),%edi
   24d86:	89 38                	mov    %edi,(%eax)
   24d88:	e9 3b f1 ff ff       	jmp    23ec8 <vfprintf+0x5e8>
   24d8d:	c7 44 94 b4 0a 00 00 	movl   $0xa,-0x4c(%esp,%edx,4)
   24d94:	00 
   24d95:	83 c0 04             	add    $0x4,%eax
   24d98:	e9 7c ec ff ff       	jmp    23a19 <vfprintf+0x139>
   24d9d:	f7 d8                	neg    %eax
   24d9f:	83 d2 00             	adc    $0x0,%edx
   24da2:	89 c5                	mov    %eax,%ebp
   24da4:	f7 da                	neg    %edx
   24da6:	89 44 24 68          	mov    %eax,0x68(%esp)
   24daa:	89 d3                	mov    %edx,%ebx
   24dac:	89 54 24 6c          	mov    %edx,0x6c(%esp)
   24db0:	c7 44 24 38 01 00 00 	movl   $0x1,0x38(%esp)
   24db7:	00 
   24db8:	c7 44 24 20 01 00 00 	movl   $0x1,0x20(%esp)
   24dbf:	00 
   24dc0:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   24dc7:	00 
   24dc8:	e9 89 f3 ff ff       	jmp    24156 <vfprintf+0x876>
   24dcd:	8b 7c 24 28          	mov    0x28(%esp),%edi
   24dd1:	8b 44 24 68          	mov    0x68(%esp),%eax
   24dd5:	89 fd                	mov    %edi,%ebp
   24dd7:	c1 fd 1f             	sar    $0x1f,%ebp
   24dda:	89 38                	mov    %edi,(%eax)
   24ddc:	89 68 04             	mov    %ebp,0x4(%eax)
   24ddf:	e9 e4 f0 ff ff       	jmp    23ec8 <vfprintf+0x5e8>
   24de4:	c7 44 24 1c 01 00 00 	movl   $0x1,0x1c(%esp)
   24deb:	00 
   24dec:	e9 bc f8 ff ff       	jmp    246ad <vfprintf+0xdcd>
   24df1:	8b 44 24 68          	mov    0x68(%esp),%eax
   24df5:	0f b7 7c 24 28       	movzwl 0x28(%esp),%edi
   24dfa:	66 89 38             	mov    %di,(%eax)
   24dfd:	e9 c6 f0 ff ff       	jmp    23ec8 <vfprintf+0x5e8>
   24e02:	8b 44 24 68          	mov    0x68(%esp),%eax
   24e06:	0f b6 5c 24 28       	movzbl 0x28(%esp),%ebx
   24e0b:	88 18                	mov    %bl,(%eax)
   24e0d:	e9 b6 f0 ff ff       	jmp    23ec8 <vfprintf+0x5e8>
   24e12:	c7 44 24 30 00 00 00 	movl   $0x0,0x30(%esp)
   24e19:	00 
   24e1a:	e9 96 ef ff ff       	jmp    23db5 <vfprintf+0x4d5>
   24e1f:	89 c5                	mov    %eax,%ebp
   24e21:	89 d3                	mov    %edx,%ebx
   24e23:	c7 44 24 38 01 00 00 	movl   $0x1,0x38(%esp)
   24e2a:	00 
   24e2b:	c7 44 24 20 01 00 00 	movl   $0x1,0x20(%esp)
   24e32:	00 
   24e33:	c7 44 24 34 01 00 00 	movl   $0x1,0x34(%esp)
   24e3a:	00 
   24e3b:	e9 16 f3 ff ff       	jmp    24156 <vfprintf+0x876>
   24e40:	c7 44 84 b4 0a 00 00 	movl   $0xa,-0x4c(%esp,%eax,4)
   24e47:	00 
   24e48:	0f be 43 02          	movsbl 0x2(%ebx),%eax
   24e4c:	83 c3 04             	add    $0x4,%ebx
   24e4f:	8d 04 40             	lea    (%eax,%eax,2),%eax
   24e52:	8b 84 84 d8 fe ff ff 	mov    -0x128(%esp,%eax,4),%eax
   24e59:	89 44 24 30          	mov    %eax,0x30(%esp)
   24e5d:	e9 53 ef ff ff       	jmp    23db5 <vfprintf+0x4d5>
   24e62:	89 e8                	mov    %ebp,%eax
   24e64:	0f b6 e8             	movzbl %al,%ebp
   24e67:	85 d2                	test   %edx,%edx
   24e69:	0f 85 c5 fa ff ff    	jne    24934 <vfprintf+0x1054>
   24e6f:	8b 84 24 b0 02 00 00 	mov    0x2b0(%esp),%eax
   24e76:	89 6c 24 04          	mov    %ebp,0x4(%esp)
   24e7a:	89 44 24 08          	mov    %eax,0x8(%esp)
   24e7e:	8d 84 24 90 01 00 00 	lea    0x190(%esp),%eax
   24e85:	89 04 24             	mov    %eax,(%esp)
   24e88:	e8 fc ff ff ff       	call   24e89 <vfprintf+0x15a9>
   24e8d:	e9 a2 fa ff ff       	jmp    24934 <vfprintf+0x1054>
   24e92:	8b 10                	mov    (%eax),%edx
   24e94:	83 e2 20             	and    $0x20,%edx
   24e97:	e9 b0 f9 ff ff       	jmp    2484c <vfprintf+0xf6c>
   24e9c:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%esp)
   24ea3:	00 
   24ea4:	c7 44 24 34 4f 45 00 	movl   $0x454f,0x34(%esp)
   24eab:	00 
   24eac:	e9 a5 f2 ff ff       	jmp    24156 <vfprintf+0x876>
   24eb1:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   24eb5:	8d 84 24 24 01 00 00 	lea    0x124(%esp),%eax
   24ebc:	e8 1f ce ff ff       	call   21ce0 <pop_arg.part.0>
   24ec1:	e9 06 ec ff ff       	jmp    23acc <vfprintf+0x1ec>
   24ec6:	8b 10                	mov    (%eax),%edx
   24ec8:	83 e2 20             	and    $0x20,%edx
   24ecb:	e9 71 fd ff ff       	jmp    24c41 <vfprintf+0x1361>
   24ed0:	c7 44 24 1c 00 00 00 	movl   $0x0,0x1c(%esp)
   24ed7:	00 
   24ed8:	e9 4d fa ff ff       	jmp    2492a <vfprintf+0x104a>
   24edd:	8b 00                	mov    (%eax),%eax
   24edf:	83 e0 20             	and    $0x20,%eax
   24ee2:	e9 9a fd ff ff       	jmp    24c81 <vfprintf+0x13a1>
   24ee7:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   24eeb:	8d 84 24 78 01 00 00 	lea    0x178(%esp),%eax
   24ef2:	e8 e9 cd ff ff       	call   21ce0 <pop_arg.part.0>
   24ef7:	e9 8d ec ff ff       	jmp    23b89 <vfprintf+0x2a9>
   24efc:	8b 10                	mov    (%eax),%edx
   24efe:	83 e2 20             	and    $0x20,%edx
   24f01:	e9 bd fd ff ff       	jmp    24cc3 <vfprintf+0x13e3>
   24f06:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   24f0a:	8d 84 24 6c 01 00 00 	lea    0x16c(%esp),%eax
   24f11:	e8 ca cd ff ff       	call   21ce0 <pop_arg.part.0>
   24f16:	e9 56 ec ff ff       	jmp    23b71 <vfprintf+0x291>
   24f1b:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   24f1f:	8d 84 24 60 01 00 00 	lea    0x160(%esp),%eax
   24f26:	e8 b5 cd ff ff       	call   21ce0 <pop_arg.part.0>
   24f2b:	e9 29 ec ff ff       	jmp    23b59 <vfprintf+0x279>
   24f30:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   24f34:	8d 84 24 54 01 00 00 	lea    0x154(%esp),%eax
   24f3b:	e8 a0 cd ff ff       	call   21ce0 <pop_arg.part.0>
   24f40:	e9 fc eb ff ff       	jmp    23b41 <vfprintf+0x261>
   24f45:	8d 4c 24 58          	lea    0x58(%esp),%ecx
   24f49:	8d 84 24 48 01 00 00 	lea    0x148(%esp),%eax
   24f50:	e8 8b cd ff ff       	call   21ce0 <pop_arg.part.0>
   24f55:	e9 cf eb ff ff       	jmp    23b29 <vfprintf+0x249>
   24f5a:	8d 9c 24 c8 00 00 00 	lea    0xc8(%esp),%ebx
   24f61:	31 c0                	xor    %eax,%eax
   24f63:	31 d2                	xor    %edx,%edx
   24f65:	89 9c 24 b4 02 00 00 	mov    %ebx,0x2b4(%esp)
   24f6c:	e9 d0 f5 ff ff       	jmp    24541 <vfprintf+0xc61>
   24f71:	b8 09 00 00 00       	mov    $0x9,%eax
   24f76:	eb 0c                	jmp    24f84 <vfprintf+0x16a4>
   24f78:	8b 54 84 74          	mov    0x74(%esp,%eax,4),%edx
   24f7c:	85 d2                	test   %edx,%edx
   24f7e:	0f 85 bd ea ff ff    	jne    23a41 <vfprintf+0x161>
   24f84:	83 c0 01             	add    $0x1,%eax
   24f87:	83 f8 0a             	cmp    $0xa,%eax
   24f8a:	75 ec                	jne    24f78 <vfprintf+0x1698>
   24f8c:	e9 1c ec ff ff       	jmp    23bad <vfprintf+0x2cd>
   24f91:	b8 08 00 00 00       	mov    $0x8,%eax
   24f96:	eb ec                	jmp    24f84 <vfprintf+0x16a4>
   24f98:	8b 10                	mov    (%eax),%edx
   24f9a:	83 e2 20             	and    $0x20,%edx
   24f9d:	e9 f7 ee ff ff       	jmp    23e99 <vfprintf+0x5b9>
   24fa2:	b8 05 00 00 00       	mov    $0x5,%eax
   24fa7:	eb db                	jmp    24f84 <vfprintf+0x16a4>
   24fa9:	b8 04 00 00 00       	mov    $0x4,%eax
   24fae:	eb d4                	jmp    24f84 <vfprintf+0x16a4>
   24fb0:	b8 07 00 00 00       	mov    $0x7,%eax
   24fb5:	eb cd                	jmp    24f84 <vfprintf+0x16a4>
   24fb7:	b8 06 00 00 00       	mov    $0x6,%eax
   24fbc:	eb c6                	jmp    24f84 <vfprintf+0x16a4>
   24fbe:	b8 02 00 00 00       	mov    $0x2,%eax
   24fc3:	eb bf                	jmp    24f84 <vfprintf+0x16a4>
   24fc5:	8b 10                	mov    (%eax),%edx
   24fc7:	83 e2 20             	and    $0x20,%edx
   24fca:	e9 98 fe ff ff       	jmp    24e67 <vfprintf+0x1587>
   24fcf:	b8 03 00 00 00       	mov    $0x3,%eax
   24fd4:	eb ae                	jmp    24f84 <vfprintf+0x16a4>
   24fd6:	b8 01 00 00 00       	mov    $0x1,%eax
   24fdb:	eb a7                	jmp    24f84 <vfprintf+0x16a4>
   24fdd:	66 90                	xchg   %ax,%ax
   24fdf:	90                   	nop

00024fe0 <memchr>:
   24fe0:	57                   	push   %edi
   24fe1:	56                   	push   %esi
   24fe2:	53                   	push   %ebx
   24fe3:	8b 54 24 10          	mov    0x10(%esp),%edx
   24fe7:	8b 4c 24 18          	mov    0x18(%esp),%ecx
   24feb:	0f b6 5c 24 14       	movzbl 0x14(%esp),%ebx
   24ff0:	f6 c2 03             	test   $0x3,%dl
   24ff3:	75 19                	jne    2500e <memchr+0x2e>
   24ff5:	eb 21                	jmp    25018 <memchr+0x38>
   24ff7:	90                   	nop
   24ff8:	0f b6 02             	movzbl (%edx),%eax
   24ffb:	39 d8                	cmp    %ebx,%eax
   24ffd:	0f 84 9d 00 00 00    	je     250a0 <memchr+0xc0>
   25003:	83 c2 01             	add    $0x1,%edx
   25006:	83 e9 01             	sub    $0x1,%ecx
   25009:	f6 c2 03             	test   $0x3,%dl
   2500c:	74 0a                	je     25018 <memchr+0x38>
   2500e:	85 c9                	test   %ecx,%ecx
   25010:	75 e6                	jne    24ff8 <memchr+0x18>
   25012:	31 c0                	xor    %eax,%eax
   25014:	5b                   	pop    %ebx
   25015:	5e                   	pop    %esi
   25016:	5f                   	pop    %edi
   25017:	c3                   	ret    
   25018:	31 c0                	xor    %eax,%eax
   2501a:	85 c9                	test   %ecx,%ecx
   2501c:	74 f6                	je     25014 <memchr+0x34>
   2501e:	0f b6 02             	movzbl (%edx),%eax
   25021:	39 c3                	cmp    %eax,%ebx
   25023:	74 7b                	je     250a0 <memchr+0xc0>
   25025:	69 fb 01 01 01 01    	imul   $0x1010101,%ebx,%edi
   2502b:	83 f9 03             	cmp    $0x3,%ecx
   2502e:	76 44                	jbe    25074 <memchr+0x94>
   25030:	8b 32                	mov    (%edx),%esi
   25032:	31 fe                	xor    %edi,%esi
   25034:	89 f0                	mov    %esi,%eax
   25036:	81 ee 01 01 01 01    	sub    $0x1010101,%esi
   2503c:	f7 d0                	not    %eax
   2503e:	21 f0                	and    %esi,%eax
   25040:	a9 80 80 80 80       	test   $0x80808080,%eax
   25045:	74 1e                	je     25065 <memchr+0x85>
   25047:	eb 2b                	jmp    25074 <memchr+0x94>
   25049:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25050:	8b 32                	mov    (%edx),%esi
   25052:	31 fe                	xor    %edi,%esi
   25054:	8d 86 ff fe fe fe    	lea    -0x1010101(%esi),%eax
   2505a:	f7 d6                	not    %esi
   2505c:	21 f0                	and    %esi,%eax
   2505e:	a9 80 80 80 80       	test   $0x80808080,%eax
   25063:	75 0f                	jne    25074 <memchr+0x94>
   25065:	83 e9 04             	sub    $0x4,%ecx
   25068:	83 c2 04             	add    $0x4,%edx
   2506b:	83 f9 03             	cmp    $0x3,%ecx
   2506e:	77 e0                	ja     25050 <memchr+0x70>
   25070:	85 c9                	test   %ecx,%ecx
   25072:	74 9e                	je     25012 <memchr+0x32>
   25074:	0f b6 32             	movzbl (%edx),%esi
   25077:	01 d1                	add    %edx,%ecx
   25079:	8d 42 01             	lea    0x1(%edx),%eax
   2507c:	39 de                	cmp    %ebx,%esi
   2507e:	75 12                	jne    25092 <memchr+0xb2>
   25080:	eb 1e                	jmp    250a0 <memchr+0xc0>
   25082:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   25088:	0f b6 32             	movzbl (%edx),%esi
   2508b:	83 c0 01             	add    $0x1,%eax
   2508e:	39 de                	cmp    %ebx,%esi
   25090:	74 0e                	je     250a0 <memchr+0xc0>
   25092:	39 c8                	cmp    %ecx,%eax
   25094:	89 c2                	mov    %eax,%edx
   25096:	75 f0                	jne    25088 <memchr+0xa8>
   25098:	e9 75 ff ff ff       	jmp    25012 <memchr+0x32>
   2509d:	8d 76 00             	lea    0x0(%esi),%esi
   250a0:	5b                   	pop    %ebx
   250a1:	89 d0                	mov    %edx,%eax
   250a3:	5e                   	pop    %esi
   250a4:	5f                   	pop    %edi
   250a5:	c3                   	ret    
   250a6:	66 90                	xchg   %ax,%ax
   250a8:	66 90                	xchg   %ax,%ax
   250aa:	66 90                	xchg   %ax,%ax
   250ac:	66 90                	xchg   %ax,%ax
   250ae:	66 90                	xchg   %ax,%ax

000250b0 <__set_thread_area>:
   250b0:	83 ec 2c             	sub    $0x2c,%esp
   250b3:	8b 44 24 30          	mov    0x30(%esp),%eax
   250b7:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   250be:	00 
   250bf:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   250c6:	00 
   250c7:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   250ce:	00 
   250cf:	89 04 24             	mov    %eax,(%esp)
   250d2:	b8 f3 00 00 00       	mov    $0xf3,%eax
   250d7:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   250de:	00 
   250df:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   250e6:	00 
   250e7:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   250ee:	00 
   250ef:	e8 fc ff ff ff       	call   250f0 <__set_thread_area+0x40>
   250f4:	83 c4 2c             	add    $0x2c,%esp
   250f7:	c3                   	ret    
   250f8:	66 90                	xchg   %ax,%ax
   250fa:	66 90                	xchg   %ax,%ax
   250fc:	66 90                	xchg   %ax,%ax
   250fe:	66 90                	xchg   %ax,%ax

00025100 <__strerror_l>:
   25100:	53                   	push   %ebx
   25101:	8b 4c 24 08          	mov    0x8(%esp),%ecx
   25105:	8b 5c 24 0c          	mov    0xc(%esp),%ebx
   25109:	83 f9 54             	cmp    $0x54,%ecx
   2510c:	74 4b                	je     25159 <__strerror_l+0x59>
   2510e:	31 d2                	xor    %edx,%edx
   25110:	eb 0a                	jmp    2511c <__strerror_l+0x1c>
   25112:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   25118:	39 c8                	cmp    %ecx,%eax
   2511a:	74 0e                	je     2512a <__strerror_l+0x2a>
   2511c:	83 c2 01             	add    $0x1,%edx
   2511f:	0f b6 82 c0 43 00 00 	movzbl 0x43c0(%edx),%eax
   25126:	84 c0                	test   %al,%al
   25128:	75 ee                	jne    25118 <__strerror_l+0x18>
   2512a:	b8 a0 3c 00 00       	mov    $0x3ca0,%eax
   2512f:	eb 0a                	jmp    2513b <__strerror_l+0x3b>
   25131:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25138:	83 c0 01             	add    $0x1,%eax
   2513b:	80 38 00             	cmpb   $0x0,(%eax)
   2513e:	75 f8                	jne    25138 <__strerror_l+0x38>
   25140:	83 c0 01             	add    $0x1,%eax
   25143:	83 ea 01             	sub    $0x1,%edx
   25146:	75 f3                	jne    2513b <__strerror_l+0x3b>
   25148:	8b 53 14             	mov    0x14(%ebx),%edx
   2514b:	89 44 24 08          	mov    %eax,0x8(%esp)
   2514f:	89 54 24 0c          	mov    %edx,0xc(%esp)
   25153:	5b                   	pop    %ebx
   25154:	e9 fc ff ff ff       	jmp    25155 <__strerror_l+0x55>
   25159:	b8 a0 3c 00 00       	mov    $0x3ca0,%eax
   2515e:	eb e8                	jmp    25148 <__strerror_l+0x48>

00025160 <strerror>:
   25160:	53                   	push   %ebx
   25161:	83 ec 18             	sub    $0x18,%esp
   25164:	8b 4c 24 20          	mov    0x20(%esp),%ecx
   25168:	65 a1 00 00 00 00    	mov    %gs:0x0,%eax
   2516e:	83 f9 54             	cmp    $0x54,%ecx
   25171:	8b 98 9c 00 00 00    	mov    0x9c(%eax),%ebx
   25177:	74 4b                	je     251c4 <strerror+0x64>
   25179:	31 d2                	xor    %edx,%edx
   2517b:	eb 07                	jmp    25184 <strerror+0x24>
   2517d:	8d 76 00             	lea    0x0(%esi),%esi
   25180:	39 c1                	cmp    %eax,%ecx
   25182:	74 0e                	je     25192 <strerror+0x32>
   25184:	83 c2 01             	add    $0x1,%edx
   25187:	0f b6 82 c0 43 00 00 	movzbl 0x43c0(%edx),%eax
   2518e:	84 c0                	test   %al,%al
   25190:	75 ee                	jne    25180 <strerror+0x20>
   25192:	b8 a0 3c 00 00       	mov    $0x3ca0,%eax
   25197:	eb 0a                	jmp    251a3 <strerror+0x43>
   25199:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   251a0:	83 c0 01             	add    $0x1,%eax
   251a3:	80 38 00             	cmpb   $0x0,(%eax)
   251a6:	75 f8                	jne    251a0 <strerror+0x40>
   251a8:	83 c0 01             	add    $0x1,%eax
   251ab:	83 ea 01             	sub    $0x1,%edx
   251ae:	75 f3                	jne    251a3 <strerror+0x43>
   251b0:	8b 53 14             	mov    0x14(%ebx),%edx
   251b3:	89 04 24             	mov    %eax,(%esp)
   251b6:	89 54 24 04          	mov    %edx,0x4(%esp)
   251ba:	e8 fc ff ff ff       	call   251bb <strerror+0x5b>
   251bf:	83 c4 18             	add    $0x18,%esp
   251c2:	5b                   	pop    %ebx
   251c3:	c3                   	ret    
   251c4:	b8 a0 3c 00 00       	mov    $0x3ca0,%eax
   251c9:	eb e5                	jmp    251b0 <strerror+0x50>
   251cb:	66 90                	xchg   %ax,%ax
   251cd:	66 90                	xchg   %ax,%ax
   251cf:	90                   	nop

000251d0 <__lctrans_impl>:
   251d0:	8b 44 24 04          	mov    0x4(%esp),%eax
   251d4:	c3                   	ret    
   251d5:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   251d9:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

000251e0 <__lctrans>:
   251e0:	e9 fc ff ff ff       	jmp    251e1 <__lctrans+0x1>
   251e5:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   251e9:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

000251f0 <__lctrans_cur>:
   251f0:	83 ec 1c             	sub    $0x1c,%esp
   251f3:	65 a1 00 00 00 00    	mov    %gs:0x0,%eax
   251f9:	8b 80 9c 00 00 00    	mov    0x9c(%eax),%eax
   251ff:	8b 40 14             	mov    0x14(%eax),%eax
   25202:	89 44 24 04          	mov    %eax,0x4(%esp)
   25206:	8b 44 24 20          	mov    0x20(%esp),%eax
   2520a:	89 04 24             	mov    %eax,(%esp)
   2520d:	e8 fc ff ff ff       	call   2520e <__lctrans_cur+0x1e>
   25212:	83 c4 1c             	add    $0x1c,%esp
   25215:	c3                   	ret    
   25216:	66 90                	xchg   %ax,%ax
   25218:	66 90                	xchg   %ax,%ax
   2521a:	66 90                	xchg   %ax,%ax
   2521c:	66 90                	xchg   %ax,%ax
   2521e:	66 90                	xchg   %ax,%ax

00025220 <__fpclassifyl>:
   25220:	56                   	push   %esi
   25221:	53                   	push   %ebx
   25222:	83 ec 14             	sub    $0x14,%esp
   25225:	db 6c 24 20          	fldt   0x20(%esp)
   25229:	db 3c 24             	fstpt  (%esp)
   2522c:	8b 5c 24 04          	mov    0x4(%esp),%ebx
   25230:	0f b7 74 24 08       	movzwl 0x8(%esp),%esi
   25235:	8b 0c 24             	mov    (%esp),%ecx
   25238:	89 da                	mov    %ebx,%edx
   2523a:	c1 ea 1f             	shr    $0x1f,%edx
   2523d:	81 e6 ff 7f 00 00    	and    $0x7fff,%esi
   25243:	89 d0                	mov    %edx,%eax
   25245:	09 f0                	or     %esi,%eax
   25247:	75 17                	jne    25260 <__fpclassifyl+0x40>
   25249:	09 d9                	or     %ebx,%ecx
   2524b:	83 f9 01             	cmp    $0x1,%ecx
   2524e:	19 c0                	sbb    %eax,%eax
   25250:	83 c0 03             	add    $0x3,%eax
   25253:	83 c4 14             	add    $0x14,%esp
   25256:	5b                   	pop    %ebx
   25257:	5e                   	pop    %esi
   25258:	c3                   	ret    
   25259:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25260:	31 c0                	xor    %eax,%eax
   25262:	85 d2                	test   %edx,%edx
   25264:	74 ed                	je     25253 <__fpclassifyl+0x33>
   25266:	81 fe ff 7f 00 00    	cmp    $0x7fff,%esi
   2526c:	b0 04                	mov    $0x4,%al
   2526e:	75 e3                	jne    25253 <__fpclassifyl+0x33>
   25270:	0f a4 cb 01          	shld   $0x1,%ecx,%ebx
   25274:	01 c9                	add    %ecx,%ecx
   25276:	89 c8                	mov    %ecx,%eax
   25278:	09 d8                	or     %ebx,%eax
   2527a:	0f 94 c0             	sete   %al
   2527d:	0f b6 c0             	movzbl %al,%eax
   25280:	eb d1                	jmp    25253 <__fpclassifyl+0x33>
   25282:	66 90                	xchg   %ax,%ax
   25284:	66 90                	xchg   %ax,%ax
   25286:	66 90                	xchg   %ax,%ax
   25288:	66 90                	xchg   %ax,%ax
   2528a:	66 90                	xchg   %ax,%ax
   2528c:	66 90                	xchg   %ax,%ax
   2528e:	66 90                	xchg   %ax,%ax

00025290 <__signbitl>:
   25290:	83 ec 1c             	sub    $0x1c,%esp
   25293:	db 6c 24 20          	fldt   0x20(%esp)
   25297:	db 3c 24             	fstpt  (%esp)
   2529a:	0f b7 44 24 08       	movzwl 0x8(%esp),%eax
   2529f:	83 c4 1c             	add    $0x1c,%esp
   252a2:	66 c1 e8 0f          	shr    $0xf,%ax
   252a6:	0f b7 c0             	movzwl %ax,%eax
   252a9:	c3                   	ret    
   252aa:	66 90                	xchg   %ax,%ax
   252ac:	66 90                	xchg   %ax,%ax
   252ae:	66 90                	xchg   %ax,%ax

000252b0 <frexpl>:
   252b0:	83 ec 4c             	sub    $0x4c,%esp
   252b3:	db 6c 24 50          	fldt   0x50(%esp)
   252b7:	d9 c0                	fld    %st(0)
   252b9:	db 7c 24 20          	fstpt  0x20(%esp)
   252bd:	0f b7 44 24 28       	movzwl 0x28(%esp),%eax
   252c2:	89 c2                	mov    %eax,%edx
   252c4:	81 e2 ff 7f 00 00    	and    $0x7fff,%edx
   252ca:	75 24                	jne    252f0 <frexpl+0x40>
   252cc:	d9 ee                	fldz   
   252ce:	d9 c9                	fxch   %st(1)
   252d0:	dd e1                	fucom  %st(1)
   252d2:	df e0                	fnstsw %ax
   252d4:	dd d9                	fstp   %st(1)
   252d6:	9e                   	sahf   
   252d7:	7a 47                	jp     25320 <frexpl+0x70>
   252d9:	75 45                	jne    25320 <frexpl+0x70>
   252db:	8b 44 24 5c          	mov    0x5c(%esp),%eax
   252df:	c7 00 00 00 00 00    	movl   $0x0,(%eax)
   252e5:	83 c4 4c             	add    $0x4c,%esp
   252e8:	c3                   	ret    
   252e9:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   252f0:	81 fa ff 7f 00 00    	cmp    $0x7fff,%edx
   252f6:	74 ed                	je     252e5 <frexpl+0x35>
   252f8:	dd d8                	fstp   %st(0)
   252fa:	8b 4c 24 5c          	mov    0x5c(%esp),%ecx
   252fe:	66 25 00 80          	and    $0x8000,%ax
   25302:	81 ea fe 3f 00 00    	sub    $0x3ffe,%edx
   25308:	66 0d fe 3f          	or     $0x3ffe,%ax
   2530c:	66 89 44 24 28       	mov    %ax,0x28(%esp)
   25311:	db 6c 24 20          	fldt   0x20(%esp)
   25315:	89 11                	mov    %edx,(%ecx)
   25317:	83 c4 4c             	add    $0x4c,%esp
   2531a:	c3                   	ret    
   2531b:	90                   	nop
   2531c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25320:	d8 0d 84 45 00 00    	fmuls  0x4584
   25326:	d9 c0                	fld    %st(0)
   25328:	db 7c 24 30          	fstpt  0x30(%esp)
   2532c:	0f b7 44 24 38       	movzwl 0x38(%esp),%eax
   25331:	89 c2                	mov    %eax,%edx
   25333:	81 e2 ff 7f 00 00    	and    $0x7fff,%edx
   25339:	75 25                	jne    25360 <frexpl+0xb0>
   2533b:	d9 ee                	fldz   
   2533d:	d9 c9                	fxch   %st(1)
   2533f:	dd e1                	fucom  %st(1)
   25341:	df e0                	fnstsw %ax
   25343:	dd d9                	fstp   %st(1)
   25345:	9e                   	sahf   
   25346:	7a 40                	jp     25388 <frexpl+0xd8>
   25348:	75 3e                	jne    25388 <frexpl+0xd8>
   2534a:	b8 88 ff ff ff       	mov    $0xffffff88,%eax
   2534f:	8b 4c 24 5c          	mov    0x5c(%esp),%ecx
   25353:	89 01                	mov    %eax,(%ecx)
   25355:	83 c4 4c             	add    $0x4c,%esp
   25358:	c3                   	ret    
   25359:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25360:	81 fa ff 7f 00 00    	cmp    $0x7fff,%edx
   25366:	74 48                	je     253b0 <frexpl+0x100>
   25368:	dd d8                	fstp   %st(0)
   2536a:	66 25 00 80          	and    $0x8000,%ax
   2536e:	66 0d fe 3f          	or     $0x3ffe,%ax
   25372:	66 89 44 24 38       	mov    %ax,0x38(%esp)
   25377:	8d 82 8a bf ff ff    	lea    -0x4076(%edx),%eax
   2537d:	db 6c 24 30          	fldt   0x30(%esp)
   25381:	eb cc                	jmp    2534f <frexpl+0x9f>
   25383:	90                   	nop
   25384:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25388:	d8 0d 84 45 00 00    	fmuls  0x4584
   2538e:	8b 44 24 5c          	mov    0x5c(%esp),%eax
   25392:	89 44 24 0c          	mov    %eax,0xc(%esp)
   25396:	db 3c 24             	fstpt  (%esp)
   25399:	e8 fc ff ff ff       	call   2539a <frexpl+0xea>
   2539e:	8b 44 24 5c          	mov    0x5c(%esp),%eax
   253a2:	8b 00                	mov    (%eax),%eax
   253a4:	89 44 24 1c          	mov    %eax,0x1c(%esp)
   253a8:	2d f0 00 00 00       	sub    $0xf0,%eax
   253ad:	eb a0                	jmp    2534f <frexpl+0x9f>
   253af:	90                   	nop
   253b0:	8b 44 24 5c          	mov    0x5c(%esp),%eax
   253b4:	8b 00                	mov    (%eax),%eax
   253b6:	89 44 24 1c          	mov    %eax,0x1c(%esp)
   253ba:	83 e8 78             	sub    $0x78,%eax
   253bd:	eb 90                	jmp    2534f <frexpl+0x9f>
   253bf:	90                   	nop

000253c0 <wctomb>:
   253c0:	83 ec 1c             	sub    $0x1c,%esp
   253c3:	31 c0                	xor    %eax,%eax
   253c5:	8b 54 24 20          	mov    0x20(%esp),%edx
   253c9:	85 d2                	test   %edx,%edx
   253cb:	74 18                	je     253e5 <wctomb+0x25>
   253cd:	8b 44 24 24          	mov    0x24(%esp),%eax
   253d1:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   253d8:	00 
   253d9:	89 14 24             	mov    %edx,(%esp)
   253dc:	89 44 24 04          	mov    %eax,0x4(%esp)
   253e0:	e8 fc ff ff ff       	call   253e1 <wctomb+0x21>
   253e5:	83 c4 1c             	add    $0x1c,%esp
   253e8:	c3                   	ret    
   253e9:	66 90                	xchg   %ax,%ax
   253eb:	66 90                	xchg   %ax,%ax
   253ed:	66 90                	xchg   %ax,%ax
   253ef:	90                   	nop

000253f0 <__lockfile>:
   253f0:	55                   	push   %ebp
   253f1:	57                   	push   %edi
   253f2:	56                   	push   %esi
   253f3:	53                   	push   %ebx
   253f4:	83 ec 1c             	sub    $0x1c,%esp
   253f7:	8b 7c 24 30          	mov    0x30(%esp),%edi
   253fb:	65 a1 00 00 00 00    	mov    %gs:0x0,%eax
   25401:	8b 58 1c             	mov    0x1c(%eax),%ebx
   25404:	8b 47 4c             	mov    0x4c(%edi),%eax
   25407:	39 d8                	cmp    %ebx,%eax
   25409:	74 4d                	je     25458 <__lockfile+0x68>
   2540b:	31 c0                	xor    %eax,%eax
   2540d:	31 f6                	xor    %esi,%esi
   2540f:	f0 0f b1 5f 4c       	lock cmpxchg %ebx,0x4c(%edi)
   25414:	8d 6f 4c             	lea    0x4c(%edi),%ebp
   25417:	83 c7 50             	add    $0x50,%edi
   2541a:	85 c0                	test   %eax,%eax
   2541c:	89 c2                	mov    %eax,%edx
   2541e:	74 25                	je     25445 <__lockfile+0x55>
   25420:	89 54 24 08          	mov    %edx,0x8(%esp)
   25424:	c7 44 24 0c 01 00 00 	movl   $0x1,0xc(%esp)
   2542b:	00 
   2542c:	89 7c 24 04          	mov    %edi,0x4(%esp)
   25430:	89 2c 24             	mov    %ebp,(%esp)
   25433:	e8 fc ff ff ff       	call   25434 <__lockfile+0x44>
   25438:	89 f0                	mov    %esi,%eax
   2543a:	f0 0f b1 5d 00       	lock cmpxchg %ebx,0x0(%ebp)
   2543f:	85 c0                	test   %eax,%eax
   25441:	89 c2                	mov    %eax,%edx
   25443:	75 db                	jne    25420 <__lockfile+0x30>
   25445:	83 c4 1c             	add    $0x1c,%esp
   25448:	b8 01 00 00 00       	mov    $0x1,%eax
   2544d:	5b                   	pop    %ebx
   2544e:	5e                   	pop    %esi
   2544f:	5f                   	pop    %edi
   25450:	5d                   	pop    %ebp
   25451:	c3                   	ret    
   25452:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   25458:	83 c4 1c             	add    $0x1c,%esp
   2545b:	31 c0                	xor    %eax,%eax
   2545d:	5b                   	pop    %ebx
   2545e:	5e                   	pop    %esi
   2545f:	5f                   	pop    %edi
   25460:	5d                   	pop    %ebp
   25461:	c3                   	ret    
   25462:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25469:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

00025470 <__unlockfile>:
   25470:	53                   	push   %ebx
   25471:	31 d2                	xor    %edx,%edx
   25473:	83 ec 28             	sub    $0x28,%esp
   25476:	8b 44 24 30          	mov    0x30(%esp),%eax
   2547a:	89 50 4c             	mov    %edx,0x4c(%eax)
   2547d:	f0 83 0c 24 00       	lock orl $0x0,(%esp)
   25482:	8d 58 4c             	lea    0x4c(%eax),%ebx
   25485:	8b 40 50             	mov    0x50(%eax),%eax
   25488:	85 c0                	test   %eax,%eax
   2548a:	75 0c                	jne    25498 <__unlockfile+0x28>
   2548c:	83 c4 28             	add    $0x28,%esp
   2548f:	5b                   	pop    %ebx
   25490:	c3                   	ret    
   25491:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25498:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   2549f:	00 
   254a0:	b8 f0 00 00 00       	mov    $0xf0,%eax
   254a5:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   254ac:	00 
   254ad:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   254b4:	00 
   254b5:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   254bc:	00 
   254bd:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
   254c4:	00 
   254c5:	c7 44 24 04 81 00 00 	movl   $0x81,0x4(%esp)
   254cc:	00 
   254cd:	89 1c 24             	mov    %ebx,(%esp)
   254d0:	e8 fc ff ff ff       	call   254d1 <__unlockfile+0x61>
   254d5:	83 f8 da             	cmp    $0xffffffda,%eax
   254d8:	75 b2                	jne    2548c <__unlockfile+0x1c>
   254da:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   254e1:	00 
   254e2:	b8 f0 00 00 00       	mov    $0xf0,%eax
   254e7:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   254ee:	00 
   254ef:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   254f6:	00 
   254f7:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   254fe:	00 
   254ff:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
   25506:	00 
   25507:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
   2550e:	00 
   2550f:	89 1c 24             	mov    %ebx,(%esp)
   25512:	e8 fc ff ff ff       	call   25513 <__unlockfile+0xa3>
   25517:	e9 70 ff ff ff       	jmp    2548c <__unlockfile+0x1c>
   2551c:	66 90                	xchg   %ax,%ax
   2551e:	66 90                	xchg   %ax,%ax

00025520 <__fwritex>:
   25520:	55                   	push   %ebp
   25521:	57                   	push   %edi
   25522:	56                   	push   %esi
   25523:	53                   	push   %ebx
   25524:	83 ec 1c             	sub    $0x1c,%esp
   25527:	8b 6c 24 38          	mov    0x38(%esp),%ebp
   2552b:	8b 74 24 30          	mov    0x30(%esp),%esi
   2552f:	8b 7c 24 34          	mov    0x34(%esp),%edi
   25533:	8b 45 10             	mov    0x10(%ebp),%eax
   25536:	85 c0                	test   %eax,%eax
   25538:	0f 84 8e 00 00 00    	je     255cc <__fwritex+0xac>
   2553e:	8b 55 14             	mov    0x14(%ebp),%edx
   25541:	29 d0                	sub    %edx,%eax
   25543:	39 f8                	cmp    %edi,%eax
   25545:	72 69                	jb     255b0 <__fwritex+0x90>
   25547:	80 7d 4b 00          	cmpb   $0x0,0x4b(%ebp)
   2554b:	78 7b                	js     255c8 <__fwritex+0xa8>
   2554d:	85 ff                	test   %edi,%edi
   2554f:	74 77                	je     255c8 <__fwritex+0xa8>
   25551:	80 7c 3e ff 0a       	cmpb   $0xa,-0x1(%esi,%edi,1)
   25556:	8d 5f ff             	lea    -0x1(%edi),%ebx
   25559:	75 11                	jne    2556c <__fwritex+0x4c>
   2555b:	eb 31                	jmp    2558e <__fwritex+0x6e>
   2555d:	8d 76 00             	lea    0x0(%esi),%esi
   25560:	80 7c 1e ff 0a       	cmpb   $0xa,-0x1(%esi,%ebx,1)
   25565:	8d 43 ff             	lea    -0x1(%ebx),%eax
   25568:	74 26                	je     25590 <__fwritex+0x70>
   2556a:	89 c3                	mov    %eax,%ebx
   2556c:	85 db                	test   %ebx,%ebx
   2556e:	75 f0                	jne    25560 <__fwritex+0x40>
   25570:	89 7c 24 08          	mov    %edi,0x8(%esp)
   25574:	89 74 24 04          	mov    %esi,0x4(%esp)
   25578:	89 14 24             	mov    %edx,(%esp)
   2557b:	e8 fc ff ff ff       	call   2557c <__fwritex+0x5c>
   25580:	8d 04 3b             	lea    (%ebx,%edi,1),%eax
   25583:	01 7d 14             	add    %edi,0x14(%ebp)
   25586:	83 c4 1c             	add    $0x1c,%esp
   25589:	5b                   	pop    %ebx
   2558a:	5e                   	pop    %esi
   2558b:	5f                   	pop    %edi
   2558c:	5d                   	pop    %ebp
   2558d:	c3                   	ret    
   2558e:	89 fb                	mov    %edi,%ebx
   25590:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   25594:	89 74 24 04          	mov    %esi,0x4(%esp)
   25598:	89 2c 24             	mov    %ebp,(%esp)
   2559b:	ff 55 24             	call   *0x24(%ebp)
   2559e:	89 c2                	mov    %eax,%edx
   255a0:	89 d8                	mov    %ebx,%eax
   255a2:	39 da                	cmp    %ebx,%edx
   255a4:	72 e0                	jb     25586 <__fwritex+0x66>
   255a6:	01 de                	add    %ebx,%esi
   255a8:	29 df                	sub    %ebx,%edi
   255aa:	8b 55 14             	mov    0x14(%ebp),%edx
   255ad:	eb c1                	jmp    25570 <__fwritex+0x50>
   255af:	90                   	nop
   255b0:	89 7c 24 38          	mov    %edi,0x38(%esp)
   255b4:	89 74 24 34          	mov    %esi,0x34(%esp)
   255b8:	89 6c 24 30          	mov    %ebp,0x30(%esp)
   255bc:	8b 45 24             	mov    0x24(%ebp),%eax
   255bf:	83 c4 1c             	add    $0x1c,%esp
   255c2:	5b                   	pop    %ebx
   255c3:	5e                   	pop    %esi
   255c4:	5f                   	pop    %edi
   255c5:	5d                   	pop    %ebp
   255c6:	ff e0                	jmp    *%eax
   255c8:	31 db                	xor    %ebx,%ebx
   255ca:	eb a4                	jmp    25570 <__fwritex+0x50>
   255cc:	89 2c 24             	mov    %ebp,(%esp)
   255cf:	e8 fc ff ff ff       	call   255d0 <__fwritex+0xb0>
   255d4:	85 c0                	test   %eax,%eax
   255d6:	75 08                	jne    255e0 <__fwritex+0xc0>
   255d8:	8b 45 10             	mov    0x10(%ebp),%eax
   255db:	e9 5e ff ff ff       	jmp    2553e <__fwritex+0x1e>
   255e0:	31 c0                	xor    %eax,%eax
   255e2:	eb a2                	jmp    25586 <__fwritex+0x66>
   255e4:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   255ea:	8d bf 00 00 00 00    	lea    0x0(%edi),%edi

000255f0 <fwrite>:
   255f0:	55                   	push   %ebp
   255f1:	57                   	push   %edi
   255f2:	56                   	push   %esi
   255f3:	53                   	push   %ebx
   255f4:	83 ec 2c             	sub    $0x2c,%esp
   255f7:	8b 7c 24 4c          	mov    0x4c(%esp),%edi
   255fb:	8b 6c 24 44          	mov    0x44(%esp),%ebp
   255ff:	0f af 6c 24 48       	imul   0x48(%esp),%ebp
   25604:	8b 74 24 40          	mov    0x40(%esp),%esi
   25608:	8b 47 4c             	mov    0x4c(%edi),%eax
   2560b:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   25612:	00 
   25613:	85 c0                	test   %eax,%eax
   25615:	78 0c                	js     25623 <fwrite+0x33>
   25617:	89 3c 24             	mov    %edi,(%esp)
   2561a:	e8 fc ff ff ff       	call   2561b <fwrite+0x2b>
   2561f:	89 44 24 18          	mov    %eax,0x18(%esp)
   25623:	8b 57 10             	mov    0x10(%edi),%edx
   25626:	85 d2                	test   %edx,%edx
   25628:	0f 84 e3 00 00 00    	je     25711 <fwrite+0x121>
   2562e:	8b 47 14             	mov    0x14(%edi),%eax
   25631:	29 c2                	sub    %eax,%edx
   25633:	39 d5                	cmp    %edx,%ebp
   25635:	0f 87 bd 00 00 00    	ja     256f8 <fwrite+0x108>
   2563b:	80 7f 4b 00          	cmpb   $0x0,0x4b(%edi)
   2563f:	0f 88 c3 00 00 00    	js     25708 <fwrite+0x118>
   25645:	85 ed                	test   %ebp,%ebp
   25647:	0f 84 e0 00 00 00    	je     2572d <fwrite+0x13d>
   2564d:	80 7c 2e ff 0a       	cmpb   $0xa,-0x1(%esi,%ebp,1)
   25652:	8d 5d ff             	lea    -0x1(%ebp),%ebx
   25655:	75 15                	jne    2566c <fwrite+0x7c>
   25657:	eb 51                	jmp    256aa <fwrite+0xba>
   25659:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25660:	80 7c 1e ff 0a       	cmpb   $0xa,-0x1(%esi,%ebx,1)
   25665:	8d 53 ff             	lea    -0x1(%ebx),%edx
   25668:	74 46                	je     256b0 <fwrite+0xc0>
   2566a:	89 d3                	mov    %edx,%ebx
   2566c:	85 db                	test   %ebx,%ebx
   2566e:	75 f0                	jne    25660 <fwrite+0x70>
   25670:	89 ea                	mov    %ebp,%edx
   25672:	89 54 24 08          	mov    %edx,0x8(%esp)
   25676:	89 74 24 04          	mov    %esi,0x4(%esp)
   2567a:	89 04 24             	mov    %eax,(%esp)
   2567d:	89 54 24 1c          	mov    %edx,0x1c(%esp)
   25681:	e8 fc ff ff ff       	call   25682 <fwrite+0x92>
   25686:	8b 54 24 1c          	mov    0x1c(%esp),%edx
   2568a:	01 57 14             	add    %edx,0x14(%edi)
   2568d:	8d 04 13             	lea    (%ebx,%edx,1),%eax
   25690:	8b 54 24 18          	mov    0x18(%esp),%edx
   25694:	85 d2                	test   %edx,%edx
   25696:	75 40                	jne    256d8 <fwrite+0xe8>
   25698:	39 c5                	cmp    %eax,%ebp
   2569a:	74 50                	je     256ec <fwrite+0xfc>
   2569c:	31 d2                	xor    %edx,%edx
   2569e:	f7 74 24 44          	divl   0x44(%esp)
   256a2:	83 c4 2c             	add    $0x2c,%esp
   256a5:	5b                   	pop    %ebx
   256a6:	5e                   	pop    %esi
   256a7:	5f                   	pop    %edi
   256a8:	5d                   	pop    %ebp
   256a9:	c3                   	ret    
   256aa:	89 eb                	mov    %ebp,%ebx
   256ac:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   256b0:	89 5c 24 08          	mov    %ebx,0x8(%esp)
   256b4:	89 74 24 04          	mov    %esi,0x4(%esp)
   256b8:	89 3c 24             	mov    %edi,(%esp)
   256bb:	ff 57 24             	call   *0x24(%edi)
   256be:	89 c2                	mov    %eax,%edx
   256c0:	89 d8                	mov    %ebx,%eax
   256c2:	39 da                	cmp    %ebx,%edx
   256c4:	72 ca                	jb     25690 <fwrite+0xa0>
   256c6:	89 ea                	mov    %ebp,%edx
   256c8:	01 de                	add    %ebx,%esi
   256ca:	8b 47 14             	mov    0x14(%edi),%eax
   256cd:	29 da                	sub    %ebx,%edx
   256cf:	eb a1                	jmp    25672 <fwrite+0x82>
   256d1:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   256d8:	89 3c 24             	mov    %edi,(%esp)
   256db:	89 44 24 18          	mov    %eax,0x18(%esp)
   256df:	e8 fc ff ff ff       	call   256e0 <fwrite+0xf0>
   256e4:	8b 44 24 18          	mov    0x18(%esp),%eax
   256e8:	39 c5                	cmp    %eax,%ebp
   256ea:	75 b0                	jne    2569c <fwrite+0xac>
   256ec:	8b 44 24 48          	mov    0x48(%esp),%eax
   256f0:	83 c4 2c             	add    $0x2c,%esp
   256f3:	5b                   	pop    %ebx
   256f4:	5e                   	pop    %esi
   256f5:	5f                   	pop    %edi
   256f6:	5d                   	pop    %ebp
   256f7:	c3                   	ret    
   256f8:	89 6c 24 08          	mov    %ebp,0x8(%esp)
   256fc:	89 74 24 04          	mov    %esi,0x4(%esp)
   25700:	89 3c 24             	mov    %edi,(%esp)
   25703:	ff 57 24             	call   *0x24(%edi)
   25706:	eb 88                	jmp    25690 <fwrite+0xa0>
   25708:	89 ea                	mov    %ebp,%edx
   2570a:	31 db                	xor    %ebx,%ebx
   2570c:	e9 61 ff ff ff       	jmp    25672 <fwrite+0x82>
   25711:	89 3c 24             	mov    %edi,(%esp)
   25714:	e8 fc ff ff ff       	call   25715 <fwrite+0x125>
   25719:	89 c2                	mov    %eax,%edx
   2571b:	31 c0                	xor    %eax,%eax
   2571d:	85 d2                	test   %edx,%edx
   2571f:	0f 85 6b ff ff ff    	jne    25690 <fwrite+0xa0>
   25725:	8b 57 10             	mov    0x10(%edi),%edx
   25728:	e9 01 ff ff ff       	jmp    2562e <fwrite+0x3e>
   2572d:	31 db                	xor    %ebx,%ebx
   2572f:	31 d2                	xor    %edx,%edx
   25731:	e9 3c ff ff ff       	jmp    25672 <fwrite+0x82>
   25736:	66 90                	xchg   %ax,%ax
   25738:	66 90                	xchg   %ax,%ax
   2573a:	66 90                	xchg   %ax,%ax
   2573c:	66 90                	xchg   %ax,%ax
   2573e:	66 90                	xchg   %ax,%ax

00025740 <__wait>:
   25740:	55                   	push   %ebp
   25741:	57                   	push   %edi
   25742:	56                   	push   %esi
   25743:	53                   	push   %ebx
   25744:	83 ec 2c             	sub    $0x2c,%esp
   25747:	8b 6c 24 4c          	mov    0x4c(%esp),%ebp
   2574b:	8b 5c 24 40          	mov    0x40(%esp),%ebx
   2574f:	8b 7c 24 44          	mov    0x44(%esp),%edi
   25753:	8b 74 24 48          	mov    0x48(%esp),%esi
   25757:	85 ed                	test   %ebp,%ebp
   25759:	74 05                	je     25760 <__wait+0x20>
   2575b:	bd 80 00 00 00       	mov    $0x80,%ebp
   25760:	85 ff                	test   %edi,%edi
   25762:	b8 64 00 00 00       	mov    $0x64,%eax
   25767:	75 14                	jne    2577d <__wait+0x3d>
   25769:	eb 7c                	jmp    257e7 <__wait+0xa7>
   2576b:	90                   	nop
   2576c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25770:	8b 13                	mov    (%ebx),%edx
   25772:	39 f2                	cmp    %esi,%edx
   25774:	75 61                	jne    257d7 <__wait+0x97>
   25776:	f3 90                	pause  
   25778:	83 e8 01             	sub    $0x1,%eax
   2577b:	74 06                	je     25783 <__wait+0x43>
   2577d:	8b 17                	mov    (%edi),%edx
   2577f:	85 d2                	test   %edx,%edx
   25781:	74 ed                	je     25770 <__wait+0x30>
   25783:	f0 ff 07             	lock incl (%edi)
   25786:	8b 03                	mov    (%ebx),%eax
   25788:	39 f0                	cmp    %esi,%eax
   2578a:	75 44                	jne    257d0 <__wait+0x90>
   2578c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25790:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   25797:	00 
   25798:	b8 f0 00 00 00       	mov    $0xf0,%eax
   2579d:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   257a4:	00 
   257a5:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   257ac:	00 
   257ad:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   257b4:	00 
   257b5:	89 74 24 08          	mov    %esi,0x8(%esp)
   257b9:	89 6c 24 04          	mov    %ebp,0x4(%esp)
   257bd:	89 1c 24             	mov    %ebx,(%esp)
   257c0:	e8 fc ff ff ff       	call   257c1 <__wait+0x81>
   257c5:	83 f8 da             	cmp    $0xffffffda,%eax
   257c8:	74 2e                	je     257f8 <__wait+0xb8>
   257ca:	8b 03                	mov    (%ebx),%eax
   257cc:	39 f0                	cmp    %esi,%eax
   257ce:	74 c0                	je     25790 <__wait+0x50>
   257d0:	85 ff                	test   %edi,%edi
   257d2:	74 03                	je     257d7 <__wait+0x97>
   257d4:	f0 ff 0f             	lock decl (%edi)
   257d7:	83 c4 2c             	add    $0x2c,%esp
   257da:	5b                   	pop    %ebx
   257db:	5e                   	pop    %esi
   257dc:	5f                   	pop    %edi
   257dd:	5d                   	pop    %ebp
   257de:	c3                   	ret    
   257df:	90                   	nop
   257e0:	f3 90                	pause  
   257e2:	83 e8 01             	sub    $0x1,%eax
   257e5:	74 e3                	je     257ca <__wait+0x8a>
   257e7:	8b 13                	mov    (%ebx),%edx
   257e9:	39 f2                	cmp    %esi,%edx
   257eb:	74 f3                	je     257e0 <__wait+0xa0>
   257ed:	8d 76 00             	lea    0x0(%esi),%esi
   257f0:	eb e5                	jmp    257d7 <__wait+0x97>
   257f2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   257f8:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   257ff:	00 
   25800:	b8 f0 00 00 00       	mov    $0xf0,%eax
   25805:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   2580c:	00 
   2580d:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   25814:	00 
   25815:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   2581c:	00 
   2581d:	89 74 24 08          	mov    %esi,0x8(%esp)
   25821:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   25828:	00 
   25829:	89 1c 24             	mov    %ebx,(%esp)
   2582c:	e8 fc ff ff ff       	call   2582d <__wait+0xed>
   25831:	eb 97                	jmp    257ca <__wait+0x8a>
   25833:	66 90                	xchg   %ax,%ax
   25835:	66 90                	xchg   %ax,%ax
   25837:	66 90                	xchg   %ax,%ax
   25839:	66 90                	xchg   %ax,%ax
   2583b:	66 90                	xchg   %ax,%ax
   2583d:	66 90                	xchg   %ax,%ax
   2583f:	90                   	nop

00025840 <wcrtomb>:
   25840:	83 ec 0c             	sub    $0xc,%esp
   25843:	8b 54 24 10          	mov    0x10(%esp),%edx
   25847:	8b 44 24 14          	mov    0x14(%esp),%eax
   2584b:	85 d2                	test   %edx,%edx
   2584d:	0f 84 a5 00 00 00    	je     258f8 <wcrtomb+0xb8>
   25853:	83 f8 7f             	cmp    $0x7f,%eax
   25856:	76 38                	jbe    25890 <wcrtomb+0x50>
   25858:	65 8b 0d 00 00 00 00 	mov    %gs:0x0,%ecx
   2585f:	8b 89 9c 00 00 00    	mov    0x9c(%ecx),%ecx
   25865:	8b 09                	mov    (%ecx),%ecx
   25867:	85 c9                	test   %ecx,%ecx
   25869:	74 35                	je     258a0 <wcrtomb+0x60>
   2586b:	3d ff 07 00 00       	cmp    $0x7ff,%eax
   25870:	77 4e                	ja     258c0 <wcrtomb+0x80>
   25872:	89 c1                	mov    %eax,%ecx
   25874:	83 e0 3f             	and    $0x3f,%eax
   25877:	c1 f9 06             	sar    $0x6,%ecx
   2587a:	83 c8 80             	or     $0xffffff80,%eax
   2587d:	83 c9 c0             	or     $0xffffffc0,%ecx
   25880:	88 42 01             	mov    %al,0x1(%edx)
   25883:	b8 02 00 00 00       	mov    $0x2,%eax
   25888:	88 0a                	mov    %cl,(%edx)
   2588a:	83 c4 0c             	add    $0xc,%esp
   2588d:	c3                   	ret    
   2588e:	66 90                	xchg   %ax,%ax
   25890:	88 02                	mov    %al,(%edx)
   25892:	b8 01 00 00 00       	mov    $0x1,%eax
   25897:	83 c4 0c             	add    $0xc,%esp
   2589a:	c3                   	ret    
   2589b:	90                   	nop
   2589c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   258a0:	8d 88 80 20 ff ff    	lea    -0xdf80(%eax),%ecx
   258a6:	83 f9 7f             	cmp    $0x7f,%ecx
   258a9:	76 e5                	jbe    25890 <wcrtomb+0x50>
   258ab:	e8 fc ff ff ff       	call   258ac <wcrtomb+0x6c>
   258b0:	c7 00 54 00 00 00    	movl   $0x54,(%eax)
   258b6:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
   258bb:	eb cd                	jmp    2588a <wcrtomb+0x4a>
   258bd:	8d 76 00             	lea    0x0(%esi),%esi
   258c0:	8d 88 00 20 ff ff    	lea    -0xe000(%eax),%ecx
   258c6:	81 f9 ff 1f 00 00    	cmp    $0x1fff,%ecx
   258cc:	77 3a                	ja     25908 <wcrtomb+0xc8>
   258ce:	89 c1                	mov    %eax,%ecx
   258d0:	c1 f9 0c             	sar    $0xc,%ecx
   258d3:	83 c9 e0             	or     $0xffffffe0,%ecx
   258d6:	88 0a                	mov    %cl,(%edx)
   258d8:	89 c1                	mov    %eax,%ecx
   258da:	83 e0 3f             	and    $0x3f,%eax
   258dd:	c1 f9 06             	sar    $0x6,%ecx
   258e0:	83 c8 80             	or     $0xffffff80,%eax
   258e3:	83 e1 3f             	and    $0x3f,%ecx
   258e6:	83 c9 80             	or     $0xffffff80,%ecx
   258e9:	88 42 02             	mov    %al,0x2(%edx)
   258ec:	b8 03 00 00 00       	mov    $0x3,%eax
   258f1:	88 4a 01             	mov    %cl,0x1(%edx)
   258f4:	83 c4 0c             	add    $0xc,%esp
   258f7:	c3                   	ret    
   258f8:	b8 01 00 00 00       	mov    $0x1,%eax
   258fd:	83 c4 0c             	add    $0xc,%esp
   25900:	c3                   	ret    
   25901:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25908:	3d ff d7 00 00       	cmp    $0xd7ff,%eax
   2590d:	76 bf                	jbe    258ce <wcrtomb+0x8e>
   2590f:	8d 88 00 00 ff ff    	lea    -0x10000(%eax),%ecx
   25915:	81 f9 ff ff 0f 00    	cmp    $0xfffff,%ecx
   2591b:	77 8e                	ja     258ab <wcrtomb+0x6b>
   2591d:	89 c1                	mov    %eax,%ecx
   2591f:	c1 f9 12             	sar    $0x12,%ecx
   25922:	83 c9 f0             	or     $0xfffffff0,%ecx
   25925:	88 0a                	mov    %cl,(%edx)
   25927:	89 c1                	mov    %eax,%ecx
   25929:	c1 f9 0c             	sar    $0xc,%ecx
   2592c:	83 e1 3f             	and    $0x3f,%ecx
   2592f:	83 c9 80             	or     $0xffffff80,%ecx
   25932:	88 4a 01             	mov    %cl,0x1(%edx)
   25935:	89 c1                	mov    %eax,%ecx
   25937:	83 e0 3f             	and    $0x3f,%eax
   2593a:	c1 f9 06             	sar    $0x6,%ecx
   2593d:	83 c8 80             	or     $0xffffff80,%eax
   25940:	83 e1 3f             	and    $0x3f,%ecx
   25943:	83 c9 80             	or     $0xffffff80,%ecx
   25946:	88 42 03             	mov    %al,0x3(%edx)
   25949:	b8 04 00 00 00       	mov    $0x4,%eax
   2594e:	88 4a 02             	mov    %cl,0x2(%edx)
   25951:	e9 34 ff ff ff       	jmp    2588a <wcrtomb+0x4a>
   25956:	66 90                	xchg   %ax,%ax
   25958:	66 90                	xchg   %ax,%ax
   2595a:	66 90                	xchg   %ax,%ax
   2595c:	66 90                	xchg   %ax,%ax
   2595e:	66 90                	xchg   %ax,%ax

00025960 <__towrite>:
   25960:	8b 44 24 04          	mov    0x4(%esp),%eax
   25964:	0f b6 48 4a          	movzbl 0x4a(%eax),%ecx
   25968:	8d 51 ff             	lea    -0x1(%ecx),%edx
   2596b:	09 ca                	or     %ecx,%edx
   2596d:	88 50 4a             	mov    %dl,0x4a(%eax)
   25970:	8b 10                	mov    (%eax),%edx
   25972:	f6 c2 08             	test   $0x8,%dl
   25975:	75 21                	jne    25998 <__towrite+0x38>
   25977:	8b 50 2c             	mov    0x2c(%eax),%edx
   2597a:	c7 40 08 00 00 00 00 	movl   $0x0,0x8(%eax)
   25981:	c7 40 04 00 00 00 00 	movl   $0x0,0x4(%eax)
   25988:	89 50 1c             	mov    %edx,0x1c(%eax)
   2598b:	89 50 14             	mov    %edx,0x14(%eax)
   2598e:	03 50 30             	add    0x30(%eax),%edx
   25991:	89 50 10             	mov    %edx,0x10(%eax)
   25994:	31 c0                	xor    %eax,%eax
   25996:	c3                   	ret    
   25997:	90                   	nop
   25998:	83 ca 20             	or     $0x20,%edx
   2599b:	89 10                	mov    %edx,(%eax)
   2599d:	b8 ff ff ff ff       	mov    $0xffffffff,%eax
   259a2:	c3                   	ret    
   259a3:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   259a9:	8d bc 27 00 00 00 00 	lea    0x0(%edi,%eiz,1),%edi

000259b0 <__towrite_needs_stdio_exit>:
   259b0:	e9 fc ff ff ff       	jmp    259b1 <__towrite_needs_stdio_exit+0x1>
   259b5:	66 90                	xchg   %ax,%ax
   259b7:	66 90                	xchg   %ax,%ax
   259b9:	66 90                	xchg   %ax,%ax
   259bb:	66 90                	xchg   %ax,%ax
   259bd:	66 90                	xchg   %ax,%ax
   259bf:	90                   	nop

000259c0 <__stdio_exit>:
   259c0:	53                   	push   %ebx
   259c1:	83 ec 18             	sub    $0x18,%esp
   259c4:	e8 fc ff ff ff       	call   259c5 <__stdio_exit+0x5>
   259c9:	8b 18                	mov    (%eax),%ebx
   259cb:	85 db                	test   %ebx,%ebx
   259cd:	75 35                	jne    25a04 <__stdio_exit+0x44>
   259cf:	eb 67                	jmp    25a38 <__stdio_exit+0x78>
   259d1:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   259d8:	8b 53 04             	mov    0x4(%ebx),%edx
   259db:	8b 43 08             	mov    0x8(%ebx),%eax
   259de:	39 c2                	cmp    %eax,%edx
   259e0:	73 1b                	jae    259fd <__stdio_exit+0x3d>
   259e2:	29 c2                	sub    %eax,%edx
   259e4:	89 54 24 04          	mov    %edx,0x4(%esp)
   259e8:	c1 fa 1f             	sar    $0x1f,%edx
   259eb:	c7 44 24 0c 01 00 00 	movl   $0x1,0xc(%esp)
   259f2:	00 
   259f3:	89 54 24 08          	mov    %edx,0x8(%esp)
   259f7:	89 1c 24             	mov    %ebx,(%esp)
   259fa:	ff 53 28             	call   *0x28(%ebx)
   259fd:	8b 5b 38             	mov    0x38(%ebx),%ebx
   25a00:	85 db                	test   %ebx,%ebx
   25a02:	74 34                	je     25a38 <__stdio_exit+0x78>
   25a04:	8b 43 4c             	mov    0x4c(%ebx),%eax
   25a07:	85 c0                	test   %eax,%eax
   25a09:	78 08                	js     25a13 <__stdio_exit+0x53>
   25a0b:	89 1c 24             	mov    %ebx,(%esp)
   25a0e:	e8 fc ff ff ff       	call   25a0f <__stdio_exit+0x4f>
   25a13:	8b 43 1c             	mov    0x1c(%ebx),%eax
   25a16:	39 43 14             	cmp    %eax,0x14(%ebx)
   25a19:	76 bd                	jbe    259d8 <__stdio_exit+0x18>
   25a1b:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   25a22:	00 
   25a23:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   25a2a:	00 
   25a2b:	89 1c 24             	mov    %ebx,(%esp)
   25a2e:	ff 53 24             	call   *0x24(%ebx)
   25a31:	eb a5                	jmp    259d8 <__stdio_exit+0x18>
   25a33:	90                   	nop
   25a34:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25a38:	8b 1d 00 00 00 00    	mov    0x0,%ebx
   25a3e:	85 db                	test   %ebx,%ebx
   25a40:	74 40                	je     25a82 <__stdio_exit+0xc2>
   25a42:	8b 43 4c             	mov    0x4c(%ebx),%eax
   25a45:	85 c0                	test   %eax,%eax
   25a47:	78 08                	js     25a51 <__stdio_exit+0x91>
   25a49:	89 1c 24             	mov    %ebx,(%esp)
   25a4c:	e8 fc ff ff ff       	call   25a4d <__stdio_exit+0x8d>
   25a51:	8b 43 1c             	mov    0x1c(%ebx),%eax
   25a54:	39 43 14             	cmp    %eax,0x14(%ebx)
   25a57:	0f 87 8b 00 00 00    	ja     25ae8 <__stdio_exit+0x128>
   25a5d:	8b 53 04             	mov    0x4(%ebx),%edx
   25a60:	8b 43 08             	mov    0x8(%ebx),%eax
   25a63:	39 c2                	cmp    %eax,%edx
   25a65:	73 1b                	jae    25a82 <__stdio_exit+0xc2>
   25a67:	29 c2                	sub    %eax,%edx
   25a69:	89 54 24 04          	mov    %edx,0x4(%esp)
   25a6d:	c1 fa 1f             	sar    $0x1f,%edx
   25a70:	c7 44 24 0c 01 00 00 	movl   $0x1,0xc(%esp)
   25a77:	00 
   25a78:	89 54 24 08          	mov    %edx,0x8(%esp)
   25a7c:	89 1c 24             	mov    %ebx,(%esp)
   25a7f:	ff 53 28             	call   *0x28(%ebx)
   25a82:	8b 1d 00 00 00 00    	mov    0x0,%ebx
   25a88:	85 db                	test   %ebx,%ebx
   25a8a:	74 3c                	je     25ac8 <__stdio_exit+0x108>
   25a8c:	8b 43 4c             	mov    0x4c(%ebx),%eax
   25a8f:	85 c0                	test   %eax,%eax
   25a91:	78 08                	js     25a9b <__stdio_exit+0xdb>
   25a93:	89 1c 24             	mov    %ebx,(%esp)
   25a96:	e8 fc ff ff ff       	call   25a97 <__stdio_exit+0xd7>
   25a9b:	8b 43 1c             	mov    0x1c(%ebx),%eax
   25a9e:	39 43 14             	cmp    %eax,0x14(%ebx)
   25aa1:	77 2d                	ja     25ad0 <__stdio_exit+0x110>
   25aa3:	8b 53 04             	mov    0x4(%ebx),%edx
   25aa6:	8b 43 08             	mov    0x8(%ebx),%eax
   25aa9:	39 c2                	cmp    %eax,%edx
   25aab:	73 1b                	jae    25ac8 <__stdio_exit+0x108>
   25aad:	29 c2                	sub    %eax,%edx
   25aaf:	89 54 24 04          	mov    %edx,0x4(%esp)
   25ab3:	c1 fa 1f             	sar    $0x1f,%edx
   25ab6:	c7 44 24 0c 01 00 00 	movl   $0x1,0xc(%esp)
   25abd:	00 
   25abe:	89 54 24 08          	mov    %edx,0x8(%esp)
   25ac2:	89 1c 24             	mov    %ebx,(%esp)
   25ac5:	ff 53 28             	call   *0x28(%ebx)
   25ac8:	83 c4 18             	add    $0x18,%esp
   25acb:	5b                   	pop    %ebx
   25acc:	c3                   	ret    
   25acd:	8d 76 00             	lea    0x0(%esi),%esi
   25ad0:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   25ad7:	00 
   25ad8:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   25adf:	00 
   25ae0:	89 1c 24             	mov    %ebx,(%esp)
   25ae3:	ff 53 24             	call   *0x24(%ebx)
   25ae6:	eb bb                	jmp    25aa3 <__stdio_exit+0xe3>
   25ae8:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%esp)
   25aef:	00 
   25af0:	c7 44 24 04 00 00 00 	movl   $0x0,0x4(%esp)
   25af7:	00 
   25af8:	89 1c 24             	mov    %ebx,(%esp)
   25afb:	ff 53 24             	call   *0x24(%ebx)
   25afe:	e9 5a ff ff ff       	jmp    25a5d <__stdio_exit+0x9d>
   25b03:	66 90                	xchg   %ax,%ax
   25b05:	66 90                	xchg   %ax,%ax
   25b07:	66 90                	xchg   %ax,%ax
   25b09:	66 90                	xchg   %ax,%ax
   25b0b:	66 90                	xchg   %ax,%ax
   25b0d:	66 90                	xchg   %ax,%ax
   25b0f:	90                   	nop

00025b10 <__ofl_lock>:
   25b10:	83 ec 1c             	sub    $0x1c,%esp
   25b13:	c7 04 24 40 3a 00 00 	movl   $0x3a40,(%esp)
   25b1a:	e8 fc ff ff ff       	call   25b1b <__ofl_lock+0xb>
   25b1f:	b8 48 3a 00 00       	mov    $0x3a48,%eax
   25b24:	83 c4 1c             	add    $0x1c,%esp
   25b27:	c3                   	ret    
   25b28:	90                   	nop
   25b29:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi

00025b30 <__ofl_unlock>:
   25b30:	83 ec 1c             	sub    $0x1c,%esp
   25b33:	c7 04 24 40 3a 00 00 	movl   $0x3a40,(%esp)
   25b3a:	e8 fc ff ff ff       	call   25b3b <__ofl_unlock+0xb>
   25b3f:	83 c4 1c             	add    $0x1c,%esp
   25b42:	c3                   	ret    
   25b43:	66 90                	xchg   %ax,%ax
   25b45:	66 90                	xchg   %ax,%ax
   25b47:	66 90                	xchg   %ax,%ax
   25b49:	66 90                	xchg   %ax,%ax
   25b4b:	66 90                	xchg   %ax,%ax
   25b4d:	66 90                	xchg   %ax,%ax
   25b4f:	90                   	nop

00025b50 <__lock>:
   25b50:	56                   	push   %esi
   25b51:	53                   	push   %ebx
   25b52:	83 ec 14             	sub    $0x14,%esp
   25b55:	a1 0c 00 00 00       	mov    0xc,%eax
   25b5a:	8b 5c 24 20          	mov    0x20(%esp),%ebx
   25b5e:	85 c0                	test   %eax,%eax
   25b60:	74 35                	je     25b97 <__lock+0x47>
   25b62:	b8 01 00 00 00       	mov    $0x1,%eax
   25b67:	87 03                	xchg   %eax,(%ebx)
   25b69:	85 c0                	test   %eax,%eax
   25b6b:	74 2a                	je     25b97 <__lock+0x47>
   25b6d:	8d 73 04             	lea    0x4(%ebx),%esi
   25b70:	c7 44 24 0c 01 00 00 	movl   $0x1,0xc(%esp)
   25b77:	00 
   25b78:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
   25b7f:	00 
   25b80:	89 74 24 04          	mov    %esi,0x4(%esp)
   25b84:	89 1c 24             	mov    %ebx,(%esp)
   25b87:	e8 fc ff ff ff       	call   25b88 <__lock+0x38>
   25b8c:	b8 01 00 00 00       	mov    $0x1,%eax
   25b91:	87 03                	xchg   %eax,(%ebx)
   25b93:	85 c0                	test   %eax,%eax
   25b95:	75 d9                	jne    25b70 <__lock+0x20>
   25b97:	83 c4 14             	add    $0x14,%esp
   25b9a:	5b                   	pop    %ebx
   25b9b:	5e                   	pop    %esi
   25b9c:	c3                   	ret    
   25b9d:	8d 76 00             	lea    0x0(%esi),%esi

00025ba0 <__unlock>:
   25ba0:	53                   	push   %ebx
   25ba1:	83 ec 28             	sub    $0x28,%esp
   25ba4:	8b 5c 24 30          	mov    0x30(%esp),%ebx
   25ba8:	8b 03                	mov    (%ebx),%eax
   25baa:	85 c0                	test   %eax,%eax
   25bac:	74 10                	je     25bbe <__unlock+0x1e>
   25bae:	31 c0                	xor    %eax,%eax
   25bb0:	89 03                	mov    %eax,(%ebx)
   25bb2:	f0 83 0c 24 00       	lock orl $0x0,(%esp)
   25bb7:	8b 43 04             	mov    0x4(%ebx),%eax
   25bba:	85 c0                	test   %eax,%eax
   25bbc:	75 0a                	jne    25bc8 <__unlock+0x28>
   25bbe:	83 c4 28             	add    $0x28,%esp
   25bc1:	5b                   	pop    %ebx
   25bc2:	c3                   	ret    
   25bc3:	90                   	nop
   25bc4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25bc8:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   25bcf:	00 
   25bd0:	b8 f0 00 00 00       	mov    $0xf0,%eax
   25bd5:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   25bdc:	00 
   25bdd:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   25be4:	00 
   25be5:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   25bec:	00 
   25bed:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
   25bf4:	00 
   25bf5:	c7 44 24 04 81 00 00 	movl   $0x81,0x4(%esp)
   25bfc:	00 
   25bfd:	89 1c 24             	mov    %ebx,(%esp)
   25c00:	e8 fc ff ff ff       	call   25c01 <__unlock+0x61>
   25c05:	83 f8 da             	cmp    $0xffffffda,%eax
   25c08:	75 b4                	jne    25bbe <__unlock+0x1e>
   25c0a:	c7 44 24 18 00 00 00 	movl   $0x0,0x18(%esp)
   25c11:	00 
   25c12:	b8 f0 00 00 00       	mov    $0xf0,%eax
   25c17:	c7 44 24 14 00 00 00 	movl   $0x0,0x14(%esp)
   25c1e:	00 
   25c1f:	c7 44 24 10 00 00 00 	movl   $0x0,0x10(%esp)
   25c26:	00 
   25c27:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%esp)
   25c2e:	00 
   25c2f:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%esp)
   25c36:	00 
   25c37:	c7 44 24 04 01 00 00 	movl   $0x1,0x4(%esp)
   25c3e:	00 
   25c3f:	89 1c 24             	mov    %ebx,(%esp)
   25c42:	e8 fc ff ff ff       	call   25c43 <__unlock+0xa3>
   25c47:	e9 72 ff ff ff       	jmp    25bbe <__unlock+0x1e>
   25c4c:	66 90                	xchg   %ax,%ax
   25c4e:	66 90                	xchg   %ax,%ax

00025c50 <__ffsdi2>:
   25c50:	8b 44 24 04          	mov    0x4(%esp),%eax
   25c54:	8b 54 24 08          	mov    0x8(%esp),%edx
   25c58:	85 c0                	test   %eax,%eax
   25c5a:	74 14                	je     25c70 <__ffsdi2+0x20>
   25c5c:	b9 01 00 00 00       	mov    $0x1,%ecx
   25c61:	f3 0f bc c0          	tzcnt  %eax,%eax
   25c65:	01 c8                	add    %ecx,%eax
   25c67:	f3 c3                	repz ret 
   25c69:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25c70:	85 d2                	test   %edx,%edx
   25c72:	89 d0                	mov    %edx,%eax
   25c74:	74 f1                	je     25c67 <__ffsdi2+0x17>
   25c76:	b9 21 00 00 00       	mov    $0x21,%ecx
   25c7b:	eb e4                	jmp    25c61 <__ffsdi2+0x11>
   25c7d:	66 90                	xchg   %ax,%ax
   25c7f:	90                   	nop

00025c80 <__popcountsi2>:
   25c80:	57                   	push   %edi
   25c81:	31 c0                	xor    %eax,%eax
   25c83:	56                   	push   %esi
   25c84:	31 c9                	xor    %ecx,%ecx
   25c86:	53                   	push   %ebx
   25c87:	8b 7c 24 10          	mov    0x10(%esp),%edi
   25c8b:	e8 fc ff ff ff       	call   25c8c <__popcountsi2+0xc>
   25c90:	81 c3 02 00 00 00    	add    $0x2,%ebx
   25c96:	8b b3 00 00 00 00    	mov    0x0(%ebx),%esi
   25c9c:	89 fa                	mov    %edi,%edx
   25c9e:	d3 ea                	shr    %cl,%edx
   25ca0:	83 c1 08             	add    $0x8,%ecx
   25ca3:	0f b6 d2             	movzbl %dl,%edx
   25ca6:	0f b6 14 16          	movzbl (%esi,%edx,1),%edx
   25caa:	01 d0                	add    %edx,%eax
   25cac:	83 f9 20             	cmp    $0x20,%ecx
   25caf:	75 eb                	jne    25c9c <__popcountsi2+0x1c>
   25cb1:	5b                   	pop    %ebx
   25cb2:	5e                   	pop    %esi
   25cb3:	5f                   	pop    %edi
   25cb4:	c3                   	ret    
   25cb5:	66 90                	xchg   %ax,%ax
   25cb7:	66 90                	xchg   %ax,%ax
   25cb9:	66 90                	xchg   %ax,%ax
   25cbb:	66 90                	xchg   %ax,%ax
   25cbd:	66 90                	xchg   %ax,%ax
   25cbf:	90                   	nop

00025cc0 <__udivdi3>:
   25cc0:	55                   	push   %ebp
   25cc1:	57                   	push   %edi
   25cc2:	56                   	push   %esi
   25cc3:	83 ec 0c             	sub    $0xc,%esp
   25cc6:	8b 44 24 28          	mov    0x28(%esp),%eax
   25cca:	8b 7c 24 1c          	mov    0x1c(%esp),%edi
   25cce:	8b 6c 24 20          	mov    0x20(%esp),%ebp
   25cd2:	8b 4c 24 24          	mov    0x24(%esp),%ecx
   25cd6:	85 c0                	test   %eax,%eax
   25cd8:	89 7c 24 04          	mov    %edi,0x4(%esp)
   25cdc:	89 ea                	mov    %ebp,%edx
   25cde:	89 0c 24             	mov    %ecx,(%esp)
   25ce1:	75 2d                	jne    25d10 <__udivdi3+0x50>
   25ce3:	39 e9                	cmp    %ebp,%ecx
   25ce5:	77 61                	ja     25d48 <__udivdi3+0x88>
   25ce7:	85 c9                	test   %ecx,%ecx
   25ce9:	89 ce                	mov    %ecx,%esi
   25ceb:	75 0b                	jne    25cf8 <__udivdi3+0x38>
   25ced:	b8 01 00 00 00       	mov    $0x1,%eax
   25cf2:	31 d2                	xor    %edx,%edx
   25cf4:	f7 f1                	div    %ecx
   25cf6:	89 c6                	mov    %eax,%esi
   25cf8:	31 d2                	xor    %edx,%edx
   25cfa:	89 e8                	mov    %ebp,%eax
   25cfc:	f7 f6                	div    %esi
   25cfe:	89 c5                	mov    %eax,%ebp
   25d00:	89 f8                	mov    %edi,%eax
   25d02:	f7 f6                	div    %esi
   25d04:	89 ea                	mov    %ebp,%edx
   25d06:	83 c4 0c             	add    $0xc,%esp
   25d09:	5e                   	pop    %esi
   25d0a:	5f                   	pop    %edi
   25d0b:	5d                   	pop    %ebp
   25d0c:	c3                   	ret    
   25d0d:	8d 76 00             	lea    0x0(%esi),%esi
   25d10:	39 e8                	cmp    %ebp,%eax
   25d12:	77 24                	ja     25d38 <__udivdi3+0x78>
   25d14:	0f bd e8             	bsr    %eax,%ebp
   25d17:	83 f5 1f             	xor    $0x1f,%ebp
   25d1a:	75 3c                	jne    25d58 <__udivdi3+0x98>
   25d1c:	8b 74 24 04          	mov    0x4(%esp),%esi
   25d20:	39 34 24             	cmp    %esi,(%esp)
   25d23:	0f 86 9f 00 00 00    	jbe    25dc8 <__udivdi3+0x108>
   25d29:	39 d0                	cmp    %edx,%eax
   25d2b:	0f 82 97 00 00 00    	jb     25dc8 <__udivdi3+0x108>
   25d31:	8d b4 26 00 00 00 00 	lea    0x0(%esi,%eiz,1),%esi
   25d38:	31 d2                	xor    %edx,%edx
   25d3a:	31 c0                	xor    %eax,%eax
   25d3c:	83 c4 0c             	add    $0xc,%esp
   25d3f:	5e                   	pop    %esi
   25d40:	5f                   	pop    %edi
   25d41:	5d                   	pop    %ebp
   25d42:	c3                   	ret    
   25d43:	90                   	nop
   25d44:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25d48:	89 f8                	mov    %edi,%eax
   25d4a:	f7 f1                	div    %ecx
   25d4c:	31 d2                	xor    %edx,%edx
   25d4e:	83 c4 0c             	add    $0xc,%esp
   25d51:	5e                   	pop    %esi
   25d52:	5f                   	pop    %edi
   25d53:	5d                   	pop    %ebp
   25d54:	c3                   	ret    
   25d55:	8d 76 00             	lea    0x0(%esi),%esi
   25d58:	89 e9                	mov    %ebp,%ecx
   25d5a:	8b 3c 24             	mov    (%esp),%edi
   25d5d:	d3 e0                	shl    %cl,%eax
   25d5f:	89 c6                	mov    %eax,%esi
   25d61:	b8 20 00 00 00       	mov    $0x20,%eax
   25d66:	29 e8                	sub    %ebp,%eax
   25d68:	89 c1                	mov    %eax,%ecx
   25d6a:	d3 ef                	shr    %cl,%edi
   25d6c:	89 e9                	mov    %ebp,%ecx
   25d6e:	89 7c 24 08          	mov    %edi,0x8(%esp)
   25d72:	8b 3c 24             	mov    (%esp),%edi
   25d75:	09 74 24 08          	or     %esi,0x8(%esp)
   25d79:	89 d6                	mov    %edx,%esi
   25d7b:	d3 e7                	shl    %cl,%edi
   25d7d:	89 c1                	mov    %eax,%ecx
   25d7f:	89 3c 24             	mov    %edi,(%esp)
   25d82:	8b 7c 24 04          	mov    0x4(%esp),%edi
   25d86:	d3 ee                	shr    %cl,%esi
   25d88:	89 e9                	mov    %ebp,%ecx
   25d8a:	d3 e2                	shl    %cl,%edx
   25d8c:	89 c1                	mov    %eax,%ecx
   25d8e:	d3 ef                	shr    %cl,%edi
   25d90:	09 d7                	or     %edx,%edi
   25d92:	89 f2                	mov    %esi,%edx
   25d94:	89 f8                	mov    %edi,%eax
   25d96:	f7 74 24 08          	divl   0x8(%esp)
   25d9a:	89 d6                	mov    %edx,%esi
   25d9c:	89 c7                	mov    %eax,%edi
   25d9e:	f7 24 24             	mull   (%esp)
   25da1:	39 d6                	cmp    %edx,%esi
   25da3:	89 14 24             	mov    %edx,(%esp)
   25da6:	72 30                	jb     25dd8 <__udivdi3+0x118>
   25da8:	8b 54 24 04          	mov    0x4(%esp),%edx
   25dac:	89 e9                	mov    %ebp,%ecx
   25dae:	d3 e2                	shl    %cl,%edx
   25db0:	39 c2                	cmp    %eax,%edx
   25db2:	73 05                	jae    25db9 <__udivdi3+0xf9>
   25db4:	3b 34 24             	cmp    (%esp),%esi
   25db7:	74 1f                	je     25dd8 <__udivdi3+0x118>
   25db9:	89 f8                	mov    %edi,%eax
   25dbb:	31 d2                	xor    %edx,%edx
   25dbd:	e9 7a ff ff ff       	jmp    25d3c <__udivdi3+0x7c>
   25dc2:	8d b6 00 00 00 00    	lea    0x0(%esi),%esi
   25dc8:	31 d2                	xor    %edx,%edx
   25dca:	b8 01 00 00 00       	mov    $0x1,%eax
   25dcf:	e9 68 ff ff ff       	jmp    25d3c <__udivdi3+0x7c>
   25dd4:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25dd8:	8d 47 ff             	lea    -0x1(%edi),%eax
   25ddb:	31 d2                	xor    %edx,%edx
   25ddd:	83 c4 0c             	add    $0xc,%esp
   25de0:	5e                   	pop    %esi
   25de1:	5f                   	pop    %edi
   25de2:	5d                   	pop    %ebp
   25de3:	c3                   	ret    
   25de4:	66 90                	xchg   %ax,%ax
   25de6:	66 90                	xchg   %ax,%ax
   25de8:	66 90                	xchg   %ax,%ax
   25dea:	66 90                	xchg   %ax,%ax
   25dec:	66 90                	xchg   %ax,%ax
   25dee:	66 90                	xchg   %ax,%ax

00025df0 <__umoddi3>:
   25df0:	55                   	push   %ebp
   25df1:	57                   	push   %edi
   25df2:	56                   	push   %esi
   25df3:	83 ec 14             	sub    $0x14,%esp
   25df6:	8b 44 24 28          	mov    0x28(%esp),%eax
   25dfa:	8b 4c 24 24          	mov    0x24(%esp),%ecx
   25dfe:	8b 74 24 2c          	mov    0x2c(%esp),%esi
   25e02:	89 c7                	mov    %eax,%edi
   25e04:	89 44 24 04          	mov    %eax,0x4(%esp)
   25e08:	8b 44 24 30          	mov    0x30(%esp),%eax
   25e0c:	89 4c 24 10          	mov    %ecx,0x10(%esp)
   25e10:	89 34 24             	mov    %esi,(%esp)
   25e13:	89 4c 24 08          	mov    %ecx,0x8(%esp)
   25e17:	85 c0                	test   %eax,%eax
   25e19:	89 c2                	mov    %eax,%edx
   25e1b:	89 7c 24 0c          	mov    %edi,0xc(%esp)
   25e1f:	75 17                	jne    25e38 <__umoddi3+0x48>
   25e21:	39 fe                	cmp    %edi,%esi
   25e23:	76 4b                	jbe    25e70 <__umoddi3+0x80>
   25e25:	89 c8                	mov    %ecx,%eax
   25e27:	89 fa                	mov    %edi,%edx
   25e29:	f7 f6                	div    %esi
   25e2b:	89 d0                	mov    %edx,%eax
   25e2d:	31 d2                	xor    %edx,%edx
   25e2f:	83 c4 14             	add    $0x14,%esp
   25e32:	5e                   	pop    %esi
   25e33:	5f                   	pop    %edi
   25e34:	5d                   	pop    %ebp
   25e35:	c3                   	ret    
   25e36:	66 90                	xchg   %ax,%ax
   25e38:	39 f8                	cmp    %edi,%eax
   25e3a:	77 54                	ja     25e90 <__umoddi3+0xa0>
   25e3c:	0f bd e8             	bsr    %eax,%ebp
   25e3f:	83 f5 1f             	xor    $0x1f,%ebp
   25e42:	75 5c                	jne    25ea0 <__umoddi3+0xb0>
   25e44:	8b 7c 24 08          	mov    0x8(%esp),%edi
   25e48:	39 3c 24             	cmp    %edi,(%esp)
   25e4b:	0f 87 e7 00 00 00    	ja     25f38 <__umoddi3+0x148>
   25e51:	8b 7c 24 04          	mov    0x4(%esp),%edi
   25e55:	29 f1                	sub    %esi,%ecx
   25e57:	19 c7                	sbb    %eax,%edi
   25e59:	89 4c 24 08          	mov    %ecx,0x8(%esp)
   25e5d:	89 7c 24 0c          	mov    %edi,0xc(%esp)
   25e61:	8b 44 24 08          	mov    0x8(%esp),%eax
   25e65:	8b 54 24 0c          	mov    0xc(%esp),%edx
   25e69:	83 c4 14             	add    $0x14,%esp
   25e6c:	5e                   	pop    %esi
   25e6d:	5f                   	pop    %edi
   25e6e:	5d                   	pop    %ebp
   25e6f:	c3                   	ret    
   25e70:	85 f6                	test   %esi,%esi
   25e72:	89 f5                	mov    %esi,%ebp
   25e74:	75 0b                	jne    25e81 <__umoddi3+0x91>
   25e76:	b8 01 00 00 00       	mov    $0x1,%eax
   25e7b:	31 d2                	xor    %edx,%edx
   25e7d:	f7 f6                	div    %esi
   25e7f:	89 c5                	mov    %eax,%ebp
   25e81:	8b 44 24 04          	mov    0x4(%esp),%eax
   25e85:	31 d2                	xor    %edx,%edx
   25e87:	f7 f5                	div    %ebp
   25e89:	89 c8                	mov    %ecx,%eax
   25e8b:	f7 f5                	div    %ebp
   25e8d:	eb 9c                	jmp    25e2b <__umoddi3+0x3b>
   25e8f:	90                   	nop
   25e90:	89 c8                	mov    %ecx,%eax
   25e92:	89 fa                	mov    %edi,%edx
   25e94:	83 c4 14             	add    $0x14,%esp
   25e97:	5e                   	pop    %esi
   25e98:	5f                   	pop    %edi
   25e99:	5d                   	pop    %ebp
   25e9a:	c3                   	ret    
   25e9b:	90                   	nop
   25e9c:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25ea0:	8b 04 24             	mov    (%esp),%eax
   25ea3:	be 20 00 00 00       	mov    $0x20,%esi
   25ea8:	89 e9                	mov    %ebp,%ecx
   25eaa:	29 ee                	sub    %ebp,%esi
   25eac:	d3 e2                	shl    %cl,%edx
   25eae:	89 f1                	mov    %esi,%ecx
   25eb0:	d3 e8                	shr    %cl,%eax
   25eb2:	89 e9                	mov    %ebp,%ecx
   25eb4:	89 44 24 04          	mov    %eax,0x4(%esp)
   25eb8:	8b 04 24             	mov    (%esp),%eax
   25ebb:	09 54 24 04          	or     %edx,0x4(%esp)
   25ebf:	89 fa                	mov    %edi,%edx
   25ec1:	d3 e0                	shl    %cl,%eax
   25ec3:	89 f1                	mov    %esi,%ecx
   25ec5:	89 44 24 08          	mov    %eax,0x8(%esp)
   25ec9:	8b 44 24 10          	mov    0x10(%esp),%eax
   25ecd:	d3 ea                	shr    %cl,%edx
   25ecf:	89 e9                	mov    %ebp,%ecx
   25ed1:	d3 e7                	shl    %cl,%edi
   25ed3:	89 f1                	mov    %esi,%ecx
   25ed5:	d3 e8                	shr    %cl,%eax
   25ed7:	89 e9                	mov    %ebp,%ecx
   25ed9:	09 f8                	or     %edi,%eax
   25edb:	8b 7c 24 10          	mov    0x10(%esp),%edi
   25edf:	f7 74 24 04          	divl   0x4(%esp)
   25ee3:	d3 e7                	shl    %cl,%edi
   25ee5:	89 7c 24 0c          	mov    %edi,0xc(%esp)
   25ee9:	89 d7                	mov    %edx,%edi
   25eeb:	f7 64 24 08          	mull   0x8(%esp)
   25eef:	39 d7                	cmp    %edx,%edi
   25ef1:	89 c1                	mov    %eax,%ecx
   25ef3:	89 14 24             	mov    %edx,(%esp)
   25ef6:	72 2c                	jb     25f24 <__umoddi3+0x134>
   25ef8:	39 44 24 0c          	cmp    %eax,0xc(%esp)
   25efc:	72 22                	jb     25f20 <__umoddi3+0x130>
   25efe:	8b 44 24 0c          	mov    0xc(%esp),%eax
   25f02:	29 c8                	sub    %ecx,%eax
   25f04:	19 d7                	sbb    %edx,%edi
   25f06:	89 e9                	mov    %ebp,%ecx
   25f08:	89 fa                	mov    %edi,%edx
   25f0a:	d3 e8                	shr    %cl,%eax
   25f0c:	89 f1                	mov    %esi,%ecx
   25f0e:	d3 e2                	shl    %cl,%edx
   25f10:	89 e9                	mov    %ebp,%ecx
   25f12:	d3 ef                	shr    %cl,%edi
   25f14:	09 d0                	or     %edx,%eax
   25f16:	89 fa                	mov    %edi,%edx
   25f18:	83 c4 14             	add    $0x14,%esp
   25f1b:	5e                   	pop    %esi
   25f1c:	5f                   	pop    %edi
   25f1d:	5d                   	pop    %ebp
   25f1e:	c3                   	ret    
   25f1f:	90                   	nop
   25f20:	39 d7                	cmp    %edx,%edi
   25f22:	75 da                	jne    25efe <__umoddi3+0x10e>
   25f24:	8b 14 24             	mov    (%esp),%edx
   25f27:	89 c1                	mov    %eax,%ecx
   25f29:	2b 4c 24 08          	sub    0x8(%esp),%ecx
   25f2d:	1b 54 24 04          	sbb    0x4(%esp),%edx
   25f31:	eb cb                	jmp    25efe <__umoddi3+0x10e>
   25f33:	90                   	nop
   25f34:	8d 74 26 00          	lea    0x0(%esi,%eiz,1),%esi
   25f38:	3b 44 24 0c          	cmp    0xc(%esp),%eax
   25f3c:	0f 82 0f ff ff ff    	jb     25e51 <__umoddi3+0x61>
   25f42:	e9 1a ff ff ff       	jmp    25e61 <__umoddi3+0x71>

Disassembly of section .text.__x86.get_pc_thunk.bx:

00000000 <__x86.get_pc_thunk.bx>:
   0:	8b 1c 24             	mov    (%esp),%ebx
   3:	c3                   	ret    
